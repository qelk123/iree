*** IR Dump After NVVMReflectPass on main_dispatch_0_matmul_1x3x4_f32 ***
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 63
  %6 = icmp eq i64 %5, 0
  call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 63
  %9 = icmp eq i64 %8, 0
  call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i32 16
  %11 = ptrtoint ptr addrspace(1) %10 to i64
  %12 = and i64 %11, 63
  %13 = icmp eq i64 %12, 0
  call void @llvm.assume(i1 %13)
  %14 = ptrtoint ptr addrspace(1) %2 to i64
  %15 = and i64 %14, 63
  %16 = icmp eq i64 %15, 0
  call void @llvm.assume(i1 %16)
  %17 = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x()
  %18 = sext i32 %17 to i64
  %19 = getelementptr float, ptr addrspace(1) %0, i64 0
  %20 = load <4 x float>, ptr addrspace(1) %19, align 4
  %21 = add i64 0, %18
  %22 = getelementptr float, ptr addrspace(1) %1, i64 %21
  %23 = load float, ptr addrspace(1) %22, align 4
  %24 = insertelement <1 x float> undef, float %23, i32 0
  %25 = shufflevector <1 x float> %24, <1 x float> undef, <1 x i32> zeroinitializer
  %26 = add i64 3, %18
  %27 = getelementptr float, ptr addrspace(1) %1, i64 %26
  %28 = load float, ptr addrspace(1) %27, align 4
  %29 = insertelement <1 x float> undef, float %28, i32 0
  %30 = shufflevector <1 x float> %29, <1 x float> undef, <1 x i32> zeroinitializer
  %31 = add i64 6, %18
  %32 = getelementptr float, ptr addrspace(1) %1, i64 %31
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i32 0
  %35 = shufflevector <1 x float> %34, <1 x float> undef, <1 x i32> zeroinitializer
  %36 = add i64 9, %18
  %37 = getelementptr float, ptr addrspace(1) %1, i64 %36
  %38 = load float, ptr addrspace(1) %37, align 4
  %39 = insertelement <1 x float> undef, float %38, i32 0
  %40 = shufflevector <1 x float> %39, <1 x float> undef, <1 x i32> zeroinitializer
  %41 = getelementptr float, ptr addrspace(1) %10, i64 %21
  %42 = load float, ptr addrspace(1) %41, align 4
  %43 = insertelement <1 x float> undef, float %42, i32 0
  %44 = shufflevector <1 x float> %43, <1 x float> undef, <1 x i32> zeroinitializer
  %45 = extractelement <4 x float> %20, i64 0
  %46 = insertelement <1 x float> undef, float %45, i32 0
  %47 = shufflevector <1 x float> %46, <1 x float> undef, <1 x i32> zeroinitializer
  %48 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %47, <1 x float> %25, <1 x float> %44)
  %49 = extractelement <4 x float> %20, i64 1
  %50 = insertelement <1 x float> undef, float %49, i32 0
  %51 = shufflevector <1 x float> %50, <1 x float> undef, <1 x i32> zeroinitializer
  %52 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %51, <1 x float> %30, <1 x float> %48)
  %53 = extractelement <4 x float> %20, i64 2
  %54 = insertelement <1 x float> undef, float %53, i32 0
  %55 = shufflevector <1 x float> %54, <1 x float> undef, <1 x i32> zeroinitializer
  %56 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %55, <1 x float> %35, <1 x float> %52)
  %57 = extractelement <4 x float> %20, i64 3
  %58 = insertelement <1 x float> undef, float %57, i32 0
  %59 = shufflevector <1 x float> %58, <1 x float> undef, <1 x i32> zeroinitializer
  %60 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %59, <1 x float> %40, <1 x float> %56)
  %61 = extractelement <1 x float> %60, i64 0
  %62 = getelementptr float, ptr addrspace(1) %2, i64 %21
  store float %61, ptr addrspace(1) %62, align 4
  ret void
}
*** IR Dump After VerifierPass on [module] ***
; ModuleID = 'main_dispatch_0'
source_filename = "main_dispatch_0"
target datalayout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64"
target triple = "nvptx64-nvidia-cuda"

declare ptr @malloc(i64)

declare void @free(ptr)

define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 63
  %6 = icmp eq i64 %5, 0
  call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 63
  %9 = icmp eq i64 %8, 0
  call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i32 16
  %11 = ptrtoint ptr addrspace(1) %10 to i64
  %12 = and i64 %11, 63
  %13 = icmp eq i64 %12, 0
  call void @llvm.assume(i1 %13)
  %14 = ptrtoint ptr addrspace(1) %2 to i64
  %15 = and i64 %14, 63
  %16 = icmp eq i64 %15, 0
  call void @llvm.assume(i1 %16)
  %17 = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x()
  %18 = sext i32 %17 to i64
  %19 = getelementptr float, ptr addrspace(1) %0, i64 0
  %20 = load <4 x float>, ptr addrspace(1) %19, align 4
  %21 = add i64 0, %18
  %22 = getelementptr float, ptr addrspace(1) %1, i64 %21
  %23 = load float, ptr addrspace(1) %22, align 4
  %24 = insertelement <1 x float> undef, float %23, i32 0
  %25 = shufflevector <1 x float> %24, <1 x float> undef, <1 x i32> zeroinitializer
  %26 = add i64 3, %18
  %27 = getelementptr float, ptr addrspace(1) %1, i64 %26
  %28 = load float, ptr addrspace(1) %27, align 4
  %29 = insertelement <1 x float> undef, float %28, i32 0
  %30 = shufflevector <1 x float> %29, <1 x float> undef, <1 x i32> zeroinitializer
  %31 = add i64 6, %18
  %32 = getelementptr float, ptr addrspace(1) %1, i64 %31
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i32 0
  %35 = shufflevector <1 x float> %34, <1 x float> undef, <1 x i32> zeroinitializer
  %36 = add i64 9, %18
  %37 = getelementptr float, ptr addrspace(1) %1, i64 %36
  %38 = load float, ptr addrspace(1) %37, align 4
  %39 = insertelement <1 x float> undef, float %38, i32 0
  %40 = shufflevector <1 x float> %39, <1 x float> undef, <1 x i32> zeroinitializer
  %41 = getelementptr float, ptr addrspace(1) %10, i64 %21
  %42 = load float, ptr addrspace(1) %41, align 4
  %43 = insertelement <1 x float> undef, float %42, i32 0
  %44 = shufflevector <1 x float> %43, <1 x float> undef, <1 x i32> zeroinitializer
  %45 = extractelement <4 x float> %20, i64 0
  %46 = insertelement <1 x float> undef, float %45, i32 0
  %47 = shufflevector <1 x float> %46, <1 x float> undef, <1 x i32> zeroinitializer
  %48 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %47, <1 x float> %25, <1 x float> %44)
  %49 = extractelement <4 x float> %20, i64 1
  %50 = insertelement <1 x float> undef, float %49, i32 0
  %51 = shufflevector <1 x float> %50, <1 x float> undef, <1 x i32> zeroinitializer
  %52 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %51, <1 x float> %30, <1 x float> %48)
  %53 = extractelement <4 x float> %20, i64 2
  %54 = insertelement <1 x float> undef, float %53, i32 0
  %55 = shufflevector <1 x float> %54, <1 x float> undef, <1 x i32> zeroinitializer
  %56 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %55, <1 x float> %35, <1 x float> %52)
  %57 = extractelement <4 x float> %20, i64 3
  %58 = insertelement <1 x float> undef, float %57, i32 0
  %59 = shufflevector <1 x float> %58, <1 x float> undef, <1 x i32> zeroinitializer
  %60 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %59, <1 x float> %40, <1 x float> %56)
  %61 = extractelement <1 x float> %60, i64 0
  %62 = getelementptr float, ptr addrspace(1) %2, i64 %21
  store float %61, ptr addrspace(1) %62, align 4
  ret void
}

; Function Attrs: nocallback nofree nosync nounwind willreturn memory(inaccessiblemem: write)
declare void @llvm.assume(i1 noundef) #0

; Function Attrs: nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare noundef i32 @llvm.nvvm.read.ptx.sreg.ctaid.x() #1

; Function Attrs: nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare <1 x float> @llvm.fmuladd.v1f32(<1 x float>, <1 x float>, <1 x float>) #1

attributes #0 = { nocallback nofree nosync nounwind willreturn memory(inaccessiblemem: write) }
attributes #1 = { nocallback nofree nosync nounwind speculatable willreturn memory(none) }

!nvvm.annotations = !{!0, !1, !2, !3}

!0 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"kernel", i32 1}
!1 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"maxntidx", i32 1}
!2 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"maxntidy", i32 3}
!3 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"maxntidz", i32 1}
*** IR Dump After SetBlockIdsRangePass on main_dispatch_0_matmul_1x3x4_f32 ***
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 63
  %6 = icmp eq i64 %5, 0
  call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 63
  %9 = icmp eq i64 %8, 0
  call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i32 16
  %11 = ptrtoint ptr addrspace(1) %10 to i64
  %12 = and i64 %11, 63
  %13 = icmp eq i64 %12, 0
  call void @llvm.assume(i1 %13)
  %14 = ptrtoint ptr addrspace(1) %2 to i64
  %15 = and i64 %14, 63
  %16 = icmp eq i64 %15, 0
  call void @llvm.assume(i1 %16)
  %17 = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %18 = sext i32 %17 to i64
  %19 = getelementptr float, ptr addrspace(1) %0, i64 0
  %20 = load <4 x float>, ptr addrspace(1) %19, align 4
  %21 = add i64 0, %18
  %22 = getelementptr float, ptr addrspace(1) %1, i64 %21
  %23 = load float, ptr addrspace(1) %22, align 4
  %24 = insertelement <1 x float> undef, float %23, i32 0
  %25 = shufflevector <1 x float> %24, <1 x float> undef, <1 x i32> zeroinitializer
  %26 = add i64 3, %18
  %27 = getelementptr float, ptr addrspace(1) %1, i64 %26
  %28 = load float, ptr addrspace(1) %27, align 4
  %29 = insertelement <1 x float> undef, float %28, i32 0
  %30 = shufflevector <1 x float> %29, <1 x float> undef, <1 x i32> zeroinitializer
  %31 = add i64 6, %18
  %32 = getelementptr float, ptr addrspace(1) %1, i64 %31
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i32 0
  %35 = shufflevector <1 x float> %34, <1 x float> undef, <1 x i32> zeroinitializer
  %36 = add i64 9, %18
  %37 = getelementptr float, ptr addrspace(1) %1, i64 %36
  %38 = load float, ptr addrspace(1) %37, align 4
  %39 = insertelement <1 x float> undef, float %38, i32 0
  %40 = shufflevector <1 x float> %39, <1 x float> undef, <1 x i32> zeroinitializer
  %41 = getelementptr float, ptr addrspace(1) %10, i64 %21
  %42 = load float, ptr addrspace(1) %41, align 4
  %43 = insertelement <1 x float> undef, float %42, i32 0
  %44 = shufflevector <1 x float> %43, <1 x float> undef, <1 x i32> zeroinitializer
  %45 = extractelement <4 x float> %20, i64 0
  %46 = insertelement <1 x float> undef, float %45, i32 0
  %47 = shufflevector <1 x float> %46, <1 x float> undef, <1 x i32> zeroinitializer
  %48 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %47, <1 x float> %25, <1 x float> %44)
  %49 = extractelement <4 x float> %20, i64 1
  %50 = insertelement <1 x float> undef, float %49, i32 0
  %51 = shufflevector <1 x float> %50, <1 x float> undef, <1 x i32> zeroinitializer
  %52 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %51, <1 x float> %30, <1 x float> %48)
  %53 = extractelement <4 x float> %20, i64 2
  %54 = insertelement <1 x float> undef, float %53, i32 0
  %55 = shufflevector <1 x float> %54, <1 x float> undef, <1 x i32> zeroinitializer
  %56 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %55, <1 x float> %35, <1 x float> %52)
  %57 = extractelement <4 x float> %20, i64 3
  %58 = insertelement <1 x float> undef, float %57, i32 0
  %59 = shufflevector <1 x float> %58, <1 x float> undef, <1 x i32> zeroinitializer
  %60 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %59, <1 x float> %40, <1 x float> %56)
  %61 = extractelement <1 x float> %60, i64 0
  %62 = getelementptr float, ptr addrspace(1) %2, i64 %21
  store float %61, ptr addrspace(1) %62, align 4
  ret void
}
*** IR Dump After Annotation2MetadataPass on [module] ***
; ModuleID = 'main_dispatch_0'
source_filename = "main_dispatch_0"
target datalayout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64"
target triple = "nvptx64-nvidia-cuda"

declare ptr @malloc(i64)

declare void @free(ptr)

define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 63
  %6 = icmp eq i64 %5, 0
  call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 63
  %9 = icmp eq i64 %8, 0
  call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i32 16
  %11 = ptrtoint ptr addrspace(1) %10 to i64
  %12 = and i64 %11, 63
  %13 = icmp eq i64 %12, 0
  call void @llvm.assume(i1 %13)
  %14 = ptrtoint ptr addrspace(1) %2 to i64
  %15 = and i64 %14, 63
  %16 = icmp eq i64 %15, 0
  call void @llvm.assume(i1 %16)
  %17 = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %18 = sext i32 %17 to i64
  %19 = getelementptr float, ptr addrspace(1) %0, i64 0
  %20 = load <4 x float>, ptr addrspace(1) %19, align 4
  %21 = add i64 0, %18
  %22 = getelementptr float, ptr addrspace(1) %1, i64 %21
  %23 = load float, ptr addrspace(1) %22, align 4
  %24 = insertelement <1 x float> undef, float %23, i32 0
  %25 = shufflevector <1 x float> %24, <1 x float> undef, <1 x i32> zeroinitializer
  %26 = add i64 3, %18
  %27 = getelementptr float, ptr addrspace(1) %1, i64 %26
  %28 = load float, ptr addrspace(1) %27, align 4
  %29 = insertelement <1 x float> undef, float %28, i32 0
  %30 = shufflevector <1 x float> %29, <1 x float> undef, <1 x i32> zeroinitializer
  %31 = add i64 6, %18
  %32 = getelementptr float, ptr addrspace(1) %1, i64 %31
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i32 0
  %35 = shufflevector <1 x float> %34, <1 x float> undef, <1 x i32> zeroinitializer
  %36 = add i64 9, %18
  %37 = getelementptr float, ptr addrspace(1) %1, i64 %36
  %38 = load float, ptr addrspace(1) %37, align 4
  %39 = insertelement <1 x float> undef, float %38, i32 0
  %40 = shufflevector <1 x float> %39, <1 x float> undef, <1 x i32> zeroinitializer
  %41 = getelementptr float, ptr addrspace(1) %10, i64 %21
  %42 = load float, ptr addrspace(1) %41, align 4
  %43 = insertelement <1 x float> undef, float %42, i32 0
  %44 = shufflevector <1 x float> %43, <1 x float> undef, <1 x i32> zeroinitializer
  %45 = extractelement <4 x float> %20, i64 0
  %46 = insertelement <1 x float> undef, float %45, i32 0
  %47 = shufflevector <1 x float> %46, <1 x float> undef, <1 x i32> zeroinitializer
  %48 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %47, <1 x float> %25, <1 x float> %44)
  %49 = extractelement <4 x float> %20, i64 1
  %50 = insertelement <1 x float> undef, float %49, i32 0
  %51 = shufflevector <1 x float> %50, <1 x float> undef, <1 x i32> zeroinitializer
  %52 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %51, <1 x float> %30, <1 x float> %48)
  %53 = extractelement <4 x float> %20, i64 2
  %54 = insertelement <1 x float> undef, float %53, i32 0
  %55 = shufflevector <1 x float> %54, <1 x float> undef, <1 x i32> zeroinitializer
  %56 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %55, <1 x float> %35, <1 x float> %52)
  %57 = extractelement <4 x float> %20, i64 3
  %58 = insertelement <1 x float> undef, float %57, i32 0
  %59 = shufflevector <1 x float> %58, <1 x float> undef, <1 x i32> zeroinitializer
  %60 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %59, <1 x float> %40, <1 x float> %56)
  %61 = extractelement <1 x float> %60, i64 0
  %62 = getelementptr float, ptr addrspace(1) %2, i64 %21
  store float %61, ptr addrspace(1) %62, align 4
  ret void
}

; Function Attrs: nocallback nofree nosync nounwind willreturn memory(inaccessiblemem: write)
declare void @llvm.assume(i1 noundef) #0

; Function Attrs: nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare noundef i32 @llvm.nvvm.read.ptx.sreg.ctaid.x() #1

; Function Attrs: nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare <1 x float> @llvm.fmuladd.v1f32(<1 x float>, <1 x float>, <1 x float>) #1

attributes #0 = { nocallback nofree nosync nounwind willreturn memory(inaccessiblemem: write) }
attributes #1 = { nocallback nofree nosync nounwind speculatable willreturn memory(none) }

!nvvm.annotations = !{!0, !1, !2, !3}

!0 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"kernel", i32 1}
!1 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"maxntidx", i32 1}
!2 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"maxntidy", i32 3}
!3 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"maxntidz", i32 1}
!4 = !{i32 0, i32 2147483647}
*** IR Dump After ForceFunctionAttrsPass on [module] ***
; ModuleID = 'main_dispatch_0'
source_filename = "main_dispatch_0"
target datalayout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64"
target triple = "nvptx64-nvidia-cuda"

declare ptr @malloc(i64)

declare void @free(ptr)

define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 63
  %6 = icmp eq i64 %5, 0
  call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 63
  %9 = icmp eq i64 %8, 0
  call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i32 16
  %11 = ptrtoint ptr addrspace(1) %10 to i64
  %12 = and i64 %11, 63
  %13 = icmp eq i64 %12, 0
  call void @llvm.assume(i1 %13)
  %14 = ptrtoint ptr addrspace(1) %2 to i64
  %15 = and i64 %14, 63
  %16 = icmp eq i64 %15, 0
  call void @llvm.assume(i1 %16)
  %17 = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %18 = sext i32 %17 to i64
  %19 = getelementptr float, ptr addrspace(1) %0, i64 0
  %20 = load <4 x float>, ptr addrspace(1) %19, align 4
  %21 = add i64 0, %18
  %22 = getelementptr float, ptr addrspace(1) %1, i64 %21
  %23 = load float, ptr addrspace(1) %22, align 4
  %24 = insertelement <1 x float> undef, float %23, i32 0
  %25 = shufflevector <1 x float> %24, <1 x float> undef, <1 x i32> zeroinitializer
  %26 = add i64 3, %18
  %27 = getelementptr float, ptr addrspace(1) %1, i64 %26
  %28 = load float, ptr addrspace(1) %27, align 4
  %29 = insertelement <1 x float> undef, float %28, i32 0
  %30 = shufflevector <1 x float> %29, <1 x float> undef, <1 x i32> zeroinitializer
  %31 = add i64 6, %18
  %32 = getelementptr float, ptr addrspace(1) %1, i64 %31
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i32 0
  %35 = shufflevector <1 x float> %34, <1 x float> undef, <1 x i32> zeroinitializer
  %36 = add i64 9, %18
  %37 = getelementptr float, ptr addrspace(1) %1, i64 %36
  %38 = load float, ptr addrspace(1) %37, align 4
  %39 = insertelement <1 x float> undef, float %38, i32 0
  %40 = shufflevector <1 x float> %39, <1 x float> undef, <1 x i32> zeroinitializer
  %41 = getelementptr float, ptr addrspace(1) %10, i64 %21
  %42 = load float, ptr addrspace(1) %41, align 4
  %43 = insertelement <1 x float> undef, float %42, i32 0
  %44 = shufflevector <1 x float> %43, <1 x float> undef, <1 x i32> zeroinitializer
  %45 = extractelement <4 x float> %20, i64 0
  %46 = insertelement <1 x float> undef, float %45, i32 0
  %47 = shufflevector <1 x float> %46, <1 x float> undef, <1 x i32> zeroinitializer
  %48 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %47, <1 x float> %25, <1 x float> %44)
  %49 = extractelement <4 x float> %20, i64 1
  %50 = insertelement <1 x float> undef, float %49, i32 0
  %51 = shufflevector <1 x float> %50, <1 x float> undef, <1 x i32> zeroinitializer
  %52 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %51, <1 x float> %30, <1 x float> %48)
  %53 = extractelement <4 x float> %20, i64 2
  %54 = insertelement <1 x float> undef, float %53, i32 0
  %55 = shufflevector <1 x float> %54, <1 x float> undef, <1 x i32> zeroinitializer
  %56 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %55, <1 x float> %35, <1 x float> %52)
  %57 = extractelement <4 x float> %20, i64 3
  %58 = insertelement <1 x float> undef, float %57, i32 0
  %59 = shufflevector <1 x float> %58, <1 x float> undef, <1 x i32> zeroinitializer
  %60 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %59, <1 x float> %40, <1 x float> %56)
  %61 = extractelement <1 x float> %60, i64 0
  %62 = getelementptr float, ptr addrspace(1) %2, i64 %21
  store float %61, ptr addrspace(1) %62, align 4
  ret void
}

; Function Attrs: nocallback nofree nosync nounwind willreturn memory(inaccessiblemem: write)
declare void @llvm.assume(i1 noundef) #0

; Function Attrs: nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare noundef i32 @llvm.nvvm.read.ptx.sreg.ctaid.x() #1

; Function Attrs: nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare <1 x float> @llvm.fmuladd.v1f32(<1 x float>, <1 x float>, <1 x float>) #1

attributes #0 = { nocallback nofree nosync nounwind willreturn memory(inaccessiblemem: write) }
attributes #1 = { nocallback nofree nosync nounwind speculatable willreturn memory(none) }

!nvvm.annotations = !{!0, !1, !2, !3}

!0 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"kernel", i32 1}
!1 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"maxntidx", i32 1}
!2 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"maxntidy", i32 3}
!3 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"maxntidz", i32 1}
!4 = !{i32 0, i32 2147483647}
*** IR Dump After NVVMReflectPass on main_dispatch_0_matmul_1x3x4_f32 ***
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 63
  %6 = icmp eq i64 %5, 0
  call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 63
  %9 = icmp eq i64 %8, 0
  call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i32 16
  %11 = ptrtoint ptr addrspace(1) %10 to i64
  %12 = and i64 %11, 63
  %13 = icmp eq i64 %12, 0
  call void @llvm.assume(i1 %13)
  %14 = ptrtoint ptr addrspace(1) %2 to i64
  %15 = and i64 %14, 63
  %16 = icmp eq i64 %15, 0
  call void @llvm.assume(i1 %16)
  %17 = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %18 = sext i32 %17 to i64
  %19 = getelementptr float, ptr addrspace(1) %0, i64 0
  %20 = load <4 x float>, ptr addrspace(1) %19, align 4
  %21 = add i64 0, %18
  %22 = getelementptr float, ptr addrspace(1) %1, i64 %21
  %23 = load float, ptr addrspace(1) %22, align 4
  %24 = insertelement <1 x float> undef, float %23, i32 0
  %25 = shufflevector <1 x float> %24, <1 x float> undef, <1 x i32> zeroinitializer
  %26 = add i64 3, %18
  %27 = getelementptr float, ptr addrspace(1) %1, i64 %26
  %28 = load float, ptr addrspace(1) %27, align 4
  %29 = insertelement <1 x float> undef, float %28, i32 0
  %30 = shufflevector <1 x float> %29, <1 x float> undef, <1 x i32> zeroinitializer
  %31 = add i64 6, %18
  %32 = getelementptr float, ptr addrspace(1) %1, i64 %31
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i32 0
  %35 = shufflevector <1 x float> %34, <1 x float> undef, <1 x i32> zeroinitializer
  %36 = add i64 9, %18
  %37 = getelementptr float, ptr addrspace(1) %1, i64 %36
  %38 = load float, ptr addrspace(1) %37, align 4
  %39 = insertelement <1 x float> undef, float %38, i32 0
  %40 = shufflevector <1 x float> %39, <1 x float> undef, <1 x i32> zeroinitializer
  %41 = getelementptr float, ptr addrspace(1) %10, i64 %21
  %42 = load float, ptr addrspace(1) %41, align 4
  %43 = insertelement <1 x float> undef, float %42, i32 0
  %44 = shufflevector <1 x float> %43, <1 x float> undef, <1 x i32> zeroinitializer
  %45 = extractelement <4 x float> %20, i64 0
  %46 = insertelement <1 x float> undef, float %45, i32 0
  %47 = shufflevector <1 x float> %46, <1 x float> undef, <1 x i32> zeroinitializer
  %48 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %47, <1 x float> %25, <1 x float> %44)
  %49 = extractelement <4 x float> %20, i64 1
  %50 = insertelement <1 x float> undef, float %49, i32 0
  %51 = shufflevector <1 x float> %50, <1 x float> undef, <1 x i32> zeroinitializer
  %52 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %51, <1 x float> %30, <1 x float> %48)
  %53 = extractelement <4 x float> %20, i64 2
  %54 = insertelement <1 x float> undef, float %53, i32 0
  %55 = shufflevector <1 x float> %54, <1 x float> undef, <1 x i32> zeroinitializer
  %56 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %55, <1 x float> %35, <1 x float> %52)
  %57 = extractelement <4 x float> %20, i64 3
  %58 = insertelement <1 x float> undef, float %57, i32 0
  %59 = shufflevector <1 x float> %58, <1 x float> undef, <1 x i32> zeroinitializer
  %60 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %59, <1 x float> %40, <1 x float> %56)
  %61 = extractelement <1 x float> %60, i64 0
  %62 = getelementptr float, ptr addrspace(1) %2, i64 %21
  store float %61, ptr addrspace(1) %62, align 4
  ret void
}
*** IR Dump After InferFunctionAttrsPass on [module] ***
; ModuleID = 'main_dispatch_0'
source_filename = "main_dispatch_0"
target datalayout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64"
target triple = "nvptx64-nvidia-cuda"

; Function Attrs: mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite)
declare noalias noundef ptr @malloc(i64 noundef) #0

; Function Attrs: mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite)
declare void @free(ptr allocptr nocapture noundef) #1

define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 63
  %6 = icmp eq i64 %5, 0
  call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 63
  %9 = icmp eq i64 %8, 0
  call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i32 16
  %11 = ptrtoint ptr addrspace(1) %10 to i64
  %12 = and i64 %11, 63
  %13 = icmp eq i64 %12, 0
  call void @llvm.assume(i1 %13)
  %14 = ptrtoint ptr addrspace(1) %2 to i64
  %15 = and i64 %14, 63
  %16 = icmp eq i64 %15, 0
  call void @llvm.assume(i1 %16)
  %17 = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %18 = sext i32 %17 to i64
  %19 = getelementptr float, ptr addrspace(1) %0, i64 0
  %20 = load <4 x float>, ptr addrspace(1) %19, align 4
  %21 = add i64 0, %18
  %22 = getelementptr float, ptr addrspace(1) %1, i64 %21
  %23 = load float, ptr addrspace(1) %22, align 4
  %24 = insertelement <1 x float> undef, float %23, i32 0
  %25 = shufflevector <1 x float> %24, <1 x float> undef, <1 x i32> zeroinitializer
  %26 = add i64 3, %18
  %27 = getelementptr float, ptr addrspace(1) %1, i64 %26
  %28 = load float, ptr addrspace(1) %27, align 4
  %29 = insertelement <1 x float> undef, float %28, i32 0
  %30 = shufflevector <1 x float> %29, <1 x float> undef, <1 x i32> zeroinitializer
  %31 = add i64 6, %18
  %32 = getelementptr float, ptr addrspace(1) %1, i64 %31
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i32 0
  %35 = shufflevector <1 x float> %34, <1 x float> undef, <1 x i32> zeroinitializer
  %36 = add i64 9, %18
  %37 = getelementptr float, ptr addrspace(1) %1, i64 %36
  %38 = load float, ptr addrspace(1) %37, align 4
  %39 = insertelement <1 x float> undef, float %38, i32 0
  %40 = shufflevector <1 x float> %39, <1 x float> undef, <1 x i32> zeroinitializer
  %41 = getelementptr float, ptr addrspace(1) %10, i64 %21
  %42 = load float, ptr addrspace(1) %41, align 4
  %43 = insertelement <1 x float> undef, float %42, i32 0
  %44 = shufflevector <1 x float> %43, <1 x float> undef, <1 x i32> zeroinitializer
  %45 = extractelement <4 x float> %20, i64 0
  %46 = insertelement <1 x float> undef, float %45, i32 0
  %47 = shufflevector <1 x float> %46, <1 x float> undef, <1 x i32> zeroinitializer
  %48 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %47, <1 x float> %25, <1 x float> %44)
  %49 = extractelement <4 x float> %20, i64 1
  %50 = insertelement <1 x float> undef, float %49, i32 0
  %51 = shufflevector <1 x float> %50, <1 x float> undef, <1 x i32> zeroinitializer
  %52 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %51, <1 x float> %30, <1 x float> %48)
  %53 = extractelement <4 x float> %20, i64 2
  %54 = insertelement <1 x float> undef, float %53, i32 0
  %55 = shufflevector <1 x float> %54, <1 x float> undef, <1 x i32> zeroinitializer
  %56 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %55, <1 x float> %35, <1 x float> %52)
  %57 = extractelement <4 x float> %20, i64 3
  %58 = insertelement <1 x float> undef, float %57, i32 0
  %59 = shufflevector <1 x float> %58, <1 x float> undef, <1 x i32> zeroinitializer
  %60 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %59, <1 x float> %40, <1 x float> %56)
  %61 = extractelement <1 x float> %60, i64 0
  %62 = getelementptr float, ptr addrspace(1) %2, i64 %21
  store float %61, ptr addrspace(1) %62, align 4
  ret void
}

; Function Attrs: mustprogress nocallback nofree nosync nounwind willreturn memory(inaccessiblemem: write)
declare void @llvm.assume(i1 noundef) #2

; Function Attrs: mustprogress nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare noundef i32 @llvm.nvvm.read.ptx.sreg.ctaid.x() #3

; Function Attrs: mustprogress nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare <1 x float> @llvm.fmuladd.v1f32(<1 x float>, <1 x float>, <1 x float>) #3

attributes #0 = { mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #1 = { mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #2 = { mustprogress nocallback nofree nosync nounwind willreturn memory(inaccessiblemem: write) }
attributes #3 = { mustprogress nocallback nofree nosync nounwind speculatable willreturn memory(none) }

!nvvm.annotations = !{!0, !1, !2, !3}

!0 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"kernel", i32 1}
!1 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"maxntidx", i32 1}
!2 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"maxntidy", i32 3}
!3 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"maxntidz", i32 1}
!4 = !{i32 0, i32 2147483647}
*** IR Dump After CoroEarlyPass on [module] ***
; ModuleID = 'main_dispatch_0'
source_filename = "main_dispatch_0"
target datalayout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64"
target triple = "nvptx64-nvidia-cuda"

; Function Attrs: mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite)
declare noalias noundef ptr @malloc(i64 noundef) #0

; Function Attrs: mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite)
declare void @free(ptr allocptr nocapture noundef) #1

define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 63
  %6 = icmp eq i64 %5, 0
  call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 63
  %9 = icmp eq i64 %8, 0
  call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i32 16
  %11 = ptrtoint ptr addrspace(1) %10 to i64
  %12 = and i64 %11, 63
  %13 = icmp eq i64 %12, 0
  call void @llvm.assume(i1 %13)
  %14 = ptrtoint ptr addrspace(1) %2 to i64
  %15 = and i64 %14, 63
  %16 = icmp eq i64 %15, 0
  call void @llvm.assume(i1 %16)
  %17 = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %18 = sext i32 %17 to i64
  %19 = getelementptr float, ptr addrspace(1) %0, i64 0
  %20 = load <4 x float>, ptr addrspace(1) %19, align 4
  %21 = add i64 0, %18
  %22 = getelementptr float, ptr addrspace(1) %1, i64 %21
  %23 = load float, ptr addrspace(1) %22, align 4
  %24 = insertelement <1 x float> undef, float %23, i32 0
  %25 = shufflevector <1 x float> %24, <1 x float> undef, <1 x i32> zeroinitializer
  %26 = add i64 3, %18
  %27 = getelementptr float, ptr addrspace(1) %1, i64 %26
  %28 = load float, ptr addrspace(1) %27, align 4
  %29 = insertelement <1 x float> undef, float %28, i32 0
  %30 = shufflevector <1 x float> %29, <1 x float> undef, <1 x i32> zeroinitializer
  %31 = add i64 6, %18
  %32 = getelementptr float, ptr addrspace(1) %1, i64 %31
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i32 0
  %35 = shufflevector <1 x float> %34, <1 x float> undef, <1 x i32> zeroinitializer
  %36 = add i64 9, %18
  %37 = getelementptr float, ptr addrspace(1) %1, i64 %36
  %38 = load float, ptr addrspace(1) %37, align 4
  %39 = insertelement <1 x float> undef, float %38, i32 0
  %40 = shufflevector <1 x float> %39, <1 x float> undef, <1 x i32> zeroinitializer
  %41 = getelementptr float, ptr addrspace(1) %10, i64 %21
  %42 = load float, ptr addrspace(1) %41, align 4
  %43 = insertelement <1 x float> undef, float %42, i32 0
  %44 = shufflevector <1 x float> %43, <1 x float> undef, <1 x i32> zeroinitializer
  %45 = extractelement <4 x float> %20, i64 0
  %46 = insertelement <1 x float> undef, float %45, i32 0
  %47 = shufflevector <1 x float> %46, <1 x float> undef, <1 x i32> zeroinitializer
  %48 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %47, <1 x float> %25, <1 x float> %44)
  %49 = extractelement <4 x float> %20, i64 1
  %50 = insertelement <1 x float> undef, float %49, i32 0
  %51 = shufflevector <1 x float> %50, <1 x float> undef, <1 x i32> zeroinitializer
  %52 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %51, <1 x float> %30, <1 x float> %48)
  %53 = extractelement <4 x float> %20, i64 2
  %54 = insertelement <1 x float> undef, float %53, i32 0
  %55 = shufflevector <1 x float> %54, <1 x float> undef, <1 x i32> zeroinitializer
  %56 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %55, <1 x float> %35, <1 x float> %52)
  %57 = extractelement <4 x float> %20, i64 3
  %58 = insertelement <1 x float> undef, float %57, i32 0
  %59 = shufflevector <1 x float> %58, <1 x float> undef, <1 x i32> zeroinitializer
  %60 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %59, <1 x float> %40, <1 x float> %56)
  %61 = extractelement <1 x float> %60, i64 0
  %62 = getelementptr float, ptr addrspace(1) %2, i64 %21
  store float %61, ptr addrspace(1) %62, align 4
  ret void
}

; Function Attrs: mustprogress nocallback nofree nosync nounwind willreturn memory(inaccessiblemem: write)
declare void @llvm.assume(i1 noundef) #2

; Function Attrs: mustprogress nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare noundef i32 @llvm.nvvm.read.ptx.sreg.ctaid.x() #3

; Function Attrs: mustprogress nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare <1 x float> @llvm.fmuladd.v1f32(<1 x float>, <1 x float>, <1 x float>) #3

attributes #0 = { mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #1 = { mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #2 = { mustprogress nocallback nofree nosync nounwind willreturn memory(inaccessiblemem: write) }
attributes #3 = { mustprogress nocallback nofree nosync nounwind speculatable willreturn memory(none) }

!nvvm.annotations = !{!0, !1, !2, !3}

!0 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"kernel", i32 1}
!1 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"maxntidx", i32 1}
!2 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"maxntidy", i32 3}
!3 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"maxntidz", i32 1}
!4 = !{i32 0, i32 2147483647}
*** IR Dump After LowerExpectIntrinsicPass on main_dispatch_0_matmul_1x3x4_f32 ***
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 63
  %6 = icmp eq i64 %5, 0
  call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 63
  %9 = icmp eq i64 %8, 0
  call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i32 16
  %11 = ptrtoint ptr addrspace(1) %10 to i64
  %12 = and i64 %11, 63
  %13 = icmp eq i64 %12, 0
  call void @llvm.assume(i1 %13)
  %14 = ptrtoint ptr addrspace(1) %2 to i64
  %15 = and i64 %14, 63
  %16 = icmp eq i64 %15, 0
  call void @llvm.assume(i1 %16)
  %17 = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %18 = sext i32 %17 to i64
  %19 = getelementptr float, ptr addrspace(1) %0, i64 0
  %20 = load <4 x float>, ptr addrspace(1) %19, align 4
  %21 = add i64 0, %18
  %22 = getelementptr float, ptr addrspace(1) %1, i64 %21
  %23 = load float, ptr addrspace(1) %22, align 4
  %24 = insertelement <1 x float> undef, float %23, i32 0
  %25 = shufflevector <1 x float> %24, <1 x float> undef, <1 x i32> zeroinitializer
  %26 = add i64 3, %18
  %27 = getelementptr float, ptr addrspace(1) %1, i64 %26
  %28 = load float, ptr addrspace(1) %27, align 4
  %29 = insertelement <1 x float> undef, float %28, i32 0
  %30 = shufflevector <1 x float> %29, <1 x float> undef, <1 x i32> zeroinitializer
  %31 = add i64 6, %18
  %32 = getelementptr float, ptr addrspace(1) %1, i64 %31
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i32 0
  %35 = shufflevector <1 x float> %34, <1 x float> undef, <1 x i32> zeroinitializer
  %36 = add i64 9, %18
  %37 = getelementptr float, ptr addrspace(1) %1, i64 %36
  %38 = load float, ptr addrspace(1) %37, align 4
  %39 = insertelement <1 x float> undef, float %38, i32 0
  %40 = shufflevector <1 x float> %39, <1 x float> undef, <1 x i32> zeroinitializer
  %41 = getelementptr float, ptr addrspace(1) %10, i64 %21
  %42 = load float, ptr addrspace(1) %41, align 4
  %43 = insertelement <1 x float> undef, float %42, i32 0
  %44 = shufflevector <1 x float> %43, <1 x float> undef, <1 x i32> zeroinitializer
  %45 = extractelement <4 x float> %20, i64 0
  %46 = insertelement <1 x float> undef, float %45, i32 0
  %47 = shufflevector <1 x float> %46, <1 x float> undef, <1 x i32> zeroinitializer
  %48 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %47, <1 x float> %25, <1 x float> %44)
  %49 = extractelement <4 x float> %20, i64 1
  %50 = insertelement <1 x float> undef, float %49, i32 0
  %51 = shufflevector <1 x float> %50, <1 x float> undef, <1 x i32> zeroinitializer
  %52 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %51, <1 x float> %30, <1 x float> %48)
  %53 = extractelement <4 x float> %20, i64 2
  %54 = insertelement <1 x float> undef, float %53, i32 0
  %55 = shufflevector <1 x float> %54, <1 x float> undef, <1 x i32> zeroinitializer
  %56 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %55, <1 x float> %35, <1 x float> %52)
  %57 = extractelement <4 x float> %20, i64 3
  %58 = insertelement <1 x float> undef, float %57, i32 0
  %59 = shufflevector <1 x float> %58, <1 x float> undef, <1 x i32> zeroinitializer
  %60 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %59, <1 x float> %40, <1 x float> %56)
  %61 = extractelement <1 x float> %60, i64 0
  %62 = getelementptr float, ptr addrspace(1) %2, i64 %21
  store float %61, ptr addrspace(1) %62, align 4
  ret void
}
*** IR Dump After SimplifyCFGPass on main_dispatch_0_matmul_1x3x4_f32 ***
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 63
  %6 = icmp eq i64 %5, 0
  call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 63
  %9 = icmp eq i64 %8, 0
  call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i32 16
  %11 = ptrtoint ptr addrspace(1) %10 to i64
  %12 = and i64 %11, 63
  %13 = icmp eq i64 %12, 0
  call void @llvm.assume(i1 %13)
  %14 = ptrtoint ptr addrspace(1) %2 to i64
  %15 = and i64 %14, 63
  %16 = icmp eq i64 %15, 0
  call void @llvm.assume(i1 %16)
  %17 = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %18 = sext i32 %17 to i64
  %19 = getelementptr float, ptr addrspace(1) %0, i64 0
  %20 = load <4 x float>, ptr addrspace(1) %19, align 4
  %21 = add i64 0, %18
  %22 = getelementptr float, ptr addrspace(1) %1, i64 %21
  %23 = load float, ptr addrspace(1) %22, align 4
  %24 = insertelement <1 x float> undef, float %23, i32 0
  %25 = shufflevector <1 x float> %24, <1 x float> undef, <1 x i32> zeroinitializer
  %26 = add i64 3, %18
  %27 = getelementptr float, ptr addrspace(1) %1, i64 %26
  %28 = load float, ptr addrspace(1) %27, align 4
  %29 = insertelement <1 x float> undef, float %28, i32 0
  %30 = shufflevector <1 x float> %29, <1 x float> undef, <1 x i32> zeroinitializer
  %31 = add i64 6, %18
  %32 = getelementptr float, ptr addrspace(1) %1, i64 %31
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i32 0
  %35 = shufflevector <1 x float> %34, <1 x float> undef, <1 x i32> zeroinitializer
  %36 = add i64 9, %18
  %37 = getelementptr float, ptr addrspace(1) %1, i64 %36
  %38 = load float, ptr addrspace(1) %37, align 4
  %39 = insertelement <1 x float> undef, float %38, i32 0
  %40 = shufflevector <1 x float> %39, <1 x float> undef, <1 x i32> zeroinitializer
  %41 = getelementptr float, ptr addrspace(1) %10, i64 %21
  %42 = load float, ptr addrspace(1) %41, align 4
  %43 = insertelement <1 x float> undef, float %42, i32 0
  %44 = shufflevector <1 x float> %43, <1 x float> undef, <1 x i32> zeroinitializer
  %45 = extractelement <4 x float> %20, i64 0
  %46 = insertelement <1 x float> undef, float %45, i32 0
  %47 = shufflevector <1 x float> %46, <1 x float> undef, <1 x i32> zeroinitializer
  %48 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %47, <1 x float> %25, <1 x float> %44)
  %49 = extractelement <4 x float> %20, i64 1
  %50 = insertelement <1 x float> undef, float %49, i32 0
  %51 = shufflevector <1 x float> %50, <1 x float> undef, <1 x i32> zeroinitializer
  %52 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %51, <1 x float> %30, <1 x float> %48)
  %53 = extractelement <4 x float> %20, i64 2
  %54 = insertelement <1 x float> undef, float %53, i32 0
  %55 = shufflevector <1 x float> %54, <1 x float> undef, <1 x i32> zeroinitializer
  %56 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %55, <1 x float> %35, <1 x float> %52)
  %57 = extractelement <4 x float> %20, i64 3
  %58 = insertelement <1 x float> undef, float %57, i32 0
  %59 = shufflevector <1 x float> %58, <1 x float> undef, <1 x i32> zeroinitializer
  %60 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %59, <1 x float> %40, <1 x float> %56)
  %61 = extractelement <1 x float> %60, i64 0
  %62 = getelementptr float, ptr addrspace(1) %2, i64 %21
  store float %61, ptr addrspace(1) %62, align 4
  ret void
}
*** IR Dump After SROAPass on main_dispatch_0_matmul_1x3x4_f32 ***
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 63
  %6 = icmp eq i64 %5, 0
  call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 63
  %9 = icmp eq i64 %8, 0
  call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i32 16
  %11 = ptrtoint ptr addrspace(1) %10 to i64
  %12 = and i64 %11, 63
  %13 = icmp eq i64 %12, 0
  call void @llvm.assume(i1 %13)
  %14 = ptrtoint ptr addrspace(1) %2 to i64
  %15 = and i64 %14, 63
  %16 = icmp eq i64 %15, 0
  call void @llvm.assume(i1 %16)
  %17 = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %18 = sext i32 %17 to i64
  %19 = getelementptr float, ptr addrspace(1) %0, i64 0
  %20 = load <4 x float>, ptr addrspace(1) %19, align 4
  %21 = add i64 0, %18
  %22 = getelementptr float, ptr addrspace(1) %1, i64 %21
  %23 = load float, ptr addrspace(1) %22, align 4
  %24 = insertelement <1 x float> undef, float %23, i32 0
  %25 = shufflevector <1 x float> %24, <1 x float> undef, <1 x i32> zeroinitializer
  %26 = add i64 3, %18
  %27 = getelementptr float, ptr addrspace(1) %1, i64 %26
  %28 = load float, ptr addrspace(1) %27, align 4
  %29 = insertelement <1 x float> undef, float %28, i32 0
  %30 = shufflevector <1 x float> %29, <1 x float> undef, <1 x i32> zeroinitializer
  %31 = add i64 6, %18
  %32 = getelementptr float, ptr addrspace(1) %1, i64 %31
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i32 0
  %35 = shufflevector <1 x float> %34, <1 x float> undef, <1 x i32> zeroinitializer
  %36 = add i64 9, %18
  %37 = getelementptr float, ptr addrspace(1) %1, i64 %36
  %38 = load float, ptr addrspace(1) %37, align 4
  %39 = insertelement <1 x float> undef, float %38, i32 0
  %40 = shufflevector <1 x float> %39, <1 x float> undef, <1 x i32> zeroinitializer
  %41 = getelementptr float, ptr addrspace(1) %10, i64 %21
  %42 = load float, ptr addrspace(1) %41, align 4
  %43 = insertelement <1 x float> undef, float %42, i32 0
  %44 = shufflevector <1 x float> %43, <1 x float> undef, <1 x i32> zeroinitializer
  %45 = extractelement <4 x float> %20, i64 0
  %46 = insertelement <1 x float> undef, float %45, i32 0
  %47 = shufflevector <1 x float> %46, <1 x float> undef, <1 x i32> zeroinitializer
  %48 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %47, <1 x float> %25, <1 x float> %44)
  %49 = extractelement <4 x float> %20, i64 1
  %50 = insertelement <1 x float> undef, float %49, i32 0
  %51 = shufflevector <1 x float> %50, <1 x float> undef, <1 x i32> zeroinitializer
  %52 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %51, <1 x float> %30, <1 x float> %48)
  %53 = extractelement <4 x float> %20, i64 2
  %54 = insertelement <1 x float> undef, float %53, i32 0
  %55 = shufflevector <1 x float> %54, <1 x float> undef, <1 x i32> zeroinitializer
  %56 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %55, <1 x float> %35, <1 x float> %52)
  %57 = extractelement <4 x float> %20, i64 3
  %58 = insertelement <1 x float> undef, float %57, i32 0
  %59 = shufflevector <1 x float> %58, <1 x float> undef, <1 x i32> zeroinitializer
  %60 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %59, <1 x float> %40, <1 x float> %56)
  %61 = extractelement <1 x float> %60, i64 0
  %62 = getelementptr float, ptr addrspace(1) %2, i64 %21
  store float %61, ptr addrspace(1) %62, align 4
  ret void
}
*** IR Dump After EarlyCSEPass on main_dispatch_0_matmul_1x3x4_f32 ***
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 63
  %6 = icmp eq i64 %5, 0
  call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 63
  %9 = icmp eq i64 %8, 0
  call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i32 16
  %11 = ptrtoint ptr addrspace(1) %10 to i64
  %12 = and i64 %11, 63
  %13 = icmp eq i64 %12, 0
  call void @llvm.assume(i1 %13)
  %14 = ptrtoint ptr addrspace(1) %2 to i64
  %15 = and i64 %14, 63
  %16 = icmp eq i64 %15, 0
  call void @llvm.assume(i1 %16)
  %17 = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %18 = sext i32 %17 to i64
  %19 = load <4 x float>, ptr addrspace(1) %0, align 4
  %20 = getelementptr float, ptr addrspace(1) %1, i64 %18
  %21 = load float, ptr addrspace(1) %20, align 4
  %22 = insertelement <1 x float> undef, float %21, i32 0
  %23 = add i64 3, %18
  %24 = getelementptr float, ptr addrspace(1) %1, i64 %23
  %25 = load float, ptr addrspace(1) %24, align 4
  %26 = insertelement <1 x float> undef, float %25, i32 0
  %27 = add i64 6, %18
  %28 = getelementptr float, ptr addrspace(1) %1, i64 %27
  %29 = load float, ptr addrspace(1) %28, align 4
  %30 = insertelement <1 x float> undef, float %29, i32 0
  %31 = add i64 9, %18
  %32 = getelementptr float, ptr addrspace(1) %1, i64 %31
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i32 0
  %35 = getelementptr float, ptr addrspace(1) %10, i64 %18
  %36 = load float, ptr addrspace(1) %35, align 4
  %37 = insertelement <1 x float> undef, float %36, i32 0
  %38 = extractelement <4 x float> %19, i64 0
  %39 = insertelement <1 x float> undef, float %38, i32 0
  %40 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %22, <1 x float> %37)
  %41 = extractelement <4 x float> %19, i64 1
  %42 = insertelement <1 x float> undef, float %41, i32 0
  %43 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %42, <1 x float> %26, <1 x float> %40)
  %44 = extractelement <4 x float> %19, i64 2
  %45 = insertelement <1 x float> undef, float %44, i32 0
  %46 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %45, <1 x float> %30, <1 x float> %43)
  %47 = extractelement <4 x float> %19, i64 3
  %48 = insertelement <1 x float> undef, float %47, i32 0
  %49 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %48, <1 x float> %34, <1 x float> %46)
  %50 = extractelement <1 x float> %49, i64 0
  %51 = getelementptr float, ptr addrspace(1) %2, i64 %18
  store float %50, ptr addrspace(1) %51, align 4
  ret void
}
*** IR Dump After OpenMPOptPass on [module] ***
; ModuleID = 'main_dispatch_0'
source_filename = "main_dispatch_0"
target datalayout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64"
target triple = "nvptx64-nvidia-cuda"

; Function Attrs: mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite)
declare noalias noundef ptr @malloc(i64 noundef) #0

; Function Attrs: mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite)
declare void @free(ptr allocptr nocapture noundef) #1

define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 63
  %6 = icmp eq i64 %5, 0
  call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 63
  %9 = icmp eq i64 %8, 0
  call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i32 16
  %11 = ptrtoint ptr addrspace(1) %10 to i64
  %12 = and i64 %11, 63
  %13 = icmp eq i64 %12, 0
  call void @llvm.assume(i1 %13)
  %14 = ptrtoint ptr addrspace(1) %2 to i64
  %15 = and i64 %14, 63
  %16 = icmp eq i64 %15, 0
  call void @llvm.assume(i1 %16)
  %17 = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %18 = sext i32 %17 to i64
  %19 = load <4 x float>, ptr addrspace(1) %0, align 4
  %20 = getelementptr float, ptr addrspace(1) %1, i64 %18
  %21 = load float, ptr addrspace(1) %20, align 4
  %22 = insertelement <1 x float> undef, float %21, i32 0
  %23 = add i64 3, %18
  %24 = getelementptr float, ptr addrspace(1) %1, i64 %23
  %25 = load float, ptr addrspace(1) %24, align 4
  %26 = insertelement <1 x float> undef, float %25, i32 0
  %27 = add i64 6, %18
  %28 = getelementptr float, ptr addrspace(1) %1, i64 %27
  %29 = load float, ptr addrspace(1) %28, align 4
  %30 = insertelement <1 x float> undef, float %29, i32 0
  %31 = add i64 9, %18
  %32 = getelementptr float, ptr addrspace(1) %1, i64 %31
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i32 0
  %35 = getelementptr float, ptr addrspace(1) %10, i64 %18
  %36 = load float, ptr addrspace(1) %35, align 4
  %37 = insertelement <1 x float> undef, float %36, i32 0
  %38 = extractelement <4 x float> %19, i64 0
  %39 = insertelement <1 x float> undef, float %38, i32 0
  %40 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %22, <1 x float> %37)
  %41 = extractelement <4 x float> %19, i64 1
  %42 = insertelement <1 x float> undef, float %41, i32 0
  %43 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %42, <1 x float> %26, <1 x float> %40)
  %44 = extractelement <4 x float> %19, i64 2
  %45 = insertelement <1 x float> undef, float %44, i32 0
  %46 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %45, <1 x float> %30, <1 x float> %43)
  %47 = extractelement <4 x float> %19, i64 3
  %48 = insertelement <1 x float> undef, float %47, i32 0
  %49 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %48, <1 x float> %34, <1 x float> %46)
  %50 = extractelement <1 x float> %49, i64 0
  %51 = getelementptr float, ptr addrspace(1) %2, i64 %18
  store float %50, ptr addrspace(1) %51, align 4
  ret void
}

; Function Attrs: mustprogress nocallback nofree nosync nounwind willreturn memory(inaccessiblemem: write)
declare void @llvm.assume(i1 noundef) #2

; Function Attrs: mustprogress nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare noundef i32 @llvm.nvvm.read.ptx.sreg.ctaid.x() #3

; Function Attrs: mustprogress nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare <1 x float> @llvm.fmuladd.v1f32(<1 x float>, <1 x float>, <1 x float>) #3

attributes #0 = { mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #1 = { mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #2 = { mustprogress nocallback nofree nosync nounwind willreturn memory(inaccessiblemem: write) }
attributes #3 = { mustprogress nocallback nofree nosync nounwind speculatable willreturn memory(none) }

!nvvm.annotations = !{!0, !1, !2, !3}

!0 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"kernel", i32 1}
!1 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"maxntidx", i32 1}
!2 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"maxntidy", i32 3}
!3 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"maxntidz", i32 1}
!4 = !{i32 0, i32 2147483647}
*** IR Dump After IPSCCPPass on [module] ***
; ModuleID = 'main_dispatch_0'
source_filename = "main_dispatch_0"
target datalayout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64"
target triple = "nvptx64-nvidia-cuda"

; Function Attrs: mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite)
declare noalias noundef ptr @malloc(i64 noundef) #0

; Function Attrs: mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite)
declare void @free(ptr allocptr nocapture noundef) #1

define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 63
  %6 = icmp eq i64 %5, 0
  call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 63
  %9 = icmp eq i64 %8, 0
  call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i32 16
  %11 = ptrtoint ptr addrspace(1) %10 to i64
  %12 = and i64 %11, 63
  %13 = icmp eq i64 %12, 0
  call void @llvm.assume(i1 %13)
  %14 = ptrtoint ptr addrspace(1) %2 to i64
  %15 = and i64 %14, 63
  %16 = icmp eq i64 %15, 0
  call void @llvm.assume(i1 %16)
  %17 = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %18 = zext i32 %17 to i64
  %19 = load <4 x float>, ptr addrspace(1) %0, align 4
  %20 = getelementptr float, ptr addrspace(1) %1, i64 %18
  %21 = load float, ptr addrspace(1) %20, align 4
  %22 = insertelement <1 x float> undef, float %21, i32 0
  %23 = add i64 3, %18
  %24 = getelementptr float, ptr addrspace(1) %1, i64 %23
  %25 = load float, ptr addrspace(1) %24, align 4
  %26 = insertelement <1 x float> undef, float %25, i32 0
  %27 = add i64 6, %18
  %28 = getelementptr float, ptr addrspace(1) %1, i64 %27
  %29 = load float, ptr addrspace(1) %28, align 4
  %30 = insertelement <1 x float> undef, float %29, i32 0
  %31 = add i64 9, %18
  %32 = getelementptr float, ptr addrspace(1) %1, i64 %31
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i32 0
  %35 = getelementptr float, ptr addrspace(1) %10, i64 %18
  %36 = load float, ptr addrspace(1) %35, align 4
  %37 = insertelement <1 x float> undef, float %36, i32 0
  %38 = extractelement <4 x float> %19, i64 0
  %39 = insertelement <1 x float> undef, float %38, i32 0
  %40 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %22, <1 x float> %37)
  %41 = extractelement <4 x float> %19, i64 1
  %42 = insertelement <1 x float> undef, float %41, i32 0
  %43 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %42, <1 x float> %26, <1 x float> %40)
  %44 = extractelement <4 x float> %19, i64 2
  %45 = insertelement <1 x float> undef, float %44, i32 0
  %46 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %45, <1 x float> %30, <1 x float> %43)
  %47 = extractelement <4 x float> %19, i64 3
  %48 = insertelement <1 x float> undef, float %47, i32 0
  %49 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %48, <1 x float> %34, <1 x float> %46)
  %50 = extractelement <1 x float> %49, i64 0
  %51 = getelementptr float, ptr addrspace(1) %2, i64 %18
  store float %50, ptr addrspace(1) %51, align 4
  ret void
}

; Function Attrs: mustprogress nocallback nofree nosync nounwind willreturn memory(inaccessiblemem: write)
declare void @llvm.assume(i1 noundef) #2

; Function Attrs: mustprogress nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare noundef i32 @llvm.nvvm.read.ptx.sreg.ctaid.x() #3

; Function Attrs: mustprogress nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare <1 x float> @llvm.fmuladd.v1f32(<1 x float>, <1 x float>, <1 x float>) #3

attributes #0 = { mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #1 = { mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #2 = { mustprogress nocallback nofree nosync nounwind willreturn memory(inaccessiblemem: write) }
attributes #3 = { mustprogress nocallback nofree nosync nounwind speculatable willreturn memory(none) }

!nvvm.annotations = !{!0, !1, !2, !3}

!0 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"kernel", i32 1}
!1 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"maxntidx", i32 1}
!2 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"maxntidy", i32 3}
!3 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"maxntidz", i32 1}
!4 = !{i32 0, i32 2147483647}
*** IR Dump After CalledValuePropagationPass on [module] ***
; ModuleID = 'main_dispatch_0'
source_filename = "main_dispatch_0"
target datalayout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64"
target triple = "nvptx64-nvidia-cuda"

; Function Attrs: mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite)
declare noalias noundef ptr @malloc(i64 noundef) #0

; Function Attrs: mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite)
declare void @free(ptr allocptr nocapture noundef) #1

define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 63
  %6 = icmp eq i64 %5, 0
  call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 63
  %9 = icmp eq i64 %8, 0
  call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i32 16
  %11 = ptrtoint ptr addrspace(1) %10 to i64
  %12 = and i64 %11, 63
  %13 = icmp eq i64 %12, 0
  call void @llvm.assume(i1 %13)
  %14 = ptrtoint ptr addrspace(1) %2 to i64
  %15 = and i64 %14, 63
  %16 = icmp eq i64 %15, 0
  call void @llvm.assume(i1 %16)
  %17 = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %18 = zext i32 %17 to i64
  %19 = load <4 x float>, ptr addrspace(1) %0, align 4
  %20 = getelementptr float, ptr addrspace(1) %1, i64 %18
  %21 = load float, ptr addrspace(1) %20, align 4
  %22 = insertelement <1 x float> undef, float %21, i32 0
  %23 = add i64 3, %18
  %24 = getelementptr float, ptr addrspace(1) %1, i64 %23
  %25 = load float, ptr addrspace(1) %24, align 4
  %26 = insertelement <1 x float> undef, float %25, i32 0
  %27 = add i64 6, %18
  %28 = getelementptr float, ptr addrspace(1) %1, i64 %27
  %29 = load float, ptr addrspace(1) %28, align 4
  %30 = insertelement <1 x float> undef, float %29, i32 0
  %31 = add i64 9, %18
  %32 = getelementptr float, ptr addrspace(1) %1, i64 %31
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i32 0
  %35 = getelementptr float, ptr addrspace(1) %10, i64 %18
  %36 = load float, ptr addrspace(1) %35, align 4
  %37 = insertelement <1 x float> undef, float %36, i32 0
  %38 = extractelement <4 x float> %19, i64 0
  %39 = insertelement <1 x float> undef, float %38, i32 0
  %40 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %22, <1 x float> %37)
  %41 = extractelement <4 x float> %19, i64 1
  %42 = insertelement <1 x float> undef, float %41, i32 0
  %43 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %42, <1 x float> %26, <1 x float> %40)
  %44 = extractelement <4 x float> %19, i64 2
  %45 = insertelement <1 x float> undef, float %44, i32 0
  %46 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %45, <1 x float> %30, <1 x float> %43)
  %47 = extractelement <4 x float> %19, i64 3
  %48 = insertelement <1 x float> undef, float %47, i32 0
  %49 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %48, <1 x float> %34, <1 x float> %46)
  %50 = extractelement <1 x float> %49, i64 0
  %51 = getelementptr float, ptr addrspace(1) %2, i64 %18
  store float %50, ptr addrspace(1) %51, align 4
  ret void
}

; Function Attrs: mustprogress nocallback nofree nosync nounwind willreturn memory(inaccessiblemem: write)
declare void @llvm.assume(i1 noundef) #2

; Function Attrs: mustprogress nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare noundef i32 @llvm.nvvm.read.ptx.sreg.ctaid.x() #3

; Function Attrs: mustprogress nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare <1 x float> @llvm.fmuladd.v1f32(<1 x float>, <1 x float>, <1 x float>) #3

attributes #0 = { mustprogress nofree nounwind willreturn allockind("alloc,uninitialized") allocsize(0) memory(inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #1 = { mustprogress nounwind willreturn allockind("free") memory(argmem: readwrite, inaccessiblemem: readwrite) "alloc-family"="malloc" }
attributes #2 = { mustprogress nocallback nofree nosync nounwind willreturn memory(inaccessiblemem: write) }
attributes #3 = { mustprogress nocallback nofree nosync nounwind speculatable willreturn memory(none) }

!nvvm.annotations = !{!0, !1, !2, !3}

!0 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"kernel", i32 1}
!1 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"maxntidx", i32 1}
!2 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"maxntidy", i32 3}
!3 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"maxntidz", i32 1}
!4 = !{i32 0, i32 2147483647}
*** IR Dump After GlobalOptPass on [module] ***
; ModuleID = 'main_dispatch_0'
source_filename = "main_dispatch_0"
target datalayout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64"
target triple = "nvptx64-nvidia-cuda"

define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 63
  %6 = icmp eq i64 %5, 0
  call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 63
  %9 = icmp eq i64 %8, 0
  call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i32 16
  %11 = ptrtoint ptr addrspace(1) %10 to i64
  %12 = and i64 %11, 63
  %13 = icmp eq i64 %12, 0
  call void @llvm.assume(i1 %13)
  %14 = ptrtoint ptr addrspace(1) %2 to i64
  %15 = and i64 %14, 63
  %16 = icmp eq i64 %15, 0
  call void @llvm.assume(i1 %16)
  %17 = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %18 = zext i32 %17 to i64
  %19 = load <4 x float>, ptr addrspace(1) %0, align 4
  %20 = getelementptr float, ptr addrspace(1) %1, i64 %18
  %21 = load float, ptr addrspace(1) %20, align 4
  %22 = insertelement <1 x float> undef, float %21, i32 0
  %23 = add i64 3, %18
  %24 = getelementptr float, ptr addrspace(1) %1, i64 %23
  %25 = load float, ptr addrspace(1) %24, align 4
  %26 = insertelement <1 x float> undef, float %25, i32 0
  %27 = add i64 6, %18
  %28 = getelementptr float, ptr addrspace(1) %1, i64 %27
  %29 = load float, ptr addrspace(1) %28, align 4
  %30 = insertelement <1 x float> undef, float %29, i32 0
  %31 = add i64 9, %18
  %32 = getelementptr float, ptr addrspace(1) %1, i64 %31
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i32 0
  %35 = getelementptr float, ptr addrspace(1) %10, i64 %18
  %36 = load float, ptr addrspace(1) %35, align 4
  %37 = insertelement <1 x float> undef, float %36, i32 0
  %38 = extractelement <4 x float> %19, i64 0
  %39 = insertelement <1 x float> undef, float %38, i32 0
  %40 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %22, <1 x float> %37)
  %41 = extractelement <4 x float> %19, i64 1
  %42 = insertelement <1 x float> undef, float %41, i32 0
  %43 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %42, <1 x float> %26, <1 x float> %40)
  %44 = extractelement <4 x float> %19, i64 2
  %45 = insertelement <1 x float> undef, float %44, i32 0
  %46 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %45, <1 x float> %30, <1 x float> %43)
  %47 = extractelement <4 x float> %19, i64 3
  %48 = insertelement <1 x float> undef, float %47, i32 0
  %49 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %48, <1 x float> %34, <1 x float> %46)
  %50 = extractelement <1 x float> %49, i64 0
  %51 = getelementptr float, ptr addrspace(1) %2, i64 %18
  store float %50, ptr addrspace(1) %51, align 4
  ret void
}

; Function Attrs: mustprogress nocallback nofree nosync nounwind willreturn memory(inaccessiblemem: write)
declare void @llvm.assume(i1 noundef) #0

; Function Attrs: mustprogress nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare noundef i32 @llvm.nvvm.read.ptx.sreg.ctaid.x() #1

; Function Attrs: mustprogress nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare <1 x float> @llvm.fmuladd.v1f32(<1 x float>, <1 x float>, <1 x float>) #1

attributes #0 = { mustprogress nocallback nofree nosync nounwind willreturn memory(inaccessiblemem: write) }
attributes #1 = { mustprogress nocallback nofree nosync nounwind speculatable willreturn memory(none) }

!nvvm.annotations = !{!0, !1, !2, !3}

!0 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"kernel", i32 1}
!1 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"maxntidx", i32 1}
!2 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"maxntidy", i32 3}
!3 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"maxntidz", i32 1}
!4 = !{i32 0, i32 2147483647}
*** IR Dump After PromotePass on main_dispatch_0_matmul_1x3x4_f32 ***
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 63
  %6 = icmp eq i64 %5, 0
  call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 63
  %9 = icmp eq i64 %8, 0
  call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i32 16
  %11 = ptrtoint ptr addrspace(1) %10 to i64
  %12 = and i64 %11, 63
  %13 = icmp eq i64 %12, 0
  call void @llvm.assume(i1 %13)
  %14 = ptrtoint ptr addrspace(1) %2 to i64
  %15 = and i64 %14, 63
  %16 = icmp eq i64 %15, 0
  call void @llvm.assume(i1 %16)
  %17 = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %18 = zext i32 %17 to i64
  %19 = load <4 x float>, ptr addrspace(1) %0, align 4
  %20 = getelementptr float, ptr addrspace(1) %1, i64 %18
  %21 = load float, ptr addrspace(1) %20, align 4
  %22 = insertelement <1 x float> undef, float %21, i32 0
  %23 = add i64 3, %18
  %24 = getelementptr float, ptr addrspace(1) %1, i64 %23
  %25 = load float, ptr addrspace(1) %24, align 4
  %26 = insertelement <1 x float> undef, float %25, i32 0
  %27 = add i64 6, %18
  %28 = getelementptr float, ptr addrspace(1) %1, i64 %27
  %29 = load float, ptr addrspace(1) %28, align 4
  %30 = insertelement <1 x float> undef, float %29, i32 0
  %31 = add i64 9, %18
  %32 = getelementptr float, ptr addrspace(1) %1, i64 %31
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i32 0
  %35 = getelementptr float, ptr addrspace(1) %10, i64 %18
  %36 = load float, ptr addrspace(1) %35, align 4
  %37 = insertelement <1 x float> undef, float %36, i32 0
  %38 = extractelement <4 x float> %19, i64 0
  %39 = insertelement <1 x float> undef, float %38, i32 0
  %40 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %22, <1 x float> %37)
  %41 = extractelement <4 x float> %19, i64 1
  %42 = insertelement <1 x float> undef, float %41, i32 0
  %43 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %42, <1 x float> %26, <1 x float> %40)
  %44 = extractelement <4 x float> %19, i64 2
  %45 = insertelement <1 x float> undef, float %44, i32 0
  %46 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %45, <1 x float> %30, <1 x float> %43)
  %47 = extractelement <4 x float> %19, i64 3
  %48 = insertelement <1 x float> undef, float %47, i32 0
  %49 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %48, <1 x float> %34, <1 x float> %46)
  %50 = extractelement <1 x float> %49, i64 0
  %51 = getelementptr float, ptr addrspace(1) %2, i64 %18
  store float %50, ptr addrspace(1) %51, align 4
  ret void
}
*** IR Dump After InstCombinePass on main_dispatch_0_matmul_1x3x4_f32 ***
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  call void @llvm.assume(i1 %13)
  %14 = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 4
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}
*** IR Dump After SimplifyCFGPass on main_dispatch_0_matmul_1x3x4_f32 ***
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  call void @llvm.assume(i1 %13)
  %14 = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 4
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}
*** IR Dump After RequireAnalysisPass<llvm::GlobalsAA, llvm::Module> on [module] ***
; ModuleID = 'main_dispatch_0'
source_filename = "main_dispatch_0"
target datalayout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64"
target triple = "nvptx64-nvidia-cuda"

define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  call void @llvm.assume(i1 %13)
  %14 = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 4
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}

; Function Attrs: mustprogress nocallback nofree nosync nounwind willreturn memory(inaccessiblemem: write)
declare void @llvm.assume(i1 noundef) #0

; Function Attrs: mustprogress nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare noundef i32 @llvm.nvvm.read.ptx.sreg.ctaid.x() #1

; Function Attrs: mustprogress nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare <1 x float> @llvm.fmuladd.v1f32(<1 x float>, <1 x float>, <1 x float>) #1

attributes #0 = { mustprogress nocallback nofree nosync nounwind willreturn memory(inaccessiblemem: write) }
attributes #1 = { mustprogress nocallback nofree nosync nounwind speculatable willreturn memory(none) }

!nvvm.annotations = !{!0, !1, !2, !3}

!0 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"kernel", i32 1}
!1 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"maxntidx", i32 1}
!2 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"maxntidy", i32 3}
!3 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"maxntidz", i32 1}
!4 = !{i32 0, i32 2147483647}
*** IR Dump After InvalidateAnalysisPass<llvm::AAManager> on main_dispatch_0_matmul_1x3x4_f32 ***
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  call void @llvm.assume(i1 %13)
  %14 = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 4
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}
*** IR Dump After RequireAnalysisPass<llvm::ProfileSummaryAnalysis, llvm::Module> on [module] ***
; ModuleID = 'main_dispatch_0'
source_filename = "main_dispatch_0"
target datalayout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64"
target triple = "nvptx64-nvidia-cuda"

define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  call void @llvm.assume(i1 %13)
  %14 = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 4
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}

; Function Attrs: mustprogress nocallback nofree nosync nounwind willreturn memory(inaccessiblemem: write)
declare void @llvm.assume(i1 noundef) #0

; Function Attrs: mustprogress nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare noundef i32 @llvm.nvvm.read.ptx.sreg.ctaid.x() #1

; Function Attrs: mustprogress nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare <1 x float> @llvm.fmuladd.v1f32(<1 x float>, <1 x float>, <1 x float>) #1

attributes #0 = { mustprogress nocallback nofree nosync nounwind willreturn memory(inaccessiblemem: write) }
attributes #1 = { mustprogress nocallback nofree nosync nounwind speculatable willreturn memory(none) }

!nvvm.annotations = !{!0, !1, !2, !3}

!0 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"kernel", i32 1}
!1 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"maxntidx", i32 1}
!2 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"maxntidy", i32 3}
!3 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"maxntidz", i32 1}
!4 = !{i32 0, i32 2147483647}
*** IR Dump After InlinerPass on (main_dispatch_0_matmul_1x3x4_f32) ***
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  call void @llvm.assume(i1 %13)
  %14 = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 4
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}
*** IR Dump After InlinerPass on (main_dispatch_0_matmul_1x3x4_f32) ***
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  call void @llvm.assume(i1 %13)
  %14 = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 4
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}
*** IR Dump After PostOrderFunctionAttrsPass on (main_dispatch_0_matmul_1x3x4_f32) ***
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  call void @llvm.assume(i1 %13)
  %14 = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 4
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}
*** IR Dump After OpenMPOptCGSCCPass on (main_dispatch_0_matmul_1x3x4_f32) ***
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  call void @llvm.assume(i1 %13)
  %14 = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 4
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}
*** IR Dump After SROAPass on main_dispatch_0_matmul_1x3x4_f32 ***
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  call void @llvm.assume(i1 %13)
  %14 = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 4
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}
*** IR Dump After EarlyCSEPass on main_dispatch_0_matmul_1x3x4_f32 ***
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  call void @llvm.assume(i1 %13)
  %14 = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 4
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}
*** IR Dump After SpeculativeExecutionPass on main_dispatch_0_matmul_1x3x4_f32 ***
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  call void @llvm.assume(i1 %13)
  %14 = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 4
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}
*** IR Dump After JumpThreadingPass on main_dispatch_0_matmul_1x3x4_f32 ***
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  call void @llvm.assume(i1 %13)
  %14 = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 4
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}
*** IR Dump After CorrelatedValuePropagationPass on main_dispatch_0_matmul_1x3x4_f32 ***
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  call void @llvm.assume(i1 %13)
  %14 = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 4
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}
*** IR Dump After SimplifyCFGPass on main_dispatch_0_matmul_1x3x4_f32 ***
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  call void @llvm.assume(i1 %13)
  %14 = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 4
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}
*** IR Dump After InstCombinePass on main_dispatch_0_matmul_1x3x4_f32 ***
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  call void @llvm.assume(i1 %13)
  %14 = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 4
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}
*** IR Dump After AggressiveInstCombinePass on main_dispatch_0_matmul_1x3x4_f32 ***
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  call void @llvm.assume(i1 %13)
  %14 = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 4
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}
*** IR Dump After LibCallsShrinkWrapPass on main_dispatch_0_matmul_1x3x4_f32 ***
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  call void @llvm.assume(i1 %13)
  %14 = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 4
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}
*** IR Dump After TailCallElimPass on main_dispatch_0_matmul_1x3x4_f32 ***
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 4
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}
*** IR Dump After SimplifyCFGPass on main_dispatch_0_matmul_1x3x4_f32 ***
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 4
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}
*** IR Dump After ReassociatePass on main_dispatch_0_matmul_1x3x4_f32 ***
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 4
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}
*** IR Dump After ConstraintEliminationPass on main_dispatch_0_matmul_1x3x4_f32 ***
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 4
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}
*** IR Dump After LoopSimplifyPass on main_dispatch_0_matmul_1x3x4_f32 ***
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 4
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}
*** IR Dump After LCSSAPass on main_dispatch_0_matmul_1x3x4_f32 ***
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 4
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}
*** IR Dump After SimplifyCFGPass on main_dispatch_0_matmul_1x3x4_f32 ***
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 4
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}
*** IR Dump After InstCombinePass on main_dispatch_0_matmul_1x3x4_f32 ***
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 4
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}
*** IR Dump After LoopSimplifyPass on main_dispatch_0_matmul_1x3x4_f32 ***
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 4
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}
*** IR Dump After LCSSAPass on main_dispatch_0_matmul_1x3x4_f32 ***
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 4
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}
*** IR Dump After SROAPass on main_dispatch_0_matmul_1x3x4_f32 ***
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 4
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}
*** IR Dump After VectorCombinePass on main_dispatch_0_matmul_1x3x4_f32 ***
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 4
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}
*** IR Dump After MergedLoadStoreMotionPass on main_dispatch_0_matmul_1x3x4_f32 ***
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 4
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}
*** IR Dump After GVNPass on main_dispatch_0_matmul_1x3x4_f32 ***
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 4
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}
*** IR Dump After SCCPPass on main_dispatch_0_matmul_1x3x4_f32 ***
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 4
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}
*** IR Dump After BDCEPass on main_dispatch_0_matmul_1x3x4_f32 ***
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 4
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}
*** IR Dump After InstCombinePass on main_dispatch_0_matmul_1x3x4_f32 ***
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 4
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}
*** IR Dump After JumpThreadingPass on main_dispatch_0_matmul_1x3x4_f32 ***
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 4
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}
*** IR Dump After CorrelatedValuePropagationPass on main_dispatch_0_matmul_1x3x4_f32 ***
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 4
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}
*** IR Dump After ADCEPass on main_dispatch_0_matmul_1x3x4_f32 ***
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 4
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}
*** IR Dump After MemCpyOptPass on main_dispatch_0_matmul_1x3x4_f32 ***
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 4
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}
*** IR Dump After DSEPass on main_dispatch_0_matmul_1x3x4_f32 ***
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 4
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}
*** IR Dump After MoveAutoInitPass on main_dispatch_0_matmul_1x3x4_f32 ***
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 4
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}
*** IR Dump After LoopSimplifyPass on main_dispatch_0_matmul_1x3x4_f32 ***
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 4
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}
*** IR Dump After LCSSAPass on main_dispatch_0_matmul_1x3x4_f32 ***
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 4
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}
*** IR Dump After CoroElidePass on main_dispatch_0_matmul_1x3x4_f32 ***
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 4
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}
*** IR Dump After SimplifyCFGPass on main_dispatch_0_matmul_1x3x4_f32 ***
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 4
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}
*** IR Dump After InstCombinePass on main_dispatch_0_matmul_1x3x4_f32 ***
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 4
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}
*** IR Dump After PostOrderFunctionAttrsPass on (main_dispatch_0_matmul_1x3x4_f32) ***
; Function Attrs: mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write)
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr #0 {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 4
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}
*** IR Dump After RequireAnalysisPass<llvm::ShouldNotRunFunctionPassesAnalysis, llvm::Function> on main_dispatch_0_matmul_1x3x4_f32 ***
; Function Attrs: mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write)
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr #0 {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 4
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}
*** IR Dump After CoroSplitPass on (main_dispatch_0_matmul_1x3x4_f32) ***
; Function Attrs: mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write)
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr #0 {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 4
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}
*** IR Dump After InvalidateAnalysisPass<llvm::ShouldNotRunFunctionPassesAnalysis> on main_dispatch_0_matmul_1x3x4_f32 ***
; Function Attrs: mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write)
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr #0 {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 4
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}
*** IR Dump After DeadArgumentEliminationPass on [module] ***
; ModuleID = 'main_dispatch_0'
source_filename = "main_dispatch_0"
target datalayout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64"
target triple = "nvptx64-nvidia-cuda"

; Function Attrs: mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write)
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr #0 {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 4
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}

; Function Attrs: mustprogress nocallback nofree nosync nounwind willreturn memory(inaccessiblemem: write)
declare void @llvm.assume(i1 noundef) #1

; Function Attrs: mustprogress nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare noundef i32 @llvm.nvvm.read.ptx.sreg.ctaid.x() #2

; Function Attrs: mustprogress nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare <1 x float> @llvm.fmuladd.v1f32(<1 x float>, <1 x float>, <1 x float>) #2

attributes #0 = { mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write) }
attributes #1 = { mustprogress nocallback nofree nosync nounwind willreturn memory(inaccessiblemem: write) }
attributes #2 = { mustprogress nocallback nofree nosync nounwind speculatable willreturn memory(none) }

!nvvm.annotations = !{!0, !1, !2, !3}

!0 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"kernel", i32 1}
!1 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"maxntidx", i32 1}
!2 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"maxntidy", i32 3}
!3 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"maxntidz", i32 1}
!4 = !{i32 0, i32 2147483647}
*** IR Dump After CoroCleanupPass on [module] ***
; ModuleID = 'main_dispatch_0'
source_filename = "main_dispatch_0"
target datalayout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64"
target triple = "nvptx64-nvidia-cuda"

; Function Attrs: mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write)
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr #0 {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 4
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}

; Function Attrs: mustprogress nocallback nofree nosync nounwind willreturn memory(inaccessiblemem: write)
declare void @llvm.assume(i1 noundef) #1

; Function Attrs: mustprogress nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare noundef i32 @llvm.nvvm.read.ptx.sreg.ctaid.x() #2

; Function Attrs: mustprogress nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare <1 x float> @llvm.fmuladd.v1f32(<1 x float>, <1 x float>, <1 x float>) #2

attributes #0 = { mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write) }
attributes #1 = { mustprogress nocallback nofree nosync nounwind willreturn memory(inaccessiblemem: write) }
attributes #2 = { mustprogress nocallback nofree nosync nounwind speculatable willreturn memory(none) }

!nvvm.annotations = !{!0, !1, !2, !3}

!0 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"kernel", i32 1}
!1 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"maxntidx", i32 1}
!2 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"maxntidy", i32 3}
!3 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"maxntidz", i32 1}
!4 = !{i32 0, i32 2147483647}
*** IR Dump After GlobalOptPass on [module] ***
; ModuleID = 'main_dispatch_0'
source_filename = "main_dispatch_0"
target datalayout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64"
target triple = "nvptx64-nvidia-cuda"

; Function Attrs: mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write)
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr #0 {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 4
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}

; Function Attrs: mustprogress nocallback nofree nosync nounwind willreturn memory(inaccessiblemem: write)
declare void @llvm.assume(i1 noundef) #1

; Function Attrs: mustprogress nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare noundef i32 @llvm.nvvm.read.ptx.sreg.ctaid.x() #2

; Function Attrs: mustprogress nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare <1 x float> @llvm.fmuladd.v1f32(<1 x float>, <1 x float>, <1 x float>) #2

attributes #0 = { mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write) }
attributes #1 = { mustprogress nocallback nofree nosync nounwind willreturn memory(inaccessiblemem: write) }
attributes #2 = { mustprogress nocallback nofree nosync nounwind speculatable willreturn memory(none) }

!nvvm.annotations = !{!0, !1, !2, !3}

!0 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"kernel", i32 1}
!1 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"maxntidx", i32 1}
!2 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"maxntidy", i32 3}
!3 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"maxntidz", i32 1}
!4 = !{i32 0, i32 2147483647}
*** IR Dump After GlobalDCEPass on [module] ***
; ModuleID = 'main_dispatch_0'
source_filename = "main_dispatch_0"
target datalayout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64"
target triple = "nvptx64-nvidia-cuda"

; Function Attrs: mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write)
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr #0 {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 4
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}

; Function Attrs: mustprogress nocallback nofree nosync nounwind willreturn memory(inaccessiblemem: write)
declare void @llvm.assume(i1 noundef) #1

; Function Attrs: mustprogress nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare noundef i32 @llvm.nvvm.read.ptx.sreg.ctaid.x() #2

; Function Attrs: mustprogress nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare <1 x float> @llvm.fmuladd.v1f32(<1 x float>, <1 x float>, <1 x float>) #2

attributes #0 = { mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write) }
attributes #1 = { mustprogress nocallback nofree nosync nounwind willreturn memory(inaccessiblemem: write) }
attributes #2 = { mustprogress nocallback nofree nosync nounwind speculatable willreturn memory(none) }

!nvvm.annotations = !{!0, !1, !2, !3}

!0 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"kernel", i32 1}
!1 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"maxntidx", i32 1}
!2 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"maxntidy", i32 3}
!3 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"maxntidz", i32 1}
!4 = !{i32 0, i32 2147483647}
*** IR Dump After EliminateAvailableExternallyPass on [module] ***
; ModuleID = 'main_dispatch_0'
source_filename = "main_dispatch_0"
target datalayout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64"
target triple = "nvptx64-nvidia-cuda"

; Function Attrs: mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write)
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr #0 {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 4
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}

; Function Attrs: mustprogress nocallback nofree nosync nounwind willreturn memory(inaccessiblemem: write)
declare void @llvm.assume(i1 noundef) #1

; Function Attrs: mustprogress nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare noundef i32 @llvm.nvvm.read.ptx.sreg.ctaid.x() #2

; Function Attrs: mustprogress nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare <1 x float> @llvm.fmuladd.v1f32(<1 x float>, <1 x float>, <1 x float>) #2

attributes #0 = { mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write) }
attributes #1 = { mustprogress nocallback nofree nosync nounwind willreturn memory(inaccessiblemem: write) }
attributes #2 = { mustprogress nocallback nofree nosync nounwind speculatable willreturn memory(none) }

!nvvm.annotations = !{!0, !1, !2, !3}

!0 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"kernel", i32 1}
!1 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"maxntidx", i32 1}
!2 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"maxntidy", i32 3}
!3 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"maxntidz", i32 1}
!4 = !{i32 0, i32 2147483647}
*** IR Dump After ReversePostOrderFunctionAttrsPass on [module] ***
; ModuleID = 'main_dispatch_0'
source_filename = "main_dispatch_0"
target datalayout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64"
target triple = "nvptx64-nvidia-cuda"

; Function Attrs: mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write)
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr #0 {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 4
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}

; Function Attrs: mustprogress nocallback nofree nosync nounwind willreturn memory(inaccessiblemem: write)
declare void @llvm.assume(i1 noundef) #1

; Function Attrs: mustprogress nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare noundef i32 @llvm.nvvm.read.ptx.sreg.ctaid.x() #2

; Function Attrs: mustprogress nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare <1 x float> @llvm.fmuladd.v1f32(<1 x float>, <1 x float>, <1 x float>) #2

attributes #0 = { mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write) }
attributes #1 = { mustprogress nocallback nofree nosync nounwind willreturn memory(inaccessiblemem: write) }
attributes #2 = { mustprogress nocallback nofree nosync nounwind speculatable willreturn memory(none) }

!nvvm.annotations = !{!0, !1, !2, !3}

!0 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"kernel", i32 1}
!1 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"maxntidx", i32 1}
!2 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"maxntidy", i32 3}
!3 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"maxntidz", i32 1}
!4 = !{i32 0, i32 2147483647}
*** IR Dump After RecomputeGlobalsAAPass on [module] ***
; ModuleID = 'main_dispatch_0'
source_filename = "main_dispatch_0"
target datalayout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64"
target triple = "nvptx64-nvidia-cuda"

; Function Attrs: mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write)
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr #0 {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 4
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}

; Function Attrs: mustprogress nocallback nofree nosync nounwind willreturn memory(inaccessiblemem: write)
declare void @llvm.assume(i1 noundef) #1

; Function Attrs: mustprogress nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare noundef i32 @llvm.nvvm.read.ptx.sreg.ctaid.x() #2

; Function Attrs: mustprogress nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare <1 x float> @llvm.fmuladd.v1f32(<1 x float>, <1 x float>, <1 x float>) #2

attributes #0 = { mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write) }
attributes #1 = { mustprogress nocallback nofree nosync nounwind willreturn memory(inaccessiblemem: write) }
attributes #2 = { mustprogress nocallback nofree nosync nounwind speculatable willreturn memory(none) }

!nvvm.annotations = !{!0, !1, !2, !3}

!0 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"kernel", i32 1}
!1 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"maxntidx", i32 1}
!2 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"maxntidy", i32 3}
!3 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"maxntidz", i32 1}
!4 = !{i32 0, i32 2147483647}
*** IR Dump After Float2IntPass on main_dispatch_0_matmul_1x3x4_f32 ***
; Function Attrs: mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write)
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr #0 {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 4
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}
*** IR Dump After LowerConstantIntrinsicsPass on main_dispatch_0_matmul_1x3x4_f32 ***
; Function Attrs: mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write)
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr #0 {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 4
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}
*** IR Dump After LoopSimplifyPass on main_dispatch_0_matmul_1x3x4_f32 ***
; Function Attrs: mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write)
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr #0 {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 4
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}
*** IR Dump After LCSSAPass on main_dispatch_0_matmul_1x3x4_f32 ***
; Function Attrs: mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write)
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr #0 {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 4
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}
*** IR Dump After LoopDistributePass on main_dispatch_0_matmul_1x3x4_f32 ***
; Function Attrs: mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write)
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr #0 {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 4
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}
*** IR Dump After InjectTLIMappings on main_dispatch_0_matmul_1x3x4_f32 ***
; Function Attrs: mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write)
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr #0 {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 4
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}
*** IR Dump After LoopVectorizePass on main_dispatch_0_matmul_1x3x4_f32 ***
; Function Attrs: mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write)
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr #0 {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 4
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}
*** IR Dump After InferAlignmentPass on main_dispatch_0_matmul_1x3x4_f32 ***
; Function Attrs: mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write)
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr #0 {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 64
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}
*** IR Dump After LoopLoadEliminationPass on main_dispatch_0_matmul_1x3x4_f32 ***
; Function Attrs: mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write)
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr #0 {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 64
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}
*** IR Dump After InstCombinePass on main_dispatch_0_matmul_1x3x4_f32 ***
; Function Attrs: mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write)
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr #0 {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 64
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}
*** IR Dump After SimplifyCFGPass on main_dispatch_0_matmul_1x3x4_f32 ***
; Function Attrs: mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write)
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr #0 {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 64
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}
*** IR Dump After VectorCombinePass on main_dispatch_0_matmul_1x3x4_f32 ***
; Function Attrs: mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write)
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr #0 {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 64
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}
*** IR Dump After InstCombinePass on main_dispatch_0_matmul_1x3x4_f32 ***
; Function Attrs: mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write)
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr #0 {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 64
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}
*** IR Dump After LoopUnrollPass on main_dispatch_0_matmul_1x3x4_f32 ***
; Function Attrs: mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write)
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr #0 {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 64
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}
*** IR Dump After WarnMissedTransformationsPass on main_dispatch_0_matmul_1x3x4_f32 ***
; Function Attrs: mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write)
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr #0 {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 64
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}
*** IR Dump After SROAPass on main_dispatch_0_matmul_1x3x4_f32 ***
; Function Attrs: mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write)
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr #0 {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 64
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}
*** IR Dump After InferAlignmentPass on main_dispatch_0_matmul_1x3x4_f32 ***
; Function Attrs: mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write)
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr #0 {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 64
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}
*** IR Dump After InstCombinePass on main_dispatch_0_matmul_1x3x4_f32 ***
; Function Attrs: mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write)
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr #0 {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 64
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}
*** IR Dump After LoopSimplifyPass on main_dispatch_0_matmul_1x3x4_f32 ***
; Function Attrs: mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write)
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr #0 {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 64
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}
*** IR Dump After LCSSAPass on main_dispatch_0_matmul_1x3x4_f32 ***
; Function Attrs: mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write)
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr #0 {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 64
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}
*** IR Dump After AlignmentFromAssumptionsPass on main_dispatch_0_matmul_1x3x4_f32 ***
; Function Attrs: mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write)
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr #0 {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 64
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}
*** IR Dump After LoopSinkPass on main_dispatch_0_matmul_1x3x4_f32 ***
; Function Attrs: mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write)
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr #0 {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 64
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}
*** IR Dump After InstSimplifyPass on main_dispatch_0_matmul_1x3x4_f32 ***
; Function Attrs: mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write)
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr #0 {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 64
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}
*** IR Dump After DivRemPairsPass on main_dispatch_0_matmul_1x3x4_f32 ***
; Function Attrs: mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write)
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr #0 {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 64
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}
*** IR Dump After TailCallElimPass on main_dispatch_0_matmul_1x3x4_f32 ***
; Function Attrs: mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write)
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr #0 {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 64
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}
*** IR Dump After SimplifyCFGPass on main_dispatch_0_matmul_1x3x4_f32 ***
; Function Attrs: mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write)
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr #0 {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 64
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}
*** IR Dump After GlobalDCEPass on [module] ***
; ModuleID = 'main_dispatch_0'
source_filename = "main_dispatch_0"
target datalayout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64"
target triple = "nvptx64-nvidia-cuda"

; Function Attrs: mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write)
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr #0 {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 64
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}

; Function Attrs: mustprogress nocallback nofree nosync nounwind willreturn memory(inaccessiblemem: write)
declare void @llvm.assume(i1 noundef) #1

; Function Attrs: mustprogress nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare noundef i32 @llvm.nvvm.read.ptx.sreg.ctaid.x() #2

; Function Attrs: mustprogress nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare <1 x float> @llvm.fmuladd.v1f32(<1 x float>, <1 x float>, <1 x float>) #2

attributes #0 = { mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write) }
attributes #1 = { mustprogress nocallback nofree nosync nounwind willreturn memory(inaccessiblemem: write) }
attributes #2 = { mustprogress nocallback nofree nosync nounwind speculatable willreturn memory(none) }

!nvvm.annotations = !{!0, !1, !2, !3}

!0 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"kernel", i32 1}
!1 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"maxntidx", i32 1}
!2 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"maxntidy", i32 3}
!3 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"maxntidz", i32 1}
!4 = !{i32 0, i32 2147483647}
*** IR Dump After ConstantMergePass on [module] ***
; ModuleID = 'main_dispatch_0'
source_filename = "main_dispatch_0"
target datalayout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64"
target triple = "nvptx64-nvidia-cuda"

; Function Attrs: mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write)
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr #0 {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 64
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}

; Function Attrs: mustprogress nocallback nofree nosync nounwind willreturn memory(inaccessiblemem: write)
declare void @llvm.assume(i1 noundef) #1

; Function Attrs: mustprogress nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare noundef i32 @llvm.nvvm.read.ptx.sreg.ctaid.x() #2

; Function Attrs: mustprogress nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare <1 x float> @llvm.fmuladd.v1f32(<1 x float>, <1 x float>, <1 x float>) #2

attributes #0 = { mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write) }
attributes #1 = { mustprogress nocallback nofree nosync nounwind willreturn memory(inaccessiblemem: write) }
attributes #2 = { mustprogress nocallback nofree nosync nounwind speculatable willreturn memory(none) }

!nvvm.annotations = !{!0, !1, !2, !3}

!0 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"kernel", i32 1}
!1 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"maxntidx", i32 1}
!2 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"maxntidy", i32 3}
!3 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"maxntidz", i32 1}
!4 = !{i32 0, i32 2147483647}
*** IR Dump After CGProfilePass on [module] ***
; ModuleID = 'main_dispatch_0'
source_filename = "main_dispatch_0"
target datalayout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64"
target triple = "nvptx64-nvidia-cuda"

; Function Attrs: mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write)
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr #0 {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 64
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}

; Function Attrs: mustprogress nocallback nofree nosync nounwind willreturn memory(inaccessiblemem: write)
declare void @llvm.assume(i1 noundef) #1

; Function Attrs: mustprogress nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare noundef i32 @llvm.nvvm.read.ptx.sreg.ctaid.x() #2

; Function Attrs: mustprogress nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare <1 x float> @llvm.fmuladd.v1f32(<1 x float>, <1 x float>, <1 x float>) #2

attributes #0 = { mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write) }
attributes #1 = { mustprogress nocallback nofree nosync nounwind willreturn memory(inaccessiblemem: write) }
attributes #2 = { mustprogress nocallback nofree nosync nounwind speculatable willreturn memory(none) }

!nvvm.annotations = !{!0, !1, !2, !3}

!0 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"kernel", i32 1}
!1 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"maxntidx", i32 1}
!2 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"maxntidy", i32 3}
!3 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"maxntidz", i32 1}
!4 = !{i32 0, i32 2147483647}
*** IR Dump After RelLookupTableConverterPass on [module] ***
; ModuleID = 'main_dispatch_0'
source_filename = "main_dispatch_0"
target datalayout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64"
target triple = "nvptx64-nvidia-cuda"

; Function Attrs: mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write)
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr #0 {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 64
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}

; Function Attrs: mustprogress nocallback nofree nosync nounwind willreturn memory(inaccessiblemem: write)
declare void @llvm.assume(i1 noundef) #1

; Function Attrs: mustprogress nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare noundef i32 @llvm.nvvm.read.ptx.sreg.ctaid.x() #2

; Function Attrs: mustprogress nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare <1 x float> @llvm.fmuladd.v1f32(<1 x float>, <1 x float>, <1 x float>) #2

attributes #0 = { mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write) }
attributes #1 = { mustprogress nocallback nofree nosync nounwind willreturn memory(inaccessiblemem: write) }
attributes #2 = { mustprogress nocallback nofree nosync nounwind speculatable willreturn memory(none) }

!nvvm.annotations = !{!0, !1, !2, !3}

!0 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"kernel", i32 1}
!1 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"maxntidx", i32 1}
!2 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"maxntidy", i32 3}
!3 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"maxntidz", i32 1}
!4 = !{i32 0, i32 2147483647}
*** IR Dump After AnnotationRemarksPass on main_dispatch_0_matmul_1x3x4_f32 ***
; Function Attrs: mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write)
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr #0 {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 64
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}
*** IR Dump After VerifierPass on [module] ***
; ModuleID = 'main_dispatch_0'
source_filename = "main_dispatch_0"
target datalayout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64"
target triple = "nvptx64-nvidia-cuda"

; Function Attrs: mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write)
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr #0 {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 64
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}

; Function Attrs: mustprogress nocallback nofree nosync nounwind willreturn memory(inaccessiblemem: write)
declare void @llvm.assume(i1 noundef) #1

; Function Attrs: mustprogress nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare noundef i32 @llvm.nvvm.read.ptx.sreg.ctaid.x() #2

; Function Attrs: mustprogress nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare <1 x float> @llvm.fmuladd.v1f32(<1 x float>, <1 x float>, <1 x float>) #2

attributes #0 = { mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write) }
attributes #1 = { mustprogress nocallback nofree nosync nounwind willreturn memory(inaccessiblemem: write) }
attributes #2 = { mustprogress nocallback nofree nosync nounwind speculatable willreturn memory(none) }

!nvvm.annotations = !{!0, !1, !2, !3}

!0 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"kernel", i32 1}
!1 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"maxntidx", i32 1}
!2 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"maxntidy", i32 3}
!3 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"maxntidz", i32 1}
!4 = !{i32 0, i32 2147483647}
*** IR Dump After Pre-ISel Intrinsic Lowering (pre-isel-intrinsic-lowering) ***
; ModuleID = 'main_dispatch_0'
source_filename = "main_dispatch_0"
target datalayout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64"
target triple = "nvptx64-nvidia-cuda"

; Function Attrs: mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write)
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr #0 {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 64
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}

; Function Attrs: mustprogress nocallback nofree nosync nounwind willreturn memory(inaccessiblemem: write)
declare void @llvm.assume(i1 noundef) #1

; Function Attrs: mustprogress nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare noundef i32 @llvm.nvvm.read.ptx.sreg.ctaid.x() #2

; Function Attrs: mustprogress nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare <1 x float> @llvm.fmuladd.v1f32(<1 x float>, <1 x float>, <1 x float>) #2

attributes #0 = { mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write) }
attributes #1 = { mustprogress nocallback nofree nosync nounwind willreturn memory(inaccessiblemem: write) }
attributes #2 = { mustprogress nocallback nofree nosync nounwind speculatable willreturn memory(none) }

!nvvm.annotations = !{!0, !1, !2, !3}

!0 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"kernel", i32 1}
!1 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"maxntidx", i32 1}
!2 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"maxntidy", i32 3}
!3 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"maxntidz", i32 1}
!4 = !{i32 0, i32 2147483647}
*** IR Dump After Expand large div/rem (expand-large-div-rem) ***
; Function Attrs: mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write)
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr #0 {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 64
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}
*** IR Dump After Expand large fp convert (expand-large-fp-convert) ***
; Function Attrs: mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write)
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr #0 {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 64
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}
*** IR Dump After Replace occurrences of __nvvm_reflect() calls with 0/1 (nvvm-reflect) ***
; Function Attrs: mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write)
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr #0 {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 64
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}
*** IR Dump After Assign valid PTX names to globals (nvptx-assign-valid-global-names) ***
; ModuleID = 'main_dispatch_0'
source_filename = "main_dispatch_0"
target datalayout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64"
target triple = "nvptx64-nvidia-cuda"

; Function Attrs: mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write)
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr #0 {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 64
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}

; Function Attrs: mustprogress nocallback nofree nosync nounwind willreturn memory(inaccessiblemem: write)
declare void @llvm.assume(i1 noundef) #1

; Function Attrs: mustprogress nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare noundef i32 @llvm.nvvm.read.ptx.sreg.ctaid.x() #2

; Function Attrs: mustprogress nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare <1 x float> @llvm.fmuladd.v1f32(<1 x float>, <1 x float>, <1 x float>) #2

attributes #0 = { mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write) }
attributes #1 = { mustprogress nocallback nofree nosync nounwind willreturn memory(inaccessiblemem: write) }
attributes #2 = { mustprogress nocallback nofree nosync nounwind speculatable willreturn memory(none) }

!nvvm.annotations = !{!0, !1, !2, !3}

!0 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"kernel", i32 1}
!1 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"maxntidx", i32 1}
!2 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"maxntidy", i32 3}
!3 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"maxntidz", i32 1}
!4 = !{i32 0, i32 2147483647}
*** IR Dump After Ensure that the global variables are in the global address space (generic-to-nvvm) ***
; ModuleID = 'main_dispatch_0'
source_filename = "main_dispatch_0"
target datalayout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64"
target triple = "nvptx64-nvidia-cuda"

; Function Attrs: mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write)
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr #0 {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 64
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}

; Function Attrs: mustprogress nocallback nofree nosync nounwind willreturn memory(inaccessiblemem: write)
declare void @llvm.assume(i1 noundef) #1

; Function Attrs: mustprogress nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare noundef i32 @llvm.nvvm.read.ptx.sreg.ctaid.x() #2

; Function Attrs: mustprogress nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare <1 x float> @llvm.fmuladd.v1f32(<1 x float>, <1 x float>, <1 x float>) #2

attributes #0 = { mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write) }
attributes #1 = { mustprogress nocallback nofree nosync nounwind willreturn memory(inaccessiblemem: write) }
attributes #2 = { mustprogress nocallback nofree nosync nounwind speculatable willreturn memory(none) }

!nvvm.annotations = !{!0, !1, !2, !3}

!0 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"kernel", i32 1}
!1 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"maxntidx", i32 1}
!2 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"maxntidy", i32 3}
!3 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"maxntidz", i32 1}
!4 = !{i32 0, i32 2147483647}
*** IR Dump After Lower pointer arguments of CUDA kernels (nvptx-lower-args) ***
; Function Attrs: mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write)
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr #0 {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 64
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}
*** IR Dump After SROA (sroa) ***
; Function Attrs: mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write)
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr #0 {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 64
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}
*** IR Dump After convert address space of alloca'ed memory to local (nvptx-lower-alloca) ***
; Function Attrs: mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write)
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr #0 {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 64
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}
*** IR Dump After Infer address spaces (infer-address-spaces) ***
; Function Attrs: mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write)
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr #0 {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 64
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}
*** IR Dump After NVPTX lower atomics of local memory (nvptx-atomic-lower) ***
; Function Attrs: mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write)
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr #0 {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 64
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = add nuw nsw i64 %15, 3
  %21 = getelementptr float, ptr addrspace(1) %1, i64 %20
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = add nuw nsw i64 %15, 6
  %25 = getelementptr float, ptr addrspace(1) %1, i64 %24
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = add nuw nsw i64 %15, 9
  %29 = getelementptr float, ptr addrspace(1) %1, i64 %28
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}
*** IR Dump After Split GEPs to a variadic base and a constant offset for better CSE (separate-const-offset-from-gep) ***
; Function Attrs: mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write)
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr #0 {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 64
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %21 = getelementptr float, ptr addrspace(1) %20, i64 3
  %22 = load float, ptr addrspace(1) %21, align 4
  %23 = insertelement <1 x float> undef, float %22, i64 0
  %24 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %25 = getelementptr float, ptr addrspace(1) %24, i64 6
  %26 = load float, ptr addrspace(1) %25, align 4
  %27 = insertelement <1 x float> undef, float %26, i64 0
  %28 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %29 = getelementptr float, ptr addrspace(1) %28, i64 9
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %36 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %35, <1 x float> %19, <1 x float> %34)
  %37 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %38 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %37, <1 x float> %23, <1 x float> %36)
  %39 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %40 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %39, <1 x float> %27, <1 x float> %38)
  %41 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %42 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %41, <1 x float> %31, <1 x float> %40)
  %43 = extractelement <1 x float> %42, i64 0
  %44 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %43, ptr addrspace(1) %44, align 4
  ret void
}
*** IR Dump After Straight line strength reduction (slsr) ***
; Function Attrs: mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write)
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr #0 {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 64
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = mul i64 %15, 0
  %21 = getelementptr float, ptr addrspace(1) %17, i64 %20
  %22 = getelementptr float, ptr addrspace(1) %21, i64 3
  %23 = load float, ptr addrspace(1) %22, align 4
  %24 = insertelement <1 x float> undef, float %23, i64 0
  %25 = mul i64 %15, 0
  %26 = getelementptr float, ptr addrspace(1) %21, i64 %25
  %27 = getelementptr float, ptr addrspace(1) %26, i64 6
  %28 = load float, ptr addrspace(1) %27, align 4
  %29 = insertelement <1 x float> undef, float %28, i64 0
  %30 = mul i64 %15, 0
  %31 = getelementptr float, ptr addrspace(1) %26, i64 %30
  %32 = getelementptr float, ptr addrspace(1) %31, i64 9
  %33 = load float, ptr addrspace(1) %32, align 4
  %34 = insertelement <1 x float> undef, float %33, i64 0
  %35 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %36 = load float, ptr addrspace(1) %35, align 4
  %37 = insertelement <1 x float> undef, float %36, i64 0
  %38 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %39 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %38, <1 x float> %19, <1 x float> %37)
  %40 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %41 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %40, <1 x float> %24, <1 x float> %39)
  %42 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %43 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %42, <1 x float> %29, <1 x float> %41)
  %44 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %45 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %44, <1 x float> %34, <1 x float> %43)
  %46 = extractelement <1 x float> %45, i64 0
  %47 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %46, ptr addrspace(1) %47, align 4
  ret void
}
*** IR Dump After Early CSE (early-cse) ***
; Function Attrs: mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write)
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr #0 {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 64
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = getelementptr float, ptr addrspace(1) %17, i64 3
  %21 = load float, ptr addrspace(1) %20, align 4
  %22 = insertelement <1 x float> undef, float %21, i64 0
  %23 = getelementptr float, ptr addrspace(1) %17, i64 6
  %24 = load float, ptr addrspace(1) %23, align 4
  %25 = insertelement <1 x float> undef, float %24, i64 0
  %26 = getelementptr float, ptr addrspace(1) %17, i64 9
  %27 = load float, ptr addrspace(1) %26, align 4
  %28 = insertelement <1 x float> undef, float %27, i64 0
  %29 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %33 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %32, <1 x float> %19, <1 x float> %31)
  %34 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %35 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %34, <1 x float> %22, <1 x float> %33)
  %36 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %37 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %36, <1 x float> %25, <1 x float> %35)
  %38 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %39 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %38, <1 x float> %28, <1 x float> %37)
  %40 = extractelement <1 x float> %39, i64 0
  %41 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %40, ptr addrspace(1) %41, align 4
  ret void
}
*** IR Dump After Nary reassociation (nary-reassociate) ***
; Function Attrs: mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write)
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr #0 {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 64
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = getelementptr float, ptr addrspace(1) %17, i64 3
  %21 = load float, ptr addrspace(1) %20, align 4
  %22 = insertelement <1 x float> undef, float %21, i64 0
  %23 = getelementptr float, ptr addrspace(1) %17, i64 6
  %24 = load float, ptr addrspace(1) %23, align 4
  %25 = insertelement <1 x float> undef, float %24, i64 0
  %26 = getelementptr float, ptr addrspace(1) %17, i64 9
  %27 = load float, ptr addrspace(1) %26, align 4
  %28 = insertelement <1 x float> undef, float %27, i64 0
  %29 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %33 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %32, <1 x float> %19, <1 x float> %31)
  %34 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %35 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %34, <1 x float> %22, <1 x float> %33)
  %36 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %37 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %36, <1 x float> %25, <1 x float> %35)
  %38 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %39 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %38, <1 x float> %28, <1 x float> %37)
  %40 = extractelement <1 x float> %39, i64 0
  %41 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %40, ptr addrspace(1) %41, align 4
  ret void
}
*** IR Dump After Early CSE (early-cse) ***
; Function Attrs: mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write)
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr #0 {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 64
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = getelementptr float, ptr addrspace(1) %17, i64 3
  %21 = load float, ptr addrspace(1) %20, align 4
  %22 = insertelement <1 x float> undef, float %21, i64 0
  %23 = getelementptr float, ptr addrspace(1) %17, i64 6
  %24 = load float, ptr addrspace(1) %23, align 4
  %25 = insertelement <1 x float> undef, float %24, i64 0
  %26 = getelementptr float, ptr addrspace(1) %17, i64 9
  %27 = load float, ptr addrspace(1) %26, align 4
  %28 = insertelement <1 x float> undef, float %27, i64 0
  %29 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %33 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %32, <1 x float> %19, <1 x float> %31)
  %34 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %35 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %34, <1 x float> %22, <1 x float> %33)
  %36 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %37 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %36, <1 x float> %25, <1 x float> %35)
  %38 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %39 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %38, <1 x float> %28, <1 x float> %37)
  %40 = extractelement <1 x float> %39, i64 0
  %41 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %40, ptr addrspace(1) %41, align 4
  ret void
}
*** IR Dump After Expand Atomic instructions (atomic-expand) ***
; Function Attrs: mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write)
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr #0 {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 64
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = getelementptr float, ptr addrspace(1) %17, i64 3
  %21 = load float, ptr addrspace(1) %20, align 4
  %22 = insertelement <1 x float> undef, float %21, i64 0
  %23 = getelementptr float, ptr addrspace(1) %17, i64 6
  %24 = load float, ptr addrspace(1) %23, align 4
  %25 = insertelement <1 x float> undef, float %24, i64 0
  %26 = getelementptr float, ptr addrspace(1) %17, i64 9
  %27 = load float, ptr addrspace(1) %26, align 4
  %28 = insertelement <1 x float> undef, float %27, i64 0
  %29 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %33 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %32, <1 x float> %19, <1 x float> %31)
  %34 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %35 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %34, <1 x float> %22, <1 x float> %33)
  %36 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %37 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %36, <1 x float> %25, <1 x float> %35)
  %38 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %39 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %38, <1 x float> %28, <1 x float> %37)
  %40 = extractelement <1 x float> %39, i64 0
  %41 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %40, ptr addrspace(1) %41, align 4
  ret void
}
*** IR Dump After Lower ctors and dtors for NVPTX (nvptx-lower-ctor-dtor) ***
; ModuleID = 'main_dispatch_0'
source_filename = "main_dispatch_0"
target datalayout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64"
target triple = "nvptx64-nvidia-cuda"

; Function Attrs: mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write)
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr #0 {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 64
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = getelementptr float, ptr addrspace(1) %17, i64 3
  %21 = load float, ptr addrspace(1) %20, align 4
  %22 = insertelement <1 x float> undef, float %21, i64 0
  %23 = getelementptr float, ptr addrspace(1) %17, i64 6
  %24 = load float, ptr addrspace(1) %23, align 4
  %25 = insertelement <1 x float> undef, float %24, i64 0
  %26 = getelementptr float, ptr addrspace(1) %17, i64 9
  %27 = load float, ptr addrspace(1) %26, align 4
  %28 = insertelement <1 x float> undef, float %27, i64 0
  %29 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %33 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %32, <1 x float> %19, <1 x float> %31)
  %34 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %35 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %34, <1 x float> %22, <1 x float> %33)
  %36 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %37 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %36, <1 x float> %25, <1 x float> %35)
  %38 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %39 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %38, <1 x float> %28, <1 x float> %37)
  %40 = extractelement <1 x float> %39, i64 0
  %41 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %40, ptr addrspace(1) %41, align 4
  ret void
}

; Function Attrs: mustprogress nocallback nofree nosync nounwind willreturn memory(inaccessiblemem: write)
declare void @llvm.assume(i1 noundef) #1

; Function Attrs: mustprogress nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare noundef i32 @llvm.nvvm.read.ptx.sreg.ctaid.x() #2

; Function Attrs: mustprogress nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare <1 x float> @llvm.fmuladd.v1f32(<1 x float>, <1 x float>, <1 x float>) #2

attributes #0 = { mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write) }
attributes #1 = { mustprogress nocallback nofree nosync nounwind willreturn memory(inaccessiblemem: write) }
attributes #2 = { mustprogress nocallback nofree nosync nounwind speculatable willreturn memory(none) }

!nvvm.annotations = !{!0, !1, !2, !3}

!0 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"kernel", i32 1}
!1 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"maxntidx", i32 1}
!2 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"maxntidy", i32 3}
!3 = !{ptr @main_dispatch_0_matmul_1x3x4_f32, !"maxntidz", i32 1}
!4 = !{i32 0, i32 2147483647}
*** IR Dump After Canonicalize natural loops (loop-simplify) ***
; Function Attrs: mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write)
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr #0 {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 64
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = getelementptr float, ptr addrspace(1) %17, i64 3
  %21 = load float, ptr addrspace(1) %20, align 4
  %22 = insertelement <1 x float> undef, float %21, i64 0
  %23 = getelementptr float, ptr addrspace(1) %17, i64 6
  %24 = load float, ptr addrspace(1) %23, align 4
  %25 = insertelement <1 x float> undef, float %24, i64 0
  %26 = getelementptr float, ptr addrspace(1) %17, i64 9
  %27 = load float, ptr addrspace(1) %26, align 4
  %28 = insertelement <1 x float> undef, float %27, i64 0
  %29 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %33 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %32, <1 x float> %19, <1 x float> %31)
  %34 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %35 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %34, <1 x float> %22, <1 x float> %33)
  %36 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %37 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %36, <1 x float> %25, <1 x float> %35)
  %38 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %39 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %38, <1 x float> %28, <1 x float> %37)
  %40 = extractelement <1 x float> %39, i64 0
  %41 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %40, ptr addrspace(1) %41, align 4
  ret void
}
*** IR Dump After Merge contiguous icmps into a memcmp (mergeicmps) ***
; Function Attrs: mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write)
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr #0 {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 64
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = getelementptr float, ptr addrspace(1) %17, i64 3
  %21 = load float, ptr addrspace(1) %20, align 4
  %22 = insertelement <1 x float> undef, float %21, i64 0
  %23 = getelementptr float, ptr addrspace(1) %17, i64 6
  %24 = load float, ptr addrspace(1) %23, align 4
  %25 = insertelement <1 x float> undef, float %24, i64 0
  %26 = getelementptr float, ptr addrspace(1) %17, i64 9
  %27 = load float, ptr addrspace(1) %26, align 4
  %28 = insertelement <1 x float> undef, float %27, i64 0
  %29 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %33 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %32, <1 x float> %19, <1 x float> %31)
  %34 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %35 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %34, <1 x float> %22, <1 x float> %33)
  %36 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %37 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %36, <1 x float> %25, <1 x float> %35)
  %38 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %39 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %38, <1 x float> %28, <1 x float> %37)
  %40 = extractelement <1 x float> %39, i64 0
  %41 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %40, ptr addrspace(1) %41, align 4
  ret void
}
*** IR Dump After Expand memcmp() to load/stores (expandmemcmp) ***
; Function Attrs: mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write)
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr #0 {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 64
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = getelementptr float, ptr addrspace(1) %17, i64 3
  %21 = load float, ptr addrspace(1) %20, align 4
  %22 = insertelement <1 x float> undef, float %21, i64 0
  %23 = getelementptr float, ptr addrspace(1) %17, i64 6
  %24 = load float, ptr addrspace(1) %23, align 4
  %25 = insertelement <1 x float> undef, float %24, i64 0
  %26 = getelementptr float, ptr addrspace(1) %17, i64 9
  %27 = load float, ptr addrspace(1) %26, align 4
  %28 = insertelement <1 x float> undef, float %27, i64 0
  %29 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %33 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %32, <1 x float> %19, <1 x float> %31)
  %34 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %35 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %34, <1 x float> %22, <1 x float> %33)
  %36 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %37 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %36, <1 x float> %25, <1 x float> %35)
  %38 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %39 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %38, <1 x float> %28, <1 x float> %37)
  %40 = extractelement <1 x float> %39, i64 0
  %41 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %40, ptr addrspace(1) %41, align 4
  ret void
}
*** IR Dump After Lower Garbage Collection Instructions (gc-lowering) ***
; Function Attrs: mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write)
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr #0 {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 64
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = getelementptr float, ptr addrspace(1) %17, i64 3
  %21 = load float, ptr addrspace(1) %20, align 4
  %22 = insertelement <1 x float> undef, float %21, i64 0
  %23 = getelementptr float, ptr addrspace(1) %17, i64 6
  %24 = load float, ptr addrspace(1) %23, align 4
  %25 = insertelement <1 x float> undef, float %24, i64 0
  %26 = getelementptr float, ptr addrspace(1) %17, i64 9
  %27 = load float, ptr addrspace(1) %26, align 4
  %28 = insertelement <1 x float> undef, float %27, i64 0
  %29 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %33 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %32, <1 x float> %19, <1 x float> %31)
  %34 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %35 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %34, <1 x float> %22, <1 x float> %33)
  %36 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %37 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %36, <1 x float> %25, <1 x float> %35)
  %38 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %39 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %38, <1 x float> %28, <1 x float> %37)
  %40 = extractelement <1 x float> %39, i64 0
  %41 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %40, ptr addrspace(1) %41, align 4
  ret void
}
*** IR Dump After Shadow Stack GC Lowering (shadow-stack-gc-lowering) ***
; Function Attrs: mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write)
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr #0 {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 64
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = getelementptr float, ptr addrspace(1) %17, i64 3
  %21 = load float, ptr addrspace(1) %20, align 4
  %22 = insertelement <1 x float> undef, float %21, i64 0
  %23 = getelementptr float, ptr addrspace(1) %17, i64 6
  %24 = load float, ptr addrspace(1) %23, align 4
  %25 = insertelement <1 x float> undef, float %24, i64 0
  %26 = getelementptr float, ptr addrspace(1) %17, i64 9
  %27 = load float, ptr addrspace(1) %26, align 4
  %28 = insertelement <1 x float> undef, float %27, i64 0
  %29 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %33 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %32, <1 x float> %19, <1 x float> %31)
  %34 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %35 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %34, <1 x float> %22, <1 x float> %33)
  %36 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %37 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %36, <1 x float> %25, <1 x float> %35)
  %38 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %39 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %38, <1 x float> %28, <1 x float> %37)
  %40 = extractelement <1 x float> %39, i64 0
  %41 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %40, ptr addrspace(1) %41, align 4
  ret void
}
*** IR Dump After Lower constant intrinsics (lower-constant-intrinsics) ***
; Function Attrs: mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write)
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr #0 {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 64
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = getelementptr float, ptr addrspace(1) %17, i64 3
  %21 = load float, ptr addrspace(1) %20, align 4
  %22 = insertelement <1 x float> undef, float %21, i64 0
  %23 = getelementptr float, ptr addrspace(1) %17, i64 6
  %24 = load float, ptr addrspace(1) %23, align 4
  %25 = insertelement <1 x float> undef, float %24, i64 0
  %26 = getelementptr float, ptr addrspace(1) %17, i64 9
  %27 = load float, ptr addrspace(1) %26, align 4
  %28 = insertelement <1 x float> undef, float %27, i64 0
  %29 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %33 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %32, <1 x float> %19, <1 x float> %31)
  %34 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %35 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %34, <1 x float> %22, <1 x float> %33)
  %36 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %37 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %36, <1 x float> %25, <1 x float> %35)
  %38 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %39 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %38, <1 x float> %28, <1 x float> %37)
  %40 = extractelement <1 x float> %39, i64 0
  %41 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %40, ptr addrspace(1) %41, align 4
  ret void
}
*** IR Dump After Remove unreachable blocks from the CFG (unreachableblockelim) ***
; Function Attrs: mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write)
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr #0 {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 64
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = getelementptr float, ptr addrspace(1) %17, i64 3
  %21 = load float, ptr addrspace(1) %20, align 4
  %22 = insertelement <1 x float> undef, float %21, i64 0
  %23 = getelementptr float, ptr addrspace(1) %17, i64 6
  %24 = load float, ptr addrspace(1) %23, align 4
  %25 = insertelement <1 x float> undef, float %24, i64 0
  %26 = getelementptr float, ptr addrspace(1) %17, i64 9
  %27 = load float, ptr addrspace(1) %26, align 4
  %28 = insertelement <1 x float> undef, float %27, i64 0
  %29 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %33 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %32, <1 x float> %19, <1 x float> %31)
  %34 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %35 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %34, <1 x float> %22, <1 x float> %33)
  %36 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %37 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %36, <1 x float> %25, <1 x float> %35)
  %38 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %39 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %38, <1 x float> %28, <1 x float> %37)
  %40 = extractelement <1 x float> %39, i64 0
  %41 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %40, ptr addrspace(1) %41, align 4
  ret void
}
*** IR Dump After Constant Hoisting (consthoist) ***
; Function Attrs: mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write)
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr #0 {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 64
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = getelementptr float, ptr addrspace(1) %17, i64 3
  %21 = load float, ptr addrspace(1) %20, align 4
  %22 = insertelement <1 x float> undef, float %21, i64 0
  %23 = getelementptr float, ptr addrspace(1) %17, i64 6
  %24 = load float, ptr addrspace(1) %23, align 4
  %25 = insertelement <1 x float> undef, float %24, i64 0
  %26 = getelementptr float, ptr addrspace(1) %17, i64 9
  %27 = load float, ptr addrspace(1) %26, align 4
  %28 = insertelement <1 x float> undef, float %27, i64 0
  %29 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %33 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %32, <1 x float> %19, <1 x float> %31)
  %34 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %35 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %34, <1 x float> %22, <1 x float> %33)
  %36 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %37 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %36, <1 x float> %25, <1 x float> %35)
  %38 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %39 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %38, <1 x float> %28, <1 x float> %37)
  %40 = extractelement <1 x float> %39, i64 0
  %41 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %40, ptr addrspace(1) %41, align 4
  ret void
}
*** IR Dump After Replace intrinsics with calls to vector library (replace-with-veclib) ***
; Function Attrs: mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write)
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr #0 {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 64
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = getelementptr float, ptr addrspace(1) %17, i64 3
  %21 = load float, ptr addrspace(1) %20, align 4
  %22 = insertelement <1 x float> undef, float %21, i64 0
  %23 = getelementptr float, ptr addrspace(1) %17, i64 6
  %24 = load float, ptr addrspace(1) %23, align 4
  %25 = insertelement <1 x float> undef, float %24, i64 0
  %26 = getelementptr float, ptr addrspace(1) %17, i64 9
  %27 = load float, ptr addrspace(1) %26, align 4
  %28 = insertelement <1 x float> undef, float %27, i64 0
  %29 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %33 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %32, <1 x float> %19, <1 x float> %31)
  %34 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %35 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %34, <1 x float> %22, <1 x float> %33)
  %36 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %37 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %36, <1 x float> %25, <1 x float> %35)
  %38 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %39 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %38, <1 x float> %28, <1 x float> %37)
  %40 = extractelement <1 x float> %39, i64 0
  %41 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %40, ptr addrspace(1) %41, align 4
  ret void
}
*** IR Dump After Partially inline calls to library functions (partially-inline-libcalls) ***
; Function Attrs: mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write)
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr #0 {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 64
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = getelementptr float, ptr addrspace(1) %17, i64 3
  %21 = load float, ptr addrspace(1) %20, align 4
  %22 = insertelement <1 x float> undef, float %21, i64 0
  %23 = getelementptr float, ptr addrspace(1) %17, i64 6
  %24 = load float, ptr addrspace(1) %23, align 4
  %25 = insertelement <1 x float> undef, float %24, i64 0
  %26 = getelementptr float, ptr addrspace(1) %17, i64 9
  %27 = load float, ptr addrspace(1) %26, align 4
  %28 = insertelement <1 x float> undef, float %27, i64 0
  %29 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %33 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %32, <1 x float> %19, <1 x float> %31)
  %34 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %35 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %34, <1 x float> %22, <1 x float> %33)
  %36 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %37 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %36, <1 x float> %25, <1 x float> %35)
  %38 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %39 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %38, <1 x float> %28, <1 x float> %37)
  %40 = extractelement <1 x float> %39, i64 0
  %41 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %40, ptr addrspace(1) %41, align 4
  ret void
}
*** IR Dump After Expand vector predication intrinsics (expandvp) ***
; Function Attrs: mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write)
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr #0 {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 64
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = getelementptr float, ptr addrspace(1) %17, i64 3
  %21 = load float, ptr addrspace(1) %20, align 4
  %22 = insertelement <1 x float> undef, float %21, i64 0
  %23 = getelementptr float, ptr addrspace(1) %17, i64 6
  %24 = load float, ptr addrspace(1) %23, align 4
  %25 = insertelement <1 x float> undef, float %24, i64 0
  %26 = getelementptr float, ptr addrspace(1) %17, i64 9
  %27 = load float, ptr addrspace(1) %26, align 4
  %28 = insertelement <1 x float> undef, float %27, i64 0
  %29 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %33 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %32, <1 x float> %19, <1 x float> %31)
  %34 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %35 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %34, <1 x float> %22, <1 x float> %33)
  %36 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %37 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %36, <1 x float> %25, <1 x float> %35)
  %38 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %39 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %38, <1 x float> %28, <1 x float> %37)
  %40 = extractelement <1 x float> %39, i64 0
  %41 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %40, ptr addrspace(1) %41, align 4
  ret void
}
*** IR Dump After Scalarize Masked Memory Intrinsics (scalarize-masked-mem-intrin) ***
; Function Attrs: mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write)
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr #0 {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 64
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = getelementptr float, ptr addrspace(1) %17, i64 3
  %21 = load float, ptr addrspace(1) %20, align 4
  %22 = insertelement <1 x float> undef, float %21, i64 0
  %23 = getelementptr float, ptr addrspace(1) %17, i64 6
  %24 = load float, ptr addrspace(1) %23, align 4
  %25 = insertelement <1 x float> undef, float %24, i64 0
  %26 = getelementptr float, ptr addrspace(1) %17, i64 9
  %27 = load float, ptr addrspace(1) %26, align 4
  %28 = insertelement <1 x float> undef, float %27, i64 0
  %29 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %33 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %32, <1 x float> %19, <1 x float> %31)
  %34 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %35 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %34, <1 x float> %22, <1 x float> %33)
  %36 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %37 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %36, <1 x float> %25, <1 x float> %35)
  %38 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %39 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %38, <1 x float> %28, <1 x float> %37)
  %40 = extractelement <1 x float> %39, i64 0
  %41 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %40, ptr addrspace(1) %41, align 4
  ret void
}
*** IR Dump After Expand reduction intrinsics (expand-reductions) ***
; Function Attrs: mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write)
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr #0 {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 64
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = getelementptr float, ptr addrspace(1) %17, i64 3
  %21 = load float, ptr addrspace(1) %20, align 4
  %22 = insertelement <1 x float> undef, float %21, i64 0
  %23 = getelementptr float, ptr addrspace(1) %17, i64 6
  %24 = load float, ptr addrspace(1) %23, align 4
  %25 = insertelement <1 x float> undef, float %24, i64 0
  %26 = getelementptr float, ptr addrspace(1) %17, i64 9
  %27 = load float, ptr addrspace(1) %26, align 4
  %28 = insertelement <1 x float> undef, float %27, i64 0
  %29 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %33 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %32, <1 x float> %19, <1 x float> %31)
  %34 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %35 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %34, <1 x float> %22, <1 x float> %33)
  %36 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %37 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %36, <1 x float> %25, <1 x float> %35)
  %38 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %39 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %38, <1 x float> %28, <1 x float> %37)
  %40 = extractelement <1 x float> %39, i64 0
  %41 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %40, ptr addrspace(1) %41, align 4
  ret void
}
*** IR Dump After TLS Variable Hoist (tlshoist) ***
; Function Attrs: mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write)
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr #0 {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 64
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = getelementptr float, ptr addrspace(1) %17, i64 3
  %21 = load float, ptr addrspace(1) %20, align 4
  %22 = insertelement <1 x float> undef, float %21, i64 0
  %23 = getelementptr float, ptr addrspace(1) %17, i64 6
  %24 = load float, ptr addrspace(1) %23, align 4
  %25 = insertelement <1 x float> undef, float %24, i64 0
  %26 = getelementptr float, ptr addrspace(1) %17, i64 9
  %27 = load float, ptr addrspace(1) %26, align 4
  %28 = insertelement <1 x float> undef, float %27, i64 0
  %29 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %33 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %32, <1 x float> %19, <1 x float> %31)
  %34 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %35 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %34, <1 x float> %22, <1 x float> %33)
  %36 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %37 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %36, <1 x float> %25, <1 x float> %35)
  %38 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %39 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %38, <1 x float> %28, <1 x float> %37)
  %40 = extractelement <1 x float> %39, i64 0
  %41 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %40, ptr addrspace(1) %41, align 4
  ret void
}
*** IR Dump After Early CSE (early-cse) ***
; Function Attrs: mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write)
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr #0 {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 64
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = getelementptr float, ptr addrspace(1) %17, i64 3
  %21 = load float, ptr addrspace(1) %20, align 4
  %22 = insertelement <1 x float> undef, float %21, i64 0
  %23 = getelementptr float, ptr addrspace(1) %17, i64 6
  %24 = load float, ptr addrspace(1) %23, align 4
  %25 = insertelement <1 x float> undef, float %24, i64 0
  %26 = getelementptr float, ptr addrspace(1) %17, i64 9
  %27 = load float, ptr addrspace(1) %26, align 4
  %28 = insertelement <1 x float> undef, float %27, i64 0
  %29 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %33 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %32, <1 x float> %19, <1 x float> %31)
  %34 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %35 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %34, <1 x float> %22, <1 x float> %33)
  %36 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %37 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %36, <1 x float> %25, <1 x float> %35)
  %38 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %39 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %38, <1 x float> %28, <1 x float> %37)
  %40 = extractelement <1 x float> %39, i64 0
  %41 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %40, ptr addrspace(1) %41, align 4
  ret void
}
*** IR Dump After GPU Load and Store Vectorizer (load-store-vectorizer) ***
; Function Attrs: mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write)
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr #0 {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 64
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = getelementptr float, ptr addrspace(1) %17, i64 3
  %21 = load float, ptr addrspace(1) %20, align 4
  %22 = insertelement <1 x float> undef, float %21, i64 0
  %23 = getelementptr float, ptr addrspace(1) %17, i64 6
  %24 = load float, ptr addrspace(1) %23, align 4
  %25 = insertelement <1 x float> undef, float %24, i64 0
  %26 = getelementptr float, ptr addrspace(1) %17, i64 9
  %27 = load float, ptr addrspace(1) %26, align 4
  %28 = insertelement <1 x float> undef, float %27, i64 0
  %29 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %33 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %32, <1 x float> %19, <1 x float> %31)
  %34 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %35 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %34, <1 x float> %22, <1 x float> %33)
  %36 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %37 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %36, <1 x float> %25, <1 x float> %35)
  %38 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %39 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %38, <1 x float> %28, <1 x float> %37)
  %40 = extractelement <1 x float> %39, i64 0
  %41 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %40, ptr addrspace(1) %41, align 4
  ret void
}
*** IR Dump After SROA (sroa) ***
; Function Attrs: mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write)
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr #0 {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 64
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = getelementptr float, ptr addrspace(1) %17, i64 3
  %21 = load float, ptr addrspace(1) %20, align 4
  %22 = insertelement <1 x float> undef, float %21, i64 0
  %23 = getelementptr float, ptr addrspace(1) %17, i64 6
  %24 = load float, ptr addrspace(1) %23, align 4
  %25 = insertelement <1 x float> undef, float %24, i64 0
  %26 = getelementptr float, ptr addrspace(1) %17, i64 9
  %27 = load float, ptr addrspace(1) %26, align 4
  %28 = insertelement <1 x float> undef, float %27, i64 0
  %29 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %33 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %32, <1 x float> %19, <1 x float> %31)
  %34 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %35 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %34, <1 x float> %22, <1 x float> %33)
  %36 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %37 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %36, <1 x float> %25, <1 x float> %35)
  %38 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %39 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %38, <1 x float> %28, <1 x float> %37)
  %40 = extractelement <1 x float> %39, i64 0
  %41 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %40, ptr addrspace(1) %41, align 4
  ret void
}
*** IR Dump After add an exit instruction before every unreachable (nvptx-lower-unreachable) ***
; Function Attrs: mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write)
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr #0 {
  %4 = ptrtoint ptr addrspace(1) %0 to i64
  %5 = and i64 %4, 48
  %6 = icmp eq i64 %5, 0
  tail call void @llvm.assume(i1 %6)
  %7 = ptrtoint ptr addrspace(1) %1 to i64
  %8 = and i64 %7, 48
  %9 = icmp eq i64 %8, 0
  tail call void @llvm.assume(i1 %9)
  %10 = getelementptr float, ptr addrspace(1) %1, i64 16
  %11 = ptrtoint ptr addrspace(1) %2 to i64
  %12 = and i64 %11, 48
  %13 = icmp eq i64 %12, 0
  tail call void @llvm.assume(i1 %13)
  %14 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %15 = zext i32 %14 to i64
  %16 = load <4 x float>, ptr addrspace(1) %0, align 64
  %17 = getelementptr float, ptr addrspace(1) %1, i64 %15
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = getelementptr float, ptr addrspace(1) %17, i64 3
  %21 = load float, ptr addrspace(1) %20, align 4
  %22 = insertelement <1 x float> undef, float %21, i64 0
  %23 = getelementptr float, ptr addrspace(1) %17, i64 6
  %24 = load float, ptr addrspace(1) %23, align 4
  %25 = insertelement <1 x float> undef, float %24, i64 0
  %26 = getelementptr float, ptr addrspace(1) %17, i64 9
  %27 = load float, ptr addrspace(1) %26, align 4
  %28 = insertelement <1 x float> undef, float %27, i64 0
  %29 = getelementptr float, ptr addrspace(1) %10, i64 %15
  %30 = load float, ptr addrspace(1) %29, align 4
  %31 = insertelement <1 x float> undef, float %30, i64 0
  %32 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> zeroinitializer
  %33 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %32, <1 x float> %19, <1 x float> %31)
  %34 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 1>
  %35 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %34, <1 x float> %22, <1 x float> %33)
  %36 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 2>
  %37 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %36, <1 x float> %25, <1 x float> %35)
  %38 = shufflevector <4 x float> %16, <4 x float> undef, <1 x i32> <i32 3>
  %39 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %38, <1 x float> %28, <1 x float> %37)
  %40 = extractelement <1 x float> %39, i64 0
  %41 = getelementptr float, ptr addrspace(1) %2, i64 %15
  store float %40, ptr addrspace(1) %41, align 4
  ret void
}
*** IR Dump After CodeGen Prepare (codegenprepare) ***
; Function Attrs: mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write)
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr #0 {
  %4 = getelementptr float, ptr addrspace(1) %1, i64 16
  %5 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %6 = zext i32 %5 to i64
  %7 = load <4 x float>, ptr addrspace(1) %0, align 64
  %8 = getelementptr float, ptr addrspace(1) %1, i64 %6
  %9 = load float, ptr addrspace(1) %8, align 4
  %10 = insertelement <1 x float> undef, float %9, i64 0
  %11 = getelementptr float, ptr addrspace(1) %8, i64 3
  %12 = load float, ptr addrspace(1) %11, align 4
  %13 = insertelement <1 x float> undef, float %12, i64 0
  %14 = getelementptr float, ptr addrspace(1) %8, i64 6
  %15 = load float, ptr addrspace(1) %14, align 4
  %16 = insertelement <1 x float> undef, float %15, i64 0
  %17 = getelementptr float, ptr addrspace(1) %8, i64 9
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = getelementptr float, ptr addrspace(1) %4, i64 %6
  %21 = load float, ptr addrspace(1) %20, align 4
  %22 = insertelement <1 x float> undef, float %21, i64 0
  %23 = shufflevector <4 x float> %7, <4 x float> undef, <1 x i32> zeroinitializer
  %24 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %23, <1 x float> %10, <1 x float> %22)
  %25 = shufflevector <4 x float> %7, <4 x float> undef, <1 x i32> <i32 1>
  %26 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %25, <1 x float> %13, <1 x float> %24)
  %27 = shufflevector <4 x float> %7, <4 x float> undef, <1 x i32> <i32 2>
  %28 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %27, <1 x float> %16, <1 x float> %26)
  %29 = shufflevector <4 x float> %7, <4 x float> undef, <1 x i32> <i32 3>
  %30 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %29, <1 x float> %19, <1 x float> %28)
  %31 = extractelement <1 x float> %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %2, i64 %6
  store float %31, ptr addrspace(1) %32, align 4
  ret void
}
*** IR Dump After Lower invoke and unwind, for unwindless code generators (lowerinvoke) ***
; Function Attrs: mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write)
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr #0 {
  %4 = getelementptr float, ptr addrspace(1) %1, i64 16
  %5 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %6 = zext i32 %5 to i64
  %7 = load <4 x float>, ptr addrspace(1) %0, align 64
  %8 = getelementptr float, ptr addrspace(1) %1, i64 %6
  %9 = load float, ptr addrspace(1) %8, align 4
  %10 = insertelement <1 x float> undef, float %9, i64 0
  %11 = getelementptr float, ptr addrspace(1) %8, i64 3
  %12 = load float, ptr addrspace(1) %11, align 4
  %13 = insertelement <1 x float> undef, float %12, i64 0
  %14 = getelementptr float, ptr addrspace(1) %8, i64 6
  %15 = load float, ptr addrspace(1) %14, align 4
  %16 = insertelement <1 x float> undef, float %15, i64 0
  %17 = getelementptr float, ptr addrspace(1) %8, i64 9
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = getelementptr float, ptr addrspace(1) %4, i64 %6
  %21 = load float, ptr addrspace(1) %20, align 4
  %22 = insertelement <1 x float> undef, float %21, i64 0
  %23 = shufflevector <4 x float> %7, <4 x float> undef, <1 x i32> zeroinitializer
  %24 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %23, <1 x float> %10, <1 x float> %22)
  %25 = shufflevector <4 x float> %7, <4 x float> undef, <1 x i32> <i32 1>
  %26 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %25, <1 x float> %13, <1 x float> %24)
  %27 = shufflevector <4 x float> %7, <4 x float> undef, <1 x i32> <i32 2>
  %28 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %27, <1 x float> %16, <1 x float> %26)
  %29 = shufflevector <4 x float> %7, <4 x float> undef, <1 x i32> <i32 3>
  %30 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %29, <1 x float> %19, <1 x float> %28)
  %31 = extractelement <1 x float> %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %2, i64 %6
  store float %31, ptr addrspace(1) %32, align 4
  ret void
}
*** IR Dump After Remove unreachable blocks from the CFG (unreachableblockelim) ***
; Function Attrs: mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write)
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr #0 {
  %4 = getelementptr float, ptr addrspace(1) %1, i64 16
  %5 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %6 = zext i32 %5 to i64
  %7 = load <4 x float>, ptr addrspace(1) %0, align 64
  %8 = getelementptr float, ptr addrspace(1) %1, i64 %6
  %9 = load float, ptr addrspace(1) %8, align 4
  %10 = insertelement <1 x float> undef, float %9, i64 0
  %11 = getelementptr float, ptr addrspace(1) %8, i64 3
  %12 = load float, ptr addrspace(1) %11, align 4
  %13 = insertelement <1 x float> undef, float %12, i64 0
  %14 = getelementptr float, ptr addrspace(1) %8, i64 6
  %15 = load float, ptr addrspace(1) %14, align 4
  %16 = insertelement <1 x float> undef, float %15, i64 0
  %17 = getelementptr float, ptr addrspace(1) %8, i64 9
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = getelementptr float, ptr addrspace(1) %4, i64 %6
  %21 = load float, ptr addrspace(1) %20, align 4
  %22 = insertelement <1 x float> undef, float %21, i64 0
  %23 = shufflevector <4 x float> %7, <4 x float> undef, <1 x i32> zeroinitializer
  %24 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %23, <1 x float> %10, <1 x float> %22)
  %25 = shufflevector <4 x float> %7, <4 x float> undef, <1 x i32> <i32 1>
  %26 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %25, <1 x float> %13, <1 x float> %24)
  %27 = shufflevector <4 x float> %7, <4 x float> undef, <1 x i32> <i32 2>
  %28 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %27, <1 x float> %16, <1 x float> %26)
  %29 = shufflevector <4 x float> %7, <4 x float> undef, <1 x i32> <i32 3>
  %30 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %29, <1 x float> %19, <1 x float> %28)
  %31 = extractelement <1 x float> %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %2, i64 %6
  store float %31, ptr addrspace(1) %32, align 4
  ret void
}
*** IR Dump After Prepare callbr (callbrprepare) ***
; Function Attrs: mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write)
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr #0 {
  %4 = getelementptr float, ptr addrspace(1) %1, i64 16
  %5 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %6 = zext i32 %5 to i64
  %7 = load <4 x float>, ptr addrspace(1) %0, align 64
  %8 = getelementptr float, ptr addrspace(1) %1, i64 %6
  %9 = load float, ptr addrspace(1) %8, align 4
  %10 = insertelement <1 x float> undef, float %9, i64 0
  %11 = getelementptr float, ptr addrspace(1) %8, i64 3
  %12 = load float, ptr addrspace(1) %11, align 4
  %13 = insertelement <1 x float> undef, float %12, i64 0
  %14 = getelementptr float, ptr addrspace(1) %8, i64 6
  %15 = load float, ptr addrspace(1) %14, align 4
  %16 = insertelement <1 x float> undef, float %15, i64 0
  %17 = getelementptr float, ptr addrspace(1) %8, i64 9
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = getelementptr float, ptr addrspace(1) %4, i64 %6
  %21 = load float, ptr addrspace(1) %20, align 4
  %22 = insertelement <1 x float> undef, float %21, i64 0
  %23 = shufflevector <4 x float> %7, <4 x float> undef, <1 x i32> zeroinitializer
  %24 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %23, <1 x float> %10, <1 x float> %22)
  %25 = shufflevector <4 x float> %7, <4 x float> undef, <1 x i32> <i32 1>
  %26 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %25, <1 x float> %13, <1 x float> %24)
  %27 = shufflevector <4 x float> %7, <4 x float> undef, <1 x i32> <i32 2>
  %28 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %27, <1 x float> %16, <1 x float> %26)
  %29 = shufflevector <4 x float> %7, <4 x float> undef, <1 x i32> <i32 3>
  %30 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %29, <1 x float> %19, <1 x float> %28)
  %31 = extractelement <1 x float> %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %2, i64 %6
  store float %31, ptr addrspace(1) %32, align 4
  ret void
}
*** IR Dump After Safe Stack instrumentation pass (safe-stack) ***
; Function Attrs: mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write)
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr #0 {
  %4 = getelementptr float, ptr addrspace(1) %1, i64 16
  %5 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %6 = zext i32 %5 to i64
  %7 = load <4 x float>, ptr addrspace(1) %0, align 64
  %8 = getelementptr float, ptr addrspace(1) %1, i64 %6
  %9 = load float, ptr addrspace(1) %8, align 4
  %10 = insertelement <1 x float> undef, float %9, i64 0
  %11 = getelementptr float, ptr addrspace(1) %8, i64 3
  %12 = load float, ptr addrspace(1) %11, align 4
  %13 = insertelement <1 x float> undef, float %12, i64 0
  %14 = getelementptr float, ptr addrspace(1) %8, i64 6
  %15 = load float, ptr addrspace(1) %14, align 4
  %16 = insertelement <1 x float> undef, float %15, i64 0
  %17 = getelementptr float, ptr addrspace(1) %8, i64 9
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = getelementptr float, ptr addrspace(1) %4, i64 %6
  %21 = load float, ptr addrspace(1) %20, align 4
  %22 = insertelement <1 x float> undef, float %21, i64 0
  %23 = shufflevector <4 x float> %7, <4 x float> undef, <1 x i32> zeroinitializer
  %24 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %23, <1 x float> %10, <1 x float> %22)
  %25 = shufflevector <4 x float> %7, <4 x float> undef, <1 x i32> <i32 1>
  %26 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %25, <1 x float> %13, <1 x float> %24)
  %27 = shufflevector <4 x float> %7, <4 x float> undef, <1 x i32> <i32 2>
  %28 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %27, <1 x float> %16, <1 x float> %26)
  %29 = shufflevector <4 x float> %7, <4 x float> undef, <1 x i32> <i32 3>
  %30 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %29, <1 x float> %19, <1 x float> %28)
  %31 = extractelement <1 x float> %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %2, i64 %6
  store float %31, ptr addrspace(1) %32, align 4
  ret void
}
*** IR Dump After Lower aggregate copies/intrinsics into loops (nvptx-lower-aggr-copies) ***
; Function Attrs: mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write)
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr #0 {
  %4 = getelementptr float, ptr addrspace(1) %1, i64 16
  %5 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %6 = zext i32 %5 to i64
  %7 = load <4 x float>, ptr addrspace(1) %0, align 64
  %8 = getelementptr float, ptr addrspace(1) %1, i64 %6
  %9 = load float, ptr addrspace(1) %8, align 4
  %10 = insertelement <1 x float> undef, float %9, i64 0
  %11 = getelementptr float, ptr addrspace(1) %8, i64 3
  %12 = load float, ptr addrspace(1) %11, align 4
  %13 = insertelement <1 x float> undef, float %12, i64 0
  %14 = getelementptr float, ptr addrspace(1) %8, i64 6
  %15 = load float, ptr addrspace(1) %14, align 4
  %16 = insertelement <1 x float> undef, float %15, i64 0
  %17 = getelementptr float, ptr addrspace(1) %8, i64 9
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = getelementptr float, ptr addrspace(1) %4, i64 %6
  %21 = load float, ptr addrspace(1) %20, align 4
  %22 = insertelement <1 x float> undef, float %21, i64 0
  %23 = shufflevector <4 x float> %7, <4 x float> undef, <1 x i32> zeroinitializer
  %24 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %23, <1 x float> %10, <1 x float> %22)
  %25 = shufflevector <4 x float> %7, <4 x float> undef, <1 x i32> <i32 1>
  %26 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %25, <1 x float> %13, <1 x float> %24)
  %27 = shufflevector <4 x float> %7, <4 x float> undef, <1 x i32> <i32 2>
  %28 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %27, <1 x float> %16, <1 x float> %26)
  %29 = shufflevector <4 x float> %7, <4 x float> undef, <1 x i32> <i32 3>
  %30 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %29, <1 x float> %19, <1 x float> %28)
  %31 = extractelement <1 x float> %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %2, i64 %6
  store float %31, ptr addrspace(1) %32, align 4
  ret void
}
*** IR Dump After NVPTX specific alloca hoisting (alloca-hoisting) ***
; Function Attrs: mustprogress nofree nosync nounwind willreturn memory(argmem: readwrite, inaccessiblemem: write)
define void @main_dispatch_0_matmul_1x3x4_f32(ptr addrspace(1) noalias readonly align 16 %0, ptr addrspace(1) noalias readonly align 16 %1, ptr addrspace(1) noalias align 16 %2) local_unnamed_addr #0 {
  %4 = getelementptr float, ptr addrspace(1) %1, i64 16
  %5 = tail call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
  %6 = zext i32 %5 to i64
  %7 = load <4 x float>, ptr addrspace(1) %0, align 64
  %8 = getelementptr float, ptr addrspace(1) %1, i64 %6
  %9 = load float, ptr addrspace(1) %8, align 4
  %10 = insertelement <1 x float> undef, float %9, i64 0
  %11 = getelementptr float, ptr addrspace(1) %8, i64 3
  %12 = load float, ptr addrspace(1) %11, align 4
  %13 = insertelement <1 x float> undef, float %12, i64 0
  %14 = getelementptr float, ptr addrspace(1) %8, i64 6
  %15 = load float, ptr addrspace(1) %14, align 4
  %16 = insertelement <1 x float> undef, float %15, i64 0
  %17 = getelementptr float, ptr addrspace(1) %8, i64 9
  %18 = load float, ptr addrspace(1) %17, align 4
  %19 = insertelement <1 x float> undef, float %18, i64 0
  %20 = getelementptr float, ptr addrspace(1) %4, i64 %6
  %21 = load float, ptr addrspace(1) %20, align 4
  %22 = insertelement <1 x float> undef, float %21, i64 0
  %23 = shufflevector <4 x float> %7, <4 x float> undef, <1 x i32> zeroinitializer
  %24 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %23, <1 x float> %10, <1 x float> %22)
  %25 = shufflevector <4 x float> %7, <4 x float> undef, <1 x i32> <i32 1>
  %26 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %25, <1 x float> %13, <1 x float> %24)
  %27 = shufflevector <4 x float> %7, <4 x float> undef, <1 x i32> <i32 2>
  %28 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %27, <1 x float> %16, <1 x float> %26)
  %29 = shufflevector <4 x float> %7, <4 x float> undef, <1 x i32> <i32 3>
  %30 = tail call <1 x float> @llvm.fmuladd.v1f32(<1 x float> %29, <1 x float> %19, <1 x float> %28)
  %31 = extractelement <1 x float> %30, i64 0
  %32 = getelementptr float, ptr addrspace(1) %2, i64 %6
  store float %31, ptr addrspace(1) %32, align 4
  ret void
}
# *** IR Dump After NVPTX DAG->DAG Pattern Instruction Selection (nvptx-isel) ***:
# Machine code for function main_dispatch_0_matmul_1x3x4_f32: IsSSA, TracksLiveness

bb.0 (%ir-block.3):
  %0:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_0 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
  %1:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_1 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
  %2:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_2 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
  %3:int32regs = INT_PTX_SREG_CTAID_x
  %4:float32regs, %5:float32regs, %6:float32regs, %7:float32regs = INT_PTX_LDG_G_v4f32_ELE_areg64 killed %0:int64regs
  %8:int64regs = MULWIDEU64Imm killed %3:int32regs, 4
  %9:int64regs = ADDi64rr killed %1:int64regs, %8:int64regs
  %10:float32regs = INT_PTX_LDG_GLOBAL_f32areg64 %9:int64regs
  %11:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 12
  %12:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 24
  %13:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 36
  %14:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 64
  %15:float32regs = FMA32rrr killed %4:float32regs, killed %10:float32regs, killed %14:float32regs
  %16:float32regs = FMA32rrr killed %5:float32regs, killed %11:float32regs, killed %15:float32regs
  %17:float32regs = FMA32rrr killed %6:float32regs, killed %12:float32regs, killed %16:float32regs
  %18:float32regs = FMA32rrr killed %7:float32regs, killed %13:float32regs, killed %17:float32regs
  %19:int64regs = ADDi64rr killed %2:int64regs, %8:int64regs
  ST_f32_areg_64 killed %18:float32regs, 0, 1, 1, 2, 32, killed %19:int64regs :: (store (s32) into %ir.32, addrspace 1)
  Return

# End machine code for function main_dispatch_0_matmul_1x3x4_f32.

# *** IR Dump After Finalize ISel and expand pseudo-instructions (finalize-isel) ***:
# Machine code for function main_dispatch_0_matmul_1x3x4_f32: IsSSA, TracksLiveness

bb.0 (%ir-block.3):
  %0:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_0 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
  %1:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_1 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
  %2:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_2 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
  %3:int32regs = INT_PTX_SREG_CTAID_x
  %4:float32regs, %5:float32regs, %6:float32regs, %7:float32regs = INT_PTX_LDG_G_v4f32_ELE_areg64 killed %0:int64regs
  %8:int64regs = MULWIDEU64Imm killed %3:int32regs, 4
  %9:int64regs = ADDi64rr killed %1:int64regs, %8:int64regs
  %10:float32regs = INT_PTX_LDG_GLOBAL_f32areg64 %9:int64regs
  %11:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 12
  %12:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 24
  %13:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 36
  %14:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 64
  %15:float32regs = FMA32rrr killed %4:float32regs, killed %10:float32regs, killed %14:float32regs
  %16:float32regs = FMA32rrr killed %5:float32regs, killed %11:float32regs, killed %15:float32regs
  %17:float32regs = FMA32rrr killed %6:float32regs, killed %12:float32regs, killed %16:float32regs
  %18:float32regs = FMA32rrr killed %7:float32regs, killed %13:float32regs, killed %17:float32regs
  %19:int64regs = ADDi64rr killed %2:int64regs, %8:int64regs
  ST_f32_areg_64 killed %18:float32regs, 0, 1, 1, 2, 32, killed %19:int64regs :: (store (s32) into %ir.32, addrspace 1)
  Return

# End machine code for function main_dispatch_0_matmul_1x3x4_f32.

# *** IR Dump After Early Tail Duplication (early-tailduplication) ***:
# Machine code for function main_dispatch_0_matmul_1x3x4_f32: IsSSA, TracksLiveness

bb.0 (%ir-block.3):
  %0:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_0 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
  %1:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_1 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
  %2:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_2 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
  %3:int32regs = INT_PTX_SREG_CTAID_x
  %4:float32regs, %5:float32regs, %6:float32regs, %7:float32regs = INT_PTX_LDG_G_v4f32_ELE_areg64 killed %0:int64regs
  %8:int64regs = MULWIDEU64Imm killed %3:int32regs, 4
  %9:int64regs = ADDi64rr killed %1:int64regs, %8:int64regs
  %10:float32regs = INT_PTX_LDG_GLOBAL_f32areg64 %9:int64regs
  %11:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 12
  %12:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 24
  %13:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 36
  %14:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 64
  %15:float32regs = FMA32rrr killed %4:float32regs, killed %10:float32regs, killed %14:float32regs
  %16:float32regs = FMA32rrr killed %5:float32regs, killed %11:float32regs, killed %15:float32regs
  %17:float32regs = FMA32rrr killed %6:float32regs, killed %12:float32regs, killed %16:float32regs
  %18:float32regs = FMA32rrr killed %7:float32regs, killed %13:float32regs, killed %17:float32regs
  %19:int64regs = ADDi64rr killed %2:int64regs, %8:int64regs
  ST_f32_areg_64 killed %18:float32regs, 0, 1, 1, 2, 32, killed %19:int64regs :: (store (s32) into %ir.32, addrspace 1)
  Return

# End machine code for function main_dispatch_0_matmul_1x3x4_f32.

# *** IR Dump After Optimize machine instruction PHIs (opt-phis) ***:
# Machine code for function main_dispatch_0_matmul_1x3x4_f32: IsSSA, TracksLiveness

bb.0 (%ir-block.3):
  %0:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_0 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
  %1:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_1 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
  %2:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_2 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
  %3:int32regs = INT_PTX_SREG_CTAID_x
  %4:float32regs, %5:float32regs, %6:float32regs, %7:float32regs = INT_PTX_LDG_G_v4f32_ELE_areg64 killed %0:int64regs
  %8:int64regs = MULWIDEU64Imm killed %3:int32regs, 4
  %9:int64regs = ADDi64rr killed %1:int64regs, %8:int64regs
  %10:float32regs = INT_PTX_LDG_GLOBAL_f32areg64 %9:int64regs
  %11:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 12
  %12:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 24
  %13:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 36
  %14:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 64
  %15:float32regs = FMA32rrr killed %4:float32regs, killed %10:float32regs, killed %14:float32regs
  %16:float32regs = FMA32rrr killed %5:float32regs, killed %11:float32regs, killed %15:float32regs
  %17:float32regs = FMA32rrr killed %6:float32regs, killed %12:float32regs, killed %16:float32regs
  %18:float32regs = FMA32rrr killed %7:float32regs, killed %13:float32regs, killed %17:float32regs
  %19:int64regs = ADDi64rr killed %2:int64regs, %8:int64regs
  ST_f32_areg_64 killed %18:float32regs, 0, 1, 1, 2, 32, killed %19:int64regs :: (store (s32) into %ir.32, addrspace 1)
  Return

# End machine code for function main_dispatch_0_matmul_1x3x4_f32.

# *** IR Dump After Slot index numbering (slotindexes) ***:
# Machine code for function main_dispatch_0_matmul_1x3x4_f32: IsSSA, TracksLiveness

0B	bb.0 (%ir-block.3):
16B	  %0:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_0 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
32B	  %1:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_1 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
48B	  %2:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_2 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
64B	  %3:int32regs = INT_PTX_SREG_CTAID_x
80B	  %4:float32regs, %5:float32regs, %6:float32regs, %7:float32regs = INT_PTX_LDG_G_v4f32_ELE_areg64 killed %0:int64regs
96B	  %8:int64regs = MULWIDEU64Imm killed %3:int32regs, 4
112B	  %9:int64regs = ADDi64rr killed %1:int64regs, %8:int64regs
128B	  %10:float32regs = INT_PTX_LDG_GLOBAL_f32areg64 %9:int64regs
144B	  %11:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 12
160B	  %12:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 24
176B	  %13:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 36
192B	  %14:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 64
208B	  %15:float32regs = FMA32rrr killed %4:float32regs, killed %10:float32regs, killed %14:float32regs
224B	  %16:float32regs = FMA32rrr killed %5:float32regs, killed %11:float32regs, killed %15:float32regs
240B	  %17:float32regs = FMA32rrr killed %6:float32regs, killed %12:float32regs, killed %16:float32regs
256B	  %18:float32regs = FMA32rrr killed %7:float32regs, killed %13:float32regs, killed %17:float32regs
272B	  %19:int64regs = ADDi64rr killed %2:int64regs, %8:int64regs
288B	  ST_f32_areg_64 killed %18:float32regs, 0, 1, 1, 2, 32, killed %19:int64regs :: (store (s32) into %ir.32, addrspace 1)
304B	  Return

# End machine code for function main_dispatch_0_matmul_1x3x4_f32.

# *** IR Dump After Merge disjoint stack slots (stack-coloring) ***:
# Machine code for function main_dispatch_0_matmul_1x3x4_f32: IsSSA, TracksLiveness

bb.0 (%ir-block.3):
  %0:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_0 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
  %1:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_1 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
  %2:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_2 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
  %3:int32regs = INT_PTX_SREG_CTAID_x
  %4:float32regs, %5:float32regs, %6:float32regs, %7:float32regs = INT_PTX_LDG_G_v4f32_ELE_areg64 killed %0:int64regs
  %8:int64regs = MULWIDEU64Imm killed %3:int32regs, 4
  %9:int64regs = ADDi64rr killed %1:int64regs, %8:int64regs
  %10:float32regs = INT_PTX_LDG_GLOBAL_f32areg64 %9:int64regs
  %11:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 12
  %12:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 24
  %13:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 36
  %14:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 64
  %15:float32regs = FMA32rrr killed %4:float32regs, killed %10:float32regs, killed %14:float32regs
  %16:float32regs = FMA32rrr killed %5:float32regs, killed %11:float32regs, killed %15:float32regs
  %17:float32regs = FMA32rrr killed %6:float32regs, killed %12:float32regs, killed %16:float32regs
  %18:float32regs = FMA32rrr killed %7:float32regs, killed %13:float32regs, killed %17:float32regs
  %19:int64regs = ADDi64rr killed %2:int64regs, %8:int64regs
  ST_f32_areg_64 killed %18:float32regs, 0, 1, 1, 2, 32, killed %19:int64regs :: (store (s32) into %ir.32, addrspace 1)
  Return

# End machine code for function main_dispatch_0_matmul_1x3x4_f32.

# *** IR Dump After Local Stack Slot Allocation (localstackalloc) ***:
# Machine code for function main_dispatch_0_matmul_1x3x4_f32: IsSSA, TracksLiveness

bb.0 (%ir-block.3):
  %0:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_0 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
  %1:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_1 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
  %2:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_2 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
  %3:int32regs = INT_PTX_SREG_CTAID_x
  %4:float32regs, %5:float32regs, %6:float32regs, %7:float32regs = INT_PTX_LDG_G_v4f32_ELE_areg64 killed %0:int64regs
  %8:int64regs = MULWIDEU64Imm killed %3:int32regs, 4
  %9:int64regs = ADDi64rr killed %1:int64regs, %8:int64regs
  %10:float32regs = INT_PTX_LDG_GLOBAL_f32areg64 %9:int64regs
  %11:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 12
  %12:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 24
  %13:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 36
  %14:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 64
  %15:float32regs = FMA32rrr killed %4:float32regs, killed %10:float32regs, killed %14:float32regs
  %16:float32regs = FMA32rrr killed %5:float32regs, killed %11:float32regs, killed %15:float32regs
  %17:float32regs = FMA32rrr killed %6:float32regs, killed %12:float32regs, killed %16:float32regs
  %18:float32regs = FMA32rrr killed %7:float32regs, killed %13:float32regs, killed %17:float32regs
  %19:int64regs = ADDi64rr killed %2:int64regs, %8:int64regs
  ST_f32_areg_64 killed %18:float32regs, 0, 1, 1, 2, 32, killed %19:int64regs :: (store (s32) into %ir.32, addrspace 1)
  Return

# End machine code for function main_dispatch_0_matmul_1x3x4_f32.

# *** IR Dump After Remove dead machine instructions (dead-mi-elimination) ***:
# Machine code for function main_dispatch_0_matmul_1x3x4_f32: IsSSA, TracksLiveness

bb.0 (%ir-block.3):
  %0:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_0 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
  %1:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_1 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
  %2:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_2 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
  %3:int32regs = INT_PTX_SREG_CTAID_x
  %4:float32regs, %5:float32regs, %6:float32regs, %7:float32regs = INT_PTX_LDG_G_v4f32_ELE_areg64 killed %0:int64regs
  %8:int64regs = MULWIDEU64Imm killed %3:int32regs, 4
  %9:int64regs = ADDi64rr killed %1:int64regs, %8:int64regs
  %10:float32regs = INT_PTX_LDG_GLOBAL_f32areg64 %9:int64regs
  %11:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 12
  %12:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 24
  %13:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 36
  %14:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 64
  %15:float32regs = FMA32rrr killed %4:float32regs, killed %10:float32regs, killed %14:float32regs
  %16:float32regs = FMA32rrr killed %5:float32regs, killed %11:float32regs, killed %15:float32regs
  %17:float32regs = FMA32rrr killed %6:float32regs, killed %12:float32regs, killed %16:float32regs
  %18:float32regs = FMA32rrr killed %7:float32regs, killed %13:float32regs, killed %17:float32regs
  %19:int64regs = ADDi64rr killed %2:int64regs, %8:int64regs
  ST_f32_areg_64 killed %18:float32regs, 0, 1, 1, 2, 32, killed %19:int64regs :: (store (s32) into %ir.32, addrspace 1)
  Return

# End machine code for function main_dispatch_0_matmul_1x3x4_f32.

# *** IR Dump After Early Machine Loop Invariant Code Motion (early-machinelicm) ***:
# Machine code for function main_dispatch_0_matmul_1x3x4_f32: IsSSA, TracksLiveness

bb.0 (%ir-block.3):
  %0:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_0 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
  %1:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_1 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
  %2:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_2 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
  %3:int32regs = INT_PTX_SREG_CTAID_x
  %4:float32regs, %5:float32regs, %6:float32regs, %7:float32regs = INT_PTX_LDG_G_v4f32_ELE_areg64 killed %0:int64regs
  %8:int64regs = MULWIDEU64Imm killed %3:int32regs, 4
  %9:int64regs = ADDi64rr killed %1:int64regs, %8:int64regs
  %10:float32regs = INT_PTX_LDG_GLOBAL_f32areg64 %9:int64regs
  %11:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 12
  %12:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 24
  %13:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 36
  %14:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 64
  %15:float32regs = FMA32rrr killed %4:float32regs, killed %10:float32regs, killed %14:float32regs
  %16:float32regs = FMA32rrr killed %5:float32regs, killed %11:float32regs, killed %15:float32regs
  %17:float32regs = FMA32rrr killed %6:float32regs, killed %12:float32regs, killed %16:float32regs
  %18:float32regs = FMA32rrr killed %7:float32regs, killed %13:float32regs, killed %17:float32regs
  %19:int64regs = ADDi64rr killed %2:int64regs, %8:int64regs
  ST_f32_areg_64 killed %18:float32regs, 0, 1, 1, 2, 32, killed %19:int64regs :: (store (s32) into %ir.32, addrspace 1)
  Return

# End machine code for function main_dispatch_0_matmul_1x3x4_f32.

# *** IR Dump After Machine Common Subexpression Elimination (machine-cse) ***:
# Machine code for function main_dispatch_0_matmul_1x3x4_f32: IsSSA, TracksLiveness

bb.0 (%ir-block.3):
  %0:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_0 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
  %1:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_1 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
  %2:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_2 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
  %3:int32regs = INT_PTX_SREG_CTAID_x
  %4:float32regs, %5:float32regs, %6:float32regs, %7:float32regs = INT_PTX_LDG_G_v4f32_ELE_areg64 killed %0:int64regs
  %8:int64regs = MULWIDEU64Imm killed %3:int32regs, 4
  %9:int64regs = ADDi64rr killed %1:int64regs, %8:int64regs
  %10:float32regs = INT_PTX_LDG_GLOBAL_f32areg64 %9:int64regs
  %11:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 12
  %12:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 24
  %13:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 36
  %14:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 64
  %15:float32regs = FMA32rrr killed %4:float32regs, killed %10:float32regs, killed %14:float32regs
  %16:float32regs = FMA32rrr killed %5:float32regs, killed %11:float32regs, killed %15:float32regs
  %17:float32regs = FMA32rrr killed %6:float32regs, killed %12:float32regs, killed %16:float32regs
  %18:float32regs = FMA32rrr killed %7:float32regs, killed %13:float32regs, killed %17:float32regs
  %19:int64regs = ADDi64rr killed %2:int64regs, %8:int64regs
  ST_f32_areg_64 killed %18:float32regs, 0, 1, 1, 2, 32, killed %19:int64regs :: (store (s32) into %ir.32, addrspace 1)
  Return

# End machine code for function main_dispatch_0_matmul_1x3x4_f32.

# *** IR Dump After Machine code sinking (machine-sink) ***:
# Machine code for function main_dispatch_0_matmul_1x3x4_f32: IsSSA, TracksLiveness

bb.0 (%ir-block.3):
  %0:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_0 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
  %1:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_1 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
  %2:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_2 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
  %3:int32regs = INT_PTX_SREG_CTAID_x
  %4:float32regs, %5:float32regs, %6:float32regs, %7:float32regs = INT_PTX_LDG_G_v4f32_ELE_areg64 killed %0:int64regs
  %8:int64regs = MULWIDEU64Imm killed %3:int32regs, 4
  %9:int64regs = ADDi64rr killed %1:int64regs, %8:int64regs
  %10:float32regs = INT_PTX_LDG_GLOBAL_f32areg64 %9:int64regs
  %11:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 12
  %12:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 24
  %13:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 36
  %14:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 64
  %15:float32regs = FMA32rrr killed %4:float32regs, killed %10:float32regs, killed %14:float32regs
  %16:float32regs = FMA32rrr killed %5:float32regs, killed %11:float32regs, killed %15:float32regs
  %17:float32regs = FMA32rrr killed %6:float32regs, killed %12:float32regs, killed %16:float32regs
  %18:float32regs = FMA32rrr killed %7:float32regs, killed %13:float32regs, killed %17:float32regs
  %19:int64regs = ADDi64rr killed %2:int64regs, %8:int64regs
  ST_f32_areg_64 killed %18:float32regs, 0, 1, 1, 2, 32, killed %19:int64regs :: (store (s32) into %ir.32, addrspace 1)
  Return

# End machine code for function main_dispatch_0_matmul_1x3x4_f32.

# *** IR Dump After Peephole Optimizations (peephole-opt) ***:
# Machine code for function main_dispatch_0_matmul_1x3x4_f32: IsSSA, TracksLiveness

bb.0 (%ir-block.3):
  %0:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_0 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
  %1:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_1 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
  %2:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_2 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
  %3:int32regs = INT_PTX_SREG_CTAID_x
  %4:float32regs, %5:float32regs, %6:float32regs, %7:float32regs = INT_PTX_LDG_G_v4f32_ELE_areg64 killed %0:int64regs
  %8:int64regs = MULWIDEU64Imm killed %3:int32regs, 4
  %9:int64regs = ADDi64rr killed %1:int64regs, %8:int64regs
  %10:float32regs = INT_PTX_LDG_GLOBAL_f32areg64 %9:int64regs
  %11:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 12
  %12:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 24
  %13:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 36
  %14:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 64
  %15:float32regs = FMA32rrr killed %4:float32regs, killed %10:float32regs, killed %14:float32regs
  %16:float32regs = FMA32rrr killed %5:float32regs, killed %11:float32regs, killed %15:float32regs
  %17:float32regs = FMA32rrr killed %6:float32regs, killed %12:float32regs, killed %16:float32regs
  %18:float32regs = FMA32rrr killed %7:float32regs, killed %13:float32regs, killed %17:float32regs
  %19:int64regs = ADDi64rr killed %2:int64regs, %8:int64regs
  ST_f32_areg_64 killed %18:float32regs, 0, 1, 1, 2, 32, killed %19:int64regs :: (store (s32) into %ir.32, addrspace 1)
  Return

# End machine code for function main_dispatch_0_matmul_1x3x4_f32.

# *** IR Dump After NVPTX Proxy Register Instruction Erasure (nvptx-proxyreg-erasure) ***:
# Machine code for function main_dispatch_0_matmul_1x3x4_f32: IsSSA, TracksLiveness

bb.0 (%ir-block.3):
  %0:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_0 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
  %1:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_1 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
  %2:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_2 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
  %3:int32regs = INT_PTX_SREG_CTAID_x
  %4:float32regs, %5:float32regs, %6:float32regs, %7:float32regs = INT_PTX_LDG_G_v4f32_ELE_areg64 killed %0:int64regs
  %8:int64regs = MULWIDEU64Imm killed %3:int32regs, 4
  %9:int64regs = ADDi64rr killed %1:int64regs, %8:int64regs
  %10:float32regs = INT_PTX_LDG_GLOBAL_f32areg64 %9:int64regs
  %11:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 12
  %12:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 24
  %13:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 36
  %14:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 64
  %15:float32regs = FMA32rrr killed %4:float32regs, killed %10:float32regs, killed %14:float32regs
  %16:float32regs = FMA32rrr killed %5:float32regs, killed %11:float32regs, killed %15:float32regs
  %17:float32regs = FMA32rrr killed %6:float32regs, killed %12:float32regs, killed %16:float32regs
  %18:float32regs = FMA32rrr killed %7:float32regs, killed %13:float32regs, killed %17:float32regs
  %19:int64regs = ADDi64rr killed %2:int64regs, %8:int64regs
  ST_f32_areg_64 killed %18:float32regs, 0, 1, 1, 2, 32, killed %19:int64regs :: (store (s32) into %ir.32, addrspace 1)
  Return

# End machine code for function main_dispatch_0_matmul_1x3x4_f32.

# *** IR Dump After Process Implicit Definitions (processimpdefs) ***:
# Machine code for function main_dispatch_0_matmul_1x3x4_f32: IsSSA, TracksLiveness

bb.0 (%ir-block.3):
  %0:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_0 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
  %1:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_1 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
  %2:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_2 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
  %3:int32regs = INT_PTX_SREG_CTAID_x
  %4:float32regs, %5:float32regs, %6:float32regs, %7:float32regs = INT_PTX_LDG_G_v4f32_ELE_areg64 killed %0:int64regs
  %8:int64regs = MULWIDEU64Imm killed %3:int32regs, 4
  %9:int64regs = ADDi64rr killed %1:int64regs, %8:int64regs
  %10:float32regs = INT_PTX_LDG_GLOBAL_f32areg64 %9:int64regs
  %11:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 12
  %12:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 24
  %13:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 36
  %14:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 64
  %15:float32regs = FMA32rrr killed %4:float32regs, killed %10:float32regs, killed %14:float32regs
  %16:float32regs = FMA32rrr killed %5:float32regs, killed %11:float32regs, killed %15:float32regs
  %17:float32regs = FMA32rrr killed %6:float32regs, killed %12:float32regs, killed %16:float32regs
  %18:float32regs = FMA32rrr killed %7:float32regs, killed %13:float32regs, killed %17:float32regs
  %19:int64regs = ADDi64rr killed %2:int64regs, %8:int64regs
  ST_f32_areg_64 killed %18:float32regs, 0, 1, 1, 2, 32, killed %19:int64regs :: (store (s32) into %ir.32, addrspace 1)
  Return

# End machine code for function main_dispatch_0_matmul_1x3x4_f32.

# *** IR Dump After Remove unreachable machine basic blocks (unreachable-mbb-elimination) ***:
# Machine code for function main_dispatch_0_matmul_1x3x4_f32: IsSSA, TracksLiveness

bb.0 (%ir-block.3):
  %0:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_0 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
  %1:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_1 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
  %2:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_2 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
  %3:int32regs = INT_PTX_SREG_CTAID_x
  %4:float32regs, %5:float32regs, %6:float32regs, %7:float32regs = INT_PTX_LDG_G_v4f32_ELE_areg64 killed %0:int64regs
  %8:int64regs = MULWIDEU64Imm killed %3:int32regs, 4
  %9:int64regs = ADDi64rr killed %1:int64regs, %8:int64regs
  %10:float32regs = INT_PTX_LDG_GLOBAL_f32areg64 %9:int64regs
  %11:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 12
  %12:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 24
  %13:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 36
  %14:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 64
  %15:float32regs = FMA32rrr killed %4:float32regs, killed %10:float32regs, killed %14:float32regs
  %16:float32regs = FMA32rrr killed %5:float32regs, killed %11:float32regs, killed %15:float32regs
  %17:float32regs = FMA32rrr killed %6:float32regs, killed %12:float32regs, killed %16:float32regs
  %18:float32regs = FMA32rrr killed %7:float32regs, killed %13:float32regs, killed %17:float32regs
  %19:int64regs = ADDi64rr killed %2:int64regs, %8:int64regs
  ST_f32_areg_64 killed %18:float32regs, 0, 1, 1, 2, 32, killed %19:int64regs :: (store (s32) into %ir.32, addrspace 1)
  Return

# End machine code for function main_dispatch_0_matmul_1x3x4_f32.

# *** IR Dump After Live Variable Analysis (livevars) ***:
# Machine code for function main_dispatch_0_matmul_1x3x4_f32: IsSSA, TracksLiveness

bb.0 (%ir-block.3):
  %0:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_0 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
  %1:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_1 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
  %2:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_2 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
  %3:int32regs = INT_PTX_SREG_CTAID_x
  %4:float32regs, %5:float32regs, %6:float32regs, %7:float32regs = INT_PTX_LDG_G_v4f32_ELE_areg64 killed %0:int64regs
  %8:int64regs = MULWIDEU64Imm killed %3:int32regs, 4
  %9:int64regs = ADDi64rr killed %1:int64regs, %8:int64regs
  %10:float32regs = INT_PTX_LDG_GLOBAL_f32areg64 %9:int64regs
  %11:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 12
  %12:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 24
  %13:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 36
  %14:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 killed %9:int64regs, 64
  %15:float32regs = FMA32rrr killed %4:float32regs, killed %10:float32regs, killed %14:float32regs
  %16:float32regs = FMA32rrr killed %5:float32regs, killed %11:float32regs, killed %15:float32regs
  %17:float32regs = FMA32rrr killed %6:float32regs, killed %12:float32regs, killed %16:float32regs
  %18:float32regs = FMA32rrr killed %7:float32regs, killed %13:float32regs, killed %17:float32regs
  %19:int64regs = ADDi64rr killed %2:int64regs, killed %8:int64regs
  ST_f32_areg_64 killed %18:float32regs, 0, 1, 1, 2, 32, killed %19:int64regs :: (store (s32) into %ir.32, addrspace 1)
  Return

# End machine code for function main_dispatch_0_matmul_1x3x4_f32.

# *** IR Dump After Eliminate PHI nodes for register allocation (phi-node-elimination) ***:
# Machine code for function main_dispatch_0_matmul_1x3x4_f32: NoPHIs, TracksLiveness

bb.0 (%ir-block.3):
  %0:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_0 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
  %1:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_1 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
  %2:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_2 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
  %3:int32regs = INT_PTX_SREG_CTAID_x
  %4:float32regs, %5:float32regs, %6:float32regs, %7:float32regs = INT_PTX_LDG_G_v4f32_ELE_areg64 killed %0:int64regs
  %8:int64regs = MULWIDEU64Imm killed %3:int32regs, 4
  %9:int64regs = ADDi64rr killed %1:int64regs, %8:int64regs
  %10:float32regs = INT_PTX_LDG_GLOBAL_f32areg64 %9:int64regs
  %11:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 12
  %12:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 24
  %13:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 36
  %14:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 killed %9:int64regs, 64
  %15:float32regs = FMA32rrr killed %4:float32regs, killed %10:float32regs, killed %14:float32regs
  %16:float32regs = FMA32rrr killed %5:float32regs, killed %11:float32regs, killed %15:float32regs
  %17:float32regs = FMA32rrr killed %6:float32regs, killed %12:float32regs, killed %16:float32regs
  %18:float32regs = FMA32rrr killed %7:float32regs, killed %13:float32regs, killed %17:float32regs
  %19:int64regs = ADDi64rr killed %2:int64regs, killed %8:int64regs
  ST_f32_areg_64 killed %18:float32regs, 0, 1, 1, 2, 32, killed %19:int64regs :: (store (s32) into %ir.32, addrspace 1)
  Return

# End machine code for function main_dispatch_0_matmul_1x3x4_f32.

# *** IR Dump After Two-Address instruction pass (twoaddressinstruction) ***:
# Machine code for function main_dispatch_0_matmul_1x3x4_f32: NoPHIs, TracksLiveness, TiedOpsRewritten

bb.0 (%ir-block.3):
  %0:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_0 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
  %1:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_1 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
  %2:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_2 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
  %3:int32regs = INT_PTX_SREG_CTAID_x
  %4:float32regs, %5:float32regs, %6:float32regs, %7:float32regs = INT_PTX_LDG_G_v4f32_ELE_areg64 killed %0:int64regs
  %8:int64regs = MULWIDEU64Imm killed %3:int32regs, 4
  %9:int64regs = ADDi64rr killed %1:int64regs, %8:int64regs
  %10:float32regs = INT_PTX_LDG_GLOBAL_f32areg64 %9:int64regs
  %11:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 12
  %12:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 24
  %13:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 36
  %14:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 killed %9:int64regs, 64
  %15:float32regs = FMA32rrr killed %4:float32regs, killed %10:float32regs, killed %14:float32regs
  %16:float32regs = FMA32rrr killed %5:float32regs, killed %11:float32regs, killed %15:float32regs
  %17:float32regs = FMA32rrr killed %6:float32regs, killed %12:float32regs, killed %16:float32regs
  %18:float32regs = FMA32rrr killed %7:float32regs, killed %13:float32regs, killed %17:float32regs
  %19:int64regs = ADDi64rr killed %2:int64regs, killed %8:int64regs
  ST_f32_areg_64 killed %18:float32regs, 0, 1, 1, 2, 32, killed %19:int64regs :: (store (s32) into %ir.32, addrspace 1)
  Return

# End machine code for function main_dispatch_0_matmul_1x3x4_f32.

# *** IR Dump After Slot index numbering (slotindexes) ***:
# Machine code for function main_dispatch_0_matmul_1x3x4_f32: NoPHIs, TracksLiveness, TiedOpsRewritten

0B	bb.0 (%ir-block.3):
16B	  %0:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_0 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
32B	  %1:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_1 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
48B	  %2:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_2 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
64B	  %3:int32regs = INT_PTX_SREG_CTAID_x
80B	  %4:float32regs, %5:float32regs, %6:float32regs, %7:float32regs = INT_PTX_LDG_G_v4f32_ELE_areg64 killed %0:int64regs
96B	  %8:int64regs = MULWIDEU64Imm killed %3:int32regs, 4
112B	  %9:int64regs = ADDi64rr killed %1:int64regs, %8:int64regs
128B	  %10:float32regs = INT_PTX_LDG_GLOBAL_f32areg64 %9:int64regs
144B	  %11:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 12
160B	  %12:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 24
176B	  %13:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 36
192B	  %14:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 killed %9:int64regs, 64
208B	  %15:float32regs = FMA32rrr killed %4:float32regs, killed %10:float32regs, killed %14:float32regs
224B	  %16:float32regs = FMA32rrr killed %5:float32regs, killed %11:float32regs, killed %15:float32regs
240B	  %17:float32regs = FMA32rrr killed %6:float32regs, killed %12:float32regs, killed %16:float32regs
256B	  %18:float32regs = FMA32rrr killed %7:float32regs, killed %13:float32regs, killed %17:float32regs
272B	  %19:int64regs = ADDi64rr killed %2:int64regs, killed %8:int64regs
288B	  ST_f32_areg_64 killed %18:float32regs, 0, 1, 1, 2, 32, killed %19:int64regs :: (store (s32) into %ir.32, addrspace 1)
304B	  Return

# End machine code for function main_dispatch_0_matmul_1x3x4_f32.

# *** IR Dump After Live Interval Analysis (liveintervals) ***:
# Machine code for function main_dispatch_0_matmul_1x3x4_f32: NoPHIs, TracksLiveness, TiedOpsRewritten

0B	bb.0 (%ir-block.3):
16B	  %0:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_0 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
32B	  %1:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_1 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
48B	  %2:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_2 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
64B	  %3:int32regs = INT_PTX_SREG_CTAID_x
80B	  %4:float32regs, %5:float32regs, %6:float32regs, %7:float32regs = INT_PTX_LDG_G_v4f32_ELE_areg64 %0:int64regs
96B	  %8:int64regs = MULWIDEU64Imm %3:int32regs, 4
112B	  %9:int64regs = ADDi64rr %1:int64regs, %8:int64regs
128B	  %10:float32regs = INT_PTX_LDG_GLOBAL_f32areg64 %9:int64regs
144B	  %11:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 12
160B	  %12:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 24
176B	  %13:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 36
192B	  %14:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 64
208B	  %15:float32regs = FMA32rrr %4:float32regs, %10:float32regs, %14:float32regs
224B	  %16:float32regs = FMA32rrr %5:float32regs, %11:float32regs, %15:float32regs
240B	  %17:float32regs = FMA32rrr %6:float32regs, %12:float32regs, %16:float32regs
256B	  %18:float32regs = FMA32rrr %7:float32regs, %13:float32regs, %17:float32regs
272B	  %19:int64regs = ADDi64rr %2:int64regs, %8:int64regs
288B	  ST_f32_areg_64 %18:float32regs, 0, 1, 1, 2, 32, %19:int64regs :: (store (s32) into %ir.32, addrspace 1)
304B	  Return

# End machine code for function main_dispatch_0_matmul_1x3x4_f32.

# *** IR Dump After Register Coalescer (register-coalescer) ***:
# Machine code for function main_dispatch_0_matmul_1x3x4_f32: NoPHIs, TracksLiveness, TiedOpsRewritten

0B	bb.0 (%ir-block.3):
16B	  %0:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_0 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
32B	  %1:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_1 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
48B	  %2:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_2 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
64B	  %3:int32regs = INT_PTX_SREG_CTAID_x
80B	  %4:float32regs, %5:float32regs, %6:float32regs, %7:float32regs = INT_PTX_LDG_G_v4f32_ELE_areg64 %0:int64regs
96B	  %8:int64regs = MULWIDEU64Imm %3:int32regs, 4
112B	  %9:int64regs = ADDi64rr %1:int64regs, %8:int64regs
128B	  %10:float32regs = INT_PTX_LDG_GLOBAL_f32areg64 %9:int64regs
144B	  %11:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 12
160B	  %12:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 24
176B	  %13:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 36
192B	  %14:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 64
208B	  %15:float32regs = FMA32rrr %4:float32regs, %10:float32regs, %14:float32regs
224B	  %16:float32regs = FMA32rrr %5:float32regs, %11:float32regs, %15:float32regs
240B	  %17:float32regs = FMA32rrr %6:float32regs, %12:float32regs, %16:float32regs
256B	  %18:float32regs = FMA32rrr %7:float32regs, %13:float32regs, %17:float32regs
272B	  %19:int64regs = ADDi64rr %2:int64regs, %8:int64regs
288B	  ST_f32_areg_64 %18:float32regs, 0, 1, 1, 2, 32, %19:int64regs :: (store (s32) into %ir.32, addrspace 1)
304B	  Return

# End machine code for function main_dispatch_0_matmul_1x3x4_f32.

# *** IR Dump After Machine Instruction Scheduler (machine-scheduler) ***:
# Machine code for function main_dispatch_0_matmul_1x3x4_f32: NoPHIs, TracksLiveness, TiedOpsRewritten

0B	bb.0 (%ir-block.3):
16B	  %0:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_0 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
32B	  %1:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_1 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
48B	  %2:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_2 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
64B	  %3:int32regs = INT_PTX_SREG_CTAID_x
80B	  %4:float32regs, %5:float32regs, %6:float32regs, %7:float32regs = INT_PTX_LDG_G_v4f32_ELE_areg64 %0:int64regs
96B	  %8:int64regs = MULWIDEU64Imm %3:int32regs, 4
112B	  %9:int64regs = ADDi64rr %1:int64regs, %8:int64regs
128B	  %10:float32regs = INT_PTX_LDG_GLOBAL_f32areg64 %9:int64regs
144B	  %11:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 12
160B	  %12:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 24
176B	  %13:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 36
192B	  %14:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 64
208B	  %15:float32regs = FMA32rrr %4:float32regs, %10:float32regs, %14:float32regs
224B	  %16:float32regs = FMA32rrr %5:float32regs, %11:float32regs, %15:float32regs
240B	  %17:float32regs = FMA32rrr %6:float32regs, %12:float32regs, %16:float32regs
256B	  %18:float32regs = FMA32rrr %7:float32regs, %13:float32regs, %17:float32regs
272B	  %19:int64regs = ADDi64rr %2:int64regs, %8:int64regs
288B	  ST_f32_areg_64 %18:float32regs, 0, 1, 1, 2, 32, %19:int64regs :: (store (s32) into %ir.32, addrspace 1)
304B	  Return

# End machine code for function main_dispatch_0_matmul_1x3x4_f32.

# *** IR Dump After Live Stack Slot Analysis (livestacks) ***:
# Machine code for function main_dispatch_0_matmul_1x3x4_f32: NoPHIs, TracksLiveness, TiedOpsRewritten

0B	bb.0 (%ir-block.3):
16B	  %0:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_0 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
32B	  %1:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_1 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
48B	  %2:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_2 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
64B	  %3:int32regs = INT_PTX_SREG_CTAID_x
80B	  %4:float32regs, %5:float32regs, %6:float32regs, %7:float32regs = INT_PTX_LDG_G_v4f32_ELE_areg64 %0:int64regs
96B	  %8:int64regs = MULWIDEU64Imm %3:int32regs, 4
112B	  %9:int64regs = ADDi64rr %1:int64regs, %8:int64regs
128B	  %10:float32regs = INT_PTX_LDG_GLOBAL_f32areg64 %9:int64regs
144B	  %11:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 12
160B	  %12:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 24
176B	  %13:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 36
192B	  %14:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 64
208B	  %15:float32regs = FMA32rrr %4:float32regs, %10:float32regs, %14:float32regs
224B	  %16:float32regs = FMA32rrr %5:float32regs, %11:float32regs, %15:float32regs
240B	  %17:float32regs = FMA32rrr %6:float32regs, %12:float32regs, %16:float32regs
256B	  %18:float32regs = FMA32rrr %7:float32regs, %13:float32regs, %17:float32regs
272B	  %19:int64regs = ADDi64rr %2:int64regs, %8:int64regs
288B	  ST_f32_areg_64 %18:float32regs, 0, 1, 1, 2, 32, %19:int64regs :: (store (s32) into %ir.32, addrspace 1)
304B	  Return

# End machine code for function main_dispatch_0_matmul_1x3x4_f32.

# *** IR Dump After Stack Slot Coloring (stack-slot-coloring) ***:
# Machine code for function main_dispatch_0_matmul_1x3x4_f32: NoPHIs, TracksLiveness, TiedOpsRewritten

0B	bb.0 (%ir-block.3):
16B	  %0:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_0 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
32B	  %1:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_1 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
48B	  %2:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_2 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
64B	  %3:int32regs = INT_PTX_SREG_CTAID_x
80B	  %4:float32regs, %5:float32regs, %6:float32regs, %7:float32regs = INT_PTX_LDG_G_v4f32_ELE_areg64 %0:int64regs
96B	  %8:int64regs = MULWIDEU64Imm %3:int32regs, 4
112B	  %9:int64regs = ADDi64rr %1:int64regs, %8:int64regs
128B	  %10:float32regs = INT_PTX_LDG_GLOBAL_f32areg64 %9:int64regs
144B	  %11:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 12
160B	  %12:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 24
176B	  %13:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 36
192B	  %14:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 64
208B	  %15:float32regs = FMA32rrr %4:float32regs, %10:float32regs, %14:float32regs
224B	  %16:float32regs = FMA32rrr %5:float32regs, %11:float32regs, %15:float32regs
240B	  %17:float32regs = FMA32rrr %6:float32regs, %12:float32regs, %16:float32regs
256B	  %18:float32regs = FMA32rrr %7:float32regs, %13:float32regs, %17:float32regs
272B	  %19:int64regs = ADDi64rr %2:int64regs, %8:int64regs
288B	  ST_f32_areg_64 %18:float32regs, 0, 1, 1, 2, 32, %19:int64regs :: (store (s32) into %ir.32, addrspace 1)
304B	  Return

# End machine code for function main_dispatch_0_matmul_1x3x4_f32.

# *** IR Dump After NVPTX optimize redundant cvta.to.local instruction (nvptx-peephole) ***:
# Machine code for function main_dispatch_0_matmul_1x3x4_f32: NoPHIs, TracksLiveness, TiedOpsRewritten

bb.0 (%ir-block.3):
  %0:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_0 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
  %1:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_1 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
  %2:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_2 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
  %3:int32regs = INT_PTX_SREG_CTAID_x
  %4:float32regs, %5:float32regs, %6:float32regs, %7:float32regs = INT_PTX_LDG_G_v4f32_ELE_areg64 %0:int64regs
  %8:int64regs = MULWIDEU64Imm %3:int32regs, 4
  %9:int64regs = ADDi64rr %1:int64regs, %8:int64regs
  %10:float32regs = INT_PTX_LDG_GLOBAL_f32areg64 %9:int64regs
  %11:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 12
  %12:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 24
  %13:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 36
  %14:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 64
  %15:float32regs = FMA32rrr %4:float32regs, %10:float32regs, %14:float32regs
  %16:float32regs = FMA32rrr %5:float32regs, %11:float32regs, %15:float32regs
  %17:float32regs = FMA32rrr %6:float32regs, %12:float32regs, %16:float32regs
  %18:float32regs = FMA32rrr %7:float32regs, %13:float32regs, %17:float32regs
  %19:int64regs = ADDi64rr %2:int64regs, %8:int64regs
  ST_f32_areg_64 %18:float32regs, 0, 1, 1, 2, 32, %19:int64regs :: (store (s32) into %ir.32, addrspace 1)
  Return

# End machine code for function main_dispatch_0_matmul_1x3x4_f32.

# *** IR Dump After Remove Redundant DEBUG_VALUE analysis (removeredundantdebugvalues) ***:
# Machine code for function main_dispatch_0_matmul_1x3x4_f32: NoPHIs, TracksLiveness, TiedOpsRewritten

bb.0 (%ir-block.3):
  %0:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_0 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
  %1:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_1 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
  %2:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_2 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
  %3:int32regs = INT_PTX_SREG_CTAID_x
  %4:float32regs, %5:float32regs, %6:float32regs, %7:float32regs = INT_PTX_LDG_G_v4f32_ELE_areg64 %0:int64regs
  %8:int64regs = MULWIDEU64Imm %3:int32regs, 4
  %9:int64regs = ADDi64rr %1:int64regs, %8:int64regs
  %10:float32regs = INT_PTX_LDG_GLOBAL_f32areg64 %9:int64regs
  %11:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 12
  %12:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 24
  %13:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 36
  %14:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 64
  %15:float32regs = FMA32rrr %4:float32regs, %10:float32regs, %14:float32regs
  %16:float32regs = FMA32rrr %5:float32regs, %11:float32regs, %15:float32regs
  %17:float32regs = FMA32rrr %6:float32regs, %12:float32regs, %16:float32regs
  %18:float32regs = FMA32rrr %7:float32regs, %13:float32regs, %17:float32regs
  %19:int64regs = ADDi64rr %2:int64regs, %8:int64regs
  ST_f32_areg_64 %18:float32regs, 0, 1, 1, 2, 32, %19:int64regs :: (store (s32) into %ir.32, addrspace 1)
  Return

# End machine code for function main_dispatch_0_matmul_1x3x4_f32.

# *** IR Dump After Fixup Statepoint Caller Saved (fixup-statepoint-caller-saved) ***:
# Machine code for function main_dispatch_0_matmul_1x3x4_f32: NoPHIs, TracksLiveness, TiedOpsRewritten

bb.0 (%ir-block.3):
  %0:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_0 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
  %1:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_1 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
  %2:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_2 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
  %3:int32regs = INT_PTX_SREG_CTAID_x
  %4:float32regs, %5:float32regs, %6:float32regs, %7:float32regs = INT_PTX_LDG_G_v4f32_ELE_areg64 %0:int64regs
  %8:int64regs = MULWIDEU64Imm %3:int32regs, 4
  %9:int64regs = ADDi64rr %1:int64regs, %8:int64regs
  %10:float32regs = INT_PTX_LDG_GLOBAL_f32areg64 %9:int64regs
  %11:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 12
  %12:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 24
  %13:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 36
  %14:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 64
  %15:float32regs = FMA32rrr %4:float32regs, %10:float32regs, %14:float32regs
  %16:float32regs = FMA32rrr %5:float32regs, %11:float32regs, %15:float32regs
  %17:float32regs = FMA32rrr %6:float32regs, %12:float32regs, %16:float32regs
  %18:float32regs = FMA32rrr %7:float32regs, %13:float32regs, %17:float32regs
  %19:int64regs = ADDi64rr %2:int64regs, %8:int64regs
  ST_f32_areg_64 %18:float32regs, 0, 1, 1, 2, 32, %19:int64regs :: (store (s32) into %ir.32, addrspace 1)
  Return

# End machine code for function main_dispatch_0_matmul_1x3x4_f32.

# *** IR Dump After Control Flow Optimizer (branch-folder) ***:
# Machine code for function main_dispatch_0_matmul_1x3x4_f32: NoPHIs, TracksLiveness, TiedOpsRewritten

bb.0 (%ir-block.3):
  %0:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_0 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
  %1:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_1 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
  %2:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_2 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
  %3:int32regs = INT_PTX_SREG_CTAID_x
  %4:float32regs, %5:float32regs, %6:float32regs, %7:float32regs = INT_PTX_LDG_G_v4f32_ELE_areg64 %0:int64regs
  %8:int64regs = MULWIDEU64Imm %3:int32regs, 4
  %9:int64regs = ADDi64rr %1:int64regs, %8:int64regs
  %10:float32regs = INT_PTX_LDG_GLOBAL_f32areg64 %9:int64regs
  %11:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 12
  %12:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 24
  %13:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 36
  %14:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 64
  %15:float32regs = FMA32rrr %4:float32regs, %10:float32regs, %14:float32regs
  %16:float32regs = FMA32rrr %5:float32regs, %11:float32regs, %15:float32regs
  %17:float32regs = FMA32rrr %6:float32regs, %12:float32regs, %16:float32regs
  %18:float32regs = FMA32rrr %7:float32regs, %13:float32regs, %17:float32regs
  %19:int64regs = ADDi64rr %2:int64regs, %8:int64regs
  ST_f32_areg_64 %18:float32regs, 0, 1, 1, 2, 32, %19:int64regs :: (store (s32) into %ir.32, addrspace 1)
  Return

# End machine code for function main_dispatch_0_matmul_1x3x4_f32.

# *** IR Dump After Post-RA pseudo instruction expansion pass (postrapseudos) ***:
# Machine code for function main_dispatch_0_matmul_1x3x4_f32: NoPHIs, TracksLiveness, TiedOpsRewritten

bb.0 (%ir-block.3):
  %0:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_0 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
  %1:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_1 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
  %2:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_2 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
  %3:int32regs = INT_PTX_SREG_CTAID_x
  %4:float32regs, %5:float32regs, %6:float32regs, %7:float32regs = INT_PTX_LDG_G_v4f32_ELE_areg64 %0:int64regs
  %8:int64regs = MULWIDEU64Imm %3:int32regs, 4
  %9:int64regs = ADDi64rr %1:int64regs, %8:int64regs
  %10:float32regs = INT_PTX_LDG_GLOBAL_f32areg64 %9:int64regs
  %11:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 12
  %12:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 24
  %13:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 36
  %14:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 64
  %15:float32regs = FMA32rrr %4:float32regs, %10:float32regs, %14:float32regs
  %16:float32regs = FMA32rrr %5:float32regs, %11:float32regs, %15:float32regs
  %17:float32regs = FMA32rrr %6:float32regs, %12:float32regs, %16:float32regs
  %18:float32regs = FMA32rrr %7:float32regs, %13:float32regs, %17:float32regs
  %19:int64regs = ADDi64rr %2:int64regs, %8:int64regs
  ST_f32_areg_64 %18:float32regs, 0, 1, 1, 2, 32, %19:int64regs :: (store (s32) into %ir.32, addrspace 1)
  Return

# End machine code for function main_dispatch_0_matmul_1x3x4_f32.

# *** IR Dump After Analyze Machine Code For Garbage Collection (gc-analysis) ***:
# Machine code for function main_dispatch_0_matmul_1x3x4_f32: NoPHIs, TracksLiveness, TiedOpsRewritten

bb.0 (%ir-block.3):
  %0:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_0 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
  %1:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_1 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
  %2:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_2 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
  %3:int32regs = INT_PTX_SREG_CTAID_x
  %4:float32regs, %5:float32regs, %6:float32regs, %7:float32regs = INT_PTX_LDG_G_v4f32_ELE_areg64 %0:int64regs
  %8:int64regs = MULWIDEU64Imm %3:int32regs, 4
  %9:int64regs = ADDi64rr %1:int64regs, %8:int64regs
  %10:float32regs = INT_PTX_LDG_GLOBAL_f32areg64 %9:int64regs
  %11:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 12
  %12:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 24
  %13:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 36
  %14:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 64
  %15:float32regs = FMA32rrr %4:float32regs, %10:float32regs, %14:float32regs
  %16:float32regs = FMA32rrr %5:float32regs, %11:float32regs, %15:float32regs
  %17:float32regs = FMA32rrr %6:float32regs, %12:float32regs, %16:float32regs
  %18:float32regs = FMA32rrr %7:float32regs, %13:float32regs, %17:float32regs
  %19:int64regs = ADDi64rr %2:int64regs, %8:int64regs
  ST_f32_areg_64 %18:float32regs, 0, 1, 1, 2, 32, %19:int64regs :: (store (s32) into %ir.32, addrspace 1)
  Return

# End machine code for function main_dispatch_0_matmul_1x3x4_f32.

# *** IR Dump After Branch Probability Basic Block Placement (block-placement) ***:
# Machine code for function main_dispatch_0_matmul_1x3x4_f32: NoPHIs, TracksLiveness, TiedOpsRewritten

bb.0 (%ir-block.3):
  %0:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_0 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
  %1:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_1 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
  %2:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_2 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
  %3:int32regs = INT_PTX_SREG_CTAID_x
  %4:float32regs, %5:float32regs, %6:float32regs, %7:float32regs = INT_PTX_LDG_G_v4f32_ELE_areg64 %0:int64regs
  %8:int64regs = MULWIDEU64Imm %3:int32regs, 4
  %9:int64regs = ADDi64rr %1:int64regs, %8:int64regs
  %10:float32regs = INT_PTX_LDG_GLOBAL_f32areg64 %9:int64regs
  %11:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 12
  %12:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 24
  %13:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 36
  %14:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 64
  %15:float32regs = FMA32rrr %4:float32regs, %10:float32regs, %14:float32regs
  %16:float32regs = FMA32rrr %5:float32regs, %11:float32regs, %15:float32regs
  %17:float32regs = FMA32rrr %6:float32regs, %12:float32regs, %16:float32regs
  %18:float32regs = FMA32rrr %7:float32regs, %13:float32regs, %17:float32regs
  %19:int64regs = ADDi64rr %2:int64regs, %8:int64regs
  ST_f32_areg_64 %18:float32regs, 0, 1, 1, 2, 32, %19:int64regs :: (store (s32) into %ir.32, addrspace 1)
  Return

# End machine code for function main_dispatch_0_matmul_1x3x4_f32.

# *** IR Dump After Insert fentry calls (fentry-insert) ***:
# Machine code for function main_dispatch_0_matmul_1x3x4_f32: NoPHIs, TracksLiveness, TiedOpsRewritten

bb.0 (%ir-block.3):
  %0:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_0 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
  %1:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_1 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
  %2:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_2 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
  %3:int32regs = INT_PTX_SREG_CTAID_x
  %4:float32regs, %5:float32regs, %6:float32regs, %7:float32regs = INT_PTX_LDG_G_v4f32_ELE_areg64 %0:int64regs
  %8:int64regs = MULWIDEU64Imm %3:int32regs, 4
  %9:int64regs = ADDi64rr %1:int64regs, %8:int64regs
  %10:float32regs = INT_PTX_LDG_GLOBAL_f32areg64 %9:int64regs
  %11:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 12
  %12:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 24
  %13:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 36
  %14:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 64
  %15:float32regs = FMA32rrr %4:float32regs, %10:float32regs, %14:float32regs
  %16:float32regs = FMA32rrr %5:float32regs, %11:float32regs, %15:float32regs
  %17:float32regs = FMA32rrr %6:float32regs, %12:float32regs, %16:float32regs
  %18:float32regs = FMA32rrr %7:float32regs, %13:float32regs, %17:float32regs
  %19:int64regs = ADDi64rr %2:int64regs, %8:int64regs
  ST_f32_areg_64 %18:float32regs, 0, 1, 1, 2, 32, %19:int64regs :: (store (s32) into %ir.32, addrspace 1)
  Return

# End machine code for function main_dispatch_0_matmul_1x3x4_f32.

# *** IR Dump After Insert XRay ops (xray-instrumentation) ***:
# Machine code for function main_dispatch_0_matmul_1x3x4_f32: NoPHIs, TracksLiveness, TiedOpsRewritten

bb.0 (%ir-block.3):
  %0:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_0 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
  %1:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_1 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
  %2:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_2 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
  %3:int32regs = INT_PTX_SREG_CTAID_x
  %4:float32regs, %5:float32regs, %6:float32regs, %7:float32regs = INT_PTX_LDG_G_v4f32_ELE_areg64 %0:int64regs
  %8:int64regs = MULWIDEU64Imm %3:int32regs, 4
  %9:int64regs = ADDi64rr %1:int64regs, %8:int64regs
  %10:float32regs = INT_PTX_LDG_GLOBAL_f32areg64 %9:int64regs
  %11:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 12
  %12:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 24
  %13:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 36
  %14:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 64
  %15:float32regs = FMA32rrr %4:float32regs, %10:float32regs, %14:float32regs
  %16:float32regs = FMA32rrr %5:float32regs, %11:float32regs, %15:float32regs
  %17:float32regs = FMA32rrr %6:float32regs, %12:float32regs, %16:float32regs
  %18:float32regs = FMA32rrr %7:float32regs, %13:float32regs, %17:float32regs
  %19:int64regs = ADDi64rr %2:int64regs, %8:int64regs
  ST_f32_areg_64 %18:float32regs, 0, 1, 1, 2, 32, %19:int64regs :: (store (s32) into %ir.32, addrspace 1)
  Return

# End machine code for function main_dispatch_0_matmul_1x3x4_f32.

# *** IR Dump After Machine Sanitizer Binary Metadata (machine-sanmd) ***:
# Machine code for function main_dispatch_0_matmul_1x3x4_f32: NoPHIs, TracksLiveness, TiedOpsRewritten

bb.0 (%ir-block.3):
  %0:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_0 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
  %1:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_1 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
  %2:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_2 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
  %3:int32regs = INT_PTX_SREG_CTAID_x
  %4:float32regs, %5:float32regs, %6:float32regs, %7:float32regs = INT_PTX_LDG_G_v4f32_ELE_areg64 %0:int64regs
  %8:int64regs = MULWIDEU64Imm %3:int32regs, 4
  %9:int64regs = ADDi64rr %1:int64regs, %8:int64regs
  %10:float32regs = INT_PTX_LDG_GLOBAL_f32areg64 %9:int64regs
  %11:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 12
  %12:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 24
  %13:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 36
  %14:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 64
  %15:float32regs = FMA32rrr %4:float32regs, %10:float32regs, %14:float32regs
  %16:float32regs = FMA32rrr %5:float32regs, %11:float32regs, %15:float32regs
  %17:float32regs = FMA32rrr %6:float32regs, %12:float32regs, %16:float32regs
  %18:float32regs = FMA32rrr %7:float32regs, %13:float32regs, %17:float32regs
  %19:int64regs = ADDi64rr %2:int64regs, %8:int64regs
  ST_f32_areg_64 %18:float32regs, 0, 1, 1, 2, 32, %19:int64regs :: (store (s32) into %ir.32, addrspace 1)
  Return

# End machine code for function main_dispatch_0_matmul_1x3x4_f32.

# *** IR Dump After Stack Frame Layout Analysis (stack-frame-layout) ***:
# Machine code for function main_dispatch_0_matmul_1x3x4_f32: NoPHIs, TracksLiveness, TiedOpsRewritten

bb.0 (%ir-block.3):
  %0:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_0 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
  %1:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_1 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
  %2:int64regs = LD_i64_avar 0, 4, 1, 0, 64, &main_dispatch_0_matmul_1x3x4_f32_param_2 :: (dereferenceable invariant load (s64) from `ptr addrspace(101) null`, addrspace 101)
  %3:int32regs = INT_PTX_SREG_CTAID_x
  %4:float32regs, %5:float32regs, %6:float32regs, %7:float32regs = INT_PTX_LDG_G_v4f32_ELE_areg64 %0:int64regs
  %8:int64regs = MULWIDEU64Imm %3:int32regs, 4
  %9:int64regs = ADDi64rr %1:int64regs, %8:int64regs
  %10:float32regs = INT_PTX_LDG_GLOBAL_f32areg64 %9:int64regs
  %11:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 12
  %12:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 24
  %13:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 36
  %14:float32regs = INT_PTX_LDG_GLOBAL_f32ari64 %9:int64regs, 64
  %15:float32regs = FMA32rrr %4:float32regs, %10:float32regs, %14:float32regs
  %16:float32regs = FMA32rrr %5:float32regs, %11:float32regs, %15:float32regs
  %17:float32regs = FMA32rrr %6:float32regs, %12:float32regs, %16:float32regs
  %18:float32regs = FMA32rrr %7:float32regs, %13:float32regs, %17:float32regs
  %19:int64regs = ADDi64rr %2:int64regs, %8:int64regs
  ST_f32_areg_64 %18:float32regs, 0, 1, 1, 2, 32, %19:int64regs :: (store (s32) into %ir.32, addrspace 1)
  Return

# End machine code for function main_dispatch_0_matmul_1x3x4_f32.

