{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUXnh11hA75x"
      },
      "source": [
        "##### Copyright 2023 The IREE Authors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "FqsvmKpjBJO2"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License v2.0 with LLVM Exceptions.\n",
        "# See https://llvm.org/LICENSE.txt for license information.\n",
        "# SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38UDc27KBPD1"
      },
      "source": [
        "# <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/1/10/PyTorch_logo_icon.svg/640px-PyTorch_logo_icon.svg.png\" height=\"20px\"> PyTorch Ahead-of-time (AOT) export workflows using <img src=\"https://raw.githubusercontent.com/openxla/iree/main/docs/website/overrides/.icons/iree/ghost.svg\" height=\"20px\"> IREE\n",
        "\n",
        "This notebook shows how to use [SHARK-Turbine](https://github.com/nod-ai/SHARK-Turbine) for export from a PyTorch session to [IREE](https://github.com/openxla/iree), leveraging [torch-mlir](https://github.com/llvm/torch-mlir) under the covers.\n",
        "\n",
        "SHARK-Turbine contains both a \"simple\" AOT exporter and an underlying advanced\n",
        "API for complicated models and full feature availability. This notebook only\n",
        "uses the \"simple\" exporter."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbcW5jMLK8gK"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KsPubQSvCbXd"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "#@title Uninstall existing packages\n",
        "#   This avoids some warnings when installing specific PyTorch packages below.\n",
        "!python -m pip uninstall -y fastai torchaudio torchdata torchtext torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "4iJFDHbsAzo4",
        "outputId": "eabab418-3340-4f8c-ac45-76d23828065c"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "google.colab.output.setIframeHeight(0, true, {maxHeight: 300})",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: shark-turbine in /home/liuyn/anaconda3/envs/iree/lib/python3.10/site-packages (0.9.2)\n",
            "Requirement already satisfied: numpy in /home/liuyn/anaconda3/envs/iree/lib/python3.10/site-packages (from shark-turbine) (1.26.2)\n",
            "Requirement already satisfied: iree-compiler>=20231113.707 in /home/liuyn/anaconda3/envs/iree/lib/python3.10/site-packages (from shark-turbine) (20231113.707)\n",
            "Requirement already satisfied: iree-runtime>=20231113.707 in /home/liuyn/anaconda3/envs/iree/lib/python3.10/site-packages (from shark-turbine) (20231113.707)\n",
            "Requirement already satisfied: torch>=2.1.0 in /home/liuyn/anaconda3/envs/iree/lib/python3.10/site-packages (from shark-turbine) (2.1.2)\n",
            "Requirement already satisfied: PyYAML in /home/liuyn/anaconda3/envs/iree/lib/python3.10/site-packages (from iree-compiler>=20231113.707->shark-turbine) (6.0.1)\n",
            "Requirement already satisfied: filelock in /home/liuyn/anaconda3/envs/iree/lib/python3.10/site-packages (from torch>=2.1.0->shark-turbine) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /home/liuyn/anaconda3/envs/iree/lib/python3.10/site-packages (from torch>=2.1.0->shark-turbine) (4.9.0)\n",
            "Requirement already satisfied: sympy in /home/liuyn/anaconda3/envs/iree/lib/python3.10/site-packages (from torch>=2.1.0->shark-turbine) (1.12)\n",
            "Requirement already satisfied: networkx in /home/liuyn/anaconda3/envs/iree/lib/python3.10/site-packages (from torch>=2.1.0->shark-turbine) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /home/liuyn/anaconda3/envs/iree/lib/python3.10/site-packages (from torch>=2.1.0->shark-turbine) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /home/liuyn/anaconda3/envs/iree/lib/python3.10/site-packages (from torch>=2.1.0->shark-turbine) (2023.12.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/liuyn/anaconda3/envs/iree/lib/python3.10/site-packages (from torch>=2.1.0->shark-turbine) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/liuyn/anaconda3/envs/iree/lib/python3.10/site-packages (from torch>=2.1.0->shark-turbine) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/liuyn/anaconda3/envs/iree/lib/python3.10/site-packages (from torch>=2.1.0->shark-turbine) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/liuyn/anaconda3/envs/iree/lib/python3.10/site-packages (from torch>=2.1.0->shark-turbine) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/liuyn/anaconda3/envs/iree/lib/python3.10/site-packages (from torch>=2.1.0->shark-turbine) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/liuyn/anaconda3/envs/iree/lib/python3.10/site-packages (from torch>=2.1.0->shark-turbine) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/liuyn/anaconda3/envs/iree/lib/python3.10/site-packages (from torch>=2.1.0->shark-turbine) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/liuyn/anaconda3/envs/iree/lib/python3.10/site-packages (from torch>=2.1.0->shark-turbine) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/liuyn/anaconda3/envs/iree/lib/python3.10/site-packages (from torch>=2.1.0->shark-turbine) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /home/liuyn/anaconda3/envs/iree/lib/python3.10/site-packages (from torch>=2.1.0->shark-turbine) (2.18.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/liuyn/anaconda3/envs/iree/lib/python3.10/site-packages (from torch>=2.1.0->shark-turbine) (12.1.105)\n",
            "Requirement already satisfied: triton==2.1.0 in /home/liuyn/anaconda3/envs/iree/lib/python3.10/site-packages (from torch>=2.1.0->shark-turbine) (2.1.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/liuyn/anaconda3/envs/iree/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.1.0->shark-turbine) (12.3.101)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /home/liuyn/anaconda3/envs/iree/lib/python3.10/site-packages (from jinja2->torch>=2.1.0->shark-turbine) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /home/liuyn/anaconda3/envs/iree/lib/python3.10/site-packages (from sympy->torch>=2.1.0->shark-turbine) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "#@title Install SHARK-Turbine\n",
        "\n",
        "# Limit cell height.\n",
        "from IPython.display import Javascript\n",
        "display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 300})'''))\n",
        "\n",
        "!python -m pip install shark-turbine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nkVLzRpcDnVL",
        "outputId": "b90948c4-fef8-4d0d-e952-962d0675e717"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Installed SHARK-Turbine, Version: 0.9.2\n",
            "\n",
            "Installed IREE, compiler version information:\n",
            "IREE (https://iree.dev):\n",
            "  IREE compiler version 20231113.707 @ e8c6432ee14e1d4bd917be8505465e2c96b94e28\n",
            "  LLVM version 18.0.0git\n",
            "  Optimized build\n",
            "\n",
            "Installed PyTorch, version: 2.1.2+cu121\n"
          ]
        }
      ],
      "source": [
        "#@title Report version information\n",
        "!echo \"Installed SHARK-Turbine, $(python -m pip show shark_turbine | grep Version)\"\n",
        "\n",
        "!echo -e \"\\nInstalled IREE, compiler version information:\"\n",
        "!iree-compile --version\n",
        "\n",
        "import torch\n",
        "print(\"\\nInstalled PyTorch, version:\", torch.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Mi3YR75LBxl"
      },
      "source": [
        "## Sample AOT workflow\n",
        "\n",
        "1. Define a program using `torch.nn.Module`\n",
        "2. Export the program using `aot.export()`\n",
        "3. Compile to a deployable artifact\n",
        "  * a: By staying within a Python session\n",
        "  * b: By outputting MLIR and continuing using native tools\n",
        "\n",
        "Useful documentation:\n",
        "\n",
        "* [PyTorch Modules](https://pytorch.org/docs/stable/notes/modules.html) (`nn.Module`) as building blocks for stateful computation\n",
        "* IREE compiler and runtime [Python bindings](https://www.iree.dev/reference/bindings/python/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "oPdjrmPZMNz6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LeNet(\n",
            "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "#@title 1. Define a program using `torch.nn.Module`\n",
        "# torch.manual_seed(0)\n",
        "\n",
        "# class LinearModule(torch.nn.Module):\n",
        "#   def __init__(self, in_features, out_features):\n",
        "#     super().__init__()\n",
        "#     self.weight = torch.nn.Parameter(torch.randn(in_features, out_features))\n",
        "#     self.bias = torch.nn.Parameter(torch.randn(out_features))\n",
        "\n",
        "#   def forward(self, input):\n",
        "#     return (input @ self.weight) + self.bias\n",
        "\n",
        "# linear_module = LinearModule(4, 3)\n",
        "\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class LeNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet, self).__init__()\n",
        "        # 卷积层 C1: 输入通道=1, 输出通道=6, 卷积核大小=5x5\n",
        "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5)\n",
        "        # 池化层 S2: 使用最大池化, 池化大小=2x2, 步长=2\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        # 卷积层 C3: 输入通道=6, 输出通道=16, 卷积核大小=5x5\n",
        "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
        "        # 池化层 S4: 使用最大池化, 池化大小=2x2, 步长=2\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        # 全连接层 F5: 输入特征=16*5*5, 输出特征=120\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        # 全连接层 F6: 输入特征=120, 输出特征=84\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        # 输出层: 输入特征=84, 输出特征=10 (假设有10个分类)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 通过 C1, 激活函数, S2\n",
        "        x = self.pool1(F.relu(self.conv1(x)))\n",
        "        # 通过 C3, 激活函数, S4\n",
        "        x = self.pool2(F.relu(self.conv2(x)))\n",
        "        # 展平特征图，准备进入全连接层\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        # 通过 F5, 激活函数\n",
        "        x = F.relu(self.fc1(x))\n",
        "        # 通过 F6, 激活函数\n",
        "        x = F.relu(self.fc2(x))\n",
        "        # 通过输出层\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# 创建 LeNet 模型实例\n",
        "lenet = LeNet()\n",
        "\n",
        "# 打印模型结构\n",
        "print(lenet)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "eK2fWVfiSQ8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'shark_turbine.aot.exporter.ExportOutput'>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/liuyn/anaconda3/envs/iree/lib/python3.10/site-packages/torch/cuda/__init__.py:138: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
            "  return torch._C._cuda_getDeviceCount() > 0\n"
          ]
        }
      ],
      "source": [
        "#@title 2. Export the program using `aot.export()`\n",
        "import shark_turbine.aot as aot\n",
        "\n",
        "example_arg = torch.randn([1, 1, 32, 32])\n",
        "export_output = aot.export(lenet, example_arg)\n",
        "print(type(export_output))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMRNdFdos900",
        "outputId": "0855ca51-042d-4101-811f-0a871d8c8438"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[-0.06582566 -0.08111075  0.10825731 -0.13008909 -0.05546051 -0.06898132\n",
            "   0.10918593  0.11239541  0.07509246  0.05092049]]\n"
          ]
        }
      ],
      "source": [
        "#@title 3a. Compile fully to a deployable artifact, in our existing Python session\n",
        "\n",
        "# Staying in Python gives the API a chance to reuse memory, improving\n",
        "# performance when compiling large programs.\n",
        "\n",
        "compiled_binary = export_output.compile(save_to=None)\n",
        "\n",
        "# Use the IREE runtime API to test the compiled program.\n",
        "import numpy as np\n",
        "import iree.runtime as ireert\n",
        "\n",
        "config = ireert.Config(\"local-task\")\n",
        "vm_module = ireert.load_vm_module(\n",
        "    ireert.VmModule.wrap_buffer(config.vm_instance, compiled_binary.map_memory()),\n",
        "    config,\n",
        ")\n",
        "\n",
        "# input = np.array([1.0, 2.0, 3.0, 4.0], dtype=np.float32)\n",
        "input = np.ones((1, 1, 32, 32)).astype(np.float32)\n",
        "result = vm_module.main(input)\n",
        "print(result.to_host()[...,:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CP2ret1SU0xl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0AdkXY8VNL2-",
        "outputId": "5803f844-efb4-48dd-9e3f-c5b0b09404af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EXEC @main\n",
            "result[0]: hal.buffer_view\n",
            "1x10xf32=[-0.0658257 -0.0811108 0.108257 -0.130089 -0.0554605 -0.0689813 0.109186 0.112395 0.0750925 0.0509205]\n"
          ]
        }
      ],
      "source": [
        "#@title 3b. Output MLIR then continue from Python or native tools later\n",
        "\n",
        "# Leaving Python allows for file system checkpointing and grants access to\n",
        "# native development workflows.\n",
        "\n",
        "mlir_file_path = \"./lenet_pytorch.mlir\"\n",
        "vmfb_file_path = \"/tmp/linear_module_pytorch_llvmcpu.vmfb\"\n",
        "\n",
        "# export_output.print_readable()\n",
        "export_output.save_mlir(mlir_file_path)\n",
        "\n",
        "!iree-compile --iree-input-type=torch --iree-hal-target-backends=llvm-cpu {mlir_file_path} -o {vmfb_file_path}\n",
        "!iree-run-module --module={vmfb_file_path} --device=local-task --input=\"1x1x32x32xf32=1.0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "UUXnh11hA75x"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
