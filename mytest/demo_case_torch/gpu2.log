// -----// IR Dump After mlir::iree_compiler::IREE::HAL::AssignTargetDevicesPass (iree-hal-assign-target-devices) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  func.func @main(%arg0: tensor<?x?xf32>) -> tensor<?x?xf32> attributes {torch.args_schema = "[1, {\22type\22: \22builtins.tuple\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: \22builtins.list\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: null, \22context\22: null, \22children_spec\22: []}]}, {\22type\22: \22builtins.dict\22, \22context\22: \22[]\22, \22children_spec\22: []}]}]", torch.return_schema = "[1, {\22type\22: null, \22context\22: null, \22children_spec\22: []}]"} {
    %0 = torch_c.from_builtin_tensor %arg0 : tensor<?x?xf32> -> !torch.vtensor<[?,?],f32>
    %1 = call @forward(%0) : (!torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],f32>
    %2 = torch_c.to_builtin_tensor %1 : !torch.vtensor<[?,?],f32> -> tensor<?x?xf32>
    return %2 : tensor<?x?xf32>
  }
  func.func private @forward(%arg0: !torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],f32> {
    %0 = torch.aten.mm %arg0, %arg0 : !torch.vtensor<[?,?],f32>, !torch.vtensor<[?,?],f32> -> !torch.vtensor<[?,?],f32>
    return %0 : !torch.vtensor<[?,?],f32>
  }
}


// -----// IR Dump After SetStrictSymbolicShapesPass (torch-iree-set-strict-symbolic-shapes) //----- //
func.func @main(%arg0: tensor<?x?xf32>) -> tensor<?x?xf32> attributes {torch.args_schema = "[1, {\22type\22: \22builtins.tuple\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: \22builtins.list\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: null, \22context\22: null, \22children_spec\22: []}]}, {\22type\22: \22builtins.dict\22, \22context\22: \22[]\22, \22children_spec\22: []}]}]", torch.assume_strict_symbolic_shapes, torch.return_schema = "[1, {\22type\22: null, \22context\22: null, \22children_spec\22: []}]"} {
  %0 = torch_c.from_builtin_tensor %arg0 : tensor<?x?xf32> -> !torch.vtensor<[?,?],f32>
  %1 = call @forward(%0) : (!torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],f32>
  %2 = torch_c.to_builtin_tensor %1 : !torch.vtensor<[?,?],f32> -> tensor<?x?xf32>
  return %2 : tensor<?x?xf32>
}

// -----// IR Dump After SetStrictSymbolicShapesPass (torch-iree-set-strict-symbolic-shapes) //----- //
func.func private @forward(%arg0: !torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],f32> attributes {torch.assume_strict_symbolic_shapes} {
  %0 = torch.aten.mm %arg0, %arg0 : !torch.vtensor<[?,?],f32>, !torch.vtensor<[?,?],f32> -> !torch.vtensor<[?,?],f32>
  return %0 : !torch.vtensor<[?,?],f32>
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main(%arg0: tensor<?x?xf32>) -> tensor<?x?xf32> attributes {torch.args_schema = "[1, {\22type\22: \22builtins.tuple\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: \22builtins.list\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: null, \22context\22: null, \22children_spec\22: []}]}, {\22type\22: \22builtins.dict\22, \22context\22: \22[]\22, \22children_spec\22: []}]}]", torch.assume_strict_symbolic_shapes, torch.return_schema = "[1, {\22type\22: null, \22context\22: null, \22children_spec\22: []}]"} {
  %0 = torch_c.from_builtin_tensor %arg0 : tensor<?x?xf32> -> !torch.vtensor<[?,?],f32>
  %1 = call @forward(%0) : (!torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],f32>
  %2 = torch_c.to_builtin_tensor %1 : !torch.vtensor<[?,?],f32> -> tensor<?x?xf32>
  return %2 : tensor<?x?xf32>
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func private @forward(%arg0: !torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],f32> attributes {torch.assume_strict_symbolic_shapes} {
  %0 = torch.aten.mm %arg0, %arg0 : !torch.vtensor<[?,?],f32>, !torch.vtensor<[?,?],f32> -> !torch.vtensor<[?,?],f32>
  return %0 : !torch.vtensor<[?,?],f32>
}

// -----// IR Dump After BitCastQuantTensorPass (torch-iree-bitcast-quant-tensor) //----- //
func.func @main(%arg0: tensor<?x?xf32>) -> tensor<?x?xf32> attributes {torch.args_schema = "[1, {\22type\22: \22builtins.tuple\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: \22builtins.list\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: null, \22context\22: null, \22children_spec\22: []}]}, {\22type\22: \22builtins.dict\22, \22context\22: \22[]\22, \22children_spec\22: []}]}]", torch.assume_strict_symbolic_shapes, torch.return_schema = "[1, {\22type\22: null, \22context\22: null, \22children_spec\22: []}]"} {
  %0 = torch_c.from_builtin_tensor %arg0 : tensor<?x?xf32> -> !torch.vtensor<[?,?],f32>
  %1 = call @forward(%0) : (!torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],f32>
  %2 = torch_c.to_builtin_tensor %1 : !torch.vtensor<[?,?],f32> -> tensor<?x?xf32>
  return %2 : tensor<?x?xf32>
}

// -----// IR Dump After BitCastQuantTensorPass (torch-iree-bitcast-quant-tensor) //----- //
func.func private @forward(%arg0: !torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],f32> attributes {torch.assume_strict_symbolic_shapes} {
  %0 = torch.aten.mm %arg0, %arg0 : !torch.vtensor<[?,?],f32>, !torch.vtensor<[?,?],f32> -> !torch.vtensor<[?,?],f32>
  return %0 : !torch.vtensor<[?,?],f32>
}

// -----// IR Dump After ConvertCustomQuantOp (torch-convert-custom-quant-op) //----- //
func.func @main(%arg0: tensor<?x?xf32>) -> tensor<?x?xf32> attributes {torch.args_schema = "[1, {\22type\22: \22builtins.tuple\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: \22builtins.list\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: null, \22context\22: null, \22children_spec\22: []}]}, {\22type\22: \22builtins.dict\22, \22context\22: \22[]\22, \22children_spec\22: []}]}]", torch.assume_strict_symbolic_shapes, torch.return_schema = "[1, {\22type\22: null, \22context\22: null, \22children_spec\22: []}]"} {
  %0 = torch_c.from_builtin_tensor %arg0 : tensor<?x?xf32> -> !torch.vtensor<[?,?],f32>
  %1 = call @forward(%0) : (!torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],f32>
  %2 = torch_c.to_builtin_tensor %1 : !torch.vtensor<[?,?],f32> -> tensor<?x?xf32>
  return %2 : tensor<?x?xf32>
}

// -----// IR Dump After ConvertCustomQuantOp (torch-convert-custom-quant-op) //----- //
func.func private @forward(%arg0: !torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],f32> attributes {torch.assume_strict_symbolic_shapes} {
  %0 = torch.aten.mm %arg0, %arg0 : !torch.vtensor<[?,?],f32>, !torch.vtensor<[?,?],f32> -> !torch.vtensor<[?,?],f32>
  return %0 : !torch.vtensor<[?,?],f32>
}

// -----// IR Dump After DecomposeComplexOps (torch-decompose-complex-ops) //----- //
func.func @main(%arg0: tensor<?x?xf32>) -> tensor<?x?xf32> attributes {torch.args_schema = "[1, {\22type\22: \22builtins.tuple\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: \22builtins.list\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: null, \22context\22: null, \22children_spec\22: []}]}, {\22type\22: \22builtins.dict\22, \22context\22: \22[]\22, \22children_spec\22: []}]}]", torch.assume_strict_symbolic_shapes, torch.return_schema = "[1, {\22type\22: null, \22context\22: null, \22children_spec\22: []}]"} {
  %0 = torch_c.from_builtin_tensor %arg0 : tensor<?x?xf32> -> !torch.vtensor<[?,?],f32>
  %1 = call @forward(%0) : (!torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],f32>
  %2 = torch_c.to_builtin_tensor %1 : !torch.vtensor<[?,?],f32> -> tensor<?x?xf32>
  return %2 : tensor<?x?xf32>
}

// -----// IR Dump After DecomposeComplexOps (torch-decompose-complex-ops) //----- //
func.func private @forward(%arg0: !torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],f32> attributes {torch.assume_strict_symbolic_shapes} {
  %0 = torch.aten.mm %arg0, %arg0 : !torch.vtensor<[?,?],f32>, !torch.vtensor<[?,?],f32> -> !torch.vtensor<[?,?],f32>
  return %0 : !torch.vtensor<[?,?],f32>
}

// -----// IR Dump After ConvertTorchToTMTensor (convert-torch-to-tmtensor) //----- //
func.func @main(%arg0: tensor<?x?xf32>) -> tensor<?x?xf32> attributes {torch.args_schema = "[1, {\22type\22: \22builtins.tuple\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: \22builtins.list\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: null, \22context\22: null, \22children_spec\22: []}]}, {\22type\22: \22builtins.dict\22, \22context\22: \22[]\22, \22children_spec\22: []}]}]", torch.assume_strict_symbolic_shapes, torch.return_schema = "[1, {\22type\22: null, \22context\22: null, \22children_spec\22: []}]"} {
  %0 = torch_c.from_builtin_tensor %arg0 : tensor<?x?xf32> -> !torch.vtensor<[?,?],f32>
  %1 = call @forward(%0) : (!torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],f32>
  %2 = torch_c.to_builtin_tensor %1 : !torch.vtensor<[?,?],f32> -> tensor<?x?xf32>
  return %2 : tensor<?x?xf32>
}

// -----// IR Dump After ConvertTorchToTMTensor (convert-torch-to-tmtensor) //----- //
func.func private @forward(%arg0: !torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],f32> attributes {torch.assume_strict_symbolic_shapes} {
  %0 = torch.aten.mm %arg0, %arg0 : !torch.vtensor<[?,?],f32>, !torch.vtensor<[?,?],f32> -> !torch.vtensor<[?,?],f32>
  return %0 : !torch.vtensor<[?,?],f32>
}

// -----// IR Dump After ConvertTorchToLinalg (convert-torch-to-linalg) //----- //
func.func @main(%arg0: tensor<?x?xf32>) -> tensor<?x?xf32> attributes {torch.args_schema = "[1, {\22type\22: \22builtins.tuple\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: \22builtins.list\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: null, \22context\22: null, \22children_spec\22: []}]}, {\22type\22: \22builtins.dict\22, \22context\22: \22[]\22, \22children_spec\22: []}]}]", torch.assume_strict_symbolic_shapes, torch.return_schema = "[1, {\22type\22: null, \22context\22: null, \22children_spec\22: []}]"} {
  %0 = torch_c.from_builtin_tensor %arg0 : tensor<?x?xf32> -> !torch.vtensor<[?,?],f32>
  %1 = call @forward(%0) : (!torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],f32>
  %2 = torch_c.to_builtin_tensor %1 : !torch.vtensor<[?,?],f32> -> tensor<?x?xf32>
  return %2 : tensor<?x?xf32>
}

// -----// IR Dump After ConvertTorchToLinalg (convert-torch-to-linalg) //----- //
func.func private @forward(%arg0: !torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],f32> attributes {torch.assume_strict_symbolic_shapes} {
  %0 = torch_c.to_builtin_tensor %arg0 : !torch.vtensor<[?,?],f32> -> tensor<?x?xf32>
  %c0 = arith.constant 0 : index
  %dim = tensor.dim %0, %c0 : tensor<?x?xf32>
  %c1 = arith.constant 1 : index
  %dim_0 = tensor.dim %0, %c1 : tensor<?x?xf32>
  %1 = tensor.empty(%dim, %dim_0) : tensor<?x?xf32>
  %cst = arith.constant 0.000000e+00 : f32
  %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %3 = linalg.matmul ins(%0, %0 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%2 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %cast = tensor.cast %3 : tensor<?x?xf32> to tensor<?x?xf32>
  %4 = torch_c.from_builtin_tensor %cast : tensor<?x?xf32> -> !torch.vtensor<[?,?],f32>
  return %4 : !torch.vtensor<[?,?],f32>
}

// -----// IR Dump After ConvertTorchToSCF (convert-torch-to-scf) //----- //
func.func @main(%arg0: tensor<?x?xf32>) -> tensor<?x?xf32> attributes {torch.args_schema = "[1, {\22type\22: \22builtins.tuple\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: \22builtins.list\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: null, \22context\22: null, \22children_spec\22: []}]}, {\22type\22: \22builtins.dict\22, \22context\22: \22[]\22, \22children_spec\22: []}]}]", torch.assume_strict_symbolic_shapes, torch.return_schema = "[1, {\22type\22: null, \22context\22: null, \22children_spec\22: []}]"} {
  %0 = torch_c.from_builtin_tensor %arg0 : tensor<?x?xf32> -> !torch.vtensor<[?,?],f32>
  %1 = call @forward(%0) : (!torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],f32>
  %2 = torch_c.to_builtin_tensor %1 : !torch.vtensor<[?,?],f32> -> tensor<?x?xf32>
  return %2 : tensor<?x?xf32>
}

// -----// IR Dump After ConvertTorchToSCF (convert-torch-to-scf) //----- //
func.func private @forward(%arg0: !torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],f32> attributes {torch.assume_strict_symbolic_shapes} {
  %0 = torch_c.to_builtin_tensor %arg0 : !torch.vtensor<[?,?],f32> -> tensor<?x?xf32>
  %c0 = arith.constant 0 : index
  %dim = tensor.dim %0, %c0 : tensor<?x?xf32>
  %c1 = arith.constant 1 : index
  %dim_0 = tensor.dim %0, %c1 : tensor<?x?xf32>
  %1 = tensor.empty(%dim, %dim_0) : tensor<?x?xf32>
  %cst = arith.constant 0.000000e+00 : f32
  %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %3 = linalg.matmul ins(%0, %0 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%2 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %4 = torch_c.from_builtin_tensor %3 : tensor<?x?xf32> -> !torch.vtensor<[?,?],f32>
  return %4 : !torch.vtensor<[?,?],f32>
}

// -----// IR Dump After ConvertTorchToArith (convert-torch-to-arith) //----- //
func.func @main(%arg0: tensor<?x?xf32>) -> tensor<?x?xf32> attributes {torch.args_schema = "[1, {\22type\22: \22builtins.tuple\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: \22builtins.list\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: null, \22context\22: null, \22children_spec\22: []}]}, {\22type\22: \22builtins.dict\22, \22context\22: \22[]\22, \22children_spec\22: []}]}]", torch.assume_strict_symbolic_shapes, torch.return_schema = "[1, {\22type\22: null, \22context\22: null, \22children_spec\22: []}]"} {
  %0 = torch_c.from_builtin_tensor %arg0 : tensor<?x?xf32> -> !torch.vtensor<[?,?],f32>
  %1 = call @forward(%0) : (!torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],f32>
  %2 = torch_c.to_builtin_tensor %1 : !torch.vtensor<[?,?],f32> -> tensor<?x?xf32>
  return %2 : tensor<?x?xf32>
}

// -----// IR Dump After ConvertTorchToArith (convert-torch-to-arith) //----- //
func.func private @forward(%arg0: !torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],f32> attributes {torch.assume_strict_symbolic_shapes} {
  %0 = torch_c.to_builtin_tensor %arg0 : !torch.vtensor<[?,?],f32> -> tensor<?x?xf32>
  %c0 = arith.constant 0 : index
  %dim = tensor.dim %0, %c0 : tensor<?x?xf32>
  %c1 = arith.constant 1 : index
  %dim_0 = tensor.dim %0, %c1 : tensor<?x?xf32>
  %1 = tensor.empty(%dim, %dim_0) : tensor<?x?xf32>
  %cst = arith.constant 0.000000e+00 : f32
  %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %3 = linalg.matmul ins(%0, %0 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%2 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %4 = torch_c.from_builtin_tensor %3 : tensor<?x?xf32> -> !torch.vtensor<[?,?],f32>
  return %4 : !torch.vtensor<[?,?],f32>
}

// -----// IR Dump After ConvertTorchConversionToMLProgram (convert-torch-conversion-to-mlprogram) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  ml_program.global private mutable @global_seed(dense<0> : tensor<i64>) : tensor<i64>
  func.func @main(%arg0: tensor<?x?xf32>) -> tensor<?x?xf32> attributes {torch.args_schema = "[1, {\22type\22: \22builtins.tuple\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: \22builtins.list\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: null, \22context\22: null, \22children_spec\22: []}]}, {\22type\22: \22builtins.dict\22, \22context\22: \22[]\22, \22children_spec\22: []}]}]", torch.assume_strict_symbolic_shapes, torch.return_schema = "[1, {\22type\22: null, \22context\22: null, \22children_spec\22: []}]"} {
    %0 = torch_c.from_builtin_tensor %arg0 : tensor<?x?xf32> -> !torch.vtensor<[?,?],f32>
    %1 = call @forward(%0) : (!torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],f32>
    %2 = torch_c.to_builtin_tensor %1 : !torch.vtensor<[?,?],f32> -> tensor<?x?xf32>
    return %2 : tensor<?x?xf32>
  }
  func.func private @forward(%arg0: !torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],f32> attributes {torch.assume_strict_symbolic_shapes} {
    %0 = torch_c.to_builtin_tensor %arg0 : !torch.vtensor<[?,?],f32> -> tensor<?x?xf32>
    %c0 = arith.constant 0 : index
    %dim = tensor.dim %0, %c0 : tensor<?x?xf32>
    %c1 = arith.constant 1 : index
    %dim_0 = tensor.dim %0, %c1 : tensor<?x?xf32>
    %1 = tensor.empty(%dim, %dim_0) : tensor<?x?xf32>
    %cst = arith.constant 0.000000e+00 : f32
    %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<?x?xf32>) -> tensor<?x?xf32>
    %3 = linalg.matmul ins(%0, %0 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%2 : tensor<?x?xf32>) -> tensor<?x?xf32>
    %4 = torch_c.from_builtin_tensor %3 : tensor<?x?xf32> -> !torch.vtensor<[?,?],f32>
    return %4 : !torch.vtensor<[?,?],f32>
  }
}


// -----// IR Dump After ExpandOps (memref-expand) //----- //
func.func @main(%arg0: tensor<?x?xf32>) -> tensor<?x?xf32> attributes {torch.args_schema = "[1, {\22type\22: \22builtins.tuple\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: \22builtins.list\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: null, \22context\22: null, \22children_spec\22: []}]}, {\22type\22: \22builtins.dict\22, \22context\22: \22[]\22, \22children_spec\22: []}]}]", torch.assume_strict_symbolic_shapes, torch.return_schema = "[1, {\22type\22: null, \22context\22: null, \22children_spec\22: []}]"} {
  %0 = torch_c.from_builtin_tensor %arg0 : tensor<?x?xf32> -> !torch.vtensor<[?,?],f32>
  %1 = call @forward(%0) : (!torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],f32>
  %2 = torch_c.to_builtin_tensor %1 : !torch.vtensor<[?,?],f32> -> tensor<?x?xf32>
  return %2 : tensor<?x?xf32>
}

// -----// IR Dump After ExpandOps (memref-expand) //----- //
func.func private @forward(%arg0: !torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],f32> attributes {torch.assume_strict_symbolic_shapes} {
  %0 = torch_c.to_builtin_tensor %arg0 : !torch.vtensor<[?,?],f32> -> tensor<?x?xf32>
  %c0 = arith.constant 0 : index
  %dim = tensor.dim %0, %c0 : tensor<?x?xf32>
  %c1 = arith.constant 1 : index
  %dim_0 = tensor.dim %0, %c1 : tensor<?x?xf32>
  %1 = tensor.empty(%dim, %dim_0) : tensor<?x?xf32>
  %cst = arith.constant 0.000000e+00 : f32
  %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %3 = linalg.matmul ins(%0, %0 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%2 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %4 = torch_c.from_builtin_tensor %3 : tensor<?x?xf32> -> !torch.vtensor<[?,?],f32>
  return %4 : !torch.vtensor<[?,?],f32>
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main(%arg0: tensor<?x?xf32>) -> tensor<?x?xf32> attributes {torch.args_schema = "[1, {\22type\22: \22builtins.tuple\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: \22builtins.list\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: null, \22context\22: null, \22children_spec\22: []}]}, {\22type\22: \22builtins.dict\22, \22context\22: \22[]\22, \22children_spec\22: []}]}]", torch.assume_strict_symbolic_shapes, torch.return_schema = "[1, {\22type\22: null, \22context\22: null, \22children_spec\22: []}]"} {
  %0 = torch_c.from_builtin_tensor %arg0 : tensor<?x?xf32> -> !torch.vtensor<[?,?],f32>
  %1 = call @forward(%0) : (!torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],f32>
  %2 = torch_c.to_builtin_tensor %1 : !torch.vtensor<[?,?],f32> -> tensor<?x?xf32>
  return %2 : tensor<?x?xf32>
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func private @forward(%arg0: !torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],f32> attributes {torch.assume_strict_symbolic_shapes} {
  %cst = arith.constant 0.000000e+00 : f32
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %0 = torch_c.to_builtin_tensor %arg0 : !torch.vtensor<[?,?],f32> -> tensor<?x?xf32>
  %dim = tensor.dim %0, %c0 : tensor<?x?xf32>
  %dim_0 = tensor.dim %0, %c1 : tensor<?x?xf32>
  %1 = tensor.empty(%dim, %dim_0) : tensor<?x?xf32>
  %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %3 = linalg.matmul ins(%0, %0 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%2 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %4 = torch_c.from_builtin_tensor %3 : tensor<?x?xf32> -> !torch.vtensor<[?,?],f32>
  return %4 : !torch.vtensor<[?,?],f32>
}

// -----// IR Dump After ResolveShapedTypeResultDims (resolve-shaped-type-result-dims) //----- //
func.func @main(%arg0: tensor<?x?xf32>) -> tensor<?x?xf32> attributes {torch.args_schema = "[1, {\22type\22: \22builtins.tuple\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: \22builtins.list\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: null, \22context\22: null, \22children_spec\22: []}]}, {\22type\22: \22builtins.dict\22, \22context\22: \22[]\22, \22children_spec\22: []}]}]", torch.assume_strict_symbolic_shapes, torch.return_schema = "[1, {\22type\22: null, \22context\22: null, \22children_spec\22: []}]"} {
  %0 = torch_c.from_builtin_tensor %arg0 : tensor<?x?xf32> -> !torch.vtensor<[?,?],f32>
  %1 = call @forward(%0) : (!torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],f32>
  %2 = torch_c.to_builtin_tensor %1 : !torch.vtensor<[?,?],f32> -> tensor<?x?xf32>
  return %2 : tensor<?x?xf32>
}

// -----// IR Dump After ResolveShapedTypeResultDims (resolve-shaped-type-result-dims) //----- //
func.func private @forward(%arg0: !torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],f32> attributes {torch.assume_strict_symbolic_shapes} {
  %cst = arith.constant 0.000000e+00 : f32
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %0 = torch_c.to_builtin_tensor %arg0 : !torch.vtensor<[?,?],f32> -> tensor<?x?xf32>
  %dim = tensor.dim %0, %c0 : tensor<?x?xf32>
  %dim_0 = tensor.dim %0, %c1 : tensor<?x?xf32>
  %1 = tensor.empty(%dim, %dim_0) : tensor<?x?xf32>
  %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %3 = linalg.matmul ins(%0, %0 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%2 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %4 = torch_c.from_builtin_tensor %3 : tensor<?x?xf32> -> !torch.vtensor<[?,?],f32>
  return %4 : !torch.vtensor<[?,?],f32>
}

// -----// IR Dump After CSE (cse) //----- //
func.func @main(%arg0: tensor<?x?xf32>) -> tensor<?x?xf32> attributes {torch.args_schema = "[1, {\22type\22: \22builtins.tuple\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: \22builtins.list\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: null, \22context\22: null, \22children_spec\22: []}]}, {\22type\22: \22builtins.dict\22, \22context\22: \22[]\22, \22children_spec\22: []}]}]", torch.assume_strict_symbolic_shapes, torch.return_schema = "[1, {\22type\22: null, \22context\22: null, \22children_spec\22: []}]"} {
  %0 = torch_c.from_builtin_tensor %arg0 : tensor<?x?xf32> -> !torch.vtensor<[?,?],f32>
  %1 = call @forward(%0) : (!torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],f32>
  %2 = torch_c.to_builtin_tensor %1 : !torch.vtensor<[?,?],f32> -> tensor<?x?xf32>
  return %2 : tensor<?x?xf32>
}

// -----// IR Dump After CSE (cse) //----- //
func.func private @forward(%arg0: !torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],f32> attributes {torch.assume_strict_symbolic_shapes} {
  %cst = arith.constant 0.000000e+00 : f32
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %0 = torch_c.to_builtin_tensor %arg0 : !torch.vtensor<[?,?],f32> -> tensor<?x?xf32>
  %dim = tensor.dim %0, %c0 : tensor<?x?xf32>
  %dim_0 = tensor.dim %0, %c1 : tensor<?x?xf32>
  %1 = tensor.empty(%dim, %dim_0) : tensor<?x?xf32>
  %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %3 = linalg.matmul ins(%0, %0 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%2 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %4 = torch_c.from_builtin_tensor %3 : tensor<?x?xf32> -> !torch.vtensor<[?,?],f32>
  return %4 : !torch.vtensor<[?,?],f32>
}

// -----// IR Dump After FuncBackendTypeConversion (torch-func-backend-type-conversion) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  ml_program.global private mutable @global_seed(dense<0> : tensor<i64>) : tensor<i64>
  func.func @main(%arg0: tensor<?x?xf32>) -> tensor<?x?xf32> attributes {torch.args_schema = "[1, {\22type\22: \22builtins.tuple\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: \22builtins.list\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: null, \22context\22: null, \22children_spec\22: []}]}, {\22type\22: \22builtins.dict\22, \22context\22: \22[]\22, \22children_spec\22: []}]}]", torch.assume_strict_symbolic_shapes, torch.return_schema = "[1, {\22type\22: null, \22context\22: null, \22children_spec\22: []}]"} {
    %0 = torch_c.from_builtin_tensor %arg0 : tensor<?x?xf32> -> !torch.vtensor<[?,?],f32>
    %1 = torch_c.to_builtin_tensor %0 : !torch.vtensor<[?,?],f32> -> tensor<?x?xf32>
    %2 = call @forward(%1) : (tensor<?x?xf32>) -> tensor<?x?xf32>
    %3 = torch_c.from_builtin_tensor %2 : tensor<?x?xf32> -> !torch.vtensor<[?,?],f32>
    %4 = torch_c.to_builtin_tensor %3 : !torch.vtensor<[?,?],f32> -> tensor<?x?xf32>
    return %4 : tensor<?x?xf32>
  }
  func.func private @forward(%arg0: tensor<?x?xf32>) -> tensor<?x?xf32> attributes {torch.assume_strict_symbolic_shapes} {
    %0 = torch_c.from_builtin_tensor %arg0 : tensor<?x?xf32> -> !torch.vtensor<[?,?],f32>
    %cst = arith.constant 0.000000e+00 : f32
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %1 = torch_c.to_builtin_tensor %0 : !torch.vtensor<[?,?],f32> -> tensor<?x?xf32>
    %dim = tensor.dim %1, %c0 : tensor<?x?xf32>
    %dim_0 = tensor.dim %1, %c1 : tensor<?x?xf32>
    %2 = tensor.empty(%dim, %dim_0) : tensor<?x?xf32>
    %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<?x?xf32>) -> tensor<?x?xf32>
    %4 = linalg.matmul ins(%1, %1 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%3 : tensor<?x?xf32>) -> tensor<?x?xf32>
    %5 = torch_c.from_builtin_tensor %4 : tensor<?x?xf32> -> !torch.vtensor<[?,?],f32>
    %6 = torch_c.to_builtin_tensor %5 : !torch.vtensor<[?,?],f32> -> tensor<?x?xf32>
    return %6 : tensor<?x?xf32>
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main(%arg0: tensor<?x?xf32>) -> tensor<?x?xf32> attributes {torch.args_schema = "[1, {\22type\22: \22builtins.tuple\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: \22builtins.list\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: null, \22context\22: null, \22children_spec\22: []}]}, {\22type\22: \22builtins.dict\22, \22context\22: \22[]\22, \22children_spec\22: []}]}]", torch.assume_strict_symbolic_shapes, torch.return_schema = "[1, {\22type\22: null, \22context\22: null, \22children_spec\22: []}]"} {
  %0 = torch_c.from_builtin_tensor %arg0 : tensor<?x?xf32> -> !torch.vtensor<[?,?],f32>
  %1 = torch_c.to_builtin_tensor %0 : !torch.vtensor<[?,?],f32> -> tensor<?x?xf32>
  %2 = call @forward(%1) : (tensor<?x?xf32>) -> tensor<?x?xf32>
  %3 = torch_c.from_builtin_tensor %2 : tensor<?x?xf32> -> !torch.vtensor<[?,?],f32>
  %4 = torch_c.to_builtin_tensor %3 : !torch.vtensor<[?,?],f32> -> tensor<?x?xf32>
  return %4 : tensor<?x?xf32>
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func private @forward(%arg0: tensor<?x?xf32>) -> tensor<?x?xf32> attributes {torch.assume_strict_symbolic_shapes} {
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %cst = arith.constant 0.000000e+00 : f32
  %0 = torch_c.from_builtin_tensor %arg0 : tensor<?x?xf32> -> !torch.vtensor<[?,?],f32>
  %1 = torch_c.to_builtin_tensor %0 : !torch.vtensor<[?,?],f32> -> tensor<?x?xf32>
  %dim = tensor.dim %1, %c0 : tensor<?x?xf32>
  %dim_0 = tensor.dim %1, %c1 : tensor<?x?xf32>
  %2 = tensor.empty(%dim, %dim_0) : tensor<?x?xf32>
  %3 = linalg.fill ins(%cst : f32) outs(%2 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %4 = linalg.matmul ins(%1, %1 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%3 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %5 = torch_c.from_builtin_tensor %4 : tensor<?x?xf32> -> !torch.vtensor<[?,?],f32>
  %6 = torch_c.to_builtin_tensor %5 : !torch.vtensor<[?,?],f32> -> tensor<?x?xf32>
  return %6 : tensor<?x?xf32>
}

// -----// IR Dump After FinalizingBackendTypeConversion (torch-finalizing-backend-type-conversion) //----- //
func.func @main(%arg0: tensor<?x?xf32>) -> tensor<?x?xf32> attributes {torch.args_schema = "[1, {\22type\22: \22builtins.tuple\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: \22builtins.list\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: null, \22context\22: null, \22children_spec\22: []}]}, {\22type\22: \22builtins.dict\22, \22context\22: \22[]\22, \22children_spec\22: []}]}]", torch.assume_strict_symbolic_shapes, torch.return_schema = "[1, {\22type\22: null, \22context\22: null, \22children_spec\22: []}]"} {
  %0 = call @forward(%arg0) : (tensor<?x?xf32>) -> tensor<?x?xf32>
  return %0 : tensor<?x?xf32>
}

// -----// IR Dump After FinalizingBackendTypeConversion (torch-finalizing-backend-type-conversion) //----- //
func.func private @forward(%arg0: tensor<?x?xf32>) -> tensor<?x?xf32> attributes {torch.assume_strict_symbolic_shapes} {
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %cst = arith.constant 0.000000e+00 : f32
  %dim = tensor.dim %arg0, %c0 : tensor<?x?xf32>
  %dim_0 = tensor.dim %arg0, %c1 : tensor<?x?xf32>
  %0 = tensor.empty(%dim, %dim_0) : tensor<?x?xf32>
  %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %2 = linalg.matmul ins(%arg0, %arg0 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%1 : tensor<?x?xf32>) -> tensor<?x?xf32>
  return %2 : tensor<?x?xf32>
}

// -----// IR Dump After SymbolDCE (symbol-dce) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  func.func @main(%arg0: tensor<?x?xf32>) -> tensor<?x?xf32> attributes {torch.args_schema = "[1, {\22type\22: \22builtins.tuple\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: \22builtins.list\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: null, \22context\22: null, \22children_spec\22: []}]}, {\22type\22: \22builtins.dict\22, \22context\22: \22[]\22, \22children_spec\22: []}]}]", torch.assume_strict_symbolic_shapes, torch.return_schema = "[1, {\22type\22: null, \22context\22: null, \22children_spec\22: []}]"} {
    %0 = call @forward(%arg0) : (tensor<?x?xf32>) -> tensor<?x?xf32>
    return %0 : tensor<?x?xf32>
  }
  func.func private @forward(%arg0: tensor<?x?xf32>) -> tensor<?x?xf32> attributes {torch.assume_strict_symbolic_shapes} {
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %cst = arith.constant 0.000000e+00 : f32
    %dim = tensor.dim %arg0, %c0 : tensor<?x?xf32>
    %dim_0 = tensor.dim %arg0, %c1 : tensor<?x?xf32>
    %0 = tensor.empty(%dim, %dim_0) : tensor<?x?xf32>
    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<?x?xf32>) -> tensor<?x?xf32>
    %2 = linalg.matmul ins(%arg0, %arg0 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%1 : tensor<?x?xf32>) -> tensor<?x?xf32>
    return %2 : tensor<?x?xf32>
  }
}


// -----// IR Dump After ConvertTMTensorToLinalgExt (torch-iree-tm-tensor-to-linalg-ext) //----- //
func.func @main(%arg0: tensor<?x?xf32>) -> tensor<?x?xf32> attributes {torch.args_schema = "[1, {\22type\22: \22builtins.tuple\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: \22builtins.list\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: null, \22context\22: null, \22children_spec\22: []}]}, {\22type\22: \22builtins.dict\22, \22context\22: \22[]\22, \22children_spec\22: []}]}]", torch.assume_strict_symbolic_shapes, torch.return_schema = "[1, {\22type\22: null, \22context\22: null, \22children_spec\22: []}]"} {
  %0 = call @forward(%arg0) : (tensor<?x?xf32>) -> tensor<?x?xf32>
  return %0 : tensor<?x?xf32>
}

// -----// IR Dump After ConvertTMTensorToLinalgExt (torch-iree-tm-tensor-to-linalg-ext) //----- //
func.func private @forward(%arg0: tensor<?x?xf32>) -> tensor<?x?xf32> attributes {torch.assume_strict_symbolic_shapes} {
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %cst = arith.constant 0.000000e+00 : f32
  %dim = tensor.dim %arg0, %c0 : tensor<?x?xf32>
  %dim_0 = tensor.dim %arg0, %c1 : tensor<?x?xf32>
  %0 = tensor.empty(%dim, %dim_0) : tensor<?x?xf32>
  %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %2 = linalg.matmul ins(%arg0, %arg0 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%1 : tensor<?x?xf32>) -> tensor<?x?xf32>
  return %2 : tensor<?x?xf32>
}

// -----// IR Dump After IREEImportPublic (iree-import-public) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  func.func @main(%arg0: tensor<?x?xf32>) -> tensor<?x?xf32> attributes {torch.args_schema = "[1, {\22type\22: \22builtins.tuple\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: \22builtins.list\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: null, \22context\22: null, \22children_spec\22: []}]}, {\22type\22: \22builtins.dict\22, \22context\22: \22[]\22, \22children_spec\22: []}]}]", torch.assume_strict_symbolic_shapes, torch.return_schema = "[1, {\22type\22: null, \22context\22: null, \22children_spec\22: []}]"} {
    %0 = call @forward(%arg0) : (tensor<?x?xf32>) -> tensor<?x?xf32>
    return %0 : tensor<?x?xf32>
  }
  func.func private @forward(%arg0: tensor<?x?xf32>) -> tensor<?x?xf32> attributes {torch.assume_strict_symbolic_shapes} {
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %cst = arith.constant 0.000000e+00 : f32
    %dim = tensor.dim %arg0, %c0 : tensor<?x?xf32>
    %dim_0 = tensor.dim %arg0, %c1 : tensor<?x?xf32>
    %0 = tensor.empty(%dim, %dim_0) : tensor<?x?xf32>
    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<?x?xf32>) -> tensor<?x?xf32>
    %2 = linalg.matmul ins(%arg0, %arg0 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%1 : tensor<?x?xf32>) -> tensor<?x?xf32>
    return %2 : tensor<?x?xf32>
  }
}


// -----// IR Dump After ImportMLProgram (iree-import-ml-program) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  func.func @main(%arg0: tensor<?x?xf32>) -> tensor<?x?xf32> attributes {torch.args_schema = "[1, {\22type\22: \22builtins.tuple\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: \22builtins.list\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: null, \22context\22: null, \22children_spec\22: []}]}, {\22type\22: \22builtins.dict\22, \22context\22: \22[]\22, \22children_spec\22: []}]}]", torch.assume_strict_symbolic_shapes, torch.return_schema = "[1, {\22type\22: null, \22context\22: null, \22children_spec\22: []}]"} {
    %0 = call @forward(%arg0) : (tensor<?x?xf32>) -> tensor<?x?xf32>
    return %0 : tensor<?x?xf32>
  }
  func.func private @forward(%arg0: tensor<?x?xf32>) -> tensor<?x?xf32> attributes {torch.assume_strict_symbolic_shapes} {
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %cst = arith.constant 0.000000e+00 : f32
    %dim = tensor.dim %arg0, %c0 : tensor<?x?xf32>
    %dim_0 = tensor.dim %arg0, %c1 : tensor<?x?xf32>
    %0 = tensor.empty(%dim, %dim_0) : tensor<?x?xf32>
    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<?x?xf32>) -> tensor<?x?xf32>
    %2 = linalg.matmul ins(%arg0, %arg0 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%1 : tensor<?x?xf32>) -> tensor<?x?xf32>
    return %2 : tensor<?x?xf32>
  }
}


// -----// IR Dump After SanitizeModuleNames (iree-sanitize-module-names) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  func.func @main(%arg0: tensor<?x?xf32>) -> tensor<?x?xf32> attributes {torch.args_schema = "[1, {\22type\22: \22builtins.tuple\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: \22builtins.list\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: null, \22context\22: null, \22children_spec\22: []}]}, {\22type\22: \22builtins.dict\22, \22context\22: \22[]\22, \22children_spec\22: []}]}]", torch.assume_strict_symbolic_shapes, torch.return_schema = "[1, {\22type\22: null, \22context\22: null, \22children_spec\22: []}]"} {
    %0 = call @forward(%arg0) : (tensor<?x?xf32>) -> tensor<?x?xf32>
    return %0 : tensor<?x?xf32>
  }
  func.func private @forward(%arg0: tensor<?x?xf32>) -> tensor<?x?xf32> attributes {torch.assume_strict_symbolic_shapes} {
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %cst = arith.constant 0.000000e+00 : f32
    %dim = tensor.dim %arg0, %c0 : tensor<?x?xf32>
    %dim_0 = tensor.dim %arg0, %c1 : tensor<?x?xf32>
    %0 = tensor.empty(%dim, %dim_0) : tensor<?x?xf32>
    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<?x?xf32>) -> tensor<?x?xf32>
    %2 = linalg.matmul ins(%arg0, %arg0 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%1 : tensor<?x?xf32>) -> tensor<?x?xf32>
    return %2 : tensor<?x?xf32>
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::ABI::ConvertStreamableOpsPass (iree-abi-convert-streamable-ops) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  func.func @main(%arg0: tensor<?x?xf32>) -> tensor<?x?xf32> attributes {torch.args_schema = "[1, {\22type\22: \22builtins.tuple\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: \22builtins.list\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: null, \22context\22: null, \22children_spec\22: []}]}, {\22type\22: \22builtins.dict\22, \22context\22: \22[]\22, \22children_spec\22: []}]}]", torch.assume_strict_symbolic_shapes, torch.return_schema = "[1, {\22type\22: null, \22context\22: null, \22children_spec\22: []}]"} {
    %0 = call @forward(%arg0) : (tensor<?x?xf32>) -> tensor<?x?xf32>
    return %0 : tensor<?x?xf32>
  }
  func.func private @forward(%arg0: tensor<?x?xf32>) -> tensor<?x?xf32> attributes {torch.assume_strict_symbolic_shapes} {
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %cst = arith.constant 0.000000e+00 : f32
    %dim = tensor.dim %arg0, %c0 : tensor<?x?xf32>
    %dim_0 = tensor.dim %arg0, %c1 : tensor<?x?xf32>
    %0 = tensor.empty(%dim, %dim_0) : tensor<?x?xf32>
    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<?x?xf32>) -> tensor<?x?xf32>
    %2 = linalg.matmul ins(%arg0, %arg0 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%1 : tensor<?x?xf32>) -> tensor<?x?xf32>
    return %2 : tensor<?x?xf32>
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::ABI::WrapEntryPointsPass (iree-abi-wrap-entry-points) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
    %3 = call @_main(%2) : (tensor<?x?xf32>) -> tensor<?x?xf32>
    %c0 = arith.constant 0 : index
    %dim = tensor.dim %3, %c0 : tensor<?x?xf32>
    %c1 = arith.constant 1 : index
    %dim_0 = tensor.dim %3, %c1 : tensor<?x?xf32>
    %4 = hal.tensor.export %3 "output 0" : tensor<?x?xf32>{%dim, %dim_0} -> !hal.buffer_view
    return %4 : !hal.buffer_view
  }
  func.func private @_main(%arg0: tensor<?x?xf32>) -> tensor<?x?xf32> attributes {torch.args_schema = "[1, {\22type\22: \22builtins.tuple\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: \22builtins.list\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: null, \22context\22: null, \22children_spec\22: []}]}, {\22type\22: \22builtins.dict\22, \22context\22: \22[]\22, \22children_spec\22: []}]}]", torch.assume_strict_symbolic_shapes, torch.return_schema = "[1, {\22type\22: null, \22context\22: null, \22children_spec\22: []}]"} {
    %0 = call @forward(%arg0) : (tensor<?x?xf32>) -> tensor<?x?xf32>
    return %0 : tensor<?x?xf32>
  }
  func.func private @forward(%arg0: tensor<?x?xf32>) -> tensor<?x?xf32> attributes {torch.assume_strict_symbolic_shapes} {
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %cst = arith.constant 0.000000e+00 : f32
    %dim = tensor.dim %arg0, %c0 : tensor<?x?xf32>
    %dim_0 = tensor.dim %arg0, %c1 : tensor<?x?xf32>
    %0 = tensor.empty(%dim, %dim_0) : tensor<?x?xf32>
    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<?x?xf32>) -> tensor<?x?xf32>
    %2 = linalg.matmul ins(%arg0, %arg0 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%1 : tensor<?x?xf32>) -> tensor<?x?xf32>
    return %2 : tensor<?x?xf32>
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func private @forward(%arg0: tensor<?x?xf32>) -> tensor<?x?xf32> attributes {torch.assume_strict_symbolic_shapes} {
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %cst = arith.constant 0.000000e+00 : f32
  %dim = tensor.dim %arg0, %c0 : tensor<?x?xf32>
  %dim_0 = tensor.dim %arg0, %c1 : tensor<?x?xf32>
  %0 = tensor.empty(%dim, %dim_0) : tensor<?x?xf32>
  %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %2 = linalg.matmul ins(%arg0, %arg0 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%1 : tensor<?x?xf32>) -> tensor<?x?xf32>
  return %2 : tensor<?x?xf32>
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func private @_main(%arg0: tensor<?x?xf32>) -> tensor<?x?xf32> attributes {torch.args_schema = "[1, {\22type\22: \22builtins.tuple\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: \22builtins.list\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: null, \22context\22: null, \22children_spec\22: []}]}, {\22type\22: \22builtins.dict\22, \22context\22: \22[]\22, \22children_spec\22: []}]}]", torch.assume_strict_symbolic_shapes, torch.return_schema = "[1, {\22type\22: null, \22context\22: null, \22children_spec\22: []}]"} {
  %0 = call @forward(%arg0) : (tensor<?x?xf32>) -> tensor<?x?xf32>
  return %0 : tensor<?x?xf32>
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func private @_main(%arg0: tensor<?x?xf32>) -> tensor<?x?xf32> attributes {torch.args_schema = "[1, {\22type\22: \22builtins.tuple\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: \22builtins.list\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: null, \22context\22: null, \22children_spec\22: []}]}, {\22type\22: \22builtins.dict\22, \22context\22: \22[]\22, \22children_spec\22: []}]}]", torch.assume_strict_symbolic_shapes, torch.return_schema = "[1, {\22type\22: null, \22context\22: null, \22children_spec\22: []}]"} {
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %cst = arith.constant 0.000000e+00 : f32
  %dim = tensor.dim %arg0, %c0 : tensor<?x?xf32>
  %dim_0 = tensor.dim %arg0, %c1 : tensor<?x?xf32>
  %0 = tensor.empty(%dim, %dim_0) : tensor<?x?xf32>
  %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %2 = linalg.matmul ins(%arg0, %arg0 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%1 : tensor<?x?xf32>) -> tensor<?x?xf32>
  return %2 : tensor<?x?xf32>
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = call @_main(%2) : (tensor<?x?xf32>) -> tensor<?x?xf32>
  %dim = tensor.dim %3, %c0 : tensor<?x?xf32>
  %dim_0 = tensor.dim %3, %c1 : tensor<?x?xf32>
  %4 = hal.tensor.export %3 "output 0" : tensor<?x?xf32>{%dim, %dim_0} -> !hal.buffer_view
  return %4 : !hal.buffer_view
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = tensor.empty(%0, %1) : tensor<?x?xf32>
  %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %5 = linalg.matmul ins(%2, %2 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%4 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %6 = hal.tensor.export %5 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
  return %6 : !hal.buffer_view
}

// -----// IR Dump After Inliner (inline) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
    %3 = tensor.empty(%0, %1) : tensor<?x?xf32>
    %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<?x?xf32>) -> tensor<?x?xf32>
    %5 = linalg.matmul ins(%2, %2 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%4 : tensor<?x?xf32>) -> tensor<?x?xf32>
    %6 = hal.tensor.export %5 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
    return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = tensor.empty(%0, %1) : tensor<?x?xf32>
  %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %5 = linalg.matmul ins(%2, %2 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%4 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %6 = hal.tensor.export %5 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
  return %6 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = tensor.empty(%0, %1) : tensor<?x?xf32>
  %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %5 = linalg.matmul ins(%2, %2 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%4 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %6 = hal.tensor.export %5 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
  return %6 : !hal.buffer_view
}

// -----// IR Dump After SymbolDCE (symbol-dce) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
    %3 = tensor.empty(%0, %1) : tensor<?x?xf32>
    %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<?x?xf32>) -> tensor<?x?xf32>
    %5 = linalg.matmul ins(%2, %2 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%4 : tensor<?x?xf32>) -> tensor<?x?xf32>
    %6 = hal.tensor.export %5 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
    return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After DemoteF64ToF32 (iree-util-demote-f64-to-f32) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
    %3 = tensor.empty(%0, %1) : tensor<?x?xf32>
    %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<?x?xf32>) -> tensor<?x?xf32>
    %5 = linalg.matmul ins(%2, %2 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%4 : tensor<?x?xf32>) -> tensor<?x?xf32>
    %6 = hal.tensor.export %5 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
    return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After RemoveZeroExtentTensors (iree-global-opt-remove-zero-extent-tensors) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = tensor.empty(%0, %1) : tensor<?x?xf32>
  %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %5 = linalg.matmul ins(%2, %2 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%4 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %6 = hal.tensor.export %5 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
  return %6 : !hal.buffer_view
}

// -----// IR Dump After DetachElementwiseFromNamedOps (iree-global-opt-detach-elementwise-from-named-ops) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = tensor.empty(%0, %1) : tensor<?x?xf32>
  %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %5 = linalg.matmul ins(%2, %2 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%4 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %6 = hal.tensor.export %5 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
  return %6 : !hal.buffer_view
}

// -----// IR Dump After LinalgNamedOpConversion (linalg-named-op-conversion) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = tensor.empty(%0, %1) : tensor<?x?xf32>
  %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %5 = linalg.matmul ins(%2, %2 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%4 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %6 = hal.tensor.export %5 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
  return %6 : !hal.buffer_view
}

// -----// IR Dump After Convert1X1FilterConv2DToMatmul (iree-global-opt-convert-1x1-filter-conv2d-to-matmul) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = tensor.empty(%0, %1) : tensor<?x?xf32>
  %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %5 = linalg.matmul ins(%2, %2 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%4 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %6 = hal.tensor.export %5 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
  return %6 : !hal.buffer_view
}

// -----// IR Dump After EraseUnusedLinalgOperands (iree-global-opt-erase-unused-linalg-operands) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
    %3 = tensor.empty(%0, %1) : tensor<?x?xf32>
    %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<?x?xf32>) -> tensor<?x?xf32>
    %5 = linalg.matmul ins(%2, %2 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%4 : tensor<?x?xf32>) -> tensor<?x?xf32>
    %6 = hal.tensor.export %5 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
    return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After ExpandTensorShapes (iree-flow-expand-tensor-shapes) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
    %3 = tensor.empty(%0, %1) : tensor<?x?xf32>
    %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<?x?xf32>) -> tensor<?x?xf32>
    %5 = linalg.matmul ins(%2, %2 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%4 : tensor<?x?xf32>) -> tensor<?x?xf32>
    %6 = hal.tensor.export %5 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
    return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After ConvertElementwiseToLinalg (convert-elementwise-to-linalg) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = tensor.empty(%0, %1) : tensor<?x?xf32>
  %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %5 = linalg.matmul ins(%2, %2 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%4 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %6 = hal.tensor.export %5 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
  return %6 : !hal.buffer_view
}

// -----// IR Dump After GeneralizeLinalgNamedOps (iree-flow-generalize-linalg-named-ops) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = tensor.empty(%0, %1) : tensor<?x?xf32>
  %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %5 = linalg.matmul ins(%2, %2 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%4 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %6 = hal.tensor.export %5 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
  return %6 : !hal.buffer_view
}

// -----// IR Dump After RaiseSpecialOps (iree-flow-raise-special-ops) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = tensor.empty(%0, %1) : tensor<?x?xf32>
  %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %5 = linalg.matmul ins(%2, %2 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%4 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %6 = hal.tensor.export %5 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
  return %6 : !hal.buffer_view
}

// -----// IR Dump After FoldUnitExtentDims (iree-flow-fold-unit-extent-dims) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = tensor.empty(%0, %1) : tensor<?x?xf32>
  %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %5 = linalg.matmul ins(%2, %2 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%4 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %6 = hal.tensor.export %5 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
  return %6 : !hal.buffer_view
}

// -----// IR Dump After FuseDequantizationMatmul (iree-flow-fuse-dequantization-matmul) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = tensor.empty(%0, %1) : tensor<?x?xf32>
  %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %5 = linalg.matmul ins(%2, %2 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%4 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %6 = hal.tensor.export %5 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
  return %6 : !hal.buffer_view
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = tensor.empty(%0, %1) : tensor<?x?xf32>
  %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %5 = linalg.matmul ins(%2, %2 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%4 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %6 = hal.tensor.export %5 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
  return %6 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = tensor.empty(%0, %1) : tensor<?x?xf32>
  %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %5 = linalg.matmul ins(%2, %2 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%4 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %6 = hal.tensor.export %5 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
  return %6 : !hal.buffer_view
}

// -----// IR Dump After MaterializeHomogeneousEncodings (iree-global-opt-materialize-homogeneous-encodings) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
    %3 = tensor.empty(%0, %1) : tensor<?x?xf32>
    %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<?x?xf32>) -> tensor<?x?xf32>
    %5 = linalg.matmul ins(%2, %2 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%4 : tensor<?x?xf32>) -> tensor<?x?xf32>
    %6 = hal.tensor.export %5 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
    return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = tensor.empty(%0, %1) : tensor<?x?xf32>
  %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %5 = linalg.matmul ins(%2, %2 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%4 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %6 = hal.tensor.export %5 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
  return %6 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda], iree.fixedpoint.iteration = 0 : index} {
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
    %3 = tensor.empty(%0, %1) : tensor<?x?xf32>
    %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<?x?xf32>) -> tensor<?x?xf32>
    %5 = linalg.matmul ins(%2, %2 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%4 : tensor<?x?xf32>) -> tensor<?x?xf32>
    %6 = hal.tensor.export %5 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
    return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda], iree.fixedpoint.iteration = 0 : index} {
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
    %3 = tensor.empty(%0, %1) : tensor<?x?xf32>
    %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<?x?xf32>) -> tensor<?x?xf32>
    %5 = linalg.matmul ins(%2, %2 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%4 : tensor<?x?xf32>) -> tensor<?x?xf32>
    %6 = hal.tensor.export %5 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
    return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda], iree.fixedpoint.iteration = 0 : index} {
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
    %3 = tensor.empty(%0, %1) : tensor<?x?xf32>
    %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<?x?xf32>) -> tensor<?x?xf32>
    %5 = linalg.matmul ins(%2, %2 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%4 : tensor<?x?xf32>) -> tensor<?x?xf32>
    %6 = hal.tensor.export %5 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
    return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After HoistIntoGlobals (iree-util-hoist-into-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda], iree.fixedpoint.iteration = 0 : index} {
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
    %3 = tensor.empty(%0, %1) : tensor<?x?xf32>
    %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<?x?xf32>) -> tensor<?x?xf32>
    %5 = linalg.matmul ins(%2, %2 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%4 : tensor<?x?xf32>) -> tensor<?x?xf32>
    %6 = hal.tensor.export %5 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
    return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After JitGlobals (iree-consteval-jit-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda], iree.fixedpoint.iteration = 0 : index} {
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
    %3 = tensor.empty(%0, %1) : tensor<?x?xf32>
    %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<?x?xf32>) -> tensor<?x?xf32>
    %5 = linalg.matmul ins(%2, %2 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%4 : tensor<?x?xf32>) -> tensor<?x?xf32>
    %6 = hal.tensor.export %5 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
    return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = tensor.empty(%0, %1) : tensor<?x?xf32>
  %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %5 = linalg.matmul ins(%2, %2 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%4 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %6 = hal.tensor.export %5 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
  return %6 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = tensor.empty(%0, %1) : tensor<?x?xf32>
  %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %5 = linalg.matmul ins(%2, %2 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%4 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %6 = hal.tensor.export %5 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
  return %6 : !hal.buffer_view
}

// -----// IR Dump After FixedPointIterator (iree-util-fixed-point-iterator) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
    %3 = tensor.empty(%0, %1) : tensor<?x?xf32>
    %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<?x?xf32>) -> tensor<?x?xf32>
    %5 = linalg.matmul ins(%2, %2 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%4 : tensor<?x?xf32>) -> tensor<?x?xf32>
    %6 = hal.tensor.export %5 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
    return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After VerifyInputLegality (iree-verify-input-legality) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
    %3 = tensor.empty(%0, %1) : tensor<?x?xf32>
    %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<?x?xf32>) -> tensor<?x?xf32>
    %5 = linalg.matmul ins(%2, %2 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%4 : tensor<?x?xf32>) -> tensor<?x?xf32>
    %6 = hal.tensor.export %5 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
    return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After TensorPadToTensorInsertSlice (iree-flow-tensor-pad-to-tensor-insert-slice) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
    %3 = tensor.empty(%0, %1) : tensor<?x?xf32>
    %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<?x?xf32>) -> tensor<?x?xf32>
    %5 = linalg.matmul ins(%2, %2 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%4 : tensor<?x?xf32>) -> tensor<?x?xf32>
    %6 = hal.tensor.export %5 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
    return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After RaiseSpecialOps (iree-flow-raise-special-ops) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = tensor.empty(%0, %1) : tensor<?x?xf32>
  %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %5 = linalg.matmul ins(%2, %2 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%4 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %6 = hal.tensor.export %5 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
  return %6 : !hal.buffer_view
}

// -----// IR Dump After InterchangeGenericOps (iree-flow-interchange-generic-ops) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = tensor.empty(%0, %1) : tensor<?x?xf32>
  %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %5 = linalg.matmul ins(%2, %2 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%4 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %6 = hal.tensor.export %5 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
  return %6 : !hal.buffer_view
}

// -----// IR Dump After CollapseDims (iree-flow-collapse-dims) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = tensor.empty(%0, %1) : tensor<?x?xf32>
  %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %5 = linalg.matmul ins(%2, %2 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%4 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %6 = hal.tensor.export %5 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
  return %6 : !hal.buffer_view
}

// -----// IR Dump After ResolveShapedTypeResultDims (resolve-shaped-type-result-dims) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = tensor.empty(%0, %1) : tensor<?x?xf32>
  %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %5 = linalg.matmul ins(%2, %2 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%4 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %6 = hal.tensor.export %5 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
  return %6 : !hal.buffer_view
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = tensor.empty(%0, %1) : tensor<?x?xf32>
  %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %5 = linalg.matmul ins(%2, %2 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%4 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %6 = hal.tensor.export %5 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
  return %6 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = tensor.empty(%0, %1) : tensor<?x?xf32>
  %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %5 = linalg.matmul ins(%2, %2 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%4 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %6 = hal.tensor.export %5 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
  return %6 : !hal.buffer_view
}

// -----// IR Dump After FusionOfTensorOps (iree-flow-fusion-of-tensor-ops) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = tensor.empty(%0, %1) : tensor<?x?xf32>
  %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %5 = linalg.matmul ins(%2, %2 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%4 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %6 = hal.tensor.export %5 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
  return %6 : !hal.buffer_view
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = tensor.empty(%0, %1) : tensor<?x?xf32>
  %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %5 = linalg.matmul ins(%2, %2 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%4 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %6 = hal.tensor.export %5 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
  return %6 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = tensor.empty(%0, %1) : tensor<?x?xf32>
  %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %5 = linalg.matmul ins(%2, %2 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%4 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %6 = hal.tensor.export %5 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
  return %6 : !hal.buffer_view
}

// -----// IR Dump After SplitReduction (iree-flow-split-reduction-ops) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = tensor.empty(%0, %1) : tensor<?x?xf32>
  %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %5 = linalg.matmul ins(%2, %2 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%4 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %6 = hal.tensor.export %5 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
  return %6 : !hal.buffer_view
}

// -----// IR Dump After InterchangeGenericOps (iree-flow-interchange-generic-ops) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = tensor.empty(%0, %1) : tensor<?x?xf32>
  %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %5 = linalg.matmul ins(%2, %2 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%4 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %6 = hal.tensor.export %5 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
  return %6 : !hal.buffer_view
}

// -----// IR Dump After FormScalarDispatches (iree-flow-form-scalar-dispatches) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = tensor.empty(%0, %1) : tensor<?x?xf32>
  %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %5 = linalg.matmul ins(%2, %2 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%4 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %6 = hal.tensor.export %5 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
  return %6 : !hal.buffer_view
}

// -----// IR Dump After FormDispatchRegions (iree-flow-form-dispatch-regions) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = tensor.empty(%0, %1) : tensor<?x?xf32>
  %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %5 = flow.dispatch.region -> (tensor<?x?xf32>{%0, %1}) {
    %7 = linalg.matmul ins(%2, %2 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%4 : tensor<?x?xf32>) -> tensor<?x?xf32>
    flow.return %7 : tensor<?x?xf32>
  }
  %6 = hal.tensor.export %5 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
  return %6 : !hal.buffer_view
}

// -----// IR Dump After CollapseDimensions (iree-flow-collapse-dimensions) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = tensor.empty(%0, %1) : tensor<?x?xf32>
  %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %5 = flow.dispatch.region -> (tensor<?x?xf32>{%0, %1}) {
    %7 = linalg.matmul ins(%2, %2 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%4 : tensor<?x?xf32>) -> tensor<?x?xf32>
    flow.return %7 : tensor<?x?xf32>
  }
  %6 = hal.tensor.export %5 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
  return %6 : !hal.buffer_view
}

// -----// IR Dump After CloneProducersIntoDispatchRegions (iree-flow-clone-producers-into-dispatch-regions) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = tensor.empty(%0, %1) : tensor<?x?xf32>
  %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %5 = flow.dispatch.region -> (tensor<?x?xf32>{%0, %1}) {
    %7 = tensor.empty(%0, %1) : tensor<?x?xf32>
    %cst_0 = arith.constant 0.000000e+00 : f32
    %8 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor<?x?xf32>) -> tensor<?x?xf32>
    %9 = linalg.matmul ins(%2, %2 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%8 : tensor<?x?xf32>) -> tensor<?x?xf32>
    flow.return %9 : tensor<?x?xf32>
  }
  %6 = hal.tensor.export %5 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
  return %6 : !hal.buffer_view
}

// -----// IR Dump After FormDispatchWorkgroups (iree-flow-form-dispatch-workgroups) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = flow.dispatch.workgroups[%0, %1](%2, %0, %1) : (tensor<?x?xf32>{%0, %1}, index, index) -> tensor<?x?xf32>{%0, %1} =
      (%arg1: !flow.dispatch.tensor<readonly:tensor<?x?xf32>>, %arg2: index, %arg3: index, %arg4: !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>) {
    %5 = flow.dispatch.workload.ordinal %arg2, 0 : index
    %6 = flow.dispatch.workload.ordinal %arg3, 1 : index
    %cst = arith.constant 0.000000e+00 : f32
    %7 = flow.dispatch.tensor.load %arg1, offsets = [0, 0], sizes = [%5, %6], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%5, %6} -> tensor<?x?xf32>
    %8 = tensor.empty(%5, %6) : tensor<?x?xf32>
    %9 = linalg.fill ins(%cst : f32) outs(%8 : tensor<?x?xf32>) -> tensor<?x?xf32>
    %10 = linalg.matmul ins(%7, %7 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%9 : tensor<?x?xf32>) -> tensor<?x?xf32>
    flow.dispatch.tensor.store %10, %arg4, offsets = [0, 0], sizes = [%5, %6], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%5, %6}
    flow.return
  } count(%arg1: index, %arg2: index) -> (index, index, index) {
    %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg1, %arg2
    flow.return %x, %y, %z : index, index, index
  }
  %4 = hal.tensor.export %3 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
  return %4 : !hal.buffer_view
}

// -----// IR Dump After CaptureDispatchDynamicDims (iree-flow-capture-dispatch-dynamic-dims) //----- // //完成了动态维度的捕获，将动态矩阵绑定到传入的参数上
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = flow.dispatch.workgroups[%0, %1](%2, %0, %1) : (tensor<?x?xf32>{%0, %1}, index, index) -> tensor<?x?xf32>{%0, %1} =
      (%arg1: !flow.dispatch.tensor<readonly:tensor<?x?xf32>>, %arg2: index, %arg3: index, %arg4: !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>) {
    %5 = flow.dispatch.tie_shape %arg1 : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg2, %arg3}
    %6 = flow.dispatch.tie_shape %arg4 : !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%arg2, %arg3}
    %7 = flow.dispatch.workload.ordinal %arg2, 0 : index
    %8 = flow.dispatch.workload.ordinal %arg3, 1 : index
    %cst = arith.constant 0.000000e+00 : f32
    %9 = flow.dispatch.tensor.load %5, offsets = [0, 0], sizes = [%7, %8], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%7, %8} -> tensor<?x?xf32>
    %10 = tensor.empty(%7, %8) : tensor<?x?xf32>
    %11 = linalg.fill ins(%cst : f32) outs(%10 : tensor<?x?xf32>) -> tensor<?x?xf32>
    %12 = linalg.matmul ins(%9, %9 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%11 : tensor<?x?xf32>) -> tensor<?x?xf32>
    flow.dispatch.tensor.store %12, %6, offsets = [0, 0], sizes = [%7, %8], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%7, %8}
    flow.return
  } count(%arg1: index, %arg2: index) -> (index, index, index) {
    %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg1, %arg2
    flow.return %x, %y, %z : index, index, index
  }
  %4 = hal.tensor.export %3 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
  return %4 : !hal.buffer_view
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = flow.dispatch.workgroups[%0, %1](%2, %0, %1) : (tensor<?x?xf32>{%0, %1}, index, index) -> tensor<?x?xf32>{%0, %1} =
      (%arg1: !flow.dispatch.tensor<readonly:tensor<?x?xf32>>, %arg2: index, %arg3: index, %arg4: !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>) {
    %cst = arith.constant 0.000000e+00 : f32
    %5 = flow.dispatch.workload.ordinal %arg2, 0 : index
    %6 = flow.dispatch.workload.ordinal %arg3, 1 : index
    %7 = flow.dispatch.tie_shape %arg1 : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%5, %6}
    %8 = flow.dispatch.tie_shape %arg4 : !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%5, %6}
    %9 = flow.dispatch.tensor.load %7, offsets = [0, 0], sizes = [%5, %6], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%5, %6} -> tensor<?x?xf32>
    %10 = tensor.empty(%5, %6) : tensor<?x?xf32>
    %11 = linalg.fill ins(%cst : f32) outs(%10 : tensor<?x?xf32>) -> tensor<?x?xf32>
    %12 = linalg.matmul ins(%9, %9 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%11 : tensor<?x?xf32>) -> tensor<?x?xf32>
    flow.dispatch.tensor.store %12, %8, offsets = [0, 0], sizes = [%5, %6], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%5, %6}
    flow.return
  } count(%arg1: index, %arg2: index) -> (index, index, index) {
    %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg1, %arg2
    flow.return %x, %y, %z : index, index, index
  }
  %4 = hal.tensor.export %3 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
  return %4 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = flow.dispatch.workgroups[%0, %1](%2, %0, %1) : (tensor<?x?xf32>{%0, %1}, index, index) -> tensor<?x?xf32>{%0, %1} =
      (%arg1: !flow.dispatch.tensor<readonly:tensor<?x?xf32>>, %arg2: index, %arg3: index, %arg4: !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>) {
    %cst = arith.constant 0.000000e+00 : f32
    %5 = flow.dispatch.workload.ordinal %arg2, 0 : index
    %6 = flow.dispatch.workload.ordinal %arg3, 1 : index
    %7 = flow.dispatch.tie_shape %arg1 : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%5, %6}
    %8 = flow.dispatch.tie_shape %arg4 : !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%5, %6}
    %9 = flow.dispatch.tensor.load %7, offsets = [0, 0], sizes = [%5, %6], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%5, %6} -> tensor<?x?xf32>
    %10 = tensor.empty(%5, %6) : tensor<?x?xf32>
    %11 = linalg.fill ins(%cst : f32) outs(%10 : tensor<?x?xf32>) -> tensor<?x?xf32>
    %12 = linalg.matmul ins(%9, %9 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%11 : tensor<?x?xf32>) -> tensor<?x?xf32>
    flow.dispatch.tensor.store %12, %8, offsets = [0, 0], sizes = [%5, %6], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%5, %6}
    flow.return
  } count(%arg1: index, %arg2: index) -> (index, index, index) {
    %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg1, %arg2
    flow.return %x, %y, %z : index, index, index
  }
  %4 = hal.tensor.export %3 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
  return %4 : !hal.buffer_view
}

// -----// IR Dump After InitializeEmptyTensors (iree-flow-initialize-empty-tensors) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = flow.dispatch.workgroups[%0, %1](%2, %0, %1) : (tensor<?x?xf32>{%0, %1}, index, index) -> tensor<?x?xf32>{%0, %1} =
      (%arg1: !flow.dispatch.tensor<readonly:tensor<?x?xf32>>, %arg2: index, %arg3: index, %arg4: !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>) {
    %cst = arith.constant 0.000000e+00 : f32
    %5 = flow.dispatch.workload.ordinal %arg2, 0 : index
    %6 = flow.dispatch.workload.ordinal %arg3, 1 : index
    %7 = flow.dispatch.tie_shape %arg1 : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%5, %6}
    %8 = flow.dispatch.tie_shape %arg4 : !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%5, %6}
    %9 = flow.dispatch.tensor.load %7, offsets = [0, 0], sizes = [%5, %6], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%5, %6} -> tensor<?x?xf32>
    %10 = tensor.empty(%5, %6) : tensor<?x?xf32>
    %11 = linalg.fill ins(%cst : f32) outs(%10 : tensor<?x?xf32>) -> tensor<?x?xf32>
    %12 = linalg.matmul ins(%9, %9 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%11 : tensor<?x?xf32>) -> tensor<?x?xf32>
    flow.dispatch.tensor.store %12, %8, offsets = [0, 0], sizes = [%5, %6], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%5, %6}
    flow.return
  } count(%arg1: index, %arg2: index) -> (index, index, index) {
    %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg1, %arg2
    flow.return %x, %y, %z : index, index, index
  }
  %4 = hal.tensor.export %3 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
  return %4 : !hal.buffer_view
}

// -----// IR Dump After OutlineDispatchRegions (iree-flow-outline-dispatch-regions) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  flow.executable private @main_dispatch_0 {
    flow.executable.export public @main_dispatch_0 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0(%arg0: !flow.dispatch.tensor<readonly:tensor<?x?xf32>>, %arg1: index, %arg2: index, %arg3: !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>) {
        %cst = arith.constant 0.000000e+00 : f32
        %0 = flow.dispatch.workload.ordinal %arg1, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg2, 1 : index
        %2 = flow.dispatch.tie_shape %arg0 : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1}
        %3 = flow.dispatch.tie_shape %arg3 : !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        %4 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1} -> tensor<?x?xf32>
        %5 = tensor.empty(%0, %1) : tensor<?x?xf32>
        %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<?x?xf32>) -> tensor<?x?xf32>
        %7 = linalg.matmul ins(%4, %4 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%6 : tensor<?x?xf32>) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %7, %3, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
    %3 = flow.dispatch @main_dispatch_0::@main_dispatch_0[%0, %1](%2, %0, %1) : (tensor<?x?xf32>{%0, %1}, index, index) -> tensor<?x?xf32>{%0, %1}
    %4 = hal.tensor.export %3 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
    return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After AnnotateDispatches (iree-flow-annotate-dispatches) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  flow.executable private @main_dispatch_0 {
    flow.executable.export public @main_dispatch_0_matmul_DxDxD_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !flow.dispatch.tensor<readonly:tensor<?x?xf32>>, %arg1: index, %arg2: index, %arg3: !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>) {
        %cst = arith.constant 0.000000e+00 : f32
        %0 = flow.dispatch.workload.ordinal %arg1, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg2, 1 : index
        %2 = flow.dispatch.tie_shape %arg0 : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1}
        %3 = flow.dispatch.tie_shape %arg3 : !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        %4 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1} -> tensor<?x?xf32>
        %5 = tensor.empty(%0, %1) : tensor<?x?xf32>
        %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<?x?xf32>) -> tensor<?x?xf32>
        %7 = linalg.matmul ins(%4, %4 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%6 : tensor<?x?xf32>) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %7, %3, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
    %3 = flow.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%2, %0, %1) : (tensor<?x?xf32>{%0, %1}, index, index) -> tensor<?x?xf32>{%0, %1}
    %4 = hal.tensor.export %3 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
    return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After StripDebugOps (iree-util-strip-debug-ops) //----- //
flow.executable private @main_dispatch_0 {
  flow.executable.export public @main_dispatch_0_matmul_DxDxD_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
    %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
    flow.return %x, %y, %z : index, index, index
  }
  builtin.module {
    func.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !flow.dispatch.tensor<readonly:tensor<?x?xf32>>, %arg1: index, %arg2: index, %arg3: !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>) {
      %cst = arith.constant 0.000000e+00 : f32
      %0 = flow.dispatch.workload.ordinal %arg1, 0 : index
      %1 = flow.dispatch.workload.ordinal %arg2, 1 : index
      %2 = flow.dispatch.tie_shape %arg0 : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1}
      %3 = flow.dispatch.tie_shape %arg3 : !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
      %4 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1} -> tensor<?x?xf32>
      %5 = tensor.empty(%0, %1) : tensor<?x?xf32>
      %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<?x?xf32>) -> tensor<?x?xf32>
      %7 = linalg.matmul ins(%4, %4 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%6 : tensor<?x?xf32>) -> tensor<?x?xf32>
      flow.dispatch.tensor.store %7, %3, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
      return
    }
  }
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = flow.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%2, %0, %1) : (tensor<?x?xf32>{%0, %1}, index, index) -> tensor<?x?xf32>{%0, %1}
  %4 = hal.tensor.export %3 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
  return %4 : !hal.buffer_view
}

// -----// IR Dump After DeduplicateExecutables (iree-flow-deduplicate-executables) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  flow.executable private @main_dispatch_0 {
    flow.executable.export public @main_dispatch_0_matmul_DxDxD_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !flow.dispatch.tensor<readonly:tensor<?x?xf32>>, %arg1: index, %arg2: index, %arg3: !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>) {
        %cst = arith.constant 0.000000e+00 : f32
        %0 = flow.dispatch.workload.ordinal %arg1, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg2, 1 : index
        %2 = flow.dispatch.tie_shape %arg0 : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1}
        %3 = flow.dispatch.tie_shape %arg3 : !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        %4 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1} -> tensor<?x?xf32>
        %5 = tensor.empty(%0, %1) : tensor<?x?xf32>
        %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<?x?xf32>) -> tensor<?x?xf32>
        %7 = linalg.matmul ins(%4, %4 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%6 : tensor<?x?xf32>) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %7, %3, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
    %3 = flow.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%2, %0, %1) : (tensor<?x?xf32>{%0, %1}, index, index) -> tensor<?x?xf32>{%0, %1}
    %4 = hal.tensor.export %3 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
    return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After CleanupTensorShapes (iree-flow-cleanup-tensor-shapes) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = flow.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%2, %0, %1) : (tensor<?x?xf32>{%0, %1}, index, index) -> tensor<?x?xf32>{%0, %1}
  %4 = hal.tensor.export %3 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
  return %4 : !hal.buffer_view
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
flow.executable private @main_dispatch_0 {
  flow.executable.export public @main_dispatch_0_matmul_DxDxD_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
    %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
    flow.return %x, %y, %z : index, index, index
  }
  builtin.module {
    func.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !flow.dispatch.tensor<readonly:tensor<?x?xf32>>, %arg1: index, %arg2: index, %arg3: !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>) {
      %cst = arith.constant 0.000000e+00 : f32
      %0 = flow.dispatch.workload.ordinal %arg1, 0 : index
      %1 = flow.dispatch.workload.ordinal %arg2, 1 : index
      %2 = flow.dispatch.tie_shape %arg0 : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1}
      %3 = flow.dispatch.tie_shape %arg3 : !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
      %4 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1} -> tensor<?x?xf32>
      %5 = tensor.empty(%0, %1) : tensor<?x?xf32>
      %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<?x?xf32>) -> tensor<?x?xf32>
      %7 = linalg.matmul ins(%4, %4 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%6 : tensor<?x?xf32>) -> tensor<?x?xf32>
      flow.dispatch.tensor.store %7, %3, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
      return
    }
  }
}

// -----// IR Dump After CSE (cse) //----- //
flow.executable private @main_dispatch_0 {
  flow.executable.export public @main_dispatch_0_matmul_DxDxD_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
    %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
    flow.return %x, %y, %z : index, index, index
  }
  builtin.module {
    func.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !flow.dispatch.tensor<readonly:tensor<?x?xf32>>, %arg1: index, %arg2: index, %arg3: !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>) {
      %cst = arith.constant 0.000000e+00 : f32
      %0 = flow.dispatch.workload.ordinal %arg1, 0 : index
      %1 = flow.dispatch.workload.ordinal %arg2, 1 : index
      %2 = flow.dispatch.tie_shape %arg0 : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1}
      %3 = flow.dispatch.tie_shape %arg3 : !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
      %4 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1} -> tensor<?x?xf32>
      %5 = tensor.empty(%0, %1) : tensor<?x?xf32>
      %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<?x?xf32>) -> tensor<?x?xf32>
      %7 = linalg.matmul ins(%4, %4 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%6 : tensor<?x?xf32>) -> tensor<?x?xf32>
      flow.dispatch.tensor.store %7, %3, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
      return
    }
  }
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = flow.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%2, %0, %1) : (tensor<?x?xf32>{%0, %1}, index, index) -> tensor<?x?xf32>{%0, %1}
  %4 = hal.tensor.export %3 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
  return %4 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = flow.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%2, %0, %1) : (tensor<?x?xf32>{%0, %1}, index, index) -> tensor<?x?xf32>{%0, %1}
  %4 = hal.tensor.export %3 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
  return %4 : !hal.buffer_view
}

// -----// IR Dump After SymbolDCE (symbol-dce) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  flow.executable private @main_dispatch_0 {
    flow.executable.export public @main_dispatch_0_matmul_DxDxD_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !flow.dispatch.tensor<readonly:tensor<?x?xf32>>, %arg1: index, %arg2: index, %arg3: !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>) {
        %cst = arith.constant 0.000000e+00 : f32
        %0 = flow.dispatch.workload.ordinal %arg1, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg2, 1 : index
        %2 = flow.dispatch.tie_shape %arg0 : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1}
        %3 = flow.dispatch.tie_shape %arg3 : !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        %4 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1} -> tensor<?x?xf32>
        %5 = tensor.empty(%0, %1) : tensor<?x?xf32>
        %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<?x?xf32>) -> tensor<?x?xf32>
        %7 = linalg.matmul ins(%4, %4 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%6 : tensor<?x?xf32>) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %7, %3, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
    %3 = flow.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%2, %0, %1) : (tensor<?x?xf32>{%0, %1}, index, index) -> tensor<?x?xf32>{%0, %1}
    %4 = hal.tensor.export %3 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
    return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After VerifyInput (iree-stream-verify-input) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  flow.executable private @main_dispatch_0 {
    flow.executable.export public @main_dispatch_0_matmul_DxDxD_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !flow.dispatch.tensor<readonly:tensor<?x?xf32>>, %arg1: index, %arg2: index, %arg3: !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>) {
        %cst = arith.constant 0.000000e+00 : f32
        %0 = flow.dispatch.workload.ordinal %arg1, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg2, 1 : index
        %2 = flow.dispatch.tie_shape %arg0 : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1}
        %3 = flow.dispatch.tie_shape %arg3 : !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        %4 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1} -> tensor<?x?xf32>
        %5 = tensor.empty(%0, %1) : tensor<?x?xf32>
        %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<?x?xf32>) -> tensor<?x?xf32>
        %7 = linalg.matmul ins(%4, %4 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%6 : tensor<?x?xf32>) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %7, %3, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
    %3 = flow.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%2, %0, %1) : (tensor<?x?xf32>{%0, %1}, index, index) -> tensor<?x?xf32>{%0, %1}
    %4 = hal.tensor.export %3 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
    return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = flow.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%2, %0, %1) : (tensor<?x?xf32>{%0, %1}, index, index) -> tensor<?x?xf32>{%0, %1}
  %4 = hal.tensor.export %3 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
  return %4 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = flow.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%2, %0, %1) : (tensor<?x?xf32>{%0, %1}, index, index) -> tensor<?x?xf32>{%0, %1}
  %4 = hal.tensor.export %3 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
  return %4 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = flow.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%2, %0, %1) : (tensor<?x?xf32>{%0, %1}, index, index) -> tensor<?x?xf32>{%0, %1}
  %4 = hal.tensor.export %3 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
  return %4 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  flow.executable private @main_dispatch_0 {
    flow.executable.export public @main_dispatch_0_matmul_DxDxD_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !flow.dispatch.tensor<readonly:tensor<?x?xf32>>, %arg1: index, %arg2: index, %arg3: !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>) {
        %cst = arith.constant 0.000000e+00 : f32
        %0 = flow.dispatch.workload.ordinal %arg1, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg2, 1 : index
        %2 = flow.dispatch.tie_shape %arg0 : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1}
        %3 = flow.dispatch.tie_shape %arg3 : !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        %4 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1} -> tensor<?x?xf32>
        %5 = tensor.empty(%0, %1) : tensor<?x?xf32>
        %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<?x?xf32>) -> tensor<?x?xf32>
        %7 = linalg.matmul ins(%4, %4 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%6 : tensor<?x?xf32>) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %7, %3, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
    %3 = flow.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%2, %0, %1) : (tensor<?x?xf32>{%0, %1}, index, index) -> tensor<?x?xf32>{%0, %1}
    %4 = hal.tensor.export %3 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
    return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  flow.executable private @main_dispatch_0 {
    flow.executable.export public @main_dispatch_0_matmul_DxDxD_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !flow.dispatch.tensor<readonly:tensor<?x?xf32>>, %arg1: index, %arg2: index, %arg3: !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>) {
        %cst = arith.constant 0.000000e+00 : f32
        %0 = flow.dispatch.workload.ordinal %arg1, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg2, 1 : index
        %2 = flow.dispatch.tie_shape %arg0 : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1}
        %3 = flow.dispatch.tie_shape %arg3 : !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        %4 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1} -> tensor<?x?xf32>
        %5 = tensor.empty(%0, %1) : tensor<?x?xf32>
        %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<?x?xf32>) -> tensor<?x?xf32>
        %7 = linalg.matmul ins(%4, %4 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%6 : tensor<?x?xf32>) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %7, %3, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
    %3 = flow.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%2, %0, %1) : (tensor<?x?xf32>{%0, %1}, index, index) -> tensor<?x?xf32>{%0, %1}
    %4 = hal.tensor.export %3 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
    return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  flow.executable private @main_dispatch_0 {
    flow.executable.export public @main_dispatch_0_matmul_DxDxD_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !flow.dispatch.tensor<readonly:tensor<?x?xf32>>, %arg1: index, %arg2: index, %arg3: !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>) {
        %cst = arith.constant 0.000000e+00 : f32
        %0 = flow.dispatch.workload.ordinal %arg1, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg2, 1 : index
        %2 = flow.dispatch.tie_shape %arg0 : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1}
        %3 = flow.dispatch.tie_shape %arg3 : !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        %4 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1} -> tensor<?x?xf32>
        %5 = tensor.empty(%0, %1) : tensor<?x?xf32>
        %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<?x?xf32>) -> tensor<?x?xf32>
        %7 = linalg.matmul ins(%4, %4 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%6 : tensor<?x?xf32>) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %7, %3, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
    %3 = flow.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%2, %0, %1) : (tensor<?x?xf32>{%0, %1}, index, index) -> tensor<?x?xf32>{%0, %1}
    %4 = hal.tensor.export %3 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
    return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  flow.executable private @main_dispatch_0 {
    flow.executable.export public @main_dispatch_0_matmul_DxDxD_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !flow.dispatch.tensor<readonly:tensor<?x?xf32>>, %arg1: index, %arg2: index, %arg3: !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>) {
        %cst = arith.constant 0.000000e+00 : f32
        %0 = flow.dispatch.workload.ordinal %arg1, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg2, 1 : index
        %2 = flow.dispatch.tie_shape %arg0 : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1}
        %3 = flow.dispatch.tie_shape %arg3 : !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        %4 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1} -> tensor<?x?xf32>
        %5 = tensor.empty(%0, %1) : tensor<?x?xf32>
        %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<?x?xf32>) -> tensor<?x?xf32>
        %7 = linalg.matmul ins(%4, %4 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%6 : tensor<?x?xf32>) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %7, %3, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
    %3 = flow.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%2, %0, %1) : (tensor<?x?xf32>{%0, %1}, index, index) -> tensor<?x?xf32>{%0, %1}
    %4 = hal.tensor.export %3 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
    return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After OutlineConstants (iree-util-outline-constants) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  flow.executable private @main_dispatch_0 {
    flow.executable.export public @main_dispatch_0_matmul_DxDxD_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !flow.dispatch.tensor<readonly:tensor<?x?xf32>>, %arg1: index, %arg2: index, %arg3: !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>) {
        %cst = arith.constant 0.000000e+00 : f32
        %0 = flow.dispatch.workload.ordinal %arg1, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg2, 1 : index
        %2 = flow.dispatch.tie_shape %arg0 : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1}
        %3 = flow.dispatch.tie_shape %arg3 : !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        %4 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1} -> tensor<?x?xf32>
        %5 = tensor.empty(%0, %1) : tensor<?x?xf32>
        %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<?x?xf32>) -> tensor<?x?xf32>
        %7 = linalg.matmul ins(%4, %4 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%6 : tensor<?x?xf32>) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %7, %3, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
    %3 = flow.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%2, %0, %1) : (tensor<?x?xf32>{%0, %1}, index, index) -> tensor<?x?xf32>{%0, %1}
    %4 = hal.tensor.export %3 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
    return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = flow.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%2, %0, %1) : (tensor<?x?xf32>{%0, %1}, index, index) -> tensor<?x?xf32>{%0, %1}
  %4 = hal.tensor.export %3 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
  return %4 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = flow.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%2, %0, %1) : (tensor<?x?xf32>{%0, %1}, index, index) -> tensor<?x?xf32>{%0, %1}
  %4 = hal.tensor.export %3 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
  return %4 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = flow.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%2, %0, %1) : (tensor<?x?xf32>{%0, %1}, index, index) -> tensor<?x?xf32>{%0, %1}
  %4 = hal.tensor.export %3 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
  return %4 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  flow.executable private @main_dispatch_0 {
    flow.executable.export public @main_dispatch_0_matmul_DxDxD_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !flow.dispatch.tensor<readonly:tensor<?x?xf32>>, %arg1: index, %arg2: index, %arg3: !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>) {
        %cst = arith.constant 0.000000e+00 : f32
        %0 = flow.dispatch.workload.ordinal %arg1, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg2, 1 : index
        %2 = flow.dispatch.tie_shape %arg0 : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1}
        %3 = flow.dispatch.tie_shape %arg3 : !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        %4 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1} -> tensor<?x?xf32>
        %5 = tensor.empty(%0, %1) : tensor<?x?xf32>
        %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<?x?xf32>) -> tensor<?x?xf32>
        %7 = linalg.matmul ins(%4, %4 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%6 : tensor<?x?xf32>) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %7, %3, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
    %3 = flow.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%2, %0, %1) : (tensor<?x?xf32>{%0, %1}, index, index) -> tensor<?x?xf32>{%0, %1}
    %4 = hal.tensor.export %3 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
    return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  flow.executable private @main_dispatch_0 {
    flow.executable.export public @main_dispatch_0_matmul_DxDxD_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !flow.dispatch.tensor<readonly:tensor<?x?xf32>>, %arg1: index, %arg2: index, %arg3: !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>) {
        %cst = arith.constant 0.000000e+00 : f32
        %0 = flow.dispatch.workload.ordinal %arg1, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg2, 1 : index
        %2 = flow.dispatch.tie_shape %arg0 : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1}
        %3 = flow.dispatch.tie_shape %arg3 : !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        %4 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1} -> tensor<?x?xf32>
        %5 = tensor.empty(%0, %1) : tensor<?x?xf32>
        %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<?x?xf32>) -> tensor<?x?xf32>
        %7 = linalg.matmul ins(%4, %4 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%6 : tensor<?x?xf32>) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %7, %3, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
    %3 = flow.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%2, %0, %1) : (tensor<?x?xf32>{%0, %1}, index, index) -> tensor<?x?xf32>{%0, %1}
    %4 = hal.tensor.export %3 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
    return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  flow.executable private @main_dispatch_0 {
    flow.executable.export public @main_dispatch_0_matmul_DxDxD_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !flow.dispatch.tensor<readonly:tensor<?x?xf32>>, %arg1: index, %arg2: index, %arg3: !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>) {
        %cst = arith.constant 0.000000e+00 : f32
        %0 = flow.dispatch.workload.ordinal %arg1, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg2, 1 : index
        %2 = flow.dispatch.tie_shape %arg0 : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1}
        %3 = flow.dispatch.tie_shape %arg3 : !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        %4 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1} -> tensor<?x?xf32>
        %5 = tensor.empty(%0, %1) : tensor<?x?xf32>
        %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<?x?xf32>) -> tensor<?x?xf32>
        %7 = linalg.matmul ins(%4, %4 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%6 : tensor<?x?xf32>) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %7, %3, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
    %3 = flow.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%2, %0, %1) : (tensor<?x?xf32>{%0, %1}, index, index) -> tensor<?x?xf32>{%0, %1}
    %4 = hal.tensor.export %3 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
    return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  flow.executable private @main_dispatch_0 {
    flow.executable.export public @main_dispatch_0_matmul_DxDxD_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !flow.dispatch.tensor<readonly:tensor<?x?xf32>>, %arg1: index, %arg2: index, %arg3: !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>) {
        %cst = arith.constant 0.000000e+00 : f32
        %0 = flow.dispatch.workload.ordinal %arg1, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg2, 1 : index
        %2 = flow.dispatch.tie_shape %arg0 : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1}
        %3 = flow.dispatch.tie_shape %arg3 : !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        %4 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1} -> tensor<?x?xf32>
        %5 = tensor.empty(%0, %1) : tensor<?x?xf32>
        %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<?x?xf32>) -> tensor<?x?xf32>
        %7 = linalg.matmul ins(%4, %4 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%6 : tensor<?x?xf32>) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %7, %3, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
    %3 = flow.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%2, %0, %1) : (tensor<?x?xf32>{%0, %1}, index, index) -> tensor<?x?xf32>{%0, %1}
    %4 = hal.tensor.export %3 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
    return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After ConvertToStream (iree-stream-conversion) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_DxDxD_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !stream.binding, %arg1: index, %arg2: index, %arg3: !stream.binding) {
        %c0 = arith.constant 0 : index
        %cst = arith.constant 0.000000e+00 : f32
        %0 = flow.dispatch.workload.ordinal %arg1, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg2, 1 : index
        %2 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1}
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        %4 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1} -> tensor<?x?xf32>
        %5 = tensor.empty(%0, %1) : tensor<?x?xf32>
        %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<?x?xf32>) -> tensor<?x?xf32>
        %7 = linalg.matmul ins(%4, %4 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%6 : tensor<?x?xf32>) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %7, %3, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = stream.tensor.sizeof tensor<?x?xf32>{%0, %1} : index
    %3 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%2}
    %4 = stream.async.transfer %3 : !stream.resource<external>{%2} -> !stream.resource<*>{%2}
    %c0 = arith.constant 0 : index
    %5 = stream.tensor.sizeof tensor<?x?xf32>{%0, %1} : index
    %6 = stream.async.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%4[%c0 to %2 for %2], %0, %1) : (!stream.resource<*>{%2}, index, index) -> !stream.resource<*>{%5}
    %7 = stream.async.transfer %6 : !stream.resource<*>{%5} -> !stream.resource<external>{%5}
    %8 = stream.tensor.export %7 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%5} -> !hal.buffer_view
    return %8 : !hal.buffer_view
  }
}


// -----// IR Dump After VerifyLoweringToTensors (iree-stream-verify-lowering-to-tensors) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_DxDxD_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !stream.binding, %arg1: index, %arg2: index, %arg3: !stream.binding) {
        %c0 = arith.constant 0 : index
        %cst = arith.constant 0.000000e+00 : f32
        %0 = flow.dispatch.workload.ordinal %arg1, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg2, 1 : index
        %2 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1}
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        %4 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1} -> tensor<?x?xf32>
        %5 = tensor.empty(%0, %1) : tensor<?x?xf32>
        %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<?x?xf32>) -> tensor<?x?xf32>
        %7 = linalg.matmul ins(%4, %4 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%6 : tensor<?x?xf32>) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %7, %3, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = stream.tensor.sizeof tensor<?x?xf32>{%0, %1} : index
    %3 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%2}
    %4 = stream.async.transfer %3 : !stream.resource<external>{%2} -> !stream.resource<*>{%2}
    %c0 = arith.constant 0 : index
    %5 = stream.tensor.sizeof tensor<?x?xf32>{%0, %1} : index
    %6 = stream.async.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%4[%c0 to %2 for %2], %0, %1) : (!stream.resource<*>{%2}, index, index) -> !stream.resource<*>{%5}
    %7 = stream.async.transfer %6 : !stream.resource<*>{%5} -> !stream.resource<external>{%5}
    %8 = stream.tensor.export %7 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%5} -> !hal.buffer_view
    return %8 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c0 = arith.constant 0 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = stream.tensor.sizeof tensor<?x?xf32>{%0, %1} : index
  %3 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%2}
  %4 = stream.async.transfer %3 : !stream.resource<external>{%2} -> !stream.resource<*>{%2}
  %5 = stream.tensor.sizeof tensor<?x?xf32>{%0, %1} : index
  %6 = stream.async.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%4[%c0 to %2 for %2], %0, %1) : (!stream.resource<*>{%2}, index, index) -> !stream.resource<*>{%5}
  %7 = stream.async.transfer %6 : !stream.resource<*>{%5} -> !stream.resource<external>{%5}
  %8 = stream.tensor.export %7 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%5} -> !hal.buffer_view
  return %8 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c0 = arith.constant 0 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = stream.tensor.sizeof tensor<?x?xf32>{%0, %1} : index
  %3 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%2}
  %4 = stream.async.transfer %3 : !stream.resource<external>{%2} -> !stream.resource<*>{%2}
  %5 = stream.async.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%4[%c0 to %2 for %2], %0, %1) : (!stream.resource<*>{%2}, index, index) -> !stream.resource<*>{%2}
  %6 = stream.async.transfer %5 : !stream.resource<*>{%2} -> !stream.resource<external>{%2}
  %7 = stream.tensor.export %6 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%2} -> !hal.buffer_view
  return %7 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c0 = arith.constant 0 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = stream.tensor.sizeof tensor<?x?xf32>{%0, %1} : index
  %3 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%2}
  %4 = stream.async.transfer %3 : !stream.resource<external>{%2} -> !stream.resource<*>{%2}
  %5 = stream.async.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%4[%c0 to %2 for %2], %0, %1) : (!stream.resource<*>{%2}, index, index) -> !stream.resource<*>{%2}
  %6 = stream.async.transfer %5 : !stream.resource<*>{%2} -> !stream.resource<external>{%2}
  %7 = stream.tensor.export %6 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%2} -> !hal.buffer_view
  return %7 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_DxDxD_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !stream.binding, %arg1: index, %arg2: index, %arg3: !stream.binding) {
        %c0 = arith.constant 0 : index
        %cst = arith.constant 0.000000e+00 : f32
        %0 = flow.dispatch.workload.ordinal %arg1, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg2, 1 : index
        %2 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1}
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        %4 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1} -> tensor<?x?xf32>
        %5 = tensor.empty(%0, %1) : tensor<?x?xf32>
        %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<?x?xf32>) -> tensor<?x?xf32>
        %7 = linalg.matmul ins(%4, %4 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%6 : tensor<?x?xf32>) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %7, %3, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = stream.tensor.sizeof tensor<?x?xf32>{%0, %1} : index
    %3 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%2}
    %4 = stream.async.transfer %3 : !stream.resource<external>{%2} -> !stream.resource<*>{%2}
    %5 = stream.async.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%4[%c0 to %2 for %2], %0, %1) : (!stream.resource<*>{%2}, index, index) -> !stream.resource<*>{%2}
    %6 = stream.async.transfer %5 : !stream.resource<*>{%2} -> !stream.resource<external>{%2}
    %7 = stream.tensor.export %6 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%2} -> !hal.buffer_view
    return %7 : !hal.buffer_view
  }
}


// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_DxDxD_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !stream.binding, %arg1: index, %arg2: index, %arg3: !stream.binding) {
        %c0 = arith.constant 0 : index
        %cst = arith.constant 0.000000e+00 : f32
        %0 = flow.dispatch.workload.ordinal %arg1, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg2, 1 : index
        %2 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1}
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        %4 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1} -> tensor<?x?xf32>
        %5 = tensor.empty(%0, %1) : tensor<?x?xf32>
        %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<?x?xf32>) -> tensor<?x?xf32>
        %7 = linalg.matmul ins(%4, %4 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%6 : tensor<?x?xf32>) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %7, %3, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = stream.tensor.sizeof tensor<?x?xf32>{%0, %1} : index
    %3 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%2}
    %4 = stream.async.transfer %3 : !stream.resource<external>{%2} -> !stream.resource<*>{%2}
    %5 = stream.async.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%4[%c0 to %2 for %2], %0, %1) : (!stream.resource<*>{%2}, index, index) -> !stream.resource<*>{%2}
    %6 = stream.async.transfer %5 : !stream.resource<*>{%2} -> !stream.resource<external>{%2}
    %7 = stream.tensor.export %6 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%2} -> !hal.buffer_view
    return %7 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_DxDxD_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !stream.binding, %arg1: index, %arg2: index, %arg3: !stream.binding) {
        %c0 = arith.constant 0 : index
        %cst = arith.constant 0.000000e+00 : f32
        %0 = flow.dispatch.workload.ordinal %arg1, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg2, 1 : index
        %2 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1}
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        %4 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1} -> tensor<?x?xf32>
        %5 = tensor.empty(%0, %1) : tensor<?x?xf32>
        %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<?x?xf32>) -> tensor<?x?xf32>
        %7 = linalg.matmul ins(%4, %4 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%6 : tensor<?x?xf32>) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %7, %3, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = stream.tensor.sizeof tensor<?x?xf32>{%0, %1} : index
    %3 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%2}
    %4 = stream.async.transfer %3 : !stream.resource<external>{%2} -> !stream.resource<*>{%2}
    %5 = stream.async.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%4[%c0 to %2 for %2], %0, %1) : (!stream.resource<*>{%2}, index, index) -> !stream.resource<*>{%2}
    %6 = stream.async.transfer %5 : !stream.resource<*>{%2} -> !stream.resource<external>{%2}
    %7 = stream.tensor.export %6 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%2} -> !hal.buffer_view
    return %7 : !hal.buffer_view
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_DxDxD_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !stream.binding, %arg1: index, %arg2: index, %arg3: !stream.binding) {
        %c0 = arith.constant 0 : index
        %cst = arith.constant 0.000000e+00 : f32
        %0 = flow.dispatch.workload.ordinal %arg1, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg2, 1 : index
        %2 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1}
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        %4 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1} -> tensor<?x?xf32>
        %5 = tensor.empty(%0, %1) : tensor<?x?xf32>
        %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<?x?xf32>) -> tensor<?x?xf32>
        %7 = linalg.matmul ins(%4, %4 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%6 : tensor<?x?xf32>) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %7, %3, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = stream.tensor.sizeof tensor<?x?xf32>{%0, %1} : index
    %3 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%2}
    %4 = stream.async.transfer %3 : !stream.resource<external>{%2} -> !stream.resource<*>{%2}
    %5 = stream.async.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%4[%c0 to %2 for %2], %0, %1) : (!stream.resource<*>{%2}, index, index) -> !stream.resource<*>{%2}
    %6 = stream.async.transfer %5 : !stream.resource<*>{%2} -> !stream.resource<external>{%2}
    %7 = stream.tensor.export %6 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%2} -> !hal.buffer_view
    return %7 : !hal.buffer_view
  }
}


// -----// IR Dump After CombineInitializers (iree-util-combine-initializers) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_DxDxD_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !stream.binding, %arg1: index, %arg2: index, %arg3: !stream.binding) {
        %c0 = arith.constant 0 : index
        %cst = arith.constant 0.000000e+00 : f32
        %0 = flow.dispatch.workload.ordinal %arg1, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg2, 1 : index
        %2 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1}
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        %4 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1} -> tensor<?x?xf32>
        %5 = tensor.empty(%0, %1) : tensor<?x?xf32>
        %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<?x?xf32>) -> tensor<?x?xf32>
        %7 = linalg.matmul ins(%4, %4 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%6 : tensor<?x?xf32>) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %7, %3, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = stream.tensor.sizeof tensor<?x?xf32>{%0, %1} : index
    %3 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%2}
    %4 = stream.async.transfer %3 : !stream.resource<external>{%2} -> !stream.resource<*>{%2}
    %5 = stream.async.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%4[%c0 to %2 for %2], %0, %1) : (!stream.resource<*>{%2}, index, index) -> !stream.resource<*>{%2}
    %6 = stream.async.transfer %5 : !stream.resource<*>{%2} -> !stream.resource<external>{%2}
    %7 = stream.tensor.export %6 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%2} -> !hal.buffer_view
    return %7 : !hal.buffer_view
  }
}


// -----// IR Dump After EncodeHostTensors (iree-stream-encode-host-tensors) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
  %5 = stream.async.transfer %4 : !stream.resource<external>{%3} -> !stream.resource<*>{%3}
  %6 = stream.async.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%5[%c0 to %3 for %3], %0, %1) : (!stream.resource<*>{%3}, index, index) -> !stream.resource<*>{%3}
  %7 = stream.async.transfer %6 : !stream.resource<*>{%3} -> !stream.resource<external>{%3}
  %8 = stream.tensor.export %7 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
  return %8 : !hal.buffer_view
}

// -----// IR Dump After EncodeDeviceTensors (iree-stream-encode-device-tensors) //----- //
stream.executable private @main_dispatch_0 {
  stream.executable.export public @main_dispatch_0_matmul_DxDxD_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
    %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
    stream.return %x, %y, %z : index, index, index
  }
  builtin.module {
    func.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !stream.binding, %arg1: index, %arg2: index, %arg3: !stream.binding) {
      %c0 = arith.constant 0 : index
      %cst = arith.constant 0.000000e+00 : f32
      %0 = flow.dispatch.workload.ordinal %arg1, 0 : index
      %1 = flow.dispatch.workload.ordinal %arg2, 1 : index
      %2 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1}
      %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
      %4 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1} -> tensor<?x?xf32>
      %5 = tensor.empty(%0, %1) : tensor<?x?xf32>
      %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<?x?xf32>) -> tensor<?x?xf32>
      %7 = linalg.matmul ins(%4, %4 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%6 : tensor<?x?xf32>) -> tensor<?x?xf32>
      flow.dispatch.tensor.store %7, %3, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
      return
    }
  }
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
  %5 = stream.async.transfer %4 : !stream.resource<external>{%3} -> !stream.resource<*>{%3}
  %6 = stream.async.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%5[%c0 to %3 for %3], %0, %1) : (!stream.resource<*>{%3}, index, index) -> !stream.resource<*>{%3}
  %7 = stream.async.transfer %6 : !stream.resource<*>{%3} -> !stream.resource<external>{%3}
  %8 = stream.tensor.export %7 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
  return %8 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
  %5 = stream.async.transfer %4 : !stream.resource<external>{%3} -> !stream.resource<*>{%3}
  %6 = stream.async.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%5[%c0 to %3 for %3], %0, %1) : (!stream.resource<*>{%3}, index, index) -> !stream.resource<*>{%3}
  %7 = stream.async.transfer %6 : !stream.resource<*>{%3} -> !stream.resource<external>{%3}
  %8 = stream.tensor.export %7 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
  return %8 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
  %5 = stream.async.transfer %4 : !stream.resource<external>{%3} -> !stream.resource<*>{%3}
  %6 = stream.async.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%5[%c0 to %3 for %3], %0, %1) : (!stream.resource<*>{%3}, index, index) -> !stream.resource<*>{%3}
  %7 = stream.async.transfer %6 : !stream.resource<*>{%3} -> !stream.resource<external>{%3}
  %8 = stream.tensor.export %7 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
  return %8 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_DxDxD_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !stream.binding, %arg1: index, %arg2: index, %arg3: !stream.binding) {
        %c0 = arith.constant 0 : index
        %cst = arith.constant 0.000000e+00 : f32
        %0 = flow.dispatch.workload.ordinal %arg1, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg2, 1 : index
        %2 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1}
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        %4 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1} -> tensor<?x?xf32>
        %5 = tensor.empty(%0, %1) : tensor<?x?xf32>
        %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<?x?xf32>) -> tensor<?x?xf32>
        %7 = linalg.matmul ins(%4, %4 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%6 : tensor<?x?xf32>) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %7, %3, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %5 = stream.async.transfer %4 : !stream.resource<external>{%3} -> !stream.resource<*>{%3}
    %6 = stream.async.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%5[%c0 to %3 for %3], %0, %1) : (!stream.resource<*>{%3}, index, index) -> !stream.resource<*>{%3}
    %7 = stream.async.transfer %6 : !stream.resource<*>{%3} -> !stream.resource<external>{%3}
    %8 = stream.tensor.export %7 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
    return %8 : !hal.buffer_view
  }
}


// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_DxDxD_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !stream.binding, %arg1: index, %arg2: index, %arg3: !stream.binding) {
        %c0 = arith.constant 0 : index
        %cst = arith.constant 0.000000e+00 : f32
        %0 = flow.dispatch.workload.ordinal %arg1, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg2, 1 : index
        %2 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1}
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        %4 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1} -> tensor<?x?xf32>
        %5 = tensor.empty(%0, %1) : tensor<?x?xf32>
        %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<?x?xf32>) -> tensor<?x?xf32>
        %7 = linalg.matmul ins(%4, %4 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%6 : tensor<?x?xf32>) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %7, %3, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %5 = stream.async.transfer %4 : !stream.resource<external>{%3} -> !stream.resource<*>{%3}
    %6 = stream.async.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%5[%c0 to %3 for %3], %0, %1) : (!stream.resource<*>{%3}, index, index) -> !stream.resource<*>{%3}
    %7 = stream.async.transfer %6 : !stream.resource<*>{%3} -> !stream.resource<external>{%3}
    %8 = stream.tensor.export %7 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
    return %8 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_DxDxD_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !stream.binding, %arg1: index, %arg2: index, %arg3: !stream.binding) {
        %c0 = arith.constant 0 : index
        %cst = arith.constant 0.000000e+00 : f32
        %0 = flow.dispatch.workload.ordinal %arg1, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg2, 1 : index
        %2 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1}
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        %4 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1} -> tensor<?x?xf32>
        %5 = tensor.empty(%0, %1) : tensor<?x?xf32>
        %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<?x?xf32>) -> tensor<?x?xf32>
        %7 = linalg.matmul ins(%4, %4 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%6 : tensor<?x?xf32>) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %7, %3, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %5 = stream.async.transfer %4 : !stream.resource<external>{%3} -> !stream.resource<*>{%3}
    %6 = stream.async.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%5[%c0 to %3 for %3], %0, %1) : (!stream.resource<*>{%3}, index, index) -> !stream.resource<*>{%3}
    %7 = stream.async.transfer %6 : !stream.resource<*>{%3} -> !stream.resource<external>{%3}
    %8 = stream.tensor.export %7 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
    return %8 : !hal.buffer_view
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_DxDxD_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !stream.binding, %arg1: index, %arg2: index, %arg3: !stream.binding) {
        %c0 = arith.constant 0 : index
        %cst = arith.constant 0.000000e+00 : f32
        %0 = flow.dispatch.workload.ordinal %arg1, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg2, 1 : index
        %2 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1}
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        %4 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1} -> tensor<?x?xf32>
        %5 = tensor.empty(%0, %1) : tensor<?x?xf32>
        %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<?x?xf32>) -> tensor<?x?xf32>
        %7 = linalg.matmul ins(%4, %4 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%6 : tensor<?x?xf32>) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %7, %3, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %5 = stream.async.transfer %4 : !stream.resource<external>{%3} -> !stream.resource<*>{%3}
    %6 = stream.async.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%5[%c0 to %3 for %3], %0, %1) : (!stream.resource<*>{%3}, index, index) -> !stream.resource<*>{%3}
    %7 = stream.async.transfer %6 : !stream.resource<*>{%3} -> !stream.resource<external>{%3}
    %8 = stream.tensor.export %7 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
    return %8 : !hal.buffer_view
  }
}


// -----// IR Dump After MaterializeCopyOnWrite (iree-stream-materialize-copy-on-write) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
  %5 = stream.async.transfer %4 : !stream.resource<external>{%3} -> !stream.resource<*>{%3}
  %6 = stream.async.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%5[%c0 to %3 for %3], %0, %1) : (!stream.resource<*>{%3}, index, index) -> !stream.resource<*>{%3}
  %7 = stream.async.transfer %6 : !stream.resource<*>{%3} -> !stream.resource<external>{%3}
  %8 = stream.tensor.export %7 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
  return %8 : !hal.buffer_view
}

// -----// IR Dump After ElideAsyncCopies (iree-stream-elide-async-copies) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_DxDxD_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !stream.binding, %arg1: index, %arg2: index, %arg3: !stream.binding) {
        %c0 = arith.constant 0 : index
        %cst = arith.constant 0.000000e+00 : f32
        %0 = flow.dispatch.workload.ordinal %arg1, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg2, 1 : index
        %2 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1}
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        %4 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1} -> tensor<?x?xf32>
        %5 = tensor.empty(%0, %1) : tensor<?x?xf32>
        %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<?x?xf32>) -> tensor<?x?xf32>
        %7 = linalg.matmul ins(%4, %4 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%6 : tensor<?x?xf32>) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %7, %3, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %5 = stream.async.transfer %4 : !stream.resource<external>{%3} -> !stream.resource<*>{%3}
    %6 = stream.async.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%5[%c0 to %3 for %3], %0, %1) : (!stream.resource<*>{%3}, index, index) -> !stream.resource<*>{%3}
    %7 = stream.async.transfer %6 : !stream.resource<*>{%3} -> !stream.resource<external>{%3}
    %8 = stream.tensor.export %7 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
    return %8 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
  %5 = stream.async.transfer %4 : !stream.resource<external>{%3} -> !stream.resource<*>{%3}
  %6 = stream.async.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%5[%c0 to %3 for %3], %0, %1) : (!stream.resource<*>{%3}, index, index) -> !stream.resource<*>{%3}
  %7 = stream.async.transfer %6 : !stream.resource<*>{%3} -> !stream.resource<external>{%3}
  %8 = stream.tensor.export %7 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
  return %8 : !hal.buffer_view
}

// -----// IR Dump After EmplaceAllocations (iree-stream-emplace-allocations) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
  %5 = stream.async.transfer %4 : !stream.resource<external>{%3} -> !stream.resource<*>{%3}
  %6 = stream.async.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%5[%c0 to %3 for %3], %0, %1) : (!stream.resource<*>{%3}, index, index) -> !stream.resource<*>{%3}
  %7 = stream.async.transfer %6 : !stream.resource<*>{%3} -> !stream.resource<external>{%3}
  %8 = stream.tensor.export %7 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
  return %8 : !hal.buffer_view
}

// -----// IR Dump After RefineUsage (iree-stream-refine-usage) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_DxDxD_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !stream.binding, %arg1: index, %arg2: index, %arg3: !stream.binding) {
        %c0 = arith.constant 0 : index
        %cst = arith.constant 0.000000e+00 : f32
        %0 = flow.dispatch.workload.ordinal %arg1, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg2, 1 : index
        %2 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1}
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        %4 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1} -> tensor<?x?xf32>
        %5 = tensor.empty(%0, %1) : tensor<?x?xf32>
        %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<?x?xf32>) -> tensor<?x?xf32>
        %7 = linalg.matmul ins(%4, %4 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%6 : tensor<?x?xf32>) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %7, %3, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %5 = stream.async.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%4[%c0 to %3 for %3], %0, %1) : (!stream.resource<external>{%3}, index, index) -> !stream.resource<external>{%3}
    %6 = stream.tensor.export %5 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
    return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
  %5 = stream.async.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%4[%c0 to %3 for %3], %0, %1) : (!stream.resource<external>{%3}, index, index) -> !stream.resource<external>{%3}
  %6 = stream.tensor.export %5 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
  return %6 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
  %5 = stream.async.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%4[%c0 to %3 for %3], %0, %1) : (!stream.resource<external>{%3}, index, index) -> !stream.resource<external>{%3}
  %6 = stream.tensor.export %5 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
  return %6 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
  %5 = stream.async.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%4[%c0 to %3 for %3], %0, %1) : (!stream.resource<external>{%3}, index, index) -> !stream.resource<external>{%3}
  %6 = stream.tensor.export %5 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
  return %6 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_DxDxD_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !stream.binding, %arg1: index, %arg2: index, %arg3: !stream.binding) {
        %c0 = arith.constant 0 : index
        %cst = arith.constant 0.000000e+00 : f32
        %0 = flow.dispatch.workload.ordinal %arg1, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg2, 1 : index
        %2 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1}
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        %4 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1} -> tensor<?x?xf32>
        %5 = tensor.empty(%0, %1) : tensor<?x?xf32>
        %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<?x?xf32>) -> tensor<?x?xf32>
        %7 = linalg.matmul ins(%4, %4 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%6 : tensor<?x?xf32>) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %7, %3, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %5 = stream.async.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%4[%c0 to %3 for %3], %0, %1) : (!stream.resource<external>{%3}, index, index) -> !stream.resource<external>{%3}
    %6 = stream.tensor.export %5 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
    return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_DxDxD_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !stream.binding, %arg1: index, %arg2: index, %arg3: !stream.binding) {
        %c0 = arith.constant 0 : index
        %cst = arith.constant 0.000000e+00 : f32
        %0 = flow.dispatch.workload.ordinal %arg1, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg2, 1 : index
        %2 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1}
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        %4 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1} -> tensor<?x?xf32>
        %5 = tensor.empty(%0, %1) : tensor<?x?xf32>
        %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<?x?xf32>) -> tensor<?x?xf32>
        %7 = linalg.matmul ins(%4, %4 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%6 : tensor<?x?xf32>) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %7, %3, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %5 = stream.async.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%4[%c0 to %3 for %3], %0, %1) : (!stream.resource<external>{%3}, index, index) -> !stream.resource<external>{%3}
    %6 = stream.tensor.export %5 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
    return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_DxDxD_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !stream.binding, %arg1: index, %arg2: index, %arg3: !stream.binding) {
        %c0 = arith.constant 0 : index
        %cst = arith.constant 0.000000e+00 : f32
        %0 = flow.dispatch.workload.ordinal %arg1, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg2, 1 : index
        %2 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1}
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        %4 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1} -> tensor<?x?xf32>
        %5 = tensor.empty(%0, %1) : tensor<?x?xf32>
        %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<?x?xf32>) -> tensor<?x?xf32>
        %7 = linalg.matmul ins(%4, %4 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%6 : tensor<?x?xf32>) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %7, %3, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %5 = stream.async.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%4[%c0 to %3 for %3], %0, %1) : (!stream.resource<external>{%3}, index, index) -> !stream.resource<external>{%3}
    %6 = stream.tensor.export %5 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
    return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_DxDxD_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !stream.binding, %arg1: index, %arg2: index, %arg3: !stream.binding) {
        %c0 = arith.constant 0 : index
        %cst = arith.constant 0.000000e+00 : f32
        %0 = flow.dispatch.workload.ordinal %arg1, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg2, 1 : index
        %2 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1}
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        %4 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1} -> tensor<?x?xf32>
        %5 = tensor.empty(%0, %1) : tensor<?x?xf32>
        %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<?x?xf32>) -> tensor<?x?xf32>
        %7 = linalg.matmul ins(%4, %4 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%6 : tensor<?x?xf32>) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %7, %3, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %5 = stream.async.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%4[%c0 to %3 for %3], %0, %1) : (!stream.resource<external>{%3}, index, index) -> !stream.resource<external>{%3}
    %6 = stream.tensor.export %5 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
    return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After VerifyAsyncAccessRanges (iree-stream-verify-async-access-ranges) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_DxDxD_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !stream.binding, %arg1: index, %arg2: index, %arg3: !stream.binding) {
        %c0 = arith.constant 0 : index
        %cst = arith.constant 0.000000e+00 : f32
        %0 = flow.dispatch.workload.ordinal %arg1, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg2, 1 : index
        %2 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1}
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        %4 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1} -> tensor<?x?xf32>
        %5 = tensor.empty(%0, %1) : tensor<?x?xf32>
        %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<?x?xf32>) -> tensor<?x?xf32>
        %7 = linalg.matmul ins(%4, %4 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%6 : tensor<?x?xf32>) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %7, %3, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %5 = stream.async.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%4[%c0 to %3 for %3], %0, %1) : (!stream.resource<external>{%3}, index, index) -> !stream.resource<external>{%3}
    %6 = stream.tensor.export %5 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
    return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After ScheduleExecution (iree-stream-schedule-execution) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
  %results, %result_timepoint = stream.async.execute with(%4 as %arg1: !stream.resource<external>{%3}) -> !stream.resource<external>{%3} {
    %7 = stream.async.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%arg1[%c0 to %3 for %3], %0, %1) : (!stream.resource<external>{%3}, index, index) -> !stream.resource<external>{%3}
    stream.yield %7 : !stream.resource<external>{%3}
  } => !stream.timepoint
  %5 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%3}
  %6 = stream.tensor.export %5 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
  return %6 : !hal.buffer_view
}

// -----// IR Dump After ScheduleConcurrency (iree-stream-schedule-concurrency) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
  %results, %result_timepoint = stream.async.execute with(%4 as %arg1: !stream.resource<external>{%3}) -> !stream.resource<external>{%3} {
    %7 = stream.async.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%arg1[%c0 to %3 for %3], %0, %1) : (!stream.resource<external>{%3}, index, index) -> !stream.resource<external>{%3}
    stream.yield %7 : !stream.resource<external>{%3}
  } => !stream.timepoint
  %5 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%3}
  %6 = stream.tensor.export %5 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
  return %6 : !hal.buffer_view
}

// -----// IR Dump After PropagateTimepoints (iree-stream-propagate-timepoints) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_DxDxD_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !stream.binding, %arg1: index, %arg2: index, %arg3: !stream.binding) {
        %c0 = arith.constant 0 : index
        %cst = arith.constant 0.000000e+00 : f32
        %0 = flow.dispatch.workload.ordinal %arg1, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg2, 1 : index
        %2 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1}
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        %4 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1} -> tensor<?x?xf32>
        %5 = tensor.empty(%0, %1) : tensor<?x?xf32>
        %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<?x?xf32>) -> tensor<?x?xf32>
        %7 = linalg.matmul ins(%4, %4 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%6 : tensor<?x?xf32>) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %7, %3, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %5 = stream.timepoint.immediate => !stream.timepoint
    %results, %result_timepoint = stream.async.execute await(%5) => with(%4 as %arg1: !stream.resource<external>{%3}) -> !stream.resource<external>{%3} {
      %8 = stream.async.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%arg1[%c0 to %3 for %3], %0, %1) : (!stream.resource<external>{%3}, index, index) -> !stream.resource<external>{%3}
      stream.yield %8 : !stream.resource<external>{%3}
    } => !stream.timepoint
    %6 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%3}
    %7 = stream.tensor.export %6 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
    return %7 : !hal.buffer_view
  }
}


// -----// IR Dump After MaterializeBuiltins (iree-stream-materialize-builtins) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_DxDxD_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !stream.binding, %arg1: index, %arg2: index, %arg3: !stream.binding) {
        %c0 = arith.constant 0 : index
        %cst = arith.constant 0.000000e+00 : f32
        %0 = flow.dispatch.workload.ordinal %arg1, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg2, 1 : index
        %2 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1}
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        %4 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1} -> tensor<?x?xf32>
        %5 = tensor.empty(%0, %1) : tensor<?x?xf32>
        %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<?x?xf32>) -> tensor<?x?xf32>
        %7 = linalg.matmul ins(%4, %4 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%6 : tensor<?x?xf32>) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %7, %3, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %5 = stream.timepoint.immediate => !stream.timepoint
    %results, %result_timepoint = stream.async.execute await(%5) => with(%4 as %arg1: !stream.resource<external>{%3}) -> !stream.resource<external>{%3} {
      %8 = stream.async.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%arg1[%c0 to %3 for %3], %0, %1) : (!stream.resource<external>{%3}, index, index) -> !stream.resource<external>{%3}
      stream.yield %8 : !stream.resource<external>{%3}
    } => !stream.timepoint
    %6 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%3}
    %7 = stream.tensor.export %6 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
    return %7 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
  %results, %result_timepoint = stream.async.execute with(%4 as %arg1: !stream.resource<external>{%3}) -> !stream.resource<external>{%3} {
    %7 = stream.async.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%arg1[%c0 to %3 for %3], %0, %1) : (!stream.resource<external>{%3}, index, index) -> !stream.resource<external>{%3}
    stream.yield %7 : !stream.resource<external>{%3}
  } => !stream.timepoint
  %5 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%3}
  %6 = stream.tensor.export %5 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
  return %6 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
  %results, %result_timepoint = stream.async.execute with(%4 as %arg1: !stream.resource<external>{%3}) -> !stream.resource<external>{%3} {
    %7 = stream.async.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%arg1[%c0 to %3 for %3], %0, %1) : (!stream.resource<external>{%3}, index, index) -> !stream.resource<external>{%3}
    stream.yield %7 : !stream.resource<external>{%3}
  } => !stream.timepoint
  %5 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%3}
  %6 = stream.tensor.export %5 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
  return %6 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
  %results, %result_timepoint = stream.async.execute with(%4 as %arg1: !stream.resource<external>{%3}) -> !stream.resource<external>{%3} {
    %7 = stream.async.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%arg1[%c0 to %3 for %3], %0, %1) : (!stream.resource<external>{%3}, index, index) -> !stream.resource<external>{%3}
    stream.yield %7 : !stream.resource<external>{%3}
  } => !stream.timepoint
  %5 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%3}
  %6 = stream.tensor.export %5 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
  return %6 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_DxDxD_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !stream.binding, %arg1: index, %arg2: index, %arg3: !stream.binding) {
        %c0 = arith.constant 0 : index
        %cst = arith.constant 0.000000e+00 : f32
        %0 = flow.dispatch.workload.ordinal %arg1, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg2, 1 : index
        %2 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1}
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        %4 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1} -> tensor<?x?xf32>
        %5 = tensor.empty(%0, %1) : tensor<?x?xf32>
        %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<?x?xf32>) -> tensor<?x?xf32>
        %7 = linalg.matmul ins(%4, %4 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%6 : tensor<?x?xf32>) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %7, %3, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %results, %result_timepoint = stream.async.execute with(%4 as %arg1: !stream.resource<external>{%3}) -> !stream.resource<external>{%3} {
      %7 = stream.async.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%arg1[%c0 to %3 for %3], %0, %1) : (!stream.resource<external>{%3}, index, index) -> !stream.resource<external>{%3}
      stream.yield %7 : !stream.resource<external>{%3}
    } => !stream.timepoint
    %5 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%3}
    %6 = stream.tensor.export %5 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
    return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_DxDxD_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !stream.binding, %arg1: index, %arg2: index, %arg3: !stream.binding) {
        %c0 = arith.constant 0 : index
        %cst = arith.constant 0.000000e+00 : f32
        %0 = flow.dispatch.workload.ordinal %arg1, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg2, 1 : index
        %2 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1}
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        %4 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1} -> tensor<?x?xf32>
        %5 = tensor.empty(%0, %1) : tensor<?x?xf32>
        %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<?x?xf32>) -> tensor<?x?xf32>
        %7 = linalg.matmul ins(%4, %4 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%6 : tensor<?x?xf32>) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %7, %3, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %results, %result_timepoint = stream.async.execute with(%4 as %arg1: !stream.resource<external>{%3}) -> !stream.resource<external>{%3} {
      %7 = stream.async.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%arg1[%c0 to %3 for %3], %0, %1) : (!stream.resource<external>{%3}, index, index) -> !stream.resource<external>{%3}
      stream.yield %7 : !stream.resource<external>{%3}
    } => !stream.timepoint
    %5 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%3}
    %6 = stream.tensor.export %5 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
    return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_DxDxD_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !stream.binding, %arg1: index, %arg2: index, %arg3: !stream.binding) {
        %c0 = arith.constant 0 : index
        %cst = arith.constant 0.000000e+00 : f32
        %0 = flow.dispatch.workload.ordinal %arg1, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg2, 1 : index
        %2 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1}
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        %4 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1} -> tensor<?x?xf32>
        %5 = tensor.empty(%0, %1) : tensor<?x?xf32>
        %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<?x?xf32>) -> tensor<?x?xf32>
        %7 = linalg.matmul ins(%4, %4 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%6 : tensor<?x?xf32>) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %7, %3, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %results, %result_timepoint = stream.async.execute with(%4 as %arg1: !stream.resource<external>{%3}) -> !stream.resource<external>{%3} {
      %7 = stream.async.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%arg1[%c0 to %3 for %3], %0, %1) : (!stream.resource<external>{%3}, index, index) -> !stream.resource<external>{%3}
      stream.yield %7 : !stream.resource<external>{%3}
    } => !stream.timepoint
    %5 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%3}
    %6 = stream.tensor.export %5 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
    return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_DxDxD_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !stream.binding, %arg1: index, %arg2: index, %arg3: !stream.binding) {
        %c0 = arith.constant 0 : index
        %cst = arith.constant 0.000000e+00 : f32
        %0 = flow.dispatch.workload.ordinal %arg1, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg2, 1 : index
        %2 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1}
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        %4 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1} -> tensor<?x?xf32>
        %5 = tensor.empty(%0, %1) : tensor<?x?xf32>
        %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<?x?xf32>) -> tensor<?x?xf32>
        %7 = linalg.matmul ins(%4, %4 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%6 : tensor<?x?xf32>) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %7, %3, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %results, %result_timepoint = stream.async.execute with(%4 as %arg1: !stream.resource<external>{%3}) -> !stream.resource<external>{%3} {
      %7 = stream.async.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%arg1[%c0 to %3 for %3], %0, %1) : (!stream.resource<external>{%3}, index, index) -> !stream.resource<external>{%3}
      stream.yield %7 : !stream.resource<external>{%3}
    } => !stream.timepoint
    %5 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%3}
    %6 = stream.tensor.export %5 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
    return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After VerifyLoweringToAsync (iree-stream-verify-lowering-to-async) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_DxDxD_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !stream.binding, %arg1: index, %arg2: index, %arg3: !stream.binding) {
        %c0 = arith.constant 0 : index
        %cst = arith.constant 0.000000e+00 : f32
        %0 = flow.dispatch.workload.ordinal %arg1, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg2, 1 : index
        %2 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1}
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        %4 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1} -> tensor<?x?xf32>
        %5 = tensor.empty(%0, %1) : tensor<?x?xf32>
        %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<?x?xf32>) -> tensor<?x?xf32>
        %7 = linalg.matmul ins(%4, %4 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%6 : tensor<?x?xf32>) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %7, %3, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %results, %result_timepoint = stream.async.execute with(%4 as %arg1: !stream.resource<external>{%3}) -> !stream.resource<external>{%3} {
      %7 = stream.async.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%arg1[%c0 to %3 for %3], %0, %1) : (!stream.resource<external>{%3}, index, index) -> !stream.resource<external>{%3}
      stream.yield %7 : !stream.resource<external>{%3}
    } => !stream.timepoint
    %5 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%3}
    %6 = stream.tensor.export %5 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
    return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After ScheduleAllocation (iree-stream-schedule-allocation) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_DxDxD_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !stream.binding, %arg1: index, %arg2: index, %arg3: !stream.binding) {
        %c0 = arith.constant 0 : index
        %cst = arith.constant 0.000000e+00 : f32
        %0 = flow.dispatch.workload.ordinal %arg1, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg2, 1 : index
        %2 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1}
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        %4 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1} -> tensor<?x?xf32>
        %5 = tensor.empty(%0, %1) : tensor<?x?xf32>
        %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<?x?xf32>) -> tensor<?x?xf32>
        %7 = linalg.matmul ins(%4, %4 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%6 : tensor<?x?xf32>) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %7, %3, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %c0_0 = arith.constant 0 : index
    %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%3} => !stream.timepoint
    %5 = stream.cmd.execute await(%result_timepoint) => with(%4 as %arg1: !stream.resource<external>{%3}, %result as %arg2: !stream.resource<external>{%3}) {
      stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%0, %1 : index, index) {
        ro %arg1[%c0 for %3] : !stream.resource<external>{%3},
        wo %arg2[%c0_0 for %3] : !stream.resource<external>{%3}
      }
    } => !stream.timepoint
    %6 = stream.timepoint.await %5 => %result : !stream.resource<external>{%3}
    %7 = stream.tensor.export %6 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
    return %7 : !hal.buffer_view
  }
}


// -----// IR Dump After PackConstants (iree-stream-pack-constants) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
  %c0_0 = arith.constant 0 : index
  %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%3} => !stream.timepoint
  %5 = stream.cmd.execute await(%result_timepoint) => with(%4 as %arg1: !stream.resource<external>{%3}, %result as %arg2: !stream.resource<external>{%3}) {
    stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%0, %1 : index, index) {
      ro %arg1[%c0 for %3] : !stream.resource<external>{%3},
      wo %arg2[%c0_0 for %3] : !stream.resource<external>{%3}
    }
  } => !stream.timepoint
  %6 = stream.timepoint.await %5 => %result : !stream.resource<external>{%3}
  %7 = stream.tensor.export %6 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
  return %7 : !hal.buffer_view
}

// -----// IR Dump After LayoutSlices (iree-stream-layout-slices) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
  %c0_0 = arith.constant 0 : index
  %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%3} => !stream.timepoint
  %5 = stream.cmd.execute await(%result_timepoint) => with(%4 as %arg1: !stream.resource<external>{%3}, %result as %arg2: !stream.resource<external>{%3}) {
    stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%0, %1 : index, index) {
      ro %arg1[%c0 for %3] : !stream.resource<external>{%3},
      wo %arg2[%c0_0 for %3] : !stream.resource<external>{%3}
    }
  } => !stream.timepoint
  %6 = stream.timepoint.await %5 => %result : !stream.resource<external>{%3}
  %7 = stream.tensor.export %6 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
  return %7 : !hal.buffer_view
}

// -----// IR Dump After PropagateSubranges (iree-util-propagate-subranges) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_DxDxD_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !stream.binding, %arg1: index, %arg2: index, %arg3: !stream.binding) {
        %c0 = arith.constant 0 : index
        %cst = arith.constant 0.000000e+00 : f32
        %0 = flow.dispatch.workload.ordinal %arg1, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg2, 1 : index
        %2 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1}
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        %4 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1} -> tensor<?x?xf32>
        %5 = tensor.empty(%0, %1) : tensor<?x?xf32>
        %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<?x?xf32>) -> tensor<?x?xf32>
        %7 = linalg.matmul ins(%4, %4 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%6 : tensor<?x?xf32>) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %7, %3, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %c0_0 = arith.constant 0 : index
    %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%3} => !stream.timepoint
    %5 = stream.cmd.execute await(%result_timepoint) => with(%4 as %arg1: !stream.resource<external>{%3}, %result as %arg2: !stream.resource<external>{%3}) {
      stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%0, %1 : index, index) {
        ro %arg1[%c0 for %3] : !stream.resource<external>{%3},
        wo %arg2[%c0_0 for %3] : !stream.resource<external>{%3}
      }
    } => !stream.timepoint
    %6 = stream.timepoint.await %5 => %result : !stream.resource<external>{%3}
    %7 = stream.tensor.export %6 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
    return %7 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
  %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%3} => !stream.timepoint
  %5 = stream.cmd.execute await(%result_timepoint) => with(%4 as %arg1: !stream.resource<external>{%3}, %result as %arg2: !stream.resource<external>{%3}) {
    stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%0, %1 : index, index) {
      ro %arg1[%c0 for %3] : !stream.resource<external>{%3},
      wo %arg2[%c0 for %3] : !stream.resource<external>{%3}
    }
  } => !stream.timepoint
  %6 = stream.timepoint.await %5 => %result : !stream.resource<external>{%3}
  %7 = stream.tensor.export %6 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
  return %7 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
  %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%3} => !stream.timepoint
  %5 = stream.cmd.execute await(%result_timepoint) => with(%4 as %arg1: !stream.resource<external>{%3}, %result as %arg2: !stream.resource<external>{%3}) {
    stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%0, %1 : index, index) {
      ro %arg1[%c0 for %3] : !stream.resource<external>{%3},
      wo %arg2[%c0 for %3] : !stream.resource<external>{%3}
    }
  } => !stream.timepoint
  %6 = stream.timepoint.await %5 => %result : !stream.resource<external>{%3}
  %7 = stream.tensor.export %6 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
  return %7 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
  %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%3} => !stream.timepoint
  %5 = stream.cmd.execute await(%result_timepoint) => with(%4 as %arg1: !stream.resource<external>{%3}, %result as %arg2: !stream.resource<external>{%3}) {
    stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%0, %1 : index, index) {
      ro %arg1[%c0 for %3] : !stream.resource<external>{%3},
      wo %arg2[%c0 for %3] : !stream.resource<external>{%3}
    }
  } => !stream.timepoint
  %6 = stream.timepoint.await %5 => %result : !stream.resource<external>{%3}
  %7 = stream.tensor.export %6 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
  return %7 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_DxDxD_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !stream.binding, %arg1: index, %arg2: index, %arg3: !stream.binding) {
        %c0 = arith.constant 0 : index
        %cst = arith.constant 0.000000e+00 : f32
        %0 = flow.dispatch.workload.ordinal %arg1, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg2, 1 : index
        %2 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1}
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        %4 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1} -> tensor<?x?xf32>
        %5 = tensor.empty(%0, %1) : tensor<?x?xf32>
        %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<?x?xf32>) -> tensor<?x?xf32>
        %7 = linalg.matmul ins(%4, %4 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%6 : tensor<?x?xf32>) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %7, %3, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%3} => !stream.timepoint
    %5 = stream.cmd.execute await(%result_timepoint) => with(%4 as %arg1: !stream.resource<external>{%3}, %result as %arg2: !stream.resource<external>{%3}) {
      stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%0, %1 : index, index) {
        ro %arg1[%c0 for %3] : !stream.resource<external>{%3},
        wo %arg2[%c0 for %3] : !stream.resource<external>{%3}
      }
    } => !stream.timepoint
    %6 = stream.timepoint.await %5 => %result : !stream.resource<external>{%3}
    %7 = stream.tensor.export %6 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
    return %7 : !hal.buffer_view
  }
}


// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_DxDxD_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !stream.binding, %arg1: index, %arg2: index, %arg3: !stream.binding) {
        %c0 = arith.constant 0 : index
        %cst = arith.constant 0.000000e+00 : f32
        %0 = flow.dispatch.workload.ordinal %arg1, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg2, 1 : index
        %2 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1}
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        %4 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1} -> tensor<?x?xf32>
        %5 = tensor.empty(%0, %1) : tensor<?x?xf32>
        %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<?x?xf32>) -> tensor<?x?xf32>
        %7 = linalg.matmul ins(%4, %4 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%6 : tensor<?x?xf32>) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %7, %3, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%3} => !stream.timepoint
    %5 = stream.cmd.execute await(%result_timepoint) => with(%4 as %arg1: !stream.resource<external>{%3}, %result as %arg2: !stream.resource<external>{%3}) {
      stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%0, %1 : index, index) {
        ro %arg1[%c0 for %3] : !stream.resource<external>{%3},
        wo %arg2[%c0 for %3] : !stream.resource<external>{%3}
      }
    } => !stream.timepoint
    %6 = stream.timepoint.await %5 => %result : !stream.resource<external>{%3}
    %7 = stream.tensor.export %6 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
    return %7 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_DxDxD_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !stream.binding, %arg1: index, %arg2: index, %arg3: !stream.binding) {
        %c0 = arith.constant 0 : index
        %cst = arith.constant 0.000000e+00 : f32
        %0 = flow.dispatch.workload.ordinal %arg1, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg2, 1 : index
        %2 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1}
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        %4 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1} -> tensor<?x?xf32>
        %5 = tensor.empty(%0, %1) : tensor<?x?xf32>
        %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<?x?xf32>) -> tensor<?x?xf32>
        %7 = linalg.matmul ins(%4, %4 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%6 : tensor<?x?xf32>) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %7, %3, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%3} => !stream.timepoint
    %5 = stream.cmd.execute await(%result_timepoint) => with(%4 as %arg1: !stream.resource<external>{%3}, %result as %arg2: !stream.resource<external>{%3}) {
      stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%0, %1 : index, index) {
        ro %arg1[%c0 for %3] : !stream.resource<external>{%3},
        wo %arg2[%c0 for %3] : !stream.resource<external>{%3}
      }
    } => !stream.timepoint
    %6 = stream.timepoint.await %5 => %result : !stream.resource<external>{%3}
    %7 = stream.tensor.export %6 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
    return %7 : !hal.buffer_view
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_DxDxD_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !stream.binding, %arg1: index, %arg2: index, %arg3: !stream.binding) {
        %c0 = arith.constant 0 : index
        %cst = arith.constant 0.000000e+00 : f32
        %0 = flow.dispatch.workload.ordinal %arg1, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg2, 1 : index
        %2 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1}
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        %4 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1} -> tensor<?x?xf32>
        %5 = tensor.empty(%0, %1) : tensor<?x?xf32>
        %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<?x?xf32>) -> tensor<?x?xf32>
        %7 = linalg.matmul ins(%4, %4 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%6 : tensor<?x?xf32>) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %7, %3, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%3} => !stream.timepoint
    %5 = stream.cmd.execute await(%result_timepoint) => with(%4 as %arg1: !stream.resource<external>{%3}, %result as %arg2: !stream.resource<external>{%3}) {
      stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%0, %1 : index, index) {
        ro %arg1[%c0 for %3] : !stream.resource<external>{%3},
        wo %arg2[%c0 for %3] : !stream.resource<external>{%3}
      }
    } => !stream.timepoint
    %6 = stream.timepoint.await %5 => %result : !stream.resource<external>{%3}
    %7 = stream.tensor.export %6 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
    return %7 : !hal.buffer_view
  }
}


// -----// IR Dump After VerifyLoweringToCmd (iree-stream-verify-lowering-to-cmd) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_DxDxD_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !stream.binding, %arg1: index, %arg2: index, %arg3: !stream.binding) {
        %c0 = arith.constant 0 : index
        %cst = arith.constant 0.000000e+00 : f32
        %0 = flow.dispatch.workload.ordinal %arg1, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg2, 1 : index
        %2 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1}
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        %4 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1} -> tensor<?x?xf32>
        %5 = tensor.empty(%0, %1) : tensor<?x?xf32>
        %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<?x?xf32>) -> tensor<?x?xf32>
        %7 = linalg.matmul ins(%4, %4 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%6 : tensor<?x?xf32>) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %7, %3, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%3} => !stream.timepoint
    %5 = stream.cmd.execute await(%result_timepoint) => with(%4 as %arg1: !stream.resource<external>{%3}, %result as %arg2: !stream.resource<external>{%3}) {
      stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%0, %1 : index, index) {
        ro %arg1[%c0 for %3] : !stream.resource<external>{%3},
        wo %arg2[%c0 for %3] : !stream.resource<external>{%3}
      }
    } => !stream.timepoint
    %6 = stream.timepoint.await %5 => %result : !stream.resource<external>{%3}
    %7 = stream.tensor.export %6 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
    return %7 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
  %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%3} => !stream.timepoint
  %5 = stream.cmd.execute await(%result_timepoint) => with(%4 as %arg1: !stream.resource<external>{%3}, %result as %arg2: !stream.resource<external>{%3}) {
    stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%0, %1 : index, index) {
      ro %arg1[%c0 for %3] : !stream.resource<external>{%3},
      wo %arg2[%c0 for %3] : !stream.resource<external>{%3}
    }
  } => !stream.timepoint
  %6 = stream.timepoint.await %5 => %result : !stream.resource<external>{%3}
  %7 = stream.tensor.export %6 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
  return %7 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
  %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%3} => !stream.timepoint
  %5 = stream.cmd.execute await(%result_timepoint) => with(%4 as %arg1: !stream.resource<external>{%3}, %result as %arg2: !stream.resource<external>{%3}) {
    stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%0, %1 : index, index) {
      ro %arg1[%c0 for %3] : !stream.resource<external>{%3},
      wo %arg2[%c0 for %3] : !stream.resource<external>{%3}
    }
  } => !stream.timepoint
  %6 = stream.timepoint.await %5 => %result : !stream.resource<external>{%3}
  %7 = stream.tensor.export %6 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
  return %7 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
  %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%3} => !stream.timepoint
  %5 = stream.cmd.execute await(%result_timepoint) => with(%4 as %arg1: !stream.resource<external>{%3}, %result as %arg2: !stream.resource<external>{%3}) {
    stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%0, %1 : index, index) {
      ro %arg1[%c0 for %3] : !stream.resource<external>{%3},
      wo %arg2[%c0 for %3] : !stream.resource<external>{%3}
    }
  } => !stream.timepoint
  %6 = stream.timepoint.await %5 => %result : !stream.resource<external>{%3}
  %7 = stream.tensor.export %6 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
  return %7 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_DxDxD_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !stream.binding, %arg1: index, %arg2: index, %arg3: !stream.binding) {
        %c0 = arith.constant 0 : index
        %cst = arith.constant 0.000000e+00 : f32
        %0 = flow.dispatch.workload.ordinal %arg1, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg2, 1 : index
        %2 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1}
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        %4 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1} -> tensor<?x?xf32>
        %5 = tensor.empty(%0, %1) : tensor<?x?xf32>
        %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<?x?xf32>) -> tensor<?x?xf32>
        %7 = linalg.matmul ins(%4, %4 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%6 : tensor<?x?xf32>) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %7, %3, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%3} => !stream.timepoint
    %5 = stream.cmd.execute await(%result_timepoint) => with(%4 as %arg1: !stream.resource<external>{%3}, %result as %arg2: !stream.resource<external>{%3}) {
      stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%0, %1 : index, index) {
        ro %arg1[%c0 for %3] : !stream.resource<external>{%3},
        wo %arg2[%c0 for %3] : !stream.resource<external>{%3}
      }
    } => !stream.timepoint
    %6 = stream.timepoint.await %5 => %result : !stream.resource<external>{%3}
    %7 = stream.tensor.export %6 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
    return %7 : !hal.buffer_view
  }
}


// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_DxDxD_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !stream.binding, %arg1: index, %arg2: index, %arg3: !stream.binding) {
        %c0 = arith.constant 0 : index
        %cst = arith.constant 0.000000e+00 : f32
        %0 = flow.dispatch.workload.ordinal %arg1, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg2, 1 : index
        %2 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1}
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        %4 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1} -> tensor<?x?xf32>
        %5 = tensor.empty(%0, %1) : tensor<?x?xf32>
        %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<?x?xf32>) -> tensor<?x?xf32>
        %7 = linalg.matmul ins(%4, %4 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%6 : tensor<?x?xf32>) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %7, %3, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%3} => !stream.timepoint
    %5 = stream.cmd.execute await(%result_timepoint) => with(%4 as %arg1: !stream.resource<external>{%3}, %result as %arg2: !stream.resource<external>{%3}) {
      stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%0, %1 : index, index) {
        ro %arg1[%c0 for %3] : !stream.resource<external>{%3},
        wo %arg2[%c0 for %3] : !stream.resource<external>{%3}
      }
    } => !stream.timepoint
    %6 = stream.timepoint.await %5 => %result : !stream.resource<external>{%3}
    %7 = stream.tensor.export %6 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
    return %7 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_DxDxD_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !stream.binding, %arg1: index, %arg2: index, %arg3: !stream.binding) {
        %c0 = arith.constant 0 : index
        %cst = arith.constant 0.000000e+00 : f32
        %0 = flow.dispatch.workload.ordinal %arg1, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg2, 1 : index
        %2 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1}
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        %4 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1} -> tensor<?x?xf32>
        %5 = tensor.empty(%0, %1) : tensor<?x?xf32>
        %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<?x?xf32>) -> tensor<?x?xf32>
        %7 = linalg.matmul ins(%4, %4 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%6 : tensor<?x?xf32>) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %7, %3, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%3} => !stream.timepoint
    %5 = stream.cmd.execute await(%result_timepoint) => with(%4 as %arg1: !stream.resource<external>{%3}, %result as %arg2: !stream.resource<external>{%3}) {
      stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%0, %1 : index, index) {
        ro %arg1[%c0 for %3] : !stream.resource<external>{%3},
        wo %arg2[%c0 for %3] : !stream.resource<external>{%3}
      }
    } => !stream.timepoint
    %6 = stream.timepoint.await %5 => %result : !stream.resource<external>{%3}
    %7 = stream.tensor.export %6 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
    return %7 : !hal.buffer_view
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_DxDxD_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !stream.binding, %arg1: index, %arg2: index, %arg3: !stream.binding) {
        %c0 = arith.constant 0 : index
        %cst = arith.constant 0.000000e+00 : f32
        %0 = flow.dispatch.workload.ordinal %arg1, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg2, 1 : index
        %2 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1}
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        %4 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1} -> tensor<?x?xf32>
        %5 = tensor.empty(%0, %1) : tensor<?x?xf32>
        %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<?x?xf32>) -> tensor<?x?xf32>
        %7 = linalg.matmul ins(%4, %4 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%6 : tensor<?x?xf32>) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %7, %3, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%3} => !stream.timepoint
    %5 = stream.cmd.execute await(%result_timepoint) => with(%4 as %arg1: !stream.resource<external>{%3}, %result as %arg2: !stream.resource<external>{%3}) {
      stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%0, %1 : index, index) {
        ro %arg1[%c0 for %3] : !stream.resource<external>{%3},
        wo %arg2[%c0 for %3] : !stream.resource<external>{%3}
      }
    } => !stream.timepoint
    %6 = stream.timepoint.await %5 => %result : !stream.resource<external>{%3}
    %7 = stream.tensor.export %6 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
    return %7 : !hal.buffer_view
  }
}


// -----// IR Dump After SCFToControlFlow (convert-scf-to-cf) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
  %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%3} => !stream.timepoint
  %5 = stream.cmd.execute await(%result_timepoint) => with(%4 as %arg1: !stream.resource<external>{%3}, %result as %arg2: !stream.resource<external>{%3}) {
    stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%0, %1 : index, index) {
      ro %arg1[%c0 for %3] : !stream.resource<external>{%3},
      wo %arg2[%c0 for %3] : !stream.resource<external>{%3}
    }
  } => !stream.timepoint
  %6 = stream.timepoint.await %5 => %result : !stream.resource<external>{%3}
  %7 = stream.tensor.export %6 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
  return %7 : !hal.buffer_view
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
  %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%3} => !stream.timepoint
  %5 = stream.cmd.execute await(%result_timepoint) => with(%4 as %arg1: !stream.resource<external>{%3}, %result as %arg2: !stream.resource<external>{%3}) {
    stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%0, %1 : index, index) {
      ro %arg1[%c0 for %3] : !stream.resource<external>{%3},
      wo %arg2[%c0 for %3] : !stream.resource<external>{%3}
    }
  } => !stream.timepoint
  %6 = stream.timepoint.await %5 => %result : !stream.resource<external>{%3}
  %7 = stream.tensor.export %6 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
  return %7 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
  %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%3} => !stream.timepoint
  %5 = stream.cmd.execute await(%result_timepoint) => with(%4 as %arg1: !stream.resource<external>{%3}, %result as %arg2: !stream.resource<external>{%3}) {
    stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%0, %1 : index, index) {
      ro %arg1[%c0 for %3] : !stream.resource<external>{%3},
      wo %arg2[%c0 for %3] : !stream.resource<external>{%3}
    }
  } => !stream.timepoint
  %6 = stream.timepoint.await %5 => %result : !stream.resource<external>{%3}
  %7 = stream.tensor.export %6 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
  return %7 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
  %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%3} => !stream.timepoint
  %5 = stream.cmd.execute await(%result_timepoint) => with(%4 as %arg1: !stream.resource<external>{%3}, %result as %arg2: !stream.resource<external>{%3}) {
    stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%0, %1 : index, index) {
      ro %arg1[%c0 for %3] : !stream.resource<external>{%3},
      wo %arg2[%c0 for %3] : !stream.resource<external>{%3}
    }
  } => !stream.timepoint
  %6 = stream.timepoint.await %5 => %result : !stream.resource<external>{%3}
  %7 = stream.tensor.export %6 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
  return %7 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda], iree.fixedpoint.iteration = 0 : index} {
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_DxDxD_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !stream.binding, %arg1: index, %arg2: index, %arg3: !stream.binding) {
        %c0 = arith.constant 0 : index
        %cst = arith.constant 0.000000e+00 : f32
        %0 = flow.dispatch.workload.ordinal %arg1, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg2, 1 : index
        %2 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1}
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        %4 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1} -> tensor<?x?xf32>
        %5 = tensor.empty(%0, %1) : tensor<?x?xf32>
        %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<?x?xf32>) -> tensor<?x?xf32>
        %7 = linalg.matmul ins(%4, %4 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%6 : tensor<?x?xf32>) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %7, %3, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%3} => !stream.timepoint
    %5 = stream.cmd.execute await(%result_timepoint) => with(%4 as %arg1: !stream.resource<external>{%3}, %result as %arg2: !stream.resource<external>{%3}) {
      stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%0, %1 : index, index) {
        ro %arg1[%c0 for %3] : !stream.resource<external>{%3},
        wo %arg2[%c0 for %3] : !stream.resource<external>{%3}
      }
    } => !stream.timepoint
    %6 = stream.timepoint.await %5 => %result : !stream.resource<external>{%3}
    %7 = stream.tensor.export %6 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
    return %7 : !hal.buffer_view
  }
}


// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda], iree.fixedpoint.iteration = 0 : index} {
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_DxDxD_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !stream.binding, %arg1: index, %arg2: index, %arg3: !stream.binding) {
        %c0 = arith.constant 0 : index
        %cst = arith.constant 0.000000e+00 : f32
        %0 = flow.dispatch.workload.ordinal %arg1, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg2, 1 : index
        %2 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1}
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        %4 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1} -> tensor<?x?xf32>
        %5 = tensor.empty(%0, %1) : tensor<?x?xf32>
        %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<?x?xf32>) -> tensor<?x?xf32>
        %7 = linalg.matmul ins(%4, %4 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%6 : tensor<?x?xf32>) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %7, %3, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%3} => !stream.timepoint
    %5 = stream.cmd.execute await(%result_timepoint) => with(%4 as %arg1: !stream.resource<external>{%3}, %result as %arg2: !stream.resource<external>{%3}) {
      stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%0, %1 : index, index) {
        ro %arg1[%c0 for %3] : !stream.resource<external>{%3},
        wo %arg2[%c0 for %3] : !stream.resource<external>{%3}
      }
    } => !stream.timepoint
    %6 = stream.timepoint.await %5 => %result : !stream.resource<external>{%3}
    %7 = stream.tensor.export %6 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
    return %7 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda], iree.fixedpoint.iteration = 0 : index} {
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_DxDxD_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !stream.binding, %arg1: index, %arg2: index, %arg3: !stream.binding) {
        %c0 = arith.constant 0 : index
        %cst = arith.constant 0.000000e+00 : f32
        %0 = flow.dispatch.workload.ordinal %arg1, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg2, 1 : index
        %2 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1}
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        %4 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1} -> tensor<?x?xf32>
        %5 = tensor.empty(%0, %1) : tensor<?x?xf32>
        %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<?x?xf32>) -> tensor<?x?xf32>
        %7 = linalg.matmul ins(%4, %4 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%6 : tensor<?x?xf32>) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %7, %3, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%3} => !stream.timepoint
    %5 = stream.cmd.execute await(%result_timepoint) => with(%4 as %arg1: !stream.resource<external>{%3}, %result as %arg2: !stream.resource<external>{%3}) {
      stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%0, %1 : index, index) {
        ro %arg1[%c0 for %3] : !stream.resource<external>{%3},
        wo %arg2[%c0 for %3] : !stream.resource<external>{%3}
      }
    } => !stream.timepoint
    %6 = stream.timepoint.await %5 => %result : !stream.resource<external>{%3}
    %7 = stream.tensor.export %6 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
    return %7 : !hal.buffer_view
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda], iree.fixedpoint.iteration = 0 : index} {
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_DxDxD_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !stream.binding, %arg1: index, %arg2: index, %arg3: !stream.binding) {
        %c0 = arith.constant 0 : index
        %cst = arith.constant 0.000000e+00 : f32
        %0 = flow.dispatch.workload.ordinal %arg1, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg2, 1 : index
        %2 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1}
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        %4 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1} -> tensor<?x?xf32>
        %5 = tensor.empty(%0, %1) : tensor<?x?xf32>
        %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<?x?xf32>) -> tensor<?x?xf32>
        %7 = linalg.matmul ins(%4, %4 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%6 : tensor<?x?xf32>) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %7, %3, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%3} => !stream.timepoint
    %5 = stream.cmd.execute await(%result_timepoint) => with(%4 as %arg1: !stream.resource<external>{%3}, %result as %arg2: !stream.resource<external>{%3}) {
      stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%0, %1 : index, index) {
        ro %arg1[%c0 for %3] : !stream.resource<external>{%3},
        wo %arg2[%c0 for %3] : !stream.resource<external>{%3}
      }
    } => !stream.timepoint
    %6 = stream.timepoint.await %5 => %result : !stream.resource<external>{%3}
    %7 = stream.tensor.export %6 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
    return %7 : !hal.buffer_view
  }
}


// -----// IR Dump After ElideTimepoints (iree-stream-elide-timepoints) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda], iree.fixedpoint.iteration = 0 : index} {
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_DxDxD_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !stream.binding, %arg1: index, %arg2: index, %arg3: !stream.binding) {
        %c0 = arith.constant 0 : index
        %cst = arith.constant 0.000000e+00 : f32
        %0 = flow.dispatch.workload.ordinal %arg1, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg2, 1 : index
        %2 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1}
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        %4 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1} -> tensor<?x?xf32>
        %5 = tensor.empty(%0, %1) : tensor<?x?xf32>
        %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<?x?xf32>) -> tensor<?x?xf32>
        %7 = linalg.matmul ins(%4, %4 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%6 : tensor<?x?xf32>) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %7, %3, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%3} => !stream.timepoint
    %5 = stream.cmd.execute await(%result_timepoint) => with(%4 as %arg1: !stream.resource<external>{%3}, %result as %arg2: !stream.resource<external>{%3}) {
      stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%0, %1 : index, index) {
        ro %arg1[%c0 for %3] : !stream.resource<external>{%3},
        wo %arg2[%c0 for %3] : !stream.resource<external>{%3}
      }
    } => !stream.timepoint
    %6 = stream.timepoint.await %5 => %result : !stream.resource<external>{%3}
    %7 = stream.tensor.export %6 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
    return %7 : !hal.buffer_view
  }
}


// -----// IR Dump After FixedPointIterator (iree-util-fixed-point-iterator) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_DxDxD_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !stream.binding, %arg1: index, %arg2: index, %arg3: !stream.binding) {
        %c0 = arith.constant 0 : index
        %cst = arith.constant 0.000000e+00 : f32
        %0 = flow.dispatch.workload.ordinal %arg1, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg2, 1 : index
        %2 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1}
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        %4 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1} -> tensor<?x?xf32>
        %5 = tensor.empty(%0, %1) : tensor<?x?xf32>
        %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<?x?xf32>) -> tensor<?x?xf32>
        %7 = linalg.matmul ins(%4, %4 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%6 : tensor<?x?xf32>) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %7, %3, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%3} => !stream.timepoint
    %5 = stream.cmd.execute await(%result_timepoint) => with(%4 as %arg1: !stream.resource<external>{%3}, %result as %arg2: !stream.resource<external>{%3}) {
      stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%0, %1 : index, index) {
        ro %arg1[%c0 for %3] : !stream.resource<external>{%3},
        wo %arg2[%c0 for %3] : !stream.resource<external>{%3}
      }
    } => !stream.timepoint
    %6 = stream.timepoint.await %5 => %result : !stream.resource<external>{%3}
    %7 = stream.tensor.export %6 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
    return %7 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseDispatchBindings (iree-stream-fuse-dispatch-bindings) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_DxDxD_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: index, %arg3: index, %arg4: index, %arg5: index) {
        %c0 = arith.constant 0 : index
        %cst = arith.constant 0.000000e+00 : f32
        %0 = flow.dispatch.workload.ordinal %arg4, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg5, 1 : index
        %2 = stream.binding.subspan %arg0[%arg2] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1}
        %3 = stream.binding.subspan %arg1[%arg3] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        %4 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1} -> tensor<?x?xf32>
        %5 = tensor.empty(%0, %1) : tensor<?x?xf32>
        %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<?x?xf32>) -> tensor<?x?xf32>
        %7 = linalg.matmul ins(%4, %4 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%6 : tensor<?x?xf32>) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %7, %3, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index # total size
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%3} => !stream.timepoint
    %c0_0 = arith.constant 0 : index
    %5 = stream.cmd.execute await(%result_timepoint) => with(%4 as %arg1: !stream.resource<external>{%3}, %result as %arg2: !stream.resource<external>{%3}) {
      stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%c0, %c0, %0, %1 : index, index, index, index) {
        ro %arg1[%c0_0 for %3] : !stream.resource<external>{%3},
        wo %arg2[%c0_0 for %3] : !stream.resource<external>{%3}
      }
    } => !stream.timepoint
    %6 = stream.timepoint.await %5 => %result : !stream.resource<external>{%3}
    %7 = stream.tensor.export %6 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
    return %7 : !hal.buffer_view
  }
}


// -----// IR Dump After AnnotateDispatchArguments (iree-stream-annotate-dispatch-arguments) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_DxDxD_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: index {stream.values = [0 : index]}, %arg3: index {stream.values = [0 : index]}, %arg4: index, %arg5: index) {
        %c0 = arith.constant 0 : index
        %cst = arith.constant 0.000000e+00 : f32
        %0 = flow.dispatch.workload.ordinal %arg4, 0 : index
        %1 = flow.dispatch.workload.ordinal %arg5, 1 : index
        %2 = stream.binding.subspan %arg0[%arg2] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1}
        %3 = stream.binding.subspan %arg1[%arg3] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        %4 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%0, %1} -> tensor<?x?xf32>
        %5 = tensor.empty(%0, %1) : tensor<?x?xf32>
        %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<?x?xf32>) -> tensor<?x?xf32>
        %7 = linalg.matmul ins(%4, %4 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%6 : tensor<?x?xf32>) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %7, %3, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%0, %1}
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%3} => !stream.timepoint
    %c0_0 = arith.constant 0 : index
    %5 = stream.cmd.execute await(%result_timepoint) => with(%4 as %arg1: !stream.resource<external>{%3}, %result as %arg2: !stream.resource<external>{%3}) {
      stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%c0, %c0, %0, %1 : index, index, index, index) {
        ro %arg1[%c0_0 for %3] : !stream.resource<external>{%3},
        wo %arg2[%c0_0 for %3] : !stream.resource<external>{%3}
      }
    } => !stream.timepoint
    %6 = stream.timepoint.await %5 => %result : !stream.resource<external>{%3}
    %7 = stream.tensor.export %6 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
    return %7 : !hal.buffer_view
  }
}


// -----// IR Dump After PackDispatchOperands (iree-stream-pack-dispatch-operands) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_DxDxD_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32) {
        %0 = arith.extui %arg2 : i32 to i64
        %1 = arith.extui %arg3 : i32 to i64
        %c32_i64 = arith.constant 32 : i64
        %2 = arith.shli %1, %c32_i64 : i64
        %3 = arith.ori %0, %2 : i64
        %4 = arith.index_castui %3 {stream.values = [0 : index]} : i64 to index
        %5 = arith.extui %arg4 : i32 to i64
        %6 = arith.extui %arg5 : i32 to i64
        %c32_i64_0 = arith.constant 32 : i64
        %7 = arith.shli %6, %c32_i64_0 : i64
        %8 = arith.ori %5, %7 : i64
        %9 = arith.index_castui %8 {stream.values = [0 : index]} : i64 to index
        %10 = arith.extui %arg6 : i32 to i64
        %11 = arith.extui %arg7 : i32 to i64
        %c32_i64_1 = arith.constant 32 : i64
        %12 = arith.shli %11, %c32_i64_1 : i64
        %13 = arith.ori %10, %12 : i64
        %14 = arith.index_castui %13 : i64 to index
        %15 = arith.extui %arg8 : i32 to i64
        %16 = arith.extui %arg9 : i32 to i64
        %c32_i64_2 = arith.constant 32 : i64
        %17 = arith.shli %16, %c32_i64_2 : i64
        %18 = arith.ori %15, %17 : i64
        %19 = arith.index_castui %18 : i64 to index
        %c0 = arith.constant 0 : index
        %cst = arith.constant 0.000000e+00 : f32
        %20 = flow.dispatch.workload.ordinal %14, 0 : index
        %21 = flow.dispatch.workload.ordinal %19, 1 : index
        %22 = stream.binding.subspan %arg0[%4] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%20, %21}
        %23 = stream.binding.subspan %arg1[%9] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%20, %21}
        %24 = flow.dispatch.tensor.load %22, offsets = [0, 0], sizes = [%20, %21], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%20, %21} -> tensor<?x?xf32>
        %25 = tensor.empty(%20, %21) : tensor<?x?xf32>
        %26 = linalg.fill ins(%cst : f32) outs(%25 : tensor<?x?xf32>) -> tensor<?x?xf32>
        %27 = linalg.matmul ins(%24, %24 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%26 : tensor<?x?xf32>) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %27, %23, offsets = [0, 0], sizes = [%20, %21], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%20, %21}
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%3} => !stream.timepoint
    %c0_0 = arith.constant 0 : index
    %c0_i64 = arith.constant 0 : i64
    %c0_i32 = arith.constant 0 : i32
    %c32_i64 = arith.constant 32 : i64
    %c0_i64_1 = arith.constant 0 : i64
    %c0_i32_2 = arith.constant 0 : i32
    %c0_i64_3 = arith.constant 0 : i64
    %c0_i32_4 = arith.constant 0 : i32
    %c32_i64_5 = arith.constant 32 : i64
    %c0_i64_6 = arith.constant 0 : i64
    %c0_i32_7 = arith.constant 0 : i32
    %5 = arith.index_castui %0 : index to i64
    %6 = arith.trunci %5 : i64 to i32
    %c32_i64_8 = arith.constant 32 : i64
    %7 = arith.shrui %5, %c32_i64_8 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %1 : index to i64
    %10 = arith.trunci %9 : i64 to i32
    %c32_i64_9 = arith.constant 32 : i64
    %11 = arith.shrui %9, %c32_i64_9 : i64
    %12 = arith.trunci %11 : i64 to i32
    %13 = stream.cmd.execute await(%result_timepoint) => with(%4 as %arg1: !stream.resource<external>{%3}, %result as %arg2: !stream.resource<external>{%3}) {
      stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%c0_i32, %c0_i32_2, %c0_i32_4, %c0_i32_7, %6, %8, %10, %12 : i32, i32, i32, i32, i32, i32, i32, i32) {
        ro %arg1[%c0_0 for %3] : !stream.resource<external>{%3},
        wo %arg2[%c0_0 for %3] : !stream.resource<external>{%3}
      }
    } => !stream.timepoint
    %14 = stream.timepoint.await %13 => %result : !stream.resource<external>{%3}
    %15 = stream.tensor.export %14 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
    return %15 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c32_i64 = arith.constant 32 : i64
  %c0_i32 = arith.constant 0 : i32
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
  %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%3} => !stream.timepoint
  %5 = arith.index_castui %0 : index to i64
  %6 = arith.trunci %5 : i64 to i32
  %7 = arith.shrui %5, %c32_i64 : i64
  %8 = arith.trunci %7 : i64 to i32
  %9 = arith.index_castui %1 : index to i64
  %10 = arith.trunci %9 : i64 to i32
  %11 = arith.shrui %9, %c32_i64 : i64
  %12 = arith.trunci %11 : i64 to i32
  %13 = stream.cmd.execute await(%result_timepoint) => with(%4 as %arg1: !stream.resource<external>{%3}, %result as %arg2: !stream.resource<external>{%3}) {
    stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%c0_i32, %c0_i32, %c0_i32, %c0_i32, %6, %8, %10, %12 : i32, i32, i32, i32, i32, i32, i32, i32) {
      ro %arg1[%c0 for %3] : !stream.resource<external>{%3},
      wo %arg2[%c0 for %3] : !stream.resource<external>{%3}
    }
  } => !stream.timepoint
  %14 = stream.timepoint.await %13 => %result : !stream.resource<external>{%3}
  %15 = stream.tensor.export %14 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
  return %15 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c32_i64 = arith.constant 32 : i64
  %c0_i32 = arith.constant 0 : i32
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
  %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%3} => !stream.timepoint
  %5 = arith.index_castui %0 : index to i64
  %6 = arith.trunci %5 : i64 to i32
  %7 = arith.shrui %5, %c32_i64 : i64
  %8 = arith.trunci %7 : i64 to i32
  %9 = arith.index_castui %1 : index to i64
  %10 = arith.trunci %9 : i64 to i32
  %11 = arith.shrui %9, %c32_i64 : i64
  %12 = arith.trunci %11 : i64 to i32
  %13 = stream.cmd.execute await(%result_timepoint) => with(%4 as %arg1: !stream.resource<external>{%3}, %result as %arg2: !stream.resource<external>{%3}) {
    stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%c0_i32, %c0_i32, %c0_i32, %c0_i32, %6, %8, %10, %12 : i32, i32, i32, i32, i32, i32, i32, i32) {
      ro %arg1[%c0 for %3] : !stream.resource<external>{%3},
      wo %arg2[%c0 for %3] : !stream.resource<external>{%3}
    }
  } => !stream.timepoint
  %14 = stream.timepoint.await %13 => %result : !stream.resource<external>{%3}
  %15 = stream.tensor.export %14 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
  return %15 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c32_i64 = arith.constant 32 : i64
  %c0_i32 = arith.constant 0 : i32
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
  %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%3} => !stream.timepoint
  %5 = arith.index_castui %0 : index to i64
  %6 = arith.trunci %5 : i64 to i32
  %7 = arith.shrui %5, %c32_i64 : i64
  %8 = arith.trunci %7 : i64 to i32
  %9 = arith.index_castui %1 : index to i64
  %10 = arith.trunci %9 : i64 to i32
  %11 = arith.shrui %9, %c32_i64 : i64
  %12 = arith.trunci %11 : i64 to i32
  %13 = stream.cmd.execute await(%result_timepoint) => with(%4 as %arg1: !stream.resource<external>{%3}, %result as %arg2: !stream.resource<external>{%3}) {
    stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%c0_i32, %c0_i32, %c0_i32, %c0_i32, %6, %8, %10, %12 : i32, i32, i32, i32, i32, i32, i32, i32) {
      ro %arg1[%c0 for %3] : !stream.resource<external>{%3},
      wo %arg2[%c0 for %3] : !stream.resource<external>{%3}
    }
  } => !stream.timepoint
  %14 = stream.timepoint.await %13 => %result : !stream.resource<external>{%3}
  %15 = stream.tensor.export %14 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
  return %15 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_DxDxD_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32) {
        %cst = arith.constant 0.000000e+00 : f32
        %c32_i64 = arith.constant 32 : i64
        %0 = arith.extui %arg2 : i32 to i64
        %1 = arith.extui %arg3 : i32 to i64
        %2 = arith.shli %1, %c32_i64 : i64
        %3 = arith.ori %0, %2 : i64
        %4 = arith.index_castui %3 {stream.values = [0 : index]} : i64 to index
        %5 = arith.extui %arg4 : i32 to i64
        %6 = arith.extui %arg5 : i32 to i64
        %7 = arith.shli %6, %c32_i64 : i64
        %8 = arith.ori %5, %7 : i64
        %9 = arith.index_castui %8 {stream.values = [0 : index]} : i64 to index
        %10 = arith.extui %arg6 : i32 to i64
        %11 = arith.extui %arg7 : i32 to i64
        %12 = arith.shli %11, %c32_i64 : i64
        %13 = arith.ori %10, %12 : i64
        %14 = arith.index_castui %13 : i64 to index
        %15 = arith.extui %arg8 : i32 to i64
        %16 = arith.extui %arg9 : i32 to i64
        %17 = arith.shli %16, %c32_i64 : i64
        %18 = arith.ori %15, %17 : i64
        %19 = arith.index_castui %18 : i64 to index
        %20 = flow.dispatch.workload.ordinal %14, 0 : index
        %21 = flow.dispatch.workload.ordinal %19, 1 : index
        %22 = stream.binding.subspan %arg0[%4] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%20, %21}
        %23 = stream.binding.subspan %arg1[%9] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%20, %21}
        %24 = flow.dispatch.tensor.load %22, offsets = [0, 0], sizes = [%20, %21], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%20, %21} -> tensor<?x?xf32>
        %25 = tensor.empty(%20, %21) : tensor<?x?xf32>
        %26 = linalg.fill ins(%cst : f32) outs(%25 : tensor<?x?xf32>) -> tensor<?x?xf32>
        %27 = linalg.matmul ins(%24, %24 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%26 : tensor<?x?xf32>) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %27, %23, offsets = [0, 0], sizes = [%20, %21], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%20, %21}
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c32_i64 = arith.constant 32 : i64
    %c0_i32 = arith.constant 0 : i32
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%3} => !stream.timepoint
    %5 = arith.index_castui %0 : index to i64
    %6 = arith.trunci %5 : i64 to i32
    %7 = arith.shrui %5, %c32_i64 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %1 : index to i64
    %10 = arith.trunci %9 : i64 to i32
    %11 = arith.shrui %9, %c32_i64 : i64
    %12 = arith.trunci %11 : i64 to i32
    %13 = stream.cmd.execute await(%result_timepoint) => with(%4 as %arg1: !stream.resource<external>{%3}, %result as %arg2: !stream.resource<external>{%3}) {
      stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%c0_i32, %c0_i32, %c0_i32, %c0_i32, %6, %8, %10, %12 : i32, i32, i32, i32, i32, i32, i32, i32) {
        ro %arg1[%c0 for %3] : !stream.resource<external>{%3},
        wo %arg2[%c0 for %3] : !stream.resource<external>{%3}
      }
    } => !stream.timepoint
    %14 = stream.timepoint.await %13 => %result : !stream.resource<external>{%3}
    %15 = stream.tensor.export %14 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
    return %15 : !hal.buffer_view
  }
}


// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_DxDxD_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32) {
        %cst = arith.constant 0.000000e+00 : f32
        %c32_i64 = arith.constant 32 : i64
        %0 = arith.extui %arg2 : i32 to i64
        %1 = arith.extui %arg3 : i32 to i64
        %2 = arith.shli %1, %c32_i64 : i64
        %3 = arith.ori %0, %2 : i64
        %4 = arith.index_castui %3 {stream.values = [0 : index]} : i64 to index
        %5 = arith.extui %arg4 : i32 to i64
        %6 = arith.extui %arg5 : i32 to i64
        %7 = arith.shli %6, %c32_i64 : i64
        %8 = arith.ori %5, %7 : i64
        %9 = arith.index_castui %8 {stream.values = [0 : index]} : i64 to index
        %10 = arith.extui %arg6 : i32 to i64
        %11 = arith.extui %arg7 : i32 to i64
        %12 = arith.shli %11, %c32_i64 : i64
        %13 = arith.ori %10, %12 : i64
        %14 = arith.index_castui %13 : i64 to index
        %15 = arith.extui %arg8 : i32 to i64
        %16 = arith.extui %arg9 : i32 to i64
        %17 = arith.shli %16, %c32_i64 : i64
        %18 = arith.ori %15, %17 : i64
        %19 = arith.index_castui %18 : i64 to index
        %20 = flow.dispatch.workload.ordinal %14, 0 : index
        %21 = flow.dispatch.workload.ordinal %19, 1 : index
        %22 = stream.binding.subspan %arg0[%4] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%20, %21}
        %23 = stream.binding.subspan %arg1[%9] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%20, %21}
        %24 = flow.dispatch.tensor.load %22, offsets = [0, 0], sizes = [%20, %21], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%20, %21} -> tensor<?x?xf32>
        %25 = tensor.empty(%20, %21) : tensor<?x?xf32>
        %26 = linalg.fill ins(%cst : f32) outs(%25 : tensor<?x?xf32>) -> tensor<?x?xf32>
        %27 = linalg.matmul ins(%24, %24 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%26 : tensor<?x?xf32>) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %27, %23, offsets = [0, 0], sizes = [%20, %21], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%20, %21}
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c32_i64 = arith.constant 32 : i64
    %c0_i32 = arith.constant 0 : i32
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%3} => !stream.timepoint
    %5 = arith.index_castui %0 : index to i64
    %6 = arith.trunci %5 : i64 to i32
    %7 = arith.shrui %5, %c32_i64 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %1 : index to i64
    %10 = arith.trunci %9 : i64 to i32
    %11 = arith.shrui %9, %c32_i64 : i64
    %12 = arith.trunci %11 : i64 to i32
    %13 = stream.cmd.execute await(%result_timepoint) => with(%4 as %arg1: !stream.resource<external>{%3}, %result as %arg2: !stream.resource<external>{%3}) {
      stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%c0_i32, %c0_i32, %c0_i32, %c0_i32, %6, %8, %10, %12 : i32, i32, i32, i32, i32, i32, i32, i32) {
        ro %arg1[%c0 for %3] : !stream.resource<external>{%3},
        wo %arg2[%c0 for %3] : !stream.resource<external>{%3}
      }
    } => !stream.timepoint
    %14 = stream.timepoint.await %13 => %result : !stream.resource<external>{%3}
    %15 = stream.tensor.export %14 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
    return %15 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_DxDxD_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32) {
        %cst = arith.constant 0.000000e+00 : f32
        %c32_i64 = arith.constant 32 : i64
        %0 = arith.extui %arg2 : i32 to i64
        %1 = arith.extui %arg3 : i32 to i64
        %2 = arith.shli %1, %c32_i64 : i64
        %3 = arith.ori %0, %2 : i64
        %4 = arith.index_castui %3 {stream.values = [0 : index]} : i64 to index
        %5 = arith.extui %arg4 : i32 to i64
        %6 = arith.extui %arg5 : i32 to i64
        %7 = arith.shli %6, %c32_i64 : i64
        %8 = arith.ori %5, %7 : i64
        %9 = arith.index_castui %8 {stream.values = [0 : index]} : i64 to index
        %10 = arith.extui %arg6 : i32 to i64
        %11 = arith.extui %arg7 : i32 to i64
        %12 = arith.shli %11, %c32_i64 : i64
        %13 = arith.ori %10, %12 : i64
        %14 = arith.index_castui %13 : i64 to index
        %15 = arith.extui %arg8 : i32 to i64
        %16 = arith.extui %arg9 : i32 to i64
        %17 = arith.shli %16, %c32_i64 : i64
        %18 = arith.ori %15, %17 : i64
        %19 = arith.index_castui %18 : i64 to index
        %20 = flow.dispatch.workload.ordinal %14, 0 : index
        %21 = flow.dispatch.workload.ordinal %19, 1 : index
        %22 = stream.binding.subspan %arg0[%4] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%20, %21}
        %23 = stream.binding.subspan %arg1[%9] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%20, %21}
        %24 = flow.dispatch.tensor.load %22, offsets = [0, 0], sizes = [%20, %21], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%20, %21} -> tensor<?x?xf32>
        %25 = tensor.empty(%20, %21) : tensor<?x?xf32>
        %26 = linalg.fill ins(%cst : f32) outs(%25 : tensor<?x?xf32>) -> tensor<?x?xf32>
        %27 = linalg.matmul ins(%24, %24 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%26 : tensor<?x?xf32>) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %27, %23, offsets = [0, 0], sizes = [%20, %21], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%20, %21}
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c32_i64 = arith.constant 32 : i64
    %c0_i32 = arith.constant 0 : i32
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%3} => !stream.timepoint
    %5 = arith.index_castui %0 : index to i64
    %6 = arith.trunci %5 : i64 to i32
    %7 = arith.shrui %5, %c32_i64 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %1 : index to i64
    %10 = arith.trunci %9 : i64 to i32
    %11 = arith.shrui %9, %c32_i64 : i64
    %12 = arith.trunci %11 : i64 to i32
    %13 = stream.cmd.execute await(%result_timepoint) => with(%4 as %arg1: !stream.resource<external>{%3}, %result as %arg2: !stream.resource<external>{%3}) {
      stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%c0_i32, %c0_i32, %c0_i32, %c0_i32, %6, %8, %10, %12 : i32, i32, i32, i32, i32, i32, i32, i32) {
        ro %arg1[%c0 for %3] : !stream.resource<external>{%3},
        wo %arg2[%c0 for %3] : !stream.resource<external>{%3}
      }
    } => !stream.timepoint
    %14 = stream.timepoint.await %13 => %result : !stream.resource<external>{%3}
    %15 = stream.tensor.export %14 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
    return %15 : !hal.buffer_view
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_DxDxD_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32) {
        %cst = arith.constant 0.000000e+00 : f32
        %c32_i64 = arith.constant 32 : i64
        %0 = arith.extui %arg2 : i32 to i64
        %1 = arith.extui %arg3 : i32 to i64
        %2 = arith.shli %1, %c32_i64 : i64
        %3 = arith.ori %0, %2 : i64
        %4 = arith.index_castui %3 {stream.values = [0 : index]} : i64 to index
        %5 = arith.extui %arg4 : i32 to i64
        %6 = arith.extui %arg5 : i32 to i64
        %7 = arith.shli %6, %c32_i64 : i64
        %8 = arith.ori %5, %7 : i64
        %9 = arith.index_castui %8 {stream.values = [0 : index]} : i64 to index
        %10 = arith.extui %arg6 : i32 to i64
        %11 = arith.extui %arg7 : i32 to i64
        %12 = arith.shli %11, %c32_i64 : i64
        %13 = arith.ori %10, %12 : i64
        %14 = arith.index_castui %13 : i64 to index
        %15 = arith.extui %arg8 : i32 to i64
        %16 = arith.extui %arg9 : i32 to i64
        %17 = arith.shli %16, %c32_i64 : i64
        %18 = arith.ori %15, %17 : i64
        %19 = arith.index_castui %18 : i64 to index
        %20 = flow.dispatch.workload.ordinal %14, 0 : index
        %21 = flow.dispatch.workload.ordinal %19, 1 : index
        %22 = stream.binding.subspan %arg0[%4] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%20, %21}
        %23 = stream.binding.subspan %arg1[%9] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%20, %21}
        %24 = flow.dispatch.tensor.load %22, offsets = [0, 0], sizes = [%20, %21], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%20, %21} -> tensor<?x?xf32>
        %25 = tensor.empty(%20, %21) : tensor<?x?xf32>
        %26 = linalg.fill ins(%cst : f32) outs(%25 : tensor<?x?xf32>) -> tensor<?x?xf32>
        %27 = linalg.matmul ins(%24, %24 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%26 : tensor<?x?xf32>) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %27, %23, offsets = [0, 0], sizes = [%20, %21], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%20, %21}
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c32_i64 = arith.constant 32 : i64
    %c0_i32 = arith.constant 0 : i32
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%3} => !stream.timepoint
    %5 = arith.index_castui %0 : index to i64
    %6 = arith.trunci %5 : i64 to i32
    %7 = arith.shrui %5, %c32_i64 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %1 : index to i64
    %10 = arith.trunci %9 : i64 to i32
    %11 = arith.shrui %9, %c32_i64 : i64
    %12 = arith.trunci %11 : i64 to i32
    %13 = stream.cmd.execute await(%result_timepoint) => with(%4 as %arg1: !stream.resource<external>{%3}, %result as %arg2: !stream.resource<external>{%3}) {
      stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%c0_i32, %c0_i32, %c0_i32, %c0_i32, %6, %8, %10, %12 : i32, i32, i32, i32, i32, i32, i32, i32) {
        ro %arg1[%c0 for %3] : !stream.resource<external>{%3},
        wo %arg2[%c0 for %3] : !stream.resource<external>{%3}
      }
    } => !stream.timepoint
    %14 = stream.timepoint.await %13 => %result : !stream.resource<external>{%3}
    %15 = stream.tensor.export %14 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
    return %15 : !hal.buffer_view
  }
}


// -----// IR Dump After FoldUniformOperands (iree-stream-fold-uniform-operands) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_DxDxD_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32) {
        %c0_i32 = arith.constant 0 : i32
        %cst = arith.constant 0.000000e+00 : f32
        %c32_i64 = arith.constant 32 : i64
        %0 = arith.extui %c0_i32 : i32 to i64
        %1 = arith.extui %c0_i32 : i32 to i64
        %2 = arith.shli %1, %c32_i64 : i64
        %3 = arith.ori %0, %2 : i64
        %4 = arith.index_castui %3 {stream.values = [0 : index]} : i64 to index
        %5 = arith.extui %c0_i32 : i32 to i64
        %6 = arith.extui %c0_i32 : i32 to i64
        %7 = arith.shli %6, %c32_i64 : i64
        %8 = arith.ori %5, %7 : i64
        %9 = arith.index_castui %8 {stream.values = [0 : index]} : i64 to index
        %10 = arith.extui %arg2 : i32 to i64
        %11 = arith.extui %arg3 : i32 to i64
        %12 = arith.shli %11, %c32_i64 : i64
        %13 = arith.ori %10, %12 : i64
        %14 = arith.index_castui %13 : i64 to index
        %15 = arith.extui %arg4 : i32 to i64
        %16 = arith.extui %arg5 : i32 to i64
        %17 = arith.shli %16, %c32_i64 : i64
        %18 = arith.ori %15, %17 : i64
        %19 = arith.index_castui %18 : i64 to index
        %20 = flow.dispatch.workload.ordinal %14, 0 : index
        %21 = flow.dispatch.workload.ordinal %19, 1 : index
        %22 = stream.binding.subspan %arg0[%4] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%20, %21}
        %23 = stream.binding.subspan %arg1[%9] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%20, %21}
        %24 = flow.dispatch.tensor.load %22, offsets = [0, 0], sizes = [%20, %21], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%20, %21} -> tensor<?x?xf32>
        %25 = tensor.empty(%20, %21) : tensor<?x?xf32>
        %26 = linalg.fill ins(%cst : f32) outs(%25 : tensor<?x?xf32>) -> tensor<?x?xf32>
        %27 = linalg.matmul ins(%24, %24 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%26 : tensor<?x?xf32>) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %27, %23, offsets = [0, 0], sizes = [%20, %21], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%20, %21}
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c32_i64 = arith.constant 32 : i64
    %c0_i32 = arith.constant 0 : i32
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%3} => !stream.timepoint
    %5 = arith.index_castui %0 : index to i64
    %6 = arith.trunci %5 : i64 to i32
    %7 = arith.shrui %5, %c32_i64 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %1 : index to i64
    %10 = arith.trunci %9 : i64 to i32
    %11 = arith.shrui %9, %c32_i64 : i64
    %12 = arith.trunci %11 : i64 to i32
    %13 = stream.cmd.execute await(%result_timepoint) => with(%4 as %arg1: !stream.resource<external>{%3}, %result as %arg2: !stream.resource<external>{%3}) {
      stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%6, %8, %10, %12 : i32, i32, i32, i32) {
        ro %arg1[%c0 for %3] : !stream.resource<external>{%3},
        wo %arg2[%c0 for %3] : !stream.resource<external>{%3}
      }
    } => !stream.timepoint
    %14 = stream.timepoint.await %13 => %result : !stream.resource<external>{%3}
    %15 = stream.tensor.export %14 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
    return %15 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c32_i64 = arith.constant 32 : i64
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
  %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%3} => !stream.timepoint
  %5 = arith.index_castui %0 : index to i64
  %6 = arith.trunci %5 : i64 to i32
  %7 = arith.shrui %5, %c32_i64 : i64
  %8 = arith.trunci %7 : i64 to i32
  %9 = arith.index_castui %1 : index to i64
  %10 = arith.trunci %9 : i64 to i32
  %11 = arith.shrui %9, %c32_i64 : i64
  %12 = arith.trunci %11 : i64 to i32
  %13 = stream.cmd.execute await(%result_timepoint) => with(%4 as %arg1: !stream.resource<external>{%3}, %result as %arg2: !stream.resource<external>{%3}) {
    stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%6, %8, %10, %12 : i32, i32, i32, i32) {
      ro %arg1[%c0 for %3] : !stream.resource<external>{%3},
      wo %arg2[%c0 for %3] : !stream.resource<external>{%3}
    }
  } => !stream.timepoint
  %14 = stream.timepoint.await %13 => %result : !stream.resource<external>{%3}
  %15 = stream.tensor.export %14 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
  return %15 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c32_i64 = arith.constant 32 : i64
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
  %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%3} => !stream.timepoint
  %5 = arith.index_castui %0 : index to i64
  %6 = arith.trunci %5 : i64 to i32
  %7 = arith.shrui %5, %c32_i64 : i64
  %8 = arith.trunci %7 : i64 to i32
  %9 = arith.index_castui %1 : index to i64
  %10 = arith.trunci %9 : i64 to i32
  %11 = arith.shrui %9, %c32_i64 : i64
  %12 = arith.trunci %11 : i64 to i32
  %13 = stream.cmd.execute await(%result_timepoint) => with(%4 as %arg1: !stream.resource<external>{%3}, %result as %arg2: !stream.resource<external>{%3}) {
    stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%6, %8, %10, %12 : i32, i32, i32, i32) {
      ro %arg1[%c0 for %3] : !stream.resource<external>{%3},
      wo %arg2[%c0 for %3] : !stream.resource<external>{%3}
    }
  } => !stream.timepoint
  %14 = stream.timepoint.await %13 => %result : !stream.resource<external>{%3}
  %15 = stream.tensor.export %14 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
  return %15 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c32_i64 = arith.constant 32 : i64
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
  %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%3} => !stream.timepoint
  %5 = arith.index_castui %0 : index to i64
  %6 = arith.trunci %5 : i64 to i32
  %7 = arith.shrui %5, %c32_i64 : i64
  %8 = arith.trunci %7 : i64 to i32
  %9 = arith.index_castui %1 : index to i64
  %10 = arith.trunci %9 : i64 to i32
  %11 = arith.shrui %9, %c32_i64 : i64
  %12 = arith.trunci %11 : i64 to i32
  %13 = stream.cmd.execute await(%result_timepoint) => with(%4 as %arg1: !stream.resource<external>{%3}, %result as %arg2: !stream.resource<external>{%3}) {
    stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%6, %8, %10, %12 : i32, i32, i32, i32) {
      ro %arg1[%c0 for %3] : !stream.resource<external>{%3},
      wo %arg2[%c0 for %3] : !stream.resource<external>{%3}
    }
  } => !stream.timepoint
  %14 = stream.timepoint.await %13 => %result : !stream.resource<external>{%3}
  %15 = stream.tensor.export %14 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
  return %15 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_DxDxD_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32) {
        %c0 = arith.constant 0 : index
        %cst = arith.constant 0.000000e+00 : f32
        %c32_i64 = arith.constant 32 : i64
        %0 = arith.extui %arg2 : i32 to i64
        %1 = arith.extui %arg3 : i32 to i64
        %2 = arith.shli %1, %c32_i64 : i64
        %3 = arith.ori %0, %2 : i64
        %4 = arith.index_castui %3 : i64 to index
        %5 = arith.extui %arg4 : i32 to i64
        %6 = arith.extui %arg5 : i32 to i64
        %7 = arith.shli %6, %c32_i64 : i64
        %8 = arith.ori %5, %7 : i64
        %9 = arith.index_castui %8 : i64 to index
        %10 = flow.dispatch.workload.ordinal %4, 0 : index
        %11 = flow.dispatch.workload.ordinal %9, 1 : index
        %12 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%10, %11}
        %13 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%10, %11}
        %14 = flow.dispatch.tensor.load %12, offsets = [0, 0], sizes = [%10, %11], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%10, %11} -> tensor<?x?xf32>
        %15 = tensor.empty(%10, %11) : tensor<?x?xf32>
        %16 = linalg.fill ins(%cst : f32) outs(%15 : tensor<?x?xf32>) -> tensor<?x?xf32>
        %17 = linalg.matmul ins(%14, %14 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%16 : tensor<?x?xf32>) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %17, %13, offsets = [0, 0], sizes = [%10, %11], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%10, %11}
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c32_i64 = arith.constant 32 : i64
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%3} => !stream.timepoint
    %5 = arith.index_castui %0 : index to i64
    %6 = arith.trunci %5 : i64 to i32
    %7 = arith.shrui %5, %c32_i64 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %1 : index to i64
    %10 = arith.trunci %9 : i64 to i32
    %11 = arith.shrui %9, %c32_i64 : i64
    %12 = arith.trunci %11 : i64 to i32
    %13 = stream.cmd.execute await(%result_timepoint) => with(%4 as %arg1: !stream.resource<external>{%3}, %result as %arg2: !stream.resource<external>{%3}) {
      stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%6, %8, %10, %12 : i32, i32, i32, i32) {
        ro %arg1[%c0 for %3] : !stream.resource<external>{%3},
        wo %arg2[%c0 for %3] : !stream.resource<external>{%3}
      }
    } => !stream.timepoint
    %14 = stream.timepoint.await %13 => %result : !stream.resource<external>{%3}
    %15 = stream.tensor.export %14 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
    return %15 : !hal.buffer_view
  }
}


// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_DxDxD_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32) {
        %c0 = arith.constant 0 : index
        %cst = arith.constant 0.000000e+00 : f32
        %c32_i64 = arith.constant 32 : i64
        %0 = arith.extui %arg2 : i32 to i64
        %1 = arith.extui %arg3 : i32 to i64
        %2 = arith.shli %1, %c32_i64 : i64
        %3 = arith.ori %0, %2 : i64
        %4 = arith.index_castui %3 : i64 to index
        %5 = arith.extui %arg4 : i32 to i64
        %6 = arith.extui %arg5 : i32 to i64
        %7 = arith.shli %6, %c32_i64 : i64
        %8 = arith.ori %5, %7 : i64
        %9 = arith.index_castui %8 : i64 to index
        %10 = flow.dispatch.workload.ordinal %4, 0 : index
        %11 = flow.dispatch.workload.ordinal %9, 1 : index
        %12 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%10, %11}
        %13 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%10, %11}
        %14 = flow.dispatch.tensor.load %12, offsets = [0, 0], sizes = [%10, %11], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%10, %11} -> tensor<?x?xf32>
        %15 = tensor.empty(%10, %11) : tensor<?x?xf32>
        %16 = linalg.fill ins(%cst : f32) outs(%15 : tensor<?x?xf32>) -> tensor<?x?xf32>
        %17 = linalg.matmul ins(%14, %14 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%16 : tensor<?x?xf32>) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %17, %13, offsets = [0, 0], sizes = [%10, %11], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%10, %11}
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c32_i64 = arith.constant 32 : i64
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%3} => !stream.timepoint
    %5 = arith.index_castui %0 : index to i64
    %6 = arith.trunci %5 : i64 to i32
    %7 = arith.shrui %5, %c32_i64 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %1 : index to i64
    %10 = arith.trunci %9 : i64 to i32
    %11 = arith.shrui %9, %c32_i64 : i64
    %12 = arith.trunci %11 : i64 to i32
    %13 = stream.cmd.execute await(%result_timepoint) => with(%4 as %arg1: !stream.resource<external>{%3}, %result as %arg2: !stream.resource<external>{%3}) {
      stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%6, %8, %10, %12 : i32, i32, i32, i32) {
        ro %arg1[%c0 for %3] : !stream.resource<external>{%3},
        wo %arg2[%c0 for %3] : !stream.resource<external>{%3}
      }
    } => !stream.timepoint
    %14 = stream.timepoint.await %13 => %result : !stream.resource<external>{%3}
    %15 = stream.tensor.export %14 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
    return %15 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_DxDxD_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32) {
        %c0 = arith.constant 0 : index
        %cst = arith.constant 0.000000e+00 : f32
        %c32_i64 = arith.constant 32 : i64
        %0 = arith.extui %arg2 : i32 to i64
        %1 = arith.extui %arg3 : i32 to i64
        %2 = arith.shli %1, %c32_i64 : i64
        %3 = arith.ori %0, %2 : i64
        %4 = arith.index_castui %3 : i64 to index
        %5 = arith.extui %arg4 : i32 to i64
        %6 = arith.extui %arg5 : i32 to i64
        %7 = arith.shli %6, %c32_i64 : i64
        %8 = arith.ori %5, %7 : i64
        %9 = arith.index_castui %8 : i64 to index
        %10 = flow.dispatch.workload.ordinal %4, 0 : index
        %11 = flow.dispatch.workload.ordinal %9, 1 : index
        %12 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%10, %11}
        %13 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%10, %11}
        %14 = flow.dispatch.tensor.load %12, offsets = [0, 0], sizes = [%10, %11], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%10, %11} -> tensor<?x?xf32>
        %15 = tensor.empty(%10, %11) : tensor<?x?xf32>
        %16 = linalg.fill ins(%cst : f32) outs(%15 : tensor<?x?xf32>) -> tensor<?x?xf32>
        %17 = linalg.matmul ins(%14, %14 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%16 : tensor<?x?xf32>) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %17, %13, offsets = [0, 0], sizes = [%10, %11], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%10, %11}
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c32_i64 = arith.constant 32 : i64
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%3} => !stream.timepoint
    %5 = arith.index_castui %0 : index to i64
    %6 = arith.trunci %5 : i64 to i32
    %7 = arith.shrui %5, %c32_i64 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %1 : index to i64
    %10 = arith.trunci %9 : i64 to i32
    %11 = arith.shrui %9, %c32_i64 : i64
    %12 = arith.trunci %11 : i64 to i32
    %13 = stream.cmd.execute await(%result_timepoint) => with(%4 as %arg1: !stream.resource<external>{%3}, %result as %arg2: !stream.resource<external>{%3}) {
      stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%6, %8, %10, %12 : i32, i32, i32, i32) {
        ro %arg1[%c0 for %3] : !stream.resource<external>{%3},
        wo %arg2[%c0 for %3] : !stream.resource<external>{%3}
      }
    } => !stream.timepoint
    %14 = stream.timepoint.await %13 => %result : !stream.resource<external>{%3}
    %15 = stream.tensor.export %14 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
    return %15 : !hal.buffer_view
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_DxDxD_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32) {
        %c0 = arith.constant 0 : index
        %cst = arith.constant 0.000000e+00 : f32
        %c32_i64 = arith.constant 32 : i64
        %0 = arith.extui %arg2 : i32 to i64
        %1 = arith.extui %arg3 : i32 to i64
        %2 = arith.shli %1, %c32_i64 : i64
        %3 = arith.ori %0, %2 : i64
        %4 = arith.index_castui %3 : i64 to index
        %5 = arith.extui %arg4 : i32 to i64
        %6 = arith.extui %arg5 : i32 to i64
        %7 = arith.shli %6, %c32_i64 : i64
        %8 = arith.ori %5, %7 : i64
        %9 = arith.index_castui %8 : i64 to index
        %10 = flow.dispatch.workload.ordinal %4, 0 : index
        %11 = flow.dispatch.workload.ordinal %9, 1 : index
        %12 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%10, %11}
        %13 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%10, %11}
        %14 = flow.dispatch.tensor.load %12, offsets = [0, 0], sizes = [%10, %11], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%10, %11} -> tensor<?x?xf32>
        %15 = tensor.empty(%10, %11) : tensor<?x?xf32>
        %16 = linalg.fill ins(%cst : f32) outs(%15 : tensor<?x?xf32>) -> tensor<?x?xf32>
        %17 = linalg.matmul ins(%14, %14 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%16 : tensor<?x?xf32>) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %17, %13, offsets = [0, 0], sizes = [%10, %11], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%10, %11}
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c32_i64 = arith.constant 32 : i64
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%3} => !stream.timepoint
    %5 = arith.index_castui %0 : index to i64
    %6 = arith.trunci %5 : i64 to i32
    %7 = arith.shrui %5, %c32_i64 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %1 : index to i64
    %10 = arith.trunci %9 : i64 to i32
    %11 = arith.shrui %9, %c32_i64 : i64
    %12 = arith.trunci %11 : i64 to i32
    %13 = stream.cmd.execute await(%result_timepoint) => with(%4 as %arg1: !stream.resource<external>{%3}, %result as %arg2: !stream.resource<external>{%3}) {
      stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%6, %8, %10, %12 : i32, i32, i32, i32) {
        ro %arg1[%c0 for %3] : !stream.resource<external>{%3},
        wo %arg2[%c0 for %3] : !stream.resource<external>{%3}
      }
    } => !stream.timepoint
    %14 = stream.timepoint.await %13 => %result : !stream.resource<external>{%3}
    %15 = stream.tensor.export %14 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
    return %15 : !hal.buffer_view
  }
}


// -----// IR Dump After SymbolDCE (symbol-dce) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_DxDxD_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32) {
        %c0 = arith.constant 0 : index
        %cst = arith.constant 0.000000e+00 : f32
        %c32_i64 = arith.constant 32 : i64
        %0 = arith.extui %arg2 : i32 to i64
        %1 = arith.extui %arg3 : i32 to i64
        %2 = arith.shli %1, %c32_i64 : i64
        %3 = arith.ori %0, %2 : i64
        %4 = arith.index_castui %3 : i64 to index
        %5 = arith.extui %arg4 : i32 to i64
        %6 = arith.extui %arg5 : i32 to i64
        %7 = arith.shli %6, %c32_i64 : i64
        %8 = arith.ori %5, %7 : i64
        %9 = arith.index_castui %8 : i64 to index
        %10 = flow.dispatch.workload.ordinal %4, 0 : index
        %11 = flow.dispatch.workload.ordinal %9, 1 : index
        %12 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%10, %11}
        %13 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%10, %11}
        %14 = flow.dispatch.tensor.load %12, offsets = [0, 0], sizes = [%10, %11], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%10, %11} -> tensor<?x?xf32>
        %15 = tensor.empty(%10, %11) : tensor<?x?xf32>
        %16 = linalg.fill ins(%cst : f32) outs(%15 : tensor<?x?xf32>) -> tensor<?x?xf32>
        %17 = linalg.matmul ins(%14, %14 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%16 : tensor<?x?xf32>) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %17, %13, offsets = [0, 0], sizes = [%10, %11], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%10, %11}
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c32_i64 = arith.constant 32 : i64
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%3} => !stream.timepoint
    %5 = arith.index_castui %0 : index to i64
    %6 = arith.trunci %5 : i64 to i32
    %7 = arith.shrui %5, %c32_i64 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %1 : index to i64
    %10 = arith.trunci %9 : i64 to i32
    %11 = arith.shrui %9, %c32_i64 : i64
    %12 = arith.trunci %11 : i64 to i32
    %13 = stream.cmd.execute await(%result_timepoint) => with(%4 as %arg1: !stream.resource<external>{%3}, %result as %arg2: !stream.resource<external>{%3}) {
      stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%6, %8, %10, %12 : i32, i32, i32, i32) {
        ro %arg1[%c0 for %3] : !stream.resource<external>{%3},
        wo %arg2[%c0 for %3] : !stream.resource<external>{%3}
      }
    } => !stream.timepoint
    %14 = stream.timepoint.await %13 => %result : !stream.resource<external>{%3}
    %15 = stream.tensor.export %14 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
    return %15 : !hal.buffer_view
  }
}


// -----// IR Dump After CSE (cse) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_DxDxD_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32) {
        %c0 = arith.constant 0 : index
        %cst = arith.constant 0.000000e+00 : f32
        %c32_i64 = arith.constant 32 : i64
        %0 = arith.extui %arg2 : i32 to i64
        %1 = arith.extui %arg3 : i32 to i64
        %2 = arith.shli %1, %c32_i64 : i64
        %3 = arith.ori %0, %2 : i64
        %4 = arith.index_castui %3 : i64 to index
        %5 = arith.extui %arg4 : i32 to i64
        %6 = arith.extui %arg5 : i32 to i64
        %7 = arith.shli %6, %c32_i64 : i64
        %8 = arith.ori %5, %7 : i64
        %9 = arith.index_castui %8 : i64 to index
        %10 = flow.dispatch.workload.ordinal %4, 0 : index
        %11 = flow.dispatch.workload.ordinal %9, 1 : index
        %12 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%10, %11}
        %13 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%10, %11}
        %14 = flow.dispatch.tensor.load %12, offsets = [0, 0], sizes = [%10, %11], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%10, %11} -> tensor<?x?xf32>
        %15 = tensor.empty(%10, %11) : tensor<?x?xf32>
        %16 = linalg.fill ins(%cst : f32) outs(%15 : tensor<?x?xf32>) -> tensor<?x?xf32>
        %17 = linalg.matmul ins(%14, %14 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%16 : tensor<?x?xf32>) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %17, %13, offsets = [0, 0], sizes = [%10, %11], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%10, %11}
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c32_i64 = arith.constant 32 : i64
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%3} => !stream.timepoint
    %5 = arith.index_castui %0 : index to i64
    %6 = arith.trunci %5 : i64 to i32
    %7 = arith.shrui %5, %c32_i64 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %1 : index to i64
    %10 = arith.trunci %9 : i64 to i32
    %11 = arith.shrui %9, %c32_i64 : i64
    %12 = arith.trunci %11 : i64 to i32
    %13 = stream.cmd.execute await(%result_timepoint) => with(%4 as %arg1: !stream.resource<external>{%3}, %result as %arg2: !stream.resource<external>{%3}) {
      stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%6, %8, %10, %12 : i32, i32, i32, i32) {
        ro %arg1[%c0 for %3] : !stream.resource<external>{%3},
        wo %arg2[%c0 for %3] : !stream.resource<external>{%3}
      }
    } => !stream.timepoint
    %14 = stream.timepoint.await %13 => %result : !stream.resource<external>{%3}
    %15 = stream.tensor.export %14 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
    return %15 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_DxDxD_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32) {
        %c0 = arith.constant 0 : index
        %cst = arith.constant 0.000000e+00 : f32
        %c32_i64 = arith.constant 32 : i64
        %0 = arith.extui %arg2 : i32 to i64
        %1 = arith.extui %arg3 : i32 to i64
        %2 = arith.shli %1, %c32_i64 : i64
        %3 = arith.ori %0, %2 : i64
        %4 = arith.index_castui %3 : i64 to index
        %5 = arith.extui %arg4 : i32 to i64
        %6 = arith.extui %arg5 : i32 to i64
        %7 = arith.shli %6, %c32_i64 : i64
        %8 = arith.ori %5, %7 : i64
        %9 = arith.index_castui %8 : i64 to index
        %10 = flow.dispatch.workload.ordinal %4, 0 : index
        %11 = flow.dispatch.workload.ordinal %9, 1 : index
        %12 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%10, %11}
        %13 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%10, %11}
        %14 = flow.dispatch.tensor.load %12, offsets = [0, 0], sizes = [%10, %11], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%10, %11} -> tensor<?x?xf32>
        %15 = tensor.empty(%10, %11) : tensor<?x?xf32>
        %16 = linalg.fill ins(%cst : f32) outs(%15 : tensor<?x?xf32>) -> tensor<?x?xf32>
        %17 = linalg.matmul ins(%14, %14 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%16 : tensor<?x?xf32>) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %17, %13, offsets = [0, 0], sizes = [%10, %11], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%10, %11}
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c32_i64 = arith.constant 32 : i64
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%3} => !stream.timepoint
    %5 = arith.index_castui %0 : index to i64
    %6 = arith.trunci %5 : i64 to i32
    %7 = arith.shrui %5, %c32_i64 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %1 : index to i64
    %10 = arith.trunci %9 : i64 to i32
    %11 = arith.shrui %9, %c32_i64 : i64
    %12 = arith.trunci %11 : i64 to i32
    %13 = stream.cmd.execute await(%result_timepoint) => with(%4 as %arg1: !stream.resource<external>{%3}, %result as %arg2: !stream.resource<external>{%3}) {
      stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%6, %8, %10, %12 : i32, i32, i32, i32) {
        ro %arg1[%c0 for %3] : !stream.resource<external>{%3},
        wo %arg2[%c0 for %3] : !stream.resource<external>{%3}
      }
    } => !stream.timepoint
    %14 = stream.timepoint.await %13 => %result : !stream.resource<external>{%3}
    %15 = stream.tensor.export %14 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
    return %15 : !hal.buffer_view
  }
}


// -----// IR Dump After CSE (cse) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_DxDxD_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32) {
        %c0 = arith.constant 0 : index
        %cst = arith.constant 0.000000e+00 : f32
        %c32_i64 = arith.constant 32 : i64
        %0 = arith.extui %arg2 : i32 to i64
        %1 = arith.extui %arg3 : i32 to i64
        %2 = arith.shli %1, %c32_i64 : i64
        %3 = arith.ori %0, %2 : i64
        %4 = arith.index_castui %3 : i64 to index
        %5 = arith.extui %arg4 : i32 to i64
        %6 = arith.extui %arg5 : i32 to i64
        %7 = arith.shli %6, %c32_i64 : i64
        %8 = arith.ori %5, %7 : i64
        %9 = arith.index_castui %8 : i64 to index
        %10 = flow.dispatch.workload.ordinal %4, 0 : index
        %11 = flow.dispatch.workload.ordinal %9, 1 : index
        %12 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%10, %11}
        %13 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%10, %11}
        %14 = flow.dispatch.tensor.load %12, offsets = [0, 0], sizes = [%10, %11], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%10, %11} -> tensor<?x?xf32>
        %15 = tensor.empty(%10, %11) : tensor<?x?xf32>
        %16 = linalg.fill ins(%cst : f32) outs(%15 : tensor<?x?xf32>) -> tensor<?x?xf32>
        %17 = linalg.matmul ins(%14, %14 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%16 : tensor<?x?xf32>) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %17, %13, offsets = [0, 0], sizes = [%10, %11], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%10, %11}
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c32_i64 = arith.constant 32 : i64
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%3} => !stream.timepoint
    %5 = arith.index_castui %0 : index to i64
    %6 = arith.trunci %5 : i64 to i32
    %7 = arith.shrui %5, %c32_i64 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %1 : index to i64
    %10 = arith.trunci %9 : i64 to i32
    %11 = arith.shrui %9, %c32_i64 : i64
    %12 = arith.trunci %11 : i64 to i32
    %13 = stream.cmd.execute await(%result_timepoint) => with(%4 as %arg1: !stream.resource<external>{%3}, %result as %arg2: !stream.resource<external>{%3}) {
      stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%6, %8, %10, %12 : i32, i32, i32, i32) {
        ro %arg1[%c0 for %3] : !stream.resource<external>{%3},
        wo %arg2[%c0 for %3] : !stream.resource<external>{%3}
      }
    } => !stream.timepoint
    %14 = stream.timepoint.await %13 => %result : !stream.resource<external>{%3}
    %15 = stream.tensor.export %14 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
    return %15 : !hal.buffer_view
  }
}


// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c32_i64 = arith.constant 32 : i64
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
  %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%3} => !stream.timepoint
  %5 = arith.index_castui %0 : index to i64
  %6 = arith.trunci %5 : i64 to i32
  %7 = arith.shrui %5, %c32_i64 : i64
  %8 = arith.trunci %7 : i64 to i32
  %9 = arith.index_castui %1 : index to i64
  %10 = arith.trunci %9 : i64 to i32
  %11 = arith.shrui %9, %c32_i64 : i64
  %12 = arith.trunci %11 : i64 to i32
  %13 = stream.cmd.execute await(%result_timepoint) => with(%4 as %arg1: !stream.resource<external>{%3}, %result as %arg2: !stream.resource<external>{%3}) {
    stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%6, %8, %10, %12 : i32, i32, i32, i32) {
      ro %arg1[%c0 for %3] : !stream.resource<external>{%3},
      wo %arg2[%c0 for %3] : !stream.resource<external>{%3}
    }
  } => !stream.timepoint
  %14 = stream.timepoint.await %13 => %result : !stream.resource<external>{%3}
  %15 = stream.tensor.export %14 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
  return %15 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_DxDxD_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32) {
        %c0 = arith.constant 0 : index
        %cst = arith.constant 0.000000e+00 : f32
        %c32_i64 = arith.constant 32 : i64
        %0 = arith.extui %arg2 : i32 to i64
        %1 = arith.extui %arg3 : i32 to i64
        %2 = arith.shli %1, %c32_i64 : i64
        %3 = arith.ori %0, %2 : i64
        %4 = arith.index_castui %3 : i64 to index
        %5 = arith.extui %arg4 : i32 to i64
        %6 = arith.extui %arg5 : i32 to i64
        %7 = arith.shli %6, %c32_i64 : i64
        %8 = arith.ori %5, %7 : i64
        %9 = arith.index_castui %8 : i64 to index
        %10 = flow.dispatch.workload.ordinal %4, 0 : index
        %11 = flow.dispatch.workload.ordinal %9, 1 : index
        %12 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%10, %11}
        %13 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%10, %11}
        %14 = flow.dispatch.tensor.load %12, offsets = [0, 0], sizes = [%10, %11], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%10, %11} -> tensor<?x?xf32>
        %15 = tensor.empty(%10, %11) : tensor<?x?xf32>
        %16 = linalg.fill ins(%cst : f32) outs(%15 : tensor<?x?xf32>) -> tensor<?x?xf32>
        %17 = linalg.matmul ins(%14, %14 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%16 : tensor<?x?xf32>) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %17, %13, offsets = [0, 0], sizes = [%10, %11], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%10, %11}
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c32_i64 = arith.constant 32 : i64
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%3} => !stream.timepoint
    %5 = arith.index_castui %0 : index to i64
    %6 = arith.trunci %5 : i64 to i32
    %7 = arith.shrui %5, %c32_i64 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %1 : index to i64
    %10 = arith.trunci %9 : i64 to i32
    %11 = arith.shrui %9, %c32_i64 : i64
    %12 = arith.trunci %11 : i64 to i32
    %13 = stream.cmd.execute await(%result_timepoint) => with(%4 as %arg1: !stream.resource<external>{%3}, %result as %arg2: !stream.resource<external>{%3}) {
      stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%6, %8, %10, %12 : i32, i32, i32, i32) {
        ro %arg1[%c0 for %3] : !stream.resource<external>{%3},
        wo %arg2[%c0 for %3] : !stream.resource<external>{%3}
      }
    } => !stream.timepoint
    %14 = stream.timepoint.await %13 => %result : !stream.resource<external>{%3}
    %15 = stream.tensor.export %14 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
    return %15 : !hal.buffer_view
  }
}


// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_DxDxD_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32) {
        %c0 = arith.constant 0 : index
        %cst = arith.constant 0.000000e+00 : f32
        %c32_i64 = arith.constant 32 : i64
        %0 = arith.extui %arg2 : i32 to i64
        %1 = arith.extui %arg3 : i32 to i64
        %2 = arith.shli %1, %c32_i64 : i64
        %3 = arith.ori %0, %2 : i64
        %4 = arith.index_castui %3 : i64 to index
        %5 = arith.extui %arg4 : i32 to i64
        %6 = arith.extui %arg5 : i32 to i64
        %7 = arith.shli %6, %c32_i64 : i64
        %8 = arith.ori %5, %7 : i64
        %9 = arith.index_castui %8 : i64 to index
        %10 = flow.dispatch.workload.ordinal %4, 0 : index
        %11 = flow.dispatch.workload.ordinal %9, 1 : index
        %12 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%10, %11}
        %13 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%10, %11}
        %14 = flow.dispatch.tensor.load %12, offsets = [0, 0], sizes = [%10, %11], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%10, %11} -> tensor<?x?xf32>
        %15 = tensor.empty(%10, %11) : tensor<?x?xf32>
        %16 = linalg.fill ins(%cst : f32) outs(%15 : tensor<?x?xf32>) -> tensor<?x?xf32>
        %17 = linalg.matmul ins(%14, %14 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%16 : tensor<?x?xf32>) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %17, %13, offsets = [0, 0], sizes = [%10, %11], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%10, %11}
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c32_i64 = arith.constant 32 : i64
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%3} => !stream.timepoint
    %5 = arith.index_castui %0 : index to i64
    %6 = arith.trunci %5 : i64 to i32
    %7 = arith.shrui %5, %c32_i64 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %1 : index to i64
    %10 = arith.trunci %9 : i64 to i32
    %11 = arith.shrui %9, %c32_i64 : i64
    %12 = arith.trunci %11 : i64 to i32
    %13 = stream.cmd.execute await(%result_timepoint) => with(%4 as %arg1: !stream.resource<external>{%3}, %result as %arg2: !stream.resource<external>{%3}) {
      stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%6, %8, %10, %12 : i32, i32, i32, i32) {
        ro %arg1[%c0 for %3] : !stream.resource<external>{%3},
        wo %arg2[%c0 for %3] : !stream.resource<external>{%3}
      }
    } => !stream.timepoint
    %14 = stream.timepoint.await %13 => %result : !stream.resource<external>{%3}
    %15 = stream.tensor.export %14 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
    return %15 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_DxDxD_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32) {
        %c0 = arith.constant 0 : index
        %cst = arith.constant 0.000000e+00 : f32
        %c32_i64 = arith.constant 32 : i64
        %0 = arith.extui %arg2 : i32 to i64
        %1 = arith.extui %arg3 : i32 to i64
        %2 = arith.shli %1, %c32_i64 : i64
        %3 = arith.ori %0, %2 : i64
        %4 = arith.index_castui %3 : i64 to index
        %5 = arith.extui %arg4 : i32 to i64
        %6 = arith.extui %arg5 : i32 to i64
        %7 = arith.shli %6, %c32_i64 : i64
        %8 = arith.ori %5, %7 : i64
        %9 = arith.index_castui %8 : i64 to index
        %10 = flow.dispatch.workload.ordinal %4, 0 : index
        %11 = flow.dispatch.workload.ordinal %9, 1 : index
        %12 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%10, %11}
        %13 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%10, %11}
        %14 = flow.dispatch.tensor.load %12, offsets = [0, 0], sizes = [%10, %11], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%10, %11} -> tensor<?x?xf32>
        %15 = tensor.empty(%10, %11) : tensor<?x?xf32>
        %16 = linalg.fill ins(%cst : f32) outs(%15 : tensor<?x?xf32>) -> tensor<?x?xf32>
        %17 = linalg.matmul ins(%14, %14 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%16 : tensor<?x?xf32>) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %17, %13, offsets = [0, 0], sizes = [%10, %11], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%10, %11}
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c32_i64 = arith.constant 32 : i64
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%3} => !stream.timepoint
    %5 = arith.index_castui %0 : index to i64
    %6 = arith.trunci %5 : i64 to i32
    %7 = arith.shrui %5, %c32_i64 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %1 : index to i64
    %10 = arith.trunci %9 : i64 to i32
    %11 = arith.shrui %9, %c32_i64 : i64
    %12 = arith.trunci %11 : i64 to i32
    %13 = stream.cmd.execute await(%result_timepoint) => with(%4 as %arg1: !stream.resource<external>{%3}, %result as %arg2: !stream.resource<external>{%3}) {
      stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%6, %8, %10, %12 : i32, i32, i32, i32) {
        ro %arg1[%c0 for %3] : !stream.resource<external>{%3},
        wo %arg2[%c0 for %3] : !stream.resource<external>{%3}
      }
    } => !stream.timepoint
    %14 = stream.timepoint.await %13 => %result : !stream.resource<external>{%3}
    %15 = stream.tensor.export %14 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
    return %15 : !hal.buffer_view
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::HAL::AssignTargetDevicesPass (iree-hal-assign-target-devices) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_DxDxD_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32) {
        %c0 = arith.constant 0 : index
        %cst = arith.constant 0.000000e+00 : f32
        %c32_i64 = arith.constant 32 : i64
        %0 = arith.extui %arg2 : i32 to i64
        %1 = arith.extui %arg3 : i32 to i64
        %2 = arith.shli %1, %c32_i64 : i64
        %3 = arith.ori %0, %2 : i64
        %4 = arith.index_castui %3 : i64 to index
        %5 = arith.extui %arg4 : i32 to i64
        %6 = arith.extui %arg5 : i32 to i64
        %7 = arith.shli %6, %c32_i64 : i64
        %8 = arith.ori %5, %7 : i64
        %9 = arith.index_castui %8 : i64 to index
        %10 = flow.dispatch.workload.ordinal %4, 0 : index
        %11 = flow.dispatch.workload.ordinal %9, 1 : index
        %12 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%10, %11}
        %13 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%10, %11}
        %14 = flow.dispatch.tensor.load %12, offsets = [0, 0], sizes = [%10, %11], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%10, %11} -> tensor<?x?xf32>
        %15 = tensor.empty(%10, %11) : tensor<?x?xf32>
        %16 = linalg.fill ins(%cst : f32) outs(%15 : tensor<?x?xf32>) -> tensor<?x?xf32>
        %17 = linalg.matmul ins(%14, %14 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%16 : tensor<?x?xf32>) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %17, %13, offsets = [0, 0], sizes = [%10, %11], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%10, %11}
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c32_i64 = arith.constant 32 : i64
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%3} => !stream.timepoint
    %5 = arith.index_castui %0 : index to i64
    %6 = arith.trunci %5 : i64 to i32
    %7 = arith.shrui %5, %c32_i64 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %1 : index to i64
    %10 = arith.trunci %9 : i64 to i32
    %11 = arith.shrui %9, %c32_i64 : i64
    %12 = arith.trunci %11 : i64 to i32
    %13 = stream.cmd.execute await(%result_timepoint) => with(%4 as %arg1: !stream.resource<external>{%3}, %result as %arg2: !stream.resource<external>{%3}) {
      stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%6, %8, %10, %12 : i32, i32, i32, i32) {
        ro %arg1[%c0 for %3] : !stream.resource<external>{%3},
        wo %arg2[%c0 for %3] : !stream.resource<external>{%3}
      }
    } => !stream.timepoint
    %14 = stream.timepoint.await %13 => %result : !stream.resource<external>{%3}
    %15 = stream.tensor.export %14 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
    return %15 : !hal.buffer_view
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::HAL::VerifyTargetEnvironmentPass (iree-hal-verify-target-environment) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_DxDxD_f32 workgroups(%arg0: index, %arg1: index) -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg0, %arg1
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32) {
        %c0 = arith.constant 0 : index
        %cst = arith.constant 0.000000e+00 : f32
        %c32_i64 = arith.constant 32 : i64
        %0 = arith.extui %arg2 : i32 to i64
        %1 = arith.extui %arg3 : i32 to i64
        %2 = arith.shli %1, %c32_i64 : i64
        %3 = arith.ori %0, %2 : i64
        %4 = arith.index_castui %3 : i64 to index
        %5 = arith.extui %arg4 : i32 to i64
        %6 = arith.extui %arg5 : i32 to i64
        %7 = arith.shli %6, %c32_i64 : i64
        %8 = arith.ori %5, %7 : i64
        %9 = arith.index_castui %8 : i64 to index
        %10 = flow.dispatch.workload.ordinal %4, 0 : index
        %11 = flow.dispatch.workload.ordinal %9, 1 : index
        %12 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%10, %11}
        %13 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%10, %11}
        %14 = flow.dispatch.tensor.load %12, offsets = [0, 0], sizes = [%10, %11], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%10, %11} -> tensor<?x?xf32>
        %15 = tensor.empty(%10, %11) : tensor<?x?xf32>
        %16 = linalg.fill ins(%cst : f32) outs(%15 : tensor<?x?xf32>) -> tensor<?x?xf32>
        %17 = linalg.matmul ins(%14, %14 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%16 : tensor<?x?xf32>) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %17, %13, offsets = [0, 0], sizes = [%10, %11], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%10, %11}
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c32_i64 = arith.constant 32 : i64
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%3} => !stream.timepoint
    %5 = arith.index_castui %0 : index to i64
    %6 = arith.trunci %5 : i64 to i32
    %7 = arith.shrui %5, %c32_i64 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %1 : index to i64
    %10 = arith.trunci %9 : i64 to i32
    %11 = arith.shrui %9, %c32_i64 : i64
    %12 = arith.trunci %11 : i64 to i32
    %13 = stream.cmd.execute await(%result_timepoint) => with(%4 as %arg1: !stream.resource<external>{%3}, %result as %arg2: !stream.resource<external>{%3}) {
      stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%6, %8, %10, %12 : i32, i32, i32, i32) {
        ro %arg1[%c0 for %3] : !stream.resource<external>{%3},
        wo %arg2[%c0 for %3] : !stream.resource<external>{%3}
      }
    } => !stream.timepoint
    %14 = stream.timepoint.await %13 => %result : !stream.resource<external>{%3}
    %15 = stream.tensor.export %14 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
    return %15 : !hal.buffer_view
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::HAL::(anonymous namespace)::MaterializeInterfacesPass (iree-hal-materialize-interfaces) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#pipeline_layout = #hal.pipeline.layout<push_constants = 4, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer>]>]>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  hal.executable private @main_dispatch_0 {
    hal.executable.variant public @cuda_nvptx_fb target(#executable_target_cuda_nvptx_fb) {
      hal.executable.export public @main_dispatch_0_matmul_DxDxD_f32 ordinal(0) layout(#pipeline_layout) {
      ^bb0(%arg0: !hal.device, %arg1: index, %arg2: index):
        %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg1, %arg2
        hal.return %x, %y, %z : index, index, index
      }
      builtin.module {
        func.func @main_dispatch_0_matmul_DxDxD_f32() {
          %c32_i64 = arith.constant 32 : i64
          %cst = arith.constant 0.000000e+00 : f32
          %c0 = arith.constant 0 : index
          %0 = hal.interface.constant.load[0] : i32
          %1 = hal.interface.constant.load[1] : i32
          %2 = hal.interface.constant.load[2] : i32
          %3 = hal.interface.constant.load[3] : i32
          %4 = arith.extui %0 : i32 to i64
          %5 = arith.extui %1 : i32 to i64
          %6 = arith.shli %5, %c32_i64 : i64
          %7 = arith.ori %4, %6 : i64
          %8 = arith.index_castui %7 : i64 to index
          %9 = arith.extui %2 : i32 to i64
          %10 = arith.extui %3 : i32 to i64
          %11 = arith.shli %10, %c32_i64 : i64
          %12 = arith.ori %9, %11 : i64
          %13 = arith.index_castui %12 : i64 to index
          %14 = flow.dispatch.workload.ordinal %8, 0 : index
          %15 = flow.dispatch.workload.ordinal %13, 1 : index
          %16 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%14, %15}
          %17 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%14, %15}
          %18 = flow.dispatch.tensor.load %16, offsets = [0, 0], sizes = [%14, %15], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%14, %15} -> tensor<?x?xf32>
          %19 = tensor.empty(%14, %15) : tensor<?x?xf32>
          %20 = linalg.fill ins(%cst : f32) outs(%19 : tensor<?x?xf32>) -> tensor<?x?xf32>
          %21 = linalg.matmul ins(%18, %18 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%20 : tensor<?x?xf32>) -> tensor<?x?xf32>
          flow.dispatch.tensor.store %21, %17, offsets = [0, 0], sizes = [%14, %15], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%14, %15}
          return
        }
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c32_i64 = arith.constant 32 : i64
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%3} => !stream.timepoint
    %5 = arith.index_castui %0 : index to i64
    %6 = arith.trunci %5 : i64 to i32
    %7 = arith.shrui %5, %c32_i64 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %1 : index to i64
    %10 = arith.trunci %9 : i64 to i32
    %11 = arith.shrui %9, %c32_i64 : i64
    %12 = arith.trunci %11 : i64 to i32
    %13 = stream.cmd.execute await(%result_timepoint) => with(%4 as %arg1: !stream.resource<external>{%3}, %result as %arg2: !stream.resource<external>{%3}) {
      stream.cmd.dispatch @main_dispatch_0::@cuda_nvptx_fb::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%6, %8, %10, %12 : i32, i32, i32, i32) {
        ro %arg1[%c0 for %3] : !stream.resource<external>{%3},
        wo %arg2[%c0 for %3] : !stream.resource<external>{%3}
      } attributes {hal.interface.bindings = [#hal.interface.binding<0, 0>, #hal.interface.binding<0, 1>]}
    } => !stream.timepoint
    %14 = stream.timepoint.await %13 => %result : !stream.resource<external>{%3}
    %15 = stream.tensor.export %14 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
    return %15 : !hal.buffer_view
  }
}


// -----// IR Dump After CPUMaterializeUpperBoundTileSize (iree-codegen-cpu-materialize-upper-bound-tile-size) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c32_i64 = arith.constant 32 : i64
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
  %result, %result_timepoint = stream.resource.alloca uninitialized : !stream.resource<external>{%3} => !stream.timepoint
  %5 = arith.index_castui %0 : index to i64
  %6 = arith.trunci %5 : i64 to i32
  %7 = arith.shrui %5, %c32_i64 : i64
  %8 = arith.trunci %7 : i64 to i32
  %9 = arith.index_castui %1 : index to i64
  %10 = arith.trunci %9 : i64 to i32
  %11 = arith.shrui %9, %c32_i64 : i64
  %12 = arith.trunci %11 : i64 to i32
  %13 = stream.cmd.execute await(%result_timepoint) => with(%4 as %arg1: !stream.resource<external>{%3}, %result as %arg2: !stream.resource<external>{%3}) {
    stream.cmd.dispatch @main_dispatch_0::@cuda_nvptx_fb::@main_dispatch_0_matmul_DxDxD_f32[%0, %1](%6, %8, %10, %12 : i32, i32, i32, i32) {
      ro %arg1[%c0 for %3] : !stream.resource<external>{%3},
      wo %arg2[%c0 for %3] : !stream.resource<external>{%3}
    } attributes {hal.interface.bindings = [#hal.interface.binding<0, 0>, #hal.interface.binding<0, 1>]}
  } => !stream.timepoint
  %14 = stream.timepoint.await %13 => %result : !stream.resource<external>{%3}
  %15 = stream.tensor.export %14 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3} -> !hal.buffer_view
  return %15 : !hal.buffer_view
}

// -----// IR Dump After TypePropagation (iree-codegen-type-propagation) //----- //
func.func @main_dispatch_0_matmul_DxDxD_f32() {
  %c32_i64 = arith.constant 32 : i64
  %cst = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.constant.load[0] : i32
  %1 = hal.interface.constant.load[1] : i32
  %2 = hal.interface.constant.load[2] : i32
  %3 = hal.interface.constant.load[3] : i32
  %4 = arith.extui %0 : i32 to i64
  %5 = arith.extui %1 : i32 to i64
  %6 = arith.shli %5, %c32_i64 : i64
  %7 = arith.ori %4, %6 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %2 : i32 to i64
  %10 = arith.extui %3 : i32 to i64
  %11 = arith.shli %10, %c32_i64 : i64
  %12 = arith.ori %9, %11 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14 = flow.dispatch.workload.ordinal %8, 0 : index
  %15 = flow.dispatch.workload.ordinal %13, 1 : index
  %16 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%14, %15}
  %17 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%14, %15}
  %18 = flow.dispatch.tensor.load %16, offsets = [0, 0], sizes = [%14, %15], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%14, %15} -> tensor<?x?xf32>
  %19 = tensor.empty(%14, %15) : tensor<?x?xf32>
  %20 = linalg.fill ins(%cst : f32) outs(%19 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %21 = linalg.matmul ins(%18, %18 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%20 : tensor<?x?xf32>) -> tensor<?x?xf32>
  flow.dispatch.tensor.store %21, %17, offsets = [0, 0], sizes = [%14, %15], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%14, %15}
  return
}

// -----// IR Dump After BubbleUpOrdinalOps (iree-codegen-bubble-up-ordinal-ops) //----- //
module {
  func.func @main_dispatch_0_matmul_DxDxD_f32() {
    %c32_i64 = arith.constant 32 : i64
    %cst = arith.constant 0.000000e+00 : f32
    %c0 = arith.constant 0 : index
    %0 = hal.interface.constant.load[0] : i32
    %1 = hal.interface.constant.load[1] : i32
    %2 = hal.interface.constant.load[2] : i32
    %3 = hal.interface.constant.load[3] : i32
    %4 = arith.extui %0 : i32 to i64
    %5 = arith.extui %1 : i32 to i64
    %6 = arith.shli %5, %c32_i64 : i64
    %7 = arith.ori %4, %6 : i64
    %8 = arith.index_castui %7 : i64 to index
    %9 = arith.extui %2 : i32 to i64
    %10 = arith.extui %3 : i32 to i64
    %11 = arith.shli %10, %c32_i64 : i64
    %12 = arith.ori %9, %11 : i64
    %13 = arith.index_castui %12 : i64 to index
    %14 = flow.dispatch.workload.ordinal %8, 0 : index
    %15 = flow.dispatch.workload.ordinal %13, 1 : index
    %16 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%14, %15}
    %17 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%14, %15}
    %18 = flow.dispatch.tensor.load %16, offsets = [0, 0], sizes = [%14, %15], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%14, %15} -> tensor<?x?xf32>
    %19 = tensor.empty(%14, %15) : tensor<?x?xf32>
    %20 = linalg.fill ins(%cst : f32) outs(%19 : tensor<?x?xf32>) -> tensor<?x?xf32>
    %21 = linalg.matmul ins(%18, %18 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%20 : tensor<?x?xf32>) -> tensor<?x?xf32>
    flow.dispatch.tensor.store %21, %17, offsets = [0, 0], sizes = [%14, %15], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%14, %15}
    return
  }
}

// -----// IR Dump After BufferizeCopyOnlyDispatches (iree-codegen-bufferize-copy-only-dispatches) //----- //
module {
  func.func @main_dispatch_0_matmul_DxDxD_f32() {
    %c32_i64 = arith.constant 32 : i64
    %cst = arith.constant 0.000000e+00 : f32
    %c0 = arith.constant 0 : index
    %0 = hal.interface.constant.load[0] : i32
    %1 = hal.interface.constant.load[1] : i32
    %2 = hal.interface.constant.load[2] : i32
    %3 = hal.interface.constant.load[3] : i32
    %4 = arith.extui %0 : i32 to i64
    %5 = arith.extui %1 : i32 to i64
    %6 = arith.shli %5, %c32_i64 : i64
    %7 = arith.ori %4, %6 : i64
    %8 = arith.index_castui %7 : i64 to index
    %9 = arith.extui %2 : i32 to i64
    %10 = arith.extui %3 : i32 to i64
    %11 = arith.shli %10, %c32_i64 : i64
    %12 = arith.ori %9, %11 : i64
    %13 = arith.index_castui %12 : i64 to index
    %14 = flow.dispatch.workload.ordinal %8, 0 : index
    %15 = flow.dispatch.workload.ordinal %13, 1 : index
    %16 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%14, %15}
    %17 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%14, %15}
    %18 = flow.dispatch.tensor.load %16, offsets = [0, 0], sizes = [%14, %15], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%14, %15} -> tensor<?x?xf32>
    %19 = tensor.empty(%14, %15) : tensor<?x?xf32>
    %20 = linalg.fill ins(%cst : f32) outs(%19 : tensor<?x?xf32>) -> tensor<?x?xf32>
    %21 = linalg.matmul ins(%18, %18 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%20 : tensor<?x?xf32>) -> tensor<?x?xf32>
    flow.dispatch.tensor.store %21, %17, offsets = [0, 0], sizes = [%14, %15], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%14, %15}
    return
  }
}

// -----// IR Dump After DecomposeSoftmax (iree-linalg-ext-decompose-softmax) //----- //
func.func @main_dispatch_0_matmul_DxDxD_f32() {
  %c32_i64 = arith.constant 32 : i64
  %cst = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.constant.load[0] : i32
  %1 = hal.interface.constant.load[1] : i32
  %2 = hal.interface.constant.load[2] : i32
  %3 = hal.interface.constant.load[3] : i32
  %4 = arith.extui %0 : i32 to i64
  %5 = arith.extui %1 : i32 to i64
  %6 = arith.shli %5, %c32_i64 : i64
  %7 = arith.ori %4, %6 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %2 : i32 to i64
  %10 = arith.extui %3 : i32 to i64
  %11 = arith.shli %10, %c32_i64 : i64
  %12 = arith.ori %9, %11 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14 = flow.dispatch.workload.ordinal %8, 0 : index
  %15 = flow.dispatch.workload.ordinal %13, 1 : index
  %16 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%14, %15}
  %17 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%14, %15}
  %18 = flow.dispatch.tensor.load %16, offsets = [0, 0], sizes = [%14, %15], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%14, %15} -> tensor<?x?xf32>
  %19 = tensor.empty(%14, %15) : tensor<?x?xf32>
  %20 = linalg.fill ins(%cst : f32) outs(%19 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %21 = linalg.matmul ins(%18, %18 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%20 : tensor<?x?xf32>) -> tensor<?x?xf32>
  flow.dispatch.tensor.store %21, %17, offsets = [0, 0], sizes = [%14, %15], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%14, %15}
  return
}

// -----// IR Dump After MaterializeUserConfigs (iree-codegen-materialize-user-configs) //----- //
hal.executable.variant public @cuda_nvptx_fb target(<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>) {
  hal.executable.export public @main_dispatch_0_matmul_DxDxD_f32 ordinal(0) layout(#hal.pipeline.layout<push_constants = 4, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer>]>]>) {
  ^bb0(%arg0: !hal.device, %arg1: index, %arg2: index):
    %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg1, %arg2
    hal.return %x, %y, %z : index, index, index
  }
  builtin.module {
    func.func @main_dispatch_0_matmul_DxDxD_f32() {
      %c32_i64 = arith.constant 32 : i64
      %cst = arith.constant 0.000000e+00 : f32
      %c0 = arith.constant 0 : index
      %0 = hal.interface.constant.load[0] : i32
      %1 = hal.interface.constant.load[1] : i32
      %2 = hal.interface.constant.load[2] : i32
      %3 = hal.interface.constant.load[3] : i32
      %4 = arith.extui %0 : i32 to i64
      %5 = arith.extui %1 : i32 to i64
      %6 = arith.shli %5, %c32_i64 : i64
      %7 = arith.ori %4, %6 : i64
      %8 = arith.index_castui %7 : i64 to index
      %9 = arith.extui %2 : i32 to i64
      %10 = arith.extui %3 : i32 to i64
      %11 = arith.shli %10, %c32_i64 : i64
      %12 = arith.ori %9, %11 : i64
      %13 = arith.index_castui %12 : i64 to index
      %14 = flow.dispatch.workload.ordinal %8, 0 : index
      %15 = flow.dispatch.workload.ordinal %13, 1 : index
      %16 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%14, %15}
      %17 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%14, %15}
      %18 = flow.dispatch.tensor.load %16, offsets = [0, 0], sizes = [%14, %15], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%14, %15} -> tensor<?x?xf32>
      %19 = tensor.empty(%14, %15) : tensor<?x?xf32>
      %20 = linalg.fill ins(%cst : f32) outs(%19 : tensor<?x?xf32>) -> tensor<?x?xf32>
      %21 = linalg.matmul ins(%18, %18 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%20 : tensor<?x?xf32>) -> tensor<?x?xf32>
      flow.dispatch.tensor.store %21, %17, offsets = [0, 0], sizes = [%14, %15], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%14, %15}
      return
    }
  }
}

// -----// IR Dump After LLVMGPUSelectLoweringStrategy (iree-llvmgpu-select-lowering-strategy) //----- //
hal.executable.variant public @cuda_nvptx_fb target(<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>) {
  hal.executable.export public @main_dispatch_0_matmul_DxDxD_f32 ordinal(0) layout(#hal.pipeline.layout<push_constants = 4, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer>]>]>) attributes {translation_info = #iree_codegen.translation_info<LLVMGPUMatmulSimt>, workgroup_size = [32 : index, 8 : index, 1 : index]} {
  ^bb0(%arg0: !hal.device, %arg1: index, %arg2: index):
    %x, %y, %z = flow.dispatch.workgroup_count_from_slice %arg1, %arg2
    hal.return %x, %y, %z : index, index, index
  }
  builtin.module {
    func.func @main_dispatch_0_matmul_DxDxD_f32() {
      %c32_i64 = arith.constant 32 : i64
      %cst = arith.constant 0.000000e+00 : f32
      %c0 = arith.constant 0 : index
      %0 = hal.interface.constant.load[0] : i32
      %1 = hal.interface.constant.load[1] : i32
      %2 = hal.interface.constant.load[2] : i32
      %3 = hal.interface.constant.load[3] : i32
      %4 = arith.extui %0 : i32 to i64
      %5 = arith.extui %1 : i32 to i64
      %6 = arith.shli %5, %c32_i64 : i64
      %7 = arith.ori %4, %6 : i64
      %8 = arith.index_castui %7 : i64 to index
      %9 = arith.extui %2 : i32 to i64
      %10 = arith.extui %3 : i32 to i64
      %11 = arith.shli %10, %c32_i64 : i64
      %12 = arith.ori %9, %11 : i64
      %13 = arith.index_castui %12 : i64 to index
      %14 = flow.dispatch.workload.ordinal %8, 0 : index
      %15 = flow.dispatch.workload.ordinal %13, 1 : index
      %16 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%14, %15}
      %17 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%14, %15}
      %18 = flow.dispatch.tensor.load %16, offsets = [0, 0], sizes = [%14, %15], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%14, %15} -> tensor<?x?xf32>
      %19 = tensor.empty(%14, %15) : tensor<?x?xf32>
      %20 = linalg.fill {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%cst : f32) outs(%19 : tensor<?x?xf32>) -> tensor<?x?xf32>
      %21 = linalg.matmul {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%18, %18 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%20 : tensor<?x?xf32>) -> tensor<?x?xf32>
      flow.dispatch.tensor.store %21, %17, offsets = [0, 0], sizes = [%14, %15], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%14, %15}
      return
    }
  }
}

// -----// IR Dump After TileAndDistributeToWorkgroups (iree-codegen-tile-and-distribute-to-workgroups) //----- //
hal.executable.variant public @cuda_nvptx_fb target(<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>) {
  hal.executable.export public @main_dispatch_0_matmul_DxDxD_f32 ordinal(0) layout(#hal.pipeline.layout<push_constants = 4, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer>]>]>) attributes {translation_info = #iree_codegen.translation_info<LLVMGPUMatmulSimt>, workgroup_size = [32 : index, 8 : index, 1 : index]} {
  ^bb0(%arg0: !hal.device, %arg1: index, %arg2: index):
    %c1 = arith.constant 1 : index
    %0 = affine.apply affine_map<()[s0, s1] -> ((s0 ceildiv 128) * (s1 ceildiv 32))>()[%arg2, %arg1]
    hal.return %0, %c1, %c1 : index, index, index
  }
  builtin.module {
    func.func @main_dispatch_0_matmul_DxDxD_f32() {
      %c32_i64 = arith.constant 32 : i64
      %cst = arith.constant 0.000000e+00 : f32
      %c0 = arith.constant 0 : index
      %0 = hal.interface.constant.load[0] : i32
      %1 = hal.interface.constant.load[1] : i32
      %2 = hal.interface.constant.load[2] : i32
      %3 = hal.interface.constant.load[3] : i32
      %4 = arith.extui %0 : i32 to i64
      %5 = arith.extui %1 : i32 to i64
      %6 = arith.shli %5, %c32_i64 : i64
      %7 = arith.ori %4, %6 : i64
      %8 = arith.index_castui %7 : i64 to index
      %9 = arith.extui %2 : i32 to i64
      %10 = arith.extui %3 : i32 to i64
      %11 = arith.shli %10, %c32_i64 : i64
      %12 = arith.ori %9, %11 : i64
      %13 = arith.index_castui %12 : i64 to index
      %14 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%8, %13}
      %15 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%8, %13}
      %workgroup_id_x = hal.interface.workgroup.id[0] : index
      %16 = affine.min affine_map<()[s0, s1, s2] -> (32, s0 - (s1 floordiv (s2 ceildiv 128)) * 32)>()[%8, %workgroup_id_x, %13]
      %17 = affine.min affine_map<()[s0, s1] -> (128, s0 - (s1 mod (s0 ceildiv 128)) * 128)>()[%13, %workgroup_id_x]
      %18 = affine.apply affine_map<()[s0, s1] -> ((s0 floordiv (s1 ceildiv 128)) * 32)>()[%workgroup_id_x, %13]
      %19 = flow.dispatch.tensor.load %14, offsets = [%18, 0], sizes = [%16, %13], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%8, %13} -> tensor<?x?xf32>
      %20 = affine.apply affine_map<()[s0, s1] -> ((s0 mod (s1 ceildiv 128)) * 128)>()[%workgroup_id_x, %13]
      %21 = flow.dispatch.tensor.load %14, offsets = [0, %20], sizes = [%13, %17], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%8, %13} -> tensor<?x?xf32>
      %22 = tensor.empty(%16, %17) : tensor<?x?xf32>
      %23 = linalg.fill {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%cst : f32) outs(%22 : tensor<?x?xf32>) -> tensor<?x?xf32>
      %24 = linalg.matmul {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%19, %21 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%23 : tensor<?x?xf32>) -> tensor<?x?xf32>
      %25 = arith.extui %0 : i32 to i64
      %26 = arith.extui %1 : i32 to i64
      %27 = arith.shli %26, %c32_i64 : i64
      %28 = arith.ori %25, %27 : i64
      %29 = arith.index_castui %28 : i64 to index
      %30 = arith.extui %2 : i32 to i64
      %31 = arith.extui %3 : i32 to i64
      %32 = arith.shli %31, %c32_i64 : i64
      %33 = arith.ori %30, %32 : i64
      %34 = arith.index_castui %33 : i64 to index
      %35 = affine.apply affine_map<()[s0, s1] -> ((s0 floordiv (s1 ceildiv 128)) * 32)>()[%workgroup_id_x, %13]
      %36 = affine.apply affine_map<()[s0, s1] -> ((s0 mod (s1 ceildiv 128)) * 128)>()[%workgroup_id_x, %13]
      flow.dispatch.tensor.store %24, %15, offsets = [%35, %36], sizes = [%16, %17], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%29, %34}
      return
    }
  }
}

// -----// IR Dump After ConvertToDestinationPassingStyle (iree-codegen-convert-to-destination-passing-style) //----- //
func.func @main_dispatch_0_matmul_DxDxD_f32() {
  %c32_i64 = arith.constant 32 : i64
  %cst = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.constant.load[0] : i32
  %1 = hal.interface.constant.load[1] : i32
  %2 = hal.interface.constant.load[2] : i32
  %3 = hal.interface.constant.load[3] : i32
  %4 = arith.extui %0 : i32 to i64
  %5 = arith.extui %1 : i32 to i64
  %6 = arith.shli %5, %c32_i64 : i64
  %7 = arith.ori %4, %6 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %2 : i32 to i64
  %10 = arith.extui %3 : i32 to i64
  %11 = arith.shli %10, %c32_i64 : i64
  %12 = arith.ori %9, %11 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%8, %13}
  %15 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%8, %13}
  %16 = arith.extui %0 : i32 to i64
  %17 = arith.extui %1 : i32 to i64
  %18 = arith.shli %17, %c32_i64 : i64
  %19 = arith.ori %16, %18 : i64
  %20 = arith.index_castui %19 : i64 to index
  %21 = arith.extui %2 : i32 to i64
  %22 = arith.extui %3 : i32 to i64
  %23 = arith.shli %22, %c32_i64 : i64
  %24 = arith.ori %21, %23 : i64
  %25 = arith.index_castui %24 : i64 to index
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %26 = arith.extui %2 : i32 to i64
  %27 = arith.extui %3 : i32 to i64
  %28 = arith.shli %27, %c32_i64 : i64
  %29 = arith.ori %26, %28 : i64
  %30 = arith.index_castui %29 : i64 to index
  %31 = affine.apply affine_map<()[s0, s1] -> ((s0 floordiv (s1 ceildiv 128)) * 32)>()[%workgroup_id_x, %30]
  %32 = affine.apply affine_map<()[s0, s1] -> ((s0 mod (s1 ceildiv 128)) * 128)>()[%workgroup_id_x, %30]
  %33 = arith.extui %0 : i32 to i64
  %34 = arith.extui %1 : i32 to i64
  %35 = arith.shli %34, %c32_i64 : i64
  %36 = arith.ori %33, %35 : i64
  %37 = arith.index_castui %36 : i64 to index
  %38 = affine.min affine_map<()[s0, s1, s2] -> (32, s0 - (s1 floordiv (s2 ceildiv 128)) * 32)>()[%37, %workgroup_id_x, %30]
  %39 = affine.min affine_map<()[s0, s1] -> (128, s0 - (s1 mod (s0 ceildiv 128)) * 128)>()[%30, %workgroup_id_x]
  %40 = flow.dispatch.tensor.load %15, offsets = [%31, %32], sizes = [%38, %39], strides = [1, 1] : !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%20, %25} -> tensor<?x?xf32>
  %workgroup_id_x_0 = hal.interface.workgroup.id[0] : index
  %41 = affine.min affine_map<()[s0, s1, s2] -> (32, s0 - (s1 floordiv (s2 ceildiv 128)) * 32)>()[%8, %workgroup_id_x_0, %13]
  %42 = affine.min affine_map<()[s0, s1] -> (128, s0 - (s1 mod (s0 ceildiv 128)) * 128)>()[%13, %workgroup_id_x_0]
  %43 = affine.apply affine_map<()[s0, s1] -> ((s0 floordiv (s1 ceildiv 128)) * 32)>()[%workgroup_id_x_0, %13]
  %44 = flow.dispatch.tensor.load %14, offsets = [%43, 0], sizes = [%41, %13], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%8, %13} -> tensor<?x?xf32>
  %45 = affine.apply affine_map<()[s0, s1] -> ((s0 mod (s1 ceildiv 128)) * 128)>()[%workgroup_id_x_0, %13]
  %46 = flow.dispatch.tensor.load %14, offsets = [0, %45], sizes = [%13, %42], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%8, %13} -> tensor<?x?xf32>
  %47 = linalg.fill {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%cst : f32) outs(%40 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %48 = linalg.matmul {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%44, %46 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%47 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %49 = arith.extui %0 : i32 to i64
  %50 = arith.extui %1 : i32 to i64
  %51 = arith.shli %50, %c32_i64 : i64
  %52 = arith.ori %49, %51 : i64
  %53 = arith.index_castui %52 : i64 to index
  %54 = arith.extui %2 : i32 to i64
  %55 = arith.extui %3 : i32 to i64
  %56 = arith.shli %55, %c32_i64 : i64
  %57 = arith.ori %54, %56 : i64
  %58 = arith.index_castui %57 : i64 to index
  %59 = affine.apply affine_map<()[s0, s1] -> ((s0 floordiv (s1 ceildiv 128)) * 32)>()[%workgroup_id_x_0, %13]
  %60 = affine.apply affine_map<()[s0, s1] -> ((s0 mod (s1 ceildiv 128)) * 128)>()[%workgroup_id_x_0, %13]
  flow.dispatch.tensor.store %48, %15, offsets = [%59, %60], sizes = [%41, %42], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%53, %58}
  return
}

// -----// IR Dump After TileAndDecomposeAttention (iree-linalg-ext-tile-and-decompose-attention) //----- //
func.func @main_dispatch_0_matmul_DxDxD_f32() {
  %c32_i64 = arith.constant 32 : i64
  %cst = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.constant.load[0] : i32
  %1 = hal.interface.constant.load[1] : i32
  %2 = hal.interface.constant.load[2] : i32
  %3 = hal.interface.constant.load[3] : i32
  %4 = arith.extui %0 : i32 to i64
  %5 = arith.extui %1 : i32 to i64
  %6 = arith.shli %5, %c32_i64 : i64
  %7 = arith.ori %4, %6 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %2 : i32 to i64
  %10 = arith.extui %3 : i32 to i64
  %11 = arith.shli %10, %c32_i64 : i64
  %12 = arith.ori %9, %11 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%8, %13}
  %15 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%8, %13}
  %16 = arith.extui %0 : i32 to i64
  %17 = arith.extui %1 : i32 to i64
  %18 = arith.shli %17, %c32_i64 : i64
  %19 = arith.ori %16, %18 : i64
  %20 = arith.index_castui %19 : i64 to index
  %21 = arith.extui %2 : i32 to i64
  %22 = arith.extui %3 : i32 to i64
  %23 = arith.shli %22, %c32_i64 : i64
  %24 = arith.ori %21, %23 : i64
  %25 = arith.index_castui %24 : i64 to index
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %26 = arith.extui %2 : i32 to i64
  %27 = arith.extui %3 : i32 to i64
  %28 = arith.shli %27, %c32_i64 : i64
  %29 = arith.ori %26, %28 : i64
  %30 = arith.index_castui %29 : i64 to index
  %31 = affine.apply affine_map<()[s0, s1] -> ((s0 floordiv (s1 ceildiv 128)) * 32)>()[%workgroup_id_x, %30]
  %32 = affine.apply affine_map<()[s0, s1] -> ((s0 mod (s1 ceildiv 128)) * 128)>()[%workgroup_id_x, %30]
  %33 = arith.extui %0 : i32 to i64
  %34 = arith.extui %1 : i32 to i64
  %35 = arith.shli %34, %c32_i64 : i64
  %36 = arith.ori %33, %35 : i64
  %37 = arith.index_castui %36 : i64 to index
  %38 = affine.min affine_map<()[s0, s1, s2] -> (32, s0 - (s1 floordiv (s2 ceildiv 128)) * 32)>()[%37, %workgroup_id_x, %30]
  %39 = affine.min affine_map<()[s0, s1] -> (128, s0 - (s1 mod (s0 ceildiv 128)) * 128)>()[%30, %workgroup_id_x]
  %40 = flow.dispatch.tensor.load %15, offsets = [%31, %32], sizes = [%38, %39], strides = [1, 1] : !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%20, %25} -> tensor<?x?xf32>
  %workgroup_id_x_0 = hal.interface.workgroup.id[0] : index
  %41 = affine.min affine_map<()[s0, s1, s2] -> (32, s0 - (s1 floordiv (s2 ceildiv 128)) * 32)>()[%8, %workgroup_id_x_0, %13]
  %42 = affine.min affine_map<()[s0, s1] -> (128, s0 - (s1 mod (s0 ceildiv 128)) * 128)>()[%13, %workgroup_id_x_0]
  %43 = affine.apply affine_map<()[s0, s1] -> ((s0 floordiv (s1 ceildiv 128)) * 32)>()[%workgroup_id_x_0, %13]
  %44 = flow.dispatch.tensor.load %14, offsets = [%43, 0], sizes = [%41, %13], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%8, %13} -> tensor<?x?xf32>
  %45 = affine.apply affine_map<()[s0, s1] -> ((s0 mod (s1 ceildiv 128)) * 128)>()[%workgroup_id_x_0, %13]
  %46 = flow.dispatch.tensor.load %14, offsets = [0, %45], sizes = [%13, %42], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%8, %13} -> tensor<?x?xf32>
  %47 = linalg.fill {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%cst : f32) outs(%40 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %48 = linalg.matmul {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%44, %46 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%47 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %49 = arith.extui %0 : i32 to i64
  %50 = arith.extui %1 : i32 to i64
  %51 = arith.shli %50, %c32_i64 : i64
  %52 = arith.ori %49, %51 : i64
  %53 = arith.index_castui %52 : i64 to index
  %54 = arith.extui %2 : i32 to i64
  %55 = arith.extui %3 : i32 to i64
  %56 = arith.shli %55, %c32_i64 : i64
  %57 = arith.ori %54, %56 : i64
  %58 = arith.index_castui %57 : i64 to index
  %59 = affine.apply affine_map<()[s0, s1] -> ((s0 floordiv (s1 ceildiv 128)) * 32)>()[%workgroup_id_x_0, %13]
  %60 = affine.apply affine_map<()[s0, s1] -> ((s0 mod (s1 ceildiv 128)) * 128)>()[%workgroup_id_x_0, %13]
  flow.dispatch.tensor.store %48, %15, offsets = [%59, %60], sizes = [%41, %42], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%53, %58}
  return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
module {
  func.func @main_dispatch_0_matmul_DxDxD_f32() {
    %c32_i64 = arith.constant 32 : i64
    %cst = arith.constant 0.000000e+00 : f32
    %c0 = arith.constant 0 : index
    %0 = hal.interface.constant.load[0] : i32
    %1 = hal.interface.constant.load[1] : i32
    %2 = hal.interface.constant.load[2] : i32
    %3 = hal.interface.constant.load[3] : i32
    %4 = arith.extui %0 : i32 to i64
    %5 = arith.extui %1 : i32 to i64
    %6 = arith.shli %5, %c32_i64 : i64
    %7 = arith.ori %4, %6 : i64
    %8 = arith.index_castui %7 : i64 to index
    %9 = arith.extui %2 : i32 to i64
    %10 = arith.extui %3 : i32 to i64
    %11 = arith.shli %10, %c32_i64 : i64
    %12 = arith.ori %9, %11 : i64
    %13 = arith.index_castui %12 : i64 to index
    %14 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%8, %13}
    %15 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%8, %13}
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %16 = arith.extui %2 : i32 to i64
    %17 = arith.extui %3 : i32 to i64
    %18 = arith.shli %17, %c32_i64 : i64
    %19 = arith.ori %16, %18 : i64
    %20 = arith.index_castui %19 : i64 to index
    %21 = affine.apply affine_map<()[s0, s1] -> ((s0 floordiv (s1 ceildiv 128)) * 32)>()[%workgroup_id_x, %20]
    %22 = affine.apply affine_map<()[s0, s1] -> ((s0 mod (s1 ceildiv 128)) * 128)>()[%workgroup_id_x, %20]
    %23 = arith.extui %0 : i32 to i64
    %24 = arith.extui %1 : i32 to i64
    %25 = arith.shli %24, %c32_i64 : i64
    %26 = arith.ori %23, %25 : i64
    %27 = arith.index_castui %26 : i64 to index
    %28 = affine.min affine_map<()[s0, s1, s2] -> (32, s0 - (s1 floordiv (s2 ceildiv 128)) * 32)>()[%27, %workgroup_id_x, %20]
    %29 = affine.min affine_map<()[s0, s1] -> (128, s0 - (s1 mod (s0 ceildiv 128)) * 128)>()[%20, %workgroup_id_x]
    %30 = flow.dispatch.tensor.load %15, offsets = [%21, %22], sizes = [%28, %29], strides = [1, 1] : !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%8, %13} -> tensor<?x?xf32>
    %workgroup_id_x_0 = hal.interface.workgroup.id[0] : index
    %31 = affine.min affine_map<()[s0, s1, s2] -> (32, s0 - (s1 floordiv (s2 ceildiv 128)) * 32)>()[%8, %workgroup_id_x_0, %13]
    %32 = affine.min affine_map<()[s0, s1] -> (128, s0 - (s1 mod (s0 ceildiv 128)) * 128)>()[%13, %workgroup_id_x_0]
    %33 = affine.apply affine_map<()[s0, s1] -> ((s0 floordiv (s1 ceildiv 128)) * 32)>()[%workgroup_id_x_0, %13]
    %34 = flow.dispatch.tensor.load %14, offsets = [%33, 0], sizes = [%31, %13], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%8, %13} -> tensor<?x?xf32>
    %35 = affine.apply affine_map<()[s0, s1] -> ((s0 mod (s1 ceildiv 128)) * 128)>()[%workgroup_id_x_0, %13]
    %36 = flow.dispatch.tensor.load %14, offsets = [0, %35], sizes = [%13, %32], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%8, %13} -> tensor<?x?xf32>
    %37 = linalg.fill {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%cst : f32) outs(%30 : tensor<?x?xf32>) -> tensor<?x?xf32>
    %38 = linalg.matmul {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%34, %36 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%37 : tensor<?x?xf32>) -> tensor<?x?xf32>
    %39 = affine.apply affine_map<()[s0, s1] -> ((s0 floordiv (s1 ceildiv 128)) * 32)>()[%workgroup_id_x_0, %13]
    %40 = affine.apply affine_map<()[s0, s1] -> ((s0 mod (s1 ceildiv 128)) * 128)>()[%workgroup_id_x_0, %13]
    flow.dispatch.tensor.store %38, %15, offsets = [%39, %40], sizes = [%31, %32], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%8, %13}
    return
  }
}

// -----// IR Dump After CSE (cse) //----- //
module {
  func.func @main_dispatch_0_matmul_DxDxD_f32() {
    %c32_i64 = arith.constant 32 : i64
    %cst = arith.constant 0.000000e+00 : f32
    %c0 = arith.constant 0 : index
    %0 = hal.interface.constant.load[0] : i32
    %1 = hal.interface.constant.load[1] : i32
    %2 = hal.interface.constant.load[2] : i32
    %3 = hal.interface.constant.load[3] : i32
    %4 = arith.extui %0 : i32 to i64
    %5 = arith.extui %1 : i32 to i64
    %6 = arith.shli %5, %c32_i64 : i64
    %7 = arith.ori %4, %6 : i64
    %8 = arith.index_castui %7 : i64 to index
    %9 = arith.extui %2 : i32 to i64
    %10 = arith.extui %3 : i32 to i64
    %11 = arith.shli %10, %c32_i64 : i64
    %12 = arith.ori %9, %11 : i64
    %13 = arith.index_castui %12 : i64 to index
    %14 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%8, %13}
    %15 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%8, %13}
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %16 = affine.apply affine_map<()[s0, s1] -> ((s0 floordiv (s1 ceildiv 128)) * 32)>()[%workgroup_id_x, %13]
    %17 = affine.apply affine_map<()[s0, s1] -> ((s0 mod (s1 ceildiv 128)) * 128)>()[%workgroup_id_x, %13]
    %18 = affine.min affine_map<()[s0, s1, s2] -> (32, s0 - (s1 floordiv (s2 ceildiv 128)) * 32)>()[%8, %workgroup_id_x, %13]
    %19 = affine.min affine_map<()[s0, s1] -> (128, s0 - (s1 mod (s0 ceildiv 128)) * 128)>()[%13, %workgroup_id_x]
    %20 = flow.dispatch.tensor.load %15, offsets = [%16, %17], sizes = [%18, %19], strides = [1, 1] : !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%8, %13} -> tensor<?x?xf32>
    %21 = flow.dispatch.tensor.load %14, offsets = [%16, 0], sizes = [%18, %13], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%8, %13} -> tensor<?x?xf32>
    %22 = flow.dispatch.tensor.load %14, offsets = [0, %17], sizes = [%13, %19], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%8, %13} -> tensor<?x?xf32>
    %23 = linalg.fill {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%cst : f32) outs(%20 : tensor<?x?xf32>) -> tensor<?x?xf32>
    %24 = linalg.matmul {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%21, %22 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%23 : tensor<?x?xf32>) -> tensor<?x?xf32>
    flow.dispatch.tensor.store %24, %15, offsets = [%16, %17], sizes = [%18, %19], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%8, %13}
    return
  }
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
module {
  func.func @main_dispatch_0_matmul_DxDxD_f32() {
    %c32_i64 = arith.constant 32 : i64
    %cst = arith.constant 0.000000e+00 : f32
    %c0 = arith.constant 0 : index
    %0 = hal.interface.constant.load[0] : i32
    %1 = hal.interface.constant.load[1] : i32
    %2 = hal.interface.constant.load[2] : i32
    %3 = hal.interface.constant.load[3] : i32
    %4 = arith.extui %0 : i32 to i64
    %5 = arith.extui %1 : i32 to i64
    %6 = arith.shli %5, %c32_i64 : i64
    %7 = arith.ori %4, %6 : i64
    %8 = arith.index_castui %7 : i64 to index
    %9 = arith.extui %2 : i32 to i64
    %10 = arith.extui %3 : i32 to i64
    %11 = arith.shli %10, %c32_i64 : i64
    %12 = arith.ori %9, %11 : i64
    %13 = arith.index_castui %12 : i64 to index
    %14 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%8, %13}
    %15 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%8, %13}
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %16 = affine.apply affine_map<()[s0, s1] -> ((s0 floordiv (s1 ceildiv 128)) * 32)>()[%workgroup_id_x, %13]
    %17 = affine.apply affine_map<()[s0, s1] -> ((s0 mod (s1 ceildiv 128)) * 128)>()[%workgroup_id_x, %13]
    %18 = affine.min affine_map<()[s0, s1, s2] -> (32, s0 - (s1 floordiv (s2 ceildiv 128)) * 32)>()[%8, %workgroup_id_x, %13]
    %19 = affine.min affine_map<()[s0, s1] -> (128, s0 - (s1 mod (s0 ceildiv 128)) * 128)>()[%13, %workgroup_id_x]
    %20 = flow.dispatch.tensor.load %15, offsets = [%16, %17], sizes = [%18, %19], strides = [1, 1] : !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%8, %13} -> tensor<?x?xf32>
    %21 = flow.dispatch.tensor.load %14, offsets = [%16, 0], sizes = [%18, %13], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%8, %13} -> tensor<?x?xf32>
    %22 = flow.dispatch.tensor.load %14, offsets = [0, %17], sizes = [%13, %19], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%8, %13} -> tensor<?x?xf32>
    %23 = linalg.fill {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%cst : f32) outs(%20 : tensor<?x?xf32>) -> tensor<?x?xf32>
    %24 = linalg.matmul {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%21, %22 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%23 : tensor<?x?xf32>) -> tensor<?x?xf32>
    flow.dispatch.tensor.store %24, %15, offsets = [%16, %17], sizes = [%18, %19], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%8, %13}
    return
  }
}

// -----// IR Dump After WorkgroupSpecialization (iree-codegen-workgroup-specialization) //----- //
func.func @main_dispatch_0_matmul_DxDxD_f32() {
  %c32_i64 = arith.constant 32 : i64
  %cst = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.constant.load[0] : i32
  %1 = hal.interface.constant.load[1] : i32
  %2 = hal.interface.constant.load[2] : i32
  %3 = hal.interface.constant.load[3] : i32
  %4 = arith.extui %0 : i32 to i64
  %5 = arith.extui %1 : i32 to i64
  %6 = arith.shli %5, %c32_i64 : i64
  %7 = arith.ori %4, %6 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %2 : i32 to i64
  %10 = arith.extui %3 : i32 to i64
  %11 = arith.shli %10, %c32_i64 : i64
  %12 = arith.ori %9, %11 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%8, %13}
  %15 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%8, %13}
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %16 = affine.apply affine_map<()[s0, s1] -> ((s0 floordiv (s1 ceildiv 128)) * 32)>()[%workgroup_id_x, %13]
  %17 = affine.apply affine_map<()[s0, s1] -> ((s0 mod (s1 ceildiv 128)) * 128)>()[%workgroup_id_x, %13]
  %18 = affine.min affine_map<()[s0, s1, s2] -> (32, s0 - (s1 floordiv (s2 ceildiv 128)) * 32)>()[%8, %workgroup_id_x, %13]
  %19 = affine.min affine_map<()[s0, s1] -> (128, s0 - (s1 mod (s0 ceildiv 128)) * 128)>()[%13, %workgroup_id_x]
  %20 = flow.dispatch.tensor.load %15, offsets = [%16, %17], sizes = [%18, %19], strides = [1, 1] : !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%8, %13} -> tensor<?x?xf32>
  %21 = flow.dispatch.tensor.load %14, offsets = [%16, 0], sizes = [%18, %13], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%8, %13} -> tensor<?x?xf32>
  %22 = flow.dispatch.tensor.load %14, offsets = [0, %17], sizes = [%13, %19], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%8, %13} -> tensor<?x?xf32>
  %23 = linalg.fill {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%cst : f32) outs(%20 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %24 = linalg.matmul {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%21, %22 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%23 : tensor<?x?xf32>) -> tensor<?x?xf32>
  flow.dispatch.tensor.store %24, %15, offsets = [%16, %17], sizes = [%18, %19], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%8, %13}
  return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
module {
  func.func @main_dispatch_0_matmul_DxDxD_f32() {
    %c32_i64 = arith.constant 32 : i64
    %cst = arith.constant 0.000000e+00 : f32
    %c0 = arith.constant 0 : index
    %0 = hal.interface.constant.load[0] : i32
    %1 = hal.interface.constant.load[1] : i32
    %2 = hal.interface.constant.load[2] : i32
    %3 = hal.interface.constant.load[3] : i32
    %4 = arith.extui %0 : i32 to i64
    %5 = arith.extui %1 : i32 to i64
    %6 = arith.shli %5, %c32_i64 : i64
    %7 = arith.ori %4, %6 : i64
    %8 = arith.index_castui %7 : i64 to index
    %9 = arith.extui %2 : i32 to i64
    %10 = arith.extui %3 : i32 to i64
    %11 = arith.shli %10, %c32_i64 : i64
    %12 = arith.ori %9, %11 : i64
    %13 = arith.index_castui %12 : i64 to index
    %14 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%8, %13}
    %15 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%8, %13}
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %16 = affine.apply affine_map<()[s0, s1] -> ((s0 floordiv (s1 ceildiv 128)) * 32)>()[%workgroup_id_x, %13]
    %17 = affine.apply affine_map<()[s0, s1] -> ((s0 mod (s1 ceildiv 128)) * 128)>()[%workgroup_id_x, %13]
    %18 = affine.min affine_map<()[s0, s1, s2] -> (32, s0 - (s1 floordiv (s2 ceildiv 128)) * 32)>()[%8, %workgroup_id_x, %13]
    %19 = affine.min affine_map<()[s0, s1] -> (128, s0 - (s1 mod (s0 ceildiv 128)) * 128)>()[%13, %workgroup_id_x]
    %20 = flow.dispatch.tensor.load %15, offsets = [%16, %17], sizes = [%18, %19], strides = [1, 1] : !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%8, %13} -> tensor<?x?xf32>
    %21 = flow.dispatch.tensor.load %14, offsets = [%16, 0], sizes = [%18, %13], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%8, %13} -> tensor<?x?xf32>
    %22 = flow.dispatch.tensor.load %14, offsets = [0, %17], sizes = [%13, %19], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%8, %13} -> tensor<?x?xf32>
    %23 = linalg.fill {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%cst : f32) outs(%20 : tensor<?x?xf32>) -> tensor<?x?xf32>
    %24 = linalg.matmul {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%21, %22 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%23 : tensor<?x?xf32>) -> tensor<?x?xf32>
    flow.dispatch.tensor.store %24, %15, offsets = [%16, %17], sizes = [%18, %19], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%8, %13}
    return
  }
}

// -----// IR Dump After CSE (cse) //----- //
module {
  func.func @main_dispatch_0_matmul_DxDxD_f32() {
    %c32_i64 = arith.constant 32 : i64
    %cst = arith.constant 0.000000e+00 : f32
    %c0 = arith.constant 0 : index
    %0 = hal.interface.constant.load[0] : i32
    %1 = hal.interface.constant.load[1] : i32
    %2 = hal.interface.constant.load[2] : i32
    %3 = hal.interface.constant.load[3] : i32
    %4 = arith.extui %0 : i32 to i64
    %5 = arith.extui %1 : i32 to i64
    %6 = arith.shli %5, %c32_i64 : i64
    %7 = arith.ori %4, %6 : i64
    %8 = arith.index_castui %7 : i64 to index
    %9 = arith.extui %2 : i32 to i64
    %10 = arith.extui %3 : i32 to i64
    %11 = arith.shli %10, %c32_i64 : i64
    %12 = arith.ori %9, %11 : i64
    %13 = arith.index_castui %12 : i64 to index
    %14 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%8, %13}
    %15 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%8, %13}
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %16 = affine.apply affine_map<()[s0, s1] -> ((s0 floordiv (s1 ceildiv 128)) * 32)>()[%workgroup_id_x, %13]
    %17 = affine.apply affine_map<()[s0, s1] -> ((s0 mod (s1 ceildiv 128)) * 128)>()[%workgroup_id_x, %13]
    %18 = affine.min affine_map<()[s0, s1, s2] -> (32, s0 - (s1 floordiv (s2 ceildiv 128)) * 32)>()[%8, %workgroup_id_x, %13]
    %19 = affine.min affine_map<()[s0, s1] -> (128, s0 - (s1 mod (s0 ceildiv 128)) * 128)>()[%13, %workgroup_id_x]
    %20 = flow.dispatch.tensor.load %15, offsets = [%16, %17], sizes = [%18, %19], strides = [1, 1] : !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%8, %13} -> tensor<?x?xf32>
    %21 = flow.dispatch.tensor.load %14, offsets = [%16, 0], sizes = [%18, %13], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%8, %13} -> tensor<?x?xf32>
    %22 = flow.dispatch.tensor.load %14, offsets = [0, %17], sizes = [%13, %19], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%8, %13} -> tensor<?x?xf32>
    %23 = linalg.fill {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%cst : f32) outs(%20 : tensor<?x?xf32>) -> tensor<?x?xf32>
    %24 = linalg.matmul {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%21, %22 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%23 : tensor<?x?xf32>) -> tensor<?x?xf32>
    flow.dispatch.tensor.store %24, %15, offsets = [%16, %17], sizes = [%18, %19], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%8, %13}
    return
  }
}

// -----// IR Dump After GPUTensorAlloc (iree-codegen-gpu-tensor-alloc) //----- //
func.func @main_dispatch_0_matmul_DxDxD_f32() {
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c32_i64 = arith.constant 32 : i64
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.interface.constant.load[0] : i32
  %1 = hal.interface.constant.load[1] : i32
  %2 = hal.interface.constant.load[2] : i32
  %3 = hal.interface.constant.load[3] : i32
  %4 = arith.extui %0 : i32 to i64
  %5 = arith.extui %1 : i32 to i64
  %6 = arith.shli %5, %c32_i64 : i64
  %7 = arith.ori %4, %6 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %2 : i32 to i64
  %10 = arith.extui %3 : i32 to i64
  %11 = arith.shli %10, %c32_i64 : i64
  %12 = arith.ori %9, %11 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%8, %13}
  %15 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%8, %13}
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %16 = affine.apply affine_map<()[s0, s1] -> ((s0 floordiv (s1 ceildiv 128)) * 32)>()[%workgroup_id_x, %13]
  %17 = affine.apply affine_map<()[s0, s1] -> ((s0 mod (s1 ceildiv 128)) * 128)>()[%workgroup_id_x, %13]
  %18 = affine.min affine_map<()[s0, s1, s2] -> (32, s0 - (s1 floordiv (s2 ceildiv 128)) * 32)>()[%8, %workgroup_id_x, %13]
  %19 = affine.min affine_map<()[s0, s1] -> (128, s0 - (s1 mod (s0 ceildiv 128)) * 128)>()[%13, %workgroup_id_x]
  %20 = flow.dispatch.tensor.load %15, offsets = [%16, %17], sizes = [%18, %19], strides = [1, 1] : !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%8, %13} -> tensor<?x?xf32>
  %21 = flow.dispatch.tensor.load %14, offsets = [%16, 0], sizes = [%18, %13], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%8, %13} -> tensor<?x?xf32>
  %22 = flow.dispatch.tensor.load %14, offsets = [0, %17], sizes = [%13, %19], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%8, %13} -> tensor<?x?xf32>
  %23 = linalg.fill {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%cst : f32) outs(%20 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %dim = tensor.dim %21, %c0 : tensor<?x?xf32>
  %dim_0 = tensor.dim %21, %c1 : tensor<?x?xf32>
  %dim_1 = tensor.dim %22, %c1 : tensor<?x?xf32>
  %24 = scf.for %arg0 = %c0 to %dim_0 step %c1 iter_args(%arg1 = %23) -> (tensor<?x?xf32>) {
    %extracted_slice = tensor.extract_slice %21[0, %arg0] [%dim, 1] [1, 1] : tensor<?x?xf32> to tensor<?x1xf32>
    %extracted_slice_2 = tensor.extract_slice %22[%arg0, 0] [1, %dim_1] [1, 1] : tensor<?x?xf32> to tensor<1x?xf32>
    %extracted_slice_3 = tensor.extract_slice %arg1[0, 0] [%dim, %dim_1] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %25 = linalg.matmul {__internal_linalg_transform__ = "workgroup_k_tiled", lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%extracted_slice, %extracted_slice_2 : tensor<?x1xf32>, tensor<1x?xf32>) outs(%extracted_slice_3 : tensor<?x?xf32>) -> tensor<?x?xf32>
    %inserted_slice = tensor.insert_slice %25 into %arg1[0, 0] [%dim, %dim_1] [1, 1] : tensor<?x?xf32> into tensor<?x?xf32>
    scf.yield %inserted_slice : tensor<?x?xf32>
  }
  flow.dispatch.tensor.store %24, %15, offsets = [%16, %17], sizes = [%18, %19], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%8, %13}
  return
}

// -----// IR Dump After GPUTensorTile (iree-codegen-gpu-tensor-tile) //----- //
func.func @main_dispatch_0_matmul_DxDxD_f32() {
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c32_i64 = arith.constant 32 : i64
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.interface.constant.load[0] : i32
  %1 = hal.interface.constant.load[1] : i32
  %2 = hal.interface.constant.load[2] : i32
  %3 = hal.interface.constant.load[3] : i32
  %4 = arith.extui %0 : i32 to i64
  %5 = arith.extui %1 : i32 to i64
  %6 = arith.shli %5, %c32_i64 : i64
  %7 = arith.ori %4, %6 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %2 : i32 to i64
  %10 = arith.extui %3 : i32 to i64
  %11 = arith.shli %10, %c32_i64 : i64
  %12 = arith.ori %9, %11 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%8, %13}
  %15 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%8, %13}
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %16 = affine.apply affine_map<()[s0, s1] -> ((s0 floordiv (s1 ceildiv 128)) * 32)>()[%workgroup_id_x, %13]
  %17 = affine.apply affine_map<()[s0, s1] -> ((s0 mod (s1 ceildiv 128)) * 128)>()[%workgroup_id_x, %13]
  %18 = affine.min affine_map<()[s0, s1, s2] -> (32, s0 - (s1 floordiv (s2 ceildiv 128)) * 32)>()[%8, %workgroup_id_x, %13]
  %19 = affine.min affine_map<()[s0, s1] -> (128, s0 - (s1 mod (s0 ceildiv 128)) * 128)>()[%13, %workgroup_id_x]
  %20 = flow.dispatch.tensor.load %15, offsets = [%16, %17], sizes = [%18, %19], strides = [1, 1] : !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%8, %13} -> tensor<?x?xf32>
  %21 = flow.dispatch.tensor.load %14, offsets = [%16, 0], sizes = [%18, %13], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%8, %13} -> tensor<?x?xf32>
  %22 = flow.dispatch.tensor.load %14, offsets = [0, %17], sizes = [%13, %19], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%8, %13} -> tensor<?x?xf32>
  %dim = tensor.dim %20, %c0 : tensor<?x?xf32>
  %dim_0 = tensor.dim %20, %c1 : tensor<?x?xf32>
  %23 = scf.forall (%arg0, %arg1) in (8, 32) shared_outs(%arg2 = %20) -> (tensor<?x?xf32>) {
    %25 = affine.min affine_map<(d0)[s0] -> (-(d0 * (s0 ceildiv 8)) + s0, s0 ceildiv 8)>(%arg0)[%dim]
    %26 = affine.max affine_map<(d0) -> (0, d0)>(%25)
    %27 = affine.min affine_map<(d0)[s0] -> (-(d0 * (s0 ceildiv 32)) + s0, s0 ceildiv 32)>(%arg1)[%dim_0]
    %28 = affine.max affine_map<(d0) -> (0, d0)>(%27)
    %29 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 8))>(%arg0)[%dim]
    %30 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 32))>(%arg1)[%dim_0]
    %extracted_slice = tensor.extract_slice %arg2[%29, %30] [%26, %28] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %31 = linalg.fill {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%cst : f32) outs(%extracted_slice : tensor<?x?xf32>) -> tensor<?x?xf32>
    %32 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 8))>(%arg0)[%dim]
    %33 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 32))>(%arg1)[%dim_0]
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %31 into %arg2[%32, %33] [%26, %28] [1, 1] : tensor<?x?xf32> into tensor<?x?xf32>
    }
  } {mapping = [#gpu.thread<y>, #gpu.thread<x>]}
  %dim_1 = tensor.dim %21, %c0 : tensor<?x?xf32>
  %dim_2 = tensor.dim %21, %c1 : tensor<?x?xf32>
  %dim_3 = tensor.dim %22, %c1 : tensor<?x?xf32>
  %24 = scf.for %arg0 = %c0 to %dim_2 step %c1 iter_args(%arg1 = %23) -> (tensor<?x?xf32>) {
    %extracted_slice = tensor.extract_slice %21[0, %arg0] [%dim_1, 1] [1, 1] : tensor<?x?xf32> to tensor<?x1xf32>
    %extracted_slice_4 = tensor.extract_slice %22[%arg0, 0] [1, %dim_3] [1, 1] : tensor<?x?xf32> to tensor<1x?xf32>
    %extracted_slice_5 = tensor.extract_slice %arg1[0, 0] [%dim_1, %dim_3] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %25 = scf.forall (%arg2, %arg3) in (8, 32) shared_outs(%arg4 = %extracted_slice_5) -> (tensor<?x?xf32>) {
      %26 = affine.min affine_map<(d0)[s0] -> (-(d0 * (s0 ceildiv 8)) + s0, s0 ceildiv 8)>(%arg2)[%dim_1]
      %27 = affine.max affine_map<(d0) -> (0, d0)>(%26)
      %28 = affine.min affine_map<(d0)[s0] -> (-(d0 * (s0 ceildiv 32)) + s0, s0 ceildiv 32)>(%arg3)[%dim_3]
      %29 = affine.max affine_map<(d0) -> (0, d0)>(%28)
      %30 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 8))>(%arg2)[%dim_1]
      %31 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 32))>(%arg3)[%dim_3]
      %32 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 8))>(%arg2)[%dim_1]
      %33 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 32))>(%arg3)[%dim_3]
      %extracted_slice_6 = tensor.extract_slice %extracted_slice[%30, 0] [%27, 1] [1, 1] : tensor<?x1xf32> to tensor<?x1xf32>
      %extracted_slice_7 = tensor.extract_slice %extracted_slice_4[0, %31] [1, %29] [1, 1] : tensor<1x?xf32> to tensor<1x?xf32>
      %extracted_slice_8 = tensor.extract_slice %arg4[%32, %33] [%27, %29] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
      %34 = linalg.matmul {__internal_linalg_transform__ = "workgroup_k_tiled", lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%extracted_slice_6, %extracted_slice_7 : tensor<?x1xf32>, tensor<1x?xf32>) outs(%extracted_slice_8 : tensor<?x?xf32>) -> tensor<?x?xf32>
      %35 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 8))>(%arg2)[%dim_1]
      %36 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 32))>(%arg3)[%dim_3]
      scf.forall.in_parallel {
        tensor.parallel_insert_slice %34 into %arg4[%35, %36] [%27, %29] [1, 1] : tensor<?x?xf32> into tensor<?x?xf32>
      }
    } {mapping = [#gpu.thread<y>, #gpu.thread<x>]}
    %inserted_slice = tensor.insert_slice %25 into %arg1[0, 0] [%dim_1, %dim_3] [1, 1] : tensor<?x?xf32> into tensor<?x?xf32>
    scf.yield %inserted_slice : tensor<?x?xf32>
  }
  flow.dispatch.tensor.store %24, %15, offsets = [%16, %17], sizes = [%18, %19], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%8, %13}
  return
}

// -----// IR Dump After DecomposeConvolutionToLowerDimOps (iree-codegen-decompose-convolution-to-lower-dim-ops) //----- //
func.func @main_dispatch_0_matmul_DxDxD_f32() {
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c32_i64 = arith.constant 32 : i64
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.interface.constant.load[0] : i32
  %1 = hal.interface.constant.load[1] : i32
  %2 = hal.interface.constant.load[2] : i32
  %3 = hal.interface.constant.load[3] : i32
  %4 = arith.extui %0 : i32 to i64
  %5 = arith.extui %1 : i32 to i64
  %6 = arith.shli %5, %c32_i64 : i64
  %7 = arith.ori %4, %6 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %2 : i32 to i64
  %10 = arith.extui %3 : i32 to i64
  %11 = arith.shli %10, %c32_i64 : i64
  %12 = arith.ori %9, %11 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%8, %13}
  %15 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%8, %13}
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %16 = affine.apply affine_map<()[s0, s1] -> ((s0 floordiv (s1 ceildiv 128)) * 32)>()[%workgroup_id_x, %13]
  %17 = affine.apply affine_map<()[s0, s1] -> ((s0 mod (s1 ceildiv 128)) * 128)>()[%workgroup_id_x, %13]
  %18 = affine.min affine_map<()[s0, s1, s2] -> (32, s0 - (s1 floordiv (s2 ceildiv 128)) * 32)>()[%8, %workgroup_id_x, %13]
  %19 = affine.min affine_map<()[s0, s1] -> (128, s0 - (s1 mod (s0 ceildiv 128)) * 128)>()[%13, %workgroup_id_x]
  %20 = flow.dispatch.tensor.load %15, offsets = [%16, %17], sizes = [%18, %19], strides = [1, 1] : !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%8, %13} -> tensor<?x?xf32>
  %21 = flow.dispatch.tensor.load %14, offsets = [%16, 0], sizes = [%18, %13], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%8, %13} -> tensor<?x?xf32>
  %22 = flow.dispatch.tensor.load %14, offsets = [0, %17], sizes = [%13, %19], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%8, %13} -> tensor<?x?xf32>
  %dim = tensor.dim %20, %c0 : tensor<?x?xf32>
  %dim_0 = tensor.dim %20, %c1 : tensor<?x?xf32>
  %23 = scf.forall (%arg0, %arg1) in (8, 32) shared_outs(%arg2 = %20) -> (tensor<?x?xf32>) {
    %25 = affine.min affine_map<(d0)[s0] -> (-(d0 * (s0 ceildiv 8)) + s0, s0 ceildiv 8)>(%arg0)[%dim]
    %26 = affine.max affine_map<(d0) -> (0, d0)>(%25)
    %27 = affine.min affine_map<(d0)[s0] -> (-(d0 * (s0 ceildiv 32)) + s0, s0 ceildiv 32)>(%arg1)[%dim_0]
    %28 = affine.max affine_map<(d0) -> (0, d0)>(%27)
    %29 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 8))>(%arg0)[%dim]
    %30 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 32))>(%arg1)[%dim_0]
    %extracted_slice = tensor.extract_slice %arg2[%29, %30] [%26, %28] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %31 = linalg.fill {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%cst : f32) outs(%extracted_slice : tensor<?x?xf32>) -> tensor<?x?xf32>
    %32 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 8))>(%arg0)[%dim]
    %33 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 32))>(%arg1)[%dim_0]
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %31 into %arg2[%32, %33] [%26, %28] [1, 1] : tensor<?x?xf32> into tensor<?x?xf32>
    }
  } {mapping = [#gpu.thread<y>, #gpu.thread<x>]}
  %dim_1 = tensor.dim %21, %c0 : tensor<?x?xf32>
  %dim_2 = tensor.dim %21, %c1 : tensor<?x?xf32>
  %dim_3 = tensor.dim %22, %c1 : tensor<?x?xf32>
  %24 = scf.for %arg0 = %c0 to %dim_2 step %c1 iter_args(%arg1 = %23) -> (tensor<?x?xf32>) {
    %extracted_slice = tensor.extract_slice %21[0, %arg0] [%dim_1, 1] [1, 1] : tensor<?x?xf32> to tensor<?x1xf32>
    %extracted_slice_4 = tensor.extract_slice %22[%arg0, 0] [1, %dim_3] [1, 1] : tensor<?x?xf32> to tensor<1x?xf32>
    %extracted_slice_5 = tensor.extract_slice %arg1[0, 0] [%dim_1, %dim_3] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %25 = scf.forall (%arg2, %arg3) in (8, 32) shared_outs(%arg4 = %extracted_slice_5) -> (tensor<?x?xf32>) {
      %26 = affine.min affine_map<(d0)[s0] -> (-(d0 * (s0 ceildiv 8)) + s0, s0 ceildiv 8)>(%arg2)[%dim_1]
      %27 = affine.max affine_map<(d0) -> (0, d0)>(%26)
      %28 = affine.min affine_map<(d0)[s0] -> (-(d0 * (s0 ceildiv 32)) + s0, s0 ceildiv 32)>(%arg3)[%dim_3]
      %29 = affine.max affine_map<(d0) -> (0, d0)>(%28)
      %30 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 8))>(%arg2)[%dim_1]
      %31 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 32))>(%arg3)[%dim_3]
      %32 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 8))>(%arg2)[%dim_1]
      %33 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 32))>(%arg3)[%dim_3]
      %extracted_slice_6 = tensor.extract_slice %extracted_slice[%30, 0] [%27, 1] [1, 1] : tensor<?x1xf32> to tensor<?x1xf32>
      %extracted_slice_7 = tensor.extract_slice %extracted_slice_4[0, %31] [1, %29] [1, 1] : tensor<1x?xf32> to tensor<1x?xf32>
      %extracted_slice_8 = tensor.extract_slice %arg4[%32, %33] [%27, %29] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
      %34 = linalg.matmul {__internal_linalg_transform__ = "workgroup_k_tiled", lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%extracted_slice_6, %extracted_slice_7 : tensor<?x1xf32>, tensor<1x?xf32>) outs(%extracted_slice_8 : tensor<?x?xf32>) -> tensor<?x?xf32>
      %35 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 8))>(%arg2)[%dim_1]
      %36 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 32))>(%arg3)[%dim_3]
      scf.forall.in_parallel {
        tensor.parallel_insert_slice %34 into %arg4[%35, %36] [%27, %29] [1, 1] : tensor<?x?xf32> into tensor<?x?xf32>
      }
    } {mapping = [#gpu.thread<y>, #gpu.thread<x>]}
    %inserted_slice = tensor.insert_slice %25 into %arg1[0, 0] [%dim_1, %dim_3] [1, 1] : tensor<?x?xf32> into tensor<?x?xf32>
    scf.yield %inserted_slice : tensor<?x?xf32>
  }
  flow.dispatch.tensor.store %24, %15, offsets = [%16, %17], sizes = [%18, %19], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%8, %13}
  return
}

// -----// IR Dump After GenericVectorization (iree-codegen-generic-vectorization) //----- //
func.func @main_dispatch_0_matmul_DxDxD_f32() {
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c32_i64 = arith.constant 32 : i64
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.interface.constant.load[0] : i32
  %1 = hal.interface.constant.load[1] : i32
  %2 = hal.interface.constant.load[2] : i32
  %3 = hal.interface.constant.load[3] : i32
  %4 = arith.extui %0 : i32 to i64
  %5 = arith.extui %1 : i32 to i64
  %6 = arith.shli %5, %c32_i64 : i64
  %7 = arith.ori %4, %6 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %2 : i32 to i64
  %10 = arith.extui %3 : i32 to i64
  %11 = arith.shli %10, %c32_i64 : i64
  %12 = arith.ori %9, %11 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%8, %13}
  %15 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%8, %13}
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %16 = affine.apply affine_map<()[s0, s1] -> ((s0 floordiv (s1 ceildiv 128)) * 32)>()[%workgroup_id_x, %13]
  %17 = affine.apply affine_map<()[s0, s1] -> ((s0 mod (s1 ceildiv 128)) * 128)>()[%workgroup_id_x, %13]
  %18 = affine.min affine_map<()[s0, s1, s2] -> (32, s0 - (s1 floordiv (s2 ceildiv 128)) * 32)>()[%8, %workgroup_id_x, %13]
  %19 = affine.min affine_map<()[s0, s1] -> (128, s0 - (s1 mod (s0 ceildiv 128)) * 128)>()[%13, %workgroup_id_x]
  %20 = flow.dispatch.tensor.load %15, offsets = [%16, %17], sizes = [%18, %19], strides = [1, 1] : !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%8, %13} -> tensor<?x?xf32>
  %21 = flow.dispatch.tensor.load %14, offsets = [%16, 0], sizes = [%18, %13], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%8, %13} -> tensor<?x?xf32>
  %22 = flow.dispatch.tensor.load %14, offsets = [0, %17], sizes = [%13, %19], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%8, %13} -> tensor<?x?xf32>
  %dim = tensor.dim %20, %c0 : tensor<?x?xf32>
  %dim_0 = tensor.dim %20, %c1 : tensor<?x?xf32>
  %23 = scf.forall (%arg0, %arg1) in (8, 32) shared_outs(%arg2 = %20) -> (tensor<?x?xf32>) {
    %25 = affine.min affine_map<(d0)[s0] -> (-(d0 * (s0 ceildiv 8)) + s0, s0 ceildiv 8)>(%arg0)[%dim]
    %26 = affine.max affine_map<(d0) -> (0, d0)>(%25)
    %27 = affine.min affine_map<(d0)[s0] -> (-(d0 * (s0 ceildiv 32)) + s0, s0 ceildiv 32)>(%arg1)[%dim_0]
    %28 = affine.max affine_map<(d0) -> (0, d0)>(%27)
    %29 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 8))>(%arg0)[%dim]
    %30 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 32))>(%arg1)[%dim_0]
    %extracted_slice = tensor.extract_slice %arg2[%29, %30] [%26, %28] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %31 = linalg.fill {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%cst : f32) outs(%extracted_slice : tensor<?x?xf32>) -> tensor<?x?xf32>
    %32 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 8))>(%arg0)[%dim]
    %33 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 32))>(%arg1)[%dim_0]
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %31 into %arg2[%32, %33] [%26, %28] [1, 1] : tensor<?x?xf32> into tensor<?x?xf32>
    }
  } {mapping = [#gpu.thread<y>, #gpu.thread<x>]}
  %dim_1 = tensor.dim %21, %c0 : tensor<?x?xf32>
  %dim_2 = tensor.dim %21, %c1 : tensor<?x?xf32>
  %dim_3 = tensor.dim %22, %c1 : tensor<?x?xf32>
  %24 = scf.for %arg0 = %c0 to %dim_2 step %c1 iter_args(%arg1 = %23) -> (tensor<?x?xf32>) {
    %extracted_slice = tensor.extract_slice %21[0, %arg0] [%dim_1, 1] [1, 1] : tensor<?x?xf32> to tensor<?x1xf32>
    %extracted_slice_4 = tensor.extract_slice %22[%arg0, 0] [1, %dim_3] [1, 1] : tensor<?x?xf32> to tensor<1x?xf32>
    %extracted_slice_5 = tensor.extract_slice %arg1[0, 0] [%dim_1, %dim_3] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %25 = scf.forall (%arg2, %arg3) in (8, 32) shared_outs(%arg4 = %extracted_slice_5) -> (tensor<?x?xf32>) {
      %26 = affine.min affine_map<(d0)[s0] -> (-(d0 * (s0 ceildiv 8)) + s0, s0 ceildiv 8)>(%arg2)[%dim_1]
      %27 = affine.max affine_map<(d0) -> (0, d0)>(%26)
      %28 = affine.min affine_map<(d0)[s0] -> (-(d0 * (s0 ceildiv 32)) + s0, s0 ceildiv 32)>(%arg3)[%dim_3]
      %29 = affine.max affine_map<(d0) -> (0, d0)>(%28)
      %30 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 8))>(%arg2)[%dim_1]
      %31 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 32))>(%arg3)[%dim_3]
      %32 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 8))>(%arg2)[%dim_1]
      %33 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 32))>(%arg3)[%dim_3]
      %extracted_slice_6 = tensor.extract_slice %extracted_slice[%30, 0] [%27, 1] [1, 1] : tensor<?x1xf32> to tensor<?x1xf32>
      %extracted_slice_7 = tensor.extract_slice %extracted_slice_4[0, %31] [1, %29] [1, 1] : tensor<1x?xf32> to tensor<1x?xf32>
      %extracted_slice_8 = tensor.extract_slice %arg4[%32, %33] [%27, %29] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
      %34 = linalg.matmul {__internal_linalg_transform__ = "workgroup_k_tiled", lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%extracted_slice_6, %extracted_slice_7 : tensor<?x1xf32>, tensor<1x?xf32>) outs(%extracted_slice_8 : tensor<?x?xf32>) -> tensor<?x?xf32>
      %35 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 8))>(%arg2)[%dim_1]
      %36 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 32))>(%arg3)[%dim_3]
      scf.forall.in_parallel {
        tensor.parallel_insert_slice %34 into %arg4[%35, %36] [%27, %29] [1, 1] : tensor<?x?xf32> into tensor<?x?xf32>
      }
    } {mapping = [#gpu.thread<y>, #gpu.thread<x>]}
    %inserted_slice = tensor.insert_slice %25 into %arg1[0, 0] [%dim_1, %dim_3] [1, 1] : tensor<?x?xf32> into tensor<?x?xf32>
    scf.yield %inserted_slice : tensor<?x?xf32>
  }
  flow.dispatch.tensor.store %24, %15, offsets = [%16, %17], sizes = [%18, %19], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%8, %13}
  return
}

// -----// IR Dump After HoistRedundantVectorTransfers (iree-codegen-hoist-redundant-vector-transfers) //----- //
func.func @main_dispatch_0_matmul_DxDxD_f32() {
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c32_i64 = arith.constant 32 : i64
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.interface.constant.load[0] : i32
  %1 = hal.interface.constant.load[1] : i32
  %2 = hal.interface.constant.load[2] : i32
  %3 = hal.interface.constant.load[3] : i32
  %4 = arith.extui %0 : i32 to i64
  %5 = arith.extui %1 : i32 to i64
  %6 = arith.shli %5, %c32_i64 : i64
  %7 = arith.ori %4, %6 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %2 : i32 to i64
  %10 = arith.extui %3 : i32 to i64
  %11 = arith.shli %10, %c32_i64 : i64
  %12 = arith.ori %9, %11 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%8, %13}
  %15 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%8, %13}
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %16 = affine.apply affine_map<()[s0, s1] -> ((s0 floordiv (s1 ceildiv 128)) * 32)>()[%workgroup_id_x, %13]
  %17 = affine.apply affine_map<()[s0, s1] -> ((s0 mod (s1 ceildiv 128)) * 128)>()[%workgroup_id_x, %13]
  %18 = affine.min affine_map<()[s0, s1, s2] -> (32, s0 - (s1 floordiv (s2 ceildiv 128)) * 32)>()[%8, %workgroup_id_x, %13]
  %19 = affine.min affine_map<()[s0, s1] -> (128, s0 - (s1 mod (s0 ceildiv 128)) * 128)>()[%13, %workgroup_id_x]
  %20 = flow.dispatch.tensor.load %15, offsets = [%16, %17], sizes = [%18, %19], strides = [1, 1] : !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%8, %13} -> tensor<?x?xf32>
  %21 = flow.dispatch.tensor.load %14, offsets = [%16, 0], sizes = [%18, %13], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%8, %13} -> tensor<?x?xf32>
  %22 = flow.dispatch.tensor.load %14, offsets = [0, %17], sizes = [%13, %19], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%8, %13} -> tensor<?x?xf32>
  %dim = tensor.dim %20, %c0 : tensor<?x?xf32>
  %dim_0 = tensor.dim %20, %c1 : tensor<?x?xf32>
  %23 = scf.forall (%arg0, %arg1) in (8, 32) shared_outs(%arg2 = %20) -> (tensor<?x?xf32>) {
    %25 = affine.min affine_map<(d0)[s0] -> (-(d0 * (s0 ceildiv 8)) + s0, s0 ceildiv 8)>(%arg0)[%dim]
    %26 = affine.max affine_map<(d0) -> (0, d0)>(%25)
    %27 = affine.min affine_map<(d0)[s0] -> (-(d0 * (s0 ceildiv 32)) + s0, s0 ceildiv 32)>(%arg1)[%dim_0]
    %28 = affine.max affine_map<(d0) -> (0, d0)>(%27)
    %29 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 8))>(%arg0)[%dim]
    %30 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 32))>(%arg1)[%dim_0]
    %extracted_slice_4 = tensor.extract_slice %arg2[%29, %30] [%26, %28] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %31 = linalg.fill {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%cst : f32) outs(%extracted_slice_4 : tensor<?x?xf32>) -> tensor<?x?xf32>
    %32 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 8))>(%arg0)[%dim]
    %33 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 32))>(%arg1)[%dim_0]
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %31 into %arg2[%32, %33] [%26, %28] [1, 1] : tensor<?x?xf32> into tensor<?x?xf32>
    }
  } {mapping = [#gpu.thread<y>, #gpu.thread<x>]}
  %dim_1 = tensor.dim %21, %c0 : tensor<?x?xf32>
  %dim_2 = tensor.dim %21, %c1 : tensor<?x?xf32>
  %dim_3 = tensor.dim %22, %c1 : tensor<?x?xf32>
  %extracted_slice = tensor.extract_slice %23[0, 0] [%dim_1, %dim_3] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
  %24:2 = scf.for %arg0 = %c0 to %dim_2 step %c1 iter_args(%arg1 = %23, %arg2 = %extracted_slice) -> (tensor<?x?xf32>, tensor<?x?xf32>) {
    %extracted_slice_4 = tensor.extract_slice %21[0, %arg0] [%dim_1, 1] [1, 1] : tensor<?x?xf32> to tensor<?x1xf32>
    %extracted_slice_5 = tensor.extract_slice %22[%arg0, 0] [1, %dim_3] [1, 1] : tensor<?x?xf32> to tensor<1x?xf32>
    %25 = scf.forall (%arg3, %arg4) in (8, 32) shared_outs(%arg5 = %arg2) -> (tensor<?x?xf32>) {
      %26 = affine.min affine_map<(d0)[s0] -> (-(d0 * (s0 ceildiv 8)) + s0, s0 ceildiv 8)>(%arg3)[%dim_1]
      %27 = affine.max affine_map<(d0) -> (0, d0)>(%26)
      %28 = affine.min affine_map<(d0)[s0] -> (-(d0 * (s0 ceildiv 32)) + s0, s0 ceildiv 32)>(%arg4)[%dim_3]
      %29 = affine.max affine_map<(d0) -> (0, d0)>(%28)
      %30 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 8))>(%arg3)[%dim_1]
      %31 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 32))>(%arg4)[%dim_3]
      %32 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 8))>(%arg3)[%dim_1]
      %33 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 32))>(%arg4)[%dim_3]
      %extracted_slice_6 = tensor.extract_slice %extracted_slice_4[%30, 0] [%27, 1] [1, 1] : tensor<?x1xf32> to tensor<?x1xf32>
      %extracted_slice_7 = tensor.extract_slice %extracted_slice_5[0, %31] [1, %29] [1, 1] : tensor<1x?xf32> to tensor<1x?xf32>
      %extracted_slice_8 = tensor.extract_slice %arg5[%32, %33] [%27, %29] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
      %34 = linalg.matmul {__internal_linalg_transform__ = "workgroup_k_tiled", lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%extracted_slice_6, %extracted_slice_7 : tensor<?x1xf32>, tensor<1x?xf32>) outs(%extracted_slice_8 : tensor<?x?xf32>) -> tensor<?x?xf32>
      %35 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 8))>(%arg3)[%dim_1]
      %36 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 32))>(%arg4)[%dim_3]
      scf.forall.in_parallel {
        tensor.parallel_insert_slice %34 into %arg5[%35, %36] [%27, %29] [1, 1] : tensor<?x?xf32> into tensor<?x?xf32>
      }
    } {mapping = [#gpu.thread<y>, #gpu.thread<x>]}
    scf.yield %arg1, %25 : tensor<?x?xf32>, tensor<?x?xf32>
  }
  %inserted_slice = tensor.insert_slice %24#1 into %24#0[0, 0] [%dim_1, %dim_3] [1, 1] : tensor<?x?xf32> into tensor<?x?xf32>
  flow.dispatch.tensor.store %inserted_slice, %15, offsets = [%16, %17], sizes = [%18, %19], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%8, %13}
  return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main_dispatch_0_matmul_DxDxD_f32() {
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c32_i64 = arith.constant 32 : i64
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.interface.constant.load[0] : i32
  %1 = hal.interface.constant.load[1] : i32
  %2 = hal.interface.constant.load[2] : i32
  %3 = hal.interface.constant.load[3] : i32
  %4 = arith.extui %0 : i32 to i64
  %5 = arith.extui %1 : i32 to i64
  %6 = arith.shli %5, %c32_i64 : i64
  %7 = arith.ori %4, %6 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %2 : i32 to i64
  %10 = arith.extui %3 : i32 to i64
  %11 = arith.shli %10, %c32_i64 : i64
  %12 = arith.ori %9, %11 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%8, %13}
  %15 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%8, %13}
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %16 = affine.apply affine_map<()[s0, s1] -> ((s0 floordiv (s1 ceildiv 128)) * 32)>()[%workgroup_id_x, %13]
  %17 = affine.apply affine_map<()[s0, s1] -> ((s0 mod (s1 ceildiv 128)) * 128)>()[%workgroup_id_x, %13]
  %18 = affine.min affine_map<()[s0, s1, s2] -> (32, s0 - (s1 floordiv (s2 ceildiv 128)) * 32)>()[%8, %workgroup_id_x, %13]
  %19 = affine.min affine_map<()[s0, s1] -> (128, s0 - (s1 mod (s0 ceildiv 128)) * 128)>()[%13, %workgroup_id_x]
  %20 = flow.dispatch.tensor.load %15, offsets = [%16, %17], sizes = [%18, %19], strides = [1, 1] : !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%8, %13} -> tensor<?x?xf32>
  %21 = flow.dispatch.tensor.load %14, offsets = [%16, 0], sizes = [%18, %13], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%8, %13} -> tensor<?x?xf32>
  %22 = flow.dispatch.tensor.load %14, offsets = [0, %17], sizes = [%13, %19], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%8, %13} -> tensor<?x?xf32>
  %23 = scf.forall (%arg0, %arg1) in (8, 32) shared_outs(%arg2 = %20) -> (tensor<?x?xf32>) {
    %25 = affine.min affine_map<(d0)[s0] -> (-(d0 * (s0 ceildiv 8)) + s0, s0 ceildiv 8)>(%arg0)[%18]
    %26 = affine.max affine_map<(d0) -> (0, d0)>(%25)
    %27 = affine.min affine_map<(d0)[s0] -> (-(d0 * (s0 ceildiv 32)) + s0, s0 ceildiv 32)>(%arg1)[%19]
    %28 = affine.max affine_map<(d0) -> (0, d0)>(%27)
    %29 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 8))>(%arg0)[%18]
    %30 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 32))>(%arg1)[%19]
    %extracted_slice_0 = tensor.extract_slice %arg2[%29, %30] [%26, %28] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %31 = linalg.fill {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%cst : f32) outs(%extracted_slice_0 : tensor<?x?xf32>) -> tensor<?x?xf32>
    %32 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 8))>(%arg0)[%18]
    %33 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 32))>(%arg1)[%19]
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %31 into %arg2[%32, %33] [%26, %28] [1, 1] : tensor<?x?xf32> into tensor<?x?xf32>
    }
  } {mapping = [#gpu.thread<y>, #gpu.thread<x>]}
  %extracted_slice = tensor.extract_slice %23[0, 0] [%18, %19] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
  %24 = scf.for %arg0 = %c0 to %13 step %c1 iter_args(%arg1 = %extracted_slice) -> (tensor<?x?xf32>) {
    %extracted_slice_0 = tensor.extract_slice %21[0, %arg0] [%18, 1] [1, 1] : tensor<?x?xf32> to tensor<?x1xf32>
    %extracted_slice_1 = tensor.extract_slice %22[%arg0, 0] [1, %19] [1, 1] : tensor<?x?xf32> to tensor<1x?xf32>
    %25 = scf.forall (%arg2, %arg3) in (8, 32) shared_outs(%arg4 = %arg1) -> (tensor<?x?xf32>) {
      %26 = affine.min affine_map<(d0)[s0] -> (-(d0 * (s0 ceildiv 8)) + s0, s0 ceildiv 8)>(%arg2)[%18]
      %27 = affine.max affine_map<(d0) -> (0, d0)>(%26)
      %28 = affine.min affine_map<(d0)[s0] -> (-(d0 * (s0 ceildiv 32)) + s0, s0 ceildiv 32)>(%arg3)[%19]
      %29 = affine.max affine_map<(d0) -> (0, d0)>(%28)
      %30 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 8))>(%arg2)[%18]
      %31 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 32))>(%arg3)[%19]
      %32 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 8))>(%arg2)[%18]
      %33 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 32))>(%arg3)[%19]
      %extracted_slice_2 = tensor.extract_slice %extracted_slice_0[%30, 0] [%27, 1] [1, 1] : tensor<?x1xf32> to tensor<?x1xf32>
      %extracted_slice_3 = tensor.extract_slice %extracted_slice_1[0, %31] [1, %29] [1, 1] : tensor<1x?xf32> to tensor<1x?xf32>
      %extracted_slice_4 = tensor.extract_slice %arg4[%32, %33] [%27, %29] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
      %34 = linalg.matmul {__internal_linalg_transform__ = "workgroup_k_tiled", lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%extracted_slice_2, %extracted_slice_3 : tensor<?x1xf32>, tensor<1x?xf32>) outs(%extracted_slice_4 : tensor<?x?xf32>) -> tensor<?x?xf32>
      %35 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 8))>(%arg2)[%18]
      %36 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 32))>(%arg3)[%19]
      scf.forall.in_parallel {
        tensor.parallel_insert_slice %34 into %arg4[%35, %36] [%27, %29] [1, 1] : tensor<?x?xf32> into tensor<?x?xf32>
      }
    } {mapping = [#gpu.thread<y>, #gpu.thread<x>]}
    scf.yield %25 : tensor<?x?xf32>
  }
  %inserted_slice = tensor.insert_slice %24 into %23[0, 0] [%18, %19] [1, 1] : tensor<?x?xf32> into tensor<?x?xf32>
  flow.dispatch.tensor.store %inserted_slice, %15, offsets = [%16, %17], sizes = [%18, %19], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%8, %13}
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @main_dispatch_0_matmul_DxDxD_f32() {
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c32_i64 = arith.constant 32 : i64
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.interface.constant.load[0] : i32
  %1 = hal.interface.constant.load[1] : i32
  %2 = hal.interface.constant.load[2] : i32
  %3 = hal.interface.constant.load[3] : i32
  %4 = arith.extui %0 : i32 to i64
  %5 = arith.extui %1 : i32 to i64
  %6 = arith.shli %5, %c32_i64 : i64
  %7 = arith.ori %4, %6 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %2 : i32 to i64
  %10 = arith.extui %3 : i32 to i64
  %11 = arith.shli %10, %c32_i64 : i64
  %12 = arith.ori %9, %11 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%8, %13}
  %15 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%8, %13}
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %16 = affine.apply affine_map<()[s0, s1] -> ((s0 floordiv (s1 ceildiv 128)) * 32)>()[%workgroup_id_x, %13]
  %17 = affine.apply affine_map<()[s0, s1] -> ((s0 mod (s1 ceildiv 128)) * 128)>()[%workgroup_id_x, %13]
  %18 = affine.min affine_map<()[s0, s1, s2] -> (32, s0 - (s1 floordiv (s2 ceildiv 128)) * 32)>()[%8, %workgroup_id_x, %13]
  %19 = affine.min affine_map<()[s0, s1] -> (128, s0 - (s1 mod (s0 ceildiv 128)) * 128)>()[%13, %workgroup_id_x]
  %20 = flow.dispatch.tensor.load %15, offsets = [%16, %17], sizes = [%18, %19], strides = [1, 1] : !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%8, %13} -> tensor<?x?xf32>
  %21 = flow.dispatch.tensor.load %14, offsets = [%16, 0], sizes = [%18, %13], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%8, %13} -> tensor<?x?xf32>
  %22 = flow.dispatch.tensor.load %14, offsets = [0, %17], sizes = [%13, %19], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%8, %13} -> tensor<?x?xf32>
  %23 = scf.forall (%arg0, %arg1) in (8, 32) shared_outs(%arg2 = %20) -> (tensor<?x?xf32>) {
    %25 = affine.min affine_map<(d0)[s0] -> (-(d0 * (s0 ceildiv 8)) + s0, s0 ceildiv 8)>(%arg0)[%18]
    %26 = affine.max affine_map<(d0) -> (0, d0)>(%25)
    %27 = affine.min affine_map<(d0)[s0] -> (-(d0 * (s0 ceildiv 32)) + s0, s0 ceildiv 32)>(%arg1)[%19]
    %28 = affine.max affine_map<(d0) -> (0, d0)>(%27)
    %29 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 8))>(%arg0)[%18]
    %30 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 32))>(%arg1)[%19]
    %extracted_slice_0 = tensor.extract_slice %arg2[%29, %30] [%26, %28] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %31 = linalg.fill {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%cst : f32) outs(%extracted_slice_0 : tensor<?x?xf32>) -> tensor<?x?xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %31 into %arg2[%29, %30] [%26, %28] [1, 1] : tensor<?x?xf32> into tensor<?x?xf32>
    }
  } {mapping = [#gpu.thread<y>, #gpu.thread<x>]}
  %extracted_slice = tensor.extract_slice %23[0, 0] [%18, %19] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
  %24 = scf.for %arg0 = %c0 to %13 step %c1 iter_args(%arg1 = %extracted_slice) -> (tensor<?x?xf32>) {
    %extracted_slice_0 = tensor.extract_slice %21[0, %arg0] [%18, 1] [1, 1] : tensor<?x?xf32> to tensor<?x1xf32>
    %extracted_slice_1 = tensor.extract_slice %22[%arg0, 0] [1, %19] [1, 1] : tensor<?x?xf32> to tensor<1x?xf32>
    %25 = scf.forall (%arg2, %arg3) in (8, 32) shared_outs(%arg4 = %arg1) -> (tensor<?x?xf32>) {
      %26 = affine.min affine_map<(d0)[s0] -> (-(d0 * (s0 ceildiv 8)) + s0, s0 ceildiv 8)>(%arg2)[%18]
      %27 = affine.max affine_map<(d0) -> (0, d0)>(%26)
      %28 = affine.min affine_map<(d0)[s0] -> (-(d0 * (s0 ceildiv 32)) + s0, s0 ceildiv 32)>(%arg3)[%19]
      %29 = affine.max affine_map<(d0) -> (0, d0)>(%28)
      %30 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 8))>(%arg2)[%18]
      %31 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 32))>(%arg3)[%19]
      %extracted_slice_2 = tensor.extract_slice %extracted_slice_0[%30, 0] [%27, 1] [1, 1] : tensor<?x1xf32> to tensor<?x1xf32>
      %extracted_slice_3 = tensor.extract_slice %extracted_slice_1[0, %31] [1, %29] [1, 1] : tensor<1x?xf32> to tensor<1x?xf32>
      %extracted_slice_4 = tensor.extract_slice %arg4[%30, %31] [%27, %29] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
      %32 = linalg.matmul {__internal_linalg_transform__ = "workgroup_k_tiled", lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%extracted_slice_2, %extracted_slice_3 : tensor<?x1xf32>, tensor<1x?xf32>) outs(%extracted_slice_4 : tensor<?x?xf32>) -> tensor<?x?xf32>
      scf.forall.in_parallel {
        tensor.parallel_insert_slice %32 into %arg4[%30, %31] [%27, %29] [1, 1] : tensor<?x?xf32> into tensor<?x?xf32>
      }
    } {mapping = [#gpu.thread<y>, #gpu.thread<x>]}
    scf.yield %25 : tensor<?x?xf32>
  }
  %inserted_slice = tensor.insert_slice %24 into %23[0, 0] [%18, %19] [1, 1] : tensor<?x?xf32> into tensor<?x?xf32>
  flow.dispatch.tensor.store %inserted_slice, %15, offsets = [%16, %17], sizes = [%18, %19], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%8, %13}
  return
}

// -----// IR Dump After EliminateEmptyTensors (iree-eliminate-empty-tensors) //----- //
module {
  func.func @main_dispatch_0_matmul_DxDxD_f32() {
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c32_i64 = arith.constant 32 : i64
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.interface.constant.load[0] : i32
    %1 = hal.interface.constant.load[1] : i32
    %2 = hal.interface.constant.load[2] : i32
    %3 = hal.interface.constant.load[3] : i32
    %4 = arith.extui %0 : i32 to i64
    %5 = arith.extui %1 : i32 to i64
    %6 = arith.shli %5, %c32_i64 : i64
    %7 = arith.ori %4, %6 : i64
    %8 = arith.index_castui %7 : i64 to index
    %9 = arith.extui %2 : i32 to i64
    %10 = arith.extui %3 : i32 to i64
    %11 = arith.shli %10, %c32_i64 : i64
    %12 = arith.ori %9, %11 : i64
    %13 = arith.index_castui %12 : i64 to index
    %14 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%8, %13}
    %15 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%8, %13}
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %16 = affine.apply affine_map<()[s0, s1] -> ((s0 floordiv (s1 ceildiv 128)) * 32)>()[%workgroup_id_x, %13]
    %17 = affine.apply affine_map<()[s0, s1] -> ((s0 mod (s1 ceildiv 128)) * 128)>()[%workgroup_id_x, %13]
    %18 = affine.min affine_map<()[s0, s1, s2] -> (32, s0 - (s1 floordiv (s2 ceildiv 128)) * 32)>()[%8, %workgroup_id_x, %13]
    %19 = affine.min affine_map<()[s0, s1] -> (128, s0 - (s1 mod (s0 ceildiv 128)) * 128)>()[%13, %workgroup_id_x]
    %20 = flow.dispatch.tensor.load %15, offsets = [%16, %17], sizes = [%18, %19], strides = [1, 1] : !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%8, %13} -> tensor<?x?xf32>
    %21 = flow.dispatch.tensor.load %14, offsets = [%16, 0], sizes = [%18, %13], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%8, %13} -> tensor<?x?xf32>
    %22 = flow.dispatch.tensor.load %14, offsets = [0, %17], sizes = [%13, %19], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%8, %13} -> tensor<?x?xf32>
    %23 = scf.forall (%arg0, %arg1) in (8, 32) shared_outs(%arg2 = %20) -> (tensor<?x?xf32>) {
      %25 = affine.min affine_map<(d0)[s0] -> (-(d0 * (s0 ceildiv 8)) + s0, s0 ceildiv 8)>(%arg0)[%18]
      %26 = affine.max affine_map<(d0) -> (0, d0)>(%25)
      %27 = affine.min affine_map<(d0)[s0] -> (-(d0 * (s0 ceildiv 32)) + s0, s0 ceildiv 32)>(%arg1)[%19]
      %28 = affine.max affine_map<(d0) -> (0, d0)>(%27)
      %29 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 8))>(%arg0)[%18]
      %30 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 32))>(%arg1)[%19]
      %extracted_slice_0 = tensor.extract_slice %arg2[%29, %30] [%26, %28] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
      %31 = linalg.fill {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%cst : f32) outs(%extracted_slice_0 : tensor<?x?xf32>) -> tensor<?x?xf32>
      scf.forall.in_parallel {
        tensor.parallel_insert_slice %31 into %arg2[%29, %30] [%26, %28] [1, 1] : tensor<?x?xf32> into tensor<?x?xf32>
      }
    } {mapping = [#gpu.thread<y>, #gpu.thread<x>]}
    %extracted_slice = tensor.extract_slice %23[0, 0] [%18, %19] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %24 = scf.for %arg0 = %c0 to %13 step %c1 iter_args(%arg1 = %extracted_slice) -> (tensor<?x?xf32>) {
      %extracted_slice_0 = tensor.extract_slice %21[0, %arg0] [%18, 1] [1, 1] : tensor<?x?xf32> to tensor<?x1xf32>
      %extracted_slice_1 = tensor.extract_slice %22[%arg0, 0] [1, %19] [1, 1] : tensor<?x?xf32> to tensor<1x?xf32>
      %25 = scf.forall (%arg2, %arg3) in (8, 32) shared_outs(%arg4 = %arg1) -> (tensor<?x?xf32>) {
        %26 = affine.min affine_map<(d0)[s0] -> (-(d0 * (s0 ceildiv 8)) + s0, s0 ceildiv 8)>(%arg2)[%18]
        %27 = affine.max affine_map<(d0) -> (0, d0)>(%26)
        %28 = affine.min affine_map<(d0)[s0] -> (-(d0 * (s0 ceildiv 32)) + s0, s0 ceildiv 32)>(%arg3)[%19]
        %29 = affine.max affine_map<(d0) -> (0, d0)>(%28)
        %30 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 8))>(%arg2)[%18]
        %31 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 32))>(%arg3)[%19]
        %extracted_slice_2 = tensor.extract_slice %extracted_slice_0[%30, 0] [%27, 1] [1, 1] : tensor<?x1xf32> to tensor<?x1xf32>
        %extracted_slice_3 = tensor.extract_slice %extracted_slice_1[0, %31] [1, %29] [1, 1] : tensor<1x?xf32> to tensor<1x?xf32>
        %extracted_slice_4 = tensor.extract_slice %arg4[%30, %31] [%27, %29] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
        %32 = linalg.matmul {__internal_linalg_transform__ = "workgroup_k_tiled", lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%extracted_slice_2, %extracted_slice_3 : tensor<?x1xf32>, tensor<1x?xf32>) outs(%extracted_slice_4 : tensor<?x?xf32>) -> tensor<?x?xf32>
        scf.forall.in_parallel {
          tensor.parallel_insert_slice %32 into %arg4[%30, %31] [%27, %29] [1, 1] : tensor<?x?xf32> into tensor<?x?xf32>
        }
      } {mapping = [#gpu.thread<y>, #gpu.thread<x>]}
      scf.yield %25 : tensor<?x?xf32>
    }
    %inserted_slice = tensor.insert_slice %24 into %23[0, 0] [%18, %19] [1, 1] : tensor<?x?xf32> into tensor<?x?xf32>
    flow.dispatch.tensor.store %inserted_slice, %15, offsets = [%16, %17], sizes = [%18, %19], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%8, %13}
    return
  }
}

// -----// IR Dump After EmptyTensorToAllocTensor (empty-tensor-to-alloc-tensor) //----- //
module {
  func.func @main_dispatch_0_matmul_DxDxD_f32() {
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c32_i64 = arith.constant 32 : i64
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.interface.constant.load[0] : i32
    %1 = hal.interface.constant.load[1] : i32
    %2 = hal.interface.constant.load[2] : i32
    %3 = hal.interface.constant.load[3] : i32
    %4 = arith.extui %0 : i32 to i64
    %5 = arith.extui %1 : i32 to i64
    %6 = arith.shli %5, %c32_i64 : i64
    %7 = arith.ori %4, %6 : i64
    %8 = arith.index_castui %7 : i64 to index
    %9 = arith.extui %2 : i32 to i64
    %10 = arith.extui %3 : i32 to i64
    %11 = arith.shli %10, %c32_i64 : i64
    %12 = arith.ori %9, %11 : i64
    %13 = arith.index_castui %12 : i64 to index
    %14 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%8, %13}
    %15 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%8, %13}
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %16 = affine.apply affine_map<()[s0, s1] -> ((s0 floordiv (s1 ceildiv 128)) * 32)>()[%workgroup_id_x, %13]
    %17 = affine.apply affine_map<()[s0, s1] -> ((s0 mod (s1 ceildiv 128)) * 128)>()[%workgroup_id_x, %13]
    %18 = affine.min affine_map<()[s0, s1, s2] -> (32, s0 - (s1 floordiv (s2 ceildiv 128)) * 32)>()[%8, %workgroup_id_x, %13]
    %19 = affine.min affine_map<()[s0, s1] -> (128, s0 - (s1 mod (s0 ceildiv 128)) * 128)>()[%13, %workgroup_id_x]
    %20 = flow.dispatch.tensor.load %15, offsets = [%16, %17], sizes = [%18, %19], strides = [1, 1] : !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%8, %13} -> tensor<?x?xf32>
    %21 = flow.dispatch.tensor.load %14, offsets = [%16, 0], sizes = [%18, %13], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%8, %13} -> tensor<?x?xf32>
    %22 = flow.dispatch.tensor.load %14, offsets = [0, %17], sizes = [%13, %19], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%8, %13} -> tensor<?x?xf32>
    %23 = scf.forall (%arg0, %arg1) in (8, 32) shared_outs(%arg2 = %20) -> (tensor<?x?xf32>) {
      %25 = affine.min affine_map<(d0)[s0] -> (-(d0 * (s0 ceildiv 8)) + s0, s0 ceildiv 8)>(%arg0)[%18]
      %26 = affine.max affine_map<(d0) -> (0, d0)>(%25)
      %27 = affine.min affine_map<(d0)[s0] -> (-(d0 * (s0 ceildiv 32)) + s0, s0 ceildiv 32)>(%arg1)[%19]
      %28 = affine.max affine_map<(d0) -> (0, d0)>(%27)
      %29 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 8))>(%arg0)[%18]
      %30 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 32))>(%arg1)[%19]
      %extracted_slice_0 = tensor.extract_slice %arg2[%29, %30] [%26, %28] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
      %31 = linalg.fill {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%cst : f32) outs(%extracted_slice_0 : tensor<?x?xf32>) -> tensor<?x?xf32>
      scf.forall.in_parallel {
        tensor.parallel_insert_slice %31 into %arg2[%29, %30] [%26, %28] [1, 1] : tensor<?x?xf32> into tensor<?x?xf32>
      }
    } {mapping = [#gpu.thread<y>, #gpu.thread<x>]}
    %extracted_slice = tensor.extract_slice %23[0, 0] [%18, %19] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %24 = scf.for %arg0 = %c0 to %13 step %c1 iter_args(%arg1 = %extracted_slice) -> (tensor<?x?xf32>) {
      %extracted_slice_0 = tensor.extract_slice %21[0, %arg0] [%18, 1] [1, 1] : tensor<?x?xf32> to tensor<?x1xf32>
      %extracted_slice_1 = tensor.extract_slice %22[%arg0, 0] [1, %19] [1, 1] : tensor<?x?xf32> to tensor<1x?xf32>
      %25 = scf.forall (%arg2, %arg3) in (8, 32) shared_outs(%arg4 = %arg1) -> (tensor<?x?xf32>) {
        %26 = affine.min affine_map<(d0)[s0] -> (-(d0 * (s0 ceildiv 8)) + s0, s0 ceildiv 8)>(%arg2)[%18]
        %27 = affine.max affine_map<(d0) -> (0, d0)>(%26)
        %28 = affine.min affine_map<(d0)[s0] -> (-(d0 * (s0 ceildiv 32)) + s0, s0 ceildiv 32)>(%arg3)[%19]
        %29 = affine.max affine_map<(d0) -> (0, d0)>(%28)
        %30 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 8))>(%arg2)[%18]
        %31 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 32))>(%arg3)[%19]
        %extracted_slice_2 = tensor.extract_slice %extracted_slice_0[%30, 0] [%27, 1] [1, 1] : tensor<?x1xf32> to tensor<?x1xf32>
        %extracted_slice_3 = tensor.extract_slice %extracted_slice_1[0, %31] [1, %29] [1, 1] : tensor<1x?xf32> to tensor<1x?xf32>
        %extracted_slice_4 = tensor.extract_slice %arg4[%30, %31] [%27, %29] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
        %32 = linalg.matmul {__internal_linalg_transform__ = "workgroup_k_tiled", lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%extracted_slice_2, %extracted_slice_3 : tensor<?x1xf32>, tensor<1x?xf32>) outs(%extracted_slice_4 : tensor<?x?xf32>) -> tensor<?x?xf32>
        scf.forall.in_parallel {
          tensor.parallel_insert_slice %32 into %arg4[%30, %31] [%27, %29] [1, 1] : tensor<?x?xf32> into tensor<?x?xf32>
        }
      } {mapping = [#gpu.thread<y>, #gpu.thread<x>]}
      scf.yield %25 : tensor<?x?xf32>
    }
    %inserted_slice = tensor.insert_slice %24 into %23[0, 0] [%18, %19] [1, 1] : tensor<?x?xf32> into tensor<?x?xf32>
    flow.dispatch.tensor.store %inserted_slice, %15, offsets = [%16, %17], sizes = [%18, %19], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<writeonly:tensor<?x?xf32>>{%8, %13}
    return
  }
}

// -----// IR Dump After IREEComprehensiveBufferize (iree-codegen-iree-comprehensive-bufferize) //----- //
module {
  func.func @main_dispatch_0_matmul_DxDxD_f32() {
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c32_i64 = arith.constant 32 : i64
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.interface.constant.load[0] : i32
    %1 = hal.interface.constant.load[1] : i32
    %2 = hal.interface.constant.load[2] : i32
    %3 = hal.interface.constant.load[3] : i32
    %4 = arith.extui %0 : i32 to i64
    %5 = arith.extui %1 : i32 to i64
    %6 = arith.shli %5, %c32_i64 : i64
    %7 = arith.ori %4, %6 : i64
    %8 = arith.index_castui %7 : i64 to index
    %9 = arith.extui %2 : i32 to i64
    %10 = arith.extui %3 : i32 to i64
    %11 = arith.shli %10, %c32_i64 : i64
    %12 = arith.ori %9, %11 : i64
    %13 = arith.index_castui %12 : i64 to index
    %14 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>{%8, %13}
    memref.assume_alignment %14, 64 : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>
    %15 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>{%8, %13}
    memref.assume_alignment %15, 64 : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %16 = affine.apply affine_map<()[s0, s1] -> ((s0 floordiv (s1 ceildiv 128)) * 32)>()[%workgroup_id_x, %13]
    %17 = affine.apply affine_map<()[s0, s1] -> ((s0 mod (s1 ceildiv 128)) * 128)>()[%workgroup_id_x, %13]
    %18 = affine.min affine_map<()[s0, s1, s2] -> (32, s0 - (s1 floordiv (s2 ceildiv 128)) * 32)>()[%8, %workgroup_id_x, %13]
    %19 = affine.min affine_map<()[s0, s1] -> (128, s0 - (s1 mod (s0 ceildiv 128)) * 128)>()[%13, %workgroup_id_x]
    %subview = memref.subview %15[%16, %17] [%18, %19] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %subview_0 = memref.subview %14[%16, 0] [%18, %13] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %subview_1 = memref.subview %14[0, %17] [%13, %19] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    scf.forall (%arg0, %arg1) in (8, 32) {
      %21 = affine.min affine_map<(d0)[s0] -> (-(d0 * (s0 ceildiv 8)) + s0, s0 ceildiv 8)>(%arg0)[%18]
      %22 = affine.max affine_map<(d0) -> (0, d0)>(%21)
      %23 = affine.min affine_map<(d0)[s0] -> (-(d0 * (s0 ceildiv 32)) + s0, s0 ceildiv 32)>(%arg1)[%19]
      %24 = affine.max affine_map<(d0) -> (0, d0)>(%23)
      %25 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 8))>(%arg0)[%18]
      %26 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 32))>(%arg1)[%19]
      %subview_3 = memref.subview %subview[%25, %26] [%22, %24] [1, 1] : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      linalg.fill {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%cst : f32) outs(%subview_3 : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>)
      %subview_4 = memref.subview %subview[%25, %26] [%22, %24] [1, 1] : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      memref.copy %subview_3, %subview_4 : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    } {mapping = [#gpu.thread<y>, #gpu.thread<x>]}
    %20 = scf.for %arg0 = %c0 to %13 step %c1 iter_args(%arg1 = %subview) -> (memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) {
      %subview_3 = memref.subview %subview_0[0, %arg0] [%18, 1] [1, 1] : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?x1xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      %subview_4 = memref.subview %subview_1[%arg0, 0] [1, %19] [1, 1] : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<1x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      scf.forall (%arg2, %arg3) in (8, 32) {
        %21 = affine.min affine_map<(d0)[s0] -> (-(d0 * (s0 ceildiv 8)) + s0, s0 ceildiv 8)>(%arg2)[%18]
        %22 = affine.max affine_map<(d0) -> (0, d0)>(%21)
        %23 = affine.min affine_map<(d0)[s0] -> (-(d0 * (s0 ceildiv 32)) + s0, s0 ceildiv 32)>(%arg3)[%19]
        %24 = affine.max affine_map<(d0) -> (0, d0)>(%23)
        %25 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 8))>(%arg2)[%18]
        %26 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 32))>(%arg3)[%19]
        %subview_5 = memref.subview %subview_3[%25, 0] [%22, 1] [1, 1] : memref<?x1xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?x1xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
        %subview_6 = memref.subview %subview_4[0, %26] [1, %24] [1, 1] : memref<1x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<1x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
        %subview_7 = memref.subview %arg1[%25, %26] [%22, %24] [1, 1] : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
        linalg.matmul {__internal_linalg_transform__ = "workgroup_k_tiled", lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%subview_5, %subview_6 : memref<?x1xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, memref<1x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) outs(%subview_7 : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>)
        %subview_8 = memref.subview %arg1[%25, %26] [%22, %24] [1, 1] : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
        memref.copy %subview_7, %subview_8 : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      } {mapping = [#gpu.thread<y>, #gpu.thread<x>]}
      scf.yield %arg1 : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    }
    memref.copy %20, %subview : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %subview_2 = memref.subview %15[%16, %17] [%18, %19] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    memref.copy %subview, %subview_2 : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    return
  }
}

// -----// IR Dump After ResolveShapedTypeResultDims (resolve-shaped-type-result-dims) //----- //
module {
  func.func @main_dispatch_0_matmul_DxDxD_f32() {
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c32_i64 = arith.constant 32 : i64
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.interface.constant.load[0] : i32
    %1 = hal.interface.constant.load[1] : i32
    %2 = hal.interface.constant.load[2] : i32
    %3 = hal.interface.constant.load[3] : i32
    %4 = arith.extui %0 : i32 to i64
    %5 = arith.extui %1 : i32 to i64
    %6 = arith.shli %5, %c32_i64 : i64
    %7 = arith.ori %4, %6 : i64
    %8 = arith.index_castui %7 : i64 to index
    %9 = arith.extui %2 : i32 to i64
    %10 = arith.extui %3 : i32 to i64
    %11 = arith.shli %10, %c32_i64 : i64
    %12 = arith.ori %9, %11 : i64
    %13 = arith.index_castui %12 : i64 to index
    %14 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>{%8, %13}
    memref.assume_alignment %14, 64 : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>
    %15 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>{%8, %13}
    memref.assume_alignment %15, 64 : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %16 = affine.apply affine_map<()[s0, s1] -> ((s0 floordiv (s1 ceildiv 128)) * 32)>()[%workgroup_id_x, %13]
    %17 = affine.apply affine_map<()[s0, s1] -> ((s0 mod (s1 ceildiv 128)) * 128)>()[%workgroup_id_x, %13]
    %18 = affine.min affine_map<()[s0, s1, s2] -> (32, s0 - (s1 floordiv (s2 ceildiv 128)) * 32)>()[%8, %workgroup_id_x, %13]
    %19 = affine.min affine_map<()[s0, s1] -> (128, s0 - (s1 mod (s0 ceildiv 128)) * 128)>()[%13, %workgroup_id_x]
    %subview = memref.subview %15[%16, %17] [%18, %19] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %subview_0 = memref.subview %14[%16, 0] [%18, %13] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %subview_1 = memref.subview %14[0, %17] [%13, %19] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    scf.forall (%arg0, %arg1) in (8, 32) {
      %21 = affine.min affine_map<(d0)[s0] -> (-(d0 * (s0 ceildiv 8)) + s0, s0 ceildiv 8)>(%arg0)[%18]
      %22 = affine.max affine_map<(d0) -> (0, d0)>(%21)
      %23 = affine.min affine_map<(d0)[s0] -> (-(d0 * (s0 ceildiv 32)) + s0, s0 ceildiv 32)>(%arg1)[%19]
      %24 = affine.max affine_map<(d0) -> (0, d0)>(%23)
      %25 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 8))>(%arg0)[%18]
      %26 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 32))>(%arg1)[%19]
      %subview_3 = memref.subview %subview[%25, %26] [%22, %24] [1, 1] : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      linalg.fill {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%cst : f32) outs(%subview_3 : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>)
      %subview_4 = memref.subview %subview[%25, %26] [%22, %24] [1, 1] : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      memref.copy %subview_3, %subview_4 : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    } {mapping = [#gpu.thread<y>, #gpu.thread<x>]}
    %20 = scf.for %arg0 = %c0 to %13 step %c1 iter_args(%arg1 = %subview) -> (memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) {
      %subview_3 = memref.subview %subview_0[0, %arg0] [%18, 1] [1, 1] : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?x1xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      %subview_4 = memref.subview %subview_1[%arg0, 0] [1, %19] [1, 1] : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<1x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      scf.forall (%arg2, %arg3) in (8, 32) {
        %21 = affine.min affine_map<(d0)[s0] -> (-(d0 * (s0 ceildiv 8)) + s0, s0 ceildiv 8)>(%arg2)[%18]
        %22 = affine.max affine_map<(d0) -> (0, d0)>(%21)
        %23 = affine.min affine_map<(d0)[s0] -> (-(d0 * (s0 ceildiv 32)) + s0, s0 ceildiv 32)>(%arg3)[%19]
        %24 = affine.max affine_map<(d0) -> (0, d0)>(%23)
        %25 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 8))>(%arg2)[%18]
        %26 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 32))>(%arg3)[%19]
        %subview_5 = memref.subview %subview_3[%25, 0] [%22, 1] [1, 1] : memref<?x1xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?x1xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
        %subview_6 = memref.subview %subview_4[0, %26] [1, %24] [1, 1] : memref<1x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<1x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
        %subview_7 = memref.subview %arg1[%25, %26] [%22, %24] [1, 1] : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
        linalg.matmul {__internal_linalg_transform__ = "workgroup_k_tiled", lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%subview_5, %subview_6 : memref<?x1xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, memref<1x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) outs(%subview_7 : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>)
        %subview_8 = memref.subview %arg1[%25, %26] [%22, %24] [1, 1] : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
        memref.copy %subview_7, %subview_8 : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      } {mapping = [#gpu.thread<y>, #gpu.thread<x>]}
      scf.yield %arg1 : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    }
    memref.copy %20, %subview : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %subview_2 = memref.subview %15[%16, %17] [%18, %19] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    memref.copy %subview, %subview_2 : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    return
  }
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main_dispatch_0_matmul_DxDxD_f32() {
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c32_i64 = arith.constant 32 : i64
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.interface.constant.load[0] : i32
  %1 = hal.interface.constant.load[1] : i32
  %2 = hal.interface.constant.load[2] : i32
  %3 = hal.interface.constant.load[3] : i32
  %4 = arith.extui %0 : i32 to i64
  %5 = arith.extui %1 : i32 to i64
  %6 = arith.shli %5, %c32_i64 : i64
  %7 = arith.ori %4, %6 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %2 : i32 to i64
  %10 = arith.extui %3 : i32 to i64
  %11 = arith.shli %10, %c32_i64 : i64
  %12 = arith.ori %9, %11 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>{%8, %13}
  memref.assume_alignment %14, 64 : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>
  %15 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>{%8, %13}
  memref.assume_alignment %15, 64 : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %16 = affine.apply affine_map<()[s0, s1] -> ((s0 floordiv (s1 ceildiv 128)) * 32)>()[%workgroup_id_x, %13]
  %17 = affine.apply affine_map<()[s0, s1] -> ((s0 mod (s1 ceildiv 128)) * 128)>()[%workgroup_id_x, %13]
  %18 = affine.min affine_map<()[s0, s1, s2] -> (32, s0 - (s1 floordiv (s2 ceildiv 128)) * 32)>()[%8, %workgroup_id_x, %13]
  %19 = affine.min affine_map<()[s0, s1] -> (128, s0 - (s1 mod (s0 ceildiv 128)) * 128)>()[%13, %workgroup_id_x]
  %subview = memref.subview %15[%16, %17] [%18, %19] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %subview_0 = memref.subview %14[%16, 0] [%18, %13] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %subview_1 = memref.subview %14[0, %17] [%13, %19] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  scf.forall (%arg0, %arg1) in (8, 32) {
    %20 = affine.min affine_map<(d0)[s0] -> (-(d0 * (s0 ceildiv 8)) + s0, s0 ceildiv 8)>(%arg0)[%18]
    %21 = affine.max affine_map<(d0) -> (0, d0)>(%20)
    %22 = affine.min affine_map<(d0)[s0] -> (-(d0 * (s0 ceildiv 32)) + s0, s0 ceildiv 32)>(%arg1)[%19]
    %23 = affine.max affine_map<(d0) -> (0, d0)>(%22)
    %24 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 8))>(%arg0)[%18]
    %25 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 32))>(%arg1)[%19]
    %subview_3 = memref.subview %subview[%24, %25] [%21, %23] [1, 1] : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    linalg.fill {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%cst : f32) outs(%subview_3 : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>)
    %subview_4 = memref.subview %subview[%24, %25] [%21, %23] [1, 1] : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    memref.copy %subview_3, %subview_4 : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  } {mapping = [#gpu.thread<y>, #gpu.thread<x>]}
  scf.for %arg0 = %c0 to %13 step %c1 {
    %subview_3 = memref.subview %subview_0[0, %arg0] [%18, 1] [1, 1] : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?x1xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %subview_4 = memref.subview %subview_1[%arg0, 0] [1, %19] [1, 1] : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<1x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    scf.forall (%arg1, %arg2) in (8, 32) {
      %20 = affine.min affine_map<(d0)[s0] -> (-(d0 * (s0 ceildiv 8)) + s0, s0 ceildiv 8)>(%arg1)[%18]
      %21 = affine.max affine_map<(d0) -> (0, d0)>(%20)
      %22 = affine.min affine_map<(d0)[s0] -> (-(d0 * (s0 ceildiv 32)) + s0, s0 ceildiv 32)>(%arg2)[%19]
      %23 = affine.max affine_map<(d0) -> (0, d0)>(%22)
      %24 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 8))>(%arg1)[%18]
      %25 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 32))>(%arg2)[%19]
      %subview_5 = memref.subview %subview_3[%24, 0] [%21, 1] [1, 1] : memref<?x1xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?x1xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      %subview_6 = memref.subview %subview_4[0, %25] [1, %23] [1, 1] : memref<1x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<1x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      %subview_7 = memref.subview %subview[%24, %25] [%21, %23] [1, 1] : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      linalg.matmul {__internal_linalg_transform__ = "workgroup_k_tiled", lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%subview_5, %subview_6 : memref<?x1xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, memref<1x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) outs(%subview_7 : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>)
      %subview_8 = memref.subview %subview[%24, %25] [%21, %23] [1, 1] : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      memref.copy %subview_7, %subview_8 : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    } {mapping = [#gpu.thread<y>, #gpu.thread<x>]}
  }
  %subview_2 = memref.subview %15[%16, %17] [%18, %19] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  memref.copy %subview, %subview_2 : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @main_dispatch_0_matmul_DxDxD_f32() {
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c32_i64 = arith.constant 32 : i64
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.interface.constant.load[0] : i32
  %1 = hal.interface.constant.load[1] : i32
  %2 = hal.interface.constant.load[2] : i32
  %3 = hal.interface.constant.load[3] : i32
  %4 = arith.extui %0 : i32 to i64
  %5 = arith.extui %1 : i32 to i64
  %6 = arith.shli %5, %c32_i64 : i64
  %7 = arith.ori %4, %6 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %2 : i32 to i64
  %10 = arith.extui %3 : i32 to i64
  %11 = arith.shli %10, %c32_i64 : i64
  %12 = arith.ori %9, %11 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>{%8, %13}
  memref.assume_alignment %14, 64 : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>
  %15 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>{%8, %13}
  memref.assume_alignment %15, 64 : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %16 = affine.apply affine_map<()[s0, s1] -> ((s0 floordiv (s1 ceildiv 128)) * 32)>()[%workgroup_id_x, %13]
  %17 = affine.apply affine_map<()[s0, s1] -> ((s0 mod (s1 ceildiv 128)) * 128)>()[%workgroup_id_x, %13]
  %18 = affine.min affine_map<()[s0, s1, s2] -> (32, s0 - (s1 floordiv (s2 ceildiv 128)) * 32)>()[%8, %workgroup_id_x, %13]
  %19 = affine.min affine_map<()[s0, s1] -> (128, s0 - (s1 mod (s0 ceildiv 128)) * 128)>()[%13, %workgroup_id_x]
  %subview = memref.subview %15[%16, %17] [%18, %19] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %subview_0 = memref.subview %14[%16, 0] [%18, %13] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %subview_1 = memref.subview %14[0, %17] [%13, %19] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  scf.forall (%arg0, %arg1) in (8, 32) {
    %20 = affine.min affine_map<(d0)[s0] -> (-(d0 * (s0 ceildiv 8)) + s0, s0 ceildiv 8)>(%arg0)[%18]
    %21 = affine.max affine_map<(d0) -> (0, d0)>(%20)
    %22 = affine.min affine_map<(d0)[s0] -> (-(d0 * (s0 ceildiv 32)) + s0, s0 ceildiv 32)>(%arg1)[%19]
    %23 = affine.max affine_map<(d0) -> (0, d0)>(%22)
    %24 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 8))>(%arg0)[%18]
    %25 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 32))>(%arg1)[%19]
    %subview_2 = memref.subview %subview[%24, %25] [%21, %23] [1, 1] : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    linalg.fill {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%cst : f32) outs(%subview_2 : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>)
    memref.copy %subview_2, %subview_2 : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  } {mapping = [#gpu.thread<y>, #gpu.thread<x>]}
  scf.for %arg0 = %c0 to %13 step %c1 {
    %subview_2 = memref.subview %subview_0[0, %arg0] [%18, 1] [1, 1] : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?x1xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %subview_3 = memref.subview %subview_1[%arg0, 0] [1, %19] [1, 1] : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<1x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    scf.forall (%arg1, %arg2) in (8, 32) {
      %20 = affine.min affine_map<(d0)[s0] -> (-(d0 * (s0 ceildiv 8)) + s0, s0 ceildiv 8)>(%arg1)[%18]
      %21 = affine.max affine_map<(d0) -> (0, d0)>(%20)
      %22 = affine.min affine_map<(d0)[s0] -> (-(d0 * (s0 ceildiv 32)) + s0, s0 ceildiv 32)>(%arg2)[%19]
      %23 = affine.max affine_map<(d0) -> (0, d0)>(%22)
      %24 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 8))>(%arg1)[%18]
      %25 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 32))>(%arg2)[%19]
      %subview_4 = memref.subview %subview_2[%24, 0] [%21, 1] [1, 1] : memref<?x1xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?x1xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      %subview_5 = memref.subview %subview_3[0, %25] [1, %23] [1, 1] : memref<1x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<1x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      %subview_6 = memref.subview %subview[%24, %25] [%21, %23] [1, 1] : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      linalg.matmul {__internal_linalg_transform__ = "workgroup_k_tiled", lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%subview_4, %subview_5 : memref<?x1xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, memref<1x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) outs(%subview_6 : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>)
      memref.copy %subview_6, %subview_6 : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    } {mapping = [#gpu.thread<y>, #gpu.thread<x>]}
  }
  memref.copy %subview, %subview : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main_dispatch_0_matmul_DxDxD_f32() {
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c32_i64 = arith.constant 32 : i64
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.interface.constant.load[0] : i32
  %1 = hal.interface.constant.load[1] : i32
  %2 = hal.interface.constant.load[2] : i32
  %3 = hal.interface.constant.load[3] : i32
  %4 = arith.extui %0 : i32 to i64
  %5 = arith.extui %1 : i32 to i64
  %6 = arith.shli %5, %c32_i64 : i64
  %7 = arith.ori %4, %6 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %2 : i32 to i64
  %10 = arith.extui %3 : i32 to i64
  %11 = arith.shli %10, %c32_i64 : i64
  %12 = arith.ori %9, %11 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>{%8, %13}
  memref.assume_alignment %14, 64 : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>
  %15 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>{%8, %13}
  memref.assume_alignment %15, 64 : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %16 = affine.apply affine_map<()[s0, s1] -> ((s0 floordiv (s1 ceildiv 128)) * 32)>()[%workgroup_id_x, %13]
  %17 = affine.apply affine_map<()[s0, s1] -> ((s0 mod (s1 ceildiv 128)) * 128)>()[%workgroup_id_x, %13]
  %18 = affine.min affine_map<()[s0, s1, s2] -> (32, s0 - (s1 floordiv (s2 ceildiv 128)) * 32)>()[%8, %workgroup_id_x, %13]
  %19 = affine.min affine_map<()[s0, s1] -> (128, s0 - (s1 mod (s0 ceildiv 128)) * 128)>()[%13, %workgroup_id_x]
  %subview = memref.subview %15[%16, %17] [%18, %19] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %subview_0 = memref.subview %14[%16, 0] [%18, %13] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %subview_1 = memref.subview %14[0, %17] [%13, %19] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  scf.forall (%arg0, %arg1) in (8, 32) {
    %20 = affine.min affine_map<(d0)[s0] -> (-(d0 * (s0 ceildiv 8)) + s0, s0 ceildiv 8)>(%arg0)[%18]
    %21 = affine.max affine_map<(d0) -> (0, d0)>(%20)
    %22 = affine.min affine_map<(d0)[s0] -> (-(d0 * (s0 ceildiv 32)) + s0, s0 ceildiv 32)>(%arg1)[%19]
    %23 = affine.max affine_map<(d0) -> (0, d0)>(%22)
    %24 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 8))>(%arg0)[%18]
    %25 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 32))>(%arg1)[%19]
    %subview_2 = memref.subview %subview[%24, %25] [%21, %23] [1, 1] : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    linalg.fill {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%cst : f32) outs(%subview_2 : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>)
  } {mapping = [#gpu.thread<y>, #gpu.thread<x>]}
  scf.for %arg0 = %c0 to %13 step %c1 {
    %subview_2 = memref.subview %subview_0[0, %arg0] [%18, 1] [1, 1] : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?x1xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %subview_3 = memref.subview %subview_1[%arg0, 0] [1, %19] [1, 1] : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<1x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    scf.forall (%arg1, %arg2) in (8, 32) {
      %20 = affine.min affine_map<(d0)[s0] -> (-(d0 * (s0 ceildiv 8)) + s0, s0 ceildiv 8)>(%arg1)[%18]
      %21 = affine.max affine_map<(d0) -> (0, d0)>(%20)
      %22 = affine.min affine_map<(d0)[s0] -> (-(d0 * (s0 ceildiv 32)) + s0, s0 ceildiv 32)>(%arg2)[%19]
      %23 = affine.max affine_map<(d0) -> (0, d0)>(%22)
      %24 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 8))>(%arg1)[%18]
      %25 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 32))>(%arg2)[%19]
      %subview_4 = memref.subview %subview_2[%24, 0] [%21, 1] [1, 1] : memref<?x1xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?x1xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      %subview_5 = memref.subview %subview_3[0, %25] [1, %23] [1, 1] : memref<1x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<1x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      %subview_6 = memref.subview %subview[%24, %25] [%21, %23] [1, 1] : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      linalg.matmul {__internal_linalg_transform__ = "workgroup_k_tiled", lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%subview_4, %subview_5 : memref<?x1xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, memref<1x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) outs(%subview_6 : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>)
    } {mapping = [#gpu.thread<y>, #gpu.thread<x>]}
  }
  return
}

// -----// IR Dump After CleanupBufferAllocView (iree-codegen-cleanup-buffer-alloc-view) //----- //
func.func @main_dispatch_0_matmul_DxDxD_f32() {
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c32_i64 = arith.constant 32 : i64
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.interface.constant.load[0] : i32
  %1 = hal.interface.constant.load[1] : i32
  %2 = hal.interface.constant.load[2] : i32
  %3 = hal.interface.constant.load[3] : i32
  %4 = arith.extui %0 : i32 to i64
  %5 = arith.extui %1 : i32 to i64
  %6 = arith.shli %5, %c32_i64 : i64
  %7 = arith.ori %4, %6 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %2 : i32 to i64
  %10 = arith.extui %3 : i32 to i64
  %11 = arith.shli %10, %c32_i64 : i64
  %12 = arith.ori %9, %11 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>{%8, %13}
  memref.assume_alignment %14, 64 : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>
  %15 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>{%8, %13}
  memref.assume_alignment %15, 64 : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %16 = affine.apply affine_map<()[s0, s1] -> ((s0 floordiv (s1 ceildiv 128)) * 32)>()[%workgroup_id_x, %13]
  %17 = affine.apply affine_map<()[s0, s1] -> ((s0 mod (s1 ceildiv 128)) * 128)>()[%workgroup_id_x, %13]
  %18 = affine.min affine_map<()[s0, s1, s2] -> (32, s0 - (s1 floordiv (s2 ceildiv 128)) * 32)>()[%8, %workgroup_id_x, %13]
  %19 = affine.min affine_map<()[s0, s1] -> (128, s0 - (s1 mod (s0 ceildiv 128)) * 128)>()[%13, %workgroup_id_x]
  %subview = memref.subview %15[%16, %17] [%18, %19] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %subview_0 = memref.subview %14[%16, 0] [%18, %13] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %subview_1 = memref.subview %14[0, %17] [%13, %19] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  scf.forall (%arg0, %arg1) in (8, 32) {
    %20 = affine.min affine_map<(d0)[s0] -> (-(d0 * (s0 ceildiv 8)) + s0, s0 ceildiv 8)>(%arg0)[%18]
    %21 = affine.max affine_map<(d0) -> (0, d0)>(%20)
    %22 = affine.min affine_map<(d0)[s0] -> (-(d0 * (s0 ceildiv 32)) + s0, s0 ceildiv 32)>(%arg1)[%19]
    %23 = affine.max affine_map<(d0) -> (0, d0)>(%22)
    %24 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 8))>(%arg0)[%18]
    %25 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 32))>(%arg1)[%19]
    %subview_2 = memref.subview %subview[%24, %25] [%21, %23] [1, 1] : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    linalg.fill {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%cst : f32) outs(%subview_2 : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>)
  } {mapping = [#gpu.thread<y>, #gpu.thread<x>]}
  scf.for %arg0 = %c0 to %13 step %c1 {
    %subview_2 = memref.subview %subview_0[0, %arg0] [%18, 1] [1, 1] : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?x1xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %subview_3 = memref.subview %subview_1[%arg0, 0] [1, %19] [1, 1] : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<1x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    scf.forall (%arg1, %arg2) in (8, 32) {
      %20 = affine.min affine_map<(d0)[s0] -> (-(d0 * (s0 ceildiv 8)) + s0, s0 ceildiv 8)>(%arg1)[%18]
      %21 = affine.max affine_map<(d0) -> (0, d0)>(%20)
      %22 = affine.min affine_map<(d0)[s0] -> (-(d0 * (s0 ceildiv 32)) + s0, s0 ceildiv 32)>(%arg2)[%19]
      %23 = affine.max affine_map<(d0) -> (0, d0)>(%22)
      %24 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 8))>(%arg1)[%18]
      %25 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 32))>(%arg2)[%19]
      %subview_4 = memref.subview %subview_2[%24, 0] [%21, 1] [1, 1] : memref<?x1xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?x1xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      %subview_5 = memref.subview %subview_3[0, %25] [1, %23] [1, 1] : memref<1x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<1x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      %subview_6 = memref.subview %subview[%24, %25] [%21, %23] [1, 1] : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      linalg.matmul {__internal_linalg_transform__ = "workgroup_k_tiled", lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%subview_4, %subview_5 : memref<?x1xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, memref<1x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) outs(%subview_6 : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>)
    } {mapping = [#gpu.thread<y>, #gpu.thread<x>]}
  }
  return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
module {
  func.func @main_dispatch_0_matmul_DxDxD_f32() {
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c32_i64 = arith.constant 32 : i64
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.interface.constant.load[0] : i32
    %1 = hal.interface.constant.load[1] : i32
    %2 = hal.interface.constant.load[2] : i32
    %3 = hal.interface.constant.load[3] : i32
    %4 = arith.extui %0 : i32 to i64
    %5 = arith.extui %1 : i32 to i64
    %6 = arith.shli %5, %c32_i64 : i64
    %7 = arith.ori %4, %6 : i64
    %8 = arith.index_castui %7 : i64 to index
    %9 = arith.extui %2 : i32 to i64
    %10 = arith.extui %3 : i32 to i64
    %11 = arith.shli %10, %c32_i64 : i64
    %12 = arith.ori %9, %11 : i64
    %13 = arith.index_castui %12 : i64 to index
    %14 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>{%8, %13}
    memref.assume_alignment %14, 64 : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>
    %15 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>{%8, %13}
    memref.assume_alignment %15, 64 : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %16 = affine.apply affine_map<()[s0, s1] -> ((s0 floordiv (s1 ceildiv 128)) * 32)>()[%workgroup_id_x, %13]
    %17 = affine.apply affine_map<()[s0, s1] -> ((s0 mod (s1 ceildiv 128)) * 128)>()[%workgroup_id_x, %13]
    %18 = affine.min affine_map<()[s0, s1, s2] -> (32, s0 - (s1 floordiv (s2 ceildiv 128)) * 32)>()[%8, %workgroup_id_x, %13]
    %19 = affine.min affine_map<()[s0, s1] -> (128, s0 - (s1 mod (s0 ceildiv 128)) * 128)>()[%13, %workgroup_id_x]
    %subview = memref.subview %15[%16, %17] [%18, %19] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %subview_0 = memref.subview %14[%16, 0] [%18, %13] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %subview_1 = memref.subview %14[0, %17] [%13, %19] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    scf.forall (%arg0, %arg1) in (8, 32) {
      %20 = affine.min affine_map<(d0)[s0] -> (-(d0 * (s0 ceildiv 8)) + s0, s0 ceildiv 8)>(%arg0)[%18]
      %21 = affine.max affine_map<(d0) -> (0, d0)>(%20)
      %22 = affine.min affine_map<(d0)[s0] -> (-(d0 * (s0 ceildiv 32)) + s0, s0 ceildiv 32)>(%arg1)[%19]
      %23 = affine.max affine_map<(d0) -> (0, d0)>(%22)
      %24 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 8))>(%arg0)[%18]
      %25 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 32))>(%arg1)[%19]
      %subview_2 = memref.subview %subview[%24, %25] [%21, %23] [1, 1] : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      linalg.fill {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%cst : f32) outs(%subview_2 : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>)
    } {mapping = [#gpu.thread<y>, #gpu.thread<x>]}
    scf.for %arg0 = %c0 to %13 step %c1 {
      %subview_2 = memref.subview %subview_0[0, %arg0] [%18, 1] [1, 1] : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?x1xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      %subview_3 = memref.subview %subview_1[%arg0, 0] [1, %19] [1, 1] : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<1x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      scf.forall (%arg1, %arg2) in (8, 32) {
        %20 = affine.min affine_map<(d0)[s0] -> (-(d0 * (s0 ceildiv 8)) + s0, s0 ceildiv 8)>(%arg1)[%18]
        %21 = affine.max affine_map<(d0) -> (0, d0)>(%20)
        %22 = affine.min affine_map<(d0)[s0] -> (-(d0 * (s0 ceildiv 32)) + s0, s0 ceildiv 32)>(%arg2)[%19]
        %23 = affine.max affine_map<(d0) -> (0, d0)>(%22)
        %24 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 8))>(%arg1)[%18]
        %25 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 32))>(%arg2)[%19]
        %subview_4 = memref.subview %subview_2[%24, 0] [%21, 1] [1, 1] : memref<?x1xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?x1xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
        %subview_5 = memref.subview %subview_3[0, %25] [1, %23] [1, 1] : memref<1x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<1x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
        %subview_6 = memref.subview %subview[%24, %25] [%21, %23] [1, 1] : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
        linalg.matmul {__internal_linalg_transform__ = "workgroup_k_tiled", lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%subview_4, %subview_5 : memref<?x1xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, memref<1x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) outs(%subview_6 : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>)
      } {mapping = [#gpu.thread<y>, #gpu.thread<x>]}
    }
    return
  }
}

// -----// IR Dump After CSE (cse) //----- //
module {
  func.func @main_dispatch_0_matmul_DxDxD_f32() {
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c32_i64 = arith.constant 32 : i64
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.interface.constant.load[0] : i32
    %1 = hal.interface.constant.load[1] : i32
    %2 = hal.interface.constant.load[2] : i32
    %3 = hal.interface.constant.load[3] : i32
    %4 = arith.extui %0 : i32 to i64
    %5 = arith.extui %1 : i32 to i64
    %6 = arith.shli %5, %c32_i64 : i64
    %7 = arith.ori %4, %6 : i64
    %8 = arith.index_castui %7 : i64 to index
    %9 = arith.extui %2 : i32 to i64
    %10 = arith.extui %3 : i32 to i64
    %11 = arith.shli %10, %c32_i64 : i64
    %12 = arith.ori %9, %11 : i64
    %13 = arith.index_castui %12 : i64 to index
    %14 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>{%8, %13}
    memref.assume_alignment %14, 64 : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>
    %15 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>{%8, %13}
    memref.assume_alignment %15, 64 : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %16 = affine.apply affine_map<()[s0, s1] -> ((s0 floordiv (s1 ceildiv 128)) * 32)>()[%workgroup_id_x, %13]
    %17 = affine.apply affine_map<()[s0, s1] -> ((s0 mod (s1 ceildiv 128)) * 128)>()[%workgroup_id_x, %13]
    %18 = affine.min affine_map<()[s0, s1, s2] -> (32, s0 - (s1 floordiv (s2 ceildiv 128)) * 32)>()[%8, %workgroup_id_x, %13]
    %19 = affine.min affine_map<()[s0, s1] -> (128, s0 - (s1 mod (s0 ceildiv 128)) * 128)>()[%13, %workgroup_id_x]
    %subview = memref.subview %15[%16, %17] [%18, %19] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %subview_0 = memref.subview %14[%16, 0] [%18, %13] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %subview_1 = memref.subview %14[0, %17] [%13, %19] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    scf.forall (%arg0, %arg1) in (8, 32) {
      %20 = affine.min affine_map<(d0)[s0] -> (-(d0 * (s0 ceildiv 8)) + s0, s0 ceildiv 8)>(%arg0)[%18]
      %21 = affine.max affine_map<(d0) -> (0, d0)>(%20)
      %22 = affine.min affine_map<(d0)[s0] -> (-(d0 * (s0 ceildiv 32)) + s0, s0 ceildiv 32)>(%arg1)[%19]
      %23 = affine.max affine_map<(d0) -> (0, d0)>(%22)
      %24 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 8))>(%arg0)[%18]
      %25 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 32))>(%arg1)[%19]
      %subview_2 = memref.subview %subview[%24, %25] [%21, %23] [1, 1] : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      linalg.fill {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%cst : f32) outs(%subview_2 : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>)
    } {mapping = [#gpu.thread<y>, #gpu.thread<x>]}
    scf.for %arg0 = %c0 to %13 step %c1 {
      %subview_2 = memref.subview %subview_0[0, %arg0] [%18, 1] [1, 1] : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?x1xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      %subview_3 = memref.subview %subview_1[%arg0, 0] [1, %19] [1, 1] : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<1x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      scf.forall (%arg1, %arg2) in (8, 32) {
        %20 = affine.min affine_map<(d0)[s0] -> (-(d0 * (s0 ceildiv 8)) + s0, s0 ceildiv 8)>(%arg1)[%18]
        %21 = affine.max affine_map<(d0) -> (0, d0)>(%20)
        %22 = affine.min affine_map<(d0)[s0] -> (-(d0 * (s0 ceildiv 32)) + s0, s0 ceildiv 32)>(%arg2)[%19]
        %23 = affine.max affine_map<(d0) -> (0, d0)>(%22)
        %24 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 8))>(%arg1)[%18]
        %25 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 32))>(%arg2)[%19]
        %subview_4 = memref.subview %subview_2[%24, 0] [%21, 1] [1, 1] : memref<?x1xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?x1xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
        %subview_5 = memref.subview %subview_3[0, %25] [1, %23] [1, 1] : memref<1x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<1x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
        %subview_6 = memref.subview %subview[%24, %25] [%21, %23] [1, 1] : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
        linalg.matmul {__internal_linalg_transform__ = "workgroup_k_tiled", lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%subview_4, %subview_5 : memref<?x1xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, memref<1x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) outs(%subview_6 : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>)
      } {mapping = [#gpu.thread<y>, #gpu.thread<x>]}
    }
    return
  }
}

// -----// IR Dump After GPUDistribute (iree-codegen-gpu-distribute) //----- //
func.func @main_dispatch_0_matmul_DxDxD_f32() {
  %c0 = arith.constant 0 : index
  %c0_0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c32_i64 = arith.constant 32 : i64
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.interface.constant.load[0] : i32
  %1 = hal.interface.constant.load[1] : i32
  %2 = hal.interface.constant.load[2] : i32
  %3 = hal.interface.constant.load[3] : i32
  %4 = arith.extui %0 : i32 to i64
  %5 = arith.extui %1 : i32 to i64
  %6 = arith.shli %5, %c32_i64 : i64
  %7 = arith.ori %4, %6 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %2 : i32 to i64
  %10 = arith.extui %3 : i32 to i64
  %11 = arith.shli %10, %c32_i64 : i64
  %12 = arith.ori %9, %11 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0_0) flags(ReadOnly) : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>{%8, %13}
  memref.assume_alignment %14, 64 : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>
  %15 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0_0) : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>{%8, %13}
  memref.assume_alignment %15, 64 : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %16 = affine.apply affine_map<()[s0, s1] -> ((s0 floordiv (s1 ceildiv 128)) * 32)>()[%workgroup_id_x, %13]
  %17 = affine.apply affine_map<()[s0, s1] -> ((s0 mod (s1 ceildiv 128)) * 128)>()[%workgroup_id_x, %13]
  %18 = affine.min affine_map<()[s0, s1, s2] -> (32, s0 - (s1 floordiv (s2 ceildiv 128)) * 32)>()[%8, %workgroup_id_x, %13]
  %19 = affine.min affine_map<()[s0, s1] -> (128, s0 - (s1 mod (s0 ceildiv 128)) * 128)>()[%13, %workgroup_id_x]
  %subview = memref.subview %15[%16, %17] [%18, %19] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %subview_1 = memref.subview %14[%16, 0] [%18, %13] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %subview_2 = memref.subview %14[0, %17] [%13, %19] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %20 = gpu.thread_id  x
  %21 = gpu.thread_id  y
  %22 = gpu.thread_id  z
  %23 = affine.min affine_map<(d0)[s0] -> (-(d0 * (s0 ceildiv 8)) + s0, s0 ceildiv 8)>(%21)[%18]
  %24 = affine.max affine_map<(d0) -> (0, d0)>(%23)
  %25 = affine.min affine_map<(d0)[s0] -> (-(d0 * (s0 ceildiv 32)) + s0, s0 ceildiv 32)>(%20)[%19]
  %26 = affine.max affine_map<(d0) -> (0, d0)>(%25)
  %27 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 8))>(%21)[%18]
  %28 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 32))>(%20)[%19]
  %subview_3 = memref.subview %subview[%27, %28] [%24, %26] [1, 1] : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  linalg.fill {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%cst : f32) outs(%subview_3 : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>)
  scf.for %arg0 = %c0_0 to %13 step %c1 {
    %subview_4 = memref.subview %subview_1[0, %arg0] [%18, 1] [1, 1] : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?x1xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %subview_5 = memref.subview %subview_2[%arg0, 0] [1, %19] [1, 1] : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<1x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %29 = gpu.thread_id  x
    %30 = gpu.thread_id  y
    %31 = gpu.thread_id  z
    %32 = affine.min affine_map<(d0)[s0] -> (-(d0 * (s0 ceildiv 8)) + s0, s0 ceildiv 8)>(%30)[%18]
    %33 = affine.max affine_map<(d0) -> (0, d0)>(%32)
    %34 = affine.min affine_map<(d0)[s0] -> (-(d0 * (s0 ceildiv 32)) + s0, s0 ceildiv 32)>(%29)[%19]
    %35 = affine.max affine_map<(d0) -> (0, d0)>(%34)
    %36 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 8))>(%30)[%18]
    %37 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 32))>(%29)[%19]
    %subview_6 = memref.subview %subview_4[%36, 0] [%33, 1] [1, 1] : memref<?x1xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?x1xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %subview_7 = memref.subview %subview_5[0, %37] [1, %35] [1, 1] : memref<1x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<1x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %subview_8 = memref.subview %subview[%36, %37] [%33, %35] [1, 1] : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    linalg.matmul {__internal_linalg_transform__ = "workgroup_k_tiled", lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%subview_6, %subview_7 : memref<?x1xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, memref<1x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) outs(%subview_8 : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>)
  }
  return
}

// -----// IR Dump After MemrefCopyToLinalgPass (iree-codegen-memrefcopy-to-linalg) //----- //
func.func @main_dispatch_0_matmul_DxDxD_f32() {
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c32_i64 = arith.constant 32 : i64
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.interface.constant.load[0] : i32
  %1 = hal.interface.constant.load[1] : i32
  %2 = hal.interface.constant.load[2] : i32
  %3 = hal.interface.constant.load[3] : i32
  %4 = arith.extui %0 : i32 to i64
  %5 = arith.extui %1 : i32 to i64
  %6 = arith.shli %5, %c32_i64 : i64
  %7 = arith.ori %4, %6 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %2 : i32 to i64
  %10 = arith.extui %3 : i32 to i64
  %11 = arith.shli %10, %c32_i64 : i64
  %12 = arith.ori %9, %11 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>{%8, %13}
  memref.assume_alignment %14, 64 : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>
  %15 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>{%8, %13}
  memref.assume_alignment %15, 64 : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %16 = affine.apply affine_map<()[s0, s1] -> ((s0 floordiv (s1 ceildiv 128)) * 32)>()[%workgroup_id_x, %13]
  %17 = affine.apply affine_map<()[s0, s1] -> ((s0 mod (s1 ceildiv 128)) * 128)>()[%workgroup_id_x, %13]
  %18 = affine.min affine_map<()[s0, s1, s2] -> (32, s0 - (s1 floordiv (s2 ceildiv 128)) * 32)>()[%8, %workgroup_id_x, %13]
  %19 = affine.min affine_map<()[s0, s1] -> (128, s0 - (s1 mod (s0 ceildiv 128)) * 128)>()[%13, %workgroup_id_x]
  %subview = memref.subview %15[%16, %17] [%18, %19] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %subview_0 = memref.subview %14[%16, 0] [%18, %13] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %subview_1 = memref.subview %14[0, %17] [%13, %19] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %20 = gpu.thread_id  x
  %21 = gpu.thread_id  y
  %22 = affine.min affine_map<(d0)[s0] -> (-(d0 * (s0 ceildiv 8)) + s0, s0 ceildiv 8)>(%21)[%18]
  %23 = affine.max affine_map<(d0) -> (0, d0)>(%22)
  %24 = affine.min affine_map<(d0)[s0] -> (-(d0 * (s0 ceildiv 32)) + s0, s0 ceildiv 32)>(%20)[%19]
  %25 = affine.max affine_map<(d0) -> (0, d0)>(%24)
  %26 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 8))>(%21)[%18]
  %27 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 32))>(%20)[%19]
  %subview_2 = memref.subview %subview[%26, %27] [%23, %25] [1, 1] : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  linalg.fill {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%cst : f32) outs(%subview_2 : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>)
  scf.for %arg0 = %c0 to %13 step %c1 {
    %subview_3 = memref.subview %subview_0[0, %arg0] [%18, 1] [1, 1] : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?x1xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %subview_4 = memref.subview %subview_1[%arg0, 0] [1, %19] [1, 1] : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<1x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %28 = gpu.thread_id  x
    %29 = gpu.thread_id  y
    %30 = affine.min affine_map<(d0)[s0] -> (-(d0 * (s0 ceildiv 8)) + s0, s0 ceildiv 8)>(%29)[%18]
    %31 = affine.max affine_map<(d0) -> (0, d0)>(%30)
    %32 = affine.min affine_map<(d0)[s0] -> (-(d0 * (s0 ceildiv 32)) + s0, s0 ceildiv 32)>(%28)[%19]
    %33 = affine.max affine_map<(d0) -> (0, d0)>(%32)
    %34 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 8))>(%29)[%18]
    %35 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 32))>(%28)[%19]
    %subview_5 = memref.subview %subview_3[%34, 0] [%31, 1] [1, 1] : memref<?x1xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?x1xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %subview_6 = memref.subview %subview_4[0, %35] [1, %33] [1, 1] : memref<1x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<1x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %subview_7 = memref.subview %subview[%34, %35] [%31, %33] [1, 1] : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    linalg.matmul {__internal_linalg_transform__ = "workgroup_k_tiled", lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%subview_5, %subview_6 : memref<?x1xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, memref<1x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) outs(%subview_7 : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>)
  }
  return
}

// -----// IR Dump After GPUDistributeSharedMemoryCopy (iree-codegen-gpu-distribute-shared-memory-copy) //----- //
func.func @main_dispatch_0_matmul_DxDxD_f32() {
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c32_i64 = arith.constant 32 : i64
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.interface.constant.load[0] : i32
  %1 = hal.interface.constant.load[1] : i32
  %2 = hal.interface.constant.load[2] : i32
  %3 = hal.interface.constant.load[3] : i32
  %4 = arith.extui %0 : i32 to i64
  %5 = arith.extui %1 : i32 to i64
  %6 = arith.shli %5, %c32_i64 : i64
  %7 = arith.ori %4, %6 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %2 : i32 to i64
  %10 = arith.extui %3 : i32 to i64
  %11 = arith.shli %10, %c32_i64 : i64
  %12 = arith.ori %9, %11 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>{%8, %13}
  memref.assume_alignment %14, 64 : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>
  %15 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>{%8, %13}
  memref.assume_alignment %15, 64 : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %16 = affine.apply affine_map<()[s0, s1] -> ((s0 floordiv (s1 ceildiv 128)) * 32)>()[%workgroup_id_x, %13]
  %17 = affine.apply affine_map<()[s0, s1] -> ((s0 mod (s1 ceildiv 128)) * 128)>()[%workgroup_id_x, %13]
  %18 = affine.min affine_map<()[s0, s1, s2] -> (32, s0 - (s1 floordiv (s2 ceildiv 128)) * 32)>()[%8, %workgroup_id_x, %13]
  %19 = affine.min affine_map<()[s0, s1] -> (128, s0 - (s1 mod (s0 ceildiv 128)) * 128)>()[%13, %workgroup_id_x]
  %subview = memref.subview %15[%16, %17] [%18, %19] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %subview_0 = memref.subview %14[%16, 0] [%18, %13] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %subview_1 = memref.subview %14[0, %17] [%13, %19] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %20 = gpu.thread_id  x
  %21 = gpu.thread_id  y
  %22 = affine.min affine_map<(d0)[s0] -> (-(d0 * (s0 ceildiv 8)) + s0, s0 ceildiv 8)>(%21)[%18]
  %23 = affine.max affine_map<(d0) -> (0, d0)>(%22)
  %24 = affine.min affine_map<(d0)[s0] -> (-(d0 * (s0 ceildiv 32)) + s0, s0 ceildiv 32)>(%20)[%19]
  %25 = affine.max affine_map<(d0) -> (0, d0)>(%24)
  %26 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 8))>(%21)[%18]
  %27 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 32))>(%20)[%19]
  %subview_2 = memref.subview %subview[%26, %27] [%23, %25] [1, 1] : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  linalg.fill {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%cst : f32) outs(%subview_2 : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>)
  scf.for %arg0 = %c0 to %13 step %c1 {
    %subview_3 = memref.subview %subview_0[0, %arg0] [%18, 1] [1, 1] : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?x1xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %subview_4 = memref.subview %subview_1[%arg0, 0] [1, %19] [1, 1] : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<1x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %28 = gpu.thread_id  x
    %29 = gpu.thread_id  y
    %30 = affine.min affine_map<(d0)[s0] -> (-(d0 * (s0 ceildiv 8)) + s0, s0 ceildiv 8)>(%29)[%18]
    %31 = affine.max affine_map<(d0) -> (0, d0)>(%30)
    %32 = affine.min affine_map<(d0)[s0] -> (-(d0 * (s0 ceildiv 32)) + s0, s0 ceildiv 32)>(%28)[%19]
    %33 = affine.max affine_map<(d0) -> (0, d0)>(%32)
    %34 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 8))>(%29)[%18]
    %35 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 32))>(%28)[%19]
    %subview_5 = memref.subview %subview_3[%34, 0] [%31, 1] [1, 1] : memref<?x1xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?x1xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %subview_6 = memref.subview %subview_4[0, %35] [1, %33] [1, 1] : memref<1x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<1x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %subview_7 = memref.subview %subview[%34, %35] [%31, %33] [1, 1] : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    linalg.matmul {__internal_linalg_transform__ = "workgroup_k_tiled", lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%subview_5, %subview_6 : memref<?x1xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, memref<1x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) outs(%subview_7 : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>)
  }
  return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
module {
  func.func @main_dispatch_0_matmul_DxDxD_f32() {
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c32_i64 = arith.constant 32 : i64
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.interface.constant.load[0] : i32
    %1 = hal.interface.constant.load[1] : i32
    %2 = hal.interface.constant.load[2] : i32
    %3 = hal.interface.constant.load[3] : i32
    %4 = arith.extui %0 : i32 to i64
    %5 = arith.extui %1 : i32 to i64
    %6 = arith.shli %5, %c32_i64 : i64
    %7 = arith.ori %4, %6 : i64
    %8 = arith.index_castui %7 : i64 to index
    %9 = arith.extui %2 : i32 to i64
    %10 = arith.extui %3 : i32 to i64
    %11 = arith.shli %10, %c32_i64 : i64
    %12 = arith.ori %9, %11 : i64
    %13 = arith.index_castui %12 : i64 to index
    %14 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>{%8, %13}
    memref.assume_alignment %14, 64 : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>
    %15 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>{%8, %13}
    memref.assume_alignment %15, 64 : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %16 = affine.apply affine_map<()[s0, s1] -> ((s0 floordiv (s1 ceildiv 128)) * 32)>()[%workgroup_id_x, %13]
    %17 = affine.apply affine_map<()[s0, s1] -> ((s0 mod (s1 ceildiv 128)) * 128)>()[%workgroup_id_x, %13]
    %18 = affine.min affine_map<()[s0, s1, s2] -> (32, s0 - (s1 floordiv (s2 ceildiv 128)) * 32)>()[%8, %workgroup_id_x, %13]
    %19 = affine.min affine_map<()[s0, s1] -> (128, s0 - (s1 mod (s0 ceildiv 128)) * 128)>()[%13, %workgroup_id_x]
    %subview = memref.subview %15[%16, %17] [%18, %19] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %subview_0 = memref.subview %14[%16, 0] [%18, %13] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %subview_1 = memref.subview %14[0, %17] [%13, %19] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %20 = gpu.thread_id  x
    %21 = gpu.thread_id  y
    %22 = affine.min affine_map<()[s0, s1] -> (s0 - s1 * (s0 ceildiv 8), s0 ceildiv 8)>()[%18, %21]
    %23 = affine.max affine_map<()[s0] -> (0, s0)>()[%22]
    %24 = affine.min affine_map<()[s0, s1] -> (s0 - s1 * (s0 ceildiv 32), s0 ceildiv 32)>()[%19, %20]
    %25 = affine.max affine_map<()[s0] -> (0, s0)>()[%24]
    %26 = affine.apply affine_map<()[s0, s1] -> (s1 * (s0 ceildiv 8))>()[%18, %21]
    %27 = affine.apply affine_map<()[s0, s1] -> (s1 * (s0 ceildiv 32))>()[%19, %20]
    %subview_2 = memref.subview %subview[%26, %27] [%23, %25] [1, 1] : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    linalg.fill {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%cst : f32) outs(%subview_2 : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>)
    scf.for %arg0 = %c0 to %13 step %c1 {
      %subview_3 = memref.subview %subview_0[0, %arg0] [%18, 1] [1, 1] : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?x1xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      %subview_4 = memref.subview %subview_1[%arg0, 0] [1, %19] [1, 1] : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<1x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      %28 = gpu.thread_id  x
      %29 = gpu.thread_id  y
      %30 = affine.min affine_map<(d0)[s0] -> (-(d0 * (s0 ceildiv 8)) + s0, s0 ceildiv 8)>(%29)[%18]
      %31 = affine.max affine_map<(d0) -> (0, d0)>(%30)
      %32 = affine.min affine_map<(d0)[s0] -> (-(d0 * (s0 ceildiv 32)) + s0, s0 ceildiv 32)>(%28)[%19]
      %33 = affine.max affine_map<(d0) -> (0, d0)>(%32)
      %34 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 8))>(%29)[%18]
      %35 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 32))>(%28)[%19]
      %subview_5 = memref.subview %subview_3[%34, 0] [%31, 1] [1, 1] : memref<?x1xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?x1xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      %subview_6 = memref.subview %subview_4[0, %35] [1, %33] [1, 1] : memref<1x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<1x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      %subview_7 = memref.subview %subview[%34, %35] [%31, %33] [1, 1] : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      linalg.matmul {__internal_linalg_transform__ = "workgroup_k_tiled", lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%subview_5, %subview_6 : memref<?x1xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, memref<1x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) outs(%subview_7 : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>)
    }
    return
  }
}

// -----// IR Dump After CSE (cse) //----- //
module {
  func.func @main_dispatch_0_matmul_DxDxD_f32() {
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c32_i64 = arith.constant 32 : i64
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.interface.constant.load[0] : i32
    %1 = hal.interface.constant.load[1] : i32
    %2 = hal.interface.constant.load[2] : i32
    %3 = hal.interface.constant.load[3] : i32
    %4 = arith.extui %0 : i32 to i64
    %5 = arith.extui %1 : i32 to i64
    %6 = arith.shli %5, %c32_i64 : i64
    %7 = arith.ori %4, %6 : i64
    %8 = arith.index_castui %7 : i64 to index
    %9 = arith.extui %2 : i32 to i64
    %10 = arith.extui %3 : i32 to i64
    %11 = arith.shli %10, %c32_i64 : i64
    %12 = arith.ori %9, %11 : i64
    %13 = arith.index_castui %12 : i64 to index
    %14 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>{%8, %13}
    memref.assume_alignment %14, 64 : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>
    %15 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>{%8, %13}
    memref.assume_alignment %15, 64 : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %16 = affine.apply affine_map<()[s0, s1] -> ((s0 floordiv (s1 ceildiv 128)) * 32)>()[%workgroup_id_x, %13]
    %17 = affine.apply affine_map<()[s0, s1] -> ((s0 mod (s1 ceildiv 128)) * 128)>()[%workgroup_id_x, %13]
    %18 = affine.min affine_map<()[s0, s1, s2] -> (32, s0 - (s1 floordiv (s2 ceildiv 128)) * 32)>()[%8, %workgroup_id_x, %13]
    %19 = affine.min affine_map<()[s0, s1] -> (128, s0 - (s1 mod (s0 ceildiv 128)) * 128)>()[%13, %workgroup_id_x]
    %subview = memref.subview %15[%16, %17] [%18, %19] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %subview_0 = memref.subview %14[%16, 0] [%18, %13] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %subview_1 = memref.subview %14[0, %17] [%13, %19] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %20 = gpu.thread_id  x
    %21 = gpu.thread_id  y
    %22 = affine.min affine_map<()[s0, s1] -> (s0 - s1 * (s0 ceildiv 8), s0 ceildiv 8)>()[%18, %21]
    %23 = affine.max affine_map<()[s0] -> (0, s0)>()[%22]
    %24 = affine.min affine_map<()[s0, s1] -> (s0 - s1 * (s0 ceildiv 32), s0 ceildiv 32)>()[%19, %20]
    %25 = affine.max affine_map<()[s0] -> (0, s0)>()[%24]
    %26 = affine.apply affine_map<()[s0, s1] -> (s1 * (s0 ceildiv 8))>()[%18, %21]
    %27 = affine.apply affine_map<()[s0, s1] -> (s1 * (s0 ceildiv 32))>()[%19, %20]
    %subview_2 = memref.subview %subview[%26, %27] [%23, %25] [1, 1] : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    linalg.fill {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%cst : f32) outs(%subview_2 : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>)
    scf.for %arg0 = %c0 to %13 step %c1 {
      %subview_3 = memref.subview %subview_0[0, %arg0] [%18, 1] [1, 1] : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?x1xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      %subview_4 = memref.subview %subview_1[%arg0, 0] [1, %19] [1, 1] : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<1x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      %28 = affine.min affine_map<(d0)[s0] -> (-(d0 * (s0 ceildiv 8)) + s0, s0 ceildiv 8)>(%21)[%18]
      %29 = affine.max affine_map<(d0) -> (0, d0)>(%28)
      %30 = affine.min affine_map<(d0)[s0] -> (-(d0 * (s0 ceildiv 32)) + s0, s0 ceildiv 32)>(%20)[%19]
      %31 = affine.max affine_map<(d0) -> (0, d0)>(%30)
      %32 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 8))>(%21)[%18]
      %33 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 32))>(%20)[%19]
      %subview_5 = memref.subview %subview_3[%32, 0] [%29, 1] [1, 1] : memref<?x1xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?x1xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      %subview_6 = memref.subview %subview_4[0, %33] [1, %31] [1, 1] : memref<1x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<1x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      %subview_7 = memref.subview %subview[%32, %33] [%29, %31] [1, 1] : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      linalg.matmul {__internal_linalg_transform__ = "workgroup_k_tiled", lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%subview_5, %subview_6 : memref<?x1xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, memref<1x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) outs(%subview_7 : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>)
    }
    return
  }
}

// -----// IR Dump After GPUReduceBankConflicts (iree-codegen-gpu-reduce-bank-conflicts) //----- //
func.func @main_dispatch_0_matmul_DxDxD_f32() {
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c32_i64 = arith.constant 32 : i64
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.interface.constant.load[0] : i32
  %1 = hal.interface.constant.load[1] : i32
  %2 = hal.interface.constant.load[2] : i32
  %3 = hal.interface.constant.load[3] : i32
  %4 = arith.extui %0 : i32 to i64
  %5 = arith.extui %1 : i32 to i64
  %6 = arith.shli %5, %c32_i64 : i64
  %7 = arith.ori %4, %6 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %2 : i32 to i64
  %10 = arith.extui %3 : i32 to i64
  %11 = arith.shli %10, %c32_i64 : i64
  %12 = arith.ori %9, %11 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>{%8, %13}
  memref.assume_alignment %14, 64 : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>
  %15 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>{%8, %13}
  memref.assume_alignment %15, 64 : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %16 = affine.apply affine_map<()[s0, s1] -> ((s0 floordiv (s1 ceildiv 128)) * 32)>()[%workgroup_id_x, %13]
  %17 = affine.apply affine_map<()[s0, s1] -> ((s0 mod (s1 ceildiv 128)) * 128)>()[%workgroup_id_x, %13]
  %18 = affine.min affine_map<()[s0, s1, s2] -> (32, s0 - (s1 floordiv (s2 ceildiv 128)) * 32)>()[%8, %workgroup_id_x, %13]
  %19 = affine.min affine_map<()[s0, s1] -> (128, s0 - (s1 mod (s0 ceildiv 128)) * 128)>()[%13, %workgroup_id_x]
  %subview = memref.subview %15[%16, %17] [%18, %19] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %subview_0 = memref.subview %14[%16, 0] [%18, %13] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %subview_1 = memref.subview %14[0, %17] [%13, %19] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %20 = gpu.thread_id  x
  %21 = gpu.thread_id  y
  %22 = affine.min affine_map<()[s0, s1] -> (s0 - s1 * (s0 ceildiv 8), s0 ceildiv 8)>()[%18, %21]
  %23 = affine.max affine_map<()[s0] -> (0, s0)>()[%22]
  %24 = affine.min affine_map<()[s0, s1] -> (s0 - s1 * (s0 ceildiv 32), s0 ceildiv 32)>()[%19, %20]
  %25 = affine.max affine_map<()[s0] -> (0, s0)>()[%24]
  %26 = affine.apply affine_map<()[s0, s1] -> (s1 * (s0 ceildiv 8))>()[%18, %21]
  %27 = affine.apply affine_map<()[s0, s1] -> (s1 * (s0 ceildiv 32))>()[%19, %20]
  %subview_2 = memref.subview %subview[%26, %27] [%23, %25] [1, 1] : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  linalg.fill {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%cst : f32) outs(%subview_2 : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>)
  scf.for %arg0 = %c0 to %13 step %c1 {
    %subview_3 = memref.subview %subview_0[0, %arg0] [%18, 1] [1, 1] : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?x1xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %subview_4 = memref.subview %subview_1[%arg0, 0] [1, %19] [1, 1] : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<1x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %28 = affine.min affine_map<(d0)[s0] -> (-(d0 * (s0 ceildiv 8)) + s0, s0 ceildiv 8)>(%21)[%18]
    %29 = affine.max affine_map<(d0) -> (0, d0)>(%28)
    %30 = affine.min affine_map<(d0)[s0] -> (-(d0 * (s0 ceildiv 32)) + s0, s0 ceildiv 32)>(%20)[%19]
    %31 = affine.max affine_map<(d0) -> (0, d0)>(%30)
    %32 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 8))>(%21)[%18]
    %33 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 32))>(%20)[%19]
    %subview_5 = memref.subview %subview_3[%32, 0] [%29, 1] [1, 1] : memref<?x1xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?x1xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %subview_6 = memref.subview %subview_4[0, %33] [1, %31] [1, 1] : memref<1x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<1x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %subview_7 = memref.subview %subview[%32, %33] [%29, %31] [1, 1] : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    linalg.matmul {__internal_linalg_transform__ = "workgroup_k_tiled", lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%subview_5, %subview_6 : memref<?x1xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, memref<1x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) outs(%subview_7 : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>)
  }
  return
}

// -----// IR Dump After WorkGroupSwizzle (iree-workgroup-swizzle) //----- //
func.func @main_dispatch_0_matmul_DxDxD_f32() {
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c32_i64 = arith.constant 32 : i64
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.interface.constant.load[0] : i32
  %1 = hal.interface.constant.load[1] : i32
  %2 = hal.interface.constant.load[2] : i32
  %3 = hal.interface.constant.load[3] : i32
  %4 = arith.extui %0 : i32 to i64
  %5 = arith.extui %1 : i32 to i64
  %6 = arith.shli %5, %c32_i64 : i64
  %7 = arith.ori %4, %6 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %2 : i32 to i64
  %10 = arith.extui %3 : i32 to i64
  %11 = arith.shli %10, %c32_i64 : i64
  %12 = arith.ori %9, %11 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>{%8, %13}
  memref.assume_alignment %14, 64 : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>
  %15 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>{%8, %13}
  memref.assume_alignment %15, 64 : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %16 = affine.apply affine_map<()[s0, s1] -> ((s0 floordiv (s1 ceildiv 128)) * 32)>()[%workgroup_id_x, %13]
  %17 = affine.apply affine_map<()[s0, s1] -> ((s0 mod (s1 ceildiv 128)) * 128)>()[%workgroup_id_x, %13]
  %18 = affine.min affine_map<()[s0, s1, s2] -> (32, s0 - (s1 floordiv (s2 ceildiv 128)) * 32)>()[%8, %workgroup_id_x, %13]
  %19 = affine.min affine_map<()[s0, s1] -> (128, s0 - (s1 mod (s0 ceildiv 128)) * 128)>()[%13, %workgroup_id_x]
  %subview = memref.subview %15[%16, %17] [%18, %19] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %subview_0 = memref.subview %14[%16, 0] [%18, %13] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %subview_1 = memref.subview %14[0, %17] [%13, %19] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %20 = gpu.thread_id  x
  %21 = gpu.thread_id  y
  %22 = affine.min affine_map<()[s0, s1] -> (s0 - s1 * (s0 ceildiv 8), s0 ceildiv 8)>()[%18, %21]
  %23 = affine.max affine_map<()[s0] -> (0, s0)>()[%22]
  %24 = affine.min affine_map<()[s0, s1] -> (s0 - s1 * (s0 ceildiv 32), s0 ceildiv 32)>()[%19, %20]
  %25 = affine.max affine_map<()[s0] -> (0, s0)>()[%24]
  %26 = affine.apply affine_map<()[s0, s1] -> (s1 * (s0 ceildiv 8))>()[%18, %21]
  %27 = affine.apply affine_map<()[s0, s1] -> (s1 * (s0 ceildiv 32))>()[%19, %20]
  %subview_2 = memref.subview %subview[%26, %27] [%23, %25] [1, 1] : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  linalg.fill {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%cst : f32) outs(%subview_2 : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>)
  scf.for %arg0 = %c0 to %13 step %c1 {
    %subview_3 = memref.subview %subview_0[0, %arg0] [%18, 1] [1, 1] : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?x1xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %subview_4 = memref.subview %subview_1[%arg0, 0] [1, %19] [1, 1] : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<1x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %28 = affine.min affine_map<(d0)[s0] -> (-(d0 * (s0 ceildiv 8)) + s0, s0 ceildiv 8)>(%21)[%18]
    %29 = affine.max affine_map<(d0) -> (0, d0)>(%28)
    %30 = affine.min affine_map<(d0)[s0] -> (-(d0 * (s0 ceildiv 32)) + s0, s0 ceildiv 32)>(%20)[%19]
    %31 = affine.max affine_map<(d0) -> (0, d0)>(%30)
    %32 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 8))>(%21)[%18]
    %33 = affine.apply affine_map<(d0)[s0] -> (d0 * (s0 ceildiv 32))>(%20)[%19]
    %subview_5 = memref.subview %subview_3[%32, 0] [%29, 1] [1, 1] : memref<?x1xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?x1xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %subview_6 = memref.subview %subview_4[0, %33] [1, %31] [1, 1] : memref<1x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<1x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %subview_7 = memref.subview %subview[%32, %33] [%29, %31] [1, 1] : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    linalg.matmul {__internal_linalg_transform__ = "workgroup_k_tiled", lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%subview_5, %subview_6 : memref<?x1xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, memref<1x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) outs(%subview_7 : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>)
  }
  return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
module {
  func.func @main_dispatch_0_matmul_DxDxD_f32() {
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c32_i64 = arith.constant 32 : i64
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.interface.constant.load[0] : i32
    %1 = hal.interface.constant.load[1] : i32
    %2 = hal.interface.constant.load[2] : i32
    %3 = hal.interface.constant.load[3] : i32
    %4 = arith.extui %0 : i32 to i64
    %5 = arith.extui %1 : i32 to i64
    %6 = arith.shli %5, %c32_i64 : i64
    %7 = arith.ori %4, %6 : i64
    %8 = arith.index_castui %7 : i64 to index
    %9 = arith.extui %2 : i32 to i64
    %10 = arith.extui %3 : i32 to i64
    %11 = arith.shli %10, %c32_i64 : i64
    %12 = arith.ori %9, %11 : i64
    %13 = arith.index_castui %12 : i64 to index
    %14 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>{%8, %13}
    memref.assume_alignment %14, 64 : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>
    %15 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>{%8, %13}
    memref.assume_alignment %15, 64 : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %16 = affine.apply affine_map<()[s0, s1] -> ((s0 floordiv (s1 ceildiv 128)) * 32)>()[%workgroup_id_x, %13]
    %17 = affine.apply affine_map<()[s0, s1] -> ((s0 mod (s1 ceildiv 128)) * 128)>()[%workgroup_id_x, %13]
    %18 = affine.min affine_map<()[s0, s1, s2] -> (32, s0 - (s1 floordiv (s2 ceildiv 128)) * 32)>()[%8, %workgroup_id_x, %13]
    %19 = affine.min affine_map<()[s0, s1] -> (128, s0 - (s1 mod (s0 ceildiv 128)) * 128)>()[%13, %workgroup_id_x]
    %subview = memref.subview %15[%16, %17] [%18, %19] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %subview_0 = memref.subview %14[%16, 0] [%18, %13] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %subview_1 = memref.subview %14[0, %17] [%13, %19] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %20 = gpu.thread_id  x
    %21 = gpu.thread_id  y
    %22 = affine.min affine_map<()[s0, s1] -> (s0 - s1 * (s0 ceildiv 8), s0 ceildiv 8)>()[%18, %21]
    %23 = affine.max affine_map<()[s0] -> (0, s0)>()[%22]
    %24 = affine.min affine_map<()[s0, s1] -> (s0 - s1 * (s0 ceildiv 32), s0 ceildiv 32)>()[%19, %20]
    %25 = affine.max affine_map<()[s0] -> (0, s0)>()[%24]
    %26 = affine.apply affine_map<()[s0, s1] -> (s1 * (s0 ceildiv 8))>()[%18, %21]
    %27 = affine.apply affine_map<()[s0, s1] -> (s1 * (s0 ceildiv 32))>()[%19, %20]
    %subview_2 = memref.subview %subview[%26, %27] [%23, %25] [1, 1] : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    linalg.fill {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%cst : f32) outs(%subview_2 : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>)
    scf.for %arg0 = %c0 to %13 step %c1 {
      %subview_3 = memref.subview %subview_0[0, %arg0] [%18, 1] [1, 1] : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?x1xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      %subview_4 = memref.subview %subview_1[%arg0, 0] [1, %19] [1, 1] : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<1x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      %28 = affine.min affine_map<()[s0, s1] -> (s0 - s1 * (s0 ceildiv 8), s0 ceildiv 8)>()[%18, %21]
      %29 = affine.max affine_map<(d0) -> (0, d0)>(%28)
      %30 = affine.min affine_map<()[s0, s1] -> (s0 - s1 * (s0 ceildiv 32), s0 ceildiv 32)>()[%19, %20]
      %31 = affine.max affine_map<(d0) -> (0, d0)>(%30)
      %32 = affine.apply affine_map<()[s0, s1] -> (s1 * (s0 ceildiv 8))>()[%18, %21]
      %33 = affine.apply affine_map<()[s0, s1] -> (s1 * (s0 ceildiv 32))>()[%19, %20]
      %subview_5 = memref.subview %subview_3[%32, 0] [%29, 1] [1, 1] : memref<?x1xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?x1xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      %subview_6 = memref.subview %subview_4[0, %33] [1, %31] [1, 1] : memref<1x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<1x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      %subview_7 = memref.subview %subview[%32, %33] [%29, %31] [1, 1] : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      linalg.matmul {__internal_linalg_transform__ = "workgroup_k_tiled", lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%subview_5, %subview_6 : memref<?x1xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, memref<1x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) outs(%subview_7 : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>)
    }
    return
  }
}

// -----// IR Dump After CSE (cse) //----- //
module {
  func.func @main_dispatch_0_matmul_DxDxD_f32() {
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c32_i64 = arith.constant 32 : i64
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.interface.constant.load[0] : i32
    %1 = hal.interface.constant.load[1] : i32
    %2 = hal.interface.constant.load[2] : i32
    %3 = hal.interface.constant.load[3] : i32
    %4 = arith.extui %0 : i32 to i64
    %5 = arith.extui %1 : i32 to i64
    %6 = arith.shli %5, %c32_i64 : i64
    %7 = arith.ori %4, %6 : i64
    %8 = arith.index_castui %7 : i64 to index
    %9 = arith.extui %2 : i32 to i64
    %10 = arith.extui %3 : i32 to i64
    %11 = arith.shli %10, %c32_i64 : i64
    %12 = arith.ori %9, %11 : i64
    %13 = arith.index_castui %12 : i64 to index
    %14 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>{%8, %13}
    memref.assume_alignment %14, 64 : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>
    %15 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>{%8, %13}
    memref.assume_alignment %15, 64 : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %16 = affine.apply affine_map<()[s0, s1] -> ((s0 floordiv (s1 ceildiv 128)) * 32)>()[%workgroup_id_x, %13]
    %17 = affine.apply affine_map<()[s0, s1] -> ((s0 mod (s1 ceildiv 128)) * 128)>()[%workgroup_id_x, %13]
    %18 = affine.min affine_map<()[s0, s1, s2] -> (32, s0 - (s1 floordiv (s2 ceildiv 128)) * 32)>()[%8, %workgroup_id_x, %13]
    %19 = affine.min affine_map<()[s0, s1] -> (128, s0 - (s1 mod (s0 ceildiv 128)) * 128)>()[%13, %workgroup_id_x]
    %subview = memref.subview %15[%16, %17] [%18, %19] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %subview_0 = memref.subview %14[%16, 0] [%18, %13] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %subview_1 = memref.subview %14[0, %17] [%13, %19] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %20 = gpu.thread_id  x
    %21 = gpu.thread_id  y
    %22 = affine.min affine_map<()[s0, s1] -> (s0 - s1 * (s0 ceildiv 8), s0 ceildiv 8)>()[%18, %21]
    %23 = affine.max affine_map<()[s0] -> (0, s0)>()[%22]
    %24 = affine.min affine_map<()[s0, s1] -> (s0 - s1 * (s0 ceildiv 32), s0 ceildiv 32)>()[%19, %20]
    %25 = affine.max affine_map<()[s0] -> (0, s0)>()[%24]
    %26 = affine.apply affine_map<()[s0, s1] -> (s1 * (s0 ceildiv 8))>()[%18, %21]
    %27 = affine.apply affine_map<()[s0, s1] -> (s1 * (s0 ceildiv 32))>()[%19, %20]
    %subview_2 = memref.subview %subview[%26, %27] [%23, %25] [1, 1] : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    linalg.fill {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%cst : f32) outs(%subview_2 : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>)
    scf.for %arg0 = %c0 to %13 step %c1 {
      %subview_3 = memref.subview %subview_0[0, %arg0] [%18, 1] [1, 1] : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?x1xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      %subview_4 = memref.subview %subview_1[%arg0, 0] [1, %19] [1, 1] : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<1x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      %28 = affine.max affine_map<(d0) -> (0, d0)>(%22)
      %29 = affine.max affine_map<(d0) -> (0, d0)>(%24)
      %subview_5 = memref.subview %subview_3[%26, 0] [%28, 1] [1, 1] : memref<?x1xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?x1xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      %subview_6 = memref.subview %subview_4[0, %27] [1, %29] [1, 1] : memref<1x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<1x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      %subview_7 = memref.subview %subview[%26, %27] [%28, %29] [1, 1] : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      linalg.matmul {__internal_linalg_transform__ = "workgroup_k_tiled", lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%subview_5, %subview_6 : memref<?x1xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, memref<1x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) outs(%subview_7 : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>)
    }
    return
  }
}

// -----// IR Dump After FoldMemRefAliasOps (fold-memref-alias-ops) //----- //
func.func @main_dispatch_0_matmul_DxDxD_f32() {
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c32_i64 = arith.constant 32 : i64
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.interface.constant.load[0] : i32
  %1 = hal.interface.constant.load[1] : i32
  %2 = hal.interface.constant.load[2] : i32
  %3 = hal.interface.constant.load[3] : i32
  %4 = arith.extui %0 : i32 to i64
  %5 = arith.extui %1 : i32 to i64
  %6 = arith.shli %5, %c32_i64 : i64
  %7 = arith.ori %4, %6 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %2 : i32 to i64
  %10 = arith.extui %3 : i32 to i64
  %11 = arith.shli %10, %c32_i64 : i64
  %12 = arith.ori %9, %11 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>{%8, %13}
  memref.assume_alignment %14, 64 : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>
  %15 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>{%8, %13}
  memref.assume_alignment %15, 64 : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %16 = affine.min affine_map<()[s0, s1, s2] -> (32, s0 - (s1 floordiv (s2 ceildiv 128)) * 32)>()[%8, %workgroup_id_x, %13]
  %17 = affine.min affine_map<()[s0, s1] -> (128, s0 - (s1 mod (s0 ceildiv 128)) * 128)>()[%13, %workgroup_id_x]
  %18 = gpu.thread_id  x
  %19 = gpu.thread_id  y
  %20 = affine.min affine_map<()[s0, s1] -> (s0 - s1 * (s0 ceildiv 8), s0 ceildiv 8)>()[%16, %19]
  %21 = affine.max affine_map<()[s0] -> (0, s0)>()[%20]
  %22 = affine.min affine_map<()[s0, s1] -> (s0 - s1 * (s0 ceildiv 32), s0 ceildiv 32)>()[%17, %18]
  %23 = affine.max affine_map<()[s0] -> (0, s0)>()[%22]
  %24 = affine.apply affine_map<()[s0, s1, s2, s3] -> ((s0 floordiv (s1 ceildiv 128)) * 32 + s3 * (s2 ceildiv 8))>()[%workgroup_id_x, %13, %16, %19]
  %25 = affine.apply affine_map<()[s0, s1, s2, s3] -> ((s0 mod (s1 ceildiv 128)) * 128 + s3 * (s2 ceildiv 32))>()[%workgroup_id_x, %13, %17, %18]
  %subview = memref.subview %15[%24, %25] [%21, %23] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  linalg.fill {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%cst : f32) outs(%subview : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>)
  scf.for %arg0 = %c0 to %13 step %c1 {
    %26 = affine.max affine_map<(d0) -> (0, d0)>(%20)
    %27 = affine.max affine_map<(d0) -> (0, d0)>(%22)
    %28 = affine.apply affine_map<()[s0, s1, s2, s3] -> ((s0 floordiv (s1 ceildiv 128)) * 32 + s3 * (s2 ceildiv 8))>()[%workgroup_id_x, %13, %16, %19]
    %subview_0 = memref.subview %14[%28, %arg0] [%26, 1] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x1xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %29 = affine.apply affine_map<()[s0, s1, s2, s3] -> ((s0 mod (s1 ceildiv 128)) * 128 + s3 * (s2 ceildiv 32))>()[%workgroup_id_x, %13, %17, %18]
    %subview_1 = memref.subview %14[%arg0, %29] [1, %27] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<1x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %30 = affine.apply affine_map<()[s0, s1, s2, s3] -> ((s0 floordiv (s1 ceildiv 128)) * 32 + s3 * (s2 ceildiv 8))>()[%workgroup_id_x, %13, %16, %19]
    %31 = affine.apply affine_map<()[s0, s1, s2, s3] -> ((s0 mod (s1 ceildiv 128)) * 128 + s3 * (s2 ceildiv 32))>()[%workgroup_id_x, %13, %17, %18]
    %subview_2 = memref.subview %15[%30, %31] [%26, %27] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    linalg.matmul {__internal_linalg_transform__ = "workgroup_k_tiled", lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%subview_0, %subview_1 : memref<?x1xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, memref<1x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) outs(%subview_2 : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>)
  }
  return
}

// -----// IR Dump After CSE (cse) //----- //
module {
  func.func @main_dispatch_0_matmul_DxDxD_f32() {
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c32_i64 = arith.constant 32 : i64
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.interface.constant.load[0] : i32
    %1 = hal.interface.constant.load[1] : i32
    %2 = hal.interface.constant.load[2] : i32
    %3 = hal.interface.constant.load[3] : i32
    %4 = arith.extui %0 : i32 to i64
    %5 = arith.extui %1 : i32 to i64
    %6 = arith.shli %5, %c32_i64 : i64
    %7 = arith.ori %4, %6 : i64
    %8 = arith.index_castui %7 : i64 to index
    %9 = arith.extui %2 : i32 to i64
    %10 = arith.extui %3 : i32 to i64
    %11 = arith.shli %10, %c32_i64 : i64
    %12 = arith.ori %9, %11 : i64
    %13 = arith.index_castui %12 : i64 to index
    %14 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>{%8, %13}
    memref.assume_alignment %14, 64 : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>
    %15 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>{%8, %13}
    memref.assume_alignment %15, 64 : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %16 = affine.min affine_map<()[s0, s1, s2] -> (32, s0 - (s1 floordiv (s2 ceildiv 128)) * 32)>()[%8, %workgroup_id_x, %13]
    %17 = affine.min affine_map<()[s0, s1] -> (128, s0 - (s1 mod (s0 ceildiv 128)) * 128)>()[%13, %workgroup_id_x]
    %18 = gpu.thread_id  x
    %19 = gpu.thread_id  y
    %20 = affine.min affine_map<()[s0, s1] -> (s0 - s1 * (s0 ceildiv 8), s0 ceildiv 8)>()[%16, %19]
    %21 = affine.max affine_map<()[s0] -> (0, s0)>()[%20]
    %22 = affine.min affine_map<()[s0, s1] -> (s0 - s1 * (s0 ceildiv 32), s0 ceildiv 32)>()[%17, %18]
    %23 = affine.max affine_map<()[s0] -> (0, s0)>()[%22]
    %24 = affine.apply affine_map<()[s0, s1, s2, s3] -> ((s0 floordiv (s1 ceildiv 128)) * 32 + s3 * (s2 ceildiv 8))>()[%workgroup_id_x, %13, %16, %19]
    %25 = affine.apply affine_map<()[s0, s1, s2, s3] -> ((s0 mod (s1 ceildiv 128)) * 128 + s3 * (s2 ceildiv 32))>()[%workgroup_id_x, %13, %17, %18]
    %subview = memref.subview %15[%24, %25] [%21, %23] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    linalg.fill {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%cst : f32) outs(%subview : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>)
    scf.for %arg0 = %c0 to %13 step %c1 {
      %26 = affine.max affine_map<(d0) -> (0, d0)>(%20)
      %27 = affine.max affine_map<(d0) -> (0, d0)>(%22)
      %subview_0 = memref.subview %14[%24, %arg0] [%26, 1] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x1xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      %subview_1 = memref.subview %14[%arg0, %25] [1, %27] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<1x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      %subview_2 = memref.subview %15[%24, %25] [%26, %27] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      linalg.matmul {__internal_linalg_transform__ = "workgroup_k_tiled", lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%subview_0, %subview_1 : memref<?x1xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, memref<1x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) outs(%subview_2 : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>)
    }
    return
  }
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
module {
  func.func @main_dispatch_0_matmul_DxDxD_f32() {
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c32_i64 = arith.constant 32 : i64
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.interface.constant.load[0] : i32
    %1 = hal.interface.constant.load[1] : i32
    %2 = hal.interface.constant.load[2] : i32
    %3 = hal.interface.constant.load[3] : i32
    %4 = arith.extui %0 : i32 to i64
    %5 = arith.extui %1 : i32 to i64
    %6 = arith.shli %5, %c32_i64 : i64
    %7 = arith.ori %4, %6 : i64
    %8 = arith.index_castui %7 : i64 to index
    %9 = arith.extui %2 : i32 to i64
    %10 = arith.extui %3 : i32 to i64
    %11 = arith.shli %10, %c32_i64 : i64
    %12 = arith.ori %9, %11 : i64
    %13 = arith.index_castui %12 : i64 to index
    %14 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>{%8, %13}
    memref.assume_alignment %14, 64 : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>
    %15 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>{%8, %13}
    memref.assume_alignment %15, 64 : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %16 = affine.min affine_map<()[s0, s1, s2] -> (32, s0 - (s1 floordiv (s2 ceildiv 128)) * 32)>()[%8, %workgroup_id_x, %13]
    %17 = affine.min affine_map<()[s0, s1] -> (128, s0 - (s1 mod (s0 ceildiv 128)) * 128)>()[%13, %workgroup_id_x]
    %18 = gpu.thread_id  x
    %19 = gpu.thread_id  y
    %20 = affine.min affine_map<()[s0, s1] -> (s0 - s1 * (s0 ceildiv 8), s0 ceildiv 8)>()[%16, %19]
    %21 = affine.max affine_map<()[s0] -> (0, s0)>()[%20]
    %22 = affine.min affine_map<()[s0, s1] -> (s0 - s1 * (s0 ceildiv 32), s0 ceildiv 32)>()[%17, %18]
    %23 = affine.max affine_map<()[s0] -> (0, s0)>()[%22]
    %24 = affine.apply affine_map<()[s0, s1, s2, s3] -> ((s0 floordiv (s1 ceildiv 128)) * 32 + s3 * (s2 ceildiv 8))>()[%workgroup_id_x, %13, %16, %19]
    %25 = affine.apply affine_map<()[s0, s1, s2, s3] -> ((s0 mod (s1 ceildiv 128)) * 128 + s3 * (s2 ceildiv 32))>()[%workgroup_id_x, %13, %17, %18]
    %subview = memref.subview %15[%24, %25] [%21, %23] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    linalg.fill {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%cst : f32) outs(%subview : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>)
    scf.for %arg0 = %c0 to %13 step %c1 {
      %26 = affine.max affine_map<()[s0] -> (0, s0)>()[%20]
      %27 = affine.max affine_map<()[s0] -> (0, s0)>()[%22]
      %subview_0 = memref.subview %14[%24, %arg0] [%26, 1] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x1xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      %subview_1 = memref.subview %14[%arg0, %25] [1, %27] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<1x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      %subview_2 = memref.subview %15[%24, %25] [%26, %27] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      linalg.matmul {__internal_linalg_transform__ = "workgroup_k_tiled", lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%subview_0, %subview_1 : memref<?x1xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, memref<1x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) outs(%subview_2 : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>)
    }
    return
  }
}

// -----// IR Dump After CSE (cse) //----- //
module {
  func.func @main_dispatch_0_matmul_DxDxD_f32() {
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c32_i64 = arith.constant 32 : i64
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.interface.constant.load[0] : i32
    %1 = hal.interface.constant.load[1] : i32
    %2 = hal.interface.constant.load[2] : i32
    %3 = hal.interface.constant.load[3] : i32
    %4 = arith.extui %0 : i32 to i64
    %5 = arith.extui %1 : i32 to i64
    %6 = arith.shli %5, %c32_i64 : i64
    %7 = arith.ori %4, %6 : i64
    %8 = arith.index_castui %7 : i64 to index
    %9 = arith.extui %2 : i32 to i64
    %10 = arith.extui %3 : i32 to i64
    %11 = arith.shli %10, %c32_i64 : i64
    %12 = arith.ori %9, %11 : i64
    %13 = arith.index_castui %12 : i64 to index
    %14 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>{%8, %13}
    memref.assume_alignment %14, 64 : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>
    %15 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>{%8, %13}
    memref.assume_alignment %15, 64 : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %16 = affine.min affine_map<()[s0, s1, s2] -> (32, s0 - (s1 floordiv (s2 ceildiv 128)) * 32)>()[%8, %workgroup_id_x, %13]
    %17 = affine.min affine_map<()[s0, s1] -> (128, s0 - (s1 mod (s0 ceildiv 128)) * 128)>()[%13, %workgroup_id_x]
    %18 = gpu.thread_id  x
    %19 = gpu.thread_id  y
    %20 = affine.min affine_map<()[s0, s1] -> (s0 - s1 * (s0 ceildiv 8), s0 ceildiv 8)>()[%16, %19]
    %21 = affine.max affine_map<()[s0] -> (0, s0)>()[%20]
    %22 = affine.min affine_map<()[s0, s1] -> (s0 - s1 * (s0 ceildiv 32), s0 ceildiv 32)>()[%17, %18]
    %23 = affine.max affine_map<()[s0] -> (0, s0)>()[%22]
    %24 = affine.apply affine_map<()[s0, s1, s2, s3] -> ((s0 floordiv (s1 ceildiv 128)) * 32 + s3 * (s2 ceildiv 8))>()[%workgroup_id_x, %13, %16, %19]
    %25 = affine.apply affine_map<()[s0, s1, s2, s3] -> ((s0 mod (s1 ceildiv 128)) * 128 + s3 * (s2 ceildiv 32))>()[%workgroup_id_x, %13, %17, %18]
    %subview = memref.subview %15[%24, %25] [%21, %23] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    linalg.fill {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%cst : f32) outs(%subview : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>)
    scf.for %arg0 = %c0 to %13 step %c1 {
      %subview_0 = memref.subview %14[%24, %arg0] [%21, 1] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x1xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      %subview_1 = memref.subview %14[%arg0, %25] [1, %23] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<1x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      linalg.matmul {__internal_linalg_transform__ = "workgroup_k_tiled", lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%subview_0, %subview_1 : memref<?x1xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, memref<1x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) outs(%subview : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>)
    }
    return
  }
}

// -----// IR Dump After HoistRedundantVectorTransfers (iree-codegen-hoist-redundant-vector-transfers) //----- //
func.func @main_dispatch_0_matmul_DxDxD_f32() {
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c32_i64 = arith.constant 32 : i64
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.interface.constant.load[0] : i32
  %1 = hal.interface.constant.load[1] : i32
  %2 = hal.interface.constant.load[2] : i32
  %3 = hal.interface.constant.load[3] : i32
  %4 = arith.extui %0 : i32 to i64
  %5 = arith.extui %1 : i32 to i64
  %6 = arith.shli %5, %c32_i64 : i64
  %7 = arith.ori %4, %6 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %2 : i32 to i64
  %10 = arith.extui %3 : i32 to i64
  %11 = arith.shli %10, %c32_i64 : i64
  %12 = arith.ori %9, %11 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>{%8, %13}
  memref.assume_alignment %14, 64 : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>
  %15 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>{%8, %13}
  memref.assume_alignment %15, 64 : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %16 = affine.min affine_map<()[s0, s1, s2] -> (32, s0 - (s1 floordiv (s2 ceildiv 128)) * 32)>()[%8, %workgroup_id_x, %13]
  %17 = affine.min affine_map<()[s0, s1] -> (128, s0 - (s1 mod (s0 ceildiv 128)) * 128)>()[%13, %workgroup_id_x]
  %18 = gpu.thread_id  x
  %19 = gpu.thread_id  y
  %20 = affine.min affine_map<()[s0, s1] -> (s0 - s1 * (s0 ceildiv 8), s0 ceildiv 8)>()[%16, %19]
  %21 = affine.max affine_map<()[s0] -> (0, s0)>()[%20]
  %22 = affine.min affine_map<()[s0, s1] -> (s0 - s1 * (s0 ceildiv 32), s0 ceildiv 32)>()[%17, %18]
  %23 = affine.max affine_map<()[s0] -> (0, s0)>()[%22]
  %24 = affine.apply affine_map<()[s0, s1, s2, s3] -> ((s0 floordiv (s1 ceildiv 128)) * 32 + s3 * (s2 ceildiv 8))>()[%workgroup_id_x, %13, %16, %19]
  %25 = affine.apply affine_map<()[s0, s1, s2, s3] -> ((s0 mod (s1 ceildiv 128)) * 128 + s3 * (s2 ceildiv 32))>()[%workgroup_id_x, %13, %17, %18]
  %subview = memref.subview %15[%24, %25] [%21, %23] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  linalg.fill {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%cst : f32) outs(%subview : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>)
  scf.for %arg0 = %c0 to %13 step %c1 {
    %subview_0 = memref.subview %14[%24, %arg0] [%21, 1] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x1xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %subview_1 = memref.subview %14[%arg0, %25] [1, %23] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<1x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    linalg.matmul {__internal_linalg_transform__ = "workgroup_k_tiled", lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%subview_0, %subview_1 : memref<?x1xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, memref<1x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) outs(%subview : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>)
  }
  return
}

// -----// IR Dump After LoopInvariantCodeMotion (loop-invariant-code-motion) //----- //
func.func @main_dispatch_0_matmul_DxDxD_f32() {
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c32_i64 = arith.constant 32 : i64
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.interface.constant.load[0] : i32
  %1 = hal.interface.constant.load[1] : i32
  %2 = hal.interface.constant.load[2] : i32
  %3 = hal.interface.constant.load[3] : i32
  %4 = arith.extui %0 : i32 to i64
  %5 = arith.extui %1 : i32 to i64
  %6 = arith.shli %5, %c32_i64 : i64
  %7 = arith.ori %4, %6 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %2 : i32 to i64
  %10 = arith.extui %3 : i32 to i64
  %11 = arith.shli %10, %c32_i64 : i64
  %12 = arith.ori %9, %11 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>{%8, %13}
  memref.assume_alignment %14, 64 : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>
  %15 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>{%8, %13}
  memref.assume_alignment %15, 64 : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %16 = affine.min affine_map<()[s0, s1, s2] -> (32, s0 - (s1 floordiv (s2 ceildiv 128)) * 32)>()[%8, %workgroup_id_x, %13]
  %17 = affine.min affine_map<()[s0, s1] -> (128, s0 - (s1 mod (s0 ceildiv 128)) * 128)>()[%13, %workgroup_id_x]
  %18 = gpu.thread_id  x
  %19 = gpu.thread_id  y
  %20 = affine.min affine_map<()[s0, s1] -> (s0 - s1 * (s0 ceildiv 8), s0 ceildiv 8)>()[%16, %19]
  %21 = affine.max affine_map<()[s0] -> (0, s0)>()[%20]
  %22 = affine.min affine_map<()[s0, s1] -> (s0 - s1 * (s0 ceildiv 32), s0 ceildiv 32)>()[%17, %18]
  %23 = affine.max affine_map<()[s0] -> (0, s0)>()[%22]
  %24 = affine.apply affine_map<()[s0, s1, s2, s3] -> ((s0 floordiv (s1 ceildiv 128)) * 32 + s3 * (s2 ceildiv 8))>()[%workgroup_id_x, %13, %16, %19]
  %25 = affine.apply affine_map<()[s0, s1, s2, s3] -> ((s0 mod (s1 ceildiv 128)) * 128 + s3 * (s2 ceildiv 32))>()[%workgroup_id_x, %13, %17, %18]
  %subview = memref.subview %15[%24, %25] [%21, %23] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  linalg.fill {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%cst : f32) outs(%subview : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>)
  scf.for %arg0 = %c0 to %13 step %c1 {
    %subview_0 = memref.subview %14[%24, %arg0] [%21, 1] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x1xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %subview_1 = memref.subview %14[%arg0, %25] [1, %23] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<1x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    linalg.matmul {__internal_linalg_transform__ = "workgroup_k_tiled", lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%subview_0, %subview_1 : memref<?x1xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, memref<1x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) outs(%subview : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>)
  }
  return
}

// -----// IR Dump After GPUPipelining (iree-codegen-gpu-pipelining) //----- //
func.func @main_dispatch_0_matmul_DxDxD_f32() {
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c32_i64 = arith.constant 32 : i64
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.interface.constant.load[0] : i32
  %1 = hal.interface.constant.load[1] : i32
  %2 = hal.interface.constant.load[2] : i32
  %3 = hal.interface.constant.load[3] : i32
  %4 = arith.extui %0 : i32 to i64
  %5 = arith.extui %1 : i32 to i64
  %6 = arith.shli %5, %c32_i64 : i64
  %7 = arith.ori %4, %6 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %2 : i32 to i64
  %10 = arith.extui %3 : i32 to i64
  %11 = arith.shli %10, %c32_i64 : i64
  %12 = arith.ori %9, %11 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>{%8, %13}
  memref.assume_alignment %14, 64 : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>
  %15 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>{%8, %13}
  memref.assume_alignment %15, 64 : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %16 = affine.min affine_map<()[s0, s1, s2] -> (32, s0 - (s1 floordiv (s2 ceildiv 128)) * 32)>()[%8, %workgroup_id_x, %13]
  %17 = affine.min affine_map<()[s0, s1] -> (128, s0 - (s1 mod (s0 ceildiv 128)) * 128)>()[%13, %workgroup_id_x]
  %18 = gpu.thread_id  x
  %19 = gpu.thread_id  y
  %20 = affine.min affine_map<()[s0, s1] -> (s0 - s1 * (s0 ceildiv 8), s0 ceildiv 8)>()[%16, %19]
  %21 = affine.max affine_map<()[s0] -> (0, s0)>()[%20]
  %22 = affine.min affine_map<()[s0, s1] -> (s0 - s1 * (s0 ceildiv 32), s0 ceildiv 32)>()[%17, %18]
  %23 = affine.max affine_map<()[s0] -> (0, s0)>()[%22]
  %24 = affine.apply affine_map<()[s0, s1, s2, s3] -> ((s0 floordiv (s1 ceildiv 128)) * 32 + s3 * (s2 ceildiv 8))>()[%workgroup_id_x, %13, %16, %19]
  %25 = affine.apply affine_map<()[s0, s1, s2, s3] -> ((s0 mod (s1 ceildiv 128)) * 128 + s3 * (s2 ceildiv 32))>()[%workgroup_id_x, %13, %17, %18]
  %subview = memref.subview %15[%24, %25] [%21, %23] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  linalg.fill {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%cst : f32) outs(%subview : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>)
  scf.for %arg0 = %c0 to %13 step %c1 {
    %subview_0 = memref.subview %14[%24, %arg0] [%21, 1] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x1xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %subview_1 = memref.subview %14[%arg0, %25] [1, %23] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<1x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    linalg.matmul {__internal_linalg_transform__ = "workgroup_k_tiled", lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%subview_0, %subview_1 : memref<?x1xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, memref<1x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) outs(%subview : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>)
  }
  return
}

// -----// IR Dump After LLVMGPULowerExecutableTarget (iree-llvmgpu-lower-executable-target) //----- //
hal.executable.variant public @cuda_nvptx_fb target(<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>) {
  hal.executable.export public @main_dispatch_0_matmul_DxDxD_f32 ordinal(0) layout(#hal.pipeline.layout<push_constants = 4, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer>]>]>) attributes {translation_info = #iree_codegen.translation_info<LLVMGPUMatmulSimt>, workgroup_size = [32 : index, 8 : index, 1 : index]} {
  ^bb0(%arg0: !hal.device, %arg1: index, %arg2: index):
    %c1 = arith.constant 1 : index
    %0 = affine.apply affine_map<()[s0, s1] -> ((s0 ceildiv 128) * (s1 ceildiv 32))>()[%arg2, %arg1]
    hal.return %0, %c1, %c1 : index, index, index
  }
  builtin.module {
    func.func @main_dispatch_0_matmul_DxDxD_f32() {
      %c0 = arith.constant 0 : index
      %c1 = arith.constant 1 : index
      %c32_i64 = arith.constant 32 : i64
      %cst = arith.constant 0.000000e+00 : f32
      %0 = hal.interface.constant.load[0] : i32
      %1 = hal.interface.constant.load[1] : i32
      %2 = hal.interface.constant.load[2] : i32
      %3 = hal.interface.constant.load[3] : i32
      %4 = arith.extui %0 : i32 to i64
      %5 = arith.extui %1 : i32 to i64
      %6 = arith.shli %5, %c32_i64 : i64
      %7 = arith.ori %4, %6 : i64
      %8 = arith.index_castui %7 : i64 to index
      %9 = arith.extui %2 : i32 to i64
      %10 = arith.extui %3 : i32 to i64
      %11 = arith.shli %10, %c32_i64 : i64
      %12 = arith.ori %9, %11 : i64
      %13 = arith.index_castui %12 : i64 to index
      %14 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>{%8, %13}
      memref.assume_alignment %14, 64 : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>
      %15 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>{%8, %13}
      memref.assume_alignment %15, 64 : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>
      %workgroup_id_x = hal.interface.workgroup.id[0] : index
      %16 = affine.min affine_map<()[s0, s1, s2] -> (32, s0 - (s1 floordiv (s2 ceildiv 128)) * 32)>()[%8, %workgroup_id_x, %13]
      %17 = affine.min affine_map<()[s0, s1] -> (128, s0 - (s1 mod (s0 ceildiv 128)) * 128)>()[%13, %workgroup_id_x]
      %18 = gpu.thread_id  x
      %19 = gpu.thread_id  y
      %20 = affine.min affine_map<()[s0, s1] -> (s0 - s1 * (s0 ceildiv 8), s0 ceildiv 8)>()[%16, %19]
      %21 = affine.max affine_map<()[s0] -> (0, s0)>()[%20]
      %22 = affine.min affine_map<()[s0, s1] -> (s0 - s1 * (s0 ceildiv 32), s0 ceildiv 32)>()[%17, %18]
      %23 = affine.max affine_map<()[s0] -> (0, s0)>()[%22]
      %24 = affine.apply affine_map<()[s0, s1, s2, s3] -> ((s0 floordiv (s1 ceildiv 128)) * 32 + s3 * (s2 ceildiv 8))>()[%workgroup_id_x, %13, %16, %19]
      %25 = affine.apply affine_map<()[s0, s1, s2, s3] -> ((s0 mod (s1 ceildiv 128)) * 128 + s3 * (s2 ceildiv 32))>()[%workgroup_id_x, %13, %17, %18]
      %subview = memref.subview %15[%24, %25] [%21, %23] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      linalg.fill {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%cst : f32) outs(%subview : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>)
      scf.for %arg0 = %c0 to %13 step %c1 {
        %subview_0 = memref.subview %14[%24, %arg0] [%21, 1] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x1xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
        %subview_1 = memref.subview %14[%arg0, %25] [1, %23] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<1x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
        linalg.matmul {__internal_linalg_transform__ = "workgroup_k_tiled", lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%subview_0, %subview_1 : memref<?x1xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, memref<1x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) outs(%subview : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>)
      }
      return
    }
  }
}

// -----// IR Dump After ConvertHALDescriptorTypeToGPUAddressSpace (iree-codegen-convert-hal-descriptor-type-to-gpu-address-space) //----- //
module {
  func.func @main_dispatch_0_matmul_DxDxD_f32() {
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c32_i64 = arith.constant 32 : i64
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.interface.constant.load[0] : i32
    %1 = hal.interface.constant.load[1] : i32
    %2 = hal.interface.constant.load[2] : i32
    %3 = hal.interface.constant.load[3] : i32
    %4 = arith.extui %0 : i32 to i64
    %5 = arith.extui %1 : i32 to i64
    %6 = arith.shli %5, %c32_i64 : i64
    %7 = arith.ori %4, %6 : i64
    %8 = arith.index_castui %7 : i64 to index
    %9 = arith.extui %2 : i32 to i64
    %10 = arith.extui %3 : i32 to i64
    %11 = arith.shli %10, %c32_i64 : i64
    %12 = arith.ori %9, %11 : i64
    %13 = arith.index_castui %12 : i64 to index
    %14 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32, #gpu.address_space<global>>{%8, %13}
    memref.assume_alignment %14, 64 : memref<?x?xf32, #gpu.address_space<global>>
    %15 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : memref<?x?xf32, #gpu.address_space<global>>{%8, %13}
    memref.assume_alignment %15, 64 : memref<?x?xf32, #gpu.address_space<global>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %16 = affine.min affine_map<()[s0, s1, s2] -> (32, s0 - (s1 floordiv (s2 ceildiv 128)) * 32)>()[%8, %workgroup_id_x, %13]
    %17 = affine.min affine_map<()[s0, s1] -> (128, s0 - (s1 mod (s0 ceildiv 128)) * 128)>()[%13, %workgroup_id_x]
    %18 = gpu.thread_id  x
    %19 = gpu.thread_id  y
    %20 = affine.min affine_map<()[s0, s1] -> (s0 - s1 * (s0 ceildiv 8), s0 ceildiv 8)>()[%16, %19]
    %21 = affine.max affine_map<()[s0] -> (0, s0)>()[%20]
    %22 = affine.min affine_map<()[s0, s1] -> (s0 - s1 * (s0 ceildiv 32), s0 ceildiv 32)>()[%17, %18]
    %23 = affine.max affine_map<()[s0] -> (0, s0)>()[%22]
    %24 = affine.apply affine_map<()[s0, s1, s2, s3] -> ((s0 floordiv (s1 ceildiv 128)) * 32 + s3 * (s2 ceildiv 8))>()[%workgroup_id_x, %13, %16, %19]
    %25 = affine.apply affine_map<()[s0, s1, s2, s3] -> ((s0 mod (s1 ceildiv 128)) * 128 + s3 * (s2 ceildiv 32))>()[%workgroup_id_x, %13, %17, %18]
    %subview = memref.subview %15[%24, %25] [%21, %23] [1, 1] : memref<?x?xf32, #gpu.address_space<global>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
    linalg.fill {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%cst : f32) outs(%subview : memref<?x?xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>)
    scf.for %arg0 = %c0 to %13 step %c1 {
      %subview_0 = memref.subview %14[%24, %arg0] [%21, 1] [1, 1] : memref<?x?xf32, #gpu.address_space<global>> to memref<?x1xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
      %subview_1 = memref.subview %14[%arg0, %25] [1, %23] [1, 1] : memref<?x?xf32, #gpu.address_space<global>> to memref<1x?xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
      linalg.matmul {__internal_linalg_transform__ = "workgroup_k_tiled", lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%subview_0, %subview_1 : memref<?x1xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>, memref<1x?xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>) outs(%subview : memref<?x?xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>)
    }
    return
  }
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
module {
  func.func @main_dispatch_0_matmul_DxDxD_f32() {
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c32_i64 = arith.constant 32 : i64
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.interface.constant.load[0] : i32
    %1 = hal.interface.constant.load[1] : i32
    %2 = hal.interface.constant.load[2] : i32
    %3 = hal.interface.constant.load[3] : i32
    %4 = arith.extui %0 : i32 to i64
    %5 = arith.extui %1 : i32 to i64
    %6 = arith.shli %5, %c32_i64 : i64
    %7 = arith.ori %4, %6 : i64
    %8 = arith.index_castui %7 : i64 to index
    %9 = arith.extui %2 : i32 to i64
    %10 = arith.extui %3 : i32 to i64
    %11 = arith.shli %10, %c32_i64 : i64
    %12 = arith.ori %9, %11 : i64
    %13 = arith.index_castui %12 : i64 to index
    %14 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32, #gpu.address_space<global>>{%8, %13}
    memref.assume_alignment %14, 64 : memref<?x?xf32, #gpu.address_space<global>>
    %15 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : memref<?x?xf32, #gpu.address_space<global>>{%8, %13}
    memref.assume_alignment %15, 64 : memref<?x?xf32, #gpu.address_space<global>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %16 = affine.min affine_map<()[s0, s1, s2] -> (32, s0 - (s1 floordiv (s2 ceildiv 128)) * 32)>()[%8, %workgroup_id_x, %13]
    %17 = affine.min affine_map<()[s0, s1] -> (128, s0 - (s1 mod (s0 ceildiv 128)) * 128)>()[%13, %workgroup_id_x]
    %18 = gpu.thread_id  x
    %19 = gpu.thread_id  y
    %20 = affine.min affine_map<()[s0, s1] -> (s0 - s1 * (s0 ceildiv 8), s0 ceildiv 8)>()[%16, %19]
    %21 = affine.max affine_map<()[s0] -> (0, s0)>()[%20]
    %22 = affine.min affine_map<()[s0, s1] -> (s0 - s1 * (s0 ceildiv 32), s0 ceildiv 32)>()[%17, %18]
    %23 = affine.max affine_map<()[s0] -> (0, s0)>()[%22]
    %24 = affine.apply affine_map<()[s0, s1, s2, s3] -> ((s0 floordiv (s1 ceildiv 128)) * 32 + s3 * (s2 ceildiv 8))>()[%workgroup_id_x, %13, %16, %19]
    %25 = affine.apply affine_map<()[s0, s1, s2, s3] -> ((s0 mod (s1 ceildiv 128)) * 128 + s3 * (s2 ceildiv 32))>()[%workgroup_id_x, %13, %17, %18]
    %subview = memref.subview %15[%24, %25] [%21, %23] [1, 1] : memref<?x?xf32, #gpu.address_space<global>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
    linalg.fill {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%cst : f32) outs(%subview : memref<?x?xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>)
    scf.for %arg0 = %c0 to %13 step %c1 {
      %subview_0 = memref.subview %14[%24, %arg0] [%21, 1] [1, 1] : memref<?x?xf32, #gpu.address_space<global>> to memref<?x1xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
      %subview_1 = memref.subview %14[%arg0, %25] [1, %23] [1, 1] : memref<?x?xf32, #gpu.address_space<global>> to memref<1x?xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
      linalg.matmul {__internal_linalg_transform__ = "workgroup_k_tiled", lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%subview_0, %subview_1 : memref<?x1xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>, memref<1x?xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>) outs(%subview : memref<?x?xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>)
    }
    return
  }
}

// -----// IR Dump After CSE (cse) //----- //
module {
  func.func @main_dispatch_0_matmul_DxDxD_f32() {
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c32_i64 = arith.constant 32 : i64
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.interface.constant.load[0] : i32
    %1 = hal.interface.constant.load[1] : i32
    %2 = hal.interface.constant.load[2] : i32
    %3 = hal.interface.constant.load[3] : i32
    %4 = arith.extui %0 : i32 to i64
    %5 = arith.extui %1 : i32 to i64
    %6 = arith.shli %5, %c32_i64 : i64
    %7 = arith.ori %4, %6 : i64
    %8 = arith.index_castui %7 : i64 to index
    %9 = arith.extui %2 : i32 to i64
    %10 = arith.extui %3 : i32 to i64
    %11 = arith.shli %10, %c32_i64 : i64
    %12 = arith.ori %9, %11 : i64
    %13 = arith.index_castui %12 : i64 to index
    %14 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32, #gpu.address_space<global>>{%8, %13}
    memref.assume_alignment %14, 64 : memref<?x?xf32, #gpu.address_space<global>>
    %15 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : memref<?x?xf32, #gpu.address_space<global>>{%8, %13}
    memref.assume_alignment %15, 64 : memref<?x?xf32, #gpu.address_space<global>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %16 = affine.min affine_map<()[s0, s1, s2] -> (32, s0 - (s1 floordiv (s2 ceildiv 128)) * 32)>()[%8, %workgroup_id_x, %13]
    %17 = affine.min affine_map<()[s0, s1] -> (128, s0 - (s1 mod (s0 ceildiv 128)) * 128)>()[%13, %workgroup_id_x]
    %18 = gpu.thread_id  x
    %19 = gpu.thread_id  y
    %20 = affine.min affine_map<()[s0, s1] -> (s0 - s1 * (s0 ceildiv 8), s0 ceildiv 8)>()[%16, %19]
    %21 = affine.max affine_map<()[s0] -> (0, s0)>()[%20]
    %22 = affine.min affine_map<()[s0, s1] -> (s0 - s1 * (s0 ceildiv 32), s0 ceildiv 32)>()[%17, %18]
    %23 = affine.max affine_map<()[s0] -> (0, s0)>()[%22]
    %24 = affine.apply affine_map<()[s0, s1, s2, s3] -> ((s0 floordiv (s1 ceildiv 128)) * 32 + s3 * (s2 ceildiv 8))>()[%workgroup_id_x, %13, %16, %19]
    %25 = affine.apply affine_map<()[s0, s1, s2, s3] -> ((s0 mod (s1 ceildiv 128)) * 128 + s3 * (s2 ceildiv 32))>()[%workgroup_id_x, %13, %17, %18]
    %subview = memref.subview %15[%24, %25] [%21, %23] [1, 1] : memref<?x?xf32, #gpu.address_space<global>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
    linalg.fill {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%cst : f32) outs(%subview : memref<?x?xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>)
    scf.for %arg0 = %c0 to %13 step %c1 {
      %subview_0 = memref.subview %14[%24, %arg0] [%21, 1] [1, 1] : memref<?x?xf32, #gpu.address_space<global>> to memref<?x1xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
      %subview_1 = memref.subview %14[%arg0, %25] [1, %23] [1, 1] : memref<?x?xf32, #gpu.address_space<global>> to memref<1x?xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
      linalg.matmul {__internal_linalg_transform__ = "workgroup_k_tiled", lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%subview_0, %subview_1 : memref<?x1xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>, memref<1x?xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>) outs(%subview : memref<?x?xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>)
    }
    return
  }
}

// -----// IR Dump After LowerUKernelOpsToCalls (iree-codegen-lower-ukernel-ops-to-calls) //----- //
module {
  func.func @main_dispatch_0_matmul_DxDxD_f32() {
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c32_i64 = arith.constant 32 : i64
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.interface.constant.load[0] : i32
    %1 = hal.interface.constant.load[1] : i32
    %2 = hal.interface.constant.load[2] : i32
    %3 = hal.interface.constant.load[3] : i32
    %4 = arith.extui %0 : i32 to i64
    %5 = arith.extui %1 : i32 to i64
    %6 = arith.shli %5, %c32_i64 : i64
    %7 = arith.ori %4, %6 : i64
    %8 = arith.index_castui %7 : i64 to index
    %9 = arith.extui %2 : i32 to i64
    %10 = arith.extui %3 : i32 to i64
    %11 = arith.shli %10, %c32_i64 : i64
    %12 = arith.ori %9, %11 : i64
    %13 = arith.index_castui %12 : i64 to index
    %14 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32, #gpu.address_space<global>>{%8, %13}
    memref.assume_alignment %14, 64 : memref<?x?xf32, #gpu.address_space<global>>
    %15 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : memref<?x?xf32, #gpu.address_space<global>>{%8, %13}
    memref.assume_alignment %15, 64 : memref<?x?xf32, #gpu.address_space<global>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %16 = affine.min affine_map<()[s0, s1, s2] -> (32, s0 - (s1 floordiv (s2 ceildiv 128)) * 32)>()[%8, %workgroup_id_x, %13]
    %17 = affine.min affine_map<()[s0, s1] -> (128, s0 - (s1 mod (s0 ceildiv 128)) * 128)>()[%13, %workgroup_id_x]
    %18 = gpu.thread_id  x
    %19 = gpu.thread_id  y
    %20 = affine.min affine_map<()[s0, s1] -> (s0 - s1 * (s0 ceildiv 8), s0 ceildiv 8)>()[%16, %19]
    %21 = affine.max affine_map<()[s0] -> (0, s0)>()[%20]
    %22 = affine.min affine_map<()[s0, s1] -> (s0 - s1 * (s0 ceildiv 32), s0 ceildiv 32)>()[%17, %18]
    %23 = affine.max affine_map<()[s0] -> (0, s0)>()[%22]
    %24 = affine.apply affine_map<()[s0, s1, s2, s3] -> ((s0 floordiv (s1 ceildiv 128)) * 32 + s3 * (s2 ceildiv 8))>()[%workgroup_id_x, %13, %16, %19]
    %25 = affine.apply affine_map<()[s0, s1, s2, s3] -> ((s0 mod (s1 ceildiv 128)) * 128 + s3 * (s2 ceildiv 32))>()[%workgroup_id_x, %13, %17, %18]
    %subview = memref.subview %15[%24, %25] [%21, %23] [1, 1] : memref<?x?xf32, #gpu.address_space<global>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
    linalg.fill {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%cst : f32) outs(%subview : memref<?x?xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>)
    scf.for %arg0 = %c0 to %13 step %c1 {
      %subview_0 = memref.subview %14[%24, %arg0] [%21, 1] [1, 1] : memref<?x?xf32, #gpu.address_space<global>> to memref<?x1xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
      %subview_1 = memref.subview %14[%arg0, %25] [1, %23] [1, 1] : memref<?x?xf32, #gpu.address_space<global>> to memref<1x?xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
      linalg.matmul {__internal_linalg_transform__ = "workgroup_k_tiled", lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%subview_0, %subview_1 : memref<?x1xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>, memref<1x?xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>) outs(%subview : memref<?x?xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>)
    }
    return
  }
}

// -----// IR Dump After LinalgExtToLoops (iree-linalg-ext-to-loops) //----- //
func.func @main_dispatch_0_matmul_DxDxD_f32() {
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c32_i64 = arith.constant 32 : i64
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.interface.constant.load[0] : i32
  %1 = hal.interface.constant.load[1] : i32
  %2 = hal.interface.constant.load[2] : i32
  %3 = hal.interface.constant.load[3] : i32
  %4 = arith.extui %0 : i32 to i64
  %5 = arith.extui %1 : i32 to i64
  %6 = arith.shli %5, %c32_i64 : i64
  %7 = arith.ori %4, %6 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %2 : i32 to i64
  %10 = arith.extui %3 : i32 to i64
  %11 = arith.shli %10, %c32_i64 : i64
  %12 = arith.ori %9, %11 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32, #gpu.address_space<global>>{%8, %13}
  memref.assume_alignment %14, 64 : memref<?x?xf32, #gpu.address_space<global>>
  %15 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : memref<?x?xf32, #gpu.address_space<global>>{%8, %13}
  memref.assume_alignment %15, 64 : memref<?x?xf32, #gpu.address_space<global>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %16 = affine.min affine_map<()[s0, s1, s2] -> (32, s0 - (s1 floordiv (s2 ceildiv 128)) * 32)>()[%8, %workgroup_id_x, %13]
  %17 = affine.min affine_map<()[s0, s1] -> (128, s0 - (s1 mod (s0 ceildiv 128)) * 128)>()[%13, %workgroup_id_x]
  %18 = gpu.thread_id  x
  %19 = gpu.thread_id  y
  %20 = affine.min affine_map<()[s0, s1] -> (s0 - s1 * (s0 ceildiv 8), s0 ceildiv 8)>()[%16, %19]
  %21 = affine.max affine_map<()[s0] -> (0, s0)>()[%20]
  %22 = affine.min affine_map<()[s0, s1] -> (s0 - s1 * (s0 ceildiv 32), s0 ceildiv 32)>()[%17, %18]
  %23 = affine.max affine_map<()[s0] -> (0, s0)>()[%22]
  %24 = affine.apply affine_map<()[s0, s1, s2, s3] -> ((s0 floordiv (s1 ceildiv 128)) * 32 + s3 * (s2 ceildiv 8))>()[%workgroup_id_x, %13, %16, %19]
  %25 = affine.apply affine_map<()[s0, s1, s2, s3] -> ((s0 mod (s1 ceildiv 128)) * 128 + s3 * (s2 ceildiv 32))>()[%workgroup_id_x, %13, %17, %18]
  %subview = memref.subview %15[%24, %25] [%21, %23] [1, 1] : memref<?x?xf32, #gpu.address_space<global>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
  linalg.fill {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%cst : f32) outs(%subview : memref<?x?xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>)
  scf.for %arg0 = %c0 to %13 step %c1 {
    %subview_0 = memref.subview %14[%24, %arg0] [%21, 1] [1, 1] : memref<?x?xf32, #gpu.address_space<global>> to memref<?x1xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
    %subview_1 = memref.subview %14[%arg0, %25] [1, %23] [1, 1] : memref<?x?xf32, #gpu.address_space<global>> to memref<1x?xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
    linalg.matmul {__internal_linalg_transform__ = "workgroup_k_tiled", lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%subview_0, %subview_1 : memref<?x1xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>, memref<1x?xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>) outs(%subview : memref<?x?xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>)
  }
  return
}

// -----// IR Dump After MemrefCopyToLinalgPass (iree-codegen-memrefcopy-to-linalg) //----- //
func.func @main_dispatch_0_matmul_DxDxD_f32() {
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c32_i64 = arith.constant 32 : i64
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.interface.constant.load[0] : i32
  %1 = hal.interface.constant.load[1] : i32
  %2 = hal.interface.constant.load[2] : i32
  %3 = hal.interface.constant.load[3] : i32
  %4 = arith.extui %0 : i32 to i64
  %5 = arith.extui %1 : i32 to i64
  %6 = arith.shli %5, %c32_i64 : i64
  %7 = arith.ori %4, %6 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %2 : i32 to i64
  %10 = arith.extui %3 : i32 to i64
  %11 = arith.shli %10, %c32_i64 : i64
  %12 = arith.ori %9, %11 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32, #gpu.address_space<global>>{%8, %13}
  memref.assume_alignment %14, 64 : memref<?x?xf32, #gpu.address_space<global>>
  %15 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : memref<?x?xf32, #gpu.address_space<global>>{%8, %13}
  memref.assume_alignment %15, 64 : memref<?x?xf32, #gpu.address_space<global>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %16 = affine.min affine_map<()[s0, s1, s2] -> (32, s0 - (s1 floordiv (s2 ceildiv 128)) * 32)>()[%8, %workgroup_id_x, %13]
  %17 = affine.min affine_map<()[s0, s1] -> (128, s0 - (s1 mod (s0 ceildiv 128)) * 128)>()[%13, %workgroup_id_x]
  %18 = gpu.thread_id  x
  %19 = gpu.thread_id  y
  %20 = affine.min affine_map<()[s0, s1] -> (s0 - s1 * (s0 ceildiv 8), s0 ceildiv 8)>()[%16, %19]
  %21 = affine.max affine_map<()[s0] -> (0, s0)>()[%20]
  %22 = affine.min affine_map<()[s0, s1] -> (s0 - s1 * (s0 ceildiv 32), s0 ceildiv 32)>()[%17, %18]
  %23 = affine.max affine_map<()[s0] -> (0, s0)>()[%22]
  %24 = affine.apply affine_map<()[s0, s1, s2, s3] -> ((s0 floordiv (s1 ceildiv 128)) * 32 + s3 * (s2 ceildiv 8))>()[%workgroup_id_x, %13, %16, %19]
  %25 = affine.apply affine_map<()[s0, s1, s2, s3] -> ((s0 mod (s1 ceildiv 128)) * 128 + s3 * (s2 ceildiv 32))>()[%workgroup_id_x, %13, %17, %18]
  %subview = memref.subview %15[%24, %25] [%21, %23] [1, 1] : memref<?x?xf32, #gpu.address_space<global>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
  linalg.fill {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%cst : f32) outs(%subview : memref<?x?xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>)
  scf.for %arg0 = %c0 to %13 step %c1 {
    %subview_0 = memref.subview %14[%24, %arg0] [%21, 1] [1, 1] : memref<?x?xf32, #gpu.address_space<global>> to memref<?x1xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
    %subview_1 = memref.subview %14[%arg0, %25] [1, %23] [1, 1] : memref<?x?xf32, #gpu.address_space<global>> to memref<1x?xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
    linalg.matmul {__internal_linalg_transform__ = "workgroup_k_tiled", lowering_config = #iree_codegen.lowering_config<tile_sizes = [[32, 128, 1]]>} ins(%subview_0, %subview_1 : memref<?x1xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>, memref<1x?xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>) outs(%subview : memref<?x?xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>)
  }
  return
}

// -----// IR Dump After LinalgLowerToLoops (convert-linalg-to-loops) //----- //
func.func @main_dispatch_0_matmul_DxDxD_f32() {
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c32_i64 = arith.constant 32 : i64
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.interface.constant.load[0] : i32
  %1 = hal.interface.constant.load[1] : i32
  %2 = hal.interface.constant.load[2] : i32
  %3 = hal.interface.constant.load[3] : i32
  %4 = arith.extui %0 : i32 to i64
  %5 = arith.extui %1 : i32 to i64
  %6 = arith.shli %5, %c32_i64 : i64
  %7 = arith.ori %4, %6 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %2 : i32 to i64
  %10 = arith.extui %3 : i32 to i64
  %11 = arith.shli %10, %c32_i64 : i64
  %12 = arith.ori %9, %11 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32, #gpu.address_space<global>>{%8, %13}
  memref.assume_alignment %14, 64 : memref<?x?xf32, #gpu.address_space<global>>
  %15 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : memref<?x?xf32, #gpu.address_space<global>>{%8, %13}
  memref.assume_alignment %15, 64 : memref<?x?xf32, #gpu.address_space<global>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %16 = affine.min affine_map<()[s0, s1, s2] -> (32, s0 - (s1 floordiv (s2 ceildiv 128)) * 32)>()[%8, %workgroup_id_x, %13]
  %17 = affine.min affine_map<()[s0, s1] -> (128, s0 - (s1 mod (s0 ceildiv 128)) * 128)>()[%13, %workgroup_id_x]
  %18 = gpu.thread_id  x
  %19 = gpu.thread_id  y
  %20 = affine.min affine_map<()[s0, s1] -> (s0 - s1 * (s0 ceildiv 8), s0 ceildiv 8)>()[%16, %19]
  %21 = affine.max affine_map<()[s0] -> (0, s0)>()[%20]
  %22 = affine.min affine_map<()[s0, s1] -> (s0 - s1 * (s0 ceildiv 32), s0 ceildiv 32)>()[%17, %18]
  %23 = affine.max affine_map<()[s0] -> (0, s0)>()[%22]
  %24 = affine.apply affine_map<()[s0, s1, s2, s3] -> ((s0 floordiv (s1 ceildiv 128)) * 32 + s3 * (s2 ceildiv 8))>()[%workgroup_id_x, %13, %16, %19]
  %25 = affine.apply affine_map<()[s0, s1, s2, s3] -> ((s0 mod (s1 ceildiv 128)) * 128 + s3 * (s2 ceildiv 32))>()[%workgroup_id_x, %13, %17, %18]
  %subview = memref.subview %15[%24, %25] [%21, %23] [1, 1] : memref<?x?xf32, #gpu.address_space<global>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
  scf.for %arg0 = %c0 to %21 step %c1 {
    scf.for %arg1 = %c0 to %23 step %c1 {
      memref.store %cst, %subview[%arg0, %arg1] : memref<?x?xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
    }
  }
  scf.for %arg0 = %c0 to %13 step %c1 {
    %subview_0 = memref.subview %14[%24, %arg0] [%21, 1] [1, 1] : memref<?x?xf32, #gpu.address_space<global>> to memref<?x1xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
    %subview_1 = memref.subview %14[%arg0, %25] [1, %23] [1, 1] : memref<?x?xf32, #gpu.address_space<global>> to memref<1x?xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
    scf.for %arg1 = %c0 to %21 step %c1 {
      scf.for %arg2 = %c0 to %23 step %c1 {
        scf.for %arg3 = %c0 to %c1 step %c1 {
          %26 = memref.load %subview_0[%arg1, %arg3] : memref<?x1xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
          %27 = memref.load %subview_1[%arg3, %arg2] : memref<1x?xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
          %28 = memref.load %subview[%arg1, %arg2] : memref<?x?xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
          %29 = arith.mulf %26, %27 : f32
          %30 = arith.addf %28, %29 : f32
          memref.store %30, %subview[%arg1, %arg2] : memref<?x?xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
        }
      }
    }
  }
  return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main_dispatch_0_matmul_DxDxD_f32() {
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c32_i64 = arith.constant 32 : i64
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.interface.constant.load[0] : i32
  %1 = hal.interface.constant.load[1] : i32
  %2 = hal.interface.constant.load[2] : i32
  %3 = hal.interface.constant.load[3] : i32
  %4 = arith.extui %0 : i32 to i64
  %5 = arith.extui %1 : i32 to i64
  %6 = arith.shli %5, %c32_i64 : i64
  %7 = arith.ori %4, %6 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %2 : i32 to i64
  %10 = arith.extui %3 : i32 to i64
  %11 = arith.shli %10, %c32_i64 : i64
  %12 = arith.ori %9, %11 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32, #gpu.address_space<global>>{%8, %13}
  memref.assume_alignment %14, 64 : memref<?x?xf32, #gpu.address_space<global>>
  %15 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : memref<?x?xf32, #gpu.address_space<global>>{%8, %13}
  memref.assume_alignment %15, 64 : memref<?x?xf32, #gpu.address_space<global>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %16 = affine.min affine_map<()[s0, s1, s2] -> (32, s0 - (s1 floordiv (s2 ceildiv 128)) * 32)>()[%8, %workgroup_id_x, %13]
  %17 = affine.min affine_map<()[s0, s1] -> (128, s0 - (s1 mod (s0 ceildiv 128)) * 128)>()[%13, %workgroup_id_x]
  %18 = gpu.thread_id  x
  %19 = gpu.thread_id  y
  %20 = affine.min affine_map<()[s0, s1] -> (s0 - s1 * (s0 ceildiv 8), s0 ceildiv 8)>()[%16, %19]
  %21 = affine.max affine_map<()[s0] -> (0, s0)>()[%20]
  %22 = affine.min affine_map<()[s0, s1] -> (s0 - s1 * (s0 ceildiv 32), s0 ceildiv 32)>()[%17, %18]
  %23 = affine.max affine_map<()[s0] -> (0, s0)>()[%22]
  %24 = affine.apply affine_map<()[s0, s1, s2, s3] -> ((s0 floordiv (s1 ceildiv 128)) * 32 + s3 * (s2 ceildiv 8))>()[%workgroup_id_x, %13, %16, %19]
  %25 = affine.apply affine_map<()[s0, s1, s2, s3] -> ((s0 mod (s1 ceildiv 128)) * 128 + s3 * (s2 ceildiv 32))>()[%workgroup_id_x, %13, %17, %18]
  %subview = memref.subview %15[%24, %25] [%21, %23] [1, 1] : memref<?x?xf32, #gpu.address_space<global>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
  scf.for %arg0 = %c0 to %21 step %c1 {
    scf.for %arg1 = %c0 to %23 step %c1 {
      memref.store %cst, %subview[%arg0, %arg1] : memref<?x?xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
    }
  }
  scf.for %arg0 = %c0 to %13 step %c1 {
    %subview_0 = memref.subview %14[%24, %arg0] [%21, 1] [1, 1] : memref<?x?xf32, #gpu.address_space<global>> to memref<?x1xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
    %subview_1 = memref.subview %14[%arg0, %25] [1, %23] [1, 1] : memref<?x?xf32, #gpu.address_space<global>> to memref<1x?xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
    scf.for %arg1 = %c0 to %21 step %c1 {
      scf.for %arg2 = %c0 to %23 step %c1 {
        %26 = memref.load %subview_0[%arg1, %c0] : memref<?x1xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
        %27 = memref.load %subview_1[%c0, %arg2] : memref<1x?xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
        %28 = memref.load %subview[%arg1, %arg2] : memref<?x?xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
        %29 = arith.mulf %26, %27 : f32
        %30 = arith.addf %28, %29 : f32
        memref.store %30, %subview[%arg1, %arg2] : memref<?x?xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
      }
    }
  }
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @main_dispatch_0_matmul_DxDxD_f32() {
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c32_i64 = arith.constant 32 : i64
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.interface.constant.load[0] : i32
  %1 = hal.interface.constant.load[1] : i32
  %2 = hal.interface.constant.load[2] : i32
  %3 = hal.interface.constant.load[3] : i32
  %4 = arith.extui %0 : i32 to i64
  %5 = arith.extui %1 : i32 to i64
  %6 = arith.shli %5, %c32_i64 : i64
  %7 = arith.ori %4, %6 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %2 : i32 to i64
  %10 = arith.extui %3 : i32 to i64
  %11 = arith.shli %10, %c32_i64 : i64
  %12 = arith.ori %9, %11 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32, #gpu.address_space<global>>{%8, %13}
  memref.assume_alignment %14, 64 : memref<?x?xf32, #gpu.address_space<global>>
  %15 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : memref<?x?xf32, #gpu.address_space<global>>{%8, %13}
  memref.assume_alignment %15, 64 : memref<?x?xf32, #gpu.address_space<global>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %16 = affine.min affine_map<()[s0, s1, s2] -> (32, s0 - (s1 floordiv (s2 ceildiv 128)) * 32)>()[%8, %workgroup_id_x, %13]
  %17 = affine.min affine_map<()[s0, s1] -> (128, s0 - (s1 mod (s0 ceildiv 128)) * 128)>()[%13, %workgroup_id_x]
  %18 = gpu.thread_id  x
  %19 = gpu.thread_id  y
  %20 = affine.min affine_map<()[s0, s1] -> (s0 - s1 * (s0 ceildiv 8), s0 ceildiv 8)>()[%16, %19]
  %21 = affine.max affine_map<()[s0] -> (0, s0)>()[%20]
  %22 = affine.min affine_map<()[s0, s1] -> (s0 - s1 * (s0 ceildiv 32), s0 ceildiv 32)>()[%17, %18]
  %23 = affine.max affine_map<()[s0] -> (0, s0)>()[%22]
  %24 = affine.apply affine_map<()[s0, s1, s2, s3] -> ((s0 floordiv (s1 ceildiv 128)) * 32 + s3 * (s2 ceildiv 8))>()[%workgroup_id_x, %13, %16, %19]
  %25 = affine.apply affine_map<()[s0, s1, s2, s3] -> ((s0 mod (s1 ceildiv 128)) * 128 + s3 * (s2 ceildiv 32))>()[%workgroup_id_x, %13, %17, %18]
  %subview = memref.subview %15[%24, %25] [%21, %23] [1, 1] : memref<?x?xf32, #gpu.address_space<global>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
  scf.for %arg0 = %c0 to %21 step %c1 {
    scf.for %arg1 = %c0 to %23 step %c1 {
      memref.store %cst, %subview[%arg0, %arg1] : memref<?x?xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
    }
  }
  scf.for %arg0 = %c0 to %13 step %c1 {
    %subview_0 = memref.subview %14[%24, %arg0] [%21, 1] [1, 1] : memref<?x?xf32, #gpu.address_space<global>> to memref<?x1xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
    %subview_1 = memref.subview %14[%arg0, %25] [1, %23] [1, 1] : memref<?x?xf32, #gpu.address_space<global>> to memref<1x?xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
    scf.for %arg1 = %c0 to %21 step %c1 {
      scf.for %arg2 = %c0 to %23 step %c1 {
        %26 = memref.load %subview_0[%arg1, %c0] : memref<?x1xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
        %27 = memref.load %subview_1[%c0, %arg2] : memref<1x?xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
        %28 = memref.load %subview[%arg1, %arg2] : memref<?x?xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
        %29 = arith.mulf %26, %27 : f32
        %30 = arith.addf %28, %29 : f32
        memref.store %30, %subview[%arg1, %arg2] : memref<?x?xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
      }
    }
  }
  return
}

// -----// IR Dump After PadDynamicAlloc (iree-codegen-pad-dynamic-alloc) //----- //
func.func @main_dispatch_0_matmul_DxDxD_f32() {
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c32_i64 = arith.constant 32 : i64
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.interface.constant.load[0] : i32
  %1 = hal.interface.constant.load[1] : i32
  %2 = hal.interface.constant.load[2] : i32
  %3 = hal.interface.constant.load[3] : i32
  %4 = arith.extui %0 : i32 to i64
  %5 = arith.extui %1 : i32 to i64
  %6 = arith.shli %5, %c32_i64 : i64
  %7 = arith.ori %4, %6 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %2 : i32 to i64
  %10 = arith.extui %3 : i32 to i64
  %11 = arith.shli %10, %c32_i64 : i64
  %12 = arith.ori %9, %11 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32, #gpu.address_space<global>>{%8, %13}
  memref.assume_alignment %14, 64 : memref<?x?xf32, #gpu.address_space<global>>
  %15 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : memref<?x?xf32, #gpu.address_space<global>>{%8, %13}
  memref.assume_alignment %15, 64 : memref<?x?xf32, #gpu.address_space<global>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %16 = affine.min affine_map<()[s0, s1, s2] -> (32, s0 - (s1 floordiv (s2 ceildiv 128)) * 32)>()[%8, %workgroup_id_x, %13]
  %17 = affine.min affine_map<()[s0, s1] -> (128, s0 - (s1 mod (s0 ceildiv 128)) * 128)>()[%13, %workgroup_id_x]
  %18 = gpu.thread_id  x
  %19 = gpu.thread_id  y
  %20 = affine.min affine_map<()[s0, s1] -> (s0 - s1 * (s0 ceildiv 8), s0 ceildiv 8)>()[%16, %19]
  %21 = affine.max affine_map<()[s0] -> (0, s0)>()[%20]
  %22 = affine.min affine_map<()[s0, s1] -> (s0 - s1 * (s0 ceildiv 32), s0 ceildiv 32)>()[%17, %18]
  %23 = affine.max affine_map<()[s0] -> (0, s0)>()[%22]
  %24 = affine.apply affine_map<()[s0, s1, s2, s3] -> ((s0 floordiv (s1 ceildiv 128)) * 32 + s3 * (s2 ceildiv 8))>()[%workgroup_id_x, %13, %16, %19]
  %25 = affine.apply affine_map<()[s0, s1, s2, s3] -> ((s0 mod (s1 ceildiv 128)) * 128 + s3 * (s2 ceildiv 32))>()[%workgroup_id_x, %13, %17, %18]
  %subview = memref.subview %15[%24, %25] [%21, %23] [1, 1] : memref<?x?xf32, #gpu.address_space<global>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
  scf.for %arg0 = %c0 to %21 step %c1 {
    scf.for %arg1 = %c0 to %23 step %c1 {
      memref.store %cst, %subview[%arg0, %arg1] : memref<?x?xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
    }
  }
  scf.for %arg0 = %c0 to %13 step %c1 {
    %subview_0 = memref.subview %14[%24, %arg0] [%21, 1] [1, 1] : memref<?x?xf32, #gpu.address_space<global>> to memref<?x1xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
    %subview_1 = memref.subview %14[%arg0, %25] [1, %23] [1, 1] : memref<?x?xf32, #gpu.address_space<global>> to memref<1x?xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
    scf.for %arg1 = %c0 to %21 step %c1 {
      scf.for %arg2 = %c0 to %23 step %c1 {
        %26 = memref.load %subview_0[%arg1, %c0] : memref<?x1xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
        %27 = memref.load %subview_1[%c0, %arg2] : memref<1x?xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
        %28 = memref.load %subview[%arg1, %arg2] : memref<?x?xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
        %29 = arith.mulf %26, %27 : f32
        %30 = arith.addf %28, %29 : f32
        memref.store %30, %subview[%arg1, %arg2] : memref<?x?xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
      }
    }
  }
  return
}

// -----// IR Dump After ConvertAffineToStandard (lower-affine) //----- //
module {
  func.func @main_dispatch_0_matmul_DxDxD_f32() {
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c32_i64 = arith.constant 32 : i64
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.interface.constant.load[0] : i32
    %1 = hal.interface.constant.load[1] : i32
    %2 = hal.interface.constant.load[2] : i32
    %3 = hal.interface.constant.load[3] : i32
    %4 = arith.extui %0 : i32 to i64
    %5 = arith.extui %1 : i32 to i64
    %6 = arith.shli %5, %c32_i64 : i64
    %7 = arith.ori %4, %6 : i64
    %8 = arith.index_castui %7 : i64 to index
    %9 = arith.extui %2 : i32 to i64
    %10 = arith.extui %3 : i32 to i64
    %11 = arith.shli %10, %c32_i64 : i64
    %12 = arith.ori %9, %11 : i64
    %13 = arith.index_castui %12 : i64 to index
    %14 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32, #gpu.address_space<global>>{%8, %13}
    memref.assume_alignment %14, 64 : memref<?x?xf32, #gpu.address_space<global>>
    %15 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : memref<?x?xf32, #gpu.address_space<global>>{%8, %13}
    memref.assume_alignment %15, 64 : memref<?x?xf32, #gpu.address_space<global>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %c32 = arith.constant 32 : index
    %c128 = arith.constant 128 : index
    %c0_0 = arith.constant 0 : index
    %c1_1 = arith.constant 1 : index
    %16 = arith.cmpi sle, %13, %c0_0 : index
    %17 = arith.subi %c0_0, %13 : index
    %18 = arith.subi %13, %c1_1 : index
    %19 = arith.select %16, %17, %18 : index
    %20 = arith.divsi %19, %c128 : index
    %21 = arith.subi %c0_0, %20 : index
    %22 = arith.addi %20, %c1_1 : index
    %23 = arith.select %16, %21, %22 : index
    %c0_2 = arith.constant 0 : index
    %c-1 = arith.constant -1 : index
    %24 = arith.cmpi slt, %workgroup_id_x, %c0_2 : index
    %25 = arith.subi %c-1, %workgroup_id_x : index
    %26 = arith.select %24, %25, %workgroup_id_x : index
    %27 = arith.divsi %26, %23 : index
    %28 = arith.subi %c-1, %27 : index
    %29 = arith.select %24, %28, %27 : index
    %c-32 = arith.constant -32 : index
    %30 = arith.muli %29, %c-32 : index
    %31 = arith.addi %8, %30 : index
    %32 = arith.cmpi slt, %c32, %31 : index
    %33 = arith.select %32, %c32, %31 : index
    %c128_3 = arith.constant 128 : index
    %c128_4 = arith.constant 128 : index
    %c0_5 = arith.constant 0 : index
    %c1_6 = arith.constant 1 : index
    %34 = arith.cmpi sle, %13, %c0_5 : index
    %35 = arith.subi %c0_5, %13 : index
    %36 = arith.subi %13, %c1_6 : index
    %37 = arith.select %34, %35, %36 : index
    %38 = arith.divsi %37, %c128_4 : index
    %39 = arith.subi %c0_5, %38 : index
    %40 = arith.addi %38, %c1_6 : index
    %41 = arith.select %34, %39, %40 : index
    %42 = arith.remsi %workgroup_id_x, %41 : index
    %c0_7 = arith.constant 0 : index
    %43 = arith.cmpi slt, %42, %c0_7 : index
    %44 = arith.addi %42, %41 : index
    %45 = arith.select %43, %44, %42 : index
    %c-128 = arith.constant -128 : index
    %46 = arith.muli %45, %c-128 : index
    %47 = arith.addi %13, %46 : index
    %48 = arith.cmpi slt, %c128_3, %47 : index
    %49 = arith.select %48, %c128_3, %47 : index
    %50 = gpu.thread_id  x
    %51 = gpu.thread_id  y
    %c8 = arith.constant 8 : index
    %c0_8 = arith.constant 0 : index
    %c1_9 = arith.constant 1 : index
    %52 = arith.cmpi sle, %33, %c0_8 : index
    %53 = arith.subi %c0_8, %33 : index
    %54 = arith.subi %33, %c1_9 : index
    %55 = arith.select %52, %53, %54 : index
    %56 = arith.divsi %55, %c8 : index
    %57 = arith.subi %c0_8, %56 : index
    %58 = arith.addi %56, %c1_9 : index
    %59 = arith.select %52, %57, %58 : index
    %60 = arith.muli %51, %59 : index
    %c-1_10 = arith.constant -1 : index
    %61 = arith.muli %60, %c-1_10 : index
    %62 = arith.addi %33, %61 : index
    %c8_11 = arith.constant 8 : index
    %c0_12 = arith.constant 0 : index
    %c1_13 = arith.constant 1 : index
    %63 = arith.cmpi sle, %33, %c0_12 : index
    %64 = arith.subi %c0_12, %33 : index
    %65 = arith.subi %33, %c1_13 : index
    %66 = arith.select %63, %64, %65 : index
    %67 = arith.divsi %66, %c8_11 : index
    %68 = arith.subi %c0_12, %67 : index
    %69 = arith.addi %67, %c1_13 : index
    %70 = arith.select %63, %68, %69 : index
    %71 = arith.cmpi slt, %62, %70 : index
    %72 = arith.select %71, %62, %70 : index
    %c0_14 = arith.constant 0 : index
    %73 = arith.cmpi sgt, %c0_14, %72 : index
    %74 = arith.select %73, %c0_14, %72 : index
    %c32_15 = arith.constant 32 : index
    %c0_16 = arith.constant 0 : index
    %c1_17 = arith.constant 1 : index
    %75 = arith.cmpi sle, %49, %c0_16 : index
    %76 = arith.subi %c0_16, %49 : index
    %77 = arith.subi %49, %c1_17 : index
    %78 = arith.select %75, %76, %77 : index
    %79 = arith.divsi %78, %c32_15 : index
    %80 = arith.subi %c0_16, %79 : index
    %81 = arith.addi %79, %c1_17 : index
    %82 = arith.select %75, %80, %81 : index
    %83 = arith.muli %50, %82 : index
    %c-1_18 = arith.constant -1 : index
    %84 = arith.muli %83, %c-1_18 : index
    %85 = arith.addi %49, %84 : index
    %c32_19 = arith.constant 32 : index
    %c0_20 = arith.constant 0 : index
    %c1_21 = arith.constant 1 : index
    %86 = arith.cmpi sle, %49, %c0_20 : index
    %87 = arith.subi %c0_20, %49 : index
    %88 = arith.subi %49, %c1_21 : index
    %89 = arith.select %86, %87, %88 : index
    %90 = arith.divsi %89, %c32_19 : index
    %91 = arith.subi %c0_20, %90 : index
    %92 = arith.addi %90, %c1_21 : index
    %93 = arith.select %86, %91, %92 : index
    %94 = arith.cmpi slt, %85, %93 : index
    %95 = arith.select %94, %85, %93 : index
    %c0_22 = arith.constant 0 : index
    %96 = arith.cmpi sgt, %c0_22, %95 : index
    %97 = arith.select %96, %c0_22, %95 : index
    %c128_23 = arith.constant 128 : index
    %c0_24 = arith.constant 0 : index
    %c1_25 = arith.constant 1 : index
    %98 = arith.cmpi sle, %13, %c0_24 : index
    %99 = arith.subi %c0_24, %13 : index
    %100 = arith.subi %13, %c1_25 : index
    %101 = arith.select %98, %99, %100 : index
    %102 = arith.divsi %101, %c128_23 : index
    %103 = arith.subi %c0_24, %102 : index
    %104 = arith.addi %102, %c1_25 : index
    %105 = arith.select %98, %103, %104 : index
    %c0_26 = arith.constant 0 : index
    %c-1_27 = arith.constant -1 : index
    %106 = arith.cmpi slt, %workgroup_id_x, %c0_26 : index
    %107 = arith.subi %c-1_27, %workgroup_id_x : index
    %108 = arith.select %106, %107, %workgroup_id_x : index
    %109 = arith.divsi %108, %105 : index
    %110 = arith.subi %c-1_27, %109 : index
    %111 = arith.select %106, %110, %109 : index
    %c32_28 = arith.constant 32 : index
    %112 = arith.muli %111, %c32_28 : index
    %c8_29 = arith.constant 8 : index
    %c0_30 = arith.constant 0 : index
    %c1_31 = arith.constant 1 : index
    %113 = arith.cmpi sle, %33, %c0_30 : index
    %114 = arith.subi %c0_30, %33 : index
    %115 = arith.subi %33, %c1_31 : index
    %116 = arith.select %113, %114, %115 : index
    %117 = arith.divsi %116, %c8_29 : index
    %118 = arith.subi %c0_30, %117 : index
    %119 = arith.addi %117, %c1_31 : index
    %120 = arith.select %113, %118, %119 : index
    %121 = arith.muli %51, %120 : index
    %122 = arith.addi %112, %121 : index
    %c128_32 = arith.constant 128 : index
    %c0_33 = arith.constant 0 : index
    %c1_34 = arith.constant 1 : index
    %123 = arith.cmpi sle, %13, %c0_33 : index
    %124 = arith.subi %c0_33, %13 : index
    %125 = arith.subi %13, %c1_34 : index
    %126 = arith.select %123, %124, %125 : index
    %127 = arith.divsi %126, %c128_32 : index
    %128 = arith.subi %c0_33, %127 : index
    %129 = arith.addi %127, %c1_34 : index
    %130 = arith.select %123, %128, %129 : index
    %131 = arith.remsi %workgroup_id_x, %130 : index
    %c0_35 = arith.constant 0 : index
    %132 = arith.cmpi slt, %131, %c0_35 : index
    %133 = arith.addi %131, %130 : index
    %134 = arith.select %132, %133, %131 : index
    %c128_36 = arith.constant 128 : index
    %135 = arith.muli %134, %c128_36 : index
    %c32_37 = arith.constant 32 : index
    %c0_38 = arith.constant 0 : index
    %c1_39 = arith.constant 1 : index
    %136 = arith.cmpi sle, %49, %c0_38 : index
    %137 = arith.subi %c0_38, %49 : index
    %138 = arith.subi %49, %c1_39 : index
    %139 = arith.select %136, %137, %138 : index
    %140 = arith.divsi %139, %c32_37 : index
    %141 = arith.subi %c0_38, %140 : index
    %142 = arith.addi %140, %c1_39 : index
    %143 = arith.select %136, %141, %142 : index
    %144 = arith.muli %50, %143 : index
    %145 = arith.addi %135, %144 : index
    %subview = memref.subview %15[%122, %145] [%74, %97] [1, 1] : memref<?x?xf32, #gpu.address_space<global>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
    scf.for %arg0 = %c0 to %74 step %c1 {
      scf.for %arg1 = %c0 to %97 step %c1 {
        memref.store %cst, %subview[%arg0, %arg1] : memref<?x?xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
      }
    }
    scf.for %arg0 = %c0 to %13 step %c1 {
      %subview_40 = memref.subview %14[%122, %arg0] [%74, 1] [1, 1] : memref<?x?xf32, #gpu.address_space<global>> to memref<?x1xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
      %subview_41 = memref.subview %14[%arg0, %145] [1, %97] [1, 1] : memref<?x?xf32, #gpu.address_space<global>> to memref<1x?xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
      scf.for %arg1 = %c0 to %74 step %c1 {
        scf.for %arg2 = %c0 to %97 step %c1 {
          %146 = memref.load %subview_40[%arg1, %c0] : memref<?x1xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
          %147 = memref.load %subview_41[%c0, %arg2] : memref<1x?xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
          %148 = memref.load %subview[%arg1, %arg2] : memref<?x?xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
          %149 = arith.mulf %146, %147 : f32
          %150 = arith.addf %148, %149 : f32
          memref.store %150, %subview[%arg1, %arg2] : memref<?x?xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
        }
      }
    }
    return
  }
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
module {
  func.func @main_dispatch_0_matmul_DxDxD_f32() {
    %c8 = arith.constant 8 : index
    %c-128 = arith.constant -128 : index
    %c-32 = arith.constant -32 : index
    %c-1 = arith.constant -1 : index
    %c128 = arith.constant 128 : index
    %c32 = arith.constant 32 : index
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c32_i64 = arith.constant 32 : i64
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.interface.constant.load[0] : i32
    %1 = hal.interface.constant.load[1] : i32
    %2 = hal.interface.constant.load[2] : i32
    %3 = hal.interface.constant.load[3] : i32
    %4 = arith.extui %0 : i32 to i64
    %5 = arith.extui %1 : i32 to i64
    %6 = arith.shli %5, %c32_i64 : i64
    %7 = arith.ori %4, %6 : i64
    %8 = arith.index_castui %7 : i64 to index
    %9 = arith.extui %2 : i32 to i64
    %10 = arith.extui %3 : i32 to i64
    %11 = arith.shli %10, %c32_i64 : i64
    %12 = arith.ori %9, %11 : i64
    %13 = arith.index_castui %12 : i64 to index
    %14 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32, #gpu.address_space<global>>{%8, %13}
    memref.assume_alignment %14, 64 : memref<?x?xf32, #gpu.address_space<global>>
    %15 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : memref<?x?xf32, #gpu.address_space<global>>{%8, %13}
    memref.assume_alignment %15, 64 : memref<?x?xf32, #gpu.address_space<global>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %16 = arith.cmpi sle, %13, %c0 : index
    %17 = arith.subi %c0, %13 : index
    %18 = arith.subi %13, %c1 : index
    %19 = arith.select %16, %17, %18 : index
    %20 = arith.divsi %19, %c128 : index
    %21 = arith.subi %c0, %20 : index
    %22 = arith.addi %20, %c1 : index
    %23 = arith.select %16, %21, %22 : index
    %24 = arith.cmpi slt, %workgroup_id_x, %c0 : index
    %25 = arith.subi %c-1, %workgroup_id_x : index
    %26 = arith.select %24, %25, %workgroup_id_x : index
    %27 = arith.divsi %26, %23 : index
    %28 = arith.subi %c-1, %27 : index
    %29 = arith.select %24, %28, %27 : index
    %30 = arith.muli %29, %c-32 : index
    %31 = arith.addi %8, %30 : index
    %32 = arith.cmpi sgt, %31, %c32 : index
    %33 = arith.select %32, %c32, %31 : index
    %34 = arith.cmpi sle, %13, %c0 : index
    %35 = arith.subi %c0, %13 : index
    %36 = arith.subi %13, %c1 : index
    %37 = arith.select %34, %35, %36 : index
    %38 = arith.divsi %37, %c128 : index
    %39 = arith.subi %c0, %38 : index
    %40 = arith.addi %38, %c1 : index
    %41 = arith.select %34, %39, %40 : index
    %42 = arith.remsi %workgroup_id_x, %41 : index
    %43 = arith.cmpi slt, %42, %c0 : index
    %44 = arith.addi %42, %41 : index
    %45 = arith.select %43, %44, %42 : index
    %46 = arith.muli %45, %c-128 : index
    %47 = arith.addi %13, %46 : index
    %48 = arith.cmpi sgt, %47, %c128 : index
    %49 = arith.select %48, %c128, %47 : index
    %50 = gpu.thread_id  x
    %51 = gpu.thread_id  y
    %52 = arith.cmpi sle, %33, %c0 : index
    %53 = arith.subi %c0, %33 : index
    %54 = arith.subi %33, %c1 : index
    %55 = arith.select %52, %53, %54 : index
    %56 = arith.divsi %55, %c8 : index
    %57 = arith.subi %c0, %56 : index
    %58 = arith.addi %56, %c1 : index
    %59 = arith.select %52, %57, %58 : index
    %60 = arith.muli %51, %59 : index
    %61 = arith.subi %33, %60 : index
    %62 = arith.cmpi sle, %33, %c0 : index
    %63 = arith.subi %c0, %33 : index
    %64 = arith.subi %33, %c1 : index
    %65 = arith.select %62, %63, %64 : index
    %66 = arith.divsi %65, %c8 : index
    %67 = arith.subi %c0, %66 : index
    %68 = arith.addi %66, %c1 : index
    %69 = arith.select %62, %67, %68 : index
    %70 = arith.cmpi slt, %61, %69 : index
    %71 = arith.select %70, %61, %69 : index
    %72 = arith.cmpi slt, %71, %c0 : index
    %73 = arith.select %72, %c0, %71 : index
    %74 = arith.cmpi sle, %49, %c0 : index
    %75 = arith.subi %c0, %49 : index
    %76 = arith.subi %49, %c1 : index
    %77 = arith.select %74, %75, %76 : index
    %78 = arith.divsi %77, %c32 : index
    %79 = arith.subi %c0, %78 : index
    %80 = arith.addi %78, %c1 : index
    %81 = arith.select %74, %79, %80 : index
    %82 = arith.muli %50, %81 : index
    %83 = arith.subi %49, %82 : index
    %84 = arith.cmpi sle, %49, %c0 : index
    %85 = arith.subi %c0, %49 : index
    %86 = arith.subi %49, %c1 : index
    %87 = arith.select %84, %85, %86 : index
    %88 = arith.divsi %87, %c32 : index
    %89 = arith.subi %c0, %88 : index
    %90 = arith.addi %88, %c1 : index
    %91 = arith.select %84, %89, %90 : index
    %92 = arith.cmpi slt, %83, %91 : index
    %93 = arith.select %92, %83, %91 : index
    %94 = arith.cmpi slt, %93, %c0 : index
    %95 = arith.select %94, %c0, %93 : index
    %96 = arith.cmpi sle, %13, %c0 : index
    %97 = arith.subi %c0, %13 : index
    %98 = arith.subi %13, %c1 : index
    %99 = arith.select %96, %97, %98 : index
    %100 = arith.divsi %99, %c128 : index
    %101 = arith.subi %c0, %100 : index
    %102 = arith.addi %100, %c1 : index
    %103 = arith.select %96, %101, %102 : index
    %104 = arith.cmpi slt, %workgroup_id_x, %c0 : index
    %105 = arith.subi %c-1, %workgroup_id_x : index
    %106 = arith.select %104, %105, %workgroup_id_x : index
    %107 = arith.divsi %106, %103 : index
    %108 = arith.subi %c-1, %107 : index
    %109 = arith.select %104, %108, %107 : index
    %110 = arith.muli %109, %c32 : index
    %111 = arith.cmpi sle, %33, %c0 : index
    %112 = arith.subi %c0, %33 : index
    %113 = arith.subi %33, %c1 : index
    %114 = arith.select %111, %112, %113 : index
    %115 = arith.divsi %114, %c8 : index
    %116 = arith.subi %c0, %115 : index
    %117 = arith.addi %115, %c1 : index
    %118 = arith.select %111, %116, %117 : index
    %119 = arith.muli %51, %118 : index
    %120 = arith.addi %110, %119 : index
    %121 = arith.cmpi sle, %13, %c0 : index
    %122 = arith.subi %c0, %13 : index
    %123 = arith.subi %13, %c1 : index
    %124 = arith.select %121, %122, %123 : index
    %125 = arith.divsi %124, %c128 : index
    %126 = arith.subi %c0, %125 : index
    %127 = arith.addi %125, %c1 : index
    %128 = arith.select %121, %126, %127 : index
    %129 = arith.remsi %workgroup_id_x, %128 : index
    %130 = arith.cmpi slt, %129, %c0 : index
    %131 = arith.addi %129, %128 : index
    %132 = arith.select %130, %131, %129 : index
    %133 = arith.muli %132, %c128 : index
    %134 = arith.cmpi sle, %49, %c0 : index
    %135 = arith.subi %c0, %49 : index
    %136 = arith.subi %49, %c1 : index
    %137 = arith.select %134, %135, %136 : index
    %138 = arith.divsi %137, %c32 : index
    %139 = arith.subi %c0, %138 : index
    %140 = arith.addi %138, %c1 : index
    %141 = arith.select %134, %139, %140 : index
    %142 = arith.muli %50, %141 : index
    %143 = arith.addi %133, %142 : index
    %subview = memref.subview %15[%120, %143] [%73, %95] [1, 1] : memref<?x?xf32, #gpu.address_space<global>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
    scf.for %arg0 = %c0 to %73 step %c1 {
      scf.for %arg1 = %c0 to %95 step %c1 {
        memref.store %cst, %subview[%arg0, %arg1] : memref<?x?xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
      }
    }
    scf.for %arg0 = %c0 to %13 step %c1 {
      %subview_0 = memref.subview %14[%120, %arg0] [%73, 1] [1, 1] : memref<?x?xf32, #gpu.address_space<global>> to memref<?x1xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
      %subview_1 = memref.subview %14[%arg0, %143] [1, %95] [1, 1] : memref<?x?xf32, #gpu.address_space<global>> to memref<1x?xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
      scf.for %arg1 = %c0 to %73 step %c1 {
        scf.for %arg2 = %c0 to %95 step %c1 {
          %144 = memref.load %subview_0[%arg1, %c0] : memref<?x1xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
          %145 = memref.load %subview_1[%c0, %arg2] : memref<1x?xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
          %146 = memref.load %subview[%arg1, %arg2] : memref<?x?xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
          %147 = arith.mulf %144, %145 : f32
          %148 = arith.addf %146, %147 : f32
          memref.store %148, %subview[%arg1, %arg2] : memref<?x?xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
        }
      }
    }
    return
  }
}

// -----// IR Dump After CSE (cse) //----- //
module {
  func.func @main_dispatch_0_matmul_DxDxD_f32() {
    %c8 = arith.constant 8 : index
    %c-128 = arith.constant -128 : index
    %c-32 = arith.constant -32 : index
    %c-1 = arith.constant -1 : index
    %c128 = arith.constant 128 : index
    %c32 = arith.constant 32 : index
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c32_i64 = arith.constant 32 : i64
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.interface.constant.load[0] : i32
    %1 = hal.interface.constant.load[1] : i32
    %2 = hal.interface.constant.load[2] : i32
    %3 = hal.interface.constant.load[3] : i32
    %4 = arith.extui %0 : i32 to i64
    %5 = arith.extui %1 : i32 to i64
    %6 = arith.shli %5, %c32_i64 : i64
    %7 = arith.ori %4, %6 : i64
    %8 = arith.index_castui %7 : i64 to index
    %9 = arith.extui %2 : i32 to i64
    %10 = arith.extui %3 : i32 to i64
    %11 = arith.shli %10, %c32_i64 : i64
    %12 = arith.ori %9, %11 : i64
    %13 = arith.index_castui %12 : i64 to index
    %14 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32, #gpu.address_space<global>>{%8, %13}
    memref.assume_alignment %14, 64 : memref<?x?xf32, #gpu.address_space<global>>
    %15 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : memref<?x?xf32, #gpu.address_space<global>>{%8, %13}
    memref.assume_alignment %15, 64 : memref<?x?xf32, #gpu.address_space<global>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %16 = arith.cmpi sle, %13, %c0 : index
    %17 = arith.subi %c0, %13 : index
    %18 = arith.subi %13, %c1 : index
    %19 = arith.select %16, %17, %18 : index
    %20 = arith.divsi %19, %c128 : index
    %21 = arith.subi %c0, %20 : index
    %22 = arith.addi %20, %c1 : index
    %23 = arith.select %16, %21, %22 : index
    %24 = arith.cmpi slt, %workgroup_id_x, %c0 : index
    %25 = arith.subi %c-1, %workgroup_id_x : index
    %26 = arith.select %24, %25, %workgroup_id_x : index
    %27 = arith.divsi %26, %23 : index
    %28 = arith.subi %c-1, %27 : index
    %29 = arith.select %24, %28, %27 : index
    %30 = arith.muli %29, %c-32 : index
    %31 = arith.addi %8, %30 : index
    %32 = arith.cmpi sgt, %31, %c32 : index
    %33 = arith.select %32, %c32, %31 : index
    %34 = arith.remsi %workgroup_id_x, %23 : index
    %35 = arith.cmpi slt, %34, %c0 : index
    %36 = arith.addi %34, %23 : index
    %37 = arith.select %35, %36, %34 : index
    %38 = arith.muli %37, %c-128 : index
    %39 = arith.addi %13, %38 : index
    %40 = arith.cmpi sgt, %39, %c128 : index
    %41 = arith.select %40, %c128, %39 : index
    %42 = gpu.thread_id  x
    %43 = gpu.thread_id  y
    %44 = arith.cmpi sle, %33, %c0 : index
    %45 = arith.subi %c0, %33 : index
    %46 = arith.subi %33, %c1 : index
    %47 = arith.select %44, %45, %46 : index
    %48 = arith.divsi %47, %c8 : index
    %49 = arith.subi %c0, %48 : index
    %50 = arith.addi %48, %c1 : index
    %51 = arith.select %44, %49, %50 : index
    %52 = arith.muli %43, %51 : index
    %53 = arith.subi %33, %52 : index
    %54 = arith.cmpi slt, %53, %51 : index
    %55 = arith.select %54, %53, %51 : index
    %56 = arith.cmpi slt, %55, %c0 : index
    %57 = arith.select %56, %c0, %55 : index
    %58 = arith.cmpi sle, %41, %c0 : index
    %59 = arith.subi %c0, %41 : index
    %60 = arith.subi %41, %c1 : index
    %61 = arith.select %58, %59, %60 : index
    %62 = arith.divsi %61, %c32 : index
    %63 = arith.subi %c0, %62 : index
    %64 = arith.addi %62, %c1 : index
    %65 = arith.select %58, %63, %64 : index
    %66 = arith.muli %42, %65 : index
    %67 = arith.subi %41, %66 : index
    %68 = arith.cmpi slt, %67, %65 : index
    %69 = arith.select %68, %67, %65 : index
    %70 = arith.cmpi slt, %69, %c0 : index
    %71 = arith.select %70, %c0, %69 : index
    %72 = arith.muli %29, %c32 : index
    %73 = arith.addi %72, %52 : index
    %74 = arith.muli %37, %c128 : index
    %75 = arith.addi %74, %66 : index
    %subview = memref.subview %15[%73, %75] [%57, %71] [1, 1] : memref<?x?xf32, #gpu.address_space<global>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
    scf.for %arg0 = %c0 to %57 step %c1 {
      scf.for %arg1 = %c0 to %71 step %c1 {
        memref.store %cst, %subview[%arg0, %arg1] : memref<?x?xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
      }
    }
    scf.for %arg0 = %c0 to %13 step %c1 {
      %subview_0 = memref.subview %14[%73, %arg0] [%57, 1] [1, 1] : memref<?x?xf32, #gpu.address_space<global>> to memref<?x1xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
      %subview_1 = memref.subview %14[%arg0, %75] [1, %71] [1, 1] : memref<?x?xf32, #gpu.address_space<global>> to memref<1x?xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
      scf.for %arg1 = %c0 to %57 step %c1 {
        scf.for %arg2 = %c0 to %71 step %c1 {
          %76 = memref.load %subview_0[%arg1, %c0] : memref<?x1xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
          %77 = memref.load %subview_1[%c0, %arg2] : memref<1x?xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
          %78 = memref.load %subview[%arg1, %arg2] : memref<?x?xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
          %79 = arith.mulf %76, %77 : f32
          %80 = arith.addf %78, %79 : f32
          memref.store %80, %subview[%arg1, %arg2] : memref<?x?xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
        }
      }
    }
    return
  }
}

// -----// IR Dump After ArithBufferizePass (arith-bufferize) //----- //
module {
  func.func @main_dispatch_0_matmul_DxDxD_f32() {
    %c8 = arith.constant 8 : index
    %c-128 = arith.constant -128 : index
    %c-32 = arith.constant -32 : index
    %c-1 = arith.constant -1 : index
    %c128 = arith.constant 128 : index
    %c32 = arith.constant 32 : index
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c32_i64 = arith.constant 32 : i64
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.interface.constant.load[0] : i32
    %1 = hal.interface.constant.load[1] : i32
    %2 = hal.interface.constant.load[2] : i32
    %3 = hal.interface.constant.load[3] : i32
    %4 = arith.extui %0 : i32 to i64
    %5 = arith.extui %1 : i32 to i64
    %6 = arith.shli %5, %c32_i64 : i64
    %7 = arith.ori %4, %6 : i64
    %8 = arith.index_castui %7 : i64 to index
    %9 = arith.extui %2 : i32 to i64
    %10 = arith.extui %3 : i32 to i64
    %11 = arith.shli %10, %c32_i64 : i64
    %12 = arith.ori %9, %11 : i64
    %13 = arith.index_castui %12 : i64 to index
    %14 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32, #gpu.address_space<global>>{%8, %13}
    memref.assume_alignment %14, 64 : memref<?x?xf32, #gpu.address_space<global>>
    %15 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : memref<?x?xf32, #gpu.address_space<global>>{%8, %13}
    memref.assume_alignment %15, 64 : memref<?x?xf32, #gpu.address_space<global>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %16 = arith.cmpi sle, %13, %c0 : index
    %17 = arith.subi %c0, %13 : index
    %18 = arith.subi %13, %c1 : index
    %19 = arith.select %16, %17, %18 : index
    %20 = arith.divsi %19, %c128 : index
    %21 = arith.subi %c0, %20 : index
    %22 = arith.addi %20, %c1 : index
    %23 = arith.select %16, %21, %22 : index
    %24 = arith.cmpi slt, %workgroup_id_x, %c0 : index
    %25 = arith.subi %c-1, %workgroup_id_x : index
    %26 = arith.select %24, %25, %workgroup_id_x : index
    %27 = arith.divsi %26, %23 : index
    %28 = arith.subi %c-1, %27 : index
    %29 = arith.select %24, %28, %27 : index
    %30 = arith.muli %29, %c-32 : index
    %31 = arith.addi %8, %30 : index
    %32 = arith.cmpi sgt, %31, %c32 : index
    %33 = arith.select %32, %c32, %31 : index
    %34 = arith.remsi %workgroup_id_x, %23 : index
    %35 = arith.cmpi slt, %34, %c0 : index
    %36 = arith.addi %34, %23 : index
    %37 = arith.select %35, %36, %34 : index
    %38 = arith.muli %37, %c-128 : index
    %39 = arith.addi %13, %38 : index
    %40 = arith.cmpi sgt, %39, %c128 : index
    %41 = arith.select %40, %c128, %39 : index
    %42 = gpu.thread_id  x
    %43 = gpu.thread_id  y
    %44 = arith.cmpi sle, %33, %c0 : index
    %45 = arith.subi %c0, %33 : index
    %46 = arith.subi %33, %c1 : index
    %47 = arith.select %44, %45, %46 : index
    %48 = arith.divsi %47, %c8 : index
    %49 = arith.subi %c0, %48 : index
    %50 = arith.addi %48, %c1 : index
    %51 = arith.select %44, %49, %50 : index
    %52 = arith.muli %43, %51 : index
    %53 = arith.subi %33, %52 : index
    %54 = arith.cmpi slt, %53, %51 : index
    %55 = arith.select %54, %53, %51 : index
    %56 = arith.cmpi slt, %55, %c0 : index
    %57 = arith.select %56, %c0, %55 : index
    %58 = arith.cmpi sle, %41, %c0 : index
    %59 = arith.subi %c0, %41 : index
    %60 = arith.subi %41, %c1 : index
    %61 = arith.select %58, %59, %60 : index
    %62 = arith.divsi %61, %c32 : index
    %63 = arith.subi %c0, %62 : index
    %64 = arith.addi %62, %c1 : index
    %65 = arith.select %58, %63, %64 : index
    %66 = arith.muli %42, %65 : index
    %67 = arith.subi %41, %66 : index
    %68 = arith.cmpi slt, %67, %65 : index
    %69 = arith.select %68, %67, %65 : index
    %70 = arith.cmpi slt, %69, %c0 : index
    %71 = arith.select %70, %c0, %69 : index
    %72 = arith.muli %29, %c32 : index
    %73 = arith.addi %72, %52 : index
    %74 = arith.muli %37, %c128 : index
    %75 = arith.addi %74, %66 : index
    %subview = memref.subview %15[%73, %75] [%57, %71] [1, 1] : memref<?x?xf32, #gpu.address_space<global>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
    scf.for %arg0 = %c0 to %57 step %c1 {
      scf.for %arg1 = %c0 to %71 step %c1 {
        memref.store %cst, %subview[%arg0, %arg1] : memref<?x?xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
      }
    }
    scf.for %arg0 = %c0 to %13 step %c1 {
      %subview_0 = memref.subview %14[%73, %arg0] [%57, 1] [1, 1] : memref<?x?xf32, #gpu.address_space<global>> to memref<?x1xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
      %subview_1 = memref.subview %14[%arg0, %75] [1, %71] [1, 1] : memref<?x?xf32, #gpu.address_space<global>> to memref<1x?xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
      scf.for %arg1 = %c0 to %57 step %c1 {
        scf.for %arg2 = %c0 to %71 step %c1 {
          %76 = memref.load %subview_0[%arg1, %c0] : memref<?x1xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
          %77 = memref.load %subview_1[%c0, %arg2] : memref<1x?xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
          %78 = memref.load %subview[%arg1, %arg2] : memref<?x?xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
          %79 = arith.mulf %76, %77 : f32
          %80 = arith.addf %78, %79 : f32
          memref.store %80, %subview[%arg1, %arg2] : memref<?x?xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
        }
      }
    }
    return
  }
}

// -----// IR Dump After FoldTensorExtractOp (iree-codegen-fold-tensor-extract-op) //----- //
module {
  func.func @main_dispatch_0_matmul_DxDxD_f32() {
    %c8 = arith.constant 8 : index
    %c-128 = arith.constant -128 : index
    %c-32 = arith.constant -32 : index
    %c-1 = arith.constant -1 : index
    %c128 = arith.constant 128 : index
    %c32 = arith.constant 32 : index
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c32_i64 = arith.constant 32 : i64
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.interface.constant.load[0] : i32
    %1 = hal.interface.constant.load[1] : i32
    %2 = hal.interface.constant.load[2] : i32
    %3 = hal.interface.constant.load[3] : i32
    %4 = arith.extui %0 : i32 to i64
    %5 = arith.extui %1 : i32 to i64
    %6 = arith.shli %5, %c32_i64 : i64
    %7 = arith.ori %4, %6 : i64
    %8 = arith.index_castui %7 : i64 to index
    %9 = arith.extui %2 : i32 to i64
    %10 = arith.extui %3 : i32 to i64
    %11 = arith.shli %10, %c32_i64 : i64
    %12 = arith.ori %9, %11 : i64
    %13 = arith.index_castui %12 : i64 to index
    %14 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32, #gpu.address_space<global>>{%8, %13}
    memref.assume_alignment %14, 64 : memref<?x?xf32, #gpu.address_space<global>>
    %15 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : memref<?x?xf32, #gpu.address_space<global>>{%8, %13}
    memref.assume_alignment %15, 64 : memref<?x?xf32, #gpu.address_space<global>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %16 = arith.cmpi sle, %13, %c0 : index
    %17 = arith.subi %c0, %13 : index
    %18 = arith.subi %13, %c1 : index
    %19 = arith.select %16, %17, %18 : index
    %20 = arith.divsi %19, %c128 : index
    %21 = arith.subi %c0, %20 : index
    %22 = arith.addi %20, %c1 : index
    %23 = arith.select %16, %21, %22 : index
    %24 = arith.cmpi slt, %workgroup_id_x, %c0 : index
    %25 = arith.subi %c-1, %workgroup_id_x : index
    %26 = arith.select %24, %25, %workgroup_id_x : index
    %27 = arith.divsi %26, %23 : index
    %28 = arith.subi %c-1, %27 : index
    %29 = arith.select %24, %28, %27 : index
    %30 = arith.muli %29, %c-32 : index
    %31 = arith.addi %8, %30 : index
    %32 = arith.cmpi sgt, %31, %c32 : index
    %33 = arith.select %32, %c32, %31 : index
    %34 = arith.remsi %workgroup_id_x, %23 : index
    %35 = arith.cmpi slt, %34, %c0 : index
    %36 = arith.addi %34, %23 : index
    %37 = arith.select %35, %36, %34 : index
    %38 = arith.muli %37, %c-128 : index
    %39 = arith.addi %13, %38 : index
    %40 = arith.cmpi sgt, %39, %c128 : index
    %41 = arith.select %40, %c128, %39 : index
    %42 = gpu.thread_id  x
    %43 = gpu.thread_id  y
    %44 = arith.cmpi sle, %33, %c0 : index
    %45 = arith.subi %c0, %33 : index
    %46 = arith.subi %33, %c1 : index
    %47 = arith.select %44, %45, %46 : index
    %48 = arith.divsi %47, %c8 : index
    %49 = arith.subi %c0, %48 : index
    %50 = arith.addi %48, %c1 : index
    %51 = arith.select %44, %49, %50 : index
    %52 = arith.muli %43, %51 : index
    %53 = arith.subi %33, %52 : index
    %54 = arith.cmpi slt, %53, %51 : index
    %55 = arith.select %54, %53, %51 : index
    %56 = arith.cmpi slt, %55, %c0 : index
    %57 = arith.select %56, %c0, %55 : index
    %58 = arith.cmpi sle, %41, %c0 : index
    %59 = arith.subi %c0, %41 : index
    %60 = arith.subi %41, %c1 : index
    %61 = arith.select %58, %59, %60 : index
    %62 = arith.divsi %61, %c32 : index
    %63 = arith.subi %c0, %62 : index
    %64 = arith.addi %62, %c1 : index
    %65 = arith.select %58, %63, %64 : index
    %66 = arith.muli %42, %65 : index
    %67 = arith.subi %41, %66 : index
    %68 = arith.cmpi slt, %67, %65 : index
    %69 = arith.select %68, %67, %65 : index
    %70 = arith.cmpi slt, %69, %c0 : index
    %71 = arith.select %70, %c0, %69 : index
    %72 = arith.muli %29, %c32 : index
    %73 = arith.addi %72, %52 : index
    %74 = arith.muli %37, %c128 : index
    %75 = arith.addi %74, %66 : index
    %subview = memref.subview %15[%73, %75] [%57, %71] [1, 1] : memref<?x?xf32, #gpu.address_space<global>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
    scf.for %arg0 = %c0 to %57 step %c1 {
      scf.for %arg1 = %c0 to %71 step %c1 {
        memref.store %cst, %subview[%arg0, %arg1] : memref<?x?xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
      }
    }
    scf.for %arg0 = %c0 to %13 step %c1 {
      %subview_0 = memref.subview %14[%73, %arg0] [%57, 1] [1, 1] : memref<?x?xf32, #gpu.address_space<global>> to memref<?x1xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
      %subview_1 = memref.subview %14[%arg0, %75] [1, %71] [1, 1] : memref<?x?xf32, #gpu.address_space<global>> to memref<1x?xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
      scf.for %arg1 = %c0 to %57 step %c1 {
        scf.for %arg2 = %c0 to %71 step %c1 {
          %76 = memref.load %subview_0[%arg1, %c0] : memref<?x1xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
          %77 = memref.load %subview_1[%c0, %arg2] : memref<1x?xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
          %78 = memref.load %subview[%arg1, %arg2] : memref<?x?xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
          %79 = arith.mulf %76, %77 : f32
          %80 = arith.addf %78, %79 : f32
          memref.store %80, %subview[%arg1, %arg2] : memref<?x?xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
        }
      }
    }
    return
  }
}

// -----// IR Dump After LLVMGPUVectorLowering (iree-llvmgpu-vector-lowering) //----- //
func.func @main_dispatch_0_matmul_DxDxD_f32() {
  %c8 = arith.constant 8 : index
  %c-128 = arith.constant -128 : index
  %c-32 = arith.constant -32 : index
  %c-1 = arith.constant -1 : index
  %c128 = arith.constant 128 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c32_i64 = arith.constant 32 : i64
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.interface.constant.load[0] : i32
  %1 = hal.interface.constant.load[1] : i32
  %2 = hal.interface.constant.load[2] : i32
  %3 = hal.interface.constant.load[3] : i32
  %4 = arith.extui %0 : i32 to i64
  %5 = arith.extui %1 : i32 to i64
  %6 = arith.shli %5, %c32_i64 : i64
  %7 = arith.ori %4, %6 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %2 : i32 to i64
  %10 = arith.extui %3 : i32 to i64
  %11 = arith.shli %10, %c32_i64 : i64
  %12 = arith.ori %9, %11 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32, #gpu.address_space<global>>{%8, %13}
  memref.assume_alignment %14, 64 : memref<?x?xf32, #gpu.address_space<global>>
  %15 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : memref<?x?xf32, #gpu.address_space<global>>{%8, %13}
  memref.assume_alignment %15, 64 : memref<?x?xf32, #gpu.address_space<global>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %16 = arith.cmpi sle, %13, %c0 : index
  %17 = arith.subi %c0, %13 : index
  %18 = arith.subi %13, %c1 : index
  %19 = arith.select %16, %17, %18 : index
  %20 = arith.divsi %19, %c128 : index
  %21 = arith.subi %c0, %20 : index
  %22 = arith.addi %20, %c1 : index
  %23 = arith.select %16, %21, %22 : index
  %24 = arith.cmpi slt, %workgroup_id_x, %c0 : index
  %25 = arith.subi %c-1, %workgroup_id_x : index
  %26 = arith.select %24, %25, %workgroup_id_x : index
  %27 = arith.divsi %26, %23 : index
  %28 = arith.subi %c-1, %27 : index
  %29 = arith.select %24, %28, %27 : index
  %30 = arith.muli %29, %c-32 : index
  %31 = arith.addi %8, %30 : index
  %32 = arith.cmpi sgt, %31, %c32 : index
  %33 = arith.select %32, %c32, %31 : index
  %34 = arith.remsi %workgroup_id_x, %23 : index
  %35 = arith.cmpi slt, %34, %c0 : index
  %36 = arith.addi %34, %23 : index
  %37 = arith.select %35, %36, %34 : index
  %38 = arith.muli %37, %c-128 : index
  %39 = arith.addi %13, %38 : index
  %40 = arith.cmpi sgt, %39, %c128 : index
  %41 = arith.select %40, %c128, %39 : index
  %42 = gpu.thread_id  x
  %43 = gpu.thread_id  y
  %44 = arith.cmpi sle, %33, %c0 : index
  %45 = arith.subi %c0, %33 : index
  %46 = arith.subi %33, %c1 : index
  %47 = arith.select %44, %45, %46 : index
  %48 = arith.divsi %47, %c8 : index
  %49 = arith.subi %c0, %48 : index
  %50 = arith.addi %48, %c1 : index
  %51 = arith.select %44, %49, %50 : index
  %52 = arith.muli %43, %51 : index
  %53 = arith.subi %33, %52 : index
  %54 = arith.cmpi slt, %53, %51 : index
  %55 = arith.select %54, %53, %51 : index
  %56 = arith.cmpi slt, %55, %c0 : index
  %57 = arith.select %56, %c0, %55 : index
  %58 = arith.cmpi sle, %41, %c0 : index
  %59 = arith.subi %c0, %41 : index
  %60 = arith.subi %41, %c1 : index
  %61 = arith.select %58, %59, %60 : index
  %62 = arith.divsi %61, %c32 : index
  %63 = arith.subi %c0, %62 : index
  %64 = arith.addi %62, %c1 : index
  %65 = arith.select %58, %63, %64 : index
  %66 = arith.muli %42, %65 : index
  %67 = arith.subi %41, %66 : index
  %68 = arith.cmpi slt, %67, %65 : index
  %69 = arith.select %68, %67, %65 : index
  %70 = arith.cmpi slt, %69, %c0 : index
  %71 = arith.select %70, %c0, %69 : index
  %72 = arith.muli %29, %c32 : index
  %73 = arith.addi %72, %52 : index
  %74 = arith.muli %37, %c128 : index
  %75 = arith.addi %74, %66 : index
  scf.for %arg0 = %c0 to %57 step %c1 {
    scf.for %arg1 = %c0 to %71 step %c1 {
      %76 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%73, %arg0]
      %77 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%75, %arg1]
      memref.store %cst, %15[%76, %77] : memref<?x?xf32, #gpu.address_space<global>>
    }
  }
  scf.for %arg0 = %c0 to %13 step %c1 {
    scf.for %arg1 = %c0 to %57 step %c1 {
      scf.for %arg2 = %c0 to %71 step %c1 {
        %76 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%73, %arg1]
        %77 = memref.load %14[%76, %arg0] : memref<?x?xf32, #gpu.address_space<global>>
        %78 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%75, %arg2]
        %79 = memref.load %14[%arg0, %78] : memref<?x?xf32, #gpu.address_space<global>>
        %80 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%73, %arg1]
        %81 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%75, %arg2]
        %82 = memref.load %15[%80, %81] : memref<?x?xf32, #gpu.address_space<global>>
        %83 = arith.mulf %77, %79 : f32
        %84 = arith.addf %82, %83 : f32
        %85 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%73, %arg1]
        %86 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%75, %arg2]
        memref.store %84, %15[%85, %86] : memref<?x?xf32, #gpu.address_space<global>>
      }
    }
  }
  return
}

// -----// IR Dump After ExtractAddressComputationGPU (extract-address-computation-gpu) //----- //
module {
  func.func @main_dispatch_0_matmul_DxDxD_f32() {
    %c8 = arith.constant 8 : index
    %c-128 = arith.constant -128 : index
    %c-32 = arith.constant -32 : index
    %c-1 = arith.constant -1 : index
    %c128 = arith.constant 128 : index
    %c32 = arith.constant 32 : index
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c32_i64 = arith.constant 32 : i64
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.interface.constant.load[0] : i32
    %1 = hal.interface.constant.load[1] : i32
    %2 = hal.interface.constant.load[2] : i32
    %3 = hal.interface.constant.load[3] : i32
    %4 = arith.extui %0 : i32 to i64
    %5 = arith.extui %1 : i32 to i64
    %6 = arith.shli %5, %c32_i64 : i64
    %7 = arith.ori %4, %6 : i64
    %8 = arith.index_castui %7 : i64 to index
    %9 = arith.extui %2 : i32 to i64
    %10 = arith.extui %3 : i32 to i64
    %11 = arith.shli %10, %c32_i64 : i64
    %12 = arith.ori %9, %11 : i64
    %13 = arith.index_castui %12 : i64 to index
    %14 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32, #gpu.address_space<global>>{%8, %13}
    memref.assume_alignment %14, 64 : memref<?x?xf32, #gpu.address_space<global>>
    %15 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : memref<?x?xf32, #gpu.address_space<global>>{%8, %13}
    memref.assume_alignment %15, 64 : memref<?x?xf32, #gpu.address_space<global>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %16 = arith.cmpi sle, %13, %c0 : index
    %17 = arith.subi %c0, %13 : index
    %18 = arith.subi %13, %c1 : index
    %19 = arith.select %16, %17, %18 : index
    %20 = arith.divsi %19, %c128 : index
    %21 = arith.subi %c0, %20 : index
    %22 = arith.addi %20, %c1 : index
    %23 = arith.select %16, %21, %22 : index
    %24 = arith.cmpi slt, %workgroup_id_x, %c0 : index
    %25 = arith.subi %c-1, %workgroup_id_x : index
    %26 = arith.select %24, %25, %workgroup_id_x : index
    %27 = arith.divsi %26, %23 : index
    %28 = arith.subi %c-1, %27 : index
    %29 = arith.select %24, %28, %27 : index
    %30 = arith.muli %29, %c-32 : index
    %31 = arith.addi %8, %30 : index
    %32 = arith.cmpi sgt, %31, %c32 : index
    %33 = arith.select %32, %c32, %31 : index
    %34 = arith.remsi %workgroup_id_x, %23 : index
    %35 = arith.cmpi slt, %34, %c0 : index
    %36 = arith.addi %34, %23 : index
    %37 = arith.select %35, %36, %34 : index
    %38 = arith.muli %37, %c-128 : index
    %39 = arith.addi %13, %38 : index
    %40 = arith.cmpi sgt, %39, %c128 : index
    %41 = arith.select %40, %c128, %39 : index
    %42 = gpu.thread_id  x
    %43 = gpu.thread_id  y
    %44 = arith.cmpi sle, %33, %c0 : index
    %45 = arith.subi %c0, %33 : index
    %46 = arith.subi %33, %c1 : index
    %47 = arith.select %44, %45, %46 : index
    %48 = arith.divsi %47, %c8 : index
    %49 = arith.subi %c0, %48 : index
    %50 = arith.addi %48, %c1 : index
    %51 = arith.select %44, %49, %50 : index
    %52 = arith.muli %43, %51 : index
    %53 = arith.subi %33, %52 : index
    %54 = arith.cmpi slt, %53, %51 : index
    %55 = arith.select %54, %53, %51 : index
    %56 = arith.cmpi slt, %55, %c0 : index
    %57 = arith.select %56, %c0, %55 : index
    %58 = arith.cmpi sle, %41, %c0 : index
    %59 = arith.subi %c0, %41 : index
    %60 = arith.subi %41, %c1 : index
    %61 = arith.select %58, %59, %60 : index
    %62 = arith.divsi %61, %c32 : index
    %63 = arith.subi %c0, %62 : index
    %64 = arith.addi %62, %c1 : index
    %65 = arith.select %58, %63, %64 : index
    %66 = arith.muli %42, %65 : index
    %67 = arith.subi %41, %66 : index
    %68 = arith.cmpi slt, %67, %65 : index
    %69 = arith.select %68, %67, %65 : index
    %70 = arith.cmpi slt, %69, %c0 : index
    %71 = arith.select %70, %c0, %69 : index
    %72 = arith.muli %29, %c32 : index
    %73 = arith.addi %72, %52 : index
    %74 = arith.muli %37, %c128 : index
    %75 = arith.addi %74, %66 : index
    scf.for %arg0 = %c0 to %57 step %c1 {
      scf.for %arg1 = %c0 to %71 step %c1 {
        %76 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%73, %arg0]
        %77 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%75, %arg1]
        %subview = memref.subview %15[%76, %77] [1, 1] [1, 1] : memref<?x?xf32, #gpu.address_space<global>> to memref<1x1xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
        memref.store %cst, %subview[%c0, %c0] : memref<1x1xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
      }
    }
    scf.for %arg0 = %c0 to %13 step %c1 {
      scf.for %arg1 = %c0 to %57 step %c1 {
        scf.for %arg2 = %c0 to %71 step %c1 {
          %76 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%73, %arg1]
          %subview = memref.subview %14[%76, %arg0] [1, 1] [1, 1] : memref<?x?xf32, #gpu.address_space<global>> to memref<1x1xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
          %77 = memref.load %subview[%c0, %c0] : memref<1x1xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
          %78 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%75, %arg2]
          %subview_0 = memref.subview %14[%arg0, %78] [1, 1] [1, 1] : memref<?x?xf32, #gpu.address_space<global>> to memref<1x1xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
          %79 = memref.load %subview_0[%c0, %c0] : memref<1x1xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
          %80 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%73, %arg1]
          %81 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%75, %arg2]
          %subview_1 = memref.subview %15[%80, %81] [1, 1] [1, 1] : memref<?x?xf32, #gpu.address_space<global>> to memref<1x1xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
          %82 = memref.load %subview_1[%c0, %c0] : memref<1x1xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
          %83 = arith.mulf %77, %79 : f32
          %84 = arith.addf %82, %83 : f32
          %85 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%73, %arg1]
          %86 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%75, %arg2]
          %subview_2 = memref.subview %15[%85, %86] [1, 1] [1, 1] : memref<?x?xf32, #gpu.address_space<global>> to memref<1x1xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
          memref.store %84, %subview_2[%c0, %c0] : memref<1x1xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
        }
      }
    }
    return
  }
}

// -----// IR Dump After ExpandOps (memref-expand) //----- //
func.func @main_dispatch_0_matmul_DxDxD_f32() {
  %c8 = arith.constant 8 : index
  %c-128 = arith.constant -128 : index
  %c-32 = arith.constant -32 : index
  %c-1 = arith.constant -1 : index
  %c128 = arith.constant 128 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c32_i64 = arith.constant 32 : i64
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.interface.constant.load[0] : i32
  %1 = hal.interface.constant.load[1] : i32
  %2 = hal.interface.constant.load[2] : i32
  %3 = hal.interface.constant.load[3] : i32
  %4 = arith.extui %0 : i32 to i64
  %5 = arith.extui %1 : i32 to i64
  %6 = arith.shli %5, %c32_i64 : i64
  %7 = arith.ori %4, %6 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %2 : i32 to i64
  %10 = arith.extui %3 : i32 to i64
  %11 = arith.shli %10, %c32_i64 : i64
  %12 = arith.ori %9, %11 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32, #gpu.address_space<global>>{%8, %13}
  memref.assume_alignment %14, 64 : memref<?x?xf32, #gpu.address_space<global>>
  %15 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : memref<?x?xf32, #gpu.address_space<global>>{%8, %13}
  memref.assume_alignment %15, 64 : memref<?x?xf32, #gpu.address_space<global>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %16 = arith.cmpi sle, %13, %c0 : index
  %17 = arith.subi %c0, %13 : index
  %18 = arith.subi %13, %c1 : index
  %19 = arith.select %16, %17, %18 : index
  %20 = arith.divsi %19, %c128 : index
  %21 = arith.subi %c0, %20 : index
  %22 = arith.addi %20, %c1 : index
  %23 = arith.select %16, %21, %22 : index
  %24 = arith.cmpi slt, %workgroup_id_x, %c0 : index
  %25 = arith.subi %c-1, %workgroup_id_x : index
  %26 = arith.select %24, %25, %workgroup_id_x : index
  %27 = arith.divsi %26, %23 : index
  %28 = arith.subi %c-1, %27 : index
  %29 = arith.select %24, %28, %27 : index
  %30 = arith.muli %29, %c-32 : index
  %31 = arith.addi %8, %30 : index
  %32 = arith.cmpi sgt, %31, %c32 : index
  %33 = arith.select %32, %c32, %31 : index
  %34 = arith.remsi %workgroup_id_x, %23 : index
  %35 = arith.cmpi slt, %34, %c0 : index
  %36 = arith.addi %34, %23 : index
  %37 = arith.select %35, %36, %34 : index
  %38 = arith.muli %37, %c-128 : index
  %39 = arith.addi %13, %38 : index
  %40 = arith.cmpi sgt, %39, %c128 : index
  %41 = arith.select %40, %c128, %39 : index
  %42 = gpu.thread_id  x
  %43 = gpu.thread_id  y
  %44 = arith.cmpi sle, %33, %c0 : index
  %45 = arith.subi %c0, %33 : index
  %46 = arith.subi %33, %c1 : index
  %47 = arith.select %44, %45, %46 : index
  %48 = arith.divsi %47, %c8 : index
  %49 = arith.subi %c0, %48 : index
  %50 = arith.addi %48, %c1 : index
  %51 = arith.select %44, %49, %50 : index
  %52 = arith.muli %43, %51 : index
  %53 = arith.subi %33, %52 : index
  %54 = arith.cmpi slt, %53, %51 : index
  %55 = arith.select %54, %53, %51 : index
  %56 = arith.cmpi slt, %55, %c0 : index
  %57 = arith.select %56, %c0, %55 : index
  %58 = arith.cmpi sle, %41, %c0 : index
  %59 = arith.subi %c0, %41 : index
  %60 = arith.subi %41, %c1 : index
  %61 = arith.select %58, %59, %60 : index
  %62 = arith.divsi %61, %c32 : index
  %63 = arith.subi %c0, %62 : index
  %64 = arith.addi %62, %c1 : index
  %65 = arith.select %58, %63, %64 : index
  %66 = arith.muli %42, %65 : index
  %67 = arith.subi %41, %66 : index
  %68 = arith.cmpi slt, %67, %65 : index
  %69 = arith.select %68, %67, %65 : index
  %70 = arith.cmpi slt, %69, %c0 : index
  %71 = arith.select %70, %c0, %69 : index
  %72 = arith.muli %29, %c32 : index
  %73 = arith.addi %72, %52 : index
  %74 = arith.muli %37, %c128 : index
  %75 = arith.addi %74, %66 : index
  scf.for %arg0 = %c0 to %57 step %c1 {
    scf.for %arg1 = %c0 to %71 step %c1 {
      %76 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%73, %arg0]
      %77 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%75, %arg1]
      %subview = memref.subview %15[%76, %77] [1, 1] [1, 1] : memref<?x?xf32, #gpu.address_space<global>> to memref<1x1xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
      memref.store %cst, %subview[%c0, %c0] : memref<1x1xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
    }
  }
  scf.for %arg0 = %c0 to %13 step %c1 {
    scf.for %arg1 = %c0 to %57 step %c1 {
      scf.for %arg2 = %c0 to %71 step %c1 {
        %76 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%73, %arg1]
        %subview = memref.subview %14[%76, %arg0] [1, 1] [1, 1] : memref<?x?xf32, #gpu.address_space<global>> to memref<1x1xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
        %77 = memref.load %subview[%c0, %c0] : memref<1x1xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
        %78 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%75, %arg2]
        %subview_0 = memref.subview %14[%arg0, %78] [1, 1] [1, 1] : memref<?x?xf32, #gpu.address_space<global>> to memref<1x1xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
        %79 = memref.load %subview_0[%c0, %c0] : memref<1x1xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
        %80 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%73, %arg1]
        %81 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%75, %arg2]
        %subview_1 = memref.subview %15[%80, %81] [1, 1] [1, 1] : memref<?x?xf32, #gpu.address_space<global>> to memref<1x1xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
        %82 = memref.load %subview_1[%c0, %c0] : memref<1x1xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
        %83 = arith.mulf %77, %79 : f32
        %84 = arith.addf %82, %83 : f32
        %85 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%73, %arg1]
        %86 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%75, %arg2]
        %subview_2 = memref.subview %15[%85, %86] [1, 1] [1, 1] : memref<?x?xf32, #gpu.address_space<global>> to memref<1x1xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
        memref.store %84, %subview_2[%c0, %c0] : memref<1x1xf32, strided<[?, 1], offset: ?>, #gpu.address_space<global>>
      }
    }
  }
  return
}

// -----// IR Dump After FoldMemRefAliasOps (fold-memref-alias-ops) //----- //
module {
  func.func @main_dispatch_0_matmul_DxDxD_f32() {
    %c8 = arith.constant 8 : index
    %c-128 = arith.constant -128 : index
    %c-32 = arith.constant -32 : index
    %c-1 = arith.constant -1 : index
    %c128 = arith.constant 128 : index
    %c32 = arith.constant 32 : index
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c32_i64 = arith.constant 32 : i64
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.interface.constant.load[0] : i32
    %1 = hal.interface.constant.load[1] : i32
    %2 = hal.interface.constant.load[2] : i32
    %3 = hal.interface.constant.load[3] : i32
    %4 = arith.extui %0 : i32 to i64
    %5 = arith.extui %1 : i32 to i64
    %6 = arith.shli %5, %c32_i64 : i64
    %7 = arith.ori %4, %6 : i64
    %8 = arith.index_castui %7 : i64 to index
    %9 = arith.extui %2 : i32 to i64
    %10 = arith.extui %3 : i32 to i64
    %11 = arith.shli %10, %c32_i64 : i64
    %12 = arith.ori %9, %11 : i64
    %13 = arith.index_castui %12 : i64 to index
    %14 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32, #gpu.address_space<global>>{%8, %13}
    memref.assume_alignment %14, 64 : memref<?x?xf32, #gpu.address_space<global>>
    %15 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : memref<?x?xf32, #gpu.address_space<global>>{%8, %13}
    memref.assume_alignment %15, 64 : memref<?x?xf32, #gpu.address_space<global>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %16 = arith.cmpi sle, %13, %c0 : index
    %17 = arith.subi %c0, %13 : index
    %18 = arith.subi %13, %c1 : index
    %19 = arith.select %16, %17, %18 : index
    %20 = arith.divsi %19, %c128 : index
    %21 = arith.subi %c0, %20 : index
    %22 = arith.addi %20, %c1 : index
    %23 = arith.select %16, %21, %22 : index
    %24 = arith.cmpi slt, %workgroup_id_x, %c0 : index
    %25 = arith.subi %c-1, %workgroup_id_x : index
    %26 = arith.select %24, %25, %workgroup_id_x : index
    %27 = arith.divsi %26, %23 : index
    %28 = arith.subi %c-1, %27 : index
    %29 = arith.select %24, %28, %27 : index
    %30 = arith.muli %29, %c-32 : index
    %31 = arith.addi %8, %30 : index
    %32 = arith.cmpi sgt, %31, %c32 : index
    %33 = arith.select %32, %c32, %31 : index
    %34 = arith.remsi %workgroup_id_x, %23 : index
    %35 = arith.cmpi slt, %34, %c0 : index
    %36 = arith.addi %34, %23 : index
    %37 = arith.select %35, %36, %34 : index
    %38 = arith.muli %37, %c-128 : index
    %39 = arith.addi %13, %38 : index
    %40 = arith.cmpi sgt, %39, %c128 : index
    %41 = arith.select %40, %c128, %39 : index
    %42 = gpu.thread_id  x
    %43 = gpu.thread_id  y
    %44 = arith.cmpi sle, %33, %c0 : index
    %45 = arith.subi %c0, %33 : index
    %46 = arith.subi %33, %c1 : index
    %47 = arith.select %44, %45, %46 : index
    %48 = arith.divsi %47, %c8 : index
    %49 = arith.subi %c0, %48 : index
    %50 = arith.addi %48, %c1 : index
    %51 = arith.select %44, %49, %50 : index
    %52 = arith.muli %43, %51 : index
    %53 = arith.subi %33, %52 : index
    %54 = arith.cmpi slt, %53, %51 : index
    %55 = arith.select %54, %53, %51 : index
    %56 = arith.cmpi slt, %55, %c0 : index
    %57 = arith.select %56, %c0, %55 : index
    %58 = arith.cmpi sle, %41, %c0 : index
    %59 = arith.subi %c0, %41 : index
    %60 = arith.subi %41, %c1 : index
    %61 = arith.select %58, %59, %60 : index
    %62 = arith.divsi %61, %c32 : index
    %63 = arith.subi %c0, %62 : index
    %64 = arith.addi %62, %c1 : index
    %65 = arith.select %58, %63, %64 : index
    %66 = arith.muli %42, %65 : index
    %67 = arith.subi %41, %66 : index
    %68 = arith.cmpi slt, %67, %65 : index
    %69 = arith.select %68, %67, %65 : index
    %70 = arith.cmpi slt, %69, %c0 : index
    %71 = arith.select %70, %c0, %69 : index
    %72 = arith.muli %29, %c32 : index
    %73 = arith.addi %72, %52 : index
    %74 = arith.muli %37, %c128 : index
    %75 = arith.addi %74, %66 : index
    scf.for %arg0 = %c0 to %57 step %c1 {
      scf.for %arg1 = %c0 to %71 step %c1 {
        %76 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%73, %arg0]
        %77 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%75, %arg1]
        memref.store %cst, %15[%76, %77] : memref<?x?xf32, #gpu.address_space<global>>
      }
    }
    scf.for %arg0 = %c0 to %13 step %c1 {
      scf.for %arg1 = %c0 to %57 step %c1 {
        scf.for %arg2 = %c0 to %71 step %c1 {
          %76 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%73, %arg1]
          %77 = memref.load %14[%76, %arg0] : memref<?x?xf32, #gpu.address_space<global>>
          %78 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%75, %arg2]
          %79 = memref.load %14[%arg0, %78] : memref<?x?xf32, #gpu.address_space<global>>
          %80 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%73, %arg1]
          %81 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%75, %arg2]
          %82 = memref.load %15[%80, %81] : memref<?x?xf32, #gpu.address_space<global>>
          %83 = arith.mulf %77, %79 : f32
          %84 = arith.addf %82, %83 : f32
          %85 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%73, %arg1]
          %86 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%75, %arg2]
          memref.store %84, %15[%85, %86] : memref<?x?xf32, #gpu.address_space<global>>
        }
      }
    }
    return
  }
}

// -----// IR Dump After ExpandStridedMetadata (expand-strided-metadata) //----- //
module {
  func.func @main_dispatch_0_matmul_DxDxD_f32() {
    %c8 = arith.constant 8 : index
    %c-128 = arith.constant -128 : index
    %c-32 = arith.constant -32 : index
    %c-1 = arith.constant -1 : index
    %c128 = arith.constant 128 : index
    %c32 = arith.constant 32 : index
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c32_i64 = arith.constant 32 : i64
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.interface.constant.load[0] : i32
    %1 = hal.interface.constant.load[1] : i32
    %2 = hal.interface.constant.load[2] : i32
    %3 = hal.interface.constant.load[3] : i32
    %4 = arith.extui %0 : i32 to i64
    %5 = arith.extui %1 : i32 to i64
    %6 = arith.shli %5, %c32_i64 : i64
    %7 = arith.ori %4, %6 : i64
    %8 = arith.index_castui %7 : i64 to index
    %9 = arith.extui %2 : i32 to i64
    %10 = arith.extui %3 : i32 to i64
    %11 = arith.shli %10, %c32_i64 : i64
    %12 = arith.ori %9, %11 : i64
    %13 = arith.index_castui %12 : i64 to index
    %14 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32, #gpu.address_space<global>>{%8, %13}
    memref.assume_alignment %14, 64 : memref<?x?xf32, #gpu.address_space<global>>
    %15 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : memref<?x?xf32, #gpu.address_space<global>>{%8, %13}
    memref.assume_alignment %15, 64 : memref<?x?xf32, #gpu.address_space<global>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %16 = arith.cmpi sle, %13, %c0 : index
    %17 = arith.subi %c0, %13 : index
    %18 = arith.subi %13, %c1 : index
    %19 = arith.select %16, %17, %18 : index
    %20 = arith.divsi %19, %c128 : index
    %21 = arith.subi %c0, %20 : index
    %22 = arith.addi %20, %c1 : index
    %23 = arith.select %16, %21, %22 : index
    %24 = arith.cmpi slt, %workgroup_id_x, %c0 : index
    %25 = arith.subi %c-1, %workgroup_id_x : index
    %26 = arith.select %24, %25, %workgroup_id_x : index
    %27 = arith.divsi %26, %23 : index
    %28 = arith.subi %c-1, %27 : index
    %29 = arith.select %24, %28, %27 : index
    %30 = arith.muli %29, %c-32 : index
    %31 = arith.addi %8, %30 : index
    %32 = arith.cmpi sgt, %31, %c32 : index
    %33 = arith.select %32, %c32, %31 : index
    %34 = arith.remsi %workgroup_id_x, %23 : index
    %35 = arith.cmpi slt, %34, %c0 : index
    %36 = arith.addi %34, %23 : index
    %37 = arith.select %35, %36, %34 : index
    %38 = arith.muli %37, %c-128 : index
    %39 = arith.addi %13, %38 : index
    %40 = arith.cmpi sgt, %39, %c128 : index
    %41 = arith.select %40, %c128, %39 : index
    %42 = gpu.thread_id  x
    %43 = gpu.thread_id  y
    %44 = arith.cmpi sle, %33, %c0 : index
    %45 = arith.subi %c0, %33 : index
    %46 = arith.subi %33, %c1 : index
    %47 = arith.select %44, %45, %46 : index
    %48 = arith.divsi %47, %c8 : index
    %49 = arith.subi %c0, %48 : index
    %50 = arith.addi %48, %c1 : index
    %51 = arith.select %44, %49, %50 : index
    %52 = arith.muli %43, %51 : index
    %53 = arith.subi %33, %52 : index
    %54 = arith.cmpi slt, %53, %51 : index
    %55 = arith.select %54, %53, %51 : index
    %56 = arith.cmpi slt, %55, %c0 : index
    %57 = arith.select %56, %c0, %55 : index
    %58 = arith.cmpi sle, %41, %c0 : index
    %59 = arith.subi %c0, %41 : index
    %60 = arith.subi %41, %c1 : index
    %61 = arith.select %58, %59, %60 : index
    %62 = arith.divsi %61, %c32 : index
    %63 = arith.subi %c0, %62 : index
    %64 = arith.addi %62, %c1 : index
    %65 = arith.select %58, %63, %64 : index
    %66 = arith.muli %42, %65 : index
    %67 = arith.subi %41, %66 : index
    %68 = arith.cmpi slt, %67, %65 : index
    %69 = arith.select %68, %67, %65 : index
    %70 = arith.cmpi slt, %69, %c0 : index
    %71 = arith.select %70, %c0, %69 : index
    %72 = arith.muli %29, %c32 : index
    %73 = arith.addi %72, %52 : index
    %74 = arith.muli %37, %c128 : index
    %75 = arith.addi %74, %66 : index
    scf.for %arg0 = %c0 to %57 step %c1 {
      scf.for %arg1 = %c0 to %71 step %c1 {
        %76 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%73, %arg0]
        %77 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%75, %arg1]
        memref.store %cst, %15[%76, %77] : memref<?x?xf32, #gpu.address_space<global>>
      }
    }
    scf.for %arg0 = %c0 to %13 step %c1 {
      scf.for %arg1 = %c0 to %57 step %c1 {
        scf.for %arg2 = %c0 to %71 step %c1 {
          %76 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%73, %arg1]
          %77 = memref.load %14[%76, %arg0] : memref<?x?xf32, #gpu.address_space<global>>
          %78 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%75, %arg2]
          %79 = memref.load %14[%arg0, %78] : memref<?x?xf32, #gpu.address_space<global>>
          %80 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%73, %arg1]
          %81 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%75, %arg2]
          %82 = memref.load %15[%80, %81] : memref<?x?xf32, #gpu.address_space<global>>
          %83 = arith.mulf %77, %79 : f32
          %84 = arith.addf %82, %83 : f32
          %85 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%73, %arg1]
          %86 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%75, %arg2]
          memref.store %84, %15[%85, %86] : memref<?x?xf32, #gpu.address_space<global>>
        }
      }
    }
    return
  }
}

// -----// IR Dump After LoopInvariantCodeMotion (loop-invariant-code-motion) //----- //
module {
  func.func @main_dispatch_0_matmul_DxDxD_f32() {
    %c8 = arith.constant 8 : index
    %c-128 = arith.constant -128 : index
    %c-32 = arith.constant -32 : index
    %c-1 = arith.constant -1 : index
    %c128 = arith.constant 128 : index
    %c32 = arith.constant 32 : index
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c32_i64 = arith.constant 32 : i64
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.interface.constant.load[0] : i32
    %1 = hal.interface.constant.load[1] : i32
    %2 = hal.interface.constant.load[2] : i32
    %3 = hal.interface.constant.load[3] : i32
    %4 = arith.extui %0 : i32 to i64
    %5 = arith.extui %1 : i32 to i64
    %6 = arith.shli %5, %c32_i64 : i64
    %7 = arith.ori %4, %6 : i64
    %8 = arith.index_castui %7 : i64 to index
    %9 = arith.extui %2 : i32 to i64
    %10 = arith.extui %3 : i32 to i64
    %11 = arith.shli %10, %c32_i64 : i64
    %12 = arith.ori %9, %11 : i64
    %13 = arith.index_castui %12 : i64 to index
    %14 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32, #gpu.address_space<global>>{%8, %13}
    memref.assume_alignment %14, 64 : memref<?x?xf32, #gpu.address_space<global>>
    %15 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : memref<?x?xf32, #gpu.address_space<global>>{%8, %13}
    memref.assume_alignment %15, 64 : memref<?x?xf32, #gpu.address_space<global>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %16 = arith.cmpi sle, %13, %c0 : index
    %17 = arith.subi %c0, %13 : index
    %18 = arith.subi %13, %c1 : index
    %19 = arith.select %16, %17, %18 : index
    %20 = arith.divsi %19, %c128 : index
    %21 = arith.subi %c0, %20 : index
    %22 = arith.addi %20, %c1 : index
    %23 = arith.select %16, %21, %22 : index
    %24 = arith.cmpi slt, %workgroup_id_x, %c0 : index
    %25 = arith.subi %c-1, %workgroup_id_x : index
    %26 = arith.select %24, %25, %workgroup_id_x : index
    %27 = arith.divsi %26, %23 : index
    %28 = arith.subi %c-1, %27 : index
    %29 = arith.select %24, %28, %27 : index
    %30 = arith.muli %29, %c-32 : index
    %31 = arith.addi %8, %30 : index
    %32 = arith.cmpi sgt, %31, %c32 : index
    %33 = arith.select %32, %c32, %31 : index
    %34 = arith.remsi %workgroup_id_x, %23 : index
    %35 = arith.cmpi slt, %34, %c0 : index
    %36 = arith.addi %34, %23 : index
    %37 = arith.select %35, %36, %34 : index
    %38 = arith.muli %37, %c-128 : index
    %39 = arith.addi %13, %38 : index
    %40 = arith.cmpi sgt, %39, %c128 : index
    %41 = arith.select %40, %c128, %39 : index
    %42 = gpu.thread_id  x
    %43 = gpu.thread_id  y
    %44 = arith.cmpi sle, %33, %c0 : index
    %45 = arith.subi %c0, %33 : index
    %46 = arith.subi %33, %c1 : index
    %47 = arith.select %44, %45, %46 : index
    %48 = arith.divsi %47, %c8 : index
    %49 = arith.subi %c0, %48 : index
    %50 = arith.addi %48, %c1 : index
    %51 = arith.select %44, %49, %50 : index
    %52 = arith.muli %43, %51 : index
    %53 = arith.subi %33, %52 : index
    %54 = arith.cmpi slt, %53, %51 : index
    %55 = arith.select %54, %53, %51 : index
    %56 = arith.cmpi slt, %55, %c0 : index
    %57 = arith.select %56, %c0, %55 : index
    %58 = arith.cmpi sle, %41, %c0 : index
    %59 = arith.subi %c0, %41 : index
    %60 = arith.subi %41, %c1 : index
    %61 = arith.select %58, %59, %60 : index
    %62 = arith.divsi %61, %c32 : index
    %63 = arith.subi %c0, %62 : index
    %64 = arith.addi %62, %c1 : index
    %65 = arith.select %58, %63, %64 : index
    %66 = arith.muli %42, %65 : index
    %67 = arith.subi %41, %66 : index
    %68 = arith.cmpi slt, %67, %65 : index
    %69 = arith.select %68, %67, %65 : index
    %70 = arith.cmpi slt, %69, %c0 : index
    %71 = arith.select %70, %c0, %69 : index
    %72 = arith.muli %29, %c32 : index
    %73 = arith.addi %72, %52 : index
    %74 = arith.muli %37, %c128 : index
    %75 = arith.addi %74, %66 : index
    scf.for %arg0 = %c0 to %57 step %c1 {
      %76 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%73, %arg0]
      scf.for %arg1 = %c0 to %71 step %c1 {
        %77 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%75, %arg1]
        memref.store %cst, %15[%76, %77] : memref<?x?xf32, #gpu.address_space<global>>
      }
    }
    scf.for %arg0 = %c0 to %13 step %c1 {
      scf.for %arg1 = %c0 to %57 step %c1 {
        %76 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%73, %arg1]
        %77 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%73, %arg1]
        %78 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%73, %arg1]
        scf.for %arg2 = %c0 to %71 step %c1 {
          %79 = memref.load %14[%76, %arg0] : memref<?x?xf32, #gpu.address_space<global>>
          %80 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%75, %arg2]
          %81 = memref.load %14[%arg0, %80] : memref<?x?xf32, #gpu.address_space<global>>
          %82 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%75, %arg2]
          %83 = memref.load %15[%77, %82] : memref<?x?xf32, #gpu.address_space<global>>
          %84 = arith.mulf %79, %81 : f32
          %85 = arith.addf %83, %84 : f32
          %86 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%75, %arg2]
          memref.store %85, %15[%78, %86] : memref<?x?xf32, #gpu.address_space<global>>
        }
      }
    }
    return
  }
}

// -----// IR Dump After DecomposeAffineOps (decompose-affine-ops) //----- //
module {
  func.func @main_dispatch_0_matmul_DxDxD_f32() {
    %c8 = arith.constant 8 : index
    %c-128 = arith.constant -128 : index
    %c-32 = arith.constant -32 : index
    %c-1 = arith.constant -1 : index
    %c128 = arith.constant 128 : index
    %c32 = arith.constant 32 : index
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c32_i64 = arith.constant 32 : i64
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.interface.constant.load[0] : i32
    %1 = hal.interface.constant.load[1] : i32
    %2 = hal.interface.constant.load[2] : i32
    %3 = hal.interface.constant.load[3] : i32
    %4 = arith.extui %0 : i32 to i64
    %5 = arith.extui %1 : i32 to i64
    %6 = arith.shli %5, %c32_i64 : i64
    %7 = arith.ori %4, %6 : i64
    %8 = arith.index_castui %7 : i64 to index
    %9 = arith.extui %2 : i32 to i64
    %10 = arith.extui %3 : i32 to i64
    %11 = arith.shli %10, %c32_i64 : i64
    %12 = arith.ori %9, %11 : i64
    %13 = arith.index_castui %12 : i64 to index
    %14 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32, #gpu.address_space<global>>{%8, %13}
    memref.assume_alignment %14, 64 : memref<?x?xf32, #gpu.address_space<global>>
    %15 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : memref<?x?xf32, #gpu.address_space<global>>{%8, %13}
    memref.assume_alignment %15, 64 : memref<?x?xf32, #gpu.address_space<global>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %16 = arith.cmpi sle, %13, %c0 : index
    %17 = arith.subi %c0, %13 : index
    %18 = arith.subi %13, %c1 : index
    %19 = arith.select %16, %17, %18 : index
    %20 = arith.divsi %19, %c128 : index
    %21 = arith.subi %c0, %20 : index
    %22 = arith.addi %20, %c1 : index
    %23 = arith.select %16, %21, %22 : index
    %24 = arith.cmpi slt, %workgroup_id_x, %c0 : index
    %25 = arith.subi %c-1, %workgroup_id_x : index
    %26 = arith.select %24, %25, %workgroup_id_x : index
    %27 = arith.divsi %26, %23 : index
    %28 = arith.subi %c-1, %27 : index
    %29 = arith.select %24, %28, %27 : index
    %30 = arith.muli %29, %c-32 : index
    %31 = arith.addi %8, %30 : index
    %32 = arith.cmpi sgt, %31, %c32 : index
    %33 = arith.select %32, %c32, %31 : index
    %34 = arith.remsi %workgroup_id_x, %23 : index
    %35 = arith.cmpi slt, %34, %c0 : index
    %36 = arith.addi %34, %23 : index
    %37 = arith.select %35, %36, %34 : index
    %38 = arith.muli %37, %c-128 : index
    %39 = arith.addi %13, %38 : index
    %40 = arith.cmpi sgt, %39, %c128 : index
    %41 = arith.select %40, %c128, %39 : index
    %42 = gpu.thread_id  x
    %43 = gpu.thread_id  y
    %44 = arith.cmpi sle, %33, %c0 : index
    %45 = arith.subi %c0, %33 : index
    %46 = arith.subi %33, %c1 : index
    %47 = arith.select %44, %45, %46 : index
    %48 = arith.divsi %47, %c8 : index
    %49 = arith.subi %c0, %48 : index
    %50 = arith.addi %48, %c1 : index
    %51 = arith.select %44, %49, %50 : index
    %52 = arith.muli %43, %51 : index
    %53 = arith.subi %33, %52 : index
    %54 = arith.cmpi slt, %53, %51 : index
    %55 = arith.select %54, %53, %51 : index
    %56 = arith.cmpi slt, %55, %c0 : index
    %57 = arith.select %56, %c0, %55 : index
    %58 = arith.cmpi sle, %41, %c0 : index
    %59 = arith.subi %c0, %41 : index
    %60 = arith.subi %41, %c1 : index
    %61 = arith.select %58, %59, %60 : index
    %62 = arith.divsi %61, %c32 : index
    %63 = arith.subi %c0, %62 : index
    %64 = arith.addi %62, %c1 : index
    %65 = arith.select %58, %63, %64 : index
    %66 = arith.muli %42, %65 : index
    %67 = arith.subi %41, %66 : index
    %68 = arith.cmpi slt, %67, %65 : index
    %69 = arith.select %68, %67, %65 : index
    %70 = arith.cmpi slt, %69, %c0 : index
    %71 = arith.select %70, %c0, %69 : index
    %72 = arith.muli %29, %c32 : index
    %73 = arith.addi %72, %52 : index
    %74 = arith.muli %37, %c128 : index
    %75 = arith.addi %74, %66 : index
    scf.for %arg0 = %c0 to %57 step %c1 {
      %76 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%73, %arg0]
      scf.for %arg1 = %c0 to %71 step %c1 {
        %77 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%75, %arg1]
        memref.store %cst, %15[%76, %77] : memref<?x?xf32, #gpu.address_space<global>>
      }
    }
    scf.for %arg0 = %c0 to %13 step %c1 {
      scf.for %arg1 = %c0 to %57 step %c1 {
        %76 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%73, %arg1]
        %77 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%73, %arg1]
        %78 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%73, %arg1]
        scf.for %arg2 = %c0 to %71 step %c1 {
          %79 = memref.load %14[%76, %arg0] : memref<?x?xf32, #gpu.address_space<global>>
          %80 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%75, %arg2]
          %81 = memref.load %14[%arg0, %80] : memref<?x?xf32, #gpu.address_space<global>>
          %82 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%75, %arg2]
          %83 = memref.load %15[%77, %82] : memref<?x?xf32, #gpu.address_space<global>>
          %84 = arith.mulf %79, %81 : f32
          %85 = arith.addf %83, %84 : f32
          %86 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%75, %arg2]
          memref.store %85, %15[%78, %86] : memref<?x?xf32, #gpu.address_space<global>>
        }
      }
    }
    return
  }
}

// -----// IR Dump After CSE (cse) //----- //
module {
  func.func @main_dispatch_0_matmul_DxDxD_f32() {
    %c8 = arith.constant 8 : index
    %c-128 = arith.constant -128 : index
    %c-32 = arith.constant -32 : index
    %c-1 = arith.constant -1 : index
    %c128 = arith.constant 128 : index
    %c32 = arith.constant 32 : index
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c32_i64 = arith.constant 32 : i64
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.interface.constant.load[0] : i32
    %1 = hal.interface.constant.load[1] : i32
    %2 = hal.interface.constant.load[2] : i32
    %3 = hal.interface.constant.load[3] : i32
    %4 = arith.extui %0 : i32 to i64
    %5 = arith.extui %1 : i32 to i64
    %6 = arith.shli %5, %c32_i64 : i64
    %7 = arith.ori %4, %6 : i64
    %8 = arith.index_castui %7 : i64 to index
    %9 = arith.extui %2 : i32 to i64
    %10 = arith.extui %3 : i32 to i64
    %11 = arith.shli %10, %c32_i64 : i64
    %12 = arith.ori %9, %11 : i64
    %13 = arith.index_castui %12 : i64 to index
    %14 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32, #gpu.address_space<global>>{%8, %13}
    memref.assume_alignment %14, 64 : memref<?x?xf32, #gpu.address_space<global>>
    %15 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : memref<?x?xf32, #gpu.address_space<global>>{%8, %13}
    memref.assume_alignment %15, 64 : memref<?x?xf32, #gpu.address_space<global>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %16 = arith.cmpi sle, %13, %c0 : index
    %17 = arith.subi %c0, %13 : index
    %18 = arith.subi %13, %c1 : index
    %19 = arith.select %16, %17, %18 : index
    %20 = arith.divsi %19, %c128 : index
    %21 = arith.subi %c0, %20 : index
    %22 = arith.addi %20, %c1 : index
    %23 = arith.select %16, %21, %22 : index
    %24 = arith.cmpi slt, %workgroup_id_x, %c0 : index
    %25 = arith.subi %c-1, %workgroup_id_x : index
    %26 = arith.select %24, %25, %workgroup_id_x : index
    %27 = arith.divsi %26, %23 : index
    %28 = arith.subi %c-1, %27 : index
    %29 = arith.select %24, %28, %27 : index
    %30 = arith.muli %29, %c-32 : index
    %31 = arith.addi %8, %30 : index
    %32 = arith.cmpi sgt, %31, %c32 : index
    %33 = arith.select %32, %c32, %31 : index
    %34 = arith.remsi %workgroup_id_x, %23 : index
    %35 = arith.cmpi slt, %34, %c0 : index
    %36 = arith.addi %34, %23 : index
    %37 = arith.select %35, %36, %34 : index
    %38 = arith.muli %37, %c-128 : index
    %39 = arith.addi %13, %38 : index
    %40 = arith.cmpi sgt, %39, %c128 : index
    %41 = arith.select %40, %c128, %39 : index
    %42 = gpu.thread_id  x
    %43 = gpu.thread_id  y
    %44 = arith.cmpi sle, %33, %c0 : index
    %45 = arith.subi %c0, %33 : index
    %46 = arith.subi %33, %c1 : index
    %47 = arith.select %44, %45, %46 : index
    %48 = arith.divsi %47, %c8 : index
    %49 = arith.subi %c0, %48 : index
    %50 = arith.addi %48, %c1 : index
    %51 = arith.select %44, %49, %50 : index
    %52 = arith.muli %43, %51 : index
    %53 = arith.subi %33, %52 : index
    %54 = arith.cmpi slt, %53, %51 : index
    %55 = arith.select %54, %53, %51 : index
    %56 = arith.cmpi slt, %55, %c0 : index
    %57 = arith.select %56, %c0, %55 : index
    %58 = arith.cmpi sle, %41, %c0 : index
    %59 = arith.subi %c0, %41 : index
    %60 = arith.subi %41, %c1 : index
    %61 = arith.select %58, %59, %60 : index
    %62 = arith.divsi %61, %c32 : index
    %63 = arith.subi %c0, %62 : index
    %64 = arith.addi %62, %c1 : index
    %65 = arith.select %58, %63, %64 : index
    %66 = arith.muli %42, %65 : index
    %67 = arith.subi %41, %66 : index
    %68 = arith.cmpi slt, %67, %65 : index
    %69 = arith.select %68, %67, %65 : index
    %70 = arith.cmpi slt, %69, %c0 : index
    %71 = arith.select %70, %c0, %69 : index
    %72 = arith.muli %29, %c32 : index
    %73 = arith.addi %72, %52 : index
    %74 = arith.muli %37, %c128 : index
    %75 = arith.addi %74, %66 : index
    scf.for %arg0 = %c0 to %57 step %c1 {
      %76 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%73, %arg0]
      scf.for %arg1 = %c0 to %71 step %c1 {
        %77 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%75, %arg1]
        memref.store %cst, %15[%76, %77] : memref<?x?xf32, #gpu.address_space<global>>
      }
    }
    scf.for %arg0 = %c0 to %13 step %c1 {
      scf.for %arg1 = %c0 to %57 step %c1 {
        %76 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%73, %arg1]
        scf.for %arg2 = %c0 to %71 step %c1 {
          %77 = memref.load %14[%76, %arg0] : memref<?x?xf32, #gpu.address_space<global>>
          %78 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%75, %arg2]
          %79 = memref.load %14[%arg0, %78] : memref<?x?xf32, #gpu.address_space<global>>
          %80 = memref.load %15[%76, %78] : memref<?x?xf32, #gpu.address_space<global>>
          %81 = arith.mulf %77, %79 : f32
          %82 = arith.addf %80, %81 : f32
          memref.store %82, %15[%76, %78] : memref<?x?xf32, #gpu.address_space<global>>
        }
      }
    }
    return
  }
}

// -----// IR Dump After LoopInvariantCodeMotion (loop-invariant-code-motion) //----- //
module {
  func.func @main_dispatch_0_matmul_DxDxD_f32() {
    %c8 = arith.constant 8 : index
    %c-128 = arith.constant -128 : index
    %c-32 = arith.constant -32 : index
    %c-1 = arith.constant -1 : index
    %c128 = arith.constant 128 : index
    %c32 = arith.constant 32 : index
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c32_i64 = arith.constant 32 : i64
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.interface.constant.load[0] : i32
    %1 = hal.interface.constant.load[1] : i32
    %2 = hal.interface.constant.load[2] : i32
    %3 = hal.interface.constant.load[3] : i32
    %4 = arith.extui %0 : i32 to i64
    %5 = arith.extui %1 : i32 to i64
    %6 = arith.shli %5, %c32_i64 : i64
    %7 = arith.ori %4, %6 : i64
    %8 = arith.index_castui %7 : i64 to index
    %9 = arith.extui %2 : i32 to i64
    %10 = arith.extui %3 : i32 to i64
    %11 = arith.shli %10, %c32_i64 : i64
    %12 = arith.ori %9, %11 : i64
    %13 = arith.index_castui %12 : i64 to index
    %14 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32, #gpu.address_space<global>>{%8, %13}
    memref.assume_alignment %14, 64 : memref<?x?xf32, #gpu.address_space<global>>
    %15 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : memref<?x?xf32, #gpu.address_space<global>>{%8, %13}
    memref.assume_alignment %15, 64 : memref<?x?xf32, #gpu.address_space<global>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %16 = arith.cmpi sle, %13, %c0 : index
    %17 = arith.subi %c0, %13 : index
    %18 = arith.subi %13, %c1 : index
    %19 = arith.select %16, %17, %18 : index
    %20 = arith.divsi %19, %c128 : index
    %21 = arith.subi %c0, %20 : index
    %22 = arith.addi %20, %c1 : index
    %23 = arith.select %16, %21, %22 : index
    %24 = arith.cmpi slt, %workgroup_id_x, %c0 : index
    %25 = arith.subi %c-1, %workgroup_id_x : index
    %26 = arith.select %24, %25, %workgroup_id_x : index
    %27 = arith.divsi %26, %23 : index
    %28 = arith.subi %c-1, %27 : index
    %29 = arith.select %24, %28, %27 : index
    %30 = arith.muli %29, %c-32 : index
    %31 = arith.addi %8, %30 : index
    %32 = arith.cmpi sgt, %31, %c32 : index
    %33 = arith.select %32, %c32, %31 : index
    %34 = arith.remsi %workgroup_id_x, %23 : index
    %35 = arith.cmpi slt, %34, %c0 : index
    %36 = arith.addi %34, %23 : index
    %37 = arith.select %35, %36, %34 : index
    %38 = arith.muli %37, %c-128 : index
    %39 = arith.addi %13, %38 : index
    %40 = arith.cmpi sgt, %39, %c128 : index
    %41 = arith.select %40, %c128, %39 : index
    %42 = gpu.thread_id  x
    %43 = gpu.thread_id  y
    %44 = arith.cmpi sle, %33, %c0 : index
    %45 = arith.subi %c0, %33 : index
    %46 = arith.subi %33, %c1 : index
    %47 = arith.select %44, %45, %46 : index
    %48 = arith.divsi %47, %c8 : index
    %49 = arith.subi %c0, %48 : index
    %50 = arith.addi %48, %c1 : index
    %51 = arith.select %44, %49, %50 : index
    %52 = arith.muli %43, %51 : index
    %53 = arith.subi %33, %52 : index
    %54 = arith.cmpi slt, %53, %51 : index
    %55 = arith.select %54, %53, %51 : index
    %56 = arith.cmpi slt, %55, %c0 : index
    %57 = arith.select %56, %c0, %55 : index
    %58 = arith.cmpi sle, %41, %c0 : index
    %59 = arith.subi %c0, %41 : index
    %60 = arith.subi %41, %c1 : index
    %61 = arith.select %58, %59, %60 : index
    %62 = arith.divsi %61, %c32 : index
    %63 = arith.subi %c0, %62 : index
    %64 = arith.addi %62, %c1 : index
    %65 = arith.select %58, %63, %64 : index
    %66 = arith.muli %42, %65 : index
    %67 = arith.subi %41, %66 : index
    %68 = arith.cmpi slt, %67, %65 : index
    %69 = arith.select %68, %67, %65 : index
    %70 = arith.cmpi slt, %69, %c0 : index
    %71 = arith.select %70, %c0, %69 : index
    %72 = arith.muli %29, %c32 : index
    %73 = arith.addi %72, %52 : index
    %74 = arith.muli %37, %c128 : index
    %75 = arith.addi %74, %66 : index
    scf.for %arg0 = %c0 to %57 step %c1 {
      %76 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%73, %arg0]
      scf.for %arg1 = %c0 to %71 step %c1 {
        %77 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%75, %arg1]
        memref.store %cst, %15[%76, %77] : memref<?x?xf32, #gpu.address_space<global>>
      }
    }
    scf.for %arg0 = %c0 to %13 step %c1 {
      scf.for %arg1 = %c0 to %57 step %c1 {
        %76 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%73, %arg1]
        scf.for %arg2 = %c0 to %71 step %c1 {
          %77 = memref.load %14[%76, %arg0] : memref<?x?xf32, #gpu.address_space<global>>
          %78 = affine.apply affine_map<()[s0, s1] -> (s0 + s1)>()[%75, %arg2]
          %79 = memref.load %14[%arg0, %78] : memref<?x?xf32, #gpu.address_space<global>>
          %80 = memref.load %15[%76, %78] : memref<?x?xf32, #gpu.address_space<global>>
          %81 = arith.mulf %77, %79 : f32
          %82 = arith.addf %80, %81 : f32
          memref.store %82, %15[%76, %78] : memref<?x?xf32, #gpu.address_space<global>>
        }
      }
    }
    return
  }
}

// -----// IR Dump After ConvertAffineToStandard (lower-affine) //----- //
module {
  func.func @main_dispatch_0_matmul_DxDxD_f32() {
    %c8 = arith.constant 8 : index
    %c-128 = arith.constant -128 : index
    %c-32 = arith.constant -32 : index
    %c-1 = arith.constant -1 : index
    %c128 = arith.constant 128 : index
    %c32 = arith.constant 32 : index
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c32_i64 = arith.constant 32 : i64
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.interface.constant.load[0] : i32
    %1 = hal.interface.constant.load[1] : i32
    %2 = hal.interface.constant.load[2] : i32
    %3 = hal.interface.constant.load[3] : i32
    %4 = arith.extui %0 : i32 to i64
    %5 = arith.extui %1 : i32 to i64
    %6 = arith.shli %5, %c32_i64 : i64
    %7 = arith.ori %4, %6 : i64
    %8 = arith.index_castui %7 : i64 to index
    %9 = arith.extui %2 : i32 to i64
    %10 = arith.extui %3 : i32 to i64
    %11 = arith.shli %10, %c32_i64 : i64
    %12 = arith.ori %9, %11 : i64
    %13 = arith.index_castui %12 : i64 to index
    %14 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32, #gpu.address_space<global>>{%8, %13}
    memref.assume_alignment %14, 64 : memref<?x?xf32, #gpu.address_space<global>>
    %15 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : memref<?x?xf32, #gpu.address_space<global>>{%8, %13}
    memref.assume_alignment %15, 64 : memref<?x?xf32, #gpu.address_space<global>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %16 = arith.cmpi sle, %13, %c0 : index
    %17 = arith.subi %c0, %13 : index
    %18 = arith.subi %13, %c1 : index
    %19 = arith.select %16, %17, %18 : index
    %20 = arith.divsi %19, %c128 : index
    %21 = arith.subi %c0, %20 : index
    %22 = arith.addi %20, %c1 : index
    %23 = arith.select %16, %21, %22 : index
    %24 = arith.cmpi slt, %workgroup_id_x, %c0 : index
    %25 = arith.subi %c-1, %workgroup_id_x : index
    %26 = arith.select %24, %25, %workgroup_id_x : index
    %27 = arith.divsi %26, %23 : index
    %28 = arith.subi %c-1, %27 : index
    %29 = arith.select %24, %28, %27 : index
    %30 = arith.muli %29, %c-32 : index
    %31 = arith.addi %8, %30 : index
    %32 = arith.cmpi sgt, %31, %c32 : index
    %33 = arith.select %32, %c32, %31 : index
    %34 = arith.remsi %workgroup_id_x, %23 : index
    %35 = arith.cmpi slt, %34, %c0 : index
    %36 = arith.addi %34, %23 : index
    %37 = arith.select %35, %36, %34 : index
    %38 = arith.muli %37, %c-128 : index
    %39 = arith.addi %13, %38 : index
    %40 = arith.cmpi sgt, %39, %c128 : index
    %41 = arith.select %40, %c128, %39 : index
    %42 = gpu.thread_id  x
    %43 = gpu.thread_id  y
    %44 = arith.cmpi sle, %33, %c0 : index
    %45 = arith.subi %c0, %33 : index
    %46 = arith.subi %33, %c1 : index
    %47 = arith.select %44, %45, %46 : index
    %48 = arith.divsi %47, %c8 : index
    %49 = arith.subi %c0, %48 : index
    %50 = arith.addi %48, %c1 : index
    %51 = arith.select %44, %49, %50 : index
    %52 = arith.muli %43, %51 : index
    %53 = arith.subi %33, %52 : index
    %54 = arith.cmpi slt, %53, %51 : index
    %55 = arith.select %54, %53, %51 : index
    %56 = arith.cmpi slt, %55, %c0 : index
    %57 = arith.select %56, %c0, %55 : index
    %58 = arith.cmpi sle, %41, %c0 : index
    %59 = arith.subi %c0, %41 : index
    %60 = arith.subi %41, %c1 : index
    %61 = arith.select %58, %59, %60 : index
    %62 = arith.divsi %61, %c32 : index
    %63 = arith.subi %c0, %62 : index
    %64 = arith.addi %62, %c1 : index
    %65 = arith.select %58, %63, %64 : index
    %66 = arith.muli %42, %65 : index
    %67 = arith.subi %41, %66 : index
    %68 = arith.cmpi slt, %67, %65 : index
    %69 = arith.select %68, %67, %65 : index
    %70 = arith.cmpi slt, %69, %c0 : index
    %71 = arith.select %70, %c0, %69 : index
    %72 = arith.muli %29, %c32 : index
    %73 = arith.addi %72, %52 : index
    %74 = arith.muli %37, %c128 : index
    %75 = arith.addi %74, %66 : index
    scf.for %arg0 = %c0 to %57 step %c1 {
      %76 = arith.addi %73, %arg0 : index
      scf.for %arg1 = %c0 to %71 step %c1 {
        %77 = arith.addi %75, %arg1 : index
        memref.store %cst, %15[%76, %77] : memref<?x?xf32, #gpu.address_space<global>>
      }
    }
    scf.for %arg0 = %c0 to %13 step %c1 {
      scf.for %arg1 = %c0 to %57 step %c1 {
        %76 = arith.addi %73, %arg1 : index
        scf.for %arg2 = %c0 to %71 step %c1 {
          %77 = memref.load %14[%76, %arg0] : memref<?x?xf32, #gpu.address_space<global>>
          %78 = arith.addi %75, %arg2 : index
          %79 = memref.load %14[%arg0, %78] : memref<?x?xf32, #gpu.address_space<global>>
          %80 = memref.load %15[%76, %78] : memref<?x?xf32, #gpu.address_space<global>>
          %81 = arith.mulf %77, %79 : f32
          %82 = arith.addf %80, %81 : f32
          memref.store %82, %15[%76, %78] : memref<?x?xf32, #gpu.address_space<global>>
        }
      }
    }
    return
  }
}

// -----// IR Dump After GPUCheckResourceUsage (iree-codegen-gpu-check-resource-usage) //----- //
module {
  func.func @main_dispatch_0_matmul_DxDxD_f32() {
    %c8 = arith.constant 8 : index
    %c-128 = arith.constant -128 : index
    %c-32 = arith.constant -32 : index
    %c-1 = arith.constant -1 : index
    %c128 = arith.constant 128 : index
    %c32 = arith.constant 32 : index
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c32_i64 = arith.constant 32 : i64
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.interface.constant.load[0] : i32
    %1 = hal.interface.constant.load[1] : i32
    %2 = hal.interface.constant.load[2] : i32
    %3 = hal.interface.constant.load[3] : i32
    %4 = arith.extui %0 : i32 to i64
    %5 = arith.extui %1 : i32 to i64
    %6 = arith.shli %5, %c32_i64 : i64
    %7 = arith.ori %4, %6 : i64
    %8 = arith.index_castui %7 : i64 to index
    %9 = arith.extui %2 : i32 to i64
    %10 = arith.extui %3 : i32 to i64
    %11 = arith.shli %10, %c32_i64 : i64
    %12 = arith.ori %9, %11 : i64
    %13 = arith.index_castui %12 : i64 to index
    %14 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32, #gpu.address_space<global>>{%8, %13}
    memref.assume_alignment %14, 64 : memref<?x?xf32, #gpu.address_space<global>>
    %15 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : memref<?x?xf32, #gpu.address_space<global>>{%8, %13}
    memref.assume_alignment %15, 64 : memref<?x?xf32, #gpu.address_space<global>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %16 = arith.cmpi sle, %13, %c0 : index
    %17 = arith.subi %c0, %13 : index
    %18 = arith.subi %13, %c1 : index
    %19 = arith.select %16, %17, %18 : index
    %20 = arith.divsi %19, %c128 : index
    %21 = arith.subi %c0, %20 : index
    %22 = arith.addi %20, %c1 : index
    %23 = arith.select %16, %21, %22 : index
    %24 = arith.cmpi slt, %workgroup_id_x, %c0 : index
    %25 = arith.subi %c-1, %workgroup_id_x : index
    %26 = arith.select %24, %25, %workgroup_id_x : index
    %27 = arith.divsi %26, %23 : index
    %28 = arith.subi %c-1, %27 : index
    %29 = arith.select %24, %28, %27 : index
    %30 = arith.muli %29, %c-32 : index
    %31 = arith.addi %8, %30 : index
    %32 = arith.cmpi sgt, %31, %c32 : index
    %33 = arith.select %32, %c32, %31 : index
    %34 = arith.remsi %workgroup_id_x, %23 : index
    %35 = arith.cmpi slt, %34, %c0 : index
    %36 = arith.addi %34, %23 : index
    %37 = arith.select %35, %36, %34 : index
    %38 = arith.muli %37, %c-128 : index
    %39 = arith.addi %13, %38 : index
    %40 = arith.cmpi sgt, %39, %c128 : index
    %41 = arith.select %40, %c128, %39 : index
    %42 = gpu.thread_id  x
    %43 = gpu.thread_id  y
    %44 = arith.cmpi sle, %33, %c0 : index
    %45 = arith.subi %c0, %33 : index
    %46 = arith.subi %33, %c1 : index
    %47 = arith.select %44, %45, %46 : index
    %48 = arith.divsi %47, %c8 : index
    %49 = arith.subi %c0, %48 : index
    %50 = arith.addi %48, %c1 : index
    %51 = arith.select %44, %49, %50 : index
    %52 = arith.muli %43, %51 : index
    %53 = arith.subi %33, %52 : index
    %54 = arith.cmpi slt, %53, %51 : index
    %55 = arith.select %54, %53, %51 : index
    %56 = arith.cmpi slt, %55, %c0 : index
    %57 = arith.select %56, %c0, %55 : index
    %58 = arith.cmpi sle, %41, %c0 : index
    %59 = arith.subi %c0, %41 : index
    %60 = arith.subi %41, %c1 : index
    %61 = arith.select %58, %59, %60 : index
    %62 = arith.divsi %61, %c32 : index
    %63 = arith.subi %c0, %62 : index
    %64 = arith.addi %62, %c1 : index
    %65 = arith.select %58, %63, %64 : index
    %66 = arith.muli %42, %65 : index
    %67 = arith.subi %41, %66 : index
    %68 = arith.cmpi slt, %67, %65 : index
    %69 = arith.select %68, %67, %65 : index
    %70 = arith.cmpi slt, %69, %c0 : index
    %71 = arith.select %70, %c0, %69 : index
    %72 = arith.muli %29, %c32 : index
    %73 = arith.addi %72, %52 : index
    %74 = arith.muli %37, %c128 : index
    %75 = arith.addi %74, %66 : index
    scf.for %arg0 = %c0 to %57 step %c1 {
      %76 = arith.addi %73, %arg0 : index
      scf.for %arg1 = %c0 to %71 step %c1 {
        %77 = arith.addi %75, %arg1 : index
        memref.store %cst, %15[%76, %77] : memref<?x?xf32, #gpu.address_space<global>>
      }
    }
    scf.for %arg0 = %c0 to %13 step %c1 {
      scf.for %arg1 = %c0 to %57 step %c1 {
        %76 = arith.addi %73, %arg1 : index
        scf.for %arg2 = %c0 to %71 step %c1 {
          %77 = memref.load %14[%76, %arg0] : memref<?x?xf32, #gpu.address_space<global>>
          %78 = arith.addi %75, %arg2 : index
          %79 = memref.load %14[%arg0, %78] : memref<?x?xf32, #gpu.address_space<global>>
          %80 = memref.load %15[%76, %78] : memref<?x?xf32, #gpu.address_space<global>>
          %81 = arith.mulf %77, %79 : f32
          %82 = arith.addf %80, %81 : f32
          memref.store %82, %15[%76, %78] : memref<?x?xf32, #gpu.address_space<global>>
        }
      }
    }
    return
  }
}

// -----// IR Dump After SCFToControlFlow (convert-scf-to-cf) //----- //
func.func @main_dispatch_0_matmul_DxDxD_f32() {
  %c8 = arith.constant 8 : index
  %c-128 = arith.constant -128 : index
  %c-32 = arith.constant -32 : index
  %c-1 = arith.constant -1 : index
  %c128 = arith.constant 128 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c32_i64 = arith.constant 32 : i64
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.interface.constant.load[0] : i32
  %1 = hal.interface.constant.load[1] : i32
  %2 = hal.interface.constant.load[2] : i32
  %3 = hal.interface.constant.load[3] : i32
  %4 = arith.extui %0 : i32 to i64
  %5 = arith.extui %1 : i32 to i64
  %6 = arith.shli %5, %c32_i64 : i64
  %7 = arith.ori %4, %6 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %2 : i32 to i64
  %10 = arith.extui %3 : i32 to i64
  %11 = arith.shli %10, %c32_i64 : i64
  %12 = arith.ori %9, %11 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32, #gpu.address_space<global>>{%8, %13}
  memref.assume_alignment %14, 64 : memref<?x?xf32, #gpu.address_space<global>>
  %15 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : memref<?x?xf32, #gpu.address_space<global>>{%8, %13}
  memref.assume_alignment %15, 64 : memref<?x?xf32, #gpu.address_space<global>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %16 = arith.cmpi sle, %13, %c0 : index
  %17 = arith.subi %c0, %13 : index
  %18 = arith.subi %13, %c1 : index
  %19 = arith.select %16, %17, %18 : index
  %20 = arith.divsi %19, %c128 : index
  %21 = arith.subi %c0, %20 : index
  %22 = arith.addi %20, %c1 : index
  %23 = arith.select %16, %21, %22 : index
  %24 = arith.cmpi slt, %workgroup_id_x, %c0 : index
  %25 = arith.subi %c-1, %workgroup_id_x : index
  %26 = arith.select %24, %25, %workgroup_id_x : index
  %27 = arith.divsi %26, %23 : index
  %28 = arith.subi %c-1, %27 : index
  %29 = arith.select %24, %28, %27 : index
  %30 = arith.muli %29, %c-32 : index
  %31 = arith.addi %8, %30 : index
  %32 = arith.cmpi sgt, %31, %c32 : index
  %33 = arith.select %32, %c32, %31 : index
  %34 = arith.remsi %workgroup_id_x, %23 : index
  %35 = arith.cmpi slt, %34, %c0 : index
  %36 = arith.addi %34, %23 : index
  %37 = arith.select %35, %36, %34 : index
  %38 = arith.muli %37, %c-128 : index
  %39 = arith.addi %13, %38 : index
  %40 = arith.cmpi sgt, %39, %c128 : index
  %41 = arith.select %40, %c128, %39 : index
  %42 = gpu.thread_id  x
  %43 = gpu.thread_id  y
  %44 = arith.cmpi sle, %33, %c0 : index
  %45 = arith.subi %c0, %33 : index
  %46 = arith.subi %33, %c1 : index
  %47 = arith.select %44, %45, %46 : index
  %48 = arith.divsi %47, %c8 : index
  %49 = arith.subi %c0, %48 : index
  %50 = arith.addi %48, %c1 : index
  %51 = arith.select %44, %49, %50 : index
  %52 = arith.muli %43, %51 : index
  %53 = arith.subi %33, %52 : index
  %54 = arith.cmpi slt, %53, %51 : index
  %55 = arith.select %54, %53, %51 : index
  %56 = arith.cmpi slt, %55, %c0 : index
  %57 = arith.select %56, %c0, %55 : index
  %58 = arith.cmpi sle, %41, %c0 : index
  %59 = arith.subi %c0, %41 : index
  %60 = arith.subi %41, %c1 : index
  %61 = arith.select %58, %59, %60 : index
  %62 = arith.divsi %61, %c32 : index
  %63 = arith.subi %c0, %62 : index
  %64 = arith.addi %62, %c1 : index
  %65 = arith.select %58, %63, %64 : index
  %66 = arith.muli %42, %65 : index
  %67 = arith.subi %41, %66 : index
  %68 = arith.cmpi slt, %67, %65 : index
  %69 = arith.select %68, %67, %65 : index
  %70 = arith.cmpi slt, %69, %c0 : index
  %71 = arith.select %70, %c0, %69 : index
  %72 = arith.muli %29, %c32 : index
  %73 = arith.addi %72, %52 : index
  %74 = arith.muli %37, %c128 : index
  %75 = arith.addi %74, %66 : index
  cf.br ^bb1(%c0 : index)
^bb1(%76: index):  // 2 preds: ^bb0, ^bb5
  %77 = arith.cmpi slt, %76, %57 : index
  cf.cond_br %77, ^bb2, ^bb6
^bb2:  // pred: ^bb1
  %78 = arith.addi %73, %76 : index
  cf.br ^bb3(%c0 : index)
^bb3(%79: index):  // 2 preds: ^bb2, ^bb4
  %80 = arith.cmpi slt, %79, %71 : index
  cf.cond_br %80, ^bb4, ^bb5
^bb4:  // pred: ^bb3
  %81 = arith.addi %75, %79 : index
  memref.store %cst, %15[%78, %81] : memref<?x?xf32, #gpu.address_space<global>>
  %82 = arith.addi %79, %c1 : index
  cf.br ^bb3(%82 : index)
^bb5:  // pred: ^bb3
  %83 = arith.addi %76, %c1 : index
  cf.br ^bb1(%83 : index)
^bb6:  // pred: ^bb1
  cf.br ^bb7(%c0 : index)
^bb7(%84: index):  // 2 preds: ^bb6, ^bb14
  %85 = arith.cmpi slt, %84, %13 : index
  cf.cond_br %85, ^bb8, ^bb15
^bb8:  // pred: ^bb7
  cf.br ^bb9(%c0 : index)
^bb9(%86: index):  // 2 preds: ^bb8, ^bb13
  %87 = arith.cmpi slt, %86, %57 : index
  cf.cond_br %87, ^bb10, ^bb14
^bb10:  // pred: ^bb9
  %88 = arith.addi %73, %86 : index
  cf.br ^bb11(%c0 : index)
^bb11(%89: index):  // 2 preds: ^bb10, ^bb12
  %90 = arith.cmpi slt, %89, %71 : index
  cf.cond_br %90, ^bb12, ^bb13
^bb12:  // pred: ^bb11
  %91 = memref.load %14[%88, %84] : memref<?x?xf32, #gpu.address_space<global>>
  %92 = arith.addi %75, %89 : index
  %93 = memref.load %14[%84, %92] : memref<?x?xf32, #gpu.address_space<global>>
  %94 = memref.load %15[%88, %92] : memref<?x?xf32, #gpu.address_space<global>>
  %95 = arith.mulf %91, %93 : f32
  %96 = arith.addf %94, %95 : f32
  memref.store %96, %15[%88, %92] : memref<?x?xf32, #gpu.address_space<global>>
  %97 = arith.addi %89, %c1 : index
  cf.br ^bb11(%97 : index)
^bb13:  // pred: ^bb11
  %98 = arith.addi %86, %c1 : index
  cf.br ^bb9(%98 : index)
^bb14:  // pred: ^bb9
  %99 = arith.addi %84, %c1 : index
  cf.br ^bb7(%99 : index)
^bb15:  // pred: ^bb7
  return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main_dispatch_0_matmul_DxDxD_f32() {
  %c8 = arith.constant 8 : index
  %c-128 = arith.constant -128 : index
  %c-32 = arith.constant -32 : index
  %c-1 = arith.constant -1 : index
  %c128 = arith.constant 128 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c32_i64 = arith.constant 32 : i64
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.interface.constant.load[0] : i32
  %1 = hal.interface.constant.load[1] : i32
  %2 = hal.interface.constant.load[2] : i32
  %3 = hal.interface.constant.load[3] : i32
  %4 = arith.extui %0 : i32 to i64
  %5 = arith.extui %1 : i32 to i64
  %6 = arith.shli %5, %c32_i64 : i64
  %7 = arith.ori %4, %6 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %2 : i32 to i64
  %10 = arith.extui %3 : i32 to i64
  %11 = arith.shli %10, %c32_i64 : i64
  %12 = arith.ori %9, %11 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32, #gpu.address_space<global>>{%8, %13}
  memref.assume_alignment %14, 64 : memref<?x?xf32, #gpu.address_space<global>>
  %15 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : memref<?x?xf32, #gpu.address_space<global>>{%8, %13}
  memref.assume_alignment %15, 64 : memref<?x?xf32, #gpu.address_space<global>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %16 = arith.cmpi sle, %13, %c0 : index
  %17 = arith.subi %c0, %13 : index
  %18 = arith.subi %13, %c1 : index
  %19 = arith.select %16, %17, %18 : index
  %20 = arith.divsi %19, %c128 : index
  %21 = arith.subi %c0, %20 : index
  %22 = arith.addi %20, %c1 : index
  %23 = arith.select %16, %21, %22 : index
  %24 = arith.cmpi slt, %workgroup_id_x, %c0 : index
  %25 = arith.subi %c-1, %workgroup_id_x : index
  %26 = arith.select %24, %25, %workgroup_id_x : index
  %27 = arith.divsi %26, %23 : index
  %28 = arith.subi %c-1, %27 : index
  %29 = arith.select %24, %28, %27 : index
  %30 = arith.muli %29, %c-32 : index
  %31 = arith.addi %8, %30 : index
  %32 = arith.cmpi sgt, %31, %c32 : index
  %33 = arith.select %32, %c32, %31 : index
  %34 = arith.remsi %workgroup_id_x, %23 : index
  %35 = arith.cmpi slt, %34, %c0 : index
  %36 = arith.addi %34, %23 : index
  %37 = arith.select %35, %36, %34 : index
  %38 = arith.muli %37, %c-128 : index
  %39 = arith.addi %13, %38 : index
  %40 = arith.cmpi sgt, %39, %c128 : index
  %41 = arith.select %40, %c128, %39 : index
  %42 = gpu.thread_id  x
  %43 = gpu.thread_id  y
  %44 = arith.cmpi sle, %33, %c0 : index
  %45 = arith.subi %c0, %33 : index
  %46 = arith.subi %33, %c1 : index
  %47 = arith.select %44, %45, %46 : index
  %48 = arith.divsi %47, %c8 : index
  %49 = arith.subi %c0, %48 : index
  %50 = arith.addi %48, %c1 : index
  %51 = arith.select %44, %49, %50 : index
  %52 = arith.muli %43, %51 : index
  %53 = arith.subi %33, %52 : index
  %54 = arith.cmpi slt, %53, %51 : index
  %55 = arith.select %54, %53, %51 : index
  %56 = arith.cmpi slt, %55, %c0 : index
  %57 = arith.select %56, %c0, %55 : index
  %58 = arith.cmpi sle, %41, %c0 : index
  %59 = arith.subi %c0, %41 : index
  %60 = arith.subi %41, %c1 : index
  %61 = arith.select %58, %59, %60 : index
  %62 = arith.divsi %61, %c32 : index
  %63 = arith.subi %c0, %62 : index
  %64 = arith.addi %62, %c1 : index
  %65 = arith.select %58, %63, %64 : index
  %66 = arith.muli %42, %65 : index
  %67 = arith.subi %41, %66 : index
  %68 = arith.cmpi slt, %67, %65 : index
  %69 = arith.select %68, %67, %65 : index
  %70 = arith.cmpi slt, %69, %c0 : index
  %71 = arith.select %70, %c0, %69 : index
  %72 = arith.muli %29, %c32 : index
  %73 = arith.addi %72, %52 : index
  %74 = arith.muli %37, %c128 : index
  %75 = arith.addi %74, %66 : index
  cf.br ^bb1(%c0 : index)
^bb1(%76: index):  // 2 preds: ^bb0, ^bb5
  %77 = arith.cmpi slt, %76, %57 : index
  cf.cond_br %77, ^bb2, ^bb6(%c0 : index)
^bb2:  // pred: ^bb1
  %78 = arith.addi %73, %76 : index
  cf.br ^bb3(%c0 : index)
^bb3(%79: index):  // 2 preds: ^bb2, ^bb4
  %80 = arith.cmpi slt, %79, %71 : index
  cf.cond_br %80, ^bb4, ^bb5
^bb4:  // pred: ^bb3
  %81 = arith.addi %75, %79 : index
  memref.store %cst, %15[%78, %81] : memref<?x?xf32, #gpu.address_space<global>>
  %82 = arith.addi %79, %c1 : index
  cf.br ^bb3(%82 : index)
^bb5:  // pred: ^bb3
  %83 = arith.addi %76, %c1 : index
  cf.br ^bb1(%83 : index)
^bb6(%84: index):  // 2 preds: ^bb1, ^bb12
  %85 = arith.cmpi slt, %84, %13 : index
  cf.cond_br %85, ^bb7(%c0 : index), ^bb13
^bb7(%86: index):  // 2 preds: ^bb6, ^bb11
  %87 = arith.cmpi slt, %86, %57 : index
  cf.cond_br %87, ^bb8, ^bb12
^bb8:  // pred: ^bb7
  %88 = arith.addi %73, %86 : index
  cf.br ^bb9(%c0 : index)
^bb9(%89: index):  // 2 preds: ^bb8, ^bb10
  %90 = arith.cmpi slt, %89, %71 : index
  cf.cond_br %90, ^bb10, ^bb11
^bb10:  // pred: ^bb9
  %91 = memref.load %14[%88, %84] : memref<?x?xf32, #gpu.address_space<global>>
  %92 = arith.addi %75, %89 : index
  %93 = memref.load %14[%84, %92] : memref<?x?xf32, #gpu.address_space<global>>
  %94 = memref.load %15[%88, %92] : memref<?x?xf32, #gpu.address_space<global>>
  %95 = arith.mulf %91, %93 : f32
  %96 = arith.addf %94, %95 : f32
  memref.store %96, %15[%88, %92] : memref<?x?xf32, #gpu.address_space<global>>
  %97 = arith.addi %89, %c1 : index
  cf.br ^bb9(%97 : index)
^bb11:  // pred: ^bb9
  %98 = arith.addi %86, %c1 : index
  cf.br ^bb7(%98 : index)
^bb12:  // pred: ^bb7
  %99 = arith.addi %84, %c1 : index
  cf.br ^bb6(%99 : index)
^bb13:  // pred: ^bb6
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @main_dispatch_0_matmul_DxDxD_f32() {
  %c8 = arith.constant 8 : index
  %c-128 = arith.constant -128 : index
  %c-32 = arith.constant -32 : index
  %c-1 = arith.constant -1 : index
  %c128 = arith.constant 128 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c32_i64 = arith.constant 32 : i64
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.interface.constant.load[0] : i32
  %1 = hal.interface.constant.load[1] : i32
  %2 = hal.interface.constant.load[2] : i32
  %3 = hal.interface.constant.load[3] : i32
  %4 = arith.extui %0 : i32 to i64
  %5 = arith.extui %1 : i32 to i64
  %6 = arith.shli %5, %c32_i64 : i64
  %7 = arith.ori %4, %6 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %2 : i32 to i64
  %10 = arith.extui %3 : i32 to i64
  %11 = arith.shli %10, %c32_i64 : i64
  %12 = arith.ori %9, %11 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32, #gpu.address_space<global>>{%8, %13}
  memref.assume_alignment %14, 64 : memref<?x?xf32, #gpu.address_space<global>>
  %15 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : memref<?x?xf32, #gpu.address_space<global>>{%8, %13}
  memref.assume_alignment %15, 64 : memref<?x?xf32, #gpu.address_space<global>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %16 = arith.cmpi sle, %13, %c0 : index
  %17 = arith.subi %c0, %13 : index
  %18 = arith.subi %13, %c1 : index
  %19 = arith.select %16, %17, %18 : index
  %20 = arith.divsi %19, %c128 : index
  %21 = arith.subi %c0, %20 : index
  %22 = arith.addi %20, %c1 : index
  %23 = arith.select %16, %21, %22 : index
  %24 = arith.cmpi slt, %workgroup_id_x, %c0 : index
  %25 = arith.subi %c-1, %workgroup_id_x : index
  %26 = arith.select %24, %25, %workgroup_id_x : index
  %27 = arith.divsi %26, %23 : index
  %28 = arith.subi %c-1, %27 : index
  %29 = arith.select %24, %28, %27 : index
  %30 = arith.muli %29, %c-32 : index
  %31 = arith.addi %8, %30 : index
  %32 = arith.cmpi sgt, %31, %c32 : index
  %33 = arith.select %32, %c32, %31 : index
  %34 = arith.remsi %workgroup_id_x, %23 : index
  %35 = arith.cmpi slt, %34, %c0 : index
  %36 = arith.addi %34, %23 : index
  %37 = arith.select %35, %36, %34 : index
  %38 = arith.muli %37, %c-128 : index
  %39 = arith.addi %13, %38 : index
  %40 = arith.cmpi sgt, %39, %c128 : index
  %41 = arith.select %40, %c128, %39 : index
  %42 = gpu.thread_id  x
  %43 = gpu.thread_id  y
  %44 = arith.cmpi sle, %33, %c0 : index
  %45 = arith.subi %c0, %33 : index
  %46 = arith.subi %33, %c1 : index
  %47 = arith.select %44, %45, %46 : index
  %48 = arith.divsi %47, %c8 : index
  %49 = arith.subi %c0, %48 : index
  %50 = arith.addi %48, %c1 : index
  %51 = arith.select %44, %49, %50 : index
  %52 = arith.muli %43, %51 : index
  %53 = arith.subi %33, %52 : index
  %54 = arith.cmpi slt, %53, %51 : index
  %55 = arith.select %54, %53, %51 : index
  %56 = arith.cmpi slt, %55, %c0 : index
  %57 = arith.select %56, %c0, %55 : index
  %58 = arith.cmpi sle, %41, %c0 : index
  %59 = arith.subi %c0, %41 : index
  %60 = arith.subi %41, %c1 : index
  %61 = arith.select %58, %59, %60 : index
  %62 = arith.divsi %61, %c32 : index
  %63 = arith.subi %c0, %62 : index
  %64 = arith.addi %62, %c1 : index
  %65 = arith.select %58, %63, %64 : index
  %66 = arith.muli %42, %65 : index
  %67 = arith.subi %41, %66 : index
  %68 = arith.cmpi slt, %67, %65 : index
  %69 = arith.select %68, %67, %65 : index
  %70 = arith.cmpi slt, %69, %c0 : index
  %71 = arith.select %70, %c0, %69 : index
  %72 = arith.muli %29, %c32 : index
  %73 = arith.addi %72, %52 : index
  %74 = arith.muli %37, %c128 : index
  %75 = arith.addi %74, %66 : index
  cf.br ^bb1(%c0 : index)
^bb1(%76: index):  // 2 preds: ^bb0, ^bb5
  %77 = arith.cmpi slt, %76, %57 : index
  cf.cond_br %77, ^bb2, ^bb6(%c0 : index)
^bb2:  // pred: ^bb1
  %78 = arith.addi %73, %76 : index
  cf.br ^bb3(%c0 : index)
^bb3(%79: index):  // 2 preds: ^bb2, ^bb4
  %80 = arith.cmpi slt, %79, %71 : index
  cf.cond_br %80, ^bb4, ^bb5
^bb4:  // pred: ^bb3
  %81 = arith.addi %75, %79 : index
  memref.store %cst, %15[%78, %81] : memref<?x?xf32, #gpu.address_space<global>>
  %82 = arith.addi %79, %c1 : index
  cf.br ^bb3(%82 : index)
^bb5:  // pred: ^bb3
  %83 = arith.addi %76, %c1 : index
  cf.br ^bb1(%83 : index)
^bb6(%84: index):  // 2 preds: ^bb1, ^bb12
  %85 = arith.cmpi slt, %84, %13 : index
  cf.cond_br %85, ^bb7(%c0 : index), ^bb13
^bb7(%86: index):  // 2 preds: ^bb6, ^bb11
  %87 = arith.cmpi slt, %86, %57 : index
  cf.cond_br %87, ^bb8, ^bb12
^bb8:  // pred: ^bb7
  %88 = arith.addi %73, %86 : index
  cf.br ^bb9(%c0 : index)
^bb9(%89: index):  // 2 preds: ^bb8, ^bb10
  %90 = arith.cmpi slt, %89, %71 : index
  cf.cond_br %90, ^bb10, ^bb11
^bb10:  // pred: ^bb9
  %91 = memref.load %14[%88, %84] : memref<?x?xf32, #gpu.address_space<global>>
  %92 = arith.addi %75, %89 : index
  %93 = memref.load %14[%84, %92] : memref<?x?xf32, #gpu.address_space<global>>
  %94 = memref.load %15[%88, %92] : memref<?x?xf32, #gpu.address_space<global>>
  %95 = arith.mulf %91, %93 : f32
  %96 = arith.addf %94, %95 : f32
  memref.store %96, %15[%88, %92] : memref<?x?xf32, #gpu.address_space<global>>
  %97 = arith.addi %89, %c1 : index
  cf.br ^bb9(%97 : index)
^bb11:  // pred: ^bb9
  %98 = arith.addi %86, %c1 : index
  cf.br ^bb7(%98 : index)
^bb12:  // pred: ^bb7
  %99 = arith.addi %84, %c1 : index
  cf.br ^bb6(%99 : index)
^bb13:  // pred: ^bb6
  return
}

// -----// IR Dump After ConvertComplexToStandard (convert-complex-to-standard) //----- //
module {
  func.func @main_dispatch_0_matmul_DxDxD_f32() {
    %c8 = arith.constant 8 : index
    %c-128 = arith.constant -128 : index
    %c-32 = arith.constant -32 : index
    %c-1 = arith.constant -1 : index
    %c128 = arith.constant 128 : index
    %c32 = arith.constant 32 : index
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c32_i64 = arith.constant 32 : i64
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.interface.constant.load[0] : i32
    %1 = hal.interface.constant.load[1] : i32
    %2 = hal.interface.constant.load[2] : i32
    %3 = hal.interface.constant.load[3] : i32
    %4 = arith.extui %0 : i32 to i64
    %5 = arith.extui %1 : i32 to i64
    %6 = arith.shli %5, %c32_i64 : i64
    %7 = arith.ori %4, %6 : i64
    %8 = arith.index_castui %7 : i64 to index
    %9 = arith.extui %2 : i32 to i64
    %10 = arith.extui %3 : i32 to i64
    %11 = arith.shli %10, %c32_i64 : i64
    %12 = arith.ori %9, %11 : i64
    %13 = arith.index_castui %12 : i64 to index
    %14 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32, #gpu.address_space<global>>{%8, %13}
    memref.assume_alignment %14, 64 : memref<?x?xf32, #gpu.address_space<global>>
    %15 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : memref<?x?xf32, #gpu.address_space<global>>{%8, %13}
    memref.assume_alignment %15, 64 : memref<?x?xf32, #gpu.address_space<global>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %16 = arith.cmpi sle, %13, %c0 : index
    %17 = arith.subi %c0, %13 : index
    %18 = arith.subi %13, %c1 : index
    %19 = arith.select %16, %17, %18 : index
    %20 = arith.divsi %19, %c128 : index
    %21 = arith.subi %c0, %20 : index
    %22 = arith.addi %20, %c1 : index
    %23 = arith.select %16, %21, %22 : index
    %24 = arith.cmpi slt, %workgroup_id_x, %c0 : index
    %25 = arith.subi %c-1, %workgroup_id_x : index
    %26 = arith.select %24, %25, %workgroup_id_x : index
    %27 = arith.divsi %26, %23 : index
    %28 = arith.subi %c-1, %27 : index
    %29 = arith.select %24, %28, %27 : index
    %30 = arith.muli %29, %c-32 : index
    %31 = arith.addi %8, %30 : index
    %32 = arith.cmpi sgt, %31, %c32 : index
    %33 = arith.select %32, %c32, %31 : index
    %34 = arith.remsi %workgroup_id_x, %23 : index
    %35 = arith.cmpi slt, %34, %c0 : index
    %36 = arith.addi %34, %23 : index
    %37 = arith.select %35, %36, %34 : index
    %38 = arith.muli %37, %c-128 : index
    %39 = arith.addi %13, %38 : index
    %40 = arith.cmpi sgt, %39, %c128 : index
    %41 = arith.select %40, %c128, %39 : index
    %42 = gpu.thread_id  x
    %43 = gpu.thread_id  y
    %44 = arith.cmpi sle, %33, %c0 : index
    %45 = arith.subi %c0, %33 : index
    %46 = arith.subi %33, %c1 : index
    %47 = arith.select %44, %45, %46 : index
    %48 = arith.divsi %47, %c8 : index
    %49 = arith.subi %c0, %48 : index
    %50 = arith.addi %48, %c1 : index
    %51 = arith.select %44, %49, %50 : index
    %52 = arith.muli %43, %51 : index
    %53 = arith.subi %33, %52 : index
    %54 = arith.cmpi slt, %53, %51 : index
    %55 = arith.select %54, %53, %51 : index
    %56 = arith.cmpi slt, %55, %c0 : index
    %57 = arith.select %56, %c0, %55 : index
    %58 = arith.cmpi sle, %41, %c0 : index
    %59 = arith.subi %c0, %41 : index
    %60 = arith.subi %41, %c1 : index
    %61 = arith.select %58, %59, %60 : index
    %62 = arith.divsi %61, %c32 : index
    %63 = arith.subi %c0, %62 : index
    %64 = arith.addi %62, %c1 : index
    %65 = arith.select %58, %63, %64 : index
    %66 = arith.muli %42, %65 : index
    %67 = arith.subi %41, %66 : index
    %68 = arith.cmpi slt, %67, %65 : index
    %69 = arith.select %68, %67, %65 : index
    %70 = arith.cmpi slt, %69, %c0 : index
    %71 = arith.select %70, %c0, %69 : index
    %72 = arith.muli %29, %c32 : index
    %73 = arith.addi %72, %52 : index
    %74 = arith.muli %37, %c128 : index
    %75 = arith.addi %74, %66 : index
    cf.br ^bb1(%c0 : index)
  ^bb1(%76: index):  // 2 preds: ^bb0, ^bb5
    %77 = arith.cmpi slt, %76, %57 : index
    cf.cond_br %77, ^bb2, ^bb6(%c0 : index)
  ^bb2:  // pred: ^bb1
    %78 = arith.addi %73, %76 : index
    cf.br ^bb3(%c0 : index)
  ^bb3(%79: index):  // 2 preds: ^bb2, ^bb4
    %80 = arith.cmpi slt, %79, %71 : index
    cf.cond_br %80, ^bb4, ^bb5
  ^bb4:  // pred: ^bb3
    %81 = arith.addi %75, %79 : index
    memref.store %cst, %15[%78, %81] : memref<?x?xf32, #gpu.address_space<global>>
    %82 = arith.addi %79, %c1 : index
    cf.br ^bb3(%82 : index)
  ^bb5:  // pred: ^bb3
    %83 = arith.addi %76, %c1 : index
    cf.br ^bb1(%83 : index)
  ^bb6(%84: index):  // 2 preds: ^bb1, ^bb12
    %85 = arith.cmpi slt, %84, %13 : index
    cf.cond_br %85, ^bb7(%c0 : index), ^bb13
  ^bb7(%86: index):  // 2 preds: ^bb6, ^bb11
    %87 = arith.cmpi slt, %86, %57 : index
    cf.cond_br %87, ^bb8, ^bb12
  ^bb8:  // pred: ^bb7
    %88 = arith.addi %73, %86 : index
    cf.br ^bb9(%c0 : index)
  ^bb9(%89: index):  // 2 preds: ^bb8, ^bb10
    %90 = arith.cmpi slt, %89, %71 : index
    cf.cond_br %90, ^bb10, ^bb11
  ^bb10:  // pred: ^bb9
    %91 = memref.load %14[%88, %84] : memref<?x?xf32, #gpu.address_space<global>>
    %92 = arith.addi %75, %89 : index
    %93 = memref.load %14[%84, %92] : memref<?x?xf32, #gpu.address_space<global>>
    %94 = memref.load %15[%88, %92] : memref<?x?xf32, #gpu.address_space<global>>
    %95 = arith.mulf %91, %93 : f32
    %96 = arith.addf %94, %95 : f32
    memref.store %96, %15[%88, %92] : memref<?x?xf32, #gpu.address_space<global>>
    %97 = arith.addi %89, %c1 : index
    cf.br ^bb9(%97 : index)
  ^bb11:  // pred: ^bb9
    %98 = arith.addi %86, %c1 : index
    cf.br ^bb7(%98 : index)
  ^bb12:  // pred: ^bb7
    %99 = arith.addi %84, %c1 : index
    cf.br ^bb6(%99 : index)
  ^bb13:  // pred: ^bb6
    return
  }
}

// -----// IR Dump After ConvertBf16ArithToF32 (iree-convert-bf16-arith-to-f32) //----- //
module {
  func.func @main_dispatch_0_matmul_DxDxD_f32() {
    %c8 = arith.constant 8 : index
    %c-128 = arith.constant -128 : index
    %c-32 = arith.constant -32 : index
    %c-1 = arith.constant -1 : index
    %c128 = arith.constant 128 : index
    %c32 = arith.constant 32 : index
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c32_i64 = arith.constant 32 : i64
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.interface.constant.load[0] : i32
    %1 = hal.interface.constant.load[1] : i32
    %2 = hal.interface.constant.load[2] : i32
    %3 = hal.interface.constant.load[3] : i32
    %4 = arith.extui %0 : i32 to i64
    %5 = arith.extui %1 : i32 to i64
    %6 = arith.shli %5, %c32_i64 : i64
    %7 = arith.ori %4, %6 : i64
    %8 = arith.index_castui %7 : i64 to index
    %9 = arith.extui %2 : i32 to i64
    %10 = arith.extui %3 : i32 to i64
    %11 = arith.shli %10, %c32_i64 : i64
    %12 = arith.ori %9, %11 : i64
    %13 = arith.index_castui %12 : i64 to index
    %14 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32, #gpu.address_space<global>>{%8, %13}
    memref.assume_alignment %14, 64 : memref<?x?xf32, #gpu.address_space<global>>
    %15 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : memref<?x?xf32, #gpu.address_space<global>>{%8, %13}
    memref.assume_alignment %15, 64 : memref<?x?xf32, #gpu.address_space<global>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %16 = arith.cmpi sle, %13, %c0 : index
    %17 = arith.subi %c0, %13 : index
    %18 = arith.subi %13, %c1 : index
    %19 = arith.select %16, %17, %18 : index
    %20 = arith.divsi %19, %c128 : index
    %21 = arith.subi %c0, %20 : index
    %22 = arith.addi %20, %c1 : index
    %23 = arith.select %16, %21, %22 : index
    %24 = arith.cmpi slt, %workgroup_id_x, %c0 : index
    %25 = arith.subi %c-1, %workgroup_id_x : index
    %26 = arith.select %24, %25, %workgroup_id_x : index
    %27 = arith.divsi %26, %23 : index
    %28 = arith.subi %c-1, %27 : index
    %29 = arith.select %24, %28, %27 : index
    %30 = arith.muli %29, %c-32 : index
    %31 = arith.addi %8, %30 : index
    %32 = arith.cmpi sgt, %31, %c32 : index
    %33 = arith.select %32, %c32, %31 : index
    %34 = arith.remsi %workgroup_id_x, %23 : index
    %35 = arith.cmpi slt, %34, %c0 : index
    %36 = arith.addi %34, %23 : index
    %37 = arith.select %35, %36, %34 : index
    %38 = arith.muli %37, %c-128 : index
    %39 = arith.addi %13, %38 : index
    %40 = arith.cmpi sgt, %39, %c128 : index
    %41 = arith.select %40, %c128, %39 : index
    %42 = gpu.thread_id  x
    %43 = gpu.thread_id  y
    %44 = arith.cmpi sle, %33, %c0 : index
    %45 = arith.subi %c0, %33 : index
    %46 = arith.subi %33, %c1 : index
    %47 = arith.select %44, %45, %46 : index
    %48 = arith.divsi %47, %c8 : index
    %49 = arith.subi %c0, %48 : index
    %50 = arith.addi %48, %c1 : index
    %51 = arith.select %44, %49, %50 : index
    %52 = arith.muli %43, %51 : index
    %53 = arith.subi %33, %52 : index
    %54 = arith.cmpi slt, %53, %51 : index
    %55 = arith.select %54, %53, %51 : index
    %56 = arith.cmpi slt, %55, %c0 : index
    %57 = arith.select %56, %c0, %55 : index
    %58 = arith.cmpi sle, %41, %c0 : index
    %59 = arith.subi %c0, %41 : index
    %60 = arith.subi %41, %c1 : index
    %61 = arith.select %58, %59, %60 : index
    %62 = arith.divsi %61, %c32 : index
    %63 = arith.subi %c0, %62 : index
    %64 = arith.addi %62, %c1 : index
    %65 = arith.select %58, %63, %64 : index
    %66 = arith.muli %42, %65 : index
    %67 = arith.subi %41, %66 : index
    %68 = arith.cmpi slt, %67, %65 : index
    %69 = arith.select %68, %67, %65 : index
    %70 = arith.cmpi slt, %69, %c0 : index
    %71 = arith.select %70, %c0, %69 : index
    %72 = arith.muli %29, %c32 : index
    %73 = arith.addi %72, %52 : index
    %74 = arith.muli %37, %c128 : index
    %75 = arith.addi %74, %66 : index
    cf.br ^bb1(%c0 : index)
  ^bb1(%76: index):  // 2 preds: ^bb0, ^bb5
    %77 = arith.cmpi slt, %76, %57 : index
    cf.cond_br %77, ^bb2, ^bb6(%c0 : index)
  ^bb2:  // pred: ^bb1
    %78 = arith.addi %73, %76 : index
    cf.br ^bb3(%c0 : index)
  ^bb3(%79: index):  // 2 preds: ^bb2, ^bb4
    %80 = arith.cmpi slt, %79, %71 : index
    cf.cond_br %80, ^bb4, ^bb5
  ^bb4:  // pred: ^bb3
    %81 = arith.addi %75, %79 : index
    memref.store %cst, %15[%78, %81] : memref<?x?xf32, #gpu.address_space<global>>
    %82 = arith.addi %79, %c1 : index
    cf.br ^bb3(%82 : index)
  ^bb5:  // pred: ^bb3
    %83 = arith.addi %76, %c1 : index
    cf.br ^bb1(%83 : index)
  ^bb6(%84: index):  // 2 preds: ^bb1, ^bb12
    %85 = arith.cmpi slt, %84, %13 : index
    cf.cond_br %85, ^bb7(%c0 : index), ^bb13
  ^bb7(%86: index):  // 2 preds: ^bb6, ^bb11
    %87 = arith.cmpi slt, %86, %57 : index
    cf.cond_br %87, ^bb8, ^bb12
  ^bb8:  // pred: ^bb7
    %88 = arith.addi %73, %86 : index
    cf.br ^bb9(%c0 : index)
  ^bb9(%89: index):  // 2 preds: ^bb8, ^bb10
    %90 = arith.cmpi slt, %89, %71 : index
    cf.cond_br %90, ^bb10, ^bb11
  ^bb10:  // pred: ^bb9
    %91 = memref.load %14[%88, %84] : memref<?x?xf32, #gpu.address_space<global>>
    %92 = arith.addi %75, %89 : index
    %93 = memref.load %14[%84, %92] : memref<?x?xf32, #gpu.address_space<global>>
    %94 = memref.load %15[%88, %92] : memref<?x?xf32, #gpu.address_space<global>>
    %95 = arith.mulf %91, %93 : f32
    %96 = arith.addf %94, %95 : f32
    memref.store %96, %15[%88, %92] : memref<?x?xf32, #gpu.address_space<global>>
    %97 = arith.addi %89, %c1 : index
    cf.br ^bb9(%97 : index)
  ^bb11:  // pred: ^bb9
    %98 = arith.addi %86, %c1 : index
    cf.br ^bb7(%98 : index)
  ^bb12:  // pred: ^bb7
    %99 = arith.addi %84, %c1 : index
    cf.br ^bb6(%99 : index)
  ^bb13:  // pred: ^bb6
    return
  }
}

// -----// IR Dump After ConvertBf16ToUInt16Buffers (iree-convert-bf16-to-uint16-buffers) //----- //
module {
  func.func @main_dispatch_0_matmul_DxDxD_f32() {
    %c8 = arith.constant 8 : index
    %c-128 = arith.constant -128 : index
    %c-32 = arith.constant -32 : index
    %c-1 = arith.constant -1 : index
    %c128 = arith.constant 128 : index
    %c32 = arith.constant 32 : index
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c32_i64 = arith.constant 32 : i64
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.interface.constant.load[0] : i32
    %1 = hal.interface.constant.load[1] : i32
    %2 = hal.interface.constant.load[2] : i32
    %3 = hal.interface.constant.load[3] : i32
    %4 = arith.extui %0 : i32 to i64
    %5 = arith.extui %1 : i32 to i64
    %6 = arith.shli %5, %c32_i64 : i64
    %7 = arith.ori %4, %6 : i64
    %8 = arith.index_castui %7 : i64 to index
    %9 = arith.extui %2 : i32 to i64
    %10 = arith.extui %3 : i32 to i64
    %11 = arith.shli %10, %c32_i64 : i64
    %12 = arith.ori %9, %11 : i64
    %13 = arith.index_castui %12 : i64 to index
    %14 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32, #gpu.address_space<global>>{%8, %13}
    memref.assume_alignment %14, 64 : memref<?x?xf32, #gpu.address_space<global>>
    %15 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : memref<?x?xf32, #gpu.address_space<global>>{%8, %13}
    memref.assume_alignment %15, 64 : memref<?x?xf32, #gpu.address_space<global>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %16 = arith.cmpi sle, %13, %c0 : index
    %17 = arith.subi %c0, %13 : index
    %18 = arith.subi %13, %c1 : index
    %19 = arith.select %16, %17, %18 : index
    %20 = arith.divsi %19, %c128 : index
    %21 = arith.subi %c0, %20 : index
    %22 = arith.addi %20, %c1 : index
    %23 = arith.select %16, %21, %22 : index
    %24 = arith.cmpi slt, %workgroup_id_x, %c0 : index
    %25 = arith.subi %c-1, %workgroup_id_x : index
    %26 = arith.select %24, %25, %workgroup_id_x : index
    %27 = arith.divsi %26, %23 : index
    %28 = arith.subi %c-1, %27 : index
    %29 = arith.select %24, %28, %27 : index
    %30 = arith.muli %29, %c-32 : index
    %31 = arith.addi %8, %30 : index
    %32 = arith.cmpi sgt, %31, %c32 : index
    %33 = arith.select %32, %c32, %31 : index
    %34 = arith.remsi %workgroup_id_x, %23 : index
    %35 = arith.cmpi slt, %34, %c0 : index
    %36 = arith.addi %34, %23 : index
    %37 = arith.select %35, %36, %34 : index
    %38 = arith.muli %37, %c-128 : index
    %39 = arith.addi %13, %38 : index
    %40 = arith.cmpi sgt, %39, %c128 : index
    %41 = arith.select %40, %c128, %39 : index
    %42 = gpu.thread_id  x
    %43 = gpu.thread_id  y
    %44 = arith.cmpi sle, %33, %c0 : index
    %45 = arith.subi %c0, %33 : index
    %46 = arith.subi %33, %c1 : index
    %47 = arith.select %44, %45, %46 : index
    %48 = arith.divsi %47, %c8 : index
    %49 = arith.subi %c0, %48 : index
    %50 = arith.addi %48, %c1 : index
    %51 = arith.select %44, %49, %50 : index
    %52 = arith.muli %43, %51 : index
    %53 = arith.subi %33, %52 : index
    %54 = arith.cmpi slt, %53, %51 : index
    %55 = arith.select %54, %53, %51 : index
    %56 = arith.cmpi slt, %55, %c0 : index
    %57 = arith.select %56, %c0, %55 : index
    %58 = arith.cmpi sle, %41, %c0 : index
    %59 = arith.subi %c0, %41 : index
    %60 = arith.subi %41, %c1 : index
    %61 = arith.select %58, %59, %60 : index
    %62 = arith.divsi %61, %c32 : index
    %63 = arith.subi %c0, %62 : index
    %64 = arith.addi %62, %c1 : index
    %65 = arith.select %58, %63, %64 : index
    %66 = arith.muli %42, %65 : index
    %67 = arith.subi %41, %66 : index
    %68 = arith.cmpi slt, %67, %65 : index
    %69 = arith.select %68, %67, %65 : index
    %70 = arith.cmpi slt, %69, %c0 : index
    %71 = arith.select %70, %c0, %69 : index
    %72 = arith.muli %29, %c32 : index
    %73 = arith.addi %72, %52 : index
    %74 = arith.muli %37, %c128 : index
    %75 = arith.addi %74, %66 : index
    cf.br ^bb1(%c0 : index)
  ^bb1(%76: index):  // 2 preds: ^bb0, ^bb5
    %77 = arith.cmpi slt, %76, %57 : index
    cf.cond_br %77, ^bb2, ^bb6(%c0 : index)
  ^bb2:  // pred: ^bb1
    %78 = arith.addi %73, %76 : index
    cf.br ^bb3(%c0 : index)
  ^bb3(%79: index):  // 2 preds: ^bb2, ^bb4
    %80 = arith.cmpi slt, %79, %71 : index
    cf.cond_br %80, ^bb4, ^bb5
  ^bb4:  // pred: ^bb3
    %81 = arith.addi %75, %79 : index
    memref.store %cst, %15[%78, %81] : memref<?x?xf32, #gpu.address_space<global>>
    %82 = arith.addi %79, %c1 : index
    cf.br ^bb3(%82 : index)
  ^bb5:  // pred: ^bb3
    %83 = arith.addi %76, %c1 : index
    cf.br ^bb1(%83 : index)
  ^bb6(%84: index):  // 2 preds: ^bb1, ^bb12
    %85 = arith.cmpi slt, %84, %13 : index
    cf.cond_br %85, ^bb7(%c0 : index), ^bb13
  ^bb7(%86: index):  // 2 preds: ^bb6, ^bb11
    %87 = arith.cmpi slt, %86, %57 : index
    cf.cond_br %87, ^bb8, ^bb12
  ^bb8:  // pred: ^bb7
    %88 = arith.addi %73, %86 : index
    cf.br ^bb9(%c0 : index)
  ^bb9(%89: index):  // 2 preds: ^bb8, ^bb10
    %90 = arith.cmpi slt, %89, %71 : index
    cf.cond_br %90, ^bb10, ^bb11
  ^bb10:  // pred: ^bb9
    %91 = memref.load %14[%88, %84] : memref<?x?xf32, #gpu.address_space<global>>
    %92 = arith.addi %75, %89 : index
    %93 = memref.load %14[%84, %92] : memref<?x?xf32, #gpu.address_space<global>>
    %94 = memref.load %15[%88, %92] : memref<?x?xf32, #gpu.address_space<global>>
    %95 = arith.mulf %91, %93 : f32
    %96 = arith.addf %94, %95 : f32
    memref.store %96, %15[%88, %92] : memref<?x?xf32, #gpu.address_space<global>>
    %97 = arith.addi %89, %c1 : index
    cf.br ^bb9(%97 : index)
  ^bb11:  // pred: ^bb9
    %98 = arith.addi %86, %c1 : index
    cf.br ^bb7(%98 : index)
  ^bb12:  // pred: ^bb7
    %99 = arith.addi %84, %c1 : index
    cf.br ^bb6(%99 : index)
  ^bb13:  // pred: ^bb6
    return
  }
}

// -----// IR Dump After ArithExpandOpsPass (arith-expand) //----- //
func.func @main_dispatch_0_matmul_DxDxD_f32() {
  %c8 = arith.constant 8 : index
  %c-128 = arith.constant -128 : index
  %c-32 = arith.constant -32 : index
  %c-1 = arith.constant -1 : index
  %c128 = arith.constant 128 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c32_i64 = arith.constant 32 : i64
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.interface.constant.load[0] : i32
  %1 = hal.interface.constant.load[1] : i32
  %2 = hal.interface.constant.load[2] : i32
  %3 = hal.interface.constant.load[3] : i32
  %4 = arith.extui %0 : i32 to i64
  %5 = arith.extui %1 : i32 to i64
  %6 = arith.shli %5, %c32_i64 : i64
  %7 = arith.ori %4, %6 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %2 : i32 to i64
  %10 = arith.extui %3 : i32 to i64
  %11 = arith.shli %10, %c32_i64 : i64
  %12 = arith.ori %9, %11 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32, #gpu.address_space<global>>{%8, %13}
  memref.assume_alignment %14, 64 : memref<?x?xf32, #gpu.address_space<global>>
  %15 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : memref<?x?xf32, #gpu.address_space<global>>{%8, %13}
  memref.assume_alignment %15, 64 : memref<?x?xf32, #gpu.address_space<global>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %16 = arith.cmpi sle, %13, %c0 : index
  %17 = arith.subi %c0, %13 : index
  %18 = arith.subi %13, %c1 : index
  %19 = arith.select %16, %17, %18 : index
  %20 = arith.divsi %19, %c128 : index
  %21 = arith.subi %c0, %20 : index
  %22 = arith.addi %20, %c1 : index
  %23 = arith.select %16, %21, %22 : index
  %24 = arith.cmpi slt, %workgroup_id_x, %c0 : index
  %25 = arith.subi %c-1, %workgroup_id_x : index
  %26 = arith.select %24, %25, %workgroup_id_x : index
  %27 = arith.divsi %26, %23 : index
  %28 = arith.subi %c-1, %27 : index
  %29 = arith.select %24, %28, %27 : index
  %30 = arith.muli %29, %c-32 : index
  %31 = arith.addi %8, %30 : index
  %32 = arith.cmpi sgt, %31, %c32 : index
  %33 = arith.select %32, %c32, %31 : index
  %34 = arith.remsi %workgroup_id_x, %23 : index
  %35 = arith.cmpi slt, %34, %c0 : index
  %36 = arith.addi %34, %23 : index
  %37 = arith.select %35, %36, %34 : index
  %38 = arith.muli %37, %c-128 : index
  %39 = arith.addi %13, %38 : index
  %40 = arith.cmpi sgt, %39, %c128 : index
  %41 = arith.select %40, %c128, %39 : index
  %42 = gpu.thread_id  x
  %43 = gpu.thread_id  y
  %44 = arith.cmpi sle, %33, %c0 : index
  %45 = arith.subi %c0, %33 : index
  %46 = arith.subi %33, %c1 : index
  %47 = arith.select %44, %45, %46 : index
  %48 = arith.divsi %47, %c8 : index
  %49 = arith.subi %c0, %48 : index
  %50 = arith.addi %48, %c1 : index
  %51 = arith.select %44, %49, %50 : index
  %52 = arith.muli %43, %51 : index
  %53 = arith.subi %33, %52 : index
  %54 = arith.cmpi slt, %53, %51 : index
  %55 = arith.select %54, %53, %51 : index
  %56 = arith.cmpi slt, %55, %c0 : index
  %57 = arith.select %56, %c0, %55 : index
  %58 = arith.cmpi sle, %41, %c0 : index
  %59 = arith.subi %c0, %41 : index
  %60 = arith.subi %41, %c1 : index
  %61 = arith.select %58, %59, %60 : index
  %62 = arith.divsi %61, %c32 : index
  %63 = arith.subi %c0, %62 : index
  %64 = arith.addi %62, %c1 : index
  %65 = arith.select %58, %63, %64 : index
  %66 = arith.muli %42, %65 : index
  %67 = arith.subi %41, %66 : index
  %68 = arith.cmpi slt, %67, %65 : index
  %69 = arith.select %68, %67, %65 : index
  %70 = arith.cmpi slt, %69, %c0 : index
  %71 = arith.select %70, %c0, %69 : index
  %72 = arith.muli %29, %c32 : index
  %73 = arith.addi %72, %52 : index
  %74 = arith.muli %37, %c128 : index
  %75 = arith.addi %74, %66 : index
  cf.br ^bb1(%c0 : index)
^bb1(%76: index):  // 2 preds: ^bb0, ^bb5
  %77 = arith.cmpi slt, %76, %57 : index
  cf.cond_br %77, ^bb2, ^bb6(%c0 : index)
^bb2:  // pred: ^bb1
  %78 = arith.addi %73, %76 : index
  cf.br ^bb3(%c0 : index)
^bb3(%79: index):  // 2 preds: ^bb2, ^bb4
  %80 = arith.cmpi slt, %79, %71 : index
  cf.cond_br %80, ^bb4, ^bb5
^bb4:  // pred: ^bb3
  %81 = arith.addi %75, %79 : index
  memref.store %cst, %15[%78, %81] : memref<?x?xf32, #gpu.address_space<global>>
  %82 = arith.addi %79, %c1 : index
  cf.br ^bb3(%82 : index)
^bb5:  // pred: ^bb3
  %83 = arith.addi %76, %c1 : index
  cf.br ^bb1(%83 : index)
^bb6(%84: index):  // 2 preds: ^bb1, ^bb12
  %85 = arith.cmpi slt, %84, %13 : index
  cf.cond_br %85, ^bb7(%c0 : index), ^bb13
^bb7(%86: index):  // 2 preds: ^bb6, ^bb11
  %87 = arith.cmpi slt, %86, %57 : index
  cf.cond_br %87, ^bb8, ^bb12
^bb8:  // pred: ^bb7
  %88 = arith.addi %73, %86 : index
  cf.br ^bb9(%c0 : index)
^bb9(%89: index):  // 2 preds: ^bb8, ^bb10
  %90 = arith.cmpi slt, %89, %71 : index
  cf.cond_br %90, ^bb10, ^bb11
^bb10:  // pred: ^bb9
  %91 = memref.load %14[%88, %84] : memref<?x?xf32, #gpu.address_space<global>>
  %92 = arith.addi %75, %89 : index
  %93 = memref.load %14[%84, %92] : memref<?x?xf32, #gpu.address_space<global>>
  %94 = memref.load %15[%88, %92] : memref<?x?xf32, #gpu.address_space<global>>
  %95 = arith.mulf %91, %93 : f32
  %96 = arith.addf %94, %95 : f32
  memref.store %96, %15[%88, %92] : memref<?x?xf32, #gpu.address_space<global>>
  %97 = arith.addi %89, %c1 : index
  cf.br ^bb9(%97 : index)
^bb11:  // pred: ^bb9
  %98 = arith.addi %86, %c1 : index
  cf.br ^bb7(%98 : index)
^bb12:  // pred: ^bb7
  %99 = arith.addi %84, %c1 : index
  cf.br ^bb6(%99 : index)
^bb13:  // pred: ^bb6
  return
}

// -----// IR Dump After PolynomialApproximationPass (iree-codegen-polynomial-approximation) //----- //
func.func @main_dispatch_0_matmul_DxDxD_f32() {
  %c8 = arith.constant 8 : index
  %c-128 = arith.constant -128 : index
  %c-32 = arith.constant -32 : index
  %c-1 = arith.constant -1 : index
  %c128 = arith.constant 128 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c32_i64 = arith.constant 32 : i64
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.interface.constant.load[0] : i32
  %1 = hal.interface.constant.load[1] : i32
  %2 = hal.interface.constant.load[2] : i32
  %3 = hal.interface.constant.load[3] : i32
  %4 = arith.extui %0 : i32 to i64
  %5 = arith.extui %1 : i32 to i64
  %6 = arith.shli %5, %c32_i64 : i64
  %7 = arith.ori %4, %6 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %2 : i32 to i64
  %10 = arith.extui %3 : i32 to i64
  %11 = arith.shli %10, %c32_i64 : i64
  %12 = arith.ori %9, %11 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32, #gpu.address_space<global>>{%8, %13}
  memref.assume_alignment %14, 64 : memref<?x?xf32, #gpu.address_space<global>>
  %15 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : memref<?x?xf32, #gpu.address_space<global>>{%8, %13}
  memref.assume_alignment %15, 64 : memref<?x?xf32, #gpu.address_space<global>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %16 = arith.cmpi sle, %13, %c0 : index
  %17 = arith.subi %c0, %13 : index
  %18 = arith.subi %13, %c1 : index
  %19 = arith.select %16, %17, %18 : index
  %20 = arith.divsi %19, %c128 : index
  %21 = arith.subi %c0, %20 : index
  %22 = arith.addi %20, %c1 : index
  %23 = arith.select %16, %21, %22 : index
  %24 = arith.cmpi slt, %workgroup_id_x, %c0 : index
  %25 = arith.subi %c-1, %workgroup_id_x : index
  %26 = arith.select %24, %25, %workgroup_id_x : index
  %27 = arith.divsi %26, %23 : index
  %28 = arith.subi %c-1, %27 : index
  %29 = arith.select %24, %28, %27 : index
  %30 = arith.muli %29, %c-32 : index
  %31 = arith.addi %8, %30 : index
  %32 = arith.cmpi sgt, %31, %c32 : index
  %33 = arith.select %32, %c32, %31 : index
  %34 = arith.remsi %workgroup_id_x, %23 : index
  %35 = arith.cmpi slt, %34, %c0 : index
  %36 = arith.addi %34, %23 : index
  %37 = arith.select %35, %36, %34 : index
  %38 = arith.muli %37, %c-128 : index
  %39 = arith.addi %13, %38 : index
  %40 = arith.cmpi sgt, %39, %c128 : index
  %41 = arith.select %40, %c128, %39 : index
  %42 = gpu.thread_id  x
  %43 = gpu.thread_id  y
  %44 = arith.cmpi sle, %33, %c0 : index
  %45 = arith.subi %c0, %33 : index
  %46 = arith.subi %33, %c1 : index
  %47 = arith.select %44, %45, %46 : index
  %48 = arith.divsi %47, %c8 : index
  %49 = arith.subi %c0, %48 : index
  %50 = arith.addi %48, %c1 : index
  %51 = arith.select %44, %49, %50 : index
  %52 = arith.muli %43, %51 : index
  %53 = arith.subi %33, %52 : index
  %54 = arith.cmpi slt, %53, %51 : index
  %55 = arith.select %54, %53, %51 : index
  %56 = arith.cmpi slt, %55, %c0 : index
  %57 = arith.select %56, %c0, %55 : index
  %58 = arith.cmpi sle, %41, %c0 : index
  %59 = arith.subi %c0, %41 : index
  %60 = arith.subi %41, %c1 : index
  %61 = arith.select %58, %59, %60 : index
  %62 = arith.divsi %61, %c32 : index
  %63 = arith.subi %c0, %62 : index
  %64 = arith.addi %62, %c1 : index
  %65 = arith.select %58, %63, %64 : index
  %66 = arith.muli %42, %65 : index
  %67 = arith.subi %41, %66 : index
  %68 = arith.cmpi slt, %67, %65 : index
  %69 = arith.select %68, %67, %65 : index
  %70 = arith.cmpi slt, %69, %c0 : index
  %71 = arith.select %70, %c0, %69 : index
  %72 = arith.muli %29, %c32 : index
  %73 = arith.addi %72, %52 : index
  %74 = arith.muli %37, %c128 : index
  %75 = arith.addi %74, %66 : index
  cf.br ^bb1(%c0 : index)
^bb1(%76: index):  // 2 preds: ^bb0, ^bb5
  %77 = arith.cmpi slt, %76, %57 : index
  cf.cond_br %77, ^bb2, ^bb6(%c0 : index)
^bb2:  // pred: ^bb1
  %78 = arith.addi %73, %76 : index
  cf.br ^bb3(%c0 : index)
^bb3(%79: index):  // 2 preds: ^bb2, ^bb4
  %80 = arith.cmpi slt, %79, %71 : index
  cf.cond_br %80, ^bb4, ^bb5
^bb4:  // pred: ^bb3
  %81 = arith.addi %75, %79 : index
  memref.store %cst, %15[%78, %81] : memref<?x?xf32, #gpu.address_space<global>>
  %82 = arith.addi %79, %c1 : index
  cf.br ^bb3(%82 : index)
^bb5:  // pred: ^bb3
  %83 = arith.addi %76, %c1 : index
  cf.br ^bb1(%83 : index)
^bb6(%84: index):  // 2 preds: ^bb1, ^bb12
  %85 = arith.cmpi slt, %84, %13 : index
  cf.cond_br %85, ^bb7(%c0 : index), ^bb13
^bb7(%86: index):  // 2 preds: ^bb6, ^bb11
  %87 = arith.cmpi slt, %86, %57 : index
  cf.cond_br %87, ^bb8, ^bb12
^bb8:  // pred: ^bb7
  %88 = arith.addi %73, %86 : index
  cf.br ^bb9(%c0 : index)
^bb9(%89: index):  // 2 preds: ^bb8, ^bb10
  %90 = arith.cmpi slt, %89, %71 : index
  cf.cond_br %90, ^bb10, ^bb11
^bb10:  // pred: ^bb9
  %91 = memref.load %14[%88, %84] : memref<?x?xf32, #gpu.address_space<global>>
  %92 = arith.addi %75, %89 : index
  %93 = memref.load %14[%84, %92] : memref<?x?xf32, #gpu.address_space<global>>
  %94 = memref.load %15[%88, %92] : memref<?x?xf32, #gpu.address_space<global>>
  %95 = arith.mulf %91, %93 : f32
  %96 = arith.addf %94, %95 : f32
  memref.store %96, %15[%88, %92] : memref<?x?xf32, #gpu.address_space<global>>
  %97 = arith.addi %89, %c1 : index
  cf.br ^bb9(%97 : index)
^bb11:  // pred: ^bb9
  %98 = arith.addi %86, %c1 : index
  cf.br ^bb7(%98 : index)
^bb12:  // pred: ^bb7
  %99 = arith.addi %84, %c1 : index
  cf.br ^bb6(%99 : index)
^bb13:  // pred: ^bb6
  return
}

// -----// IR Dump After ExpandOps (memref-expand) //----- //
func.func @main_dispatch_0_matmul_DxDxD_f32() {
  %c8 = arith.constant 8 : index
  %c-128 = arith.constant -128 : index
  %c-32 = arith.constant -32 : index
  %c-1 = arith.constant -1 : index
  %c128 = arith.constant 128 : index
  %c32 = arith.constant 32 : index
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c32_i64 = arith.constant 32 : i64
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.interface.constant.load[0] : i32
  %1 = hal.interface.constant.load[1] : i32
  %2 = hal.interface.constant.load[2] : i32
  %3 = hal.interface.constant.load[3] : i32
  %4 = arith.extui %0 : i32 to i64
  %5 = arith.extui %1 : i32 to i64
  %6 = arith.shli %5, %c32_i64 : i64
  %7 = arith.ori %4, %6 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %2 : i32 to i64
  %10 = arith.extui %3 : i32 to i64
  %11 = arith.shli %10, %c32_i64 : i64
  %12 = arith.ori %9, %11 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32, #gpu.address_space<global>>{%8, %13}
  memref.assume_alignment %14, 64 : memref<?x?xf32, #gpu.address_space<global>>
  %15 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : memref<?x?xf32, #gpu.address_space<global>>{%8, %13}
  memref.assume_alignment %15, 64 : memref<?x?xf32, #gpu.address_space<global>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %16 = arith.cmpi sle, %13, %c0 : index
  %17 = arith.subi %c0, %13 : index
  %18 = arith.subi %13, %c1 : index
  %19 = arith.select %16, %17, %18 : index
  %20 = arith.divsi %19, %c128 : index
  %21 = arith.subi %c0, %20 : index
  %22 = arith.addi %20, %c1 : index
  %23 = arith.select %16, %21, %22 : index
  %24 = arith.cmpi slt, %workgroup_id_x, %c0 : index
  %25 = arith.subi %c-1, %workgroup_id_x : index
  %26 = arith.select %24, %25, %workgroup_id_x : index
  %27 = arith.divsi %26, %23 : index
  %28 = arith.subi %c-1, %27 : index
  %29 = arith.select %24, %28, %27 : index
  %30 = arith.muli %29, %c-32 : index
  %31 = arith.addi %8, %30 : index
  %32 = arith.cmpi sgt, %31, %c32 : index
  %33 = arith.select %32, %c32, %31 : index
  %34 = arith.remsi %workgroup_id_x, %23 : index
  %35 = arith.cmpi slt, %34, %c0 : index
  %36 = arith.addi %34, %23 : index
  %37 = arith.select %35, %36, %34 : index
  %38 = arith.muli %37, %c-128 : index
  %39 = arith.addi %13, %38 : index
  %40 = arith.cmpi sgt, %39, %c128 : index
  %41 = arith.select %40, %c128, %39 : index
  %42 = gpu.thread_id  x
  %43 = gpu.thread_id  y
  %44 = arith.cmpi sle, %33, %c0 : index
  %45 = arith.subi %c0, %33 : index
  %46 = arith.subi %33, %c1 : index
  %47 = arith.select %44, %45, %46 : index
  %48 = arith.divsi %47, %c8 : index
  %49 = arith.subi %c0, %48 : index
  %50 = arith.addi %48, %c1 : index
  %51 = arith.select %44, %49, %50 : index
  %52 = arith.muli %43, %51 : index
  %53 = arith.subi %33, %52 : index
  %54 = arith.cmpi slt, %53, %51 : index
  %55 = arith.select %54, %53, %51 : index
  %56 = arith.cmpi slt, %55, %c0 : index
  %57 = arith.select %56, %c0, %55 : index
  %58 = arith.cmpi sle, %41, %c0 : index
  %59 = arith.subi %c0, %41 : index
  %60 = arith.subi %41, %c1 : index
  %61 = arith.select %58, %59, %60 : index
  %62 = arith.divsi %61, %c32 : index
  %63 = arith.subi %c0, %62 : index
  %64 = arith.addi %62, %c1 : index
  %65 = arith.select %58, %63, %64 : index
  %66 = arith.muli %42, %65 : index
  %67 = arith.subi %41, %66 : index
  %68 = arith.cmpi slt, %67, %65 : index
  %69 = arith.select %68, %67, %65 : index
  %70 = arith.cmpi slt, %69, %c0 : index
  %71 = arith.select %70, %c0, %69 : index
  %72 = arith.muli %29, %c32 : index
  %73 = arith.addi %72, %52 : index
  %74 = arith.muli %37, %c128 : index
  %75 = arith.addi %74, %66 : index
  cf.br ^bb1(%c0 : index)
^bb1(%76: index):  // 2 preds: ^bb0, ^bb5
  %77 = arith.cmpi slt, %76, %57 : index
  cf.cond_br %77, ^bb2, ^bb6(%c0 : index)
^bb2:  // pred: ^bb1
  %78 = arith.addi %73, %76 : index
  cf.br ^bb3(%c0 : index)
^bb3(%79: index):  // 2 preds: ^bb2, ^bb4
  %80 = arith.cmpi slt, %79, %71 : index
  cf.cond_br %80, ^bb4, ^bb5
^bb4:  // pred: ^bb3
  %81 = arith.addi %75, %79 : index
  memref.store %cst, %15[%78, %81] : memref<?x?xf32, #gpu.address_space<global>>
  %82 = arith.addi %79, %c1 : index
  cf.br ^bb3(%82 : index)
^bb5:  // pred: ^bb3
  %83 = arith.addi %76, %c1 : index
  cf.br ^bb1(%83 : index)
^bb6(%84: index):  // 2 preds: ^bb1, ^bb12
  %85 = arith.cmpi slt, %84, %13 : index
  cf.cond_br %85, ^bb7(%c0 : index), ^bb13
^bb7(%86: index):  // 2 preds: ^bb6, ^bb11
  %87 = arith.cmpi slt, %86, %57 : index
  cf.cond_br %87, ^bb8, ^bb12
^bb8:  // pred: ^bb7
  %88 = arith.addi %73, %86 : index
  cf.br ^bb9(%c0 : index)
^bb9(%89: index):  // 2 preds: ^bb8, ^bb10
  %90 = arith.cmpi slt, %89, %71 : index
  cf.cond_br %90, ^bb10, ^bb11
^bb10:  // pred: ^bb9
  %91 = memref.load %14[%88, %84] : memref<?x?xf32, #gpu.address_space<global>>
  %92 = arith.addi %75, %89 : index
  %93 = memref.load %14[%84, %92] : memref<?x?xf32, #gpu.address_space<global>>
  %94 = memref.load %15[%88, %92] : memref<?x?xf32, #gpu.address_space<global>>
  %95 = arith.mulf %91, %93 : f32
  %96 = arith.addf %94, %95 : f32
  memref.store %96, %15[%88, %92] : memref<?x?xf32, #gpu.address_space<global>>
  %97 = arith.addi %89, %c1 : index
  cf.br ^bb9(%97 : index)
^bb11:  // pred: ^bb9
  %98 = arith.addi %86, %c1 : index
  cf.br ^bb7(%98 : index)
^bb12:  // pred: ^bb7
  %99 = arith.addi %84, %c1 : index
  cf.br ^bb6(%99 : index)
^bb13:  // pred: ^bb6
  return
}

// -----// IR Dump After FoldMemRefAliasOps (fold-memref-alias-ops) //----- //
module {
  func.func @main_dispatch_0_matmul_DxDxD_f32() {
    %c8 = arith.constant 8 : index
    %c-128 = arith.constant -128 : index
    %c-32 = arith.constant -32 : index
    %c-1 = arith.constant -1 : index
    %c128 = arith.constant 128 : index
    %c32 = arith.constant 32 : index
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c32_i64 = arith.constant 32 : i64
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.interface.constant.load[0] : i32
    %1 = hal.interface.constant.load[1] : i32
    %2 = hal.interface.constant.load[2] : i32
    %3 = hal.interface.constant.load[3] : i32
    %4 = arith.extui %0 : i32 to i64
    %5 = arith.extui %1 : i32 to i64
    %6 = arith.shli %5, %c32_i64 : i64
    %7 = arith.ori %4, %6 : i64
    %8 = arith.index_castui %7 : i64 to index
    %9 = arith.extui %2 : i32 to i64
    %10 = arith.extui %3 : i32 to i64
    %11 = arith.shli %10, %c32_i64 : i64
    %12 = arith.ori %9, %11 : i64
    %13 = arith.index_castui %12 : i64 to index
    %14 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32, #gpu.address_space<global>>{%8, %13}
    memref.assume_alignment %14, 64 : memref<?x?xf32, #gpu.address_space<global>>
    %15 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : memref<?x?xf32, #gpu.address_space<global>>{%8, %13}
    memref.assume_alignment %15, 64 : memref<?x?xf32, #gpu.address_space<global>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %16 = arith.cmpi sle, %13, %c0 : index
    %17 = arith.subi %c0, %13 : index
    %18 = arith.subi %13, %c1 : index
    %19 = arith.select %16, %17, %18 : index
    %20 = arith.divsi %19, %c128 : index
    %21 = arith.subi %c0, %20 : index
    %22 = arith.addi %20, %c1 : index
    %23 = arith.select %16, %21, %22 : index
    %24 = arith.cmpi slt, %workgroup_id_x, %c0 : index
    %25 = arith.subi %c-1, %workgroup_id_x : index
    %26 = arith.select %24, %25, %workgroup_id_x : index
    %27 = arith.divsi %26, %23 : index
    %28 = arith.subi %c-1, %27 : index
    %29 = arith.select %24, %28, %27 : index
    %30 = arith.muli %29, %c-32 : index
    %31 = arith.addi %8, %30 : index
    %32 = arith.cmpi sgt, %31, %c32 : index
    %33 = arith.select %32, %c32, %31 : index
    %34 = arith.remsi %workgroup_id_x, %23 : index
    %35 = arith.cmpi slt, %34, %c0 : index
    %36 = arith.addi %34, %23 : index
    %37 = arith.select %35, %36, %34 : index
    %38 = arith.muli %37, %c-128 : index
    %39 = arith.addi %13, %38 : index
    %40 = arith.cmpi sgt, %39, %c128 : index
    %41 = arith.select %40, %c128, %39 : index
    %42 = gpu.thread_id  x
    %43 = gpu.thread_id  y
    %44 = arith.cmpi sle, %33, %c0 : index
    %45 = arith.subi %c0, %33 : index
    %46 = arith.subi %33, %c1 : index
    %47 = arith.select %44, %45, %46 : index
    %48 = arith.divsi %47, %c8 : index
    %49 = arith.subi %c0, %48 : index
    %50 = arith.addi %48, %c1 : index
    %51 = arith.select %44, %49, %50 : index
    %52 = arith.muli %43, %51 : index
    %53 = arith.subi %33, %52 : index
    %54 = arith.cmpi slt, %53, %51 : index
    %55 = arith.select %54, %53, %51 : index
    %56 = arith.cmpi slt, %55, %c0 : index
    %57 = arith.select %56, %c0, %55 : index
    %58 = arith.cmpi sle, %41, %c0 : index
    %59 = arith.subi %c0, %41 : index
    %60 = arith.subi %41, %c1 : index
    %61 = arith.select %58, %59, %60 : index
    %62 = arith.divsi %61, %c32 : index
    %63 = arith.subi %c0, %62 : index
    %64 = arith.addi %62, %c1 : index
    %65 = arith.select %58, %63, %64 : index
    %66 = arith.muli %42, %65 : index
    %67 = arith.subi %41, %66 : index
    %68 = arith.cmpi slt, %67, %65 : index
    %69 = arith.select %68, %67, %65 : index
    %70 = arith.cmpi slt, %69, %c0 : index
    %71 = arith.select %70, %c0, %69 : index
    %72 = arith.muli %29, %c32 : index
    %73 = arith.addi %72, %52 : index
    %74 = arith.muli %37, %c128 : index
    %75 = arith.addi %74, %66 : index
    cf.br ^bb1(%c0 : index)
  ^bb1(%76: index):  // 2 preds: ^bb0, ^bb5
    %77 = arith.cmpi slt, %76, %57 : index
    cf.cond_br %77, ^bb2, ^bb6(%c0 : index)
  ^bb2:  // pred: ^bb1
    %78 = arith.addi %73, %76 : index
    cf.br ^bb3(%c0 : index)
  ^bb3(%79: index):  // 2 preds: ^bb2, ^bb4
    %80 = arith.cmpi slt, %79, %71 : index
    cf.cond_br %80, ^bb4, ^bb5
  ^bb4:  // pred: ^bb3
    %81 = arith.addi %75, %79 : index
    memref.store %cst, %15[%78, %81] : memref<?x?xf32, #gpu.address_space<global>>
    %82 = arith.addi %79, %c1 : index
    cf.br ^bb3(%82 : index)
  ^bb5:  // pred: ^bb3
    %83 = arith.addi %76, %c1 : index
    cf.br ^bb1(%83 : index)
  ^bb6(%84: index):  // 2 preds: ^bb1, ^bb12
    %85 = arith.cmpi slt, %84, %13 : index
    cf.cond_br %85, ^bb7(%c0 : index), ^bb13
  ^bb7(%86: index):  // 2 preds: ^bb6, ^bb11
    %87 = arith.cmpi slt, %86, %57 : index
    cf.cond_br %87, ^bb8, ^bb12
  ^bb8:  // pred: ^bb7
    %88 = arith.addi %73, %86 : index
    cf.br ^bb9(%c0 : index)
  ^bb9(%89: index):  // 2 preds: ^bb8, ^bb10
    %90 = arith.cmpi slt, %89, %71 : index
    cf.cond_br %90, ^bb10, ^bb11
  ^bb10:  // pred: ^bb9
    %91 = memref.load %14[%88, %84] : memref<?x?xf32, #gpu.address_space<global>>
    %92 = arith.addi %75, %89 : index
    %93 = memref.load %14[%84, %92] : memref<?x?xf32, #gpu.address_space<global>>
    %94 = memref.load %15[%88, %92] : memref<?x?xf32, #gpu.address_space<global>>
    %95 = arith.mulf %91, %93 : f32
    %96 = arith.addf %94, %95 : f32
    memref.store %96, %15[%88, %92] : memref<?x?xf32, #gpu.address_space<global>>
    %97 = arith.addi %89, %c1 : index
    cf.br ^bb9(%97 : index)
  ^bb11:  // pred: ^bb9
    %98 = arith.addi %86, %c1 : index
    cf.br ^bb7(%98 : index)
  ^bb12:  // pred: ^bb7
    %99 = arith.addi %84, %c1 : index
    cf.br ^bb6(%99 : index)
  ^bb13:  // pred: ^bb6
    return
  }
}

// -----// IR Dump After ExpandStridedMetadata (expand-strided-metadata) //----- //
module {
  func.func @main_dispatch_0_matmul_DxDxD_f32() {
    %c8 = arith.constant 8 : index
    %c-128 = arith.constant -128 : index
    %c-32 = arith.constant -32 : index
    %c-1 = arith.constant -1 : index
    %c128 = arith.constant 128 : index
    %c32 = arith.constant 32 : index
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c32_i64 = arith.constant 32 : i64
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.interface.constant.load[0] : i32
    %1 = hal.interface.constant.load[1] : i32
    %2 = hal.interface.constant.load[2] : i32
    %3 = hal.interface.constant.load[3] : i32
    %4 = arith.extui %0 : i32 to i64
    %5 = arith.extui %1 : i32 to i64
    %6 = arith.shli %5, %c32_i64 : i64
    %7 = arith.ori %4, %6 : i64
    %8 = arith.index_castui %7 : i64 to index
    %9 = arith.extui %2 : i32 to i64
    %10 = arith.extui %3 : i32 to i64
    %11 = arith.shli %10, %c32_i64 : i64
    %12 = arith.ori %9, %11 : i64
    %13 = arith.index_castui %12 : i64 to index
    %14 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32, #gpu.address_space<global>>{%8, %13}
    memref.assume_alignment %14, 64 : memref<?x?xf32, #gpu.address_space<global>>
    %15 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : memref<?x?xf32, #gpu.address_space<global>>{%8, %13}
    memref.assume_alignment %15, 64 : memref<?x?xf32, #gpu.address_space<global>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %16 = arith.cmpi sle, %13, %c0 : index
    %17 = arith.subi %c0, %13 : index
    %18 = arith.subi %13, %c1 : index
    %19 = arith.select %16, %17, %18 : index
    %20 = arith.divsi %19, %c128 : index
    %21 = arith.subi %c0, %20 : index
    %22 = arith.addi %20, %c1 : index
    %23 = arith.select %16, %21, %22 : index
    %24 = arith.cmpi slt, %workgroup_id_x, %c0 : index
    %25 = arith.subi %c-1, %workgroup_id_x : index
    %26 = arith.select %24, %25, %workgroup_id_x : index
    %27 = arith.divsi %26, %23 : index
    %28 = arith.subi %c-1, %27 : index
    %29 = arith.select %24, %28, %27 : index
    %30 = arith.muli %29, %c-32 : index
    %31 = arith.addi %8, %30 : index
    %32 = arith.cmpi sgt, %31, %c32 : index
    %33 = arith.select %32, %c32, %31 : index
    %34 = arith.remsi %workgroup_id_x, %23 : index
    %35 = arith.cmpi slt, %34, %c0 : index
    %36 = arith.addi %34, %23 : index
    %37 = arith.select %35, %36, %34 : index
    %38 = arith.muli %37, %c-128 : index
    %39 = arith.addi %13, %38 : index
    %40 = arith.cmpi sgt, %39, %c128 : index
    %41 = arith.select %40, %c128, %39 : index
    %42 = gpu.thread_id  x
    %43 = gpu.thread_id  y
    %44 = arith.cmpi sle, %33, %c0 : index
    %45 = arith.subi %c0, %33 : index
    %46 = arith.subi %33, %c1 : index
    %47 = arith.select %44, %45, %46 : index
    %48 = arith.divsi %47, %c8 : index
    %49 = arith.subi %c0, %48 : index
    %50 = arith.addi %48, %c1 : index
    %51 = arith.select %44, %49, %50 : index
    %52 = arith.muli %43, %51 : index
    %53 = arith.subi %33, %52 : index
    %54 = arith.cmpi slt, %53, %51 : index
    %55 = arith.select %54, %53, %51 : index
    %56 = arith.cmpi slt, %55, %c0 : index
    %57 = arith.select %56, %c0, %55 : index
    %58 = arith.cmpi sle, %41, %c0 : index
    %59 = arith.subi %c0, %41 : index
    %60 = arith.subi %41, %c1 : index
    %61 = arith.select %58, %59, %60 : index
    %62 = arith.divsi %61, %c32 : index
    %63 = arith.subi %c0, %62 : index
    %64 = arith.addi %62, %c1 : index
    %65 = arith.select %58, %63, %64 : index
    %66 = arith.muli %42, %65 : index
    %67 = arith.subi %41, %66 : index
    %68 = arith.cmpi slt, %67, %65 : index
    %69 = arith.select %68, %67, %65 : index
    %70 = arith.cmpi slt, %69, %c0 : index
    %71 = arith.select %70, %c0, %69 : index
    %72 = arith.muli %29, %c32 : index
    %73 = arith.addi %72, %52 : index
    %74 = arith.muli %37, %c128 : index
    %75 = arith.addi %74, %66 : index
    cf.br ^bb1(%c0 : index)
  ^bb1(%76: index):  // 2 preds: ^bb0, ^bb5
    %77 = arith.cmpi slt, %76, %57 : index
    cf.cond_br %77, ^bb2, ^bb6(%c0 : index)
  ^bb2:  // pred: ^bb1
    %78 = arith.addi %73, %76 : index
    cf.br ^bb3(%c0 : index)
  ^bb3(%79: index):  // 2 preds: ^bb2, ^bb4
    %80 = arith.cmpi slt, %79, %71 : index
    cf.cond_br %80, ^bb4, ^bb5
  ^bb4:  // pred: ^bb3
    %81 = arith.addi %75, %79 : index
    memref.store %cst, %15[%78, %81] : memref<?x?xf32, #gpu.address_space<global>>
    %82 = arith.addi %79, %c1 : index
    cf.br ^bb3(%82 : index)
  ^bb5:  // pred: ^bb3
    %83 = arith.addi %76, %c1 : index
    cf.br ^bb1(%83 : index)
  ^bb6(%84: index):  // 2 preds: ^bb1, ^bb12
    %85 = arith.cmpi slt, %84, %13 : index
    cf.cond_br %85, ^bb7(%c0 : index), ^bb13
  ^bb7(%86: index):  // 2 preds: ^bb6, ^bb11
    %87 = arith.cmpi slt, %86, %57 : index
    cf.cond_br %87, ^bb8, ^bb12
  ^bb8:  // pred: ^bb7
    %88 = arith.addi %73, %86 : index
    cf.br ^bb9(%c0 : index)
  ^bb9(%89: index):  // 2 preds: ^bb8, ^bb10
    %90 = arith.cmpi slt, %89, %71 : index
    cf.cond_br %90, ^bb10, ^bb11
  ^bb10:  // pred: ^bb9
    %91 = memref.load %14[%88, %84] : memref<?x?xf32, #gpu.address_space<global>>
    %92 = arith.addi %75, %89 : index
    %93 = memref.load %14[%84, %92] : memref<?x?xf32, #gpu.address_space<global>>
    %94 = memref.load %15[%88, %92] : memref<?x?xf32, #gpu.address_space<global>>
    %95 = arith.mulf %91, %93 : f32
    %96 = arith.addf %94, %95 : f32
    memref.store %96, %15[%88, %92] : memref<?x?xf32, #gpu.address_space<global>>
    %97 = arith.addi %89, %c1 : index
    cf.br ^bb9(%97 : index)
  ^bb11:  // pred: ^bb9
    %98 = arith.addi %86, %c1 : index
    cf.br ^bb7(%98 : index)
  ^bb12:  // pred: ^bb7
    %99 = arith.addi %84, %c1 : index
    cf.br ^bb6(%99 : index)
  ^bb13:  // pred: ^bb6
    return
  }
}

// -----// IR Dump After EmulateNarrowType (iree-codegen-emulate-narrow-type) //----- //
module {
  func.func @main_dispatch_0_matmul_DxDxD_f32() {
    %c8 = arith.constant 8 : index
    %c-128 = arith.constant -128 : index
    %c-32 = arith.constant -32 : index
    %c-1 = arith.constant -1 : index
    %c128 = arith.constant 128 : index
    %c32 = arith.constant 32 : index
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c32_i64 = arith.constant 32 : i64
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.interface.constant.load[0] : i32
    %1 = hal.interface.constant.load[1] : i32
    %2 = hal.interface.constant.load[2] : i32
    %3 = hal.interface.constant.load[3] : i32
    %4 = arith.extui %0 : i32 to i64
    %5 = arith.extui %1 : i32 to i64
    %6 = arith.shli %5, %c32_i64 : i64
    %7 = arith.ori %4, %6 : i64
    %8 = arith.index_castui %7 : i64 to index
    %9 = arith.extui %2 : i32 to i64
    %10 = arith.extui %3 : i32 to i64
    %11 = arith.shli %10, %c32_i64 : i64
    %12 = arith.ori %9, %11 : i64
    %13 = arith.index_castui %12 : i64 to index
    %14 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32, #gpu.address_space<global>>{%8, %13}
    memref.assume_alignment %14, 64 : memref<?x?xf32, #gpu.address_space<global>>
    %15 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : memref<?x?xf32, #gpu.address_space<global>>{%8, %13}
    memref.assume_alignment %15, 64 : memref<?x?xf32, #gpu.address_space<global>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %16 = arith.cmpi sle, %13, %c0 : index
    %17 = arith.subi %c0, %13 : index
    %18 = arith.subi %13, %c1 : index
    %19 = arith.select %16, %17, %18 : index
    %20 = arith.divsi %19, %c128 : index
    %21 = arith.subi %c0, %20 : index
    %22 = arith.addi %20, %c1 : index
    %23 = arith.select %16, %21, %22 : index
    %24 = arith.cmpi slt, %workgroup_id_x, %c0 : index
    %25 = arith.subi %c-1, %workgroup_id_x : index
    %26 = arith.select %24, %25, %workgroup_id_x : index
    %27 = arith.divsi %26, %23 : index
    %28 = arith.subi %c-1, %27 : index
    %29 = arith.select %24, %28, %27 : index
    %30 = arith.muli %29, %c-32 : index
    %31 = arith.addi %8, %30 : index
    %32 = arith.cmpi sgt, %31, %c32 : index
    %33 = arith.select %32, %c32, %31 : index
    %34 = arith.remsi %workgroup_id_x, %23 : index
    %35 = arith.cmpi slt, %34, %c0 : index
    %36 = arith.addi %34, %23 : index
    %37 = arith.select %35, %36, %34 : index
    %38 = arith.muli %37, %c-128 : index
    %39 = arith.addi %13, %38 : index
    %40 = arith.cmpi sgt, %39, %c128 : index
    %41 = arith.select %40, %c128, %39 : index
    %42 = gpu.thread_id  x
    %43 = gpu.thread_id  y
    %44 = arith.cmpi sle, %33, %c0 : index
    %45 = arith.subi %c0, %33 : index
    %46 = arith.subi %33, %c1 : index
    %47 = arith.select %44, %45, %46 : index
    %48 = arith.divsi %47, %c8 : index
    %49 = arith.subi %c0, %48 : index
    %50 = arith.addi %48, %c1 : index
    %51 = arith.select %44, %49, %50 : index
    %52 = arith.muli %43, %51 : index
    %53 = arith.subi %33, %52 : index
    %54 = arith.cmpi slt, %53, %51 : index
    %55 = arith.select %54, %53, %51 : index
    %56 = arith.cmpi slt, %55, %c0 : index
    %57 = arith.select %56, %c0, %55 : index
    %58 = arith.cmpi sle, %41, %c0 : index
    %59 = arith.subi %c0, %41 : index
    %60 = arith.subi %41, %c1 : index
    %61 = arith.select %58, %59, %60 : index
    %62 = arith.divsi %61, %c32 : index
    %63 = arith.subi %c0, %62 : index
    %64 = arith.addi %62, %c1 : index
    %65 = arith.select %58, %63, %64 : index
    %66 = arith.muli %42, %65 : index
    %67 = arith.subi %41, %66 : index
    %68 = arith.cmpi slt, %67, %65 : index
    %69 = arith.select %68, %67, %65 : index
    %70 = arith.cmpi slt, %69, %c0 : index
    %71 = arith.select %70, %c0, %69 : index
    %72 = arith.muli %29, %c32 : index
    %73 = arith.addi %72, %52 : index
    %74 = arith.muli %37, %c128 : index
    %75 = arith.addi %74, %66 : index
    cf.br ^bb1(%c0 : index)
  ^bb1(%76: index):  // 2 preds: ^bb0, ^bb5
    %77 = arith.cmpi slt, %76, %57 : index
    cf.cond_br %77, ^bb2, ^bb6(%c0 : index)
  ^bb2:  // pred: ^bb1
    %78 = arith.addi %73, %76 : index
    cf.br ^bb3(%c0 : index)
  ^bb3(%79: index):  // 2 preds: ^bb2, ^bb4
    %80 = arith.cmpi slt, %79, %71 : index
    cf.cond_br %80, ^bb4, ^bb5
  ^bb4:  // pred: ^bb3
    %81 = arith.addi %75, %79 : index
    memref.store %cst, %15[%78, %81] : memref<?x?xf32, #gpu.address_space<global>>
    %82 = arith.addi %79, %c1 : index
    cf.br ^bb3(%82 : index)
  ^bb5:  // pred: ^bb3
    %83 = arith.addi %76, %c1 : index
    cf.br ^bb1(%83 : index)
  ^bb6(%84: index):  // 2 preds: ^bb1, ^bb12
    %85 = arith.cmpi slt, %84, %13 : index
    cf.cond_br %85, ^bb7(%c0 : index), ^bb13
  ^bb7(%86: index):  // 2 preds: ^bb6, ^bb11
    %87 = arith.cmpi slt, %86, %57 : index
    cf.cond_br %87, ^bb8, ^bb12
  ^bb8:  // pred: ^bb7
    %88 = arith.addi %73, %86 : index
    cf.br ^bb9(%c0 : index)
  ^bb9(%89: index):  // 2 preds: ^bb8, ^bb10
    %90 = arith.cmpi slt, %89, %71 : index
    cf.cond_br %90, ^bb10, ^bb11
  ^bb10:  // pred: ^bb9
    %91 = memref.load %14[%88, %84] : memref<?x?xf32, #gpu.address_space<global>>
    %92 = arith.addi %75, %89 : index
    %93 = memref.load %14[%84, %92] : memref<?x?xf32, #gpu.address_space<global>>
    %94 = memref.load %15[%88, %92] : memref<?x?xf32, #gpu.address_space<global>>
    %95 = arith.mulf %91, %93 : f32
    %96 = arith.addf %94, %95 : f32
    memref.store %96, %15[%88, %92] : memref<?x?xf32, #gpu.address_space<global>>
    %97 = arith.addi %89, %c1 : index
    cf.br ^bb9(%97 : index)
  ^bb11:  // pred: ^bb9
    %98 = arith.addi %86, %c1 : index
    cf.br ^bb7(%98 : index)
  ^bb12:  // pred: ^bb7
    %99 = arith.addi %84, %c1 : index
    cf.br ^bb6(%99 : index)
  ^bb13:  // pred: ^bb6
    return
  }
}

// -----// IR Dump After ConvertAffineToStandard (lower-affine) //----- //
module {
  func.func @main_dispatch_0_matmul_DxDxD_f32() {
    %c8 = arith.constant 8 : index
    %c-128 = arith.constant -128 : index
    %c-32 = arith.constant -32 : index
    %c-1 = arith.constant -1 : index
    %c128 = arith.constant 128 : index
    %c32 = arith.constant 32 : index
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c32_i64 = arith.constant 32 : i64
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.interface.constant.load[0] : i32
    %1 = hal.interface.constant.load[1] : i32
    %2 = hal.interface.constant.load[2] : i32
    %3 = hal.interface.constant.load[3] : i32
    %4 = arith.extui %0 : i32 to i64
    %5 = arith.extui %1 : i32 to i64
    %6 = arith.shli %5, %c32_i64 : i64
    %7 = arith.ori %4, %6 : i64
    %8 = arith.index_castui %7 : i64 to index
    %9 = arith.extui %2 : i32 to i64
    %10 = arith.extui %3 : i32 to i64
    %11 = arith.shli %10, %c32_i64 : i64
    %12 = arith.ori %9, %11 : i64
    %13 = arith.index_castui %12 : i64 to index
    %14 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32, #gpu.address_space<global>>{%8, %13}
    memref.assume_alignment %14, 64 : memref<?x?xf32, #gpu.address_space<global>>
    %15 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : memref<?x?xf32, #gpu.address_space<global>>{%8, %13}
    memref.assume_alignment %15, 64 : memref<?x?xf32, #gpu.address_space<global>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %16 = arith.cmpi sle, %13, %c0 : index
    %17 = arith.subi %c0, %13 : index
    %18 = arith.subi %13, %c1 : index
    %19 = arith.select %16, %17, %18 : index
    %20 = arith.divsi %19, %c128 : index
    %21 = arith.subi %c0, %20 : index
    %22 = arith.addi %20, %c1 : index
    %23 = arith.select %16, %21, %22 : index
    %24 = arith.cmpi slt, %workgroup_id_x, %c0 : index
    %25 = arith.subi %c-1, %workgroup_id_x : index
    %26 = arith.select %24, %25, %workgroup_id_x : index
    %27 = arith.divsi %26, %23 : index
    %28 = arith.subi %c-1, %27 : index
    %29 = arith.select %24, %28, %27 : index
    %30 = arith.muli %29, %c-32 : index
    %31 = arith.addi %8, %30 : index
    %32 = arith.cmpi sgt, %31, %c32 : index
    %33 = arith.select %32, %c32, %31 : index
    %34 = arith.remsi %workgroup_id_x, %23 : index
    %35 = arith.cmpi slt, %34, %c0 : index
    %36 = arith.addi %34, %23 : index
    %37 = arith.select %35, %36, %34 : index
    %38 = arith.muli %37, %c-128 : index
    %39 = arith.addi %13, %38 : index
    %40 = arith.cmpi sgt, %39, %c128 : index
    %41 = arith.select %40, %c128, %39 : index
    %42 = gpu.thread_id  x
    %43 = gpu.thread_id  y
    %44 = arith.cmpi sle, %33, %c0 : index
    %45 = arith.subi %c0, %33 : index
    %46 = arith.subi %33, %c1 : index
    %47 = arith.select %44, %45, %46 : index
    %48 = arith.divsi %47, %c8 : index
    %49 = arith.subi %c0, %48 : index
    %50 = arith.addi %48, %c1 : index
    %51 = arith.select %44, %49, %50 : index
    %52 = arith.muli %43, %51 : index
    %53 = arith.subi %33, %52 : index
    %54 = arith.cmpi slt, %53, %51 : index
    %55 = arith.select %54, %53, %51 : index
    %56 = arith.cmpi slt, %55, %c0 : index
    %57 = arith.select %56, %c0, %55 : index
    %58 = arith.cmpi sle, %41, %c0 : index
    %59 = arith.subi %c0, %41 : index
    %60 = arith.subi %41, %c1 : index
    %61 = arith.select %58, %59, %60 : index
    %62 = arith.divsi %61, %c32 : index
    %63 = arith.subi %c0, %62 : index
    %64 = arith.addi %62, %c1 : index
    %65 = arith.select %58, %63, %64 : index
    %66 = arith.muli %42, %65 : index
    %67 = arith.subi %41, %66 : index
    %68 = arith.cmpi slt, %67, %65 : index
    %69 = arith.select %68, %67, %65 : index
    %70 = arith.cmpi slt, %69, %c0 : index
    %71 = arith.select %70, %c0, %69 : index
    %72 = arith.muli %29, %c32 : index
    %73 = arith.addi %72, %52 : index
    %74 = arith.muli %37, %c128 : index
    %75 = arith.addi %74, %66 : index
    cf.br ^bb1(%c0 : index)
  ^bb1(%76: index):  // 2 preds: ^bb0, ^bb5
    %77 = arith.cmpi slt, %76, %57 : index
    cf.cond_br %77, ^bb2, ^bb6(%c0 : index)
  ^bb2:  // pred: ^bb1
    %78 = arith.addi %73, %76 : index
    cf.br ^bb3(%c0 : index)
  ^bb3(%79: index):  // 2 preds: ^bb2, ^bb4
    %80 = arith.cmpi slt, %79, %71 : index
    cf.cond_br %80, ^bb4, ^bb5
  ^bb4:  // pred: ^bb3
    %81 = arith.addi %75, %79 : index
    memref.store %cst, %15[%78, %81] : memref<?x?xf32, #gpu.address_space<global>>
    %82 = arith.addi %79, %c1 : index
    cf.br ^bb3(%82 : index)
  ^bb5:  // pred: ^bb3
    %83 = arith.addi %76, %c1 : index
    cf.br ^bb1(%83 : index)
  ^bb6(%84: index):  // 2 preds: ^bb1, ^bb12
    %85 = arith.cmpi slt, %84, %13 : index
    cf.cond_br %85, ^bb7(%c0 : index), ^bb13
  ^bb7(%86: index):  // 2 preds: ^bb6, ^bb11
    %87 = arith.cmpi slt, %86, %57 : index
    cf.cond_br %87, ^bb8, ^bb12
  ^bb8:  // pred: ^bb7
    %88 = arith.addi %73, %86 : index
    cf.br ^bb9(%c0 : index)
  ^bb9(%89: index):  // 2 preds: ^bb8, ^bb10
    %90 = arith.cmpi slt, %89, %71 : index
    cf.cond_br %90, ^bb10, ^bb11
  ^bb10:  // pred: ^bb9
    %91 = memref.load %14[%88, %84] : memref<?x?xf32, #gpu.address_space<global>>
    %92 = arith.addi %75, %89 : index
    %93 = memref.load %14[%84, %92] : memref<?x?xf32, #gpu.address_space<global>>
    %94 = memref.load %15[%88, %92] : memref<?x?xf32, #gpu.address_space<global>>
    %95 = arith.mulf %91, %93 : f32
    %96 = arith.addf %94, %95 : f32
    memref.store %96, %15[%88, %92] : memref<?x?xf32, #gpu.address_space<global>>
    %97 = arith.addi %89, %c1 : index
    cf.br ^bb9(%97 : index)
  ^bb11:  // pred: ^bb9
    %98 = arith.addi %86, %c1 : index
    cf.br ^bb7(%98 : index)
  ^bb12:  // pred: ^bb7
    %99 = arith.addi %84, %c1 : index
    cf.br ^bb6(%99 : index)
  ^bb13:  // pred: ^bb6
    return
  }
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
module {
  func.func @main_dispatch_0_matmul_DxDxD_f32() {
    %c8 = arith.constant 8 : index
    %c-128 = arith.constant -128 : index
    %c-32 = arith.constant -32 : index
    %c-1 = arith.constant -1 : index
    %c128 = arith.constant 128 : index
    %c32 = arith.constant 32 : index
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c32_i64 = arith.constant 32 : i64
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.interface.constant.load[0] : i32
    %1 = hal.interface.constant.load[1] : i32
    %2 = hal.interface.constant.load[2] : i32
    %3 = hal.interface.constant.load[3] : i32
    %4 = arith.extui %0 : i32 to i64
    %5 = arith.extui %1 : i32 to i64
    %6 = arith.shli %5, %c32_i64 : i64
    %7 = arith.ori %4, %6 : i64
    %8 = arith.index_castui %7 : i64 to index
    %9 = arith.extui %2 : i32 to i64
    %10 = arith.extui %3 : i32 to i64
    %11 = arith.shli %10, %c32_i64 : i64
    %12 = arith.ori %9, %11 : i64
    %13 = arith.index_castui %12 : i64 to index
    %14 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32, #gpu.address_space<global>>{%8, %13}
    memref.assume_alignment %14, 64 : memref<?x?xf32, #gpu.address_space<global>>
    %15 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : memref<?x?xf32, #gpu.address_space<global>>{%8, %13}
    memref.assume_alignment %15, 64 : memref<?x?xf32, #gpu.address_space<global>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %16 = arith.cmpi sle, %13, %c0 : index
    %17 = arith.subi %c0, %13 : index
    %18 = arith.subi %13, %c1 : index
    %19 = arith.select %16, %17, %18 : index
    %20 = arith.divsi %19, %c128 : index
    %21 = arith.subi %c0, %20 : index
    %22 = arith.addi %20, %c1 : index
    %23 = arith.select %16, %21, %22 : index
    %24 = arith.cmpi slt, %workgroup_id_x, %c0 : index
    %25 = arith.subi %c-1, %workgroup_id_x : index
    %26 = arith.select %24, %25, %workgroup_id_x : index
    %27 = arith.divsi %26, %23 : index
    %28 = arith.subi %c-1, %27 : index
    %29 = arith.select %24, %28, %27 : index
    %30 = arith.muli %29, %c-32 : index
    %31 = arith.addi %8, %30 : index
    %32 = arith.cmpi sgt, %31, %c32 : index
    %33 = arith.select %32, %c32, %31 : index
    %34 = arith.remsi %workgroup_id_x, %23 : index
    %35 = arith.cmpi slt, %34, %c0 : index
    %36 = arith.addi %34, %23 : index
    %37 = arith.select %35, %36, %34 : index
    %38 = arith.muli %37, %c-128 : index
    %39 = arith.addi %13, %38 : index
    %40 = arith.cmpi sgt, %39, %c128 : index
    %41 = arith.select %40, %c128, %39 : index
    %42 = gpu.thread_id  x
    %43 = gpu.thread_id  y
    %44 = arith.cmpi sle, %33, %c0 : index
    %45 = arith.subi %c0, %33 : index
    %46 = arith.subi %33, %c1 : index
    %47 = arith.select %44, %45, %46 : index
    %48 = arith.divsi %47, %c8 : index
    %49 = arith.subi %c0, %48 : index
    %50 = arith.addi %48, %c1 : index
    %51 = arith.select %44, %49, %50 : index
    %52 = arith.muli %43, %51 : index
    %53 = arith.subi %33, %52 : index
    %54 = arith.cmpi slt, %53, %51 : index
    %55 = arith.select %54, %53, %51 : index
    %56 = arith.cmpi slt, %55, %c0 : index
    %57 = arith.select %56, %c0, %55 : index
    %58 = arith.cmpi sle, %41, %c0 : index
    %59 = arith.subi %c0, %41 : index
    %60 = arith.subi %41, %c1 : index
    %61 = arith.select %58, %59, %60 : index
    %62 = arith.divsi %61, %c32 : index
    %63 = arith.subi %c0, %62 : index
    %64 = arith.addi %62, %c1 : index
    %65 = arith.select %58, %63, %64 : index
    %66 = arith.muli %42, %65 : index
    %67 = arith.subi %41, %66 : index
    %68 = arith.cmpi slt, %67, %65 : index
    %69 = arith.select %68, %67, %65 : index
    %70 = arith.cmpi slt, %69, %c0 : index
    %71 = arith.select %70, %c0, %69 : index
    %72 = arith.muli %29, %c32 : index
    %73 = arith.addi %72, %52 : index
    %74 = arith.muli %37, %c128 : index
    %75 = arith.addi %74, %66 : index
    cf.br ^bb1(%c0 : index)
  ^bb1(%76: index):  // 2 preds: ^bb0, ^bb5
    %77 = arith.cmpi slt, %76, %57 : index
    cf.cond_br %77, ^bb2, ^bb6(%c0 : index)
  ^bb2:  // pred: ^bb1
    %78 = arith.addi %73, %76 : index
    cf.br ^bb3(%c0 : index)
  ^bb3(%79: index):  // 2 preds: ^bb2, ^bb4
    %80 = arith.cmpi slt, %79, %71 : index
    cf.cond_br %80, ^bb4, ^bb5
  ^bb4:  // pred: ^bb3
    %81 = arith.addi %75, %79 : index
    memref.store %cst, %15[%78, %81] : memref<?x?xf32, #gpu.address_space<global>>
    %82 = arith.addi %79, %c1 : index
    cf.br ^bb3(%82 : index)
  ^bb5:  // pred: ^bb3
    %83 = arith.addi %76, %c1 : index
    cf.br ^bb1(%83 : index)
  ^bb6(%84: index):  // 2 preds: ^bb1, ^bb12
    %85 = arith.cmpi slt, %84, %13 : index
    cf.cond_br %85, ^bb7(%c0 : index), ^bb13
  ^bb7(%86: index):  // 2 preds: ^bb6, ^bb11
    %87 = arith.cmpi slt, %86, %57 : index
    cf.cond_br %87, ^bb8, ^bb12
  ^bb8:  // pred: ^bb7
    %88 = arith.addi %73, %86 : index
    cf.br ^bb9(%c0 : index)
  ^bb9(%89: index):  // 2 preds: ^bb8, ^bb10
    %90 = arith.cmpi slt, %89, %71 : index
    cf.cond_br %90, ^bb10, ^bb11
  ^bb10:  // pred: ^bb9
    %91 = memref.load %14[%88, %84] : memref<?x?xf32, #gpu.address_space<global>>
    %92 = arith.addi %75, %89 : index
    %93 = memref.load %14[%84, %92] : memref<?x?xf32, #gpu.address_space<global>>
    %94 = memref.load %15[%88, %92] : memref<?x?xf32, #gpu.address_space<global>>
    %95 = arith.mulf %91, %93 : f32
    %96 = arith.addf %94, %95 : f32
    memref.store %96, %15[%88, %92] : memref<?x?xf32, #gpu.address_space<global>>
    %97 = arith.addi %89, %c1 : index
    cf.br ^bb9(%97 : index)
  ^bb11:  // pred: ^bb9
    %98 = arith.addi %86, %c1 : index
    cf.br ^bb7(%98 : index)
  ^bb12:  // pred: ^bb7
    %99 = arith.addi %84, %c1 : index
    cf.br ^bb6(%99 : index)
  ^bb13:  // pred: ^bb6
    return
  }
}

// -----// IR Dump After CSE (cse) //----- //
module {
  func.func @main_dispatch_0_matmul_DxDxD_f32() {
    %c8 = arith.constant 8 : index
    %c-128 = arith.constant -128 : index
    %c-32 = arith.constant -32 : index
    %c-1 = arith.constant -1 : index
    %c128 = arith.constant 128 : index
    %c32 = arith.constant 32 : index
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c32_i64 = arith.constant 32 : i64
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.interface.constant.load[0] : i32
    %1 = hal.interface.constant.load[1] : i32
    %2 = hal.interface.constant.load[2] : i32
    %3 = hal.interface.constant.load[3] : i32
    %4 = arith.extui %0 : i32 to i64
    %5 = arith.extui %1 : i32 to i64
    %6 = arith.shli %5, %c32_i64 : i64
    %7 = arith.ori %4, %6 : i64
    %8 = arith.index_castui %7 : i64 to index
    %9 = arith.extui %2 : i32 to i64
    %10 = arith.extui %3 : i32 to i64
    %11 = arith.shli %10, %c32_i64 : i64
    %12 = arith.ori %9, %11 : i64
    %13 = arith.index_castui %12 : i64 to index
    %14 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32, #gpu.address_space<global>>{%8, %13}
    memref.assume_alignment %14, 64 : memref<?x?xf32, #gpu.address_space<global>>
    %15 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : memref<?x?xf32, #gpu.address_space<global>>{%8, %13}
    memref.assume_alignment %15, 64 : memref<?x?xf32, #gpu.address_space<global>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %16 = arith.cmpi sle, %13, %c0 : index
    %17 = arith.subi %c0, %13 : index
    %18 = arith.subi %13, %c1 : index
    %19 = arith.select %16, %17, %18 : index
    %20 = arith.divsi %19, %c128 : index
    %21 = arith.subi %c0, %20 : index
    %22 = arith.addi %20, %c1 : index
    %23 = arith.select %16, %21, %22 : index
    %24 = arith.cmpi slt, %workgroup_id_x, %c0 : index
    %25 = arith.subi %c-1, %workgroup_id_x : index
    %26 = arith.select %24, %25, %workgroup_id_x : index
    %27 = arith.divsi %26, %23 : index
    %28 = arith.subi %c-1, %27 : index
    %29 = arith.select %24, %28, %27 : index
    %30 = arith.muli %29, %c-32 : index
    %31 = arith.addi %8, %30 : index
    %32 = arith.cmpi sgt, %31, %c32 : index
    %33 = arith.select %32, %c32, %31 : index
    %34 = arith.remsi %workgroup_id_x, %23 : index
    %35 = arith.cmpi slt, %34, %c0 : index
    %36 = arith.addi %34, %23 : index
    %37 = arith.select %35, %36, %34 : index
    %38 = arith.muli %37, %c-128 : index
    %39 = arith.addi %13, %38 : index
    %40 = arith.cmpi sgt, %39, %c128 : index
    %41 = arith.select %40, %c128, %39 : index
    %42 = gpu.thread_id  x
    %43 = gpu.thread_id  y
    %44 = arith.cmpi sle, %33, %c0 : index
    %45 = arith.subi %c0, %33 : index
    %46 = arith.subi %33, %c1 : index
    %47 = arith.select %44, %45, %46 : index
    %48 = arith.divsi %47, %c8 : index
    %49 = arith.subi %c0, %48 : index
    %50 = arith.addi %48, %c1 : index
    %51 = arith.select %44, %49, %50 : index
    %52 = arith.muli %43, %51 : index
    %53 = arith.subi %33, %52 : index
    %54 = arith.cmpi slt, %53, %51 : index
    %55 = arith.select %54, %53, %51 : index
    %56 = arith.cmpi slt, %55, %c0 : index
    %57 = arith.select %56, %c0, %55 : index
    %58 = arith.cmpi sle, %41, %c0 : index
    %59 = arith.subi %c0, %41 : index
    %60 = arith.subi %41, %c1 : index
    %61 = arith.select %58, %59, %60 : index
    %62 = arith.divsi %61, %c32 : index
    %63 = arith.subi %c0, %62 : index
    %64 = arith.addi %62, %c1 : index
    %65 = arith.select %58, %63, %64 : index
    %66 = arith.muli %42, %65 : index
    %67 = arith.subi %41, %66 : index
    %68 = arith.cmpi slt, %67, %65 : index
    %69 = arith.select %68, %67, %65 : index
    %70 = arith.cmpi slt, %69, %c0 : index
    %71 = arith.select %70, %c0, %69 : index
    %72 = arith.muli %29, %c32 : index
    %73 = arith.addi %72, %52 : index
    %74 = arith.muli %37, %c128 : index
    %75 = arith.addi %74, %66 : index
    cf.br ^bb1(%c0 : index)
  ^bb1(%76: index):  // 2 preds: ^bb0, ^bb5
    %77 = arith.cmpi slt, %76, %57 : index
    cf.cond_br %77, ^bb2, ^bb6(%c0 : index)
  ^bb2:  // pred: ^bb1
    %78 = arith.addi %73, %76 : index
    cf.br ^bb3(%c0 : index)
  ^bb3(%79: index):  // 2 preds: ^bb2, ^bb4
    %80 = arith.cmpi slt, %79, %71 : index
    cf.cond_br %80, ^bb4, ^bb5
  ^bb4:  // pred: ^bb3
    %81 = arith.addi %75, %79 : index
    memref.store %cst, %15[%78, %81] : memref<?x?xf32, #gpu.address_space<global>>
    %82 = arith.addi %79, %c1 : index
    cf.br ^bb3(%82 : index)
  ^bb5:  // pred: ^bb3
    %83 = arith.addi %76, %c1 : index
    cf.br ^bb1(%83 : index)
  ^bb6(%84: index):  // 2 preds: ^bb1, ^bb12
    %85 = arith.cmpi slt, %84, %13 : index
    cf.cond_br %85, ^bb7(%c0 : index), ^bb13
  ^bb7(%86: index):  // 2 preds: ^bb6, ^bb11
    %87 = arith.cmpi slt, %86, %57 : index
    cf.cond_br %87, ^bb8, ^bb12
  ^bb8:  // pred: ^bb7
    %88 = arith.addi %73, %86 : index
    cf.br ^bb9(%c0 : index)
  ^bb9(%89: index):  // 2 preds: ^bb8, ^bb10
    %90 = arith.cmpi slt, %89, %71 : index
    cf.cond_br %90, ^bb10, ^bb11
  ^bb10:  // pred: ^bb9
    %91 = memref.load %14[%88, %84] : memref<?x?xf32, #gpu.address_space<global>>
    %92 = arith.addi %75, %89 : index
    %93 = memref.load %14[%84, %92] : memref<?x?xf32, #gpu.address_space<global>>
    %94 = memref.load %15[%88, %92] : memref<?x?xf32, #gpu.address_space<global>>
    %95 = arith.mulf %91, %93 : f32
    %96 = arith.addf %94, %95 : f32
    memref.store %96, %15[%88, %92] : memref<?x?xf32, #gpu.address_space<global>>
    %97 = arith.addi %89, %c1 : index
    cf.br ^bb9(%97 : index)
  ^bb11:  // pred: ^bb9
    %98 = arith.addi %86, %c1 : index
    cf.br ^bb7(%98 : index)
  ^bb12:  // pred: ^bb7
    %99 = arith.addi %84, %c1 : index
    cf.br ^bb6(%99 : index)
  ^bb13:  // pred: ^bb6
    return
  }
}

// -----// IR Dump After StripDebugInfo (strip-debuginfo) //----- //
module {
  func.func @main_dispatch_0_matmul_DxDxD_f32() {
    %c8 = arith.constant 8 : index
    %c-128 = arith.constant -128 : index
    %c-32 = arith.constant -32 : index
    %c-1 = arith.constant -1 : index
    %c128 = arith.constant 128 : index
    %c32 = arith.constant 32 : index
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c32_i64 = arith.constant 32 : i64
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.interface.constant.load[0] : i32
    %1 = hal.interface.constant.load[1] : i32
    %2 = hal.interface.constant.load[2] : i32
    %3 = hal.interface.constant.load[3] : i32
    %4 = arith.extui %0 : i32 to i64
    %5 = arith.extui %1 : i32 to i64
    %6 = arith.shli %5, %c32_i64 : i64
    %7 = arith.ori %4, %6 : i64
    %8 = arith.index_castui %7 : i64 to index
    %9 = arith.extui %2 : i32 to i64
    %10 = arith.extui %3 : i32 to i64
    %11 = arith.shli %10, %c32_i64 : i64
    %12 = arith.ori %9, %11 : i64
    %13 = arith.index_castui %12 : i64 to index
    %14 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32, #gpu.address_space<global>>{%8, %13}
    memref.assume_alignment %14, 64 : memref<?x?xf32, #gpu.address_space<global>>
    %15 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : memref<?x?xf32, #gpu.address_space<global>>{%8, %13}
    memref.assume_alignment %15, 64 : memref<?x?xf32, #gpu.address_space<global>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %16 = arith.cmpi sle, %13, %c0 : index
    %17 = arith.subi %c0, %13 : index
    %18 = arith.subi %13, %c1 : index
    %19 = arith.select %16, %17, %18 : index
    %20 = arith.divsi %19, %c128 : index
    %21 = arith.subi %c0, %20 : index
    %22 = arith.addi %20, %c1 : index
    %23 = arith.select %16, %21, %22 : index
    %24 = arith.cmpi slt, %workgroup_id_x, %c0 : index
    %25 = arith.subi %c-1, %workgroup_id_x : index
    %26 = arith.select %24, %25, %workgroup_id_x : index
    %27 = arith.divsi %26, %23 : index
    %28 = arith.subi %c-1, %27 : index
    %29 = arith.select %24, %28, %27 : index
    %30 = arith.muli %29, %c-32 : index
    %31 = arith.addi %8, %30 : index
    %32 = arith.cmpi sgt, %31, %c32 : index
    %33 = arith.select %32, %c32, %31 : index
    %34 = arith.remsi %workgroup_id_x, %23 : index
    %35 = arith.cmpi slt, %34, %c0 : index
    %36 = arith.addi %34, %23 : index
    %37 = arith.select %35, %36, %34 : index
    %38 = arith.muli %37, %c-128 : index
    %39 = arith.addi %13, %38 : index
    %40 = arith.cmpi sgt, %39, %c128 : index
    %41 = arith.select %40, %c128, %39 : index
    %42 = gpu.thread_id  x
    %43 = gpu.thread_id  y
    %44 = arith.cmpi sle, %33, %c0 : index
    %45 = arith.subi %c0, %33 : index
    %46 = arith.subi %33, %c1 : index
    %47 = arith.select %44, %45, %46 : index
    %48 = arith.divsi %47, %c8 : index
    %49 = arith.subi %c0, %48 : index
    %50 = arith.addi %48, %c1 : index
    %51 = arith.select %44, %49, %50 : index
    %52 = arith.muli %43, %51 : index
    %53 = arith.subi %33, %52 : index
    %54 = arith.cmpi slt, %53, %51 : index
    %55 = arith.select %54, %53, %51 : index
    %56 = arith.cmpi slt, %55, %c0 : index
    %57 = arith.select %56, %c0, %55 : index
    %58 = arith.cmpi sle, %41, %c0 : index
    %59 = arith.subi %c0, %41 : index
    %60 = arith.subi %41, %c1 : index
    %61 = arith.select %58, %59, %60 : index
    %62 = arith.divsi %61, %c32 : index
    %63 = arith.subi %c0, %62 : index
    %64 = arith.addi %62, %c1 : index
    %65 = arith.select %58, %63, %64 : index
    %66 = arith.muli %42, %65 : index
    %67 = arith.subi %41, %66 : index
    %68 = arith.cmpi slt, %67, %65 : index
    %69 = arith.select %68, %67, %65 : index
    %70 = arith.cmpi slt, %69, %c0 : index
    %71 = arith.select %70, %c0, %69 : index
    %72 = arith.muli %29, %c32 : index
    %73 = arith.addi %72, %52 : index
    %74 = arith.muli %37, %c128 : index
    %75 = arith.addi %74, %66 : index
    cf.br ^bb1(%c0 : index)
  ^bb1(%76: index):  // 2 preds: ^bb0, ^bb5
    %77 = arith.cmpi slt, %76, %57 : index
    cf.cond_br %77, ^bb2, ^bb6(%c0 : index)
  ^bb2:  // pred: ^bb1
    %78 = arith.addi %73, %76 : index
    cf.br ^bb3(%c0 : index)
  ^bb3(%79: index):  // 2 preds: ^bb2, ^bb4
    %80 = arith.cmpi slt, %79, %71 : index
    cf.cond_br %80, ^bb4, ^bb5
  ^bb4:  // pred: ^bb3
    %81 = arith.addi %75, %79 : index
    memref.store %cst, %15[%78, %81] : memref<?x?xf32, #gpu.address_space<global>>
    %82 = arith.addi %79, %c1 : index
    cf.br ^bb3(%82 : index)
  ^bb5:  // pred: ^bb3
    %83 = arith.addi %76, %c1 : index
    cf.br ^bb1(%83 : index)
  ^bb6(%84: index):  // 2 preds: ^bb1, ^bb12
    %85 = arith.cmpi slt, %84, %13 : index
    cf.cond_br %85, ^bb7(%c0 : index), ^bb13
  ^bb7(%86: index):  // 2 preds: ^bb6, ^bb11
    %87 = arith.cmpi slt, %86, %57 : index
    cf.cond_br %87, ^bb8, ^bb12
  ^bb8:  // pred: ^bb7
    %88 = arith.addi %73, %86 : index
    cf.br ^bb9(%c0 : index)
  ^bb9(%89: index):  // 2 preds: ^bb8, ^bb10
    %90 = arith.cmpi slt, %89, %71 : index
    cf.cond_br %90, ^bb10, ^bb11
  ^bb10:  // pred: ^bb9
    %91 = memref.load %14[%88, %84] : memref<?x?xf32, #gpu.address_space<global>>
    %92 = arith.addi %75, %89 : index
    %93 = memref.load %14[%84, %92] : memref<?x?xf32, #gpu.address_space<global>>
    %94 = memref.load %15[%88, %92] : memref<?x?xf32, #gpu.address_space<global>>
    %95 = arith.mulf %91, %93 : f32
    %96 = arith.addf %94, %95 : f32
    memref.store %96, %15[%88, %92] : memref<?x?xf32, #gpu.address_space<global>>
    %97 = arith.addi %89, %c1 : index
    cf.br ^bb9(%97 : index)
  ^bb11:  // pred: ^bb9
    %98 = arith.addi %86, %c1 : index
    cf.br ^bb7(%98 : index)
  ^bb12:  // pred: ^bb7
    %99 = arith.addi %84, %c1 : index
    cf.br ^bb6(%99 : index)
  ^bb13:  // pred: ^bb6
    return
  }
}

// -----// IR Dump After LLVMGPUCastAddressSpaceFunction (iree-llvmgpu-cast-address-space-function) //----- //
module {
  func.func @main_dispatch_0_matmul_DxDxD_f32() {
    %c8 = arith.constant 8 : index
    %c-128 = arith.constant -128 : index
    %c-32 = arith.constant -32 : index
    %c-1 = arith.constant -1 : index
    %c128 = arith.constant 128 : index
    %c32 = arith.constant 32 : index
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c32_i64 = arith.constant 32 : i64
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.interface.constant.load[0] : i32
    %1 = hal.interface.constant.load[1] : i32
    %2 = hal.interface.constant.load[2] : i32
    %3 = hal.interface.constant.load[3] : i32
    %4 = arith.extui %0 : i32 to i64
    %5 = arith.extui %1 : i32 to i64
    %6 = arith.shli %5, %c32_i64 : i64
    %7 = arith.ori %4, %6 : i64
    %8 = arith.index_castui %7 : i64 to index
    %9 = arith.extui %2 : i32 to i64
    %10 = arith.extui %3 : i32 to i64
    %11 = arith.shli %10, %c32_i64 : i64
    %12 = arith.ori %9, %11 : i64
    %13 = arith.index_castui %12 : i64 to index
    %14 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32, #gpu.address_space<global>>{%8, %13}
    memref.assume_alignment %14, 64 : memref<?x?xf32, #gpu.address_space<global>>
    %15 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) : memref<?x?xf32, #gpu.address_space<global>>{%8, %13}
    memref.assume_alignment %15, 64 : memref<?x?xf32, #gpu.address_space<global>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %16 = arith.cmpi sle, %13, %c0 : index
    %17 = arith.subi %c0, %13 : index
    %18 = arith.subi %13, %c1 : index
    %19 = arith.select %16, %17, %18 : index
    %20 = arith.divsi %19, %c128 : index
    %21 = arith.subi %c0, %20 : index
    %22 = arith.addi %20, %c1 : index
    %23 = arith.select %16, %21, %22 : index
    %24 = arith.cmpi slt, %workgroup_id_x, %c0 : index
    %25 = arith.subi %c-1, %workgroup_id_x : index
    %26 = arith.select %24, %25, %workgroup_id_x : index
    %27 = arith.divsi %26, %23 : index
    %28 = arith.subi %c-1, %27 : index
    %29 = arith.select %24, %28, %27 : index
    %30 = arith.muli %29, %c-32 : index
    %31 = arith.addi %8, %30 : index
    %32 = arith.cmpi sgt, %31, %c32 : index
    %33 = arith.select %32, %c32, %31 : index
    %34 = arith.remsi %workgroup_id_x, %23 : index
    %35 = arith.cmpi slt, %34, %c0 : index
    %36 = arith.addi %34, %23 : index
    %37 = arith.select %35, %36, %34 : index
    %38 = arith.muli %37, %c-128 : index
    %39 = arith.addi %13, %38 : index
    %40 = arith.cmpi sgt, %39, %c128 : index
    %41 = arith.select %40, %c128, %39 : index
    %42 = gpu.thread_id  x
    %43 = gpu.thread_id  y
    %44 = arith.cmpi sle, %33, %c0 : index
    %45 = arith.subi %c0, %33 : index
    %46 = arith.subi %33, %c1 : index
    %47 = arith.select %44, %45, %46 : index
    %48 = arith.divsi %47, %c8 : index
    %49 = arith.subi %c0, %48 : index
    %50 = arith.addi %48, %c1 : index
    %51 = arith.select %44, %49, %50 : index
    %52 = arith.muli %43, %51 : index
    %53 = arith.subi %33, %52 : index
    %54 = arith.cmpi slt, %53, %51 : index
    %55 = arith.select %54, %53, %51 : index
    %56 = arith.cmpi slt, %55, %c0 : index
    %57 = arith.select %56, %c0, %55 : index
    %58 = arith.cmpi sle, %41, %c0 : index
    %59 = arith.subi %c0, %41 : index
    %60 = arith.subi %41, %c1 : index
    %61 = arith.select %58, %59, %60 : index
    %62 = arith.divsi %61, %c32 : index
    %63 = arith.subi %c0, %62 : index
    %64 = arith.addi %62, %c1 : index
    %65 = arith.select %58, %63, %64 : index
    %66 = arith.muli %42, %65 : index
    %67 = arith.subi %41, %66 : index
    %68 = arith.cmpi slt, %67, %65 : index
    %69 = arith.select %68, %67, %65 : index
    %70 = arith.cmpi slt, %69, %c0 : index
    %71 = arith.select %70, %c0, %69 : index
    %72 = arith.muli %29, %c32 : index
    %73 = arith.addi %72, %52 : index
    %74 = arith.muli %37, %c128 : index
    %75 = arith.addi %74, %66 : index
    cf.br ^bb1(%c0 : index)
  ^bb1(%76: index):  // 2 preds: ^bb0, ^bb5
    %77 = arith.cmpi slt, %76, %57 : index
    cf.cond_br %77, ^bb2, ^bb6(%c0 : index)
  ^bb2:  // pred: ^bb1
    %78 = arith.addi %73, %76 : index
    cf.br ^bb3(%c0 : index)
  ^bb3(%79: index):  // 2 preds: ^bb2, ^bb4
    %80 = arith.cmpi slt, %79, %71 : index
    cf.cond_br %80, ^bb4, ^bb5
  ^bb4:  // pred: ^bb3
    %81 = arith.addi %75, %79 : index
    memref.store %cst, %15[%78, %81] : memref<?x?xf32, #gpu.address_space<global>>
    %82 = arith.addi %79, %c1 : index
    cf.br ^bb3(%82 : index)
  ^bb5:  // pred: ^bb3
    %83 = arith.addi %76, %c1 : index
    cf.br ^bb1(%83 : index)
  ^bb6(%84: index):  // 2 preds: ^bb1, ^bb12
    %85 = arith.cmpi slt, %84, %13 : index
    cf.cond_br %85, ^bb7(%c0 : index), ^bb13
  ^bb7(%86: index):  // 2 preds: ^bb6, ^bb11
    %87 = arith.cmpi slt, %86, %57 : index
    cf.cond_br %87, ^bb8, ^bb12
  ^bb8:  // pred: ^bb7
    %88 = arith.addi %73, %86 : index
    cf.br ^bb9(%c0 : index)
  ^bb9(%89: index):  // 2 preds: ^bb8, ^bb10
    %90 = arith.cmpi slt, %89, %71 : index
    cf.cond_br %90, ^bb10, ^bb11
  ^bb10:  // pred: ^bb9
    %91 = memref.load %14[%88, %84] : memref<?x?xf32, #gpu.address_space<global>>
    %92 = arith.addi %75, %89 : index
    %93 = memref.load %14[%84, %92] : memref<?x?xf32, #gpu.address_space<global>>
    %94 = memref.load %15[%88, %92] : memref<?x?xf32, #gpu.address_space<global>>
    %95 = arith.mulf %91, %93 : f32
    %96 = arith.addf %94, %95 : f32
    memref.store %96, %15[%88, %92] : memref<?x?xf32, #gpu.address_space<global>>
    %97 = arith.addi %89, %c1 : index
    cf.br ^bb9(%97 : index)
  ^bb11:  // pred: ^bb9
    %98 = arith.addi %86, %c1 : index
    cf.br ^bb7(%98 : index)
  ^bb12:  // pred: ^bb7
    %99 = arith.addi %84, %c1 : index
    cf.br ^bb6(%99 : index)
  ^bb13:  // pred: ^bb6
    return
  }
}

// -----// IR Dump After ConvertToNVVM (iree-convert-to-nvvm) //----- //
module {
  llvm.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias}, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32) {
    %0 = llvm.mlir.constant(63 : index) : i64
    %1 = llvm.mlir.constant(1 : i64) : i64
    %2 = llvm.mlir.constant(8 : index) : i64
    %3 = llvm.mlir.constant(-128 : index) : i64
    %4 = llvm.mlir.constant(-32 : index) : i64
    %5 = llvm.mlir.constant(-1 : index) : i64
    %6 = llvm.mlir.constant(128 : index) : i64
    %7 = llvm.mlir.constant(32 : index) : i64
    %8 = llvm.mlir.constant(0 : index) : i64
    %9 = llvm.mlir.constant(1 : index) : i64
    %10 = llvm.mlir.constant(32 : i64) : i64
    %11 = llvm.mlir.constant(0.000000e+00 : f32) : f32
    %12 = llvm.zext %arg2 : i32 to i64
    %13 = llvm.zext %arg3 : i32 to i64
    %14 = llvm.shl %13, %10  : i64
    %15 = llvm.or %12, %14  : i64
    %16 = llvm.zext %arg4 : i32 to i64
    %17 = llvm.zext %arg5 : i32 to i64
    %18 = llvm.shl %17, %10  : i64
    %19 = llvm.or %16, %18  : i64
    %20 = llvm.mul %19, %1  : i64
    %21 = llvm.ptrtoint %arg0 : !llvm.ptr<1> to i64
    %22 = llvm.and %21, %0  : i64
    %23 = llvm.icmp "eq" %22, %8 : i64
    "llvm.intr.assume"(%23) : (i1) -> ()
    %24 = llvm.mul %19, %1  : i64
    %25 = llvm.ptrtoint %arg1 : !llvm.ptr<1> to i64
    %26 = llvm.and %25, %0  : i64
    %27 = llvm.icmp "eq" %26, %8 : i64
    "llvm.intr.assume"(%27) : (i1) -> ()
    %28 = nvvm.read.ptx.sreg.ctaid.x : i32
    %29 = llvm.sext %28 : i32 to i64
    %30 = llvm.icmp "sle" %19, %8 : i64
    %31 = llvm.sub %8, %19  : i64
    %32 = llvm.sub %19, %9  : i64
    %33 = llvm.select %30, %31, %32 : i1, i64
    %34 = llvm.sdiv %33, %6  : i64
    %35 = llvm.sub %8, %34  : i64
    %36 = llvm.add %34, %9  : i64
    %37 = llvm.select %30, %35, %36 : i1, i64
    %38 = llvm.icmp "slt" %29, %8 : i64
    %39 = llvm.sub %5, %29  : i64
    %40 = llvm.select %38, %39, %29 : i1, i64
    %41 = llvm.sdiv %40, %37  : i64
    %42 = llvm.sub %5, %41  : i64
    %43 = llvm.select %38, %42, %41 : i1, i64
    %44 = llvm.mul %43, %4  : i64
    %45 = llvm.add %15, %44  : i64
    %46 = llvm.icmp "sgt" %45, %7 : i64
    %47 = llvm.select %46, %7, %45 : i1, i64
    %48 = llvm.srem %29, %37  : i64
    %49 = llvm.icmp "slt" %48, %8 : i64
    %50 = llvm.add %48, %37  : i64
    %51 = llvm.select %49, %50, %48 : i1, i64
    %52 = llvm.mul %51, %3  : i64
    %53 = llvm.add %19, %52  : i64
    %54 = llvm.icmp "sgt" %53, %6 : i64
    %55 = llvm.select %54, %6, %53 : i1, i64
    %56 = nvvm.read.ptx.sreg.tid.x : i32
    %57 = llvm.sext %56 : i32 to i64
    %58 = nvvm.read.ptx.sreg.tid.y : i32
    %59 = llvm.sext %58 : i32 to i64
    %60 = llvm.icmp "sle" %47, %8 : i64
    %61 = llvm.sub %8, %47  : i64
    %62 = llvm.sub %47, %9  : i64
    %63 = llvm.select %60, %61, %62 : i1, i64
    %64 = llvm.sdiv %63, %2  : i64
    %65 = llvm.sub %8, %64  : i64
    %66 = llvm.add %64, %9  : i64
    %67 = llvm.select %60, %65, %66 : i1, i64
    %68 = llvm.mul %59, %67  : i64
    %69 = llvm.sub %47, %68  : i64
    %70 = llvm.icmp "slt" %69, %67 : i64
    %71 = llvm.select %70, %69, %67 : i1, i64
    %72 = llvm.icmp "slt" %71, %8 : i64
    %73 = llvm.select %72, %8, %71 : i1, i64
    %74 = llvm.icmp "sle" %55, %8 : i64
    %75 = llvm.sub %8, %55  : i64
    %76 = llvm.sub %55, %9  : i64
    %77 = llvm.select %74, %75, %76 : i1, i64
    %78 = llvm.sdiv %77, %7  : i64
    %79 = llvm.sub %8, %78  : i64
    %80 = llvm.add %78, %9  : i64
    %81 = llvm.select %74, %79, %80 : i1, i64
    %82 = llvm.mul %57, %81  : i64
    %83 = llvm.sub %55, %82  : i64
    %84 = llvm.icmp "slt" %83, %81 : i64
    %85 = llvm.select %84, %83, %81 : i1, i64
    %86 = llvm.icmp "slt" %85, %8 : i64
    %87 = llvm.select %86, %8, %85 : i1, i64
    %88 = llvm.mul %43, %7  : i64
    %89 = llvm.add %88, %68  : i64
    %90 = llvm.mul %51, %6  : i64
    %91 = llvm.add %90, %82  : i64
    llvm.br ^bb1(%8 : i64)
  ^bb1(%92: i64):  // 2 preds: ^bb0, ^bb5
    %93 = llvm.icmp "slt" %92, %73 : i64
    llvm.cond_br %93, ^bb2, ^bb6(%8 : i64)
  ^bb2:  // pred: ^bb1
    %94 = llvm.add %89, %92  : i64
    llvm.br ^bb3(%8 : i64)
  ^bb3(%95: i64):  // 2 preds: ^bb2, ^bb4
    %96 = llvm.icmp "slt" %95, %87 : i64
    llvm.cond_br %96, ^bb4, ^bb5
  ^bb4:  // pred: ^bb3
    %97 = llvm.add %91, %95  : i64
    %98 = llvm.mul %94, %24  : i64
    %99 = llvm.add %98, %97  : i64
    %100 = llvm.getelementptr %arg1[%99] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
    llvm.store %11, %100 : f32, !llvm.ptr<1>
    %101 = llvm.add %95, %9  : i64
    llvm.br ^bb3(%101 : i64)
  ^bb5:  // pred: ^bb3
    %102 = llvm.add %92, %9  : i64
    llvm.br ^bb1(%102 : i64)
  ^bb6(%103: i64):  // 2 preds: ^bb1, ^bb12
    %104 = llvm.icmp "slt" %103, %19 : i64
    llvm.cond_br %104, ^bb7(%8 : i64), ^bb13
  ^bb7(%105: i64):  // 2 preds: ^bb6, ^bb11
    %106 = llvm.icmp "slt" %105, %73 : i64
    llvm.cond_br %106, ^bb8, ^bb12
  ^bb8:  // pred: ^bb7
    %107 = llvm.add %89, %105  : i64
    llvm.br ^bb9(%8 : i64)
  ^bb9(%108: i64):  // 2 preds: ^bb8, ^bb10
    %109 = llvm.icmp "slt" %108, %87 : i64
    llvm.cond_br %109, ^bb10, ^bb11
  ^bb10:  // pred: ^bb9
    %110 = llvm.mul %107, %20  : i64
    %111 = llvm.add %110, %103  : i64
    %112 = llvm.getelementptr %arg0[%111] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
    %113 = llvm.load %112 : !llvm.ptr<1> -> f32
    %114 = llvm.add %91, %108  : i64
    %115 = llvm.mul %103, %20  : i64
    %116 = llvm.add %115, %114  : i64
    %117 = llvm.getelementptr %arg0[%116] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
    %118 = llvm.load %117 : !llvm.ptr<1> -> f32
    %119 = llvm.mul %107, %24  : i64
    %120 = llvm.add %119, %114  : i64
    %121 = llvm.getelementptr %arg1[%120] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
    %122 = llvm.load %121 : !llvm.ptr<1> -> f32
    %123 = llvm.fmul %113, %118  : f32
    %124 = llvm.fadd %122, %123  : f32
    %125 = llvm.mul %107, %24  : i64
    %126 = llvm.add %125, %114  : i64
    %127 = llvm.getelementptr %arg1[%126] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
    llvm.store %124, %127 : f32, !llvm.ptr<1>
    %128 = llvm.add %108, %9  : i64
    llvm.br ^bb9(%128 : i64)
  ^bb11:  // pred: ^bb9
    %129 = llvm.add %105, %9  : i64
    llvm.br ^bb7(%129 : i64)
  ^bb12:  // pred: ^bb7
    %130 = llvm.add %103, %9  : i64
    llvm.br ^bb6(%130 : i64)
  ^bb13:  // pred: ^bb6
    llvm.return
  }
}

// -----// IR Dump After mlir::iree_compiler::IREE::HAL::TranslateTargetExecutableVariantsPass (iree-hal-translate-target-executable-variants) //----- //
hal.executable.variant public @cuda_nvptx_fb target(<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>) {
  hal.executable.export public @main_dispatch_0_matmul_DxDxD_f32 ordinal(0) layout(#hal.pipeline.layout<push_constants = 4, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer>]>]>) attributes {translation_info = #iree_codegen.translation_info<LLVMGPUMatmulSimt>, workgroup_size = [32 : index, 8 : index, 1 : index]} {
  ^bb0(%arg0: !hal.device, %arg1: index, %arg2: index):
    %c1 = arith.constant 1 : index
    %0 = affine.apply affine_map<()[s0, s1] -> ((s0 ceildiv 128) * (s1 ceildiv 32))>()[%arg2, %arg1]
    hal.return %0, %c1, %c1 : index, index, index
  }
  builtin.module {
    llvm.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias}, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32) {
      %0 = llvm.mlir.constant(63 : index) : i64
      %1 = llvm.mlir.constant(1 : i64) : i64
      %2 = llvm.mlir.constant(8 : index) : i64
      %3 = llvm.mlir.constant(-128 : index) : i64
      %4 = llvm.mlir.constant(-32 : index) : i64
      %5 = llvm.mlir.constant(-1 : index) : i64
      %6 = llvm.mlir.constant(128 : index) : i64
      %7 = llvm.mlir.constant(32 : index) : i64
      %8 = llvm.mlir.constant(0 : index) : i64
      %9 = llvm.mlir.constant(1 : index) : i64
      %10 = llvm.mlir.constant(32 : i64) : i64
      %11 = llvm.mlir.constant(0.000000e+00 : f32) : f32
      %12 = llvm.zext %arg2 : i32 to i64
      %13 = llvm.zext %arg3 : i32 to i64
      %14 = llvm.shl %13, %10  : i64
      %15 = llvm.or %12, %14  : i64
      %16 = llvm.zext %arg4 : i32 to i64
      %17 = llvm.zext %arg5 : i32 to i64
      %18 = llvm.shl %17, %10  : i64
      %19 = llvm.or %16, %18  : i64
      %20 = llvm.mul %19, %1  : i64
      %21 = llvm.ptrtoint %arg0 : !llvm.ptr<1> to i64
      %22 = llvm.and %21, %0  : i64
      %23 = llvm.icmp "eq" %22, %8 : i64
      "llvm.intr.assume"(%23) : (i1) -> ()
      %24 = llvm.mul %19, %1  : i64
      %25 = llvm.ptrtoint %arg1 : !llvm.ptr<1> to i64
      %26 = llvm.and %25, %0  : i64
      %27 = llvm.icmp "eq" %26, %8 : i64
      "llvm.intr.assume"(%27) : (i1) -> ()
      %28 = nvvm.read.ptx.sreg.ctaid.x : i32
      %29 = llvm.sext %28 : i32 to i64
      %30 = llvm.icmp "sle" %19, %8 : i64
      %31 = llvm.sub %8, %19  : i64
      %32 = llvm.sub %19, %9  : i64
      %33 = llvm.select %30, %31, %32 : i1, i64
      %34 = llvm.sdiv %33, %6  : i64
      %35 = llvm.sub %8, %34  : i64
      %36 = llvm.add %34, %9  : i64
      %37 = llvm.select %30, %35, %36 : i1, i64
      %38 = llvm.icmp "slt" %29, %8 : i64
      %39 = llvm.sub %5, %29  : i64
      %40 = llvm.select %38, %39, %29 : i1, i64
      %41 = llvm.sdiv %40, %37  : i64
      %42 = llvm.sub %5, %41  : i64
      %43 = llvm.select %38, %42, %41 : i1, i64
      %44 = llvm.mul %43, %4  : i64
      %45 = llvm.add %15, %44  : i64
      %46 = llvm.icmp "sgt" %45, %7 : i64
      %47 = llvm.select %46, %7, %45 : i1, i64
      %48 = llvm.srem %29, %37  : i64
      %49 = llvm.icmp "slt" %48, %8 : i64
      %50 = llvm.add %48, %37  : i64
      %51 = llvm.select %49, %50, %48 : i1, i64
      %52 = llvm.mul %51, %3  : i64
      %53 = llvm.add %19, %52  : i64
      %54 = llvm.icmp "sgt" %53, %6 : i64
      %55 = llvm.select %54, %6, %53 : i1, i64
      %56 = nvvm.read.ptx.sreg.tid.x : i32
      %57 = llvm.sext %56 : i32 to i64
      %58 = nvvm.read.ptx.sreg.tid.y : i32
      %59 = llvm.sext %58 : i32 to i64
      %60 = llvm.icmp "sle" %47, %8 : i64
      %61 = llvm.sub %8, %47  : i64
      %62 = llvm.sub %47, %9  : i64
      %63 = llvm.select %60, %61, %62 : i1, i64
      %64 = llvm.sdiv %63, %2  : i64
      %65 = llvm.sub %8, %64  : i64
      %66 = llvm.add %64, %9  : i64
      %67 = llvm.select %60, %65, %66 : i1, i64
      %68 = llvm.mul %59, %67  : i64
      %69 = llvm.sub %47, %68  : i64
      %70 = llvm.icmp "slt" %69, %67 : i64
      %71 = llvm.select %70, %69, %67 : i1, i64
      %72 = llvm.icmp "slt" %71, %8 : i64
      %73 = llvm.select %72, %8, %71 : i1, i64
      %74 = llvm.icmp "sle" %55, %8 : i64
      %75 = llvm.sub %8, %55  : i64
      %76 = llvm.sub %55, %9  : i64
      %77 = llvm.select %74, %75, %76 : i1, i64
      %78 = llvm.sdiv %77, %7  : i64
      %79 = llvm.sub %8, %78  : i64
      %80 = llvm.add %78, %9  : i64
      %81 = llvm.select %74, %79, %80 : i1, i64
      %82 = llvm.mul %57, %81  : i64
      %83 = llvm.sub %55, %82  : i64
      %84 = llvm.icmp "slt" %83, %81 : i64
      %85 = llvm.select %84, %83, %81 : i1, i64
      %86 = llvm.icmp "slt" %85, %8 : i64
      %87 = llvm.select %86, %8, %85 : i1, i64
      %88 = llvm.mul %43, %7  : i64
      %89 = llvm.add %88, %68  : i64
      %90 = llvm.mul %51, %6  : i64
      %91 = llvm.add %90, %82  : i64
      llvm.br ^bb1(%8 : i64)
    ^bb1(%92: i64):  // 2 preds: ^bb0, ^bb5
      %93 = llvm.icmp "slt" %92, %73 : i64
      llvm.cond_br %93, ^bb2, ^bb6(%8 : i64)
    ^bb2:  // pred: ^bb1
      %94 = llvm.add %89, %92  : i64
      llvm.br ^bb3(%8 : i64)
    ^bb3(%95: i64):  // 2 preds: ^bb2, ^bb4
      %96 = llvm.icmp "slt" %95, %87 : i64
      llvm.cond_br %96, ^bb4, ^bb5
    ^bb4:  // pred: ^bb3
      %97 = llvm.add %91, %95  : i64
      %98 = llvm.mul %94, %24  : i64
      %99 = llvm.add %98, %97  : i64
      %100 = llvm.getelementptr %arg1[%99] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
      llvm.store %11, %100 : f32, !llvm.ptr<1>
      %101 = llvm.add %95, %9  : i64
      llvm.br ^bb3(%101 : i64)
    ^bb5:  // pred: ^bb3
      %102 = llvm.add %92, %9  : i64
      llvm.br ^bb1(%102 : i64)
    ^bb6(%103: i64):  // 2 preds: ^bb1, ^bb12
      %104 = llvm.icmp "slt" %103, %19 : i64
      llvm.cond_br %104, ^bb7(%8 : i64), ^bb13
    ^bb7(%105: i64):  // 2 preds: ^bb6, ^bb11
      %106 = llvm.icmp "slt" %105, %73 : i64
      llvm.cond_br %106, ^bb8, ^bb12
    ^bb8:  // pred: ^bb7
      %107 = llvm.add %89, %105  : i64
      llvm.br ^bb9(%8 : i64)
    ^bb9(%108: i64):  // 2 preds: ^bb8, ^bb10
      %109 = llvm.icmp "slt" %108, %87 : i64
      llvm.cond_br %109, ^bb10, ^bb11
    ^bb10:  // pred: ^bb9
      %110 = llvm.mul %107, %20  : i64
      %111 = llvm.add %110, %103  : i64
      %112 = llvm.getelementptr %arg0[%111] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
      %113 = llvm.load %112 : !llvm.ptr<1> -> f32
      %114 = llvm.add %91, %108  : i64
      %115 = llvm.mul %103, %20  : i64
      %116 = llvm.add %115, %114  : i64
      %117 = llvm.getelementptr %arg0[%116] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
      %118 = llvm.load %117 : !llvm.ptr<1> -> f32
      %119 = llvm.mul %107, %24  : i64
      %120 = llvm.add %119, %114  : i64
      %121 = llvm.getelementptr %arg1[%120] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
      %122 = llvm.load %121 : !llvm.ptr<1> -> f32
      %123 = llvm.fmul %113, %118  : f32
      %124 = llvm.fadd %122, %123  : f32
      %125 = llvm.mul %107, %24  : i64
      %126 = llvm.add %125, %114  : i64
      %127 = llvm.getelementptr %arg1[%126] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
      llvm.store %124, %127 : f32, !llvm.ptr<1>
      %128 = llvm.add %108, %9  : i64
      llvm.br ^bb9(%128 : i64)
    ^bb11:  // pred: ^bb9
      %129 = llvm.add %105, %9  : i64
      llvm.br ^bb7(%129 : i64)
    ^bb12:  // pred: ^bb7
      %130 = llvm.add %103, %9  : i64
      llvm.br ^bb6(%130 : i64)
    ^bb13:  // pred: ^bb6
      llvm.return
    }
  }
}

// -----// IR Dump After mlir::iree_compiler::IREE::HAL::TranslateExecutablesPass (iree-hal-translate-executables) //----- //
hal.executable private @main_dispatch_0 {
  hal.executable.variant public @cuda_nvptx_fb target(<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>) {
    hal.executable.export public @main_dispatch_0_matmul_DxDxD_f32 ordinal(0) layout(#hal.pipeline.layout<push_constants = 4, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer>]>]>) attributes {translation_info = #iree_codegen.translation_info<LLVMGPUMatmulSimt>, workgroup_size = [32 : index, 8 : index, 1 : index]} {
    ^bb0(%arg0: !hal.device, %arg1: index, %arg2: index):
      %c1 = arith.constant 1 : index
      %0 = affine.apply affine_map<()[s0, s1] -> ((s0 ceildiv 128) * (s1 ceildiv 32))>()[%arg2, %arg1]
      hal.return %0, %c1, %c1 : index, index, index
    }
    builtin.module {
      llvm.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias}, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32) {
        %0 = llvm.mlir.constant(63 : index) : i64
        %1 = llvm.mlir.constant(1 : i64) : i64
        %2 = llvm.mlir.constant(8 : index) : i64
        %3 = llvm.mlir.constant(-128 : index) : i64
        %4 = llvm.mlir.constant(-32 : index) : i64
        %5 = llvm.mlir.constant(-1 : index) : i64
        %6 = llvm.mlir.constant(128 : index) : i64
        %7 = llvm.mlir.constant(32 : index) : i64
        %8 = llvm.mlir.constant(0 : index) : i64
        %9 = llvm.mlir.constant(1 : index) : i64
        %10 = llvm.mlir.constant(32 : i64) : i64
        %11 = llvm.mlir.constant(0.000000e+00 : f32) : f32
        %12 = llvm.zext %arg2 : i32 to i64
        %13 = llvm.zext %arg3 : i32 to i64
        %14 = llvm.shl %13, %10  : i64
        %15 = llvm.or %12, %14  : i64
        %16 = llvm.zext %arg4 : i32 to i64
        %17 = llvm.zext %arg5 : i32 to i64
        %18 = llvm.shl %17, %10  : i64
        %19 = llvm.or %16, %18  : i64
        %20 = llvm.mul %19, %1  : i64
        %21 = llvm.ptrtoint %arg0 : !llvm.ptr<1> to i64
        %22 = llvm.and %21, %0  : i64
        %23 = llvm.icmp "eq" %22, %8 : i64
        "llvm.intr.assume"(%23) : (i1) -> ()
        %24 = llvm.mul %19, %1  : i64
        %25 = llvm.ptrtoint %arg1 : !llvm.ptr<1> to i64
        %26 = llvm.and %25, %0  : i64
        %27 = llvm.icmp "eq" %26, %8 : i64
        "llvm.intr.assume"(%27) : (i1) -> ()
        %28 = nvvm.read.ptx.sreg.ctaid.x : i32
        %29 = llvm.sext %28 : i32 to i64
        %30 = llvm.icmp "sle" %19, %8 : i64
        %31 = llvm.sub %8, %19  : i64
        %32 = llvm.sub %19, %9  : i64
        %33 = llvm.select %30, %31, %32 : i1, i64
        %34 = llvm.sdiv %33, %6  : i64
        %35 = llvm.sub %8, %34  : i64
        %36 = llvm.add %34, %9  : i64
        %37 = llvm.select %30, %35, %36 : i1, i64
        %38 = llvm.icmp "slt" %29, %8 : i64
        %39 = llvm.sub %5, %29  : i64
        %40 = llvm.select %38, %39, %29 : i1, i64
        %41 = llvm.sdiv %40, %37  : i64
        %42 = llvm.sub %5, %41  : i64
        %43 = llvm.select %38, %42, %41 : i1, i64
        %44 = llvm.mul %43, %4  : i64
        %45 = llvm.add %15, %44  : i64
        %46 = llvm.icmp "sgt" %45, %7 : i64
        %47 = llvm.select %46, %7, %45 : i1, i64
        %48 = llvm.srem %29, %37  : i64
        %49 = llvm.icmp "slt" %48, %8 : i64
        %50 = llvm.add %48, %37  : i64
        %51 = llvm.select %49, %50, %48 : i1, i64
        %52 = llvm.mul %51, %3  : i64
        %53 = llvm.add %19, %52  : i64
        %54 = llvm.icmp "sgt" %53, %6 : i64
        %55 = llvm.select %54, %6, %53 : i1, i64
        %56 = nvvm.read.ptx.sreg.tid.x : i32
        %57 = llvm.sext %56 : i32 to i64
        %58 = nvvm.read.ptx.sreg.tid.y : i32
        %59 = llvm.sext %58 : i32 to i64
        %60 = llvm.icmp "sle" %47, %8 : i64
        %61 = llvm.sub %8, %47  : i64
        %62 = llvm.sub %47, %9  : i64
        %63 = llvm.select %60, %61, %62 : i1, i64
        %64 = llvm.sdiv %63, %2  : i64
        %65 = llvm.sub %8, %64  : i64
        %66 = llvm.add %64, %9  : i64
        %67 = llvm.select %60, %65, %66 : i1, i64
        %68 = llvm.mul %59, %67  : i64
        %69 = llvm.sub %47, %68  : i64
        %70 = llvm.icmp "slt" %69, %67 : i64
        %71 = llvm.select %70, %69, %67 : i1, i64
        %72 = llvm.icmp "slt" %71, %8 : i64
        %73 = llvm.select %72, %8, %71 : i1, i64
        %74 = llvm.icmp "sle" %55, %8 : i64
        %75 = llvm.sub %8, %55  : i64
        %76 = llvm.sub %55, %9  : i64
        %77 = llvm.select %74, %75, %76 : i1, i64
        %78 = llvm.sdiv %77, %7  : i64
        %79 = llvm.sub %8, %78  : i64
        %80 = llvm.add %78, %9  : i64
        %81 = llvm.select %74, %79, %80 : i1, i64
        %82 = llvm.mul %57, %81  : i64
        %83 = llvm.sub %55, %82  : i64
        %84 = llvm.icmp "slt" %83, %81 : i64
        %85 = llvm.select %84, %83, %81 : i1, i64
        %86 = llvm.icmp "slt" %85, %8 : i64
        %87 = llvm.select %86, %8, %85 : i1, i64
        %88 = llvm.mul %43, %7  : i64
        %89 = llvm.add %88, %68  : i64
        %90 = llvm.mul %51, %6  : i64
        %91 = llvm.add %90, %82  : i64
        llvm.br ^bb1(%8 : i64)
      ^bb1(%92: i64):  // 2 preds: ^bb0, ^bb5
        %93 = llvm.icmp "slt" %92, %73 : i64
        llvm.cond_br %93, ^bb2, ^bb6(%8 : i64)
      ^bb2:  // pred: ^bb1
        %94 = llvm.add %89, %92  : i64
        llvm.br ^bb3(%8 : i64)
      ^bb3(%95: i64):  // 2 preds: ^bb2, ^bb4
        %96 = llvm.icmp "slt" %95, %87 : i64
        llvm.cond_br %96, ^bb4, ^bb5
      ^bb4:  // pred: ^bb3
        %97 = llvm.add %91, %95  : i64
        %98 = llvm.mul %94, %24  : i64
        %99 = llvm.add %98, %97  : i64
        %100 = llvm.getelementptr %arg1[%99] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
        llvm.store %11, %100 : f32, !llvm.ptr<1>
        %101 = llvm.add %95, %9  : i64
        llvm.br ^bb3(%101 : i64)
      ^bb5:  // pred: ^bb3
        %102 = llvm.add %92, %9  : i64
        llvm.br ^bb1(%102 : i64)
      ^bb6(%103: i64):  // 2 preds: ^bb1, ^bb12
        %104 = llvm.icmp "slt" %103, %19 : i64
        llvm.cond_br %104, ^bb7(%8 : i64), ^bb13
      ^bb7(%105: i64):  // 2 preds: ^bb6, ^bb11
        %106 = llvm.icmp "slt" %105, %73 : i64
        llvm.cond_br %106, ^bb8, ^bb12
      ^bb8:  // pred: ^bb7
        %107 = llvm.add %89, %105  : i64
        llvm.br ^bb9(%8 : i64)
      ^bb9(%108: i64):  // 2 preds: ^bb8, ^bb10
        %109 = llvm.icmp "slt" %108, %87 : i64
        llvm.cond_br %109, ^bb10, ^bb11
      ^bb10:  // pred: ^bb9
        %110 = llvm.mul %107, %20  : i64
        %111 = llvm.add %110, %103  : i64
        %112 = llvm.getelementptr %arg0[%111] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
        %113 = llvm.load %112 : !llvm.ptr<1> -> f32
        %114 = llvm.add %91, %108  : i64
        %115 = llvm.mul %103, %20  : i64
        %116 = llvm.add %115, %114  : i64
        %117 = llvm.getelementptr %arg0[%116] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
        %118 = llvm.load %117 : !llvm.ptr<1> -> f32
        %119 = llvm.mul %107, %24  : i64
        %120 = llvm.add %119, %114  : i64
        %121 = llvm.getelementptr %arg1[%120] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
        %122 = llvm.load %121 : !llvm.ptr<1> -> f32
        %123 = llvm.fmul %113, %118  : f32
        %124 = llvm.fadd %122, %123  : f32
        %125 = llvm.mul %107, %24  : i64
        %126 = llvm.add %125, %114  : i64
        %127 = llvm.getelementptr %arg1[%126] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
        llvm.store %124, %127 : f32, !llvm.ptr<1>
        %128 = llvm.add %108, %9  : i64
        llvm.br ^bb9(%128 : i64)
      ^bb11:  // pred: ^bb9
        %129 = llvm.add %105, %9  : i64
        llvm.br ^bb7(%129 : i64)
      ^bb12:  // pred: ^bb7
        %130 = llvm.add %103, %9  : i64
        llvm.br ^bb6(%130 : i64)
      ^bb13:  // pred: ^bb6
        llvm.return
      }
    }
  }
}

// -----// IR Dump After mlir::iree_compiler::IREE::HAL::(anonymous namespace)::ConvertToHALPass (iree-hal-conversion) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<()[s0, s1] -> ((s0 ceildiv 128) * (s1 ceildiv 32))>
#pipeline_layout = #hal.pipeline.layout<push_constants = 4, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer>]>]>
#translation = #iree_codegen.translation_info<LLVMGPUMatmulSimt>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  hal.executable private @main_dispatch_0 {
    hal.executable.variant public @cuda_nvptx_fb target(#executable_target_cuda_nvptx_fb) {
      hal.executable.export public @main_dispatch_0_matmul_DxDxD_f32 ordinal(0) layout(#pipeline_layout) attributes {translation_info = #translation, workgroup_size = [32 : index, 8 : index, 1 : index]} {
      ^bb0(%arg0: !hal.device, %arg1: index, %arg2: index):
        %c1 = arith.constant 1 : index
        %0 = affine.apply #map()[%arg2, %arg1]
        hal.return %0, %c1, %c1 : index, index, index
      }
      builtin.module {
        llvm.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias}, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32) {
          %0 = llvm.mlir.constant(63 : index) : i64
          %1 = llvm.mlir.constant(1 : i64) : i64
          %2 = llvm.mlir.constant(8 : index) : i64
          %3 = llvm.mlir.constant(-128 : index) : i64
          %4 = llvm.mlir.constant(-32 : index) : i64
          %5 = llvm.mlir.constant(-1 : index) : i64
          %6 = llvm.mlir.constant(128 : index) : i64
          %7 = llvm.mlir.constant(32 : index) : i64
          %8 = llvm.mlir.constant(0 : index) : i64
          %9 = llvm.mlir.constant(1 : index) : i64
          %10 = llvm.mlir.constant(32 : i64) : i64
          %11 = llvm.mlir.constant(0.000000e+00 : f32) : f32
          %12 = llvm.zext %arg2 : i32 to i64
          %13 = llvm.zext %arg3 : i32 to i64
          %14 = llvm.shl %13, %10  : i64
          %15 = llvm.or %12, %14  : i64
          %16 = llvm.zext %arg4 : i32 to i64
          %17 = llvm.zext %arg5 : i32 to i64
          %18 = llvm.shl %17, %10  : i64
          %19 = llvm.or %16, %18  : i64
          %20 = llvm.mul %19, %1  : i64
          %21 = llvm.ptrtoint %arg0 : !llvm.ptr<1> to i64
          %22 = llvm.and %21, %0  : i64
          %23 = llvm.icmp "eq" %22, %8 : i64
          "llvm.intr.assume"(%23) : (i1) -> ()
          %24 = llvm.mul %19, %1  : i64
          %25 = llvm.ptrtoint %arg1 : !llvm.ptr<1> to i64
          %26 = llvm.and %25, %0  : i64
          %27 = llvm.icmp "eq" %26, %8 : i64
          "llvm.intr.assume"(%27) : (i1) -> ()
          %28 = nvvm.read.ptx.sreg.ctaid.x : i32
          %29 = llvm.sext %28 : i32 to i64
          %30 = llvm.icmp "sle" %19, %8 : i64
          %31 = llvm.sub %8, %19  : i64
          %32 = llvm.sub %19, %9  : i64
          %33 = llvm.select %30, %31, %32 : i1, i64
          %34 = llvm.sdiv %33, %6  : i64
          %35 = llvm.sub %8, %34  : i64
          %36 = llvm.add %34, %9  : i64
          %37 = llvm.select %30, %35, %36 : i1, i64
          %38 = llvm.icmp "slt" %29, %8 : i64
          %39 = llvm.sub %5, %29  : i64
          %40 = llvm.select %38, %39, %29 : i1, i64
          %41 = llvm.sdiv %40, %37  : i64
          %42 = llvm.sub %5, %41  : i64
          %43 = llvm.select %38, %42, %41 : i1, i64
          %44 = llvm.mul %43, %4  : i64
          %45 = llvm.add %15, %44  : i64
          %46 = llvm.icmp "sgt" %45, %7 : i64
          %47 = llvm.select %46, %7, %45 : i1, i64
          %48 = llvm.srem %29, %37  : i64
          %49 = llvm.icmp "slt" %48, %8 : i64
          %50 = llvm.add %48, %37  : i64
          %51 = llvm.select %49, %50, %48 : i1, i64
          %52 = llvm.mul %51, %3  : i64
          %53 = llvm.add %19, %52  : i64
          %54 = llvm.icmp "sgt" %53, %6 : i64
          %55 = llvm.select %54, %6, %53 : i1, i64
          %56 = nvvm.read.ptx.sreg.tid.x : i32
          %57 = llvm.sext %56 : i32 to i64
          %58 = nvvm.read.ptx.sreg.tid.y : i32
          %59 = llvm.sext %58 : i32 to i64
          %60 = llvm.icmp "sle" %47, %8 : i64
          %61 = llvm.sub %8, %47  : i64
          %62 = llvm.sub %47, %9  : i64
          %63 = llvm.select %60, %61, %62 : i1, i64
          %64 = llvm.sdiv %63, %2  : i64
          %65 = llvm.sub %8, %64  : i64
          %66 = llvm.add %64, %9  : i64
          %67 = llvm.select %60, %65, %66 : i1, i64
          %68 = llvm.mul %59, %67  : i64
          %69 = llvm.sub %47, %68  : i64
          %70 = llvm.icmp "slt" %69, %67 : i64
          %71 = llvm.select %70, %69, %67 : i1, i64
          %72 = llvm.icmp "slt" %71, %8 : i64
          %73 = llvm.select %72, %8, %71 : i1, i64
          %74 = llvm.icmp "sle" %55, %8 : i64
          %75 = llvm.sub %8, %55  : i64
          %76 = llvm.sub %55, %9  : i64
          %77 = llvm.select %74, %75, %76 : i1, i64
          %78 = llvm.sdiv %77, %7  : i64
          %79 = llvm.sub %8, %78  : i64
          %80 = llvm.add %78, %9  : i64
          %81 = llvm.select %74, %79, %80 : i1, i64
          %82 = llvm.mul %57, %81  : i64
          %83 = llvm.sub %55, %82  : i64
          %84 = llvm.icmp "slt" %83, %81 : i64
          %85 = llvm.select %84, %83, %81 : i1, i64
          %86 = llvm.icmp "slt" %85, %8 : i64
          %87 = llvm.select %86, %8, %85 : i1, i64
          %88 = llvm.mul %43, %7  : i64
          %89 = llvm.add %88, %68  : i64
          %90 = llvm.mul %51, %6  : i64
          %91 = llvm.add %90, %82  : i64
          llvm.br ^bb1(%8 : i64)
        ^bb1(%92: i64):  // 2 preds: ^bb0, ^bb5
          %93 = llvm.icmp "slt" %92, %73 : i64
          llvm.cond_br %93, ^bb2, ^bb6(%8 : i64)
        ^bb2:  // pred: ^bb1
          %94 = llvm.add %89, %92  : i64
          llvm.br ^bb3(%8 : i64)
        ^bb3(%95: i64):  // 2 preds: ^bb2, ^bb4
          %96 = llvm.icmp "slt" %95, %87 : i64
          llvm.cond_br %96, ^bb4, ^bb5
        ^bb4:  // pred: ^bb3
          %97 = llvm.add %91, %95  : i64
          %98 = llvm.mul %94, %24  : i64
          %99 = llvm.add %98, %97  : i64
          %100 = llvm.getelementptr %arg1[%99] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          llvm.store %11, %100 : f32, !llvm.ptr<1>
          %101 = llvm.add %95, %9  : i64
          llvm.br ^bb3(%101 : i64)
        ^bb5:  // pred: ^bb3
          %102 = llvm.add %92, %9  : i64
          llvm.br ^bb1(%102 : i64)
        ^bb6(%103: i64):  // 2 preds: ^bb1, ^bb12
          %104 = llvm.icmp "slt" %103, %19 : i64
          llvm.cond_br %104, ^bb7(%8 : i64), ^bb13
        ^bb7(%105: i64):  // 2 preds: ^bb6, ^bb11
          %106 = llvm.icmp "slt" %105, %73 : i64
          llvm.cond_br %106, ^bb8, ^bb12
        ^bb8:  // pred: ^bb7
          %107 = llvm.add %89, %105  : i64
          llvm.br ^bb9(%8 : i64)
        ^bb9(%108: i64):  // 2 preds: ^bb8, ^bb10
          %109 = llvm.icmp "slt" %108, %87 : i64
          llvm.cond_br %109, ^bb10, ^bb11
        ^bb10:  // pred: ^bb9
          %110 = llvm.mul %107, %20  : i64
          %111 = llvm.add %110, %103  : i64
          %112 = llvm.getelementptr %arg0[%111] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %113 = llvm.load %112 : !llvm.ptr<1> -> f32
          %114 = llvm.add %91, %108  : i64
          %115 = llvm.mul %103, %20  : i64
          %116 = llvm.add %115, %114  : i64
          %117 = llvm.getelementptr %arg0[%116] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %118 = llvm.load %117 : !llvm.ptr<1> -> f32
          %119 = llvm.mul %107, %24  : i64
          %120 = llvm.add %119, %114  : i64
          %121 = llvm.getelementptr %arg1[%120] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %122 = llvm.load %121 : !llvm.ptr<1> -> f32
          %123 = llvm.fmul %113, %118  : f32
          %124 = llvm.fadd %122, %123  : f32
          %125 = llvm.mul %107, %24  : i64
          %126 = llvm.add %125, %114  : i64
          %127 = llvm.getelementptr %arg1[%126] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          llvm.store %124, %127 : f32, !llvm.ptr<1>
          %128 = llvm.add %108, %9  : i64
          llvm.br ^bb9(%128 : i64)
        ^bb11:  // pred: ^bb9
          %129 = llvm.add %105, %9  : i64
          llvm.br ^bb7(%129 : i64)
        ^bb12:  // pred: ^bb7
          %130 = llvm.add %103, %9  : i64
          llvm.br ^bb6(%130 : i64)
        ^bb13:  // pred: ^bb6
          llvm.return
        }
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c32_i64 = arith.constant 32 : i64
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %device_0 = hal.ex.shared_device : !hal.device
    %c-1_i64 = arith.constant -1 : i64
    %4 = util.null : !hal.fence
    %fence = hal.fence.create device(%device_0 : !hal.device) flags("None") : !hal.fence
    %c0_i64 = arith.constant 0 : i64
    %transient_buffer = hal.device.queue.alloca<%device_0 : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%3}
    %5 = arith.index_castui %0 : index to i64
    %6 = arith.trunci %5 : i64 to i32
    %7 = arith.shrui %5, %c32_i64 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %1 : index to i64
    %10 = arith.trunci %9 : i64 to i32
    %11 = arith.shrui %9, %c32_i64 : i64
    %12 = arith.trunci %11 : i64 to i32
    %device_1 = hal.ex.shared_device : !hal.device
    %c-1_i64_2 = arith.constant -1 : i64
    %cmd = hal.command_buffer.create device(%device_1 : !hal.device) mode(OneShot) categories("Transfer|Dispatch") : !hal.command_buffer
    %13 = hal.command_buffer.device<%cmd : !hal.command_buffer> : !hal.device
    %ok, %value = hal.device.query<%13 : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    %c-1 = arith.constant -1 : index
    %c0_3 = arith.constant 0 : index
    %14 = arith.select %value, %c0_3, %c-1 : index
    scf.index_switch %14 
    case 0 {
      %pipeline_layout = hal.pipeline_layout.lookup device(%13 : !hal.device) layout(#pipeline_layout) : !hal.pipeline_layout
      hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%pipeline_layout : !hal.pipeline_layout) offset(0) values([%6, %8, %10, %12]) : i32, i32, i32, i32
      %c0_8 = arith.constant 0 : index
      %c1 = arith.constant 1 : index
      %c0_9 = arith.constant 0 : index
      hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%pipeline_layout : !hal.pipeline_layout)[%c0_9] bindings([
        %c0_8 = (%buffer : !hal.buffer)[%c0, %3], 
        %c1 = (%transient_buffer : !hal.buffer)[%c0, %3]
      ])
      %c1_10 = arith.constant 1 : index
      %15 = affine.apply #map()[%1, %0]
      hal.command_buffer.dispatch.symbol<%cmd : !hal.command_buffer> target(@main_dispatch_0::@cuda_nvptx_fb::@main_dispatch_0_matmul_DxDxD_f32) workgroups([%15, %c1_10, %c1_10])
      scf.yield
    }
    default {
    }
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_4 = hal.fence.create device(%device_1 : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%device_1 : !hal.device> affinity(%c-1_i64_2) wait(%fence) signal(%fence_4) commands([%cmd])
    %c-1_i32 = arith.constant -1 : i32
    %status = hal.fence.await until([%fence_4]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %c0_5 = arith.constant 0 : index
    %c553648160_i32_6 = arith.constant 553648160 : i32
    %c1_i32_7 = arith.constant 1 : i32
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0_5, %3] shape([%0, %1]) type(%c553648160_i32_6) encoding(%c1_i32_7) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::HAL::FixupLegacySyncPass (iree-hal-fixup-legacy-sync) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<()[s0, s1] -> ((s0 ceildiv 128) * (s1 ceildiv 32))>
#pipeline_layout = #hal.pipeline.layout<push_constants = 4, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer>]>]>
#translation = #iree_codegen.translation_info<LLVMGPUMatmulSimt>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  hal.executable private @main_dispatch_0 {
    hal.executable.variant public @cuda_nvptx_fb target(#executable_target_cuda_nvptx_fb) {
      hal.executable.export public @main_dispatch_0_matmul_DxDxD_f32 ordinal(0) layout(#pipeline_layout) attributes {translation_info = #translation, workgroup_size = [32 : index, 8 : index, 1 : index]} {
      ^bb0(%arg0: !hal.device, %arg1: index, %arg2: index):
        %c1 = arith.constant 1 : index
        %0 = affine.apply #map()[%arg2, %arg1]
        hal.return %0, %c1, %c1 : index, index, index
      }
      builtin.module {
        llvm.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias}, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32) {
          %0 = llvm.mlir.constant(63 : index) : i64
          %1 = llvm.mlir.constant(1 : i64) : i64
          %2 = llvm.mlir.constant(8 : index) : i64
          %3 = llvm.mlir.constant(-128 : index) : i64
          %4 = llvm.mlir.constant(-32 : index) : i64
          %5 = llvm.mlir.constant(-1 : index) : i64
          %6 = llvm.mlir.constant(128 : index) : i64
          %7 = llvm.mlir.constant(32 : index) : i64
          %8 = llvm.mlir.constant(0 : index) : i64
          %9 = llvm.mlir.constant(1 : index) : i64
          %10 = llvm.mlir.constant(32 : i64) : i64
          %11 = llvm.mlir.constant(0.000000e+00 : f32) : f32
          %12 = llvm.zext %arg2 : i32 to i64
          %13 = llvm.zext %arg3 : i32 to i64
          %14 = llvm.shl %13, %10  : i64
          %15 = llvm.or %12, %14  : i64
          %16 = llvm.zext %arg4 : i32 to i64
          %17 = llvm.zext %arg5 : i32 to i64
          %18 = llvm.shl %17, %10  : i64
          %19 = llvm.or %16, %18  : i64
          %20 = llvm.mul %19, %1  : i64
          %21 = llvm.ptrtoint %arg0 : !llvm.ptr<1> to i64
          %22 = llvm.and %21, %0  : i64
          %23 = llvm.icmp "eq" %22, %8 : i64
          "llvm.intr.assume"(%23) : (i1) -> ()
          %24 = llvm.mul %19, %1  : i64
          %25 = llvm.ptrtoint %arg1 : !llvm.ptr<1> to i64
          %26 = llvm.and %25, %0  : i64
          %27 = llvm.icmp "eq" %26, %8 : i64
          "llvm.intr.assume"(%27) : (i1) -> ()
          %28 = nvvm.read.ptx.sreg.ctaid.x : i32
          %29 = llvm.sext %28 : i32 to i64
          %30 = llvm.icmp "sle" %19, %8 : i64
          %31 = llvm.sub %8, %19  : i64
          %32 = llvm.sub %19, %9  : i64
          %33 = llvm.select %30, %31, %32 : i1, i64
          %34 = llvm.sdiv %33, %6  : i64
          %35 = llvm.sub %8, %34  : i64
          %36 = llvm.add %34, %9  : i64
          %37 = llvm.select %30, %35, %36 : i1, i64
          %38 = llvm.icmp "slt" %29, %8 : i64
          %39 = llvm.sub %5, %29  : i64
          %40 = llvm.select %38, %39, %29 : i1, i64
          %41 = llvm.sdiv %40, %37  : i64
          %42 = llvm.sub %5, %41  : i64
          %43 = llvm.select %38, %42, %41 : i1, i64
          %44 = llvm.mul %43, %4  : i64
          %45 = llvm.add %15, %44  : i64
          %46 = llvm.icmp "sgt" %45, %7 : i64
          %47 = llvm.select %46, %7, %45 : i1, i64
          %48 = llvm.srem %29, %37  : i64
          %49 = llvm.icmp "slt" %48, %8 : i64
          %50 = llvm.add %48, %37  : i64
          %51 = llvm.select %49, %50, %48 : i1, i64
          %52 = llvm.mul %51, %3  : i64
          %53 = llvm.add %19, %52  : i64
          %54 = llvm.icmp "sgt" %53, %6 : i64
          %55 = llvm.select %54, %6, %53 : i1, i64
          %56 = nvvm.read.ptx.sreg.tid.x : i32
          %57 = llvm.sext %56 : i32 to i64
          %58 = nvvm.read.ptx.sreg.tid.y : i32
          %59 = llvm.sext %58 : i32 to i64
          %60 = llvm.icmp "sle" %47, %8 : i64
          %61 = llvm.sub %8, %47  : i64
          %62 = llvm.sub %47, %9  : i64
          %63 = llvm.select %60, %61, %62 : i1, i64
          %64 = llvm.sdiv %63, %2  : i64
          %65 = llvm.sub %8, %64  : i64
          %66 = llvm.add %64, %9  : i64
          %67 = llvm.select %60, %65, %66 : i1, i64
          %68 = llvm.mul %59, %67  : i64
          %69 = llvm.sub %47, %68  : i64
          %70 = llvm.icmp "slt" %69, %67 : i64
          %71 = llvm.select %70, %69, %67 : i1, i64
          %72 = llvm.icmp "slt" %71, %8 : i64
          %73 = llvm.select %72, %8, %71 : i1, i64
          %74 = llvm.icmp "sle" %55, %8 : i64
          %75 = llvm.sub %8, %55  : i64
          %76 = llvm.sub %55, %9  : i64
          %77 = llvm.select %74, %75, %76 : i1, i64
          %78 = llvm.sdiv %77, %7  : i64
          %79 = llvm.sub %8, %78  : i64
          %80 = llvm.add %78, %9  : i64
          %81 = llvm.select %74, %79, %80 : i1, i64
          %82 = llvm.mul %57, %81  : i64
          %83 = llvm.sub %55, %82  : i64
          %84 = llvm.icmp "slt" %83, %81 : i64
          %85 = llvm.select %84, %83, %81 : i1, i64
          %86 = llvm.icmp "slt" %85, %8 : i64
          %87 = llvm.select %86, %8, %85 : i1, i64
          %88 = llvm.mul %43, %7  : i64
          %89 = llvm.add %88, %68  : i64
          %90 = llvm.mul %51, %6  : i64
          %91 = llvm.add %90, %82  : i64
          llvm.br ^bb1(%8 : i64)
        ^bb1(%92: i64):  // 2 preds: ^bb0, ^bb5
          %93 = llvm.icmp "slt" %92, %73 : i64
          llvm.cond_br %93, ^bb2, ^bb6(%8 : i64)
        ^bb2:  // pred: ^bb1
          %94 = llvm.add %89, %92  : i64
          llvm.br ^bb3(%8 : i64)
        ^bb3(%95: i64):  // 2 preds: ^bb2, ^bb4
          %96 = llvm.icmp "slt" %95, %87 : i64
          llvm.cond_br %96, ^bb4, ^bb5
        ^bb4:  // pred: ^bb3
          %97 = llvm.add %91, %95  : i64
          %98 = llvm.mul %94, %24  : i64
          %99 = llvm.add %98, %97  : i64
          %100 = llvm.getelementptr %arg1[%99] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          llvm.store %11, %100 : f32, !llvm.ptr<1>
          %101 = llvm.add %95, %9  : i64
          llvm.br ^bb3(%101 : i64)
        ^bb5:  // pred: ^bb3
          %102 = llvm.add %92, %9  : i64
          llvm.br ^bb1(%102 : i64)
        ^bb6(%103: i64):  // 2 preds: ^bb1, ^bb12
          %104 = llvm.icmp "slt" %103, %19 : i64
          llvm.cond_br %104, ^bb7(%8 : i64), ^bb13
        ^bb7(%105: i64):  // 2 preds: ^bb6, ^bb11
          %106 = llvm.icmp "slt" %105, %73 : i64
          llvm.cond_br %106, ^bb8, ^bb12
        ^bb8:  // pred: ^bb7
          %107 = llvm.add %89, %105  : i64
          llvm.br ^bb9(%8 : i64)
        ^bb9(%108: i64):  // 2 preds: ^bb8, ^bb10
          %109 = llvm.icmp "slt" %108, %87 : i64
          llvm.cond_br %109, ^bb10, ^bb11
        ^bb10:  // pred: ^bb9
          %110 = llvm.mul %107, %20  : i64
          %111 = llvm.add %110, %103  : i64
          %112 = llvm.getelementptr %arg0[%111] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %113 = llvm.load %112 : !llvm.ptr<1> -> f32
          %114 = llvm.add %91, %108  : i64
          %115 = llvm.mul %103, %20  : i64
          %116 = llvm.add %115, %114  : i64
          %117 = llvm.getelementptr %arg0[%116] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %118 = llvm.load %117 : !llvm.ptr<1> -> f32
          %119 = llvm.mul %107, %24  : i64
          %120 = llvm.add %119, %114  : i64
          %121 = llvm.getelementptr %arg1[%120] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %122 = llvm.load %121 : !llvm.ptr<1> -> f32
          %123 = llvm.fmul %113, %118  : f32
          %124 = llvm.fadd %122, %123  : f32
          %125 = llvm.mul %107, %24  : i64
          %126 = llvm.add %125, %114  : i64
          %127 = llvm.getelementptr %arg1[%126] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          llvm.store %124, %127 : f32, !llvm.ptr<1>
          %128 = llvm.add %108, %9  : i64
          llvm.br ^bb9(%128 : i64)
        ^bb11:  // pred: ^bb9
          %129 = llvm.add %105, %9  : i64
          llvm.br ^bb7(%129 : i64)
        ^bb12:  // pred: ^bb7
          %130 = llvm.add %103, %9  : i64
          llvm.br ^bb6(%130 : i64)
        ^bb13:  // pred: ^bb6
          llvm.return
        }
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c32_i64 = arith.constant 32 : i64
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %device_0 = hal.ex.shared_device : !hal.device
    %c-1_i64 = arith.constant -1 : i64
    %4 = util.null : !hal.fence
    %fence = hal.fence.create device(%device_0 : !hal.device) flags("None") : !hal.fence
    %c0_i64 = arith.constant 0 : i64
    %c-1_i32 = arith.constant -1 : i32
    %status = hal.fence.await until([%4]) timeout_millis(%c-1_i32) : i32
    %transient_buffer = hal.device.queue.alloca<%device_0 : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%3}
    %status_1 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    %5 = arith.index_castui %0 : index to i64
    %6 = arith.trunci %5 : i64 to i32
    %7 = arith.shrui %5, %c32_i64 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %1 : index to i64
    %10 = arith.trunci %9 : i64 to i32
    %11 = arith.shrui %9, %c32_i64 : i64
    %12 = arith.trunci %11 : i64 to i32
    %device_2 = hal.ex.shared_device : !hal.device
    %c-1_i64_3 = arith.constant -1 : i64
    %cmd = hal.command_buffer.create device(%device_2 : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    %13 = hal.command_buffer.device<%cmd : !hal.command_buffer> : !hal.device
    %ok, %value = hal.device.query<%13 : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    %c-1 = arith.constant -1 : index
    %c0_4 = arith.constant 0 : index
    %14 = arith.select %value, %c0_4, %c-1 : index
    scf.index_switch %14 
    case 0 {
      %pipeline_layout = hal.pipeline_layout.lookup device(%13 : !hal.device) layout(#pipeline_layout) : !hal.pipeline_layout
      hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%pipeline_layout : !hal.pipeline_layout) offset(0) values([%6, %8, %10, %12]) : i32, i32, i32, i32
      %c0_13 = arith.constant 0 : index
      %c1 = arith.constant 1 : index
      %c0_14 = arith.constant 0 : index
      hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%pipeline_layout : !hal.pipeline_layout)[%c0_14] bindings([
        %c0_13 = (%buffer : !hal.buffer)[%c0, %3], 
        %c1 = (%transient_buffer : !hal.buffer)[%c0, %3]
      ])
      %c1_15 = arith.constant 1 : index
      %16 = affine.apply #map()[%1, %0]
      hal.command_buffer.dispatch.symbol<%cmd : !hal.command_buffer> target(@main_dispatch_0::@cuda_nvptx_fb::@main_dispatch_0_matmul_DxDxD_f32) workgroups([%16, %c1_15, %c1_15])
      scf.yield
    }
    default {
    }
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_5 = hal.fence.create device(%device_2 : !hal.device) flags("None") : !hal.fence
    %c-1_i32_6 = arith.constant -1 : i32
    %status_7 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32_6) : i32
    %15 = util.null : !hal.fence
    hal.device.queue.execute<%device_2 : !hal.device> affinity(%c-1_i64_3) wait(%15) signal(%fence_5) commands([%cmd])
    %c-1_i32_8 = arith.constant -1 : i32
    %status_9 = hal.fence.await until([%fence_5]) timeout_millis(%c-1_i32_8) : i32
    util.status.check_ok %status_9, "failed to wait on timepoint"
    %c0_10 = arith.constant 0 : index
    %c553648160_i32_11 = arith.constant 553648160 : i32
    %c1_i32_12 = arith.constant 1 : i32
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0_10, %3] shape([%0, %1]) type(%c553648160_i32_11) encoding(%c1_i32_12) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After CSE (cse) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<()[s0, s1] -> ((s0 ceildiv 128) * (s1 ceildiv 32))>
#pipeline_layout = #hal.pipeline.layout<push_constants = 4, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer>]>]>
#translation = #iree_codegen.translation_info<LLVMGPUMatmulSimt>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  hal.executable private @main_dispatch_0 {
    hal.executable.variant public @cuda_nvptx_fb target(#executable_target_cuda_nvptx_fb) {
      hal.executable.export public @main_dispatch_0_matmul_DxDxD_f32 ordinal(0) layout(#pipeline_layout) attributes {translation_info = #translation, workgroup_size = [32 : index, 8 : index, 1 : index]} {
      ^bb0(%arg0: !hal.device, %arg1: index, %arg2: index):
        %c1 = arith.constant 1 : index
        %0 = affine.apply #map()[%arg2, %arg1]
        hal.return %0, %c1, %c1 : index, index, index
      }
      builtin.module {
        llvm.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias}, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32) {
          %0 = llvm.mlir.constant(63 : index) : i64
          %1 = llvm.mlir.constant(1 : i64) : i64
          %2 = llvm.mlir.constant(8 : index) : i64
          %3 = llvm.mlir.constant(-128 : index) : i64
          %4 = llvm.mlir.constant(-32 : index) : i64
          %5 = llvm.mlir.constant(-1 : index) : i64
          %6 = llvm.mlir.constant(128 : index) : i64
          %7 = llvm.mlir.constant(32 : index) : i64
          %8 = llvm.mlir.constant(0 : index) : i64
          %9 = llvm.mlir.constant(1 : index) : i64
          %10 = llvm.mlir.constant(32 : i64) : i64
          %11 = llvm.mlir.constant(0.000000e+00 : f32) : f32
          %12 = llvm.zext %arg2 : i32 to i64
          %13 = llvm.zext %arg3 : i32 to i64
          %14 = llvm.shl %13, %10  : i64
          %15 = llvm.or %12, %14  : i64
          %16 = llvm.zext %arg4 : i32 to i64
          %17 = llvm.zext %arg5 : i32 to i64
          %18 = llvm.shl %17, %10  : i64
          %19 = llvm.or %16, %18  : i64
          %20 = llvm.mul %19, %1  : i64
          %21 = llvm.ptrtoint %arg0 : !llvm.ptr<1> to i64
          %22 = llvm.and %21, %0  : i64
          %23 = llvm.icmp "eq" %22, %8 : i64
          "llvm.intr.assume"(%23) : (i1) -> ()
          %24 = llvm.ptrtoint %arg1 : !llvm.ptr<1> to i64
          %25 = llvm.and %24, %0  : i64
          %26 = llvm.icmp "eq" %25, %8 : i64
          "llvm.intr.assume"(%26) : (i1) -> ()
          %27 = nvvm.read.ptx.sreg.ctaid.x : i32
          %28 = llvm.sext %27 : i32 to i64
          %29 = llvm.icmp "sle" %19, %8 : i64
          %30 = llvm.sub %8, %19  : i64
          %31 = llvm.sub %19, %9  : i64
          %32 = llvm.select %29, %30, %31 : i1, i64
          %33 = llvm.sdiv %32, %6  : i64
          %34 = llvm.sub %8, %33  : i64
          %35 = llvm.add %33, %9  : i64
          %36 = llvm.select %29, %34, %35 : i1, i64
          %37 = llvm.icmp "slt" %28, %8 : i64
          %38 = llvm.sub %5, %28  : i64
          %39 = llvm.select %37, %38, %28 : i1, i64
          %40 = llvm.sdiv %39, %36  : i64
          %41 = llvm.sub %5, %40  : i64
          %42 = llvm.select %37, %41, %40 : i1, i64
          %43 = llvm.mul %42, %4  : i64
          %44 = llvm.add %15, %43  : i64
          %45 = llvm.icmp "sgt" %44, %7 : i64
          %46 = llvm.select %45, %7, %44 : i1, i64
          %47 = llvm.srem %28, %36  : i64
          %48 = llvm.icmp "slt" %47, %8 : i64
          %49 = llvm.add %47, %36  : i64
          %50 = llvm.select %48, %49, %47 : i1, i64
          %51 = llvm.mul %50, %3  : i64
          %52 = llvm.add %19, %51  : i64
          %53 = llvm.icmp "sgt" %52, %6 : i64
          %54 = llvm.select %53, %6, %52 : i1, i64
          %55 = nvvm.read.ptx.sreg.tid.x : i32
          %56 = llvm.sext %55 : i32 to i64
          %57 = nvvm.read.ptx.sreg.tid.y : i32
          %58 = llvm.sext %57 : i32 to i64
          %59 = llvm.icmp "sle" %46, %8 : i64
          %60 = llvm.sub %8, %46  : i64
          %61 = llvm.sub %46, %9  : i64
          %62 = llvm.select %59, %60, %61 : i1, i64
          %63 = llvm.sdiv %62, %2  : i64
          %64 = llvm.sub %8, %63  : i64
          %65 = llvm.add %63, %9  : i64
          %66 = llvm.select %59, %64, %65 : i1, i64
          %67 = llvm.mul %58, %66  : i64
          %68 = llvm.sub %46, %67  : i64
          %69 = llvm.icmp "slt" %68, %66 : i64
          %70 = llvm.select %69, %68, %66 : i1, i64
          %71 = llvm.icmp "slt" %70, %8 : i64
          %72 = llvm.select %71, %8, %70 : i1, i64
          %73 = llvm.icmp "sle" %54, %8 : i64
          %74 = llvm.sub %8, %54  : i64
          %75 = llvm.sub %54, %9  : i64
          %76 = llvm.select %73, %74, %75 : i1, i64
          %77 = llvm.sdiv %76, %7  : i64
          %78 = llvm.sub %8, %77  : i64
          %79 = llvm.add %77, %9  : i64
          %80 = llvm.select %73, %78, %79 : i1, i64
          %81 = llvm.mul %56, %80  : i64
          %82 = llvm.sub %54, %81  : i64
          %83 = llvm.icmp "slt" %82, %80 : i64
          %84 = llvm.select %83, %82, %80 : i1, i64
          %85 = llvm.icmp "slt" %84, %8 : i64
          %86 = llvm.select %85, %8, %84 : i1, i64
          %87 = llvm.mul %42, %7  : i64
          %88 = llvm.add %87, %67  : i64
          %89 = llvm.mul %50, %6  : i64
          %90 = llvm.add %89, %81  : i64
          llvm.br ^bb1(%8 : i64)
        ^bb1(%91: i64):  // 2 preds: ^bb0, ^bb5
          %92 = llvm.icmp "slt" %91, %72 : i64
          llvm.cond_br %92, ^bb2, ^bb6(%8 : i64)
        ^bb2:  // pred: ^bb1
          %93 = llvm.add %88, %91  : i64
          llvm.br ^bb3(%8 : i64)
        ^bb3(%94: i64):  // 2 preds: ^bb2, ^bb4
          %95 = llvm.icmp "slt" %94, %86 : i64
          llvm.cond_br %95, ^bb4, ^bb5
        ^bb4:  // pred: ^bb3
          %96 = llvm.add %90, %94  : i64
          %97 = llvm.mul %93, %20  : i64
          %98 = llvm.add %97, %96  : i64
          %99 = llvm.getelementptr %arg1[%98] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          llvm.store %11, %99 : f32, !llvm.ptr<1>
          %100 = llvm.add %94, %9  : i64
          llvm.br ^bb3(%100 : i64)
        ^bb5:  // pred: ^bb3
          %101 = llvm.add %91, %9  : i64
          llvm.br ^bb1(%101 : i64)
        ^bb6(%102: i64):  // 2 preds: ^bb1, ^bb12
          %103 = llvm.icmp "slt" %102, %19 : i64
          llvm.cond_br %103, ^bb7(%8 : i64), ^bb13
        ^bb7(%104: i64):  // 2 preds: ^bb6, ^bb11
          %105 = llvm.icmp "slt" %104, %72 : i64
          llvm.cond_br %105, ^bb8, ^bb12
        ^bb8:  // pred: ^bb7
          %106 = llvm.add %88, %104  : i64
          llvm.br ^bb9(%8 : i64)
        ^bb9(%107: i64):  // 2 preds: ^bb8, ^bb10
          %108 = llvm.icmp "slt" %107, %86 : i64
          llvm.cond_br %108, ^bb10, ^bb11
        ^bb10:  // pred: ^bb9
          %109 = llvm.mul %106, %20  : i64
          %110 = llvm.add %109, %102  : i64
          %111 = llvm.getelementptr %arg0[%110] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %112 = llvm.load %111 : !llvm.ptr<1> -> f32
          %113 = llvm.add %90, %107  : i64
          %114 = llvm.mul %102, %20  : i64
          %115 = llvm.add %114, %113  : i64
          %116 = llvm.getelementptr %arg0[%115] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %117 = llvm.load %116 : !llvm.ptr<1> -> f32
          %118 = llvm.add %109, %113  : i64
          %119 = llvm.getelementptr %arg1[%118] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %120 = llvm.load %119 : !llvm.ptr<1> -> f32
          %121 = llvm.fmul %112, %117  : f32
          %122 = llvm.fadd %120, %121  : f32
          llvm.store %122, %119 : f32, !llvm.ptr<1>
          %123 = llvm.add %107, %9  : i64
          llvm.br ^bb9(%123 : i64)
        ^bb11:  // pred: ^bb9
          %124 = llvm.add %104, %9  : i64
          llvm.br ^bb7(%124 : i64)
        ^bb12:  // pred: ^bb7
          %125 = llvm.add %102, %9  : i64
          llvm.br ^bb6(%125 : i64)
        ^bb13:  // pred: ^bb6
          llvm.return
        }
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c32_i64 = arith.constant 32 : i64
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %c-1_i64 = arith.constant -1 : i64
    %4 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %c0_i64 = arith.constant 0 : i64
    %c-1_i32 = arith.constant -1 : i32
    %status = hal.fence.await until([%4]) timeout_millis(%c-1_i32) : i32
    %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%3}
    %status_0 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    %5 = arith.index_castui %0 : index to i64
    %6 = arith.trunci %5 : i64 to i32
    %7 = arith.shrui %5, %c32_i64 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %1 : index to i64
    %10 = arith.trunci %9 : i64 to i32
    %11 = arith.shrui %9, %c32_i64 : i64
    %12 = arith.trunci %11 : i64 to i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    %13 = hal.command_buffer.device<%cmd : !hal.command_buffer> : !hal.device
    %ok, %value = hal.device.query<%13 : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    %c-1 = arith.constant -1 : index
    %14 = arith.select %value, %c0, %c-1 : index
    scf.index_switch %14 
    case 0 {
      %pipeline_layout = hal.pipeline_layout.lookup device(%13 : !hal.device) layout(#pipeline_layout) : !hal.pipeline_layout
      hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%pipeline_layout : !hal.pipeline_layout) offset(0) values([%6, %8, %10, %12]) : i32, i32, i32, i32
      %c1 = arith.constant 1 : index
      hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%pipeline_layout : !hal.pipeline_layout)[%c0] bindings([
        %c0 = (%buffer : !hal.buffer)[%c0, %3], 
        %c1 = (%transient_buffer : !hal.buffer)[%c0, %3]
      ])
      %15 = affine.apply #map()[%1, %0]
      hal.command_buffer.dispatch.symbol<%cmd : !hal.command_buffer> target(@main_dispatch_0::@cuda_nvptx_fb::@main_dispatch_0_matmul_DxDxD_f32) workgroups([%15, %c1, %c1])
      scf.yield
    }
    default {
    }
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_1 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status_2 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence_1) commands([%cmd])
    %status_3 = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status_3, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %3] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<()[s0, s1] -> ((s0 ceildiv 128) * (s1 ceildiv 32))>
#pipeline_layout = #hal.pipeline.layout<push_constants = 4, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer>]>]>
#translation = #iree_codegen.translation_info<LLVMGPUMatmulSimt>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  hal.executable private @main_dispatch_0 {
    hal.executable.variant public @cuda_nvptx_fb target(#executable_target_cuda_nvptx_fb) {
      hal.executable.export public @main_dispatch_0_matmul_DxDxD_f32 ordinal(0) layout(#pipeline_layout) attributes {translation_info = #translation, workgroup_size = [32 : index, 8 : index, 1 : index]} {
      ^bb0(%arg0: !hal.device, %arg1: index, %arg2: index):
        %c1 = arith.constant 1 : index
        %0 = affine.apply #map()[%arg2, %arg1]
        hal.return %0, %c1, %c1 : index, index, index
      }
      builtin.module {
        llvm.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias}, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32) {
          %0 = llvm.mlir.constant(63 : index) : i64
          %1 = llvm.mlir.constant(1 : i64) : i64
          %2 = llvm.mlir.constant(8 : index) : i64
          %3 = llvm.mlir.constant(-128 : index) : i64
          %4 = llvm.mlir.constant(-32 : index) : i64
          %5 = llvm.mlir.constant(-1 : index) : i64
          %6 = llvm.mlir.constant(128 : index) : i64
          %7 = llvm.mlir.constant(32 : index) : i64
          %8 = llvm.mlir.constant(0 : index) : i64
          %9 = llvm.mlir.constant(1 : index) : i64
          %10 = llvm.mlir.constant(32 : i64) : i64
          %11 = llvm.mlir.constant(0.000000e+00 : f32) : f32
          %12 = llvm.zext %arg2 : i32 to i64
          %13 = llvm.zext %arg3 : i32 to i64
          %14 = llvm.shl %13, %10  : i64
          %15 = llvm.or %12, %14  : i64
          %16 = llvm.zext %arg4 : i32 to i64
          %17 = llvm.zext %arg5 : i32 to i64
          %18 = llvm.shl %17, %10  : i64
          %19 = llvm.or %16, %18  : i64
          %20 = llvm.mul %19, %1  : i64
          %21 = llvm.ptrtoint %arg0 : !llvm.ptr<1> to i64
          %22 = llvm.and %21, %0  : i64
          %23 = llvm.icmp "eq" %22, %8 : i64
          "llvm.intr.assume"(%23) : (i1) -> ()
          %24 = llvm.ptrtoint %arg1 : !llvm.ptr<1> to i64
          %25 = llvm.and %24, %0  : i64
          %26 = llvm.icmp "eq" %25, %8 : i64
          "llvm.intr.assume"(%26) : (i1) -> ()
          %27 = nvvm.read.ptx.sreg.ctaid.x : i32
          %28 = llvm.sext %27 : i32 to i64
          %29 = llvm.icmp "sle" %19, %8 : i64
          %30 = llvm.sub %8, %19  : i64
          %31 = llvm.sub %19, %9  : i64
          %32 = llvm.select %29, %30, %31 : i1, i64
          %33 = llvm.sdiv %32, %6  : i64
          %34 = llvm.sub %8, %33  : i64
          %35 = llvm.add %33, %9  : i64
          %36 = llvm.select %29, %34, %35 : i1, i64
          %37 = llvm.icmp "slt" %28, %8 : i64
          %38 = llvm.sub %5, %28  : i64
          %39 = llvm.select %37, %38, %28 : i1, i64
          %40 = llvm.sdiv %39, %36  : i64
          %41 = llvm.sub %5, %40  : i64
          %42 = llvm.select %37, %41, %40 : i1, i64
          %43 = llvm.mul %42, %4  : i64
          %44 = llvm.add %15, %43  : i64
          %45 = llvm.icmp "sgt" %44, %7 : i64
          %46 = llvm.select %45, %7, %44 : i1, i64
          %47 = llvm.srem %28, %36  : i64
          %48 = llvm.icmp "slt" %47, %8 : i64
          %49 = llvm.add %47, %36  : i64
          %50 = llvm.select %48, %49, %47 : i1, i64
          %51 = llvm.mul %50, %3  : i64
          %52 = llvm.add %19, %51  : i64
          %53 = llvm.icmp "sgt" %52, %6 : i64
          %54 = llvm.select %53, %6, %52 : i1, i64
          %55 = nvvm.read.ptx.sreg.tid.x : i32
          %56 = llvm.sext %55 : i32 to i64
          %57 = nvvm.read.ptx.sreg.tid.y : i32
          %58 = llvm.sext %57 : i32 to i64
          %59 = llvm.icmp "sle" %46, %8 : i64
          %60 = llvm.sub %8, %46  : i64
          %61 = llvm.sub %46, %9  : i64
          %62 = llvm.select %59, %60, %61 : i1, i64
          %63 = llvm.sdiv %62, %2  : i64
          %64 = llvm.sub %8, %63  : i64
          %65 = llvm.add %63, %9  : i64
          %66 = llvm.select %59, %64, %65 : i1, i64
          %67 = llvm.mul %58, %66  : i64
          %68 = llvm.sub %46, %67  : i64
          %69 = llvm.icmp "slt" %68, %66 : i64
          %70 = llvm.select %69, %68, %66 : i1, i64
          %71 = llvm.icmp "slt" %70, %8 : i64
          %72 = llvm.select %71, %8, %70 : i1, i64
          %73 = llvm.icmp "sle" %54, %8 : i64
          %74 = llvm.sub %8, %54  : i64
          %75 = llvm.sub %54, %9  : i64
          %76 = llvm.select %73, %74, %75 : i1, i64
          %77 = llvm.sdiv %76, %7  : i64
          %78 = llvm.sub %8, %77  : i64
          %79 = llvm.add %77, %9  : i64
          %80 = llvm.select %73, %78, %79 : i1, i64
          %81 = llvm.mul %56, %80  : i64
          %82 = llvm.sub %54, %81  : i64
          %83 = llvm.icmp "slt" %82, %80 : i64
          %84 = llvm.select %83, %82, %80 : i1, i64
          %85 = llvm.icmp "slt" %84, %8 : i64
          %86 = llvm.select %85, %8, %84 : i1, i64
          %87 = llvm.mul %42, %7  : i64
          %88 = llvm.add %87, %67  : i64
          %89 = llvm.mul %50, %6  : i64
          %90 = llvm.add %89, %81  : i64
          llvm.br ^bb1(%8 : i64)
        ^bb1(%91: i64):  // 2 preds: ^bb0, ^bb5
          %92 = llvm.icmp "slt" %91, %72 : i64
          llvm.cond_br %92, ^bb2, ^bb6(%8 : i64)
        ^bb2:  // pred: ^bb1
          %93 = llvm.add %88, %91  : i64
          llvm.br ^bb3(%8 : i64)
        ^bb3(%94: i64):  // 2 preds: ^bb2, ^bb4
          %95 = llvm.icmp "slt" %94, %86 : i64
          llvm.cond_br %95, ^bb4, ^bb5
        ^bb4:  // pred: ^bb3
          %96 = llvm.add %90, %94  : i64
          %97 = llvm.mul %93, %20  : i64
          %98 = llvm.add %97, %96  : i64
          %99 = llvm.getelementptr %arg1[%98] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          llvm.store %11, %99 : f32, !llvm.ptr<1>
          %100 = llvm.add %94, %9  : i64
          llvm.br ^bb3(%100 : i64)
        ^bb5:  // pred: ^bb3
          %101 = llvm.add %91, %9  : i64
          llvm.br ^bb1(%101 : i64)
        ^bb6(%102: i64):  // 2 preds: ^bb1, ^bb12
          %103 = llvm.icmp "slt" %102, %19 : i64
          llvm.cond_br %103, ^bb7(%8 : i64), ^bb13
        ^bb7(%104: i64):  // 2 preds: ^bb6, ^bb11
          %105 = llvm.icmp "slt" %104, %72 : i64
          llvm.cond_br %105, ^bb8, ^bb12
        ^bb8:  // pred: ^bb7
          %106 = llvm.add %88, %104  : i64
          llvm.br ^bb9(%8 : i64)
        ^bb9(%107: i64):  // 2 preds: ^bb8, ^bb10
          %108 = llvm.icmp "slt" %107, %86 : i64
          llvm.cond_br %108, ^bb10, ^bb11
        ^bb10:  // pred: ^bb9
          %109 = llvm.mul %106, %20  : i64
          %110 = llvm.add %109, %102  : i64
          %111 = llvm.getelementptr %arg0[%110] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %112 = llvm.load %111 : !llvm.ptr<1> -> f32
          %113 = llvm.add %90, %107  : i64
          %114 = llvm.mul %102, %20  : i64
          %115 = llvm.add %114, %113  : i64
          %116 = llvm.getelementptr %arg0[%115] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %117 = llvm.load %116 : !llvm.ptr<1> -> f32
          %118 = llvm.add %109, %113  : i64
          %119 = llvm.getelementptr %arg1[%118] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %120 = llvm.load %119 : !llvm.ptr<1> -> f32
          %121 = llvm.fmul %112, %117  : f32
          %122 = llvm.fadd %120, %121  : f32
          llvm.store %122, %119 : f32, !llvm.ptr<1>
          %123 = llvm.add %107, %9  : i64
          llvm.br ^bb9(%123 : i64)
        ^bb11:  // pred: ^bb9
          %124 = llvm.add %104, %9  : i64
          llvm.br ^bb7(%124 : i64)
        ^bb12:  // pred: ^bb7
          %125 = llvm.add %102, %9  : i64
          llvm.br ^bb6(%125 : i64)
        ^bb13:  // pred: ^bb6
          llvm.return
        }
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c1 = arith.constant 1 : index
    %c-1 = arith.constant -1 : index
    %c-1_i32 = arith.constant -1 : i32
    %c0_i64 = arith.constant 0 : i64
    %c-1_i64 = arith.constant -1 : i64
    %c32_i64 = arith.constant 32 : i64
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %4 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%3}
    %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    %5 = arith.index_castui %0 : index to i64
    %6 = arith.trunci %5 : i64 to i32
    %7 = arith.shrui %5, %c32_i64 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %1 : index to i64
    %10 = arith.trunci %9 : i64 to i32
    %11 = arith.shrui %9, %c32_i64 : i64
    %12 = arith.trunci %11 : i64 to i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    %13 = arith.select %value, %c0, %c-1 : index
    scf.index_switch %13 
    case 0 {
      %pipeline_layout = hal.pipeline_layout.lookup device(%device : !hal.device) layout(#pipeline_layout) : !hal.pipeline_layout
      hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%pipeline_layout : !hal.pipeline_layout) offset(0) values([%6, %8, %10, %12]) : i32, i32, i32, i32
      hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%pipeline_layout : !hal.pipeline_layout)[%c0] bindings([
        %c0 = (%buffer : !hal.buffer)[%c0, %3], 
        %c1 = (%transient_buffer : !hal.buffer)[%c0, %3]
      ])
      %14 = affine.apply #map()[%1, %0]
      hal.command_buffer.dispatch.symbol<%cmd : !hal.command_buffer> target(@main_dispatch_0::@cuda_nvptx_fb::@main_dispatch_0_matmul_DxDxD_f32) workgroups([%14, %c1, %c1])
      scf.yield
    }
    default {
    }
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_0 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status_1 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence_0) commands([%cmd])
    %status_2 = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status_2, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %3] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After CSE (cse) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<()[s0, s1] -> ((s0 ceildiv 128) * (s1 ceildiv 32))>
#pipeline_layout = #hal.pipeline.layout<push_constants = 4, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer>]>]>
#translation = #iree_codegen.translation_info<LLVMGPUMatmulSimt>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  hal.executable private @main_dispatch_0 {
    hal.executable.variant public @cuda_nvptx_fb target(#executable_target_cuda_nvptx_fb) {
      hal.executable.export public @main_dispatch_0_matmul_DxDxD_f32 ordinal(0) layout(#pipeline_layout) attributes {translation_info = #translation, workgroup_size = [32 : index, 8 : index, 1 : index]} {
      ^bb0(%arg0: !hal.device, %arg1: index, %arg2: index):
        %c1 = arith.constant 1 : index
        %0 = affine.apply #map()[%arg2, %arg1]
        hal.return %0, %c1, %c1 : index, index, index
      }
      builtin.module {
        llvm.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias}, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32) {
          %0 = llvm.mlir.constant(63 : index) : i64
          %1 = llvm.mlir.constant(1 : i64) : i64
          %2 = llvm.mlir.constant(8 : index) : i64
          %3 = llvm.mlir.constant(-128 : index) : i64
          %4 = llvm.mlir.constant(-32 : index) : i64
          %5 = llvm.mlir.constant(-1 : index) : i64
          %6 = llvm.mlir.constant(128 : index) : i64
          %7 = llvm.mlir.constant(32 : index) : i64
          %8 = llvm.mlir.constant(0 : index) : i64
          %9 = llvm.mlir.constant(1 : index) : i64
          %10 = llvm.mlir.constant(32 : i64) : i64
          %11 = llvm.mlir.constant(0.000000e+00 : f32) : f32
          %12 = llvm.zext %arg2 : i32 to i64
          %13 = llvm.zext %arg3 : i32 to i64
          %14 = llvm.shl %13, %10  : i64
          %15 = llvm.or %12, %14  : i64
          %16 = llvm.zext %arg4 : i32 to i64
          %17 = llvm.zext %arg5 : i32 to i64
          %18 = llvm.shl %17, %10  : i64
          %19 = llvm.or %16, %18  : i64
          %20 = llvm.mul %19, %1  : i64
          %21 = llvm.ptrtoint %arg0 : !llvm.ptr<1> to i64
          %22 = llvm.and %21, %0  : i64
          %23 = llvm.icmp "eq" %22, %8 : i64
          "llvm.intr.assume"(%23) : (i1) -> ()
          %24 = llvm.ptrtoint %arg1 : !llvm.ptr<1> to i64
          %25 = llvm.and %24, %0  : i64
          %26 = llvm.icmp "eq" %25, %8 : i64
          "llvm.intr.assume"(%26) : (i1) -> ()
          %27 = nvvm.read.ptx.sreg.ctaid.x : i32
          %28 = llvm.sext %27 : i32 to i64
          %29 = llvm.icmp "sle" %19, %8 : i64
          %30 = llvm.sub %8, %19  : i64
          %31 = llvm.sub %19, %9  : i64
          %32 = llvm.select %29, %30, %31 : i1, i64
          %33 = llvm.sdiv %32, %6  : i64
          %34 = llvm.sub %8, %33  : i64
          %35 = llvm.add %33, %9  : i64
          %36 = llvm.select %29, %34, %35 : i1, i64
          %37 = llvm.icmp "slt" %28, %8 : i64
          %38 = llvm.sub %5, %28  : i64
          %39 = llvm.select %37, %38, %28 : i1, i64
          %40 = llvm.sdiv %39, %36  : i64
          %41 = llvm.sub %5, %40  : i64
          %42 = llvm.select %37, %41, %40 : i1, i64
          %43 = llvm.mul %42, %4  : i64
          %44 = llvm.add %15, %43  : i64
          %45 = llvm.icmp "sgt" %44, %7 : i64
          %46 = llvm.select %45, %7, %44 : i1, i64
          %47 = llvm.srem %28, %36  : i64
          %48 = llvm.icmp "slt" %47, %8 : i64
          %49 = llvm.add %47, %36  : i64
          %50 = llvm.select %48, %49, %47 : i1, i64
          %51 = llvm.mul %50, %3  : i64
          %52 = llvm.add %19, %51  : i64
          %53 = llvm.icmp "sgt" %52, %6 : i64
          %54 = llvm.select %53, %6, %52 : i1, i64
          %55 = nvvm.read.ptx.sreg.tid.x : i32
          %56 = llvm.sext %55 : i32 to i64
          %57 = nvvm.read.ptx.sreg.tid.y : i32
          %58 = llvm.sext %57 : i32 to i64
          %59 = llvm.icmp "sle" %46, %8 : i64
          %60 = llvm.sub %8, %46  : i64
          %61 = llvm.sub %46, %9  : i64
          %62 = llvm.select %59, %60, %61 : i1, i64
          %63 = llvm.sdiv %62, %2  : i64
          %64 = llvm.sub %8, %63  : i64
          %65 = llvm.add %63, %9  : i64
          %66 = llvm.select %59, %64, %65 : i1, i64
          %67 = llvm.mul %58, %66  : i64
          %68 = llvm.sub %46, %67  : i64
          %69 = llvm.icmp "slt" %68, %66 : i64
          %70 = llvm.select %69, %68, %66 : i1, i64
          %71 = llvm.icmp "slt" %70, %8 : i64
          %72 = llvm.select %71, %8, %70 : i1, i64
          %73 = llvm.icmp "sle" %54, %8 : i64
          %74 = llvm.sub %8, %54  : i64
          %75 = llvm.sub %54, %9  : i64
          %76 = llvm.select %73, %74, %75 : i1, i64
          %77 = llvm.sdiv %76, %7  : i64
          %78 = llvm.sub %8, %77  : i64
          %79 = llvm.add %77, %9  : i64
          %80 = llvm.select %73, %78, %79 : i1, i64
          %81 = llvm.mul %56, %80  : i64
          %82 = llvm.sub %54, %81  : i64
          %83 = llvm.icmp "slt" %82, %80 : i64
          %84 = llvm.select %83, %82, %80 : i1, i64
          %85 = llvm.icmp "slt" %84, %8 : i64
          %86 = llvm.select %85, %8, %84 : i1, i64
          %87 = llvm.mul %42, %7  : i64
          %88 = llvm.add %87, %67  : i64
          %89 = llvm.mul %50, %6  : i64
          %90 = llvm.add %89, %81  : i64
          llvm.br ^bb1(%8 : i64)
        ^bb1(%91: i64):  // 2 preds: ^bb0, ^bb5
          %92 = llvm.icmp "slt" %91, %72 : i64
          llvm.cond_br %92, ^bb2, ^bb6(%8 : i64)
        ^bb2:  // pred: ^bb1
          %93 = llvm.add %88, %91  : i64
          llvm.br ^bb3(%8 : i64)
        ^bb3(%94: i64):  // 2 preds: ^bb2, ^bb4
          %95 = llvm.icmp "slt" %94, %86 : i64
          llvm.cond_br %95, ^bb4, ^bb5
        ^bb4:  // pred: ^bb3
          %96 = llvm.add %90, %94  : i64
          %97 = llvm.mul %93, %20  : i64
          %98 = llvm.add %97, %96  : i64
          %99 = llvm.getelementptr %arg1[%98] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          llvm.store %11, %99 : f32, !llvm.ptr<1>
          %100 = llvm.add %94, %9  : i64
          llvm.br ^bb3(%100 : i64)
        ^bb5:  // pred: ^bb3
          %101 = llvm.add %91, %9  : i64
          llvm.br ^bb1(%101 : i64)
        ^bb6(%102: i64):  // 2 preds: ^bb1, ^bb12
          %103 = llvm.icmp "slt" %102, %19 : i64
          llvm.cond_br %103, ^bb7(%8 : i64), ^bb13
        ^bb7(%104: i64):  // 2 preds: ^bb6, ^bb11
          %105 = llvm.icmp "slt" %104, %72 : i64
          llvm.cond_br %105, ^bb8, ^bb12
        ^bb8:  // pred: ^bb7
          %106 = llvm.add %88, %104  : i64
          llvm.br ^bb9(%8 : i64)
        ^bb9(%107: i64):  // 2 preds: ^bb8, ^bb10
          %108 = llvm.icmp "slt" %107, %86 : i64
          llvm.cond_br %108, ^bb10, ^bb11
        ^bb10:  // pred: ^bb9
          %109 = llvm.mul %106, %20  : i64
          %110 = llvm.add %109, %102  : i64
          %111 = llvm.getelementptr %arg0[%110] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %112 = llvm.load %111 : !llvm.ptr<1> -> f32
          %113 = llvm.add %90, %107  : i64
          %114 = llvm.mul %102, %20  : i64
          %115 = llvm.add %114, %113  : i64
          %116 = llvm.getelementptr %arg0[%115] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %117 = llvm.load %116 : !llvm.ptr<1> -> f32
          %118 = llvm.add %109, %113  : i64
          %119 = llvm.getelementptr %arg1[%118] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %120 = llvm.load %119 : !llvm.ptr<1> -> f32
          %121 = llvm.fmul %112, %117  : f32
          %122 = llvm.fadd %120, %121  : f32
          llvm.store %122, %119 : f32, !llvm.ptr<1>
          %123 = llvm.add %107, %9  : i64
          llvm.br ^bb9(%123 : i64)
        ^bb11:  // pred: ^bb9
          %124 = llvm.add %104, %9  : i64
          llvm.br ^bb7(%124 : i64)
        ^bb12:  // pred: ^bb7
          %125 = llvm.add %102, %9  : i64
          llvm.br ^bb6(%125 : i64)
        ^bb13:  // pred: ^bb6
          llvm.return
        }
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c1 = arith.constant 1 : index
    %c-1 = arith.constant -1 : index
    %c-1_i32 = arith.constant -1 : i32
    %c0_i64 = arith.constant 0 : i64
    %c-1_i64 = arith.constant -1 : i64
    %c32_i64 = arith.constant 32 : i64
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %4 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%3}
    %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    %5 = arith.index_castui %0 : index to i64
    %6 = arith.trunci %5 : i64 to i32
    %7 = arith.shrui %5, %c32_i64 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %1 : index to i64
    %10 = arith.trunci %9 : i64 to i32
    %11 = arith.shrui %9, %c32_i64 : i64
    %12 = arith.trunci %11 : i64 to i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    %13 = arith.select %value, %c0, %c-1 : index
    scf.index_switch %13 
    case 0 {
      %pipeline_layout = hal.pipeline_layout.lookup device(%device : !hal.device) layout(#pipeline_layout) : !hal.pipeline_layout
      hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%pipeline_layout : !hal.pipeline_layout) offset(0) values([%6, %8, %10, %12]) : i32, i32, i32, i32
      hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%pipeline_layout : !hal.pipeline_layout)[%c0] bindings([
        %c0 = (%buffer : !hal.buffer)[%c0, %3], 
        %c1 = (%transient_buffer : !hal.buffer)[%c0, %3]
      ])
      %14 = affine.apply #map()[%1, %0]
      hal.command_buffer.dispatch.symbol<%cmd : !hal.command_buffer> target(@main_dispatch_0::@cuda_nvptx_fb::@main_dispatch_0_matmul_DxDxD_f32) workgroups([%14, %c1, %c1])
      scf.yield
    }
    default {
    }
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_0 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status_1 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence_0) commands([%cmd])
    %status_2 = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status_2, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %3] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c1 = arith.constant 1 : index
  %c-1 = arith.constant -1 : index
  %c-1_i32 = arith.constant -1 : i32
  %c0_i64 = arith.constant 0 : i64
  %c-1_i64 = arith.constant -1 : i64
  %c32_i64 = arith.constant 32 : i64
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %device = hal.ex.shared_device : !hal.device
  %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %4 = util.null : !hal.fence
  %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
  %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%3}
  %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
  %5 = arith.index_castui %0 : index to i64
  %6 = arith.trunci %5 : i64 to i32
  %7 = arith.shrui %5, %c32_i64 : i64
  %8 = arith.trunci %7 : i64 to i32
  %9 = arith.index_castui %1 : index to i64
  %10 = arith.trunci %9 : i64 to i32
  %11 = arith.shrui %9, %c32_i64 : i64
  %12 = arith.trunci %11 : i64 to i32
  %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
  %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
  %13 = arith.select %value, %c0, %c-1 : index
  scf.index_switch %13 
  case 0 {
    %pipeline_layout = hal.pipeline_layout.lookup device(%device : !hal.device) layout(<push_constants = 4, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer>]>]>) : !hal.pipeline_layout
    hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%pipeline_layout : !hal.pipeline_layout) offset(0) values([%6, %8, %10, %12]) : i32, i32, i32, i32
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%pipeline_layout : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%buffer : !hal.buffer)[%c0, %3], 
      %c1 = (%transient_buffer : !hal.buffer)[%c0, %3]
    ])
    %14 = affine.apply affine_map<()[s0, s1] -> ((s0 ceildiv 128) * (s1 ceildiv 32))>()[%1, %0]
    hal.command_buffer.dispatch.symbol<%cmd : !hal.command_buffer> target(@main_dispatch_0::@cuda_nvptx_fb::@main_dispatch_0_matmul_DxDxD_f32) workgroups([%14, %c1, %c1])
    scf.yield
  }
  default {
  }
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  %fence_0 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
  %status_1 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
  hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence_0) commands([%cmd])
  %status_2 = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) : i32
  util.status.check_ok %status_2, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %3] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
  return %view : !hal.buffer_view
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<()[s0, s1] -> ((s0 ceildiv 128) * (s1 ceildiv 32))>
#pipeline_layout = #hal.pipeline.layout<push_constants = 4, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer>]>]>
#translation = #iree_codegen.translation_info<LLVMGPUMatmulSimt>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  hal.executable private @main_dispatch_0 {
    hal.executable.variant public @cuda_nvptx_fb target(#executable_target_cuda_nvptx_fb) {
      hal.executable.export public @main_dispatch_0_matmul_DxDxD_f32 ordinal(0) layout(#pipeline_layout) attributes {translation_info = #translation, workgroup_size = [32 : index, 8 : index, 1 : index]} {
      ^bb0(%arg0: !hal.device, %arg1: index, %arg2: index):
        %c1 = arith.constant 1 : index
        %0 = affine.apply #map()[%arg2, %arg1]
        hal.return %0, %c1, %c1 : index, index, index
      }
      builtin.module {
        llvm.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias}, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32) {
          %0 = llvm.mlir.constant(63 : index) : i64
          %1 = llvm.mlir.constant(1 : i64) : i64
          %2 = llvm.mlir.constant(8 : index) : i64
          %3 = llvm.mlir.constant(-128 : index) : i64
          %4 = llvm.mlir.constant(-32 : index) : i64
          %5 = llvm.mlir.constant(-1 : index) : i64
          %6 = llvm.mlir.constant(128 : index) : i64
          %7 = llvm.mlir.constant(32 : index) : i64
          %8 = llvm.mlir.constant(0 : index) : i64
          %9 = llvm.mlir.constant(1 : index) : i64
          %10 = llvm.mlir.constant(32 : i64) : i64
          %11 = llvm.mlir.constant(0.000000e+00 : f32) : f32
          %12 = llvm.zext %arg2 : i32 to i64
          %13 = llvm.zext %arg3 : i32 to i64
          %14 = llvm.shl %13, %10  : i64
          %15 = llvm.or %12, %14  : i64
          %16 = llvm.zext %arg4 : i32 to i64
          %17 = llvm.zext %arg5 : i32 to i64
          %18 = llvm.shl %17, %10  : i64
          %19 = llvm.or %16, %18  : i64
          %20 = llvm.mul %19, %1  : i64
          %21 = llvm.ptrtoint %arg0 : !llvm.ptr<1> to i64
          %22 = llvm.and %21, %0  : i64
          %23 = llvm.icmp "eq" %22, %8 : i64
          "llvm.intr.assume"(%23) : (i1) -> ()
          %24 = llvm.ptrtoint %arg1 : !llvm.ptr<1> to i64
          %25 = llvm.and %24, %0  : i64
          %26 = llvm.icmp "eq" %25, %8 : i64
          "llvm.intr.assume"(%26) : (i1) -> ()
          %27 = nvvm.read.ptx.sreg.ctaid.x : i32
          %28 = llvm.sext %27 : i32 to i64
          %29 = llvm.icmp "sle" %19, %8 : i64
          %30 = llvm.sub %8, %19  : i64
          %31 = llvm.sub %19, %9  : i64
          %32 = llvm.select %29, %30, %31 : i1, i64
          %33 = llvm.sdiv %32, %6  : i64
          %34 = llvm.sub %8, %33  : i64
          %35 = llvm.add %33, %9  : i64
          %36 = llvm.select %29, %34, %35 : i1, i64
          %37 = llvm.icmp "slt" %28, %8 : i64
          %38 = llvm.sub %5, %28  : i64
          %39 = llvm.select %37, %38, %28 : i1, i64
          %40 = llvm.sdiv %39, %36  : i64
          %41 = llvm.sub %5, %40  : i64
          %42 = llvm.select %37, %41, %40 : i1, i64
          %43 = llvm.mul %42, %4  : i64
          %44 = llvm.add %15, %43  : i64
          %45 = llvm.icmp "sgt" %44, %7 : i64
          %46 = llvm.select %45, %7, %44 : i1, i64
          %47 = llvm.srem %28, %36  : i64
          %48 = llvm.icmp "slt" %47, %8 : i64
          %49 = llvm.add %47, %36  : i64
          %50 = llvm.select %48, %49, %47 : i1, i64
          %51 = llvm.mul %50, %3  : i64
          %52 = llvm.add %19, %51  : i64
          %53 = llvm.icmp "sgt" %52, %6 : i64
          %54 = llvm.select %53, %6, %52 : i1, i64
          %55 = nvvm.read.ptx.sreg.tid.x : i32
          %56 = llvm.sext %55 : i32 to i64
          %57 = nvvm.read.ptx.sreg.tid.y : i32
          %58 = llvm.sext %57 : i32 to i64
          %59 = llvm.icmp "sle" %46, %8 : i64
          %60 = llvm.sub %8, %46  : i64
          %61 = llvm.sub %46, %9  : i64
          %62 = llvm.select %59, %60, %61 : i1, i64
          %63 = llvm.sdiv %62, %2  : i64
          %64 = llvm.sub %8, %63  : i64
          %65 = llvm.add %63, %9  : i64
          %66 = llvm.select %59, %64, %65 : i1, i64
          %67 = llvm.mul %58, %66  : i64
          %68 = llvm.sub %46, %67  : i64
          %69 = llvm.icmp "slt" %68, %66 : i64
          %70 = llvm.select %69, %68, %66 : i1, i64
          %71 = llvm.icmp "slt" %70, %8 : i64
          %72 = llvm.select %71, %8, %70 : i1, i64
          %73 = llvm.icmp "sle" %54, %8 : i64
          %74 = llvm.sub %8, %54  : i64
          %75 = llvm.sub %54, %9  : i64
          %76 = llvm.select %73, %74, %75 : i1, i64
          %77 = llvm.sdiv %76, %7  : i64
          %78 = llvm.sub %8, %77  : i64
          %79 = llvm.add %77, %9  : i64
          %80 = llvm.select %73, %78, %79 : i1, i64
          %81 = llvm.mul %56, %80  : i64
          %82 = llvm.sub %54, %81  : i64
          %83 = llvm.icmp "slt" %82, %80 : i64
          %84 = llvm.select %83, %82, %80 : i1, i64
          %85 = llvm.icmp "slt" %84, %8 : i64
          %86 = llvm.select %85, %8, %84 : i1, i64
          %87 = llvm.mul %42, %7  : i64
          %88 = llvm.add %87, %67  : i64
          %89 = llvm.mul %50, %6  : i64
          %90 = llvm.add %89, %81  : i64
          llvm.br ^bb1(%8 : i64)
        ^bb1(%91: i64):  // 2 preds: ^bb0, ^bb5
          %92 = llvm.icmp "slt" %91, %72 : i64
          llvm.cond_br %92, ^bb2, ^bb6(%8 : i64)
        ^bb2:  // pred: ^bb1
          %93 = llvm.add %88, %91  : i64
          llvm.br ^bb3(%8 : i64)
        ^bb3(%94: i64):  // 2 preds: ^bb2, ^bb4
          %95 = llvm.icmp "slt" %94, %86 : i64
          llvm.cond_br %95, ^bb4, ^bb5
        ^bb4:  // pred: ^bb3
          %96 = llvm.add %90, %94  : i64
          %97 = llvm.mul %93, %20  : i64
          %98 = llvm.add %97, %96  : i64
          %99 = llvm.getelementptr %arg1[%98] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          llvm.store %11, %99 : f32, !llvm.ptr<1>
          %100 = llvm.add %94, %9  : i64
          llvm.br ^bb3(%100 : i64)
        ^bb5:  // pred: ^bb3
          %101 = llvm.add %91, %9  : i64
          llvm.br ^bb1(%101 : i64)
        ^bb6(%102: i64):  // 2 preds: ^bb1, ^bb12
          %103 = llvm.icmp "slt" %102, %19 : i64
          llvm.cond_br %103, ^bb7(%8 : i64), ^bb13
        ^bb7(%104: i64):  // 2 preds: ^bb6, ^bb11
          %105 = llvm.icmp "slt" %104, %72 : i64
          llvm.cond_br %105, ^bb8, ^bb12
        ^bb8:  // pred: ^bb7
          %106 = llvm.add %88, %104  : i64
          llvm.br ^bb9(%8 : i64)
        ^bb9(%107: i64):  // 2 preds: ^bb8, ^bb10
          %108 = llvm.icmp "slt" %107, %86 : i64
          llvm.cond_br %108, ^bb10, ^bb11
        ^bb10:  // pred: ^bb9
          %109 = llvm.mul %106, %20  : i64
          %110 = llvm.add %109, %102  : i64
          %111 = llvm.getelementptr %arg0[%110] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %112 = llvm.load %111 : !llvm.ptr<1> -> f32
          %113 = llvm.add %90, %107  : i64
          %114 = llvm.mul %102, %20  : i64
          %115 = llvm.add %114, %113  : i64
          %116 = llvm.getelementptr %arg0[%115] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %117 = llvm.load %116 : !llvm.ptr<1> -> f32
          %118 = llvm.add %109, %113  : i64
          %119 = llvm.getelementptr %arg1[%118] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %120 = llvm.load %119 : !llvm.ptr<1> -> f32
          %121 = llvm.fmul %112, %117  : f32
          %122 = llvm.fadd %120, %121  : f32
          llvm.store %122, %119 : f32, !llvm.ptr<1>
          %123 = llvm.add %107, %9  : i64
          llvm.br ^bb9(%123 : i64)
        ^bb11:  // pred: ^bb9
          %124 = llvm.add %104, %9  : i64
          llvm.br ^bb7(%124 : i64)
        ^bb12:  // pred: ^bb7
          %125 = llvm.add %102, %9  : i64
          llvm.br ^bb6(%125 : i64)
        ^bb13:  // pred: ^bb6
          llvm.return
        }
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c1 = arith.constant 1 : index
    %c-1 = arith.constant -1 : index
    %c-1_i32 = arith.constant -1 : i32
    %c0_i64 = arith.constant 0 : i64
    %c-1_i64 = arith.constant -1 : i64
    %c32_i64 = arith.constant 32 : i64
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %4 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%3}
    %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    %5 = arith.index_castui %0 : index to i64
    %6 = arith.trunci %5 : i64 to i32
    %7 = arith.shrui %5, %c32_i64 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %1 : index to i64
    %10 = arith.trunci %9 : i64 to i32
    %11 = arith.shrui %9, %c32_i64 : i64
    %12 = arith.trunci %11 : i64 to i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    %13 = arith.select %value, %c0, %c-1 : index
    scf.index_switch %13 
    case 0 {
      %pipeline_layout = hal.pipeline_layout.lookup device(%device : !hal.device) layout(#pipeline_layout) : !hal.pipeline_layout
      hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%pipeline_layout : !hal.pipeline_layout) offset(0) values([%6, %8, %10, %12]) : i32, i32, i32, i32
      hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%pipeline_layout : !hal.pipeline_layout)[%c0] bindings([
        %c0 = (%buffer : !hal.buffer)[%c0, %3], 
        %c1 = (%transient_buffer : !hal.buffer)[%c0, %3]
      ])
      %14 = affine.apply #map()[%1, %0]
      hal.command_buffer.dispatch.symbol<%cmd : !hal.command_buffer> target(@main_dispatch_0::@cuda_nvptx_fb::@main_dispatch_0_matmul_DxDxD_f32) workgroups([%14, %c1, %c1])
      scf.yield
    }
    default {
    }
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_0 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status_1 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence_0) commands([%cmd])
    %status_2 = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status_2, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %3] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<()[s0, s1] -> ((s0 ceildiv 128) * (s1 ceildiv 32))>
#pipeline_layout = #hal.pipeline.layout<push_constants = 4, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer>]>]>
#translation = #iree_codegen.translation_info<LLVMGPUMatmulSimt>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  hal.executable private @main_dispatch_0 {
    hal.executable.variant public @cuda_nvptx_fb target(#executable_target_cuda_nvptx_fb) {
      hal.executable.export public @main_dispatch_0_matmul_DxDxD_f32 ordinal(0) layout(#pipeline_layout) attributes {translation_info = #translation, workgroup_size = [32 : index, 8 : index, 1 : index]} {
      ^bb0(%arg0: !hal.device, %arg1: index, %arg2: index):
        %c1 = arith.constant 1 : index
        %0 = affine.apply #map()[%arg2, %arg1]
        hal.return %0, %c1, %c1 : index, index, index
      }
      builtin.module {
        llvm.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias}, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32) {
          %0 = llvm.mlir.constant(63 : index) : i64
          %1 = llvm.mlir.constant(1 : i64) : i64
          %2 = llvm.mlir.constant(8 : index) : i64
          %3 = llvm.mlir.constant(-128 : index) : i64
          %4 = llvm.mlir.constant(-32 : index) : i64
          %5 = llvm.mlir.constant(-1 : index) : i64
          %6 = llvm.mlir.constant(128 : index) : i64
          %7 = llvm.mlir.constant(32 : index) : i64
          %8 = llvm.mlir.constant(0 : index) : i64
          %9 = llvm.mlir.constant(1 : index) : i64
          %10 = llvm.mlir.constant(32 : i64) : i64
          %11 = llvm.mlir.constant(0.000000e+00 : f32) : f32
          %12 = llvm.zext %arg2 : i32 to i64
          %13 = llvm.zext %arg3 : i32 to i64
          %14 = llvm.shl %13, %10  : i64
          %15 = llvm.or %12, %14  : i64
          %16 = llvm.zext %arg4 : i32 to i64
          %17 = llvm.zext %arg5 : i32 to i64
          %18 = llvm.shl %17, %10  : i64
          %19 = llvm.or %16, %18  : i64
          %20 = llvm.mul %19, %1  : i64
          %21 = llvm.ptrtoint %arg0 : !llvm.ptr<1> to i64
          %22 = llvm.and %21, %0  : i64
          %23 = llvm.icmp "eq" %22, %8 : i64
          "llvm.intr.assume"(%23) : (i1) -> ()
          %24 = llvm.ptrtoint %arg1 : !llvm.ptr<1> to i64
          %25 = llvm.and %24, %0  : i64
          %26 = llvm.icmp "eq" %25, %8 : i64
          "llvm.intr.assume"(%26) : (i1) -> ()
          %27 = nvvm.read.ptx.sreg.ctaid.x : i32
          %28 = llvm.sext %27 : i32 to i64
          %29 = llvm.icmp "sle" %19, %8 : i64
          %30 = llvm.sub %8, %19  : i64
          %31 = llvm.sub %19, %9  : i64
          %32 = llvm.select %29, %30, %31 : i1, i64
          %33 = llvm.sdiv %32, %6  : i64
          %34 = llvm.sub %8, %33  : i64
          %35 = llvm.add %33, %9  : i64
          %36 = llvm.select %29, %34, %35 : i1, i64
          %37 = llvm.icmp "slt" %28, %8 : i64
          %38 = llvm.sub %5, %28  : i64
          %39 = llvm.select %37, %38, %28 : i1, i64
          %40 = llvm.sdiv %39, %36  : i64
          %41 = llvm.sub %5, %40  : i64
          %42 = llvm.select %37, %41, %40 : i1, i64
          %43 = llvm.mul %42, %4  : i64
          %44 = llvm.add %15, %43  : i64
          %45 = llvm.icmp "sgt" %44, %7 : i64
          %46 = llvm.select %45, %7, %44 : i1, i64
          %47 = llvm.srem %28, %36  : i64
          %48 = llvm.icmp "slt" %47, %8 : i64
          %49 = llvm.add %47, %36  : i64
          %50 = llvm.select %48, %49, %47 : i1, i64
          %51 = llvm.mul %50, %3  : i64
          %52 = llvm.add %19, %51  : i64
          %53 = llvm.icmp "sgt" %52, %6 : i64
          %54 = llvm.select %53, %6, %52 : i1, i64
          %55 = nvvm.read.ptx.sreg.tid.x : i32
          %56 = llvm.sext %55 : i32 to i64
          %57 = nvvm.read.ptx.sreg.tid.y : i32
          %58 = llvm.sext %57 : i32 to i64
          %59 = llvm.icmp "sle" %46, %8 : i64
          %60 = llvm.sub %8, %46  : i64
          %61 = llvm.sub %46, %9  : i64
          %62 = llvm.select %59, %60, %61 : i1, i64
          %63 = llvm.sdiv %62, %2  : i64
          %64 = llvm.sub %8, %63  : i64
          %65 = llvm.add %63, %9  : i64
          %66 = llvm.select %59, %64, %65 : i1, i64
          %67 = llvm.mul %58, %66  : i64
          %68 = llvm.sub %46, %67  : i64
          %69 = llvm.icmp "slt" %68, %66 : i64
          %70 = llvm.select %69, %68, %66 : i1, i64
          %71 = llvm.icmp "slt" %70, %8 : i64
          %72 = llvm.select %71, %8, %70 : i1, i64
          %73 = llvm.icmp "sle" %54, %8 : i64
          %74 = llvm.sub %8, %54  : i64
          %75 = llvm.sub %54, %9  : i64
          %76 = llvm.select %73, %74, %75 : i1, i64
          %77 = llvm.sdiv %76, %7  : i64
          %78 = llvm.sub %8, %77  : i64
          %79 = llvm.add %77, %9  : i64
          %80 = llvm.select %73, %78, %79 : i1, i64
          %81 = llvm.mul %56, %80  : i64
          %82 = llvm.sub %54, %81  : i64
          %83 = llvm.icmp "slt" %82, %80 : i64
          %84 = llvm.select %83, %82, %80 : i1, i64
          %85 = llvm.icmp "slt" %84, %8 : i64
          %86 = llvm.select %85, %8, %84 : i1, i64
          %87 = llvm.mul %42, %7  : i64
          %88 = llvm.add %87, %67  : i64
          %89 = llvm.mul %50, %6  : i64
          %90 = llvm.add %89, %81  : i64
          llvm.br ^bb1(%8 : i64)
        ^bb1(%91: i64):  // 2 preds: ^bb0, ^bb5
          %92 = llvm.icmp "slt" %91, %72 : i64
          llvm.cond_br %92, ^bb2, ^bb6(%8 : i64)
        ^bb2:  // pred: ^bb1
          %93 = llvm.add %88, %91  : i64
          llvm.br ^bb3(%8 : i64)
        ^bb3(%94: i64):  // 2 preds: ^bb2, ^bb4
          %95 = llvm.icmp "slt" %94, %86 : i64
          llvm.cond_br %95, ^bb4, ^bb5
        ^bb4:  // pred: ^bb3
          %96 = llvm.add %90, %94  : i64
          %97 = llvm.mul %93, %20  : i64
          %98 = llvm.add %97, %96  : i64
          %99 = llvm.getelementptr %arg1[%98] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          llvm.store %11, %99 : f32, !llvm.ptr<1>
          %100 = llvm.add %94, %9  : i64
          llvm.br ^bb3(%100 : i64)
        ^bb5:  // pred: ^bb3
          %101 = llvm.add %91, %9  : i64
          llvm.br ^bb1(%101 : i64)
        ^bb6(%102: i64):  // 2 preds: ^bb1, ^bb12
          %103 = llvm.icmp "slt" %102, %19 : i64
          llvm.cond_br %103, ^bb7(%8 : i64), ^bb13
        ^bb7(%104: i64):  // 2 preds: ^bb6, ^bb11
          %105 = llvm.icmp "slt" %104, %72 : i64
          llvm.cond_br %105, ^bb8, ^bb12
        ^bb8:  // pred: ^bb7
          %106 = llvm.add %88, %104  : i64
          llvm.br ^bb9(%8 : i64)
        ^bb9(%107: i64):  // 2 preds: ^bb8, ^bb10
          %108 = llvm.icmp "slt" %107, %86 : i64
          llvm.cond_br %108, ^bb10, ^bb11
        ^bb10:  // pred: ^bb9
          %109 = llvm.mul %106, %20  : i64
          %110 = llvm.add %109, %102  : i64
          %111 = llvm.getelementptr %arg0[%110] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %112 = llvm.load %111 : !llvm.ptr<1> -> f32
          %113 = llvm.add %90, %107  : i64
          %114 = llvm.mul %102, %20  : i64
          %115 = llvm.add %114, %113  : i64
          %116 = llvm.getelementptr %arg0[%115] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %117 = llvm.load %116 : !llvm.ptr<1> -> f32
          %118 = llvm.add %109, %113  : i64
          %119 = llvm.getelementptr %arg1[%118] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %120 = llvm.load %119 : !llvm.ptr<1> -> f32
          %121 = llvm.fmul %112, %117  : f32
          %122 = llvm.fadd %120, %121  : f32
          llvm.store %122, %119 : f32, !llvm.ptr<1>
          %123 = llvm.add %107, %9  : i64
          llvm.br ^bb9(%123 : i64)
        ^bb11:  // pred: ^bb9
          %124 = llvm.add %104, %9  : i64
          llvm.br ^bb7(%124 : i64)
        ^bb12:  // pred: ^bb7
          %125 = llvm.add %102, %9  : i64
          llvm.br ^bb6(%125 : i64)
        ^bb13:  // pred: ^bb6
          llvm.return
        }
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c1 = arith.constant 1 : index
    %c-1 = arith.constant -1 : index
    %c-1_i32 = arith.constant -1 : i32
    %c0_i64 = arith.constant 0 : i64
    %c-1_i64 = arith.constant -1 : i64
    %c32_i64 = arith.constant 32 : i64
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %4 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%3}
    %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    %5 = arith.index_castui %0 : index to i64
    %6 = arith.trunci %5 : i64 to i32
    %7 = arith.shrui %5, %c32_i64 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %1 : index to i64
    %10 = arith.trunci %9 : i64 to i32
    %11 = arith.shrui %9, %c32_i64 : i64
    %12 = arith.trunci %11 : i64 to i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    %13 = arith.select %value, %c0, %c-1 : index
    scf.index_switch %13 
    case 0 {
      %pipeline_layout = hal.pipeline_layout.lookup device(%device : !hal.device) layout(#pipeline_layout) : !hal.pipeline_layout
      hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%pipeline_layout : !hal.pipeline_layout) offset(0) values([%6, %8, %10, %12]) : i32, i32, i32, i32
      hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%pipeline_layout : !hal.pipeline_layout)[%c0] bindings([
        %c0 = (%buffer : !hal.buffer)[%c0, %3], 
        %c1 = (%transient_buffer : !hal.buffer)[%c0, %3]
      ])
      %14 = affine.apply #map()[%1, %0]
      hal.command_buffer.dispatch.symbol<%cmd : !hal.command_buffer> target(@main_dispatch_0::@cuda_nvptx_fb::@main_dispatch_0_matmul_DxDxD_f32) workgroups([%14, %c1, %c1])
      scf.yield
    }
    default {
    }
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_0 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status_1 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence_0) commands([%cmd])
    %status_2 = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status_2, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %3] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<()[s0, s1] -> ((s0 ceildiv 128) * (s1 ceildiv 32))>
#pipeline_layout = #hal.pipeline.layout<push_constants = 4, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer>]>]>
#translation = #iree_codegen.translation_info<LLVMGPUMatmulSimt>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  hal.executable private @main_dispatch_0 {
    hal.executable.variant public @cuda_nvptx_fb target(#executable_target_cuda_nvptx_fb) {
      hal.executable.export public @main_dispatch_0_matmul_DxDxD_f32 ordinal(0) layout(#pipeline_layout) attributes {translation_info = #translation, workgroup_size = [32 : index, 8 : index, 1 : index]} {
      ^bb0(%arg0: !hal.device, %arg1: index, %arg2: index):
        %c1 = arith.constant 1 : index
        %0 = affine.apply #map()[%arg2, %arg1]
        hal.return %0, %c1, %c1 : index, index, index
      }
      builtin.module {
        llvm.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias}, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32) {
          %0 = llvm.mlir.constant(63 : index) : i64
          %1 = llvm.mlir.constant(1 : i64) : i64
          %2 = llvm.mlir.constant(8 : index) : i64
          %3 = llvm.mlir.constant(-128 : index) : i64
          %4 = llvm.mlir.constant(-32 : index) : i64
          %5 = llvm.mlir.constant(-1 : index) : i64
          %6 = llvm.mlir.constant(128 : index) : i64
          %7 = llvm.mlir.constant(32 : index) : i64
          %8 = llvm.mlir.constant(0 : index) : i64
          %9 = llvm.mlir.constant(1 : index) : i64
          %10 = llvm.mlir.constant(32 : i64) : i64
          %11 = llvm.mlir.constant(0.000000e+00 : f32) : f32
          %12 = llvm.zext %arg2 : i32 to i64
          %13 = llvm.zext %arg3 : i32 to i64
          %14 = llvm.shl %13, %10  : i64
          %15 = llvm.or %12, %14  : i64
          %16 = llvm.zext %arg4 : i32 to i64
          %17 = llvm.zext %arg5 : i32 to i64
          %18 = llvm.shl %17, %10  : i64
          %19 = llvm.or %16, %18  : i64
          %20 = llvm.mul %19, %1  : i64
          %21 = llvm.ptrtoint %arg0 : !llvm.ptr<1> to i64
          %22 = llvm.and %21, %0  : i64
          %23 = llvm.icmp "eq" %22, %8 : i64
          "llvm.intr.assume"(%23) : (i1) -> ()
          %24 = llvm.ptrtoint %arg1 : !llvm.ptr<1> to i64
          %25 = llvm.and %24, %0  : i64
          %26 = llvm.icmp "eq" %25, %8 : i64
          "llvm.intr.assume"(%26) : (i1) -> ()
          %27 = nvvm.read.ptx.sreg.ctaid.x : i32
          %28 = llvm.sext %27 : i32 to i64
          %29 = llvm.icmp "sle" %19, %8 : i64
          %30 = llvm.sub %8, %19  : i64
          %31 = llvm.sub %19, %9  : i64
          %32 = llvm.select %29, %30, %31 : i1, i64
          %33 = llvm.sdiv %32, %6  : i64
          %34 = llvm.sub %8, %33  : i64
          %35 = llvm.add %33, %9  : i64
          %36 = llvm.select %29, %34, %35 : i1, i64
          %37 = llvm.icmp "slt" %28, %8 : i64
          %38 = llvm.sub %5, %28  : i64
          %39 = llvm.select %37, %38, %28 : i1, i64
          %40 = llvm.sdiv %39, %36  : i64
          %41 = llvm.sub %5, %40  : i64
          %42 = llvm.select %37, %41, %40 : i1, i64
          %43 = llvm.mul %42, %4  : i64
          %44 = llvm.add %15, %43  : i64
          %45 = llvm.icmp "sgt" %44, %7 : i64
          %46 = llvm.select %45, %7, %44 : i1, i64
          %47 = llvm.srem %28, %36  : i64
          %48 = llvm.icmp "slt" %47, %8 : i64
          %49 = llvm.add %47, %36  : i64
          %50 = llvm.select %48, %49, %47 : i1, i64
          %51 = llvm.mul %50, %3  : i64
          %52 = llvm.add %19, %51  : i64
          %53 = llvm.icmp "sgt" %52, %6 : i64
          %54 = llvm.select %53, %6, %52 : i1, i64
          %55 = nvvm.read.ptx.sreg.tid.x : i32
          %56 = llvm.sext %55 : i32 to i64
          %57 = nvvm.read.ptx.sreg.tid.y : i32
          %58 = llvm.sext %57 : i32 to i64
          %59 = llvm.icmp "sle" %46, %8 : i64
          %60 = llvm.sub %8, %46  : i64
          %61 = llvm.sub %46, %9  : i64
          %62 = llvm.select %59, %60, %61 : i1, i64
          %63 = llvm.sdiv %62, %2  : i64
          %64 = llvm.sub %8, %63  : i64
          %65 = llvm.add %63, %9  : i64
          %66 = llvm.select %59, %64, %65 : i1, i64
          %67 = llvm.mul %58, %66  : i64
          %68 = llvm.sub %46, %67  : i64
          %69 = llvm.icmp "slt" %68, %66 : i64
          %70 = llvm.select %69, %68, %66 : i1, i64
          %71 = llvm.icmp "slt" %70, %8 : i64
          %72 = llvm.select %71, %8, %70 : i1, i64
          %73 = llvm.icmp "sle" %54, %8 : i64
          %74 = llvm.sub %8, %54  : i64
          %75 = llvm.sub %54, %9  : i64
          %76 = llvm.select %73, %74, %75 : i1, i64
          %77 = llvm.sdiv %76, %7  : i64
          %78 = llvm.sub %8, %77  : i64
          %79 = llvm.add %77, %9  : i64
          %80 = llvm.select %73, %78, %79 : i1, i64
          %81 = llvm.mul %56, %80  : i64
          %82 = llvm.sub %54, %81  : i64
          %83 = llvm.icmp "slt" %82, %80 : i64
          %84 = llvm.select %83, %82, %80 : i1, i64
          %85 = llvm.icmp "slt" %84, %8 : i64
          %86 = llvm.select %85, %8, %84 : i1, i64
          %87 = llvm.mul %42, %7  : i64
          %88 = llvm.add %87, %67  : i64
          %89 = llvm.mul %50, %6  : i64
          %90 = llvm.add %89, %81  : i64
          llvm.br ^bb1(%8 : i64)
        ^bb1(%91: i64):  // 2 preds: ^bb0, ^bb5
          %92 = llvm.icmp "slt" %91, %72 : i64
          llvm.cond_br %92, ^bb2, ^bb6(%8 : i64)
        ^bb2:  // pred: ^bb1
          %93 = llvm.add %88, %91  : i64
          llvm.br ^bb3(%8 : i64)
        ^bb3(%94: i64):  // 2 preds: ^bb2, ^bb4
          %95 = llvm.icmp "slt" %94, %86 : i64
          llvm.cond_br %95, ^bb4, ^bb5
        ^bb4:  // pred: ^bb3
          %96 = llvm.add %90, %94  : i64
          %97 = llvm.mul %93, %20  : i64
          %98 = llvm.add %97, %96  : i64
          %99 = llvm.getelementptr %arg1[%98] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          llvm.store %11, %99 : f32, !llvm.ptr<1>
          %100 = llvm.add %94, %9  : i64
          llvm.br ^bb3(%100 : i64)
        ^bb5:  // pred: ^bb3
          %101 = llvm.add %91, %9  : i64
          llvm.br ^bb1(%101 : i64)
        ^bb6(%102: i64):  // 2 preds: ^bb1, ^bb12
          %103 = llvm.icmp "slt" %102, %19 : i64
          llvm.cond_br %103, ^bb7(%8 : i64), ^bb13
        ^bb7(%104: i64):  // 2 preds: ^bb6, ^bb11
          %105 = llvm.icmp "slt" %104, %72 : i64
          llvm.cond_br %105, ^bb8, ^bb12
        ^bb8:  // pred: ^bb7
          %106 = llvm.add %88, %104  : i64
          llvm.br ^bb9(%8 : i64)
        ^bb9(%107: i64):  // 2 preds: ^bb8, ^bb10
          %108 = llvm.icmp "slt" %107, %86 : i64
          llvm.cond_br %108, ^bb10, ^bb11
        ^bb10:  // pred: ^bb9
          %109 = llvm.mul %106, %20  : i64
          %110 = llvm.add %109, %102  : i64
          %111 = llvm.getelementptr %arg0[%110] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %112 = llvm.load %111 : !llvm.ptr<1> -> f32
          %113 = llvm.add %90, %107  : i64
          %114 = llvm.mul %102, %20  : i64
          %115 = llvm.add %114, %113  : i64
          %116 = llvm.getelementptr %arg0[%115] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %117 = llvm.load %116 : !llvm.ptr<1> -> f32
          %118 = llvm.add %109, %113  : i64
          %119 = llvm.getelementptr %arg1[%118] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %120 = llvm.load %119 : !llvm.ptr<1> -> f32
          %121 = llvm.fmul %112, %117  : f32
          %122 = llvm.fadd %120, %121  : f32
          llvm.store %122, %119 : f32, !llvm.ptr<1>
          %123 = llvm.add %107, %9  : i64
          llvm.br ^bb9(%123 : i64)
        ^bb11:  // pred: ^bb9
          %124 = llvm.add %104, %9  : i64
          llvm.br ^bb7(%124 : i64)
        ^bb12:  // pred: ^bb7
          %125 = llvm.add %102, %9  : i64
          llvm.br ^bb6(%125 : i64)
        ^bb13:  // pred: ^bb6
          llvm.return
        }
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c1 = arith.constant 1 : index
    %c-1 = arith.constant -1 : index
    %c-1_i32 = arith.constant -1 : i32
    %c0_i64 = arith.constant 0 : i64
    %c-1_i64 = arith.constant -1 : i64
    %c32_i64 = arith.constant 32 : i64
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %4 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%3}
    %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    %5 = arith.index_castui %0 : index to i64
    %6 = arith.trunci %5 : i64 to i32
    %7 = arith.shrui %5, %c32_i64 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %1 : index to i64
    %10 = arith.trunci %9 : i64 to i32
    %11 = arith.shrui %9, %c32_i64 : i64
    %12 = arith.trunci %11 : i64 to i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    %13 = arith.select %value, %c0, %c-1 : index
    scf.index_switch %13 
    case 0 {
      %pipeline_layout = hal.pipeline_layout.lookup device(%device : !hal.device) layout(#pipeline_layout) : !hal.pipeline_layout
      hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%pipeline_layout : !hal.pipeline_layout) offset(0) values([%6, %8, %10, %12]) : i32, i32, i32, i32
      hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%pipeline_layout : !hal.pipeline_layout)[%c0] bindings([
        %c0 = (%buffer : !hal.buffer)[%c0, %3], 
        %c1 = (%transient_buffer : !hal.buffer)[%c0, %3]
      ])
      %14 = affine.apply #map()[%1, %0]
      hal.command_buffer.dispatch.symbol<%cmd : !hal.command_buffer> target(@main_dispatch_0::@cuda_nvptx_fb::@main_dispatch_0_matmul_DxDxD_f32) workgroups([%14, %c1, %c1])
      scf.yield
    }
    default {
    }
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_0 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status_1 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence_0) commands([%cmd])
    %status_2 = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status_2, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %3] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::HAL::LinkTargetExecutablesPass (iree-hal-link-target-executables) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<()[s0, s1] -> ((s0 ceildiv 128) * (s1 ceildiv 32))>
#pipeline_layout = #hal.pipeline.layout<push_constants = 4, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer>]>]>
#translation = #iree_codegen.translation_info<LLVMGPUMatmulSimt>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  hal.executable private @main_dispatch_0 {
    hal.executable.variant public @cuda_nvptx_fb target(#executable_target_cuda_nvptx_fb) {
      hal.executable.export public @main_dispatch_0_matmul_DxDxD_f32 ordinal(0) layout(#pipeline_layout) attributes {translation_info = #translation, workgroup_size = [32 : index, 8 : index, 1 : index]} {
      ^bb0(%arg0: !hal.device, %arg1: index, %arg2: index):
        %c1 = arith.constant 1 : index
        %0 = affine.apply #map()[%arg2, %arg1]
        hal.return %0, %c1, %c1 : index, index, index
      }
      builtin.module {
        llvm.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias}, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32) {
          %0 = llvm.mlir.constant(63 : index) : i64
          %1 = llvm.mlir.constant(1 : i64) : i64
          %2 = llvm.mlir.constant(8 : index) : i64
          %3 = llvm.mlir.constant(-128 : index) : i64
          %4 = llvm.mlir.constant(-32 : index) : i64
          %5 = llvm.mlir.constant(-1 : index) : i64
          %6 = llvm.mlir.constant(128 : index) : i64
          %7 = llvm.mlir.constant(32 : index) : i64
          %8 = llvm.mlir.constant(0 : index) : i64
          %9 = llvm.mlir.constant(1 : index) : i64
          %10 = llvm.mlir.constant(32 : i64) : i64
          %11 = llvm.mlir.constant(0.000000e+00 : f32) : f32
          %12 = llvm.zext %arg2 : i32 to i64
          %13 = llvm.zext %arg3 : i32 to i64
          %14 = llvm.shl %13, %10  : i64
          %15 = llvm.or %12, %14  : i64
          %16 = llvm.zext %arg4 : i32 to i64
          %17 = llvm.zext %arg5 : i32 to i64
          %18 = llvm.shl %17, %10  : i64
          %19 = llvm.or %16, %18  : i64
          %20 = llvm.mul %19, %1  : i64
          %21 = llvm.ptrtoint %arg0 : !llvm.ptr<1> to i64
          %22 = llvm.and %21, %0  : i64
          %23 = llvm.icmp "eq" %22, %8 : i64
          "llvm.intr.assume"(%23) : (i1) -> ()
          %24 = llvm.ptrtoint %arg1 : !llvm.ptr<1> to i64
          %25 = llvm.and %24, %0  : i64
          %26 = llvm.icmp "eq" %25, %8 : i64
          "llvm.intr.assume"(%26) : (i1) -> ()
          %27 = nvvm.read.ptx.sreg.ctaid.x : i32
          %28 = llvm.sext %27 : i32 to i64
          %29 = llvm.icmp "sle" %19, %8 : i64
          %30 = llvm.sub %8, %19  : i64
          %31 = llvm.sub %19, %9  : i64
          %32 = llvm.select %29, %30, %31 : i1, i64
          %33 = llvm.sdiv %32, %6  : i64
          %34 = llvm.sub %8, %33  : i64
          %35 = llvm.add %33, %9  : i64
          %36 = llvm.select %29, %34, %35 : i1, i64
          %37 = llvm.icmp "slt" %28, %8 : i64
          %38 = llvm.sub %5, %28  : i64
          %39 = llvm.select %37, %38, %28 : i1, i64
          %40 = llvm.sdiv %39, %36  : i64
          %41 = llvm.sub %5, %40  : i64
          %42 = llvm.select %37, %41, %40 : i1, i64
          %43 = llvm.mul %42, %4  : i64
          %44 = llvm.add %15, %43  : i64
          %45 = llvm.icmp "sgt" %44, %7 : i64
          %46 = llvm.select %45, %7, %44 : i1, i64
          %47 = llvm.srem %28, %36  : i64
          %48 = llvm.icmp "slt" %47, %8 : i64
          %49 = llvm.add %47, %36  : i64
          %50 = llvm.select %48, %49, %47 : i1, i64
          %51 = llvm.mul %50, %3  : i64
          %52 = llvm.add %19, %51  : i64
          %53 = llvm.icmp "sgt" %52, %6 : i64
          %54 = llvm.select %53, %6, %52 : i1, i64
          %55 = nvvm.read.ptx.sreg.tid.x : i32
          %56 = llvm.sext %55 : i32 to i64
          %57 = nvvm.read.ptx.sreg.tid.y : i32
          %58 = llvm.sext %57 : i32 to i64
          %59 = llvm.icmp "sle" %46, %8 : i64
          %60 = llvm.sub %8, %46  : i64
          %61 = llvm.sub %46, %9  : i64
          %62 = llvm.select %59, %60, %61 : i1, i64
          %63 = llvm.sdiv %62, %2  : i64
          %64 = llvm.sub %8, %63  : i64
          %65 = llvm.add %63, %9  : i64
          %66 = llvm.select %59, %64, %65 : i1, i64
          %67 = llvm.mul %58, %66  : i64
          %68 = llvm.sub %46, %67  : i64
          %69 = llvm.icmp "slt" %68, %66 : i64
          %70 = llvm.select %69, %68, %66 : i1, i64
          %71 = llvm.icmp "slt" %70, %8 : i64
          %72 = llvm.select %71, %8, %70 : i1, i64
          %73 = llvm.icmp "sle" %54, %8 : i64
          %74 = llvm.sub %8, %54  : i64
          %75 = llvm.sub %54, %9  : i64
          %76 = llvm.select %73, %74, %75 : i1, i64
          %77 = llvm.sdiv %76, %7  : i64
          %78 = llvm.sub %8, %77  : i64
          %79 = llvm.add %77, %9  : i64
          %80 = llvm.select %73, %78, %79 : i1, i64
          %81 = llvm.mul %56, %80  : i64
          %82 = llvm.sub %54, %81  : i64
          %83 = llvm.icmp "slt" %82, %80 : i64
          %84 = llvm.select %83, %82, %80 : i1, i64
          %85 = llvm.icmp "slt" %84, %8 : i64
          %86 = llvm.select %85, %8, %84 : i1, i64
          %87 = llvm.mul %42, %7  : i64
          %88 = llvm.add %87, %67  : i64
          %89 = llvm.mul %50, %6  : i64
          %90 = llvm.add %89, %81  : i64
          llvm.br ^bb1(%8 : i64)
        ^bb1(%91: i64):  // 2 preds: ^bb0, ^bb5
          %92 = llvm.icmp "slt" %91, %72 : i64
          llvm.cond_br %92, ^bb2, ^bb6(%8 : i64)
        ^bb2:  // pred: ^bb1
          %93 = llvm.add %88, %91  : i64
          llvm.br ^bb3(%8 : i64)
        ^bb3(%94: i64):  // 2 preds: ^bb2, ^bb4
          %95 = llvm.icmp "slt" %94, %86 : i64
          llvm.cond_br %95, ^bb4, ^bb5
        ^bb4:  // pred: ^bb3
          %96 = llvm.add %90, %94  : i64
          %97 = llvm.mul %93, %20  : i64
          %98 = llvm.add %97, %96  : i64
          %99 = llvm.getelementptr %arg1[%98] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          llvm.store %11, %99 : f32, !llvm.ptr<1>
          %100 = llvm.add %94, %9  : i64
          llvm.br ^bb3(%100 : i64)
        ^bb5:  // pred: ^bb3
          %101 = llvm.add %91, %9  : i64
          llvm.br ^bb1(%101 : i64)
        ^bb6(%102: i64):  // 2 preds: ^bb1, ^bb12
          %103 = llvm.icmp "slt" %102, %19 : i64
          llvm.cond_br %103, ^bb7(%8 : i64), ^bb13
        ^bb7(%104: i64):  // 2 preds: ^bb6, ^bb11
          %105 = llvm.icmp "slt" %104, %72 : i64
          llvm.cond_br %105, ^bb8, ^bb12
        ^bb8:  // pred: ^bb7
          %106 = llvm.add %88, %104  : i64
          llvm.br ^bb9(%8 : i64)
        ^bb9(%107: i64):  // 2 preds: ^bb8, ^bb10
          %108 = llvm.icmp "slt" %107, %86 : i64
          llvm.cond_br %108, ^bb10, ^bb11
        ^bb10:  // pred: ^bb9
          %109 = llvm.mul %106, %20  : i64
          %110 = llvm.add %109, %102  : i64
          %111 = llvm.getelementptr %arg0[%110] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %112 = llvm.load %111 : !llvm.ptr<1> -> f32
          %113 = llvm.add %90, %107  : i64
          %114 = llvm.mul %102, %20  : i64
          %115 = llvm.add %114, %113  : i64
          %116 = llvm.getelementptr %arg0[%115] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %117 = llvm.load %116 : !llvm.ptr<1> -> f32
          %118 = llvm.add %109, %113  : i64
          %119 = llvm.getelementptr %arg1[%118] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %120 = llvm.load %119 : !llvm.ptr<1> -> f32
          %121 = llvm.fmul %112, %117  : f32
          %122 = llvm.fadd %120, %121  : f32
          llvm.store %122, %119 : f32, !llvm.ptr<1>
          %123 = llvm.add %107, %9  : i64
          llvm.br ^bb9(%123 : i64)
        ^bb11:  // pred: ^bb9
          %124 = llvm.add %104, %9  : i64
          llvm.br ^bb7(%124 : i64)
        ^bb12:  // pred: ^bb7
          %125 = llvm.add %102, %9  : i64
          llvm.br ^bb6(%125 : i64)
        ^bb13:  // pred: ^bb6
          llvm.return
        }
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c1 = arith.constant 1 : index
    %c-1 = arith.constant -1 : index
    %c-1_i32 = arith.constant -1 : i32
    %c0_i64 = arith.constant 0 : i64
    %c-1_i64 = arith.constant -1 : i64
    %c32_i64 = arith.constant 32 : i64
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %4 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%3}
    %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    %5 = arith.index_castui %0 : index to i64
    %6 = arith.trunci %5 : i64 to i32
    %7 = arith.shrui %5, %c32_i64 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %1 : index to i64
    %10 = arith.trunci %9 : i64 to i32
    %11 = arith.shrui %9, %c32_i64 : i64
    %12 = arith.trunci %11 : i64 to i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    %13 = arith.select %value, %c0, %c-1 : index
    scf.index_switch %13 
    case 0 {
      %pipeline_layout = hal.pipeline_layout.lookup device(%device : !hal.device) layout(#pipeline_layout) : !hal.pipeline_layout
      hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%pipeline_layout : !hal.pipeline_layout) offset(0) values([%6, %8, %10, %12]) : i32, i32, i32, i32
      hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%pipeline_layout : !hal.pipeline_layout)[%c0] bindings([
        %c0 = (%buffer : !hal.buffer)[%c0, %3], 
        %c1 = (%transient_buffer : !hal.buffer)[%c0, %3]
      ])
      %14 = affine.apply #map()[%1, %0]
      hal.command_buffer.dispatch.symbol<%cmd : !hal.command_buffer> target(@main_dispatch_0::@cuda_nvptx_fb::@main_dispatch_0_matmul_DxDxD_f32) workgroups([%14, %c1, %c1])
      scf.yield
    }
    default {
    }
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_0 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status_1 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence_0) commands([%cmd])
    %status_2 = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status_2, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %3] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After SymbolDCE (symbol-dce) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<()[s0, s1] -> ((s0 ceildiv 128) * (s1 ceildiv 32))>
#pipeline_layout = #hal.pipeline.layout<push_constants = 4, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer>]>]>
#translation = #iree_codegen.translation_info<LLVMGPUMatmulSimt>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  hal.executable private @main_dispatch_0 {
    hal.executable.variant public @cuda_nvptx_fb target(#executable_target_cuda_nvptx_fb) {
      hal.executable.export public @main_dispatch_0_matmul_DxDxD_f32 ordinal(0) layout(#pipeline_layout) attributes {translation_info = #translation, workgroup_size = [32 : index, 8 : index, 1 : index]} {
      ^bb0(%arg0: !hal.device, %arg1: index, %arg2: index):
        %c1 = arith.constant 1 : index
        %0 = affine.apply #map()[%arg2, %arg1]
        hal.return %0, %c1, %c1 : index, index, index
      }
      builtin.module {
        llvm.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias}, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32) {
          %0 = llvm.mlir.constant(63 : index) : i64
          %1 = llvm.mlir.constant(1 : i64) : i64
          %2 = llvm.mlir.constant(8 : index) : i64
          %3 = llvm.mlir.constant(-128 : index) : i64
          %4 = llvm.mlir.constant(-32 : index) : i64
          %5 = llvm.mlir.constant(-1 : index) : i64
          %6 = llvm.mlir.constant(128 : index) : i64
          %7 = llvm.mlir.constant(32 : index) : i64
          %8 = llvm.mlir.constant(0 : index) : i64
          %9 = llvm.mlir.constant(1 : index) : i64
          %10 = llvm.mlir.constant(32 : i64) : i64
          %11 = llvm.mlir.constant(0.000000e+00 : f32) : f32
          %12 = llvm.zext %arg2 : i32 to i64
          %13 = llvm.zext %arg3 : i32 to i64
          %14 = llvm.shl %13, %10  : i64
          %15 = llvm.or %12, %14  : i64
          %16 = llvm.zext %arg4 : i32 to i64
          %17 = llvm.zext %arg5 : i32 to i64
          %18 = llvm.shl %17, %10  : i64
          %19 = llvm.or %16, %18  : i64
          %20 = llvm.mul %19, %1  : i64
          %21 = llvm.ptrtoint %arg0 : !llvm.ptr<1> to i64
          %22 = llvm.and %21, %0  : i64
          %23 = llvm.icmp "eq" %22, %8 : i64
          "llvm.intr.assume"(%23) : (i1) -> ()
          %24 = llvm.ptrtoint %arg1 : !llvm.ptr<1> to i64
          %25 = llvm.and %24, %0  : i64
          %26 = llvm.icmp "eq" %25, %8 : i64
          "llvm.intr.assume"(%26) : (i1) -> ()
          %27 = nvvm.read.ptx.sreg.ctaid.x : i32
          %28 = llvm.sext %27 : i32 to i64
          %29 = llvm.icmp "sle" %19, %8 : i64
          %30 = llvm.sub %8, %19  : i64
          %31 = llvm.sub %19, %9  : i64
          %32 = llvm.select %29, %30, %31 : i1, i64
          %33 = llvm.sdiv %32, %6  : i64
          %34 = llvm.sub %8, %33  : i64
          %35 = llvm.add %33, %9  : i64
          %36 = llvm.select %29, %34, %35 : i1, i64
          %37 = llvm.icmp "slt" %28, %8 : i64
          %38 = llvm.sub %5, %28  : i64
          %39 = llvm.select %37, %38, %28 : i1, i64
          %40 = llvm.sdiv %39, %36  : i64
          %41 = llvm.sub %5, %40  : i64
          %42 = llvm.select %37, %41, %40 : i1, i64
          %43 = llvm.mul %42, %4  : i64
          %44 = llvm.add %15, %43  : i64
          %45 = llvm.icmp "sgt" %44, %7 : i64
          %46 = llvm.select %45, %7, %44 : i1, i64
          %47 = llvm.srem %28, %36  : i64
          %48 = llvm.icmp "slt" %47, %8 : i64
          %49 = llvm.add %47, %36  : i64
          %50 = llvm.select %48, %49, %47 : i1, i64
          %51 = llvm.mul %50, %3  : i64
          %52 = llvm.add %19, %51  : i64
          %53 = llvm.icmp "sgt" %52, %6 : i64
          %54 = llvm.select %53, %6, %52 : i1, i64
          %55 = nvvm.read.ptx.sreg.tid.x : i32
          %56 = llvm.sext %55 : i32 to i64
          %57 = nvvm.read.ptx.sreg.tid.y : i32
          %58 = llvm.sext %57 : i32 to i64
          %59 = llvm.icmp "sle" %46, %8 : i64
          %60 = llvm.sub %8, %46  : i64
          %61 = llvm.sub %46, %9  : i64
          %62 = llvm.select %59, %60, %61 : i1, i64
          %63 = llvm.sdiv %62, %2  : i64
          %64 = llvm.sub %8, %63  : i64
          %65 = llvm.add %63, %9  : i64
          %66 = llvm.select %59, %64, %65 : i1, i64
          %67 = llvm.mul %58, %66  : i64
          %68 = llvm.sub %46, %67  : i64
          %69 = llvm.icmp "slt" %68, %66 : i64
          %70 = llvm.select %69, %68, %66 : i1, i64
          %71 = llvm.icmp "slt" %70, %8 : i64
          %72 = llvm.select %71, %8, %70 : i1, i64
          %73 = llvm.icmp "sle" %54, %8 : i64
          %74 = llvm.sub %8, %54  : i64
          %75 = llvm.sub %54, %9  : i64
          %76 = llvm.select %73, %74, %75 : i1, i64
          %77 = llvm.sdiv %76, %7  : i64
          %78 = llvm.sub %8, %77  : i64
          %79 = llvm.add %77, %9  : i64
          %80 = llvm.select %73, %78, %79 : i1, i64
          %81 = llvm.mul %56, %80  : i64
          %82 = llvm.sub %54, %81  : i64
          %83 = llvm.icmp "slt" %82, %80 : i64
          %84 = llvm.select %83, %82, %80 : i1, i64
          %85 = llvm.icmp "slt" %84, %8 : i64
          %86 = llvm.select %85, %8, %84 : i1, i64
          %87 = llvm.mul %42, %7  : i64
          %88 = llvm.add %87, %67  : i64
          %89 = llvm.mul %50, %6  : i64
          %90 = llvm.add %89, %81  : i64
          llvm.br ^bb1(%8 : i64)
        ^bb1(%91: i64):  // 2 preds: ^bb0, ^bb5
          %92 = llvm.icmp "slt" %91, %72 : i64
          llvm.cond_br %92, ^bb2, ^bb6(%8 : i64)
        ^bb2:  // pred: ^bb1
          %93 = llvm.add %88, %91  : i64
          llvm.br ^bb3(%8 : i64)
        ^bb3(%94: i64):  // 2 preds: ^bb2, ^bb4
          %95 = llvm.icmp "slt" %94, %86 : i64
          llvm.cond_br %95, ^bb4, ^bb5
        ^bb4:  // pred: ^bb3
          %96 = llvm.add %90, %94  : i64
          %97 = llvm.mul %93, %20  : i64
          %98 = llvm.add %97, %96  : i64
          %99 = llvm.getelementptr %arg1[%98] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          llvm.store %11, %99 : f32, !llvm.ptr<1>
          %100 = llvm.add %94, %9  : i64
          llvm.br ^bb3(%100 : i64)
        ^bb5:  // pred: ^bb3
          %101 = llvm.add %91, %9  : i64
          llvm.br ^bb1(%101 : i64)
        ^bb6(%102: i64):  // 2 preds: ^bb1, ^bb12
          %103 = llvm.icmp "slt" %102, %19 : i64
          llvm.cond_br %103, ^bb7(%8 : i64), ^bb13
        ^bb7(%104: i64):  // 2 preds: ^bb6, ^bb11
          %105 = llvm.icmp "slt" %104, %72 : i64
          llvm.cond_br %105, ^bb8, ^bb12
        ^bb8:  // pred: ^bb7
          %106 = llvm.add %88, %104  : i64
          llvm.br ^bb9(%8 : i64)
        ^bb9(%107: i64):  // 2 preds: ^bb8, ^bb10
          %108 = llvm.icmp "slt" %107, %86 : i64
          llvm.cond_br %108, ^bb10, ^bb11
        ^bb10:  // pred: ^bb9
          %109 = llvm.mul %106, %20  : i64
          %110 = llvm.add %109, %102  : i64
          %111 = llvm.getelementptr %arg0[%110] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %112 = llvm.load %111 : !llvm.ptr<1> -> f32
          %113 = llvm.add %90, %107  : i64
          %114 = llvm.mul %102, %20  : i64
          %115 = llvm.add %114, %113  : i64
          %116 = llvm.getelementptr %arg0[%115] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %117 = llvm.load %116 : !llvm.ptr<1> -> f32
          %118 = llvm.add %109, %113  : i64
          %119 = llvm.getelementptr %arg1[%118] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %120 = llvm.load %119 : !llvm.ptr<1> -> f32
          %121 = llvm.fmul %112, %117  : f32
          %122 = llvm.fadd %120, %121  : f32
          llvm.store %122, %119 : f32, !llvm.ptr<1>
          %123 = llvm.add %107, %9  : i64
          llvm.br ^bb9(%123 : i64)
        ^bb11:  // pred: ^bb9
          %124 = llvm.add %104, %9  : i64
          llvm.br ^bb7(%124 : i64)
        ^bb12:  // pred: ^bb7
          %125 = llvm.add %102, %9  : i64
          llvm.br ^bb6(%125 : i64)
        ^bb13:  // pred: ^bb6
          llvm.return
        }
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c1 = arith.constant 1 : index
    %c-1 = arith.constant -1 : index
    %c-1_i32 = arith.constant -1 : i32
    %c0_i64 = arith.constant 0 : i64
    %c-1_i64 = arith.constant -1 : i64
    %c32_i64 = arith.constant 32 : i64
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %4 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%3}
    %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    %5 = arith.index_castui %0 : index to i64
    %6 = arith.trunci %5 : i64 to i32
    %7 = arith.shrui %5, %c32_i64 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %1 : index to i64
    %10 = arith.trunci %9 : i64 to i32
    %11 = arith.shrui %9, %c32_i64 : i64
    %12 = arith.trunci %11 : i64 to i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    %13 = arith.select %value, %c0, %c-1 : index
    scf.index_switch %13 
    case 0 {
      %pipeline_layout = hal.pipeline_layout.lookup device(%device : !hal.device) layout(#pipeline_layout) : !hal.pipeline_layout
      hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%pipeline_layout : !hal.pipeline_layout) offset(0) values([%6, %8, %10, %12]) : i32, i32, i32, i32
      hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%pipeline_layout : !hal.pipeline_layout)[%c0] bindings([
        %c0 = (%buffer : !hal.buffer)[%c0, %3], 
        %c1 = (%transient_buffer : !hal.buffer)[%c0, %3]
      ])
      %14 = affine.apply #map()[%1, %0]
      hal.command_buffer.dispatch.symbol<%cmd : !hal.command_buffer> target(@main_dispatch_0::@cuda_nvptx_fb::@main_dispatch_0_matmul_DxDxD_f32) workgroups([%14, %c1, %c1])
      scf.yield
    }
    default {
    }
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_0 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status_1 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence_0) commands([%cmd])
    %status_2 = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status_2, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %3] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::HAL::LinkExecutablesPass (iree-hal-link-executables) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<()[s0, s1] -> ((s0 ceildiv 128) * (s1 ceildiv 32))>
#pipeline_layout = #hal.pipeline.layout<push_constants = 4, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer>]>]>
#translation = #iree_codegen.translation_info<LLVMGPUMatmulSimt>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  hal.executable private @main_dispatch_0 {
    hal.executable.variant public @cuda_nvptx_fb target(#executable_target_cuda_nvptx_fb) {
      hal.executable.export public @main_dispatch_0_matmul_DxDxD_f32 ordinal(0) layout(#pipeline_layout) attributes {translation_info = #translation, workgroup_size = [32 : index, 8 : index, 1 : index]} {
      ^bb0(%arg0: !hal.device, %arg1: index, %arg2: index):
        %c1 = arith.constant 1 : index
        %0 = affine.apply #map()[%arg2, %arg1]
        hal.return %0, %c1, %c1 : index, index, index
      }
      builtin.module {
        llvm.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias}, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32) {
          %0 = llvm.mlir.constant(63 : index) : i64
          %1 = llvm.mlir.constant(1 : i64) : i64
          %2 = llvm.mlir.constant(8 : index) : i64
          %3 = llvm.mlir.constant(-128 : index) : i64
          %4 = llvm.mlir.constant(-32 : index) : i64
          %5 = llvm.mlir.constant(-1 : index) : i64
          %6 = llvm.mlir.constant(128 : index) : i64
          %7 = llvm.mlir.constant(32 : index) : i64
          %8 = llvm.mlir.constant(0 : index) : i64
          %9 = llvm.mlir.constant(1 : index) : i64
          %10 = llvm.mlir.constant(32 : i64) : i64
          %11 = llvm.mlir.constant(0.000000e+00 : f32) : f32
          %12 = llvm.zext %arg2 : i32 to i64
          %13 = llvm.zext %arg3 : i32 to i64
          %14 = llvm.shl %13, %10  : i64
          %15 = llvm.or %12, %14  : i64
          %16 = llvm.zext %arg4 : i32 to i64
          %17 = llvm.zext %arg5 : i32 to i64
          %18 = llvm.shl %17, %10  : i64
          %19 = llvm.or %16, %18  : i64
          %20 = llvm.mul %19, %1  : i64
          %21 = llvm.ptrtoint %arg0 : !llvm.ptr<1> to i64
          %22 = llvm.and %21, %0  : i64
          %23 = llvm.icmp "eq" %22, %8 : i64
          "llvm.intr.assume"(%23) : (i1) -> ()
          %24 = llvm.ptrtoint %arg1 : !llvm.ptr<1> to i64
          %25 = llvm.and %24, %0  : i64
          %26 = llvm.icmp "eq" %25, %8 : i64
          "llvm.intr.assume"(%26) : (i1) -> ()
          %27 = nvvm.read.ptx.sreg.ctaid.x : i32
          %28 = llvm.sext %27 : i32 to i64
          %29 = llvm.icmp "sle" %19, %8 : i64
          %30 = llvm.sub %8, %19  : i64
          %31 = llvm.sub %19, %9  : i64
          %32 = llvm.select %29, %30, %31 : i1, i64
          %33 = llvm.sdiv %32, %6  : i64
          %34 = llvm.sub %8, %33  : i64
          %35 = llvm.add %33, %9  : i64
          %36 = llvm.select %29, %34, %35 : i1, i64
          %37 = llvm.icmp "slt" %28, %8 : i64
          %38 = llvm.sub %5, %28  : i64
          %39 = llvm.select %37, %38, %28 : i1, i64
          %40 = llvm.sdiv %39, %36  : i64
          %41 = llvm.sub %5, %40  : i64
          %42 = llvm.select %37, %41, %40 : i1, i64
          %43 = llvm.mul %42, %4  : i64
          %44 = llvm.add %15, %43  : i64
          %45 = llvm.icmp "sgt" %44, %7 : i64
          %46 = llvm.select %45, %7, %44 : i1, i64
          %47 = llvm.srem %28, %36  : i64
          %48 = llvm.icmp "slt" %47, %8 : i64
          %49 = llvm.add %47, %36  : i64
          %50 = llvm.select %48, %49, %47 : i1, i64
          %51 = llvm.mul %50, %3  : i64
          %52 = llvm.add %19, %51  : i64
          %53 = llvm.icmp "sgt" %52, %6 : i64
          %54 = llvm.select %53, %6, %52 : i1, i64
          %55 = nvvm.read.ptx.sreg.tid.x : i32
          %56 = llvm.sext %55 : i32 to i64
          %57 = nvvm.read.ptx.sreg.tid.y : i32
          %58 = llvm.sext %57 : i32 to i64
          %59 = llvm.icmp "sle" %46, %8 : i64
          %60 = llvm.sub %8, %46  : i64
          %61 = llvm.sub %46, %9  : i64
          %62 = llvm.select %59, %60, %61 : i1, i64
          %63 = llvm.sdiv %62, %2  : i64
          %64 = llvm.sub %8, %63  : i64
          %65 = llvm.add %63, %9  : i64
          %66 = llvm.select %59, %64, %65 : i1, i64
          %67 = llvm.mul %58, %66  : i64
          %68 = llvm.sub %46, %67  : i64
          %69 = llvm.icmp "slt" %68, %66 : i64
          %70 = llvm.select %69, %68, %66 : i1, i64
          %71 = llvm.icmp "slt" %70, %8 : i64
          %72 = llvm.select %71, %8, %70 : i1, i64
          %73 = llvm.icmp "sle" %54, %8 : i64
          %74 = llvm.sub %8, %54  : i64
          %75 = llvm.sub %54, %9  : i64
          %76 = llvm.select %73, %74, %75 : i1, i64
          %77 = llvm.sdiv %76, %7  : i64
          %78 = llvm.sub %8, %77  : i64
          %79 = llvm.add %77, %9  : i64
          %80 = llvm.select %73, %78, %79 : i1, i64
          %81 = llvm.mul %56, %80  : i64
          %82 = llvm.sub %54, %81  : i64
          %83 = llvm.icmp "slt" %82, %80 : i64
          %84 = llvm.select %83, %82, %80 : i1, i64
          %85 = llvm.icmp "slt" %84, %8 : i64
          %86 = llvm.select %85, %8, %84 : i1, i64
          %87 = llvm.mul %42, %7  : i64
          %88 = llvm.add %87, %67  : i64
          %89 = llvm.mul %50, %6  : i64
          %90 = llvm.add %89, %81  : i64
          llvm.br ^bb1(%8 : i64)
        ^bb1(%91: i64):  // 2 preds: ^bb0, ^bb5
          %92 = llvm.icmp "slt" %91, %72 : i64
          llvm.cond_br %92, ^bb2, ^bb6(%8 : i64)
        ^bb2:  // pred: ^bb1
          %93 = llvm.add %88, %91  : i64
          llvm.br ^bb3(%8 : i64)
        ^bb3(%94: i64):  // 2 preds: ^bb2, ^bb4
          %95 = llvm.icmp "slt" %94, %86 : i64
          llvm.cond_br %95, ^bb4, ^bb5
        ^bb4:  // pred: ^bb3
          %96 = llvm.add %90, %94  : i64
          %97 = llvm.mul %93, %20  : i64
          %98 = llvm.add %97, %96  : i64
          %99 = llvm.getelementptr %arg1[%98] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          llvm.store %11, %99 : f32, !llvm.ptr<1>
          %100 = llvm.add %94, %9  : i64
          llvm.br ^bb3(%100 : i64)
        ^bb5:  // pred: ^bb3
          %101 = llvm.add %91, %9  : i64
          llvm.br ^bb1(%101 : i64)
        ^bb6(%102: i64):  // 2 preds: ^bb1, ^bb12
          %103 = llvm.icmp "slt" %102, %19 : i64
          llvm.cond_br %103, ^bb7(%8 : i64), ^bb13
        ^bb7(%104: i64):  // 2 preds: ^bb6, ^bb11
          %105 = llvm.icmp "slt" %104, %72 : i64
          llvm.cond_br %105, ^bb8, ^bb12
        ^bb8:  // pred: ^bb7
          %106 = llvm.add %88, %104  : i64
          llvm.br ^bb9(%8 : i64)
        ^bb9(%107: i64):  // 2 preds: ^bb8, ^bb10
          %108 = llvm.icmp "slt" %107, %86 : i64
          llvm.cond_br %108, ^bb10, ^bb11
        ^bb10:  // pred: ^bb9
          %109 = llvm.mul %106, %20  : i64
          %110 = llvm.add %109, %102  : i64
          %111 = llvm.getelementptr %arg0[%110] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %112 = llvm.load %111 : !llvm.ptr<1> -> f32
          %113 = llvm.add %90, %107  : i64
          %114 = llvm.mul %102, %20  : i64
          %115 = llvm.add %114, %113  : i64
          %116 = llvm.getelementptr %arg0[%115] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %117 = llvm.load %116 : !llvm.ptr<1> -> f32
          %118 = llvm.add %109, %113  : i64
          %119 = llvm.getelementptr %arg1[%118] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %120 = llvm.load %119 : !llvm.ptr<1> -> f32
          %121 = llvm.fmul %112, %117  : f32
          %122 = llvm.fadd %120, %121  : f32
          llvm.store %122, %119 : f32, !llvm.ptr<1>
          %123 = llvm.add %107, %9  : i64
          llvm.br ^bb9(%123 : i64)
        ^bb11:  // pred: ^bb9
          %124 = llvm.add %104, %9  : i64
          llvm.br ^bb7(%124 : i64)
        ^bb12:  // pred: ^bb7
          %125 = llvm.add %102, %9  : i64
          llvm.br ^bb6(%125 : i64)
        ^bb13:  // pred: ^bb6
          llvm.return
        }
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c1 = arith.constant 1 : index
    %c-1 = arith.constant -1 : index
    %c-1_i32 = arith.constant -1 : i32
    %c0_i64 = arith.constant 0 : i64
    %c-1_i64 = arith.constant -1 : i64
    %c32_i64 = arith.constant 32 : i64
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %4 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%3}
    %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    %5 = arith.index_castui %0 : index to i64
    %6 = arith.trunci %5 : i64 to i32
    %7 = arith.shrui %5, %c32_i64 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %1 : index to i64
    %10 = arith.trunci %9 : i64 to i32
    %11 = arith.shrui %9, %c32_i64 : i64
    %12 = arith.trunci %11 : i64 to i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    %13 = arith.select %value, %c0, %c-1 : index
    scf.index_switch %13 
    case 0 {
      %pipeline_layout = hal.pipeline_layout.lookup device(%device : !hal.device) layout(#pipeline_layout) : !hal.pipeline_layout
      hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%pipeline_layout : !hal.pipeline_layout) offset(0) values([%6, %8, %10, %12]) : i32, i32, i32, i32
      hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%pipeline_layout : !hal.pipeline_layout)[%c0] bindings([
        %c0 = (%buffer : !hal.buffer)[%c0, %3], 
        %c1 = (%transient_buffer : !hal.buffer)[%c0, %3]
      ])
      %14 = affine.apply #map()[%1, %0]
      hal.command_buffer.dispatch.symbol<%cmd : !hal.command_buffer> target(@main_dispatch_0::@cuda_nvptx_fb::@main_dispatch_0_matmul_DxDxD_f32) workgroups([%14, %c1, %c1])
      scf.yield
    }
    default {
    }
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_0 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status_1 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence_0) commands([%cmd])
    %status_2 = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status_2, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %3] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::HAL::ResolveExportOrdinalsPass (iree-hal-resolve-export-ordinals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<()[s0, s1] -> ((s0 ceildiv 128) * (s1 ceildiv 32))>
#pipeline_layout = #hal.pipeline.layout<push_constants = 4, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer>]>]>
#translation = #iree_codegen.translation_info<LLVMGPUMatmulSimt>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  hal.executable private @main_dispatch_0 {
    hal.executable.variant public @cuda_nvptx_fb target(#executable_target_cuda_nvptx_fb) {
      hal.executable.export public @main_dispatch_0_matmul_DxDxD_f32 ordinal(0) layout(#pipeline_layout) attributes {translation_info = #translation, workgroup_size = [32 : index, 8 : index, 1 : index]} {
      ^bb0(%arg0: !hal.device, %arg1: index, %arg2: index):
        %c1 = arith.constant 1 : index
        %0 = affine.apply #map()[%arg2, %arg1]
        hal.return %0, %c1, %c1 : index, index, index
      }
      builtin.module {
        llvm.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias}, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32) {
          %0 = llvm.mlir.constant(63 : index) : i64
          %1 = llvm.mlir.constant(1 : i64) : i64
          %2 = llvm.mlir.constant(8 : index) : i64
          %3 = llvm.mlir.constant(-128 : index) : i64
          %4 = llvm.mlir.constant(-32 : index) : i64
          %5 = llvm.mlir.constant(-1 : index) : i64
          %6 = llvm.mlir.constant(128 : index) : i64
          %7 = llvm.mlir.constant(32 : index) : i64
          %8 = llvm.mlir.constant(0 : index) : i64
          %9 = llvm.mlir.constant(1 : index) : i64
          %10 = llvm.mlir.constant(32 : i64) : i64
          %11 = llvm.mlir.constant(0.000000e+00 : f32) : f32
          %12 = llvm.zext %arg2 : i32 to i64
          %13 = llvm.zext %arg3 : i32 to i64
          %14 = llvm.shl %13, %10  : i64
          %15 = llvm.or %12, %14  : i64
          %16 = llvm.zext %arg4 : i32 to i64
          %17 = llvm.zext %arg5 : i32 to i64
          %18 = llvm.shl %17, %10  : i64
          %19 = llvm.or %16, %18  : i64
          %20 = llvm.mul %19, %1  : i64
          %21 = llvm.ptrtoint %arg0 : !llvm.ptr<1> to i64
          %22 = llvm.and %21, %0  : i64
          %23 = llvm.icmp "eq" %22, %8 : i64
          "llvm.intr.assume"(%23) : (i1) -> ()
          %24 = llvm.ptrtoint %arg1 : !llvm.ptr<1> to i64
          %25 = llvm.and %24, %0  : i64
          %26 = llvm.icmp "eq" %25, %8 : i64
          "llvm.intr.assume"(%26) : (i1) -> ()
          %27 = nvvm.read.ptx.sreg.ctaid.x : i32
          %28 = llvm.sext %27 : i32 to i64
          %29 = llvm.icmp "sle" %19, %8 : i64
          %30 = llvm.sub %8, %19  : i64
          %31 = llvm.sub %19, %9  : i64
          %32 = llvm.select %29, %30, %31 : i1, i64
          %33 = llvm.sdiv %32, %6  : i64
          %34 = llvm.sub %8, %33  : i64
          %35 = llvm.add %33, %9  : i64
          %36 = llvm.select %29, %34, %35 : i1, i64
          %37 = llvm.icmp "slt" %28, %8 : i64
          %38 = llvm.sub %5, %28  : i64
          %39 = llvm.select %37, %38, %28 : i1, i64
          %40 = llvm.sdiv %39, %36  : i64
          %41 = llvm.sub %5, %40  : i64
          %42 = llvm.select %37, %41, %40 : i1, i64
          %43 = llvm.mul %42, %4  : i64
          %44 = llvm.add %15, %43  : i64
          %45 = llvm.icmp "sgt" %44, %7 : i64
          %46 = llvm.select %45, %7, %44 : i1, i64
          %47 = llvm.srem %28, %36  : i64
          %48 = llvm.icmp "slt" %47, %8 : i64
          %49 = llvm.add %47, %36  : i64
          %50 = llvm.select %48, %49, %47 : i1, i64
          %51 = llvm.mul %50, %3  : i64
          %52 = llvm.add %19, %51  : i64
          %53 = llvm.icmp "sgt" %52, %6 : i64
          %54 = llvm.select %53, %6, %52 : i1, i64
          %55 = nvvm.read.ptx.sreg.tid.x : i32
          %56 = llvm.sext %55 : i32 to i64
          %57 = nvvm.read.ptx.sreg.tid.y : i32
          %58 = llvm.sext %57 : i32 to i64
          %59 = llvm.icmp "sle" %46, %8 : i64
          %60 = llvm.sub %8, %46  : i64
          %61 = llvm.sub %46, %9  : i64
          %62 = llvm.select %59, %60, %61 : i1, i64
          %63 = llvm.sdiv %62, %2  : i64
          %64 = llvm.sub %8, %63  : i64
          %65 = llvm.add %63, %9  : i64
          %66 = llvm.select %59, %64, %65 : i1, i64
          %67 = llvm.mul %58, %66  : i64
          %68 = llvm.sub %46, %67  : i64
          %69 = llvm.icmp "slt" %68, %66 : i64
          %70 = llvm.select %69, %68, %66 : i1, i64
          %71 = llvm.icmp "slt" %70, %8 : i64
          %72 = llvm.select %71, %8, %70 : i1, i64
          %73 = llvm.icmp "sle" %54, %8 : i64
          %74 = llvm.sub %8, %54  : i64
          %75 = llvm.sub %54, %9  : i64
          %76 = llvm.select %73, %74, %75 : i1, i64
          %77 = llvm.sdiv %76, %7  : i64
          %78 = llvm.sub %8, %77  : i64
          %79 = llvm.add %77, %9  : i64
          %80 = llvm.select %73, %78, %79 : i1, i64
          %81 = llvm.mul %56, %80  : i64
          %82 = llvm.sub %54, %81  : i64
          %83 = llvm.icmp "slt" %82, %80 : i64
          %84 = llvm.select %83, %82, %80 : i1, i64
          %85 = llvm.icmp "slt" %84, %8 : i64
          %86 = llvm.select %85, %8, %84 : i1, i64
          %87 = llvm.mul %42, %7  : i64
          %88 = llvm.add %87, %67  : i64
          %89 = llvm.mul %50, %6  : i64
          %90 = llvm.add %89, %81  : i64
          llvm.br ^bb1(%8 : i64)
        ^bb1(%91: i64):  // 2 preds: ^bb0, ^bb5
          %92 = llvm.icmp "slt" %91, %72 : i64
          llvm.cond_br %92, ^bb2, ^bb6(%8 : i64)
        ^bb2:  // pred: ^bb1
          %93 = llvm.add %88, %91  : i64
          llvm.br ^bb3(%8 : i64)
        ^bb3(%94: i64):  // 2 preds: ^bb2, ^bb4
          %95 = llvm.icmp "slt" %94, %86 : i64
          llvm.cond_br %95, ^bb4, ^bb5
        ^bb4:  // pred: ^bb3
          %96 = llvm.add %90, %94  : i64
          %97 = llvm.mul %93, %20  : i64
          %98 = llvm.add %97, %96  : i64
          %99 = llvm.getelementptr %arg1[%98] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          llvm.store %11, %99 : f32, !llvm.ptr<1>
          %100 = llvm.add %94, %9  : i64
          llvm.br ^bb3(%100 : i64)
        ^bb5:  // pred: ^bb3
          %101 = llvm.add %91, %9  : i64
          llvm.br ^bb1(%101 : i64)
        ^bb6(%102: i64):  // 2 preds: ^bb1, ^bb12
          %103 = llvm.icmp "slt" %102, %19 : i64
          llvm.cond_br %103, ^bb7(%8 : i64), ^bb13
        ^bb7(%104: i64):  // 2 preds: ^bb6, ^bb11
          %105 = llvm.icmp "slt" %104, %72 : i64
          llvm.cond_br %105, ^bb8, ^bb12
        ^bb8:  // pred: ^bb7
          %106 = llvm.add %88, %104  : i64
          llvm.br ^bb9(%8 : i64)
        ^bb9(%107: i64):  // 2 preds: ^bb8, ^bb10
          %108 = llvm.icmp "slt" %107, %86 : i64
          llvm.cond_br %108, ^bb10, ^bb11
        ^bb10:  // pred: ^bb9
          %109 = llvm.mul %106, %20  : i64
          %110 = llvm.add %109, %102  : i64
          %111 = llvm.getelementptr %arg0[%110] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %112 = llvm.load %111 : !llvm.ptr<1> -> f32
          %113 = llvm.add %90, %107  : i64
          %114 = llvm.mul %102, %20  : i64
          %115 = llvm.add %114, %113  : i64
          %116 = llvm.getelementptr %arg0[%115] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %117 = llvm.load %116 : !llvm.ptr<1> -> f32
          %118 = llvm.add %109, %113  : i64
          %119 = llvm.getelementptr %arg1[%118] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %120 = llvm.load %119 : !llvm.ptr<1> -> f32
          %121 = llvm.fmul %112, %117  : f32
          %122 = llvm.fadd %120, %121  : f32
          llvm.store %122, %119 : f32, !llvm.ptr<1>
          %123 = llvm.add %107, %9  : i64
          llvm.br ^bb9(%123 : i64)
        ^bb11:  // pred: ^bb9
          %124 = llvm.add %104, %9  : i64
          llvm.br ^bb7(%124 : i64)
        ^bb12:  // pred: ^bb7
          %125 = llvm.add %102, %9  : i64
          llvm.br ^bb6(%125 : i64)
        ^bb13:  // pred: ^bb6
          llvm.return
        }
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c1 = arith.constant 1 : index
    %c-1 = arith.constant -1 : index
    %c-1_i32 = arith.constant -1 : i32
    %c0_i64 = arith.constant 0 : i64
    %c-1_i64 = arith.constant -1 : i64
    %c32_i64 = arith.constant 32 : i64
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %4 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%3}
    %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    %5 = arith.index_castui %0 : index to i64
    %6 = arith.trunci %5 : i64 to i32
    %7 = arith.shrui %5, %c32_i64 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %1 : index to i64
    %10 = arith.trunci %9 : i64 to i32
    %11 = arith.shrui %9, %c32_i64 : i64
    %12 = arith.trunci %11 : i64 to i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    %13 = arith.select %value, %c0, %c-1 : index
    scf.index_switch %13 
    case 0 {
      %pipeline_layout = hal.pipeline_layout.lookup device(%device : !hal.device) layout(#pipeline_layout) : !hal.pipeline_layout
      hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%pipeline_layout : !hal.pipeline_layout) offset(0) values([%6, %8, %10, %12]) : i32, i32, i32, i32
      hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%pipeline_layout : !hal.pipeline_layout)[%c0] bindings([
        %c0 = (%buffer : !hal.buffer)[%c0, %3], 
        %c1 = (%transient_buffer : !hal.buffer)[%c0, %3]
      ])
      %14 = affine.apply #map()[%1, %0]
      %15 = hal.command_buffer.device<%cmd : !hal.command_buffer> : !hal.device
      %exe = hal.executable.lookup device(%15 : !hal.device) executable(@main_dispatch_0) : !hal.executable
      hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%exe : !hal.executable)[0] workgroups([%14, %c1, %c1])
      scf.yield
    }
    default {
    }
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_0 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status_1 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence_0) commands([%cmd])
    %status_2 = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status_2, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %3] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::HAL::MaterializeResourceCachesPass (iree-hal-materialize-resource-caches) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<()[s0, s1] -> ((s0 ceildiv 128) * (s1 ceildiv 32))>
#pipeline_layout = #hal.pipeline.layout<push_constants = 4, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer>]>]>
#translation = #iree_codegen.translation_info<LLVMGPUMatmulSimt>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer>]) : !hal.descriptor_set_layout
    util.global.store %descriptor_set_layout, @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    util.initializer.return
  }
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.initializer {
    %_descriptor_set_layout_0 = util.global.load @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    %device = hal.ex.shared_device : !hal.device
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(4) layouts([%_descriptor_set_layout_0]) : !hal.pipeline_layout
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    util.initializer.return
  }
  util.global private @_executable_main_dispatch_0 : !hal.executable
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    %c-1 = arith.constant -1 : index
    %c0 = arith.constant 0 : index
    %0 = arith.select %value, %c0, %c-1 : index
    %1 = scf.index_switch %0 -> !hal.executable 
    case 0 {
      %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
      %exe = hal.executable.create device(%device : !hal.device) target(@main_dispatch_0::@cuda_nvptx_fb) layouts([%_pipeline_layout_0]) : !hal.executable
      scf.yield %exe : !hal.executable
    }
    default {
      %2 = util.null : !hal.executable
      scf.yield %2 : !hal.executable
    }
    util.global.store %1, @_executable_main_dispatch_0 : !hal.executable
    util.initializer.return
  }
  hal.executable private @main_dispatch_0 {
    hal.executable.variant public @cuda_nvptx_fb target(#executable_target_cuda_nvptx_fb) {
      hal.executable.export public @main_dispatch_0_matmul_DxDxD_f32 ordinal(0) layout(#pipeline_layout) attributes {translation_info = #translation, workgroup_size = [32 : index, 8 : index, 1 : index]} {
      ^bb0(%arg0: !hal.device, %arg1: index, %arg2: index):
        %c1 = arith.constant 1 : index
        %0 = affine.apply #map()[%arg2, %arg1]
        hal.return %0, %c1, %c1 : index, index, index
      }
      builtin.module {
        llvm.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias}, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32) {
          %0 = llvm.mlir.constant(63 : index) : i64
          %1 = llvm.mlir.constant(1 : i64) : i64
          %2 = llvm.mlir.constant(8 : index) : i64
          %3 = llvm.mlir.constant(-128 : index) : i64
          %4 = llvm.mlir.constant(-32 : index) : i64
          %5 = llvm.mlir.constant(-1 : index) : i64
          %6 = llvm.mlir.constant(128 : index) : i64
          %7 = llvm.mlir.constant(32 : index) : i64
          %8 = llvm.mlir.constant(0 : index) : i64
          %9 = llvm.mlir.constant(1 : index) : i64
          %10 = llvm.mlir.constant(32 : i64) : i64
          %11 = llvm.mlir.constant(0.000000e+00 : f32) : f32
          %12 = llvm.zext %arg2 : i32 to i64
          %13 = llvm.zext %arg3 : i32 to i64
          %14 = llvm.shl %13, %10  : i64
          %15 = llvm.or %12, %14  : i64
          %16 = llvm.zext %arg4 : i32 to i64
          %17 = llvm.zext %arg5 : i32 to i64
          %18 = llvm.shl %17, %10  : i64
          %19 = llvm.or %16, %18  : i64
          %20 = llvm.mul %19, %1  : i64
          %21 = llvm.ptrtoint %arg0 : !llvm.ptr<1> to i64
          %22 = llvm.and %21, %0  : i64
          %23 = llvm.icmp "eq" %22, %8 : i64
          "llvm.intr.assume"(%23) : (i1) -> ()
          %24 = llvm.ptrtoint %arg1 : !llvm.ptr<1> to i64
          %25 = llvm.and %24, %0  : i64
          %26 = llvm.icmp "eq" %25, %8 : i64
          "llvm.intr.assume"(%26) : (i1) -> ()
          %27 = nvvm.read.ptx.sreg.ctaid.x : i32
          %28 = llvm.sext %27 : i32 to i64
          %29 = llvm.icmp "sle" %19, %8 : i64
          %30 = llvm.sub %8, %19  : i64
          %31 = llvm.sub %19, %9  : i64
          %32 = llvm.select %29, %30, %31 : i1, i64
          %33 = llvm.sdiv %32, %6  : i64
          %34 = llvm.sub %8, %33  : i64
          %35 = llvm.add %33, %9  : i64
          %36 = llvm.select %29, %34, %35 : i1, i64
          %37 = llvm.icmp "slt" %28, %8 : i64
          %38 = llvm.sub %5, %28  : i64
          %39 = llvm.select %37, %38, %28 : i1, i64
          %40 = llvm.sdiv %39, %36  : i64
          %41 = llvm.sub %5, %40  : i64
          %42 = llvm.select %37, %41, %40 : i1, i64
          %43 = llvm.mul %42, %4  : i64
          %44 = llvm.add %15, %43  : i64
          %45 = llvm.icmp "sgt" %44, %7 : i64
          %46 = llvm.select %45, %7, %44 : i1, i64
          %47 = llvm.srem %28, %36  : i64
          %48 = llvm.icmp "slt" %47, %8 : i64
          %49 = llvm.add %47, %36  : i64
          %50 = llvm.select %48, %49, %47 : i1, i64
          %51 = llvm.mul %50, %3  : i64
          %52 = llvm.add %19, %51  : i64
          %53 = llvm.icmp "sgt" %52, %6 : i64
          %54 = llvm.select %53, %6, %52 : i1, i64
          %55 = nvvm.read.ptx.sreg.tid.x : i32
          %56 = llvm.sext %55 : i32 to i64
          %57 = nvvm.read.ptx.sreg.tid.y : i32
          %58 = llvm.sext %57 : i32 to i64
          %59 = llvm.icmp "sle" %46, %8 : i64
          %60 = llvm.sub %8, %46  : i64
          %61 = llvm.sub %46, %9  : i64
          %62 = llvm.select %59, %60, %61 : i1, i64
          %63 = llvm.sdiv %62, %2  : i64
          %64 = llvm.sub %8, %63  : i64
          %65 = llvm.add %63, %9  : i64
          %66 = llvm.select %59, %64, %65 : i1, i64
          %67 = llvm.mul %58, %66  : i64
          %68 = llvm.sub %46, %67  : i64
          %69 = llvm.icmp "slt" %68, %66 : i64
          %70 = llvm.select %69, %68, %66 : i1, i64
          %71 = llvm.icmp "slt" %70, %8 : i64
          %72 = llvm.select %71, %8, %70 : i1, i64
          %73 = llvm.icmp "sle" %54, %8 : i64
          %74 = llvm.sub %8, %54  : i64
          %75 = llvm.sub %54, %9  : i64
          %76 = llvm.select %73, %74, %75 : i1, i64
          %77 = llvm.sdiv %76, %7  : i64
          %78 = llvm.sub %8, %77  : i64
          %79 = llvm.add %77, %9  : i64
          %80 = llvm.select %73, %78, %79 : i1, i64
          %81 = llvm.mul %56, %80  : i64
          %82 = llvm.sub %54, %81  : i64
          %83 = llvm.icmp "slt" %82, %80 : i64
          %84 = llvm.select %83, %82, %80 : i1, i64
          %85 = llvm.icmp "slt" %84, %8 : i64
          %86 = llvm.select %85, %8, %84 : i1, i64
          %87 = llvm.mul %42, %7  : i64
          %88 = llvm.add %87, %67  : i64
          %89 = llvm.mul %50, %6  : i64
          %90 = llvm.add %89, %81  : i64
          llvm.br ^bb1(%8 : i64)
        ^bb1(%91: i64):  // 2 preds: ^bb0, ^bb5
          %92 = llvm.icmp "slt" %91, %72 : i64
          llvm.cond_br %92, ^bb2, ^bb6(%8 : i64)
        ^bb2:  // pred: ^bb1
          %93 = llvm.add %88, %91  : i64
          llvm.br ^bb3(%8 : i64)
        ^bb3(%94: i64):  // 2 preds: ^bb2, ^bb4
          %95 = llvm.icmp "slt" %94, %86 : i64
          llvm.cond_br %95, ^bb4, ^bb5
        ^bb4:  // pred: ^bb3
          %96 = llvm.add %90, %94  : i64
          %97 = llvm.mul %93, %20  : i64
          %98 = llvm.add %97, %96  : i64
          %99 = llvm.getelementptr %arg1[%98] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          llvm.store %11, %99 : f32, !llvm.ptr<1>
          %100 = llvm.add %94, %9  : i64
          llvm.br ^bb3(%100 : i64)
        ^bb5:  // pred: ^bb3
          %101 = llvm.add %91, %9  : i64
          llvm.br ^bb1(%101 : i64)
        ^bb6(%102: i64):  // 2 preds: ^bb1, ^bb12
          %103 = llvm.icmp "slt" %102, %19 : i64
          llvm.cond_br %103, ^bb7(%8 : i64), ^bb13
        ^bb7(%104: i64):  // 2 preds: ^bb6, ^bb11
          %105 = llvm.icmp "slt" %104, %72 : i64
          llvm.cond_br %105, ^bb8, ^bb12
        ^bb8:  // pred: ^bb7
          %106 = llvm.add %88, %104  : i64
          llvm.br ^bb9(%8 : i64)
        ^bb9(%107: i64):  // 2 preds: ^bb8, ^bb10
          %108 = llvm.icmp "slt" %107, %86 : i64
          llvm.cond_br %108, ^bb10, ^bb11
        ^bb10:  // pred: ^bb9
          %109 = llvm.mul %106, %20  : i64
          %110 = llvm.add %109, %102  : i64
          %111 = llvm.getelementptr %arg0[%110] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %112 = llvm.load %111 : !llvm.ptr<1> -> f32
          %113 = llvm.add %90, %107  : i64
          %114 = llvm.mul %102, %20  : i64
          %115 = llvm.add %114, %113  : i64
          %116 = llvm.getelementptr %arg0[%115] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %117 = llvm.load %116 : !llvm.ptr<1> -> f32
          %118 = llvm.add %109, %113  : i64
          %119 = llvm.getelementptr %arg1[%118] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %120 = llvm.load %119 : !llvm.ptr<1> -> f32
          %121 = llvm.fmul %112, %117  : f32
          %122 = llvm.fadd %120, %121  : f32
          llvm.store %122, %119 : f32, !llvm.ptr<1>
          %123 = llvm.add %107, %9  : i64
          llvm.br ^bb9(%123 : i64)
        ^bb11:  // pred: ^bb9
          %124 = llvm.add %104, %9  : i64
          llvm.br ^bb7(%124 : i64)
        ^bb12:  // pred: ^bb7
          %125 = llvm.add %102, %9  : i64
          llvm.br ^bb6(%125 : i64)
        ^bb13:  // pred: ^bb6
          llvm.return
        }
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c1 = arith.constant 1 : index
    %c-1 = arith.constant -1 : index
    %c-1_i32 = arith.constant -1 : i32
    %c0_i64 = arith.constant 0 : i64
    %c-1_i64 = arith.constant -1 : i64
    %c32_i64 = arith.constant 32 : i64
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %4 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%3}
    %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    %5 = arith.index_castui %0 : index to i64
    %6 = arith.trunci %5 : i64 to i32
    %7 = arith.shrui %5, %c32_i64 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %1 : index to i64
    %10 = arith.trunci %9 : i64 to i32
    %11 = arith.shrui %9, %c32_i64 : i64
    %12 = arith.trunci %11 : i64 to i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    %13 = arith.select %value, %c0, %c-1 : index
    scf.index_switch %13 
    case 0 {
      %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
      hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout) offset(0) values([%6, %8, %10, %12]) : i32, i32, i32, i32
      hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
        %c0 = (%buffer : !hal.buffer)[%c0, %3], 
        %c1 = (%transient_buffer : !hal.buffer)[%c0, %3]
      ])
      %14 = affine.apply #map()[%1, %0]
      %15 = hal.command_buffer.device<%cmd : !hal.command_buffer> : !hal.device
      %_executable_main_dispatch_0 = util.global.load @_executable_main_dispatch_0 : !hal.executable
      hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_main_dispatch_0 : !hal.executable)[0] workgroups([%14, %c1, %c1])
      scf.yield
    }
    default {
    }
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_0 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status_1 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence_0) commands([%cmd])
    %status_2 = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status_2, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %3] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::HAL::MemoizeDeviceQueriesPass (iree-hal-memoize-device-queries) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<()[s0, s1] -> ((s0 ceildiv 128) * (s1 ceildiv 32))>
#pipeline_layout = #hal.pipeline.layout<push_constants = 4, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer>]>]>
#translation = #iree_codegen.translation_info<LLVMGPUMatmulSimt>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private @_device_query_0 : i1
  util.global private @_device_query_0_ok : i1
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    util.global.store %ok, @_device_query_0_ok : i1
    util.global.store %value, @_device_query_0 : i1
    util.initializer.return
  }
  util.global private @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer>]) : !hal.descriptor_set_layout
    util.global.store %descriptor_set_layout, @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    util.initializer.return
  }
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.initializer {
    %_descriptor_set_layout_0 = util.global.load @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    %device = hal.ex.shared_device : !hal.device
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(4) layouts([%_descriptor_set_layout_0]) : !hal.pipeline_layout
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    util.initializer.return
  }
  util.global private @_executable_main_dispatch_0 : !hal.executable
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %_device_query_0_ok = util.global.load @_device_query_0_ok : i1
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %c-1 = arith.constant -1 : index
    %c0 = arith.constant 0 : index
    %0 = arith.select %_device_query_0, %c0, %c-1 : index
    %1 = scf.index_switch %0 -> !hal.executable 
    case 0 {
      %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
      %exe = hal.executable.create device(%device : !hal.device) target(@main_dispatch_0::@cuda_nvptx_fb) layouts([%_pipeline_layout_0]) : !hal.executable
      scf.yield %exe : !hal.executable
    }
    default {
      %2 = util.null : !hal.executable
      scf.yield %2 : !hal.executable
    }
    util.global.store %1, @_executable_main_dispatch_0 : !hal.executable
    util.initializer.return
  }
  hal.executable private @main_dispatch_0 {
    hal.executable.variant public @cuda_nvptx_fb target(#executable_target_cuda_nvptx_fb) {
      hal.executable.export public @main_dispatch_0_matmul_DxDxD_f32 ordinal(0) layout(#pipeline_layout) attributes {translation_info = #translation, workgroup_size = [32 : index, 8 : index, 1 : index]} {
      ^bb0(%arg0: !hal.device, %arg1: index, %arg2: index):
        %c1 = arith.constant 1 : index
        %0 = affine.apply #map()[%arg2, %arg1]
        hal.return %0, %c1, %c1 : index, index, index
      }
      builtin.module {
        llvm.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias}, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32) {
          %0 = llvm.mlir.constant(63 : index) : i64
          %1 = llvm.mlir.constant(1 : i64) : i64
          %2 = llvm.mlir.constant(8 : index) : i64
          %3 = llvm.mlir.constant(-128 : index) : i64
          %4 = llvm.mlir.constant(-32 : index) : i64
          %5 = llvm.mlir.constant(-1 : index) : i64
          %6 = llvm.mlir.constant(128 : index) : i64
          %7 = llvm.mlir.constant(32 : index) : i64
          %8 = llvm.mlir.constant(0 : index) : i64
          %9 = llvm.mlir.constant(1 : index) : i64
          %10 = llvm.mlir.constant(32 : i64) : i64
          %11 = llvm.mlir.constant(0.000000e+00 : f32) : f32
          %12 = llvm.zext %arg2 : i32 to i64
          %13 = llvm.zext %arg3 : i32 to i64
          %14 = llvm.shl %13, %10  : i64
          %15 = llvm.or %12, %14  : i64
          %16 = llvm.zext %arg4 : i32 to i64
          %17 = llvm.zext %arg5 : i32 to i64
          %18 = llvm.shl %17, %10  : i64
          %19 = llvm.or %16, %18  : i64
          %20 = llvm.mul %19, %1  : i64
          %21 = llvm.ptrtoint %arg0 : !llvm.ptr<1> to i64
          %22 = llvm.and %21, %0  : i64
          %23 = llvm.icmp "eq" %22, %8 : i64
          "llvm.intr.assume"(%23) : (i1) -> ()
          %24 = llvm.ptrtoint %arg1 : !llvm.ptr<1> to i64
          %25 = llvm.and %24, %0  : i64
          %26 = llvm.icmp "eq" %25, %8 : i64
          "llvm.intr.assume"(%26) : (i1) -> ()
          %27 = nvvm.read.ptx.sreg.ctaid.x : i32
          %28 = llvm.sext %27 : i32 to i64
          %29 = llvm.icmp "sle" %19, %8 : i64
          %30 = llvm.sub %8, %19  : i64
          %31 = llvm.sub %19, %9  : i64
          %32 = llvm.select %29, %30, %31 : i1, i64
          %33 = llvm.sdiv %32, %6  : i64
          %34 = llvm.sub %8, %33  : i64
          %35 = llvm.add %33, %9  : i64
          %36 = llvm.select %29, %34, %35 : i1, i64
          %37 = llvm.icmp "slt" %28, %8 : i64
          %38 = llvm.sub %5, %28  : i64
          %39 = llvm.select %37, %38, %28 : i1, i64
          %40 = llvm.sdiv %39, %36  : i64
          %41 = llvm.sub %5, %40  : i64
          %42 = llvm.select %37, %41, %40 : i1, i64
          %43 = llvm.mul %42, %4  : i64
          %44 = llvm.add %15, %43  : i64
          %45 = llvm.icmp "sgt" %44, %7 : i64
          %46 = llvm.select %45, %7, %44 : i1, i64
          %47 = llvm.srem %28, %36  : i64
          %48 = llvm.icmp "slt" %47, %8 : i64
          %49 = llvm.add %47, %36  : i64
          %50 = llvm.select %48, %49, %47 : i1, i64
          %51 = llvm.mul %50, %3  : i64
          %52 = llvm.add %19, %51  : i64
          %53 = llvm.icmp "sgt" %52, %6 : i64
          %54 = llvm.select %53, %6, %52 : i1, i64
          %55 = nvvm.read.ptx.sreg.tid.x : i32
          %56 = llvm.sext %55 : i32 to i64
          %57 = nvvm.read.ptx.sreg.tid.y : i32
          %58 = llvm.sext %57 : i32 to i64
          %59 = llvm.icmp "sle" %46, %8 : i64
          %60 = llvm.sub %8, %46  : i64
          %61 = llvm.sub %46, %9  : i64
          %62 = llvm.select %59, %60, %61 : i1, i64
          %63 = llvm.sdiv %62, %2  : i64
          %64 = llvm.sub %8, %63  : i64
          %65 = llvm.add %63, %9  : i64
          %66 = llvm.select %59, %64, %65 : i1, i64
          %67 = llvm.mul %58, %66  : i64
          %68 = llvm.sub %46, %67  : i64
          %69 = llvm.icmp "slt" %68, %66 : i64
          %70 = llvm.select %69, %68, %66 : i1, i64
          %71 = llvm.icmp "slt" %70, %8 : i64
          %72 = llvm.select %71, %8, %70 : i1, i64
          %73 = llvm.icmp "sle" %54, %8 : i64
          %74 = llvm.sub %8, %54  : i64
          %75 = llvm.sub %54, %9  : i64
          %76 = llvm.select %73, %74, %75 : i1, i64
          %77 = llvm.sdiv %76, %7  : i64
          %78 = llvm.sub %8, %77  : i64
          %79 = llvm.add %77, %9  : i64
          %80 = llvm.select %73, %78, %79 : i1, i64
          %81 = llvm.mul %56, %80  : i64
          %82 = llvm.sub %54, %81  : i64
          %83 = llvm.icmp "slt" %82, %80 : i64
          %84 = llvm.select %83, %82, %80 : i1, i64
          %85 = llvm.icmp "slt" %84, %8 : i64
          %86 = llvm.select %85, %8, %84 : i1, i64
          %87 = llvm.mul %42, %7  : i64
          %88 = llvm.add %87, %67  : i64
          %89 = llvm.mul %50, %6  : i64
          %90 = llvm.add %89, %81  : i64
          llvm.br ^bb1(%8 : i64)
        ^bb1(%91: i64):  // 2 preds: ^bb0, ^bb5
          %92 = llvm.icmp "slt" %91, %72 : i64
          llvm.cond_br %92, ^bb2, ^bb6(%8 : i64)
        ^bb2:  // pred: ^bb1
          %93 = llvm.add %88, %91  : i64
          llvm.br ^bb3(%8 : i64)
        ^bb3(%94: i64):  // 2 preds: ^bb2, ^bb4
          %95 = llvm.icmp "slt" %94, %86 : i64
          llvm.cond_br %95, ^bb4, ^bb5
        ^bb4:  // pred: ^bb3
          %96 = llvm.add %90, %94  : i64
          %97 = llvm.mul %93, %20  : i64
          %98 = llvm.add %97, %96  : i64
          %99 = llvm.getelementptr %arg1[%98] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          llvm.store %11, %99 : f32, !llvm.ptr<1>
          %100 = llvm.add %94, %9  : i64
          llvm.br ^bb3(%100 : i64)
        ^bb5:  // pred: ^bb3
          %101 = llvm.add %91, %9  : i64
          llvm.br ^bb1(%101 : i64)
        ^bb6(%102: i64):  // 2 preds: ^bb1, ^bb12
          %103 = llvm.icmp "slt" %102, %19 : i64
          llvm.cond_br %103, ^bb7(%8 : i64), ^bb13
        ^bb7(%104: i64):  // 2 preds: ^bb6, ^bb11
          %105 = llvm.icmp "slt" %104, %72 : i64
          llvm.cond_br %105, ^bb8, ^bb12
        ^bb8:  // pred: ^bb7
          %106 = llvm.add %88, %104  : i64
          llvm.br ^bb9(%8 : i64)
        ^bb9(%107: i64):  // 2 preds: ^bb8, ^bb10
          %108 = llvm.icmp "slt" %107, %86 : i64
          llvm.cond_br %108, ^bb10, ^bb11
        ^bb10:  // pred: ^bb9
          %109 = llvm.mul %106, %20  : i64
          %110 = llvm.add %109, %102  : i64
          %111 = llvm.getelementptr %arg0[%110] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %112 = llvm.load %111 : !llvm.ptr<1> -> f32
          %113 = llvm.add %90, %107  : i64
          %114 = llvm.mul %102, %20  : i64
          %115 = llvm.add %114, %113  : i64
          %116 = llvm.getelementptr %arg0[%115] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %117 = llvm.load %116 : !llvm.ptr<1> -> f32
          %118 = llvm.add %109, %113  : i64
          %119 = llvm.getelementptr %arg1[%118] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %120 = llvm.load %119 : !llvm.ptr<1> -> f32
          %121 = llvm.fmul %112, %117  : f32
          %122 = llvm.fadd %120, %121  : f32
          llvm.store %122, %119 : f32, !llvm.ptr<1>
          %123 = llvm.add %107, %9  : i64
          llvm.br ^bb9(%123 : i64)
        ^bb11:  // pred: ^bb9
          %124 = llvm.add %104, %9  : i64
          llvm.br ^bb7(%124 : i64)
        ^bb12:  // pred: ^bb7
          %125 = llvm.add %102, %9  : i64
          llvm.br ^bb6(%125 : i64)
        ^bb13:  // pred: ^bb6
          llvm.return
        }
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c1 = arith.constant 1 : index
    %c-1 = arith.constant -1 : index
    %c-1_i32 = arith.constant -1 : i32
    %c0_i64 = arith.constant 0 : i64
    %c-1_i64 = arith.constant -1 : i64
    %c32_i64 = arith.constant 32 : i64
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %4 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%3}
    %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    %5 = arith.index_castui %0 : index to i64
    %6 = arith.trunci %5 : i64 to i32
    %7 = arith.shrui %5, %c32_i64 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %1 : index to i64
    %10 = arith.trunci %9 : i64 to i32
    %11 = arith.shrui %9, %c32_i64 : i64
    %12 = arith.trunci %11 : i64 to i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    %_device_query_0_ok = util.global.load @_device_query_0_ok : i1
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %13 = arith.select %_device_query_0, %c0, %c-1 : index
    scf.index_switch %13 
    case 0 {
      %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
      hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout) offset(0) values([%6, %8, %10, %12]) : i32, i32, i32, i32
      hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
        %c0 = (%buffer : !hal.buffer)[%c0, %3], 
        %c1 = (%transient_buffer : !hal.buffer)[%c0, %3]
      ])
      %14 = affine.apply #map()[%1, %0]
      %15 = hal.command_buffer.device<%cmd : !hal.command_buffer> : !hal.device
      %_executable_main_dispatch_0 = util.global.load @_executable_main_dispatch_0 : !hal.executable
      hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_main_dispatch_0 : !hal.executable)[0] workgroups([%14, %c1, %c1])
      scf.yield
    }
    default {
    }
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_0 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status_1 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence_0) commands([%cmd])
    %status_2 = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status_2, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %3] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After CSE (cse) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<()[s0, s1] -> ((s0 ceildiv 128) * (s1 ceildiv 32))>
#pipeline_layout = #hal.pipeline.layout<push_constants = 4, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer>]>]>
#translation = #iree_codegen.translation_info<LLVMGPUMatmulSimt>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private @_device_query_0 : i1
  util.global private @_device_query_0_ok : i1
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    util.global.store %ok, @_device_query_0_ok : i1
    util.global.store %value, @_device_query_0 : i1
    util.initializer.return
  }
  util.global private @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer>]) : !hal.descriptor_set_layout
    util.global.store %descriptor_set_layout, @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    util.initializer.return
  }
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.initializer {
    %_descriptor_set_layout_0 = util.global.load @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    %device = hal.ex.shared_device : !hal.device
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(4) layouts([%_descriptor_set_layout_0]) : !hal.pipeline_layout
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    util.initializer.return
  }
  util.global private @_executable_main_dispatch_0 : !hal.executable
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %c-1 = arith.constant -1 : index
    %c0 = arith.constant 0 : index
    %0 = arith.select %_device_query_0, %c0, %c-1 : index
    %1 = scf.index_switch %0 -> !hal.executable 
    case 0 {
      %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
      %exe = hal.executable.create device(%device : !hal.device) target(@main_dispatch_0::@cuda_nvptx_fb) layouts([%_pipeline_layout_0]) : !hal.executable
      scf.yield %exe : !hal.executable
    }
    default {
      %2 = util.null : !hal.executable
      scf.yield %2 : !hal.executable
    }
    util.global.store %1, @_executable_main_dispatch_0 : !hal.executable
    util.initializer.return
  }
  hal.executable private @main_dispatch_0 {
    hal.executable.variant public @cuda_nvptx_fb target(#executable_target_cuda_nvptx_fb) {
      hal.executable.export public @main_dispatch_0_matmul_DxDxD_f32 ordinal(0) layout(#pipeline_layout) attributes {translation_info = #translation, workgroup_size = [32 : index, 8 : index, 1 : index]} {
      ^bb0(%arg0: !hal.device, %arg1: index, %arg2: index):
        %c1 = arith.constant 1 : index
        %0 = affine.apply #map()[%arg2, %arg1]
        hal.return %0, %c1, %c1 : index, index, index
      }
      builtin.module {
        llvm.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias}, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32) {
          %0 = llvm.mlir.constant(63 : index) : i64
          %1 = llvm.mlir.constant(1 : i64) : i64
          %2 = llvm.mlir.constant(8 : index) : i64
          %3 = llvm.mlir.constant(-128 : index) : i64
          %4 = llvm.mlir.constant(-32 : index) : i64
          %5 = llvm.mlir.constant(-1 : index) : i64
          %6 = llvm.mlir.constant(128 : index) : i64
          %7 = llvm.mlir.constant(32 : index) : i64
          %8 = llvm.mlir.constant(0 : index) : i64
          %9 = llvm.mlir.constant(1 : index) : i64
          %10 = llvm.mlir.constant(32 : i64) : i64
          %11 = llvm.mlir.constant(0.000000e+00 : f32) : f32
          %12 = llvm.zext %arg2 : i32 to i64
          %13 = llvm.zext %arg3 : i32 to i64
          %14 = llvm.shl %13, %10  : i64
          %15 = llvm.or %12, %14  : i64
          %16 = llvm.zext %arg4 : i32 to i64
          %17 = llvm.zext %arg5 : i32 to i64
          %18 = llvm.shl %17, %10  : i64
          %19 = llvm.or %16, %18  : i64
          %20 = llvm.mul %19, %1  : i64
          %21 = llvm.ptrtoint %arg0 : !llvm.ptr<1> to i64
          %22 = llvm.and %21, %0  : i64
          %23 = llvm.icmp "eq" %22, %8 : i64
          "llvm.intr.assume"(%23) : (i1) -> ()
          %24 = llvm.ptrtoint %arg1 : !llvm.ptr<1> to i64
          %25 = llvm.and %24, %0  : i64
          %26 = llvm.icmp "eq" %25, %8 : i64
          "llvm.intr.assume"(%26) : (i1) -> ()
          %27 = nvvm.read.ptx.sreg.ctaid.x : i32
          %28 = llvm.sext %27 : i32 to i64
          %29 = llvm.icmp "sle" %19, %8 : i64
          %30 = llvm.sub %8, %19  : i64
          %31 = llvm.sub %19, %9  : i64
          %32 = llvm.select %29, %30, %31 : i1, i64
          %33 = llvm.sdiv %32, %6  : i64
          %34 = llvm.sub %8, %33  : i64
          %35 = llvm.add %33, %9  : i64
          %36 = llvm.select %29, %34, %35 : i1, i64
          %37 = llvm.icmp "slt" %28, %8 : i64
          %38 = llvm.sub %5, %28  : i64
          %39 = llvm.select %37, %38, %28 : i1, i64
          %40 = llvm.sdiv %39, %36  : i64
          %41 = llvm.sub %5, %40  : i64
          %42 = llvm.select %37, %41, %40 : i1, i64
          %43 = llvm.mul %42, %4  : i64
          %44 = llvm.add %15, %43  : i64
          %45 = llvm.icmp "sgt" %44, %7 : i64
          %46 = llvm.select %45, %7, %44 : i1, i64
          %47 = llvm.srem %28, %36  : i64
          %48 = llvm.icmp "slt" %47, %8 : i64
          %49 = llvm.add %47, %36  : i64
          %50 = llvm.select %48, %49, %47 : i1, i64
          %51 = llvm.mul %50, %3  : i64
          %52 = llvm.add %19, %51  : i64
          %53 = llvm.icmp "sgt" %52, %6 : i64
          %54 = llvm.select %53, %6, %52 : i1, i64
          %55 = nvvm.read.ptx.sreg.tid.x : i32
          %56 = llvm.sext %55 : i32 to i64
          %57 = nvvm.read.ptx.sreg.tid.y : i32
          %58 = llvm.sext %57 : i32 to i64
          %59 = llvm.icmp "sle" %46, %8 : i64
          %60 = llvm.sub %8, %46  : i64
          %61 = llvm.sub %46, %9  : i64
          %62 = llvm.select %59, %60, %61 : i1, i64
          %63 = llvm.sdiv %62, %2  : i64
          %64 = llvm.sub %8, %63  : i64
          %65 = llvm.add %63, %9  : i64
          %66 = llvm.select %59, %64, %65 : i1, i64
          %67 = llvm.mul %58, %66  : i64
          %68 = llvm.sub %46, %67  : i64
          %69 = llvm.icmp "slt" %68, %66 : i64
          %70 = llvm.select %69, %68, %66 : i1, i64
          %71 = llvm.icmp "slt" %70, %8 : i64
          %72 = llvm.select %71, %8, %70 : i1, i64
          %73 = llvm.icmp "sle" %54, %8 : i64
          %74 = llvm.sub %8, %54  : i64
          %75 = llvm.sub %54, %9  : i64
          %76 = llvm.select %73, %74, %75 : i1, i64
          %77 = llvm.sdiv %76, %7  : i64
          %78 = llvm.sub %8, %77  : i64
          %79 = llvm.add %77, %9  : i64
          %80 = llvm.select %73, %78, %79 : i1, i64
          %81 = llvm.mul %56, %80  : i64
          %82 = llvm.sub %54, %81  : i64
          %83 = llvm.icmp "slt" %82, %80 : i64
          %84 = llvm.select %83, %82, %80 : i1, i64
          %85 = llvm.icmp "slt" %84, %8 : i64
          %86 = llvm.select %85, %8, %84 : i1, i64
          %87 = llvm.mul %42, %7  : i64
          %88 = llvm.add %87, %67  : i64
          %89 = llvm.mul %50, %6  : i64
          %90 = llvm.add %89, %81  : i64
          llvm.br ^bb1(%8 : i64)
        ^bb1(%91: i64):  // 2 preds: ^bb0, ^bb5
          %92 = llvm.icmp "slt" %91, %72 : i64
          llvm.cond_br %92, ^bb2, ^bb6(%8 : i64)
        ^bb2:  // pred: ^bb1
          %93 = llvm.add %88, %91  : i64
          llvm.br ^bb3(%8 : i64)
        ^bb3(%94: i64):  // 2 preds: ^bb2, ^bb4
          %95 = llvm.icmp "slt" %94, %86 : i64
          llvm.cond_br %95, ^bb4, ^bb5
        ^bb4:  // pred: ^bb3
          %96 = llvm.add %90, %94  : i64
          %97 = llvm.mul %93, %20  : i64
          %98 = llvm.add %97, %96  : i64
          %99 = llvm.getelementptr %arg1[%98] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          llvm.store %11, %99 : f32, !llvm.ptr<1>
          %100 = llvm.add %94, %9  : i64
          llvm.br ^bb3(%100 : i64)
        ^bb5:  // pred: ^bb3
          %101 = llvm.add %91, %9  : i64
          llvm.br ^bb1(%101 : i64)
        ^bb6(%102: i64):  // 2 preds: ^bb1, ^bb12
          %103 = llvm.icmp "slt" %102, %19 : i64
          llvm.cond_br %103, ^bb7(%8 : i64), ^bb13
        ^bb7(%104: i64):  // 2 preds: ^bb6, ^bb11
          %105 = llvm.icmp "slt" %104, %72 : i64
          llvm.cond_br %105, ^bb8, ^bb12
        ^bb8:  // pred: ^bb7
          %106 = llvm.add %88, %104  : i64
          llvm.br ^bb9(%8 : i64)
        ^bb9(%107: i64):  // 2 preds: ^bb8, ^bb10
          %108 = llvm.icmp "slt" %107, %86 : i64
          llvm.cond_br %108, ^bb10, ^bb11
        ^bb10:  // pred: ^bb9
          %109 = llvm.mul %106, %20  : i64
          %110 = llvm.add %109, %102  : i64
          %111 = llvm.getelementptr %arg0[%110] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %112 = llvm.load %111 : !llvm.ptr<1> -> f32
          %113 = llvm.add %90, %107  : i64
          %114 = llvm.mul %102, %20  : i64
          %115 = llvm.add %114, %113  : i64
          %116 = llvm.getelementptr %arg0[%115] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %117 = llvm.load %116 : !llvm.ptr<1> -> f32
          %118 = llvm.add %109, %113  : i64
          %119 = llvm.getelementptr %arg1[%118] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %120 = llvm.load %119 : !llvm.ptr<1> -> f32
          %121 = llvm.fmul %112, %117  : f32
          %122 = llvm.fadd %120, %121  : f32
          llvm.store %122, %119 : f32, !llvm.ptr<1>
          %123 = llvm.add %107, %9  : i64
          llvm.br ^bb9(%123 : i64)
        ^bb11:  // pred: ^bb9
          %124 = llvm.add %104, %9  : i64
          llvm.br ^bb7(%124 : i64)
        ^bb12:  // pred: ^bb7
          %125 = llvm.add %102, %9  : i64
          llvm.br ^bb6(%125 : i64)
        ^bb13:  // pred: ^bb6
          llvm.return
        }
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c1 = arith.constant 1 : index
    %c-1 = arith.constant -1 : index
    %c-1_i32 = arith.constant -1 : i32
    %c0_i64 = arith.constant 0 : i64
    %c-1_i64 = arith.constant -1 : i64
    %c32_i64 = arith.constant 32 : i64
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %4 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%3}
    %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    %5 = arith.index_castui %0 : index to i64
    %6 = arith.trunci %5 : i64 to i32
    %7 = arith.shrui %5, %c32_i64 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %1 : index to i64
    %10 = arith.trunci %9 : i64 to i32
    %11 = arith.shrui %9, %c32_i64 : i64
    %12 = arith.trunci %11 : i64 to i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %13 = arith.select %_device_query_0, %c0, %c-1 : index
    scf.index_switch %13 
    case 0 {
      %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
      hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout) offset(0) values([%6, %8, %10, %12]) : i32, i32, i32, i32
      hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
        %c0 = (%buffer : !hal.buffer)[%c0, %3], 
        %c1 = (%transient_buffer : !hal.buffer)[%c0, %3]
      ])
      %14 = affine.apply #map()[%1, %0]
      %_executable_main_dispatch_0 = util.global.load @_executable_main_dispatch_0 : !hal.executable
      hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_main_dispatch_0 : !hal.executable)[0] workgroups([%14, %c1, %c1])
      scf.yield
    }
    default {
    }
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_0 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status_1 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence_0) commands([%cmd])
    %status_2 = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status_2, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %3] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<()[s0, s1] -> ((s0 ceildiv 128) * (s1 ceildiv 32))>
#pipeline_layout = #hal.pipeline.layout<push_constants = 4, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer>]>]>
#translation = #iree_codegen.translation_info<LLVMGPUMatmulSimt>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private @_device_query_0 : i1
  util.global private @_device_query_0_ok : i1
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    util.global.store %ok, @_device_query_0_ok : i1
    util.global.store %value, @_device_query_0 : i1
    util.initializer.return
  }
  util.global private @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer>]) : !hal.descriptor_set_layout
    util.global.store %descriptor_set_layout, @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    util.initializer.return
  }
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.initializer {
    %_descriptor_set_layout_0 = util.global.load @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    %device = hal.ex.shared_device : !hal.device
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(4) layouts([%_descriptor_set_layout_0]) : !hal.pipeline_layout
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    util.initializer.return
  }
  util.global private @_executable_main_dispatch_0 : !hal.executable
  util.initializer {
    %c0 = arith.constant 0 : index
    %c-1 = arith.constant -1 : index
    %device = hal.ex.shared_device : !hal.device
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %0 = arith.select %_device_query_0, %c0, %c-1 : index
    %1 = scf.index_switch %0 -> !hal.executable 
    case 0 {
      %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
      %exe = hal.executable.create device(%device : !hal.device) target(@main_dispatch_0::@cuda_nvptx_fb) layouts([%_pipeline_layout_0]) : !hal.executable
      scf.yield %exe : !hal.executable
    }
    default {
      %2 = util.null : !hal.executable
      scf.yield %2 : !hal.executable
    }
    util.global.store %1, @_executable_main_dispatch_0 : !hal.executable
    util.initializer.return
  }
  hal.executable private @main_dispatch_0 {
    hal.executable.variant public @cuda_nvptx_fb target(#executable_target_cuda_nvptx_fb) {
      hal.executable.export public @main_dispatch_0_matmul_DxDxD_f32 ordinal(0) layout(#pipeline_layout) attributes {translation_info = #translation, workgroup_size = [32 : index, 8 : index, 1 : index]} {
      ^bb0(%arg0: !hal.device, %arg1: index, %arg2: index):
        %c1 = arith.constant 1 : index
        %0 = affine.apply #map()[%arg2, %arg1]
        hal.return %0, %c1, %c1 : index, index, index
      }
      builtin.module {
        llvm.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias}, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32) {
          %0 = llvm.mlir.constant(63 : index) : i64
          %1 = llvm.mlir.constant(1 : i64) : i64
          %2 = llvm.mlir.constant(8 : index) : i64
          %3 = llvm.mlir.constant(-128 : index) : i64
          %4 = llvm.mlir.constant(-32 : index) : i64
          %5 = llvm.mlir.constant(-1 : index) : i64
          %6 = llvm.mlir.constant(128 : index) : i64
          %7 = llvm.mlir.constant(32 : index) : i64
          %8 = llvm.mlir.constant(0 : index) : i64
          %9 = llvm.mlir.constant(1 : index) : i64
          %10 = llvm.mlir.constant(32 : i64) : i64
          %11 = llvm.mlir.constant(0.000000e+00 : f32) : f32
          %12 = llvm.zext %arg2 : i32 to i64
          %13 = llvm.zext %arg3 : i32 to i64
          %14 = llvm.shl %13, %10  : i64
          %15 = llvm.or %12, %14  : i64
          %16 = llvm.zext %arg4 : i32 to i64
          %17 = llvm.zext %arg5 : i32 to i64
          %18 = llvm.shl %17, %10  : i64
          %19 = llvm.or %16, %18  : i64
          %20 = llvm.mul %19, %1  : i64
          %21 = llvm.ptrtoint %arg0 : !llvm.ptr<1> to i64
          %22 = llvm.and %21, %0  : i64
          %23 = llvm.icmp "eq" %22, %8 : i64
          "llvm.intr.assume"(%23) : (i1) -> ()
          %24 = llvm.ptrtoint %arg1 : !llvm.ptr<1> to i64
          %25 = llvm.and %24, %0  : i64
          %26 = llvm.icmp "eq" %25, %8 : i64
          "llvm.intr.assume"(%26) : (i1) -> ()
          %27 = nvvm.read.ptx.sreg.ctaid.x : i32
          %28 = llvm.sext %27 : i32 to i64
          %29 = llvm.icmp "sle" %19, %8 : i64
          %30 = llvm.sub %8, %19  : i64
          %31 = llvm.sub %19, %9  : i64
          %32 = llvm.select %29, %30, %31 : i1, i64
          %33 = llvm.sdiv %32, %6  : i64
          %34 = llvm.sub %8, %33  : i64
          %35 = llvm.add %33, %9  : i64
          %36 = llvm.select %29, %34, %35 : i1, i64
          %37 = llvm.icmp "slt" %28, %8 : i64
          %38 = llvm.sub %5, %28  : i64
          %39 = llvm.select %37, %38, %28 : i1, i64
          %40 = llvm.sdiv %39, %36  : i64
          %41 = llvm.sub %5, %40  : i64
          %42 = llvm.select %37, %41, %40 : i1, i64
          %43 = llvm.mul %42, %4  : i64
          %44 = llvm.add %15, %43  : i64
          %45 = llvm.icmp "sgt" %44, %7 : i64
          %46 = llvm.select %45, %7, %44 : i1, i64
          %47 = llvm.srem %28, %36  : i64
          %48 = llvm.icmp "slt" %47, %8 : i64
          %49 = llvm.add %47, %36  : i64
          %50 = llvm.select %48, %49, %47 : i1, i64
          %51 = llvm.mul %50, %3  : i64
          %52 = llvm.add %19, %51  : i64
          %53 = llvm.icmp "sgt" %52, %6 : i64
          %54 = llvm.select %53, %6, %52 : i1, i64
          %55 = nvvm.read.ptx.sreg.tid.x : i32
          %56 = llvm.sext %55 : i32 to i64
          %57 = nvvm.read.ptx.sreg.tid.y : i32
          %58 = llvm.sext %57 : i32 to i64
          %59 = llvm.icmp "sle" %46, %8 : i64
          %60 = llvm.sub %8, %46  : i64
          %61 = llvm.sub %46, %9  : i64
          %62 = llvm.select %59, %60, %61 : i1, i64
          %63 = llvm.sdiv %62, %2  : i64
          %64 = llvm.sub %8, %63  : i64
          %65 = llvm.add %63, %9  : i64
          %66 = llvm.select %59, %64, %65 : i1, i64
          %67 = llvm.mul %58, %66  : i64
          %68 = llvm.sub %46, %67  : i64
          %69 = llvm.icmp "slt" %68, %66 : i64
          %70 = llvm.select %69, %68, %66 : i1, i64
          %71 = llvm.icmp "slt" %70, %8 : i64
          %72 = llvm.select %71, %8, %70 : i1, i64
          %73 = llvm.icmp "sle" %54, %8 : i64
          %74 = llvm.sub %8, %54  : i64
          %75 = llvm.sub %54, %9  : i64
          %76 = llvm.select %73, %74, %75 : i1, i64
          %77 = llvm.sdiv %76, %7  : i64
          %78 = llvm.sub %8, %77  : i64
          %79 = llvm.add %77, %9  : i64
          %80 = llvm.select %73, %78, %79 : i1, i64
          %81 = llvm.mul %56, %80  : i64
          %82 = llvm.sub %54, %81  : i64
          %83 = llvm.icmp "slt" %82, %80 : i64
          %84 = llvm.select %83, %82, %80 : i1, i64
          %85 = llvm.icmp "slt" %84, %8 : i64
          %86 = llvm.select %85, %8, %84 : i1, i64
          %87 = llvm.mul %42, %7  : i64
          %88 = llvm.add %87, %67  : i64
          %89 = llvm.mul %50, %6  : i64
          %90 = llvm.add %89, %81  : i64
          llvm.br ^bb1(%8 : i64)
        ^bb1(%91: i64):  // 2 preds: ^bb0, ^bb5
          %92 = llvm.icmp "slt" %91, %72 : i64
          llvm.cond_br %92, ^bb2, ^bb6(%8 : i64)
        ^bb2:  // pred: ^bb1
          %93 = llvm.add %88, %91  : i64
          llvm.br ^bb3(%8 : i64)
        ^bb3(%94: i64):  // 2 preds: ^bb2, ^bb4
          %95 = llvm.icmp "slt" %94, %86 : i64
          llvm.cond_br %95, ^bb4, ^bb5
        ^bb4:  // pred: ^bb3
          %96 = llvm.add %90, %94  : i64
          %97 = llvm.mul %93, %20  : i64
          %98 = llvm.add %97, %96  : i64
          %99 = llvm.getelementptr %arg1[%98] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          llvm.store %11, %99 : f32, !llvm.ptr<1>
          %100 = llvm.add %94, %9  : i64
          llvm.br ^bb3(%100 : i64)
        ^bb5:  // pred: ^bb3
          %101 = llvm.add %91, %9  : i64
          llvm.br ^bb1(%101 : i64)
        ^bb6(%102: i64):  // 2 preds: ^bb1, ^bb12
          %103 = llvm.icmp "slt" %102, %19 : i64
          llvm.cond_br %103, ^bb7(%8 : i64), ^bb13
        ^bb7(%104: i64):  // 2 preds: ^bb6, ^bb11
          %105 = llvm.icmp "slt" %104, %72 : i64
          llvm.cond_br %105, ^bb8, ^bb12
        ^bb8:  // pred: ^bb7
          %106 = llvm.add %88, %104  : i64
          llvm.br ^bb9(%8 : i64)
        ^bb9(%107: i64):  // 2 preds: ^bb8, ^bb10
          %108 = llvm.icmp "slt" %107, %86 : i64
          llvm.cond_br %108, ^bb10, ^bb11
        ^bb10:  // pred: ^bb9
          %109 = llvm.mul %106, %20  : i64
          %110 = llvm.add %109, %102  : i64
          %111 = llvm.getelementptr %arg0[%110] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %112 = llvm.load %111 : !llvm.ptr<1> -> f32
          %113 = llvm.add %90, %107  : i64
          %114 = llvm.mul %102, %20  : i64
          %115 = llvm.add %114, %113  : i64
          %116 = llvm.getelementptr %arg0[%115] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %117 = llvm.load %116 : !llvm.ptr<1> -> f32
          %118 = llvm.add %109, %113  : i64
          %119 = llvm.getelementptr %arg1[%118] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %120 = llvm.load %119 : !llvm.ptr<1> -> f32
          %121 = llvm.fmul %112, %117  : f32
          %122 = llvm.fadd %120, %121  : f32
          llvm.store %122, %119 : f32, !llvm.ptr<1>
          %123 = llvm.add %107, %9  : i64
          llvm.br ^bb9(%123 : i64)
        ^bb11:  // pred: ^bb9
          %124 = llvm.add %104, %9  : i64
          llvm.br ^bb7(%124 : i64)
        ^bb12:  // pred: ^bb7
          %125 = llvm.add %102, %9  : i64
          llvm.br ^bb6(%125 : i64)
        ^bb13:  // pred: ^bb6
          llvm.return
        }
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c1 = arith.constant 1 : index
    %c-1 = arith.constant -1 : index
    %c-1_i32 = arith.constant -1 : i32
    %c0_i64 = arith.constant 0 : i64
    %c-1_i64 = arith.constant -1 : i64
    %c32_i64 = arith.constant 32 : i64
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %4 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%3}
    %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    %5 = arith.index_castui %0 : index to i64
    %6 = arith.trunci %5 : i64 to i32
    %7 = arith.shrui %5, %c32_i64 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %1 : index to i64
    %10 = arith.trunci %9 : i64 to i32
    %11 = arith.shrui %9, %c32_i64 : i64
    %12 = arith.trunci %11 : i64 to i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %13 = arith.select %_device_query_0, %c0, %c-1 : index
    scf.index_switch %13 
    case 0 {
      %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
      hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout) offset(0) values([%6, %8, %10, %12]) : i32, i32, i32, i32
      hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
        %c0 = (%buffer : !hal.buffer)[%c0, %3], 
        %c1 = (%transient_buffer : !hal.buffer)[%c0, %3]
      ])
      %14 = affine.apply #map()[%1, %0]
      %_executable_main_dispatch_0 = util.global.load @_executable_main_dispatch_0 : !hal.executable
      hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_main_dispatch_0 : !hal.executable)[0] workgroups([%14, %c1, %c1])
      scf.yield
    }
    default {
    }
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_0 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status_1 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence_0) commands([%cmd])
    %status_2 = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status_2, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %3] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After CSE (cse) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<()[s0, s1] -> ((s0 ceildiv 128) * (s1 ceildiv 32))>
#pipeline_layout = #hal.pipeline.layout<push_constants = 4, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer>]>]>
#translation = #iree_codegen.translation_info<LLVMGPUMatmulSimt>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private @_device_query_0 : i1
  util.global private @_device_query_0_ok : i1
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    util.global.store %ok, @_device_query_0_ok : i1
    util.global.store %value, @_device_query_0 : i1
    util.initializer.return
  }
  util.global private @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer>]) : !hal.descriptor_set_layout
    util.global.store %descriptor_set_layout, @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    util.initializer.return
  }
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.initializer {
    %_descriptor_set_layout_0 = util.global.load @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    %device = hal.ex.shared_device : !hal.device
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(4) layouts([%_descriptor_set_layout_0]) : !hal.pipeline_layout
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    util.initializer.return
  }
  util.global private @_executable_main_dispatch_0 : !hal.executable
  util.initializer {
    %c0 = arith.constant 0 : index
    %c-1 = arith.constant -1 : index
    %device = hal.ex.shared_device : !hal.device
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %0 = arith.select %_device_query_0, %c0, %c-1 : index
    %1 = scf.index_switch %0 -> !hal.executable 
    case 0 {
      %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
      %exe = hal.executable.create device(%device : !hal.device) target(@main_dispatch_0::@cuda_nvptx_fb) layouts([%_pipeline_layout_0]) : !hal.executable
      scf.yield %exe : !hal.executable
    }
    default {
      %2 = util.null : !hal.executable
      scf.yield %2 : !hal.executable
    }
    util.global.store %1, @_executable_main_dispatch_0 : !hal.executable
    util.initializer.return
  }
  hal.executable private @main_dispatch_0 {
    hal.executable.variant public @cuda_nvptx_fb target(#executable_target_cuda_nvptx_fb) {
      hal.executable.export public @main_dispatch_0_matmul_DxDxD_f32 ordinal(0) layout(#pipeline_layout) attributes {translation_info = #translation, workgroup_size = [32 : index, 8 : index, 1 : index]} {
      ^bb0(%arg0: !hal.device, %arg1: index, %arg2: index):
        %c1 = arith.constant 1 : index
        %0 = affine.apply #map()[%arg2, %arg1]
        hal.return %0, %c1, %c1 : index, index, index
      }
      builtin.module {
        llvm.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias}, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32) {
          %0 = llvm.mlir.constant(63 : index) : i64
          %1 = llvm.mlir.constant(1 : i64) : i64
          %2 = llvm.mlir.constant(8 : index) : i64
          %3 = llvm.mlir.constant(-128 : index) : i64
          %4 = llvm.mlir.constant(-32 : index) : i64
          %5 = llvm.mlir.constant(-1 : index) : i64
          %6 = llvm.mlir.constant(128 : index) : i64
          %7 = llvm.mlir.constant(32 : index) : i64
          %8 = llvm.mlir.constant(0 : index) : i64
          %9 = llvm.mlir.constant(1 : index) : i64
          %10 = llvm.mlir.constant(32 : i64) : i64
          %11 = llvm.mlir.constant(0.000000e+00 : f32) : f32
          %12 = llvm.zext %arg2 : i32 to i64
          %13 = llvm.zext %arg3 : i32 to i64
          %14 = llvm.shl %13, %10  : i64
          %15 = llvm.or %12, %14  : i64
          %16 = llvm.zext %arg4 : i32 to i64
          %17 = llvm.zext %arg5 : i32 to i64
          %18 = llvm.shl %17, %10  : i64
          %19 = llvm.or %16, %18  : i64
          %20 = llvm.mul %19, %1  : i64
          %21 = llvm.ptrtoint %arg0 : !llvm.ptr<1> to i64
          %22 = llvm.and %21, %0  : i64
          %23 = llvm.icmp "eq" %22, %8 : i64
          "llvm.intr.assume"(%23) : (i1) -> ()
          %24 = llvm.ptrtoint %arg1 : !llvm.ptr<1> to i64
          %25 = llvm.and %24, %0  : i64
          %26 = llvm.icmp "eq" %25, %8 : i64
          "llvm.intr.assume"(%26) : (i1) -> ()
          %27 = nvvm.read.ptx.sreg.ctaid.x : i32
          %28 = llvm.sext %27 : i32 to i64
          %29 = llvm.icmp "sle" %19, %8 : i64
          %30 = llvm.sub %8, %19  : i64
          %31 = llvm.sub %19, %9  : i64
          %32 = llvm.select %29, %30, %31 : i1, i64
          %33 = llvm.sdiv %32, %6  : i64
          %34 = llvm.sub %8, %33  : i64
          %35 = llvm.add %33, %9  : i64
          %36 = llvm.select %29, %34, %35 : i1, i64
          %37 = llvm.icmp "slt" %28, %8 : i64
          %38 = llvm.sub %5, %28  : i64
          %39 = llvm.select %37, %38, %28 : i1, i64
          %40 = llvm.sdiv %39, %36  : i64
          %41 = llvm.sub %5, %40  : i64
          %42 = llvm.select %37, %41, %40 : i1, i64
          %43 = llvm.mul %42, %4  : i64
          %44 = llvm.add %15, %43  : i64
          %45 = llvm.icmp "sgt" %44, %7 : i64
          %46 = llvm.select %45, %7, %44 : i1, i64
          %47 = llvm.srem %28, %36  : i64
          %48 = llvm.icmp "slt" %47, %8 : i64
          %49 = llvm.add %47, %36  : i64
          %50 = llvm.select %48, %49, %47 : i1, i64
          %51 = llvm.mul %50, %3  : i64
          %52 = llvm.add %19, %51  : i64
          %53 = llvm.icmp "sgt" %52, %6 : i64
          %54 = llvm.select %53, %6, %52 : i1, i64
          %55 = nvvm.read.ptx.sreg.tid.x : i32
          %56 = llvm.sext %55 : i32 to i64
          %57 = nvvm.read.ptx.sreg.tid.y : i32
          %58 = llvm.sext %57 : i32 to i64
          %59 = llvm.icmp "sle" %46, %8 : i64
          %60 = llvm.sub %8, %46  : i64
          %61 = llvm.sub %46, %9  : i64
          %62 = llvm.select %59, %60, %61 : i1, i64
          %63 = llvm.sdiv %62, %2  : i64
          %64 = llvm.sub %8, %63  : i64
          %65 = llvm.add %63, %9  : i64
          %66 = llvm.select %59, %64, %65 : i1, i64
          %67 = llvm.mul %58, %66  : i64
          %68 = llvm.sub %46, %67  : i64
          %69 = llvm.icmp "slt" %68, %66 : i64
          %70 = llvm.select %69, %68, %66 : i1, i64
          %71 = llvm.icmp "slt" %70, %8 : i64
          %72 = llvm.select %71, %8, %70 : i1, i64
          %73 = llvm.icmp "sle" %54, %8 : i64
          %74 = llvm.sub %8, %54  : i64
          %75 = llvm.sub %54, %9  : i64
          %76 = llvm.select %73, %74, %75 : i1, i64
          %77 = llvm.sdiv %76, %7  : i64
          %78 = llvm.sub %8, %77  : i64
          %79 = llvm.add %77, %9  : i64
          %80 = llvm.select %73, %78, %79 : i1, i64
          %81 = llvm.mul %56, %80  : i64
          %82 = llvm.sub %54, %81  : i64
          %83 = llvm.icmp "slt" %82, %80 : i64
          %84 = llvm.select %83, %82, %80 : i1, i64
          %85 = llvm.icmp "slt" %84, %8 : i64
          %86 = llvm.select %85, %8, %84 : i1, i64
          %87 = llvm.mul %42, %7  : i64
          %88 = llvm.add %87, %67  : i64
          %89 = llvm.mul %50, %6  : i64
          %90 = llvm.add %89, %81  : i64
          llvm.br ^bb1(%8 : i64)
        ^bb1(%91: i64):  // 2 preds: ^bb0, ^bb5
          %92 = llvm.icmp "slt" %91, %72 : i64
          llvm.cond_br %92, ^bb2, ^bb6(%8 : i64)
        ^bb2:  // pred: ^bb1
          %93 = llvm.add %88, %91  : i64
          llvm.br ^bb3(%8 : i64)
        ^bb3(%94: i64):  // 2 preds: ^bb2, ^bb4
          %95 = llvm.icmp "slt" %94, %86 : i64
          llvm.cond_br %95, ^bb4, ^bb5
        ^bb4:  // pred: ^bb3
          %96 = llvm.add %90, %94  : i64
          %97 = llvm.mul %93, %20  : i64
          %98 = llvm.add %97, %96  : i64
          %99 = llvm.getelementptr %arg1[%98] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          llvm.store %11, %99 : f32, !llvm.ptr<1>
          %100 = llvm.add %94, %9  : i64
          llvm.br ^bb3(%100 : i64)
        ^bb5:  // pred: ^bb3
          %101 = llvm.add %91, %9  : i64
          llvm.br ^bb1(%101 : i64)
        ^bb6(%102: i64):  // 2 preds: ^bb1, ^bb12
          %103 = llvm.icmp "slt" %102, %19 : i64
          llvm.cond_br %103, ^bb7(%8 : i64), ^bb13
        ^bb7(%104: i64):  // 2 preds: ^bb6, ^bb11
          %105 = llvm.icmp "slt" %104, %72 : i64
          llvm.cond_br %105, ^bb8, ^bb12
        ^bb8:  // pred: ^bb7
          %106 = llvm.add %88, %104  : i64
          llvm.br ^bb9(%8 : i64)
        ^bb9(%107: i64):  // 2 preds: ^bb8, ^bb10
          %108 = llvm.icmp "slt" %107, %86 : i64
          llvm.cond_br %108, ^bb10, ^bb11
        ^bb10:  // pred: ^bb9
          %109 = llvm.mul %106, %20  : i64
          %110 = llvm.add %109, %102  : i64
          %111 = llvm.getelementptr %arg0[%110] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %112 = llvm.load %111 : !llvm.ptr<1> -> f32
          %113 = llvm.add %90, %107  : i64
          %114 = llvm.mul %102, %20  : i64
          %115 = llvm.add %114, %113  : i64
          %116 = llvm.getelementptr %arg0[%115] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %117 = llvm.load %116 : !llvm.ptr<1> -> f32
          %118 = llvm.add %109, %113  : i64
          %119 = llvm.getelementptr %arg1[%118] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %120 = llvm.load %119 : !llvm.ptr<1> -> f32
          %121 = llvm.fmul %112, %117  : f32
          %122 = llvm.fadd %120, %121  : f32
          llvm.store %122, %119 : f32, !llvm.ptr<1>
          %123 = llvm.add %107, %9  : i64
          llvm.br ^bb9(%123 : i64)
        ^bb11:  // pred: ^bb9
          %124 = llvm.add %104, %9  : i64
          llvm.br ^bb7(%124 : i64)
        ^bb12:  // pred: ^bb7
          %125 = llvm.add %102, %9  : i64
          llvm.br ^bb6(%125 : i64)
        ^bb13:  // pred: ^bb6
          llvm.return
        }
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c1 = arith.constant 1 : index
    %c-1 = arith.constant -1 : index
    %c-1_i32 = arith.constant -1 : i32
    %c0_i64 = arith.constant 0 : i64
    %c-1_i64 = arith.constant -1 : i64
    %c32_i64 = arith.constant 32 : i64
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %4 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%3}
    %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    %5 = arith.index_castui %0 : index to i64
    %6 = arith.trunci %5 : i64 to i32
    %7 = arith.shrui %5, %c32_i64 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %1 : index to i64
    %10 = arith.trunci %9 : i64 to i32
    %11 = arith.shrui %9, %c32_i64 : i64
    %12 = arith.trunci %11 : i64 to i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %13 = arith.select %_device_query_0, %c0, %c-1 : index
    scf.index_switch %13 
    case 0 {
      %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
      hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout) offset(0) values([%6, %8, %10, %12]) : i32, i32, i32, i32
      hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
        %c0 = (%buffer : !hal.buffer)[%c0, %3], 
        %c1 = (%transient_buffer : !hal.buffer)[%c0, %3]
      ])
      %14 = affine.apply #map()[%1, %0]
      %_executable_main_dispatch_0 = util.global.load @_executable_main_dispatch_0 : !hal.executable
      hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_main_dispatch_0 : !hal.executable)[0] workgroups([%14, %c1, %c1])
      scf.yield
    }
    default {
    }
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_0 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status_1 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence_0) commands([%cmd])
    %status_2 = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status_2, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %3] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.initializer {
  %device = hal.ex.shared_device : !hal.device
  %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer>]) : !hal.descriptor_set_layout
  util.global.store %descriptor_set_layout, @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  util.initializer.return
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.initializer {
  %device = hal.ex.shared_device : !hal.device
  %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
  util.global.store %value, @_device_query_0 : i1
  util.global.store %ok, @_device_query_0_ok : i1
  util.initializer.return
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.initializer {
  %_descriptor_set_layout_0 = util.global.load @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  %device = hal.ex.shared_device : !hal.device
  %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(4) layouts([%_descriptor_set_layout_0]) : !hal.pipeline_layout
  util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
  util.initializer.return
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.initializer {
  %_device_query_0 = util.global.load @_device_query_0 : i1
  %c0 = arith.constant 0 : index
  %c-1 = arith.constant -1 : index
  %device = hal.ex.shared_device : !hal.device
  %0 = arith.select %_device_query_0, %c0, %c-1 : index
  %1 = scf.index_switch %0 -> !hal.executable 
  case 0 {
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device : !hal.device) target(@main_dispatch_0::@cuda_nvptx_fb) layouts([%_pipeline_layout_0]) : !hal.executable
    scf.yield %exe : !hal.executable
  }
  default {
    %2 = util.null : !hal.executable
    scf.yield %2 : !hal.executable
  }
  util.global.store %1, @_executable_main_dispatch_0 : !hal.executable
  util.initializer.return
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %_device_query_0 = util.global.load @_device_query_0 : i1
  %c1 = arith.constant 1 : index
  %c-1 = arith.constant -1 : index
  %c-1_i32 = arith.constant -1 : i32
  %c0_i64 = arith.constant 0 : i64
  %c-1_i64 = arith.constant -1 : i64
  %c32_i64 = arith.constant 32 : i64
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %device = hal.ex.shared_device : !hal.device
  %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %4 = util.null : !hal.fence
  %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
  %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%3}
  %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
  %5 = arith.index_castui %0 : index to i64
  %6 = arith.trunci %5 : i64 to i32
  %7 = arith.shrui %5, %c32_i64 : i64
  %8 = arith.trunci %7 : i64 to i32
  %9 = arith.index_castui %1 : index to i64
  %10 = arith.trunci %9 : i64 to i32
  %11 = arith.shrui %9, %c32_i64 : i64
  %12 = arith.trunci %11 : i64 to i32
  %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
  %13 = arith.select %_device_query_0, %c0, %c-1 : index
  scf.index_switch %13 
  case 0 {
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout) offset(0) values([%6, %8, %10, %12]) : i32, i32, i32, i32
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%buffer : !hal.buffer)[%c0, %3], 
      %c1 = (%transient_buffer : !hal.buffer)[%c0, %3]
    ])
    %14 = affine.apply affine_map<()[s0, s1] -> ((s0 ceildiv 128) * (s1 ceildiv 32))>()[%1, %0]
    %_executable_main_dispatch_0 = util.global.load @_executable_main_dispatch_0 : !hal.executable
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_main_dispatch_0 : !hal.executable)[0] workgroups([%14, %c1, %c1])
    scf.yield
  }
  default {
  }
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  %fence_0 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
  %status_1 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
  hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence_0) commands([%cmd])
  %status_2 = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) : i32
  util.status.check_ok %status_2, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %3] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
  return %view : !hal.buffer_view
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<()[s0, s1] -> ((s0 ceildiv 128) * (s1 ceildiv 32))>
#pipeline_layout = #hal.pipeline.layout<push_constants = 4, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer>]>]>
#translation = #iree_codegen.translation_info<LLVMGPUMatmulSimt>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private @_device_query_0 : i1
  util.global private @_device_query_0_ok : i1
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    util.global.store %value, @_device_query_0 : i1
    util.global.store %ok, @_device_query_0_ok : i1
    util.initializer.return
  }
  util.global private @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer>]) : !hal.descriptor_set_layout
    util.global.store %descriptor_set_layout, @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    util.initializer.return
  }
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.initializer {
    %_descriptor_set_layout_0 = util.global.load @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    %device = hal.ex.shared_device : !hal.device
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(4) layouts([%_descriptor_set_layout_0]) : !hal.pipeline_layout
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    util.initializer.return
  }
  util.global private @_executable_main_dispatch_0 : !hal.executable
  util.initializer {
    %c-1 = arith.constant -1 : index
    %c0 = arith.constant 0 : index
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %device = hal.ex.shared_device : !hal.device
    %0 = arith.select %_device_query_0, %c0, %c-1 : index
    %1 = scf.index_switch %0 -> !hal.executable 
    case 0 {
      %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
      %exe = hal.executable.create device(%device : !hal.device) target(@main_dispatch_0::@cuda_nvptx_fb) layouts([%_pipeline_layout_0]) : !hal.executable
      scf.yield %exe : !hal.executable
    }
    default {
      %2 = util.null : !hal.executable
      scf.yield %2 : !hal.executable
    }
    util.global.store %1, @_executable_main_dispatch_0 : !hal.executable
    util.initializer.return
  }
  hal.executable private @main_dispatch_0 {
    hal.executable.variant public @cuda_nvptx_fb target(#executable_target_cuda_nvptx_fb) {
      hal.executable.export public @main_dispatch_0_matmul_DxDxD_f32 ordinal(0) layout(#pipeline_layout) attributes {translation_info = #translation, workgroup_size = [32 : index, 8 : index, 1 : index]} {
      ^bb0(%arg0: !hal.device, %arg1: index, %arg2: index):
        %c1 = arith.constant 1 : index
        %0 = affine.apply #map()[%arg2, %arg1]
        hal.return %0, %c1, %c1 : index, index, index
      }
      builtin.module {
        llvm.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias}, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32) {
          %0 = llvm.mlir.constant(63 : index) : i64
          %1 = llvm.mlir.constant(1 : i64) : i64
          %2 = llvm.mlir.constant(8 : index) : i64
          %3 = llvm.mlir.constant(-128 : index) : i64
          %4 = llvm.mlir.constant(-32 : index) : i64
          %5 = llvm.mlir.constant(-1 : index) : i64
          %6 = llvm.mlir.constant(128 : index) : i64
          %7 = llvm.mlir.constant(32 : index) : i64
          %8 = llvm.mlir.constant(0 : index) : i64
          %9 = llvm.mlir.constant(1 : index) : i64
          %10 = llvm.mlir.constant(32 : i64) : i64
          %11 = llvm.mlir.constant(0.000000e+00 : f32) : f32
          %12 = llvm.zext %arg2 : i32 to i64
          %13 = llvm.zext %arg3 : i32 to i64
          %14 = llvm.shl %13, %10  : i64
          %15 = llvm.or %12, %14  : i64
          %16 = llvm.zext %arg4 : i32 to i64
          %17 = llvm.zext %arg5 : i32 to i64
          %18 = llvm.shl %17, %10  : i64
          %19 = llvm.or %16, %18  : i64
          %20 = llvm.mul %19, %1  : i64
          %21 = llvm.ptrtoint %arg0 : !llvm.ptr<1> to i64
          %22 = llvm.and %21, %0  : i64
          %23 = llvm.icmp "eq" %22, %8 : i64
          "llvm.intr.assume"(%23) : (i1) -> ()
          %24 = llvm.ptrtoint %arg1 : !llvm.ptr<1> to i64
          %25 = llvm.and %24, %0  : i64
          %26 = llvm.icmp "eq" %25, %8 : i64
          "llvm.intr.assume"(%26) : (i1) -> ()
          %27 = nvvm.read.ptx.sreg.ctaid.x : i32
          %28 = llvm.sext %27 : i32 to i64
          %29 = llvm.icmp "sle" %19, %8 : i64
          %30 = llvm.sub %8, %19  : i64
          %31 = llvm.sub %19, %9  : i64
          %32 = llvm.select %29, %30, %31 : i1, i64
          %33 = llvm.sdiv %32, %6  : i64
          %34 = llvm.sub %8, %33  : i64
          %35 = llvm.add %33, %9  : i64
          %36 = llvm.select %29, %34, %35 : i1, i64
          %37 = llvm.icmp "slt" %28, %8 : i64
          %38 = llvm.sub %5, %28  : i64
          %39 = llvm.select %37, %38, %28 : i1, i64
          %40 = llvm.sdiv %39, %36  : i64
          %41 = llvm.sub %5, %40  : i64
          %42 = llvm.select %37, %41, %40 : i1, i64
          %43 = llvm.mul %42, %4  : i64
          %44 = llvm.add %15, %43  : i64
          %45 = llvm.icmp "sgt" %44, %7 : i64
          %46 = llvm.select %45, %7, %44 : i1, i64
          %47 = llvm.srem %28, %36  : i64
          %48 = llvm.icmp "slt" %47, %8 : i64
          %49 = llvm.add %47, %36  : i64
          %50 = llvm.select %48, %49, %47 : i1, i64
          %51 = llvm.mul %50, %3  : i64
          %52 = llvm.add %19, %51  : i64
          %53 = llvm.icmp "sgt" %52, %6 : i64
          %54 = llvm.select %53, %6, %52 : i1, i64
          %55 = nvvm.read.ptx.sreg.tid.x : i32
          %56 = llvm.sext %55 : i32 to i64
          %57 = nvvm.read.ptx.sreg.tid.y : i32
          %58 = llvm.sext %57 : i32 to i64
          %59 = llvm.icmp "sle" %46, %8 : i64
          %60 = llvm.sub %8, %46  : i64
          %61 = llvm.sub %46, %9  : i64
          %62 = llvm.select %59, %60, %61 : i1, i64
          %63 = llvm.sdiv %62, %2  : i64
          %64 = llvm.sub %8, %63  : i64
          %65 = llvm.add %63, %9  : i64
          %66 = llvm.select %59, %64, %65 : i1, i64
          %67 = llvm.mul %58, %66  : i64
          %68 = llvm.sub %46, %67  : i64
          %69 = llvm.icmp "slt" %68, %66 : i64
          %70 = llvm.select %69, %68, %66 : i1, i64
          %71 = llvm.icmp "slt" %70, %8 : i64
          %72 = llvm.select %71, %8, %70 : i1, i64
          %73 = llvm.icmp "sle" %54, %8 : i64
          %74 = llvm.sub %8, %54  : i64
          %75 = llvm.sub %54, %9  : i64
          %76 = llvm.select %73, %74, %75 : i1, i64
          %77 = llvm.sdiv %76, %7  : i64
          %78 = llvm.sub %8, %77  : i64
          %79 = llvm.add %77, %9  : i64
          %80 = llvm.select %73, %78, %79 : i1, i64
          %81 = llvm.mul %56, %80  : i64
          %82 = llvm.sub %54, %81  : i64
          %83 = llvm.icmp "slt" %82, %80 : i64
          %84 = llvm.select %83, %82, %80 : i1, i64
          %85 = llvm.icmp "slt" %84, %8 : i64
          %86 = llvm.select %85, %8, %84 : i1, i64
          %87 = llvm.mul %42, %7  : i64
          %88 = llvm.add %87, %67  : i64
          %89 = llvm.mul %50, %6  : i64
          %90 = llvm.add %89, %81  : i64
          llvm.br ^bb1(%8 : i64)
        ^bb1(%91: i64):  // 2 preds: ^bb0, ^bb5
          %92 = llvm.icmp "slt" %91, %72 : i64
          llvm.cond_br %92, ^bb2, ^bb6(%8 : i64)
        ^bb2:  // pred: ^bb1
          %93 = llvm.add %88, %91  : i64
          llvm.br ^bb3(%8 : i64)
        ^bb3(%94: i64):  // 2 preds: ^bb2, ^bb4
          %95 = llvm.icmp "slt" %94, %86 : i64
          llvm.cond_br %95, ^bb4, ^bb5
        ^bb4:  // pred: ^bb3
          %96 = llvm.add %90, %94  : i64
          %97 = llvm.mul %93, %20  : i64
          %98 = llvm.add %97, %96  : i64
          %99 = llvm.getelementptr %arg1[%98] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          llvm.store %11, %99 : f32, !llvm.ptr<1>
          %100 = llvm.add %94, %9  : i64
          llvm.br ^bb3(%100 : i64)
        ^bb5:  // pred: ^bb3
          %101 = llvm.add %91, %9  : i64
          llvm.br ^bb1(%101 : i64)
        ^bb6(%102: i64):  // 2 preds: ^bb1, ^bb12
          %103 = llvm.icmp "slt" %102, %19 : i64
          llvm.cond_br %103, ^bb7(%8 : i64), ^bb13
        ^bb7(%104: i64):  // 2 preds: ^bb6, ^bb11
          %105 = llvm.icmp "slt" %104, %72 : i64
          llvm.cond_br %105, ^bb8, ^bb12
        ^bb8:  // pred: ^bb7
          %106 = llvm.add %88, %104  : i64
          llvm.br ^bb9(%8 : i64)
        ^bb9(%107: i64):  // 2 preds: ^bb8, ^bb10
          %108 = llvm.icmp "slt" %107, %86 : i64
          llvm.cond_br %108, ^bb10, ^bb11
        ^bb10:  // pred: ^bb9
          %109 = llvm.mul %106, %20  : i64
          %110 = llvm.add %109, %102  : i64
          %111 = llvm.getelementptr %arg0[%110] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %112 = llvm.load %111 : !llvm.ptr<1> -> f32
          %113 = llvm.add %90, %107  : i64
          %114 = llvm.mul %102, %20  : i64
          %115 = llvm.add %114, %113  : i64
          %116 = llvm.getelementptr %arg0[%115] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %117 = llvm.load %116 : !llvm.ptr<1> -> f32
          %118 = llvm.add %109, %113  : i64
          %119 = llvm.getelementptr %arg1[%118] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %120 = llvm.load %119 : !llvm.ptr<1> -> f32
          %121 = llvm.fmul %112, %117  : f32
          %122 = llvm.fadd %120, %121  : f32
          llvm.store %122, %119 : f32, !llvm.ptr<1>
          %123 = llvm.add %107, %9  : i64
          llvm.br ^bb9(%123 : i64)
        ^bb11:  // pred: ^bb9
          %124 = llvm.add %104, %9  : i64
          llvm.br ^bb7(%124 : i64)
        ^bb12:  // pred: ^bb7
          %125 = llvm.add %102, %9  : i64
          llvm.br ^bb6(%125 : i64)
        ^bb13:  // pred: ^bb6
          llvm.return
        }
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c32_i64 = arith.constant 32 : i64
    %c-1_i64 = arith.constant -1 : i64
    %c0_i64 = arith.constant 0 : i64
    %c-1_i32 = arith.constant -1 : i32
    %c-1 = arith.constant -1 : index
    %c1 = arith.constant 1 : index
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %4 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%3}
    %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    %5 = arith.index_castui %0 : index to i64
    %6 = arith.trunci %5 : i64 to i32
    %7 = arith.shrui %5, %c32_i64 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %1 : index to i64
    %10 = arith.trunci %9 : i64 to i32
    %11 = arith.shrui %9, %c32_i64 : i64
    %12 = arith.trunci %11 : i64 to i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    %13 = arith.select %_device_query_0, %c0, %c-1 : index
    scf.index_switch %13 
    case 0 {
      %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
      hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout) offset(0) values([%6, %8, %10, %12]) : i32, i32, i32, i32
      hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
        %c0 = (%buffer : !hal.buffer)[%c0, %3], 
        %c1 = (%transient_buffer : !hal.buffer)[%c0, %3]
      ])
      %14 = affine.apply #map()[%1, %0]
      %_executable_main_dispatch_0 = util.global.load @_executable_main_dispatch_0 : !hal.executable
      hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_main_dispatch_0 : !hal.executable)[0] workgroups([%14, %c1, %c1])
      scf.yield
    }
    default {
    }
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_0 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status_1 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence_0) commands([%cmd])
    %status_2 = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status_2, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %3] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<()[s0, s1] -> ((s0 ceildiv 128) * (s1 ceildiv 32))>
#pipeline_layout = #hal.pipeline.layout<push_constants = 4, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer>]>]>
#translation = #iree_codegen.translation_info<LLVMGPUMatmulSimt>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private @_device_query_0 : i1
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    util.global.store %value, @_device_query_0 : i1
    util.initializer.return
  }
  util.global private @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer>]) : !hal.descriptor_set_layout
    util.global.store %descriptor_set_layout, @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    util.initializer.return
  }
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.initializer {
    %_descriptor_set_layout_0 = util.global.load @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    %device = hal.ex.shared_device : !hal.device
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(4) layouts([%_descriptor_set_layout_0]) : !hal.pipeline_layout
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    util.initializer.return
  }
  util.global private @_executable_main_dispatch_0 : !hal.executable
  util.initializer {
    %c-1 = arith.constant -1 : index
    %c0 = arith.constant 0 : index
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %device = hal.ex.shared_device : !hal.device
    %0 = arith.select %_device_query_0, %c0, %c-1 : index
    %1 = scf.index_switch %0 -> !hal.executable 
    case 0 {
      %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
      %exe = hal.executable.create device(%device : !hal.device) target(@main_dispatch_0::@cuda_nvptx_fb) layouts([%_pipeline_layout_0]) : !hal.executable
      scf.yield %exe : !hal.executable
    }
    default {
      %2 = util.null : !hal.executable
      scf.yield %2 : !hal.executable
    }
    util.global.store %1, @_executable_main_dispatch_0 : !hal.executable
    util.initializer.return
  }
  hal.executable private @main_dispatch_0 {
    hal.executable.variant public @cuda_nvptx_fb target(#executable_target_cuda_nvptx_fb) {
      hal.executable.export public @main_dispatch_0_matmul_DxDxD_f32 ordinal(0) layout(#pipeline_layout) attributes {translation_info = #translation, workgroup_size = [32 : index, 8 : index, 1 : index]} {
      ^bb0(%arg0: !hal.device, %arg1: index, %arg2: index):
        %c1 = arith.constant 1 : index
        %0 = affine.apply #map()[%arg2, %arg1]
        hal.return %0, %c1, %c1 : index, index, index
      }
      builtin.module {
        llvm.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias}, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32) {
          %0 = llvm.mlir.constant(63 : index) : i64
          %1 = llvm.mlir.constant(1 : i64) : i64
          %2 = llvm.mlir.constant(8 : index) : i64
          %3 = llvm.mlir.constant(-128 : index) : i64
          %4 = llvm.mlir.constant(-32 : index) : i64
          %5 = llvm.mlir.constant(-1 : index) : i64
          %6 = llvm.mlir.constant(128 : index) : i64
          %7 = llvm.mlir.constant(32 : index) : i64
          %8 = llvm.mlir.constant(0 : index) : i64
          %9 = llvm.mlir.constant(1 : index) : i64
          %10 = llvm.mlir.constant(32 : i64) : i64
          %11 = llvm.mlir.constant(0.000000e+00 : f32) : f32
          %12 = llvm.zext %arg2 : i32 to i64
          %13 = llvm.zext %arg3 : i32 to i64
          %14 = llvm.shl %13, %10  : i64
          %15 = llvm.or %12, %14  : i64
          %16 = llvm.zext %arg4 : i32 to i64
          %17 = llvm.zext %arg5 : i32 to i64
          %18 = llvm.shl %17, %10  : i64
          %19 = llvm.or %16, %18  : i64
          %20 = llvm.mul %19, %1  : i64
          %21 = llvm.ptrtoint %arg0 : !llvm.ptr<1> to i64
          %22 = llvm.and %21, %0  : i64
          %23 = llvm.icmp "eq" %22, %8 : i64
          "llvm.intr.assume"(%23) : (i1) -> ()
          %24 = llvm.ptrtoint %arg1 : !llvm.ptr<1> to i64
          %25 = llvm.and %24, %0  : i64
          %26 = llvm.icmp "eq" %25, %8 : i64
          "llvm.intr.assume"(%26) : (i1) -> ()
          %27 = nvvm.read.ptx.sreg.ctaid.x : i32
          %28 = llvm.sext %27 : i32 to i64
          %29 = llvm.icmp "sle" %19, %8 : i64
          %30 = llvm.sub %8, %19  : i64
          %31 = llvm.sub %19, %9  : i64
          %32 = llvm.select %29, %30, %31 : i1, i64
          %33 = llvm.sdiv %32, %6  : i64
          %34 = llvm.sub %8, %33  : i64
          %35 = llvm.add %33, %9  : i64
          %36 = llvm.select %29, %34, %35 : i1, i64
          %37 = llvm.icmp "slt" %28, %8 : i64
          %38 = llvm.sub %5, %28  : i64
          %39 = llvm.select %37, %38, %28 : i1, i64
          %40 = llvm.sdiv %39, %36  : i64
          %41 = llvm.sub %5, %40  : i64
          %42 = llvm.select %37, %41, %40 : i1, i64
          %43 = llvm.mul %42, %4  : i64
          %44 = llvm.add %15, %43  : i64
          %45 = llvm.icmp "sgt" %44, %7 : i64
          %46 = llvm.select %45, %7, %44 : i1, i64
          %47 = llvm.srem %28, %36  : i64
          %48 = llvm.icmp "slt" %47, %8 : i64
          %49 = llvm.add %47, %36  : i64
          %50 = llvm.select %48, %49, %47 : i1, i64
          %51 = llvm.mul %50, %3  : i64
          %52 = llvm.add %19, %51  : i64
          %53 = llvm.icmp "sgt" %52, %6 : i64
          %54 = llvm.select %53, %6, %52 : i1, i64
          %55 = nvvm.read.ptx.sreg.tid.x : i32
          %56 = llvm.sext %55 : i32 to i64
          %57 = nvvm.read.ptx.sreg.tid.y : i32
          %58 = llvm.sext %57 : i32 to i64
          %59 = llvm.icmp "sle" %46, %8 : i64
          %60 = llvm.sub %8, %46  : i64
          %61 = llvm.sub %46, %9  : i64
          %62 = llvm.select %59, %60, %61 : i1, i64
          %63 = llvm.sdiv %62, %2  : i64
          %64 = llvm.sub %8, %63  : i64
          %65 = llvm.add %63, %9  : i64
          %66 = llvm.select %59, %64, %65 : i1, i64
          %67 = llvm.mul %58, %66  : i64
          %68 = llvm.sub %46, %67  : i64
          %69 = llvm.icmp "slt" %68, %66 : i64
          %70 = llvm.select %69, %68, %66 : i1, i64
          %71 = llvm.icmp "slt" %70, %8 : i64
          %72 = llvm.select %71, %8, %70 : i1, i64
          %73 = llvm.icmp "sle" %54, %8 : i64
          %74 = llvm.sub %8, %54  : i64
          %75 = llvm.sub %54, %9  : i64
          %76 = llvm.select %73, %74, %75 : i1, i64
          %77 = llvm.sdiv %76, %7  : i64
          %78 = llvm.sub %8, %77  : i64
          %79 = llvm.add %77, %9  : i64
          %80 = llvm.select %73, %78, %79 : i1, i64
          %81 = llvm.mul %56, %80  : i64
          %82 = llvm.sub %54, %81  : i64
          %83 = llvm.icmp "slt" %82, %80 : i64
          %84 = llvm.select %83, %82, %80 : i1, i64
          %85 = llvm.icmp "slt" %84, %8 : i64
          %86 = llvm.select %85, %8, %84 : i1, i64
          %87 = llvm.mul %42, %7  : i64
          %88 = llvm.add %87, %67  : i64
          %89 = llvm.mul %50, %6  : i64
          %90 = llvm.add %89, %81  : i64
          llvm.br ^bb1(%8 : i64)
        ^bb1(%91: i64):  // 2 preds: ^bb0, ^bb5
          %92 = llvm.icmp "slt" %91, %72 : i64
          llvm.cond_br %92, ^bb2, ^bb6(%8 : i64)
        ^bb2:  // pred: ^bb1
          %93 = llvm.add %88, %91  : i64
          llvm.br ^bb3(%8 : i64)
        ^bb3(%94: i64):  // 2 preds: ^bb2, ^bb4
          %95 = llvm.icmp "slt" %94, %86 : i64
          llvm.cond_br %95, ^bb4, ^bb5
        ^bb4:  // pred: ^bb3
          %96 = llvm.add %90, %94  : i64
          %97 = llvm.mul %93, %20  : i64
          %98 = llvm.add %97, %96  : i64
          %99 = llvm.getelementptr %arg1[%98] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          llvm.store %11, %99 : f32, !llvm.ptr<1>
          %100 = llvm.add %94, %9  : i64
          llvm.br ^bb3(%100 : i64)
        ^bb5:  // pred: ^bb3
          %101 = llvm.add %91, %9  : i64
          llvm.br ^bb1(%101 : i64)
        ^bb6(%102: i64):  // 2 preds: ^bb1, ^bb12
          %103 = llvm.icmp "slt" %102, %19 : i64
          llvm.cond_br %103, ^bb7(%8 : i64), ^bb13
        ^bb7(%104: i64):  // 2 preds: ^bb6, ^bb11
          %105 = llvm.icmp "slt" %104, %72 : i64
          llvm.cond_br %105, ^bb8, ^bb12
        ^bb8:  // pred: ^bb7
          %106 = llvm.add %88, %104  : i64
          llvm.br ^bb9(%8 : i64)
        ^bb9(%107: i64):  // 2 preds: ^bb8, ^bb10
          %108 = llvm.icmp "slt" %107, %86 : i64
          llvm.cond_br %108, ^bb10, ^bb11
        ^bb10:  // pred: ^bb9
          %109 = llvm.mul %106, %20  : i64
          %110 = llvm.add %109, %102  : i64
          %111 = llvm.getelementptr %arg0[%110] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %112 = llvm.load %111 : !llvm.ptr<1> -> f32
          %113 = llvm.add %90, %107  : i64
          %114 = llvm.mul %102, %20  : i64
          %115 = llvm.add %114, %113  : i64
          %116 = llvm.getelementptr %arg0[%115] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %117 = llvm.load %116 : !llvm.ptr<1> -> f32
          %118 = llvm.add %109, %113  : i64
          %119 = llvm.getelementptr %arg1[%118] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %120 = llvm.load %119 : !llvm.ptr<1> -> f32
          %121 = llvm.fmul %112, %117  : f32
          %122 = llvm.fadd %120, %121  : f32
          llvm.store %122, %119 : f32, !llvm.ptr<1>
          %123 = llvm.add %107, %9  : i64
          llvm.br ^bb9(%123 : i64)
        ^bb11:  // pred: ^bb9
          %124 = llvm.add %104, %9  : i64
          llvm.br ^bb7(%124 : i64)
        ^bb12:  // pred: ^bb7
          %125 = llvm.add %102, %9  : i64
          llvm.br ^bb6(%125 : i64)
        ^bb13:  // pred: ^bb6
          llvm.return
        }
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c32_i64 = arith.constant 32 : i64
    %c-1_i64 = arith.constant -1 : i64
    %c0_i64 = arith.constant 0 : i64
    %c-1_i32 = arith.constant -1 : i32
    %c-1 = arith.constant -1 : index
    %c1 = arith.constant 1 : index
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %4 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%3}
    %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    %5 = arith.index_castui %0 : index to i64
    %6 = arith.trunci %5 : i64 to i32
    %7 = arith.shrui %5, %c32_i64 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %1 : index to i64
    %10 = arith.trunci %9 : i64 to i32
    %11 = arith.shrui %9, %c32_i64 : i64
    %12 = arith.trunci %11 : i64 to i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    %13 = arith.select %_device_query_0, %c0, %c-1 : index
    scf.index_switch %13 
    case 0 {
      %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
      hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout) offset(0) values([%6, %8, %10, %12]) : i32, i32, i32, i32
      hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
        %c0 = (%buffer : !hal.buffer)[%c0, %3], 
        %c1 = (%transient_buffer : !hal.buffer)[%c0, %3]
      ])
      %14 = affine.apply #map()[%1, %0]
      %_executable_main_dispatch_0 = util.global.load @_executable_main_dispatch_0 : !hal.executable
      hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_main_dispatch_0 : !hal.executable)[0] workgroups([%14, %c1, %c1])
      scf.yield
    }
    default {
    }
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_0 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status_1 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence_0) commands([%cmd])
    %status_2 = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status_2, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %3] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<()[s0, s1] -> ((s0 ceildiv 128) * (s1 ceildiv 32))>
#pipeline_layout = #hal.pipeline.layout<push_constants = 4, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer>]>]>
#translation = #iree_codegen.translation_info<LLVMGPUMatmulSimt>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private @_device_query_0 : i1
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    util.global.store %value, @_device_query_0 : i1
    util.initializer.return
  }
  util.global private @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer>]) : !hal.descriptor_set_layout
    util.global.store %descriptor_set_layout, @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    util.initializer.return
  }
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.initializer {
    %_descriptor_set_layout_0 = util.global.load @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    %device = hal.ex.shared_device : !hal.device
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(4) layouts([%_descriptor_set_layout_0]) : !hal.pipeline_layout
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    util.initializer.return
  }
  util.global private @_executable_main_dispatch_0 : !hal.executable
  util.initializer {
    %c-1 = arith.constant -1 : index
    %c0 = arith.constant 0 : index
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %device = hal.ex.shared_device : !hal.device
    %0 = arith.select %_device_query_0, %c0, %c-1 : index
    %1 = scf.index_switch %0 -> !hal.executable 
    case 0 {
      %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
      %exe = hal.executable.create device(%device : !hal.device) target(@main_dispatch_0::@cuda_nvptx_fb) layouts([%_pipeline_layout_0]) : !hal.executable
      scf.yield %exe : !hal.executable
    }
    default {
      %2 = util.null : !hal.executable
      scf.yield %2 : !hal.executable
    }
    util.global.store %1, @_executable_main_dispatch_0 : !hal.executable
    util.initializer.return
  }
  hal.executable private @main_dispatch_0 {
    hal.executable.variant public @cuda_nvptx_fb target(#executable_target_cuda_nvptx_fb) {
      hal.executable.export public @main_dispatch_0_matmul_DxDxD_f32 ordinal(0) layout(#pipeline_layout) attributes {translation_info = #translation, workgroup_size = [32 : index, 8 : index, 1 : index]} {
      ^bb0(%arg0: !hal.device, %arg1: index, %arg2: index):
        %c1 = arith.constant 1 : index
        %0 = affine.apply #map()[%arg2, %arg1]
        hal.return %0, %c1, %c1 : index, index, index
      }
      builtin.module {
        llvm.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias}, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32) {
          %0 = llvm.mlir.constant(63 : index) : i64
          %1 = llvm.mlir.constant(1 : i64) : i64
          %2 = llvm.mlir.constant(8 : index) : i64
          %3 = llvm.mlir.constant(-128 : index) : i64
          %4 = llvm.mlir.constant(-32 : index) : i64
          %5 = llvm.mlir.constant(-1 : index) : i64
          %6 = llvm.mlir.constant(128 : index) : i64
          %7 = llvm.mlir.constant(32 : index) : i64
          %8 = llvm.mlir.constant(0 : index) : i64
          %9 = llvm.mlir.constant(1 : index) : i64
          %10 = llvm.mlir.constant(32 : i64) : i64
          %11 = llvm.mlir.constant(0.000000e+00 : f32) : f32
          %12 = llvm.zext %arg2 : i32 to i64
          %13 = llvm.zext %arg3 : i32 to i64
          %14 = llvm.shl %13, %10  : i64
          %15 = llvm.or %12, %14  : i64
          %16 = llvm.zext %arg4 : i32 to i64
          %17 = llvm.zext %arg5 : i32 to i64
          %18 = llvm.shl %17, %10  : i64
          %19 = llvm.or %16, %18  : i64
          %20 = llvm.mul %19, %1  : i64
          %21 = llvm.ptrtoint %arg0 : !llvm.ptr<1> to i64
          %22 = llvm.and %21, %0  : i64
          %23 = llvm.icmp "eq" %22, %8 : i64
          "llvm.intr.assume"(%23) : (i1) -> ()
          %24 = llvm.ptrtoint %arg1 : !llvm.ptr<1> to i64
          %25 = llvm.and %24, %0  : i64
          %26 = llvm.icmp "eq" %25, %8 : i64
          "llvm.intr.assume"(%26) : (i1) -> ()
          %27 = nvvm.read.ptx.sreg.ctaid.x : i32
          %28 = llvm.sext %27 : i32 to i64
          %29 = llvm.icmp "sle" %19, %8 : i64
          %30 = llvm.sub %8, %19  : i64
          %31 = llvm.sub %19, %9  : i64
          %32 = llvm.select %29, %30, %31 : i1, i64
          %33 = llvm.sdiv %32, %6  : i64
          %34 = llvm.sub %8, %33  : i64
          %35 = llvm.add %33, %9  : i64
          %36 = llvm.select %29, %34, %35 : i1, i64
          %37 = llvm.icmp "slt" %28, %8 : i64
          %38 = llvm.sub %5, %28  : i64
          %39 = llvm.select %37, %38, %28 : i1, i64
          %40 = llvm.sdiv %39, %36  : i64
          %41 = llvm.sub %5, %40  : i64
          %42 = llvm.select %37, %41, %40 : i1, i64
          %43 = llvm.mul %42, %4  : i64
          %44 = llvm.add %15, %43  : i64
          %45 = llvm.icmp "sgt" %44, %7 : i64
          %46 = llvm.select %45, %7, %44 : i1, i64
          %47 = llvm.srem %28, %36  : i64
          %48 = llvm.icmp "slt" %47, %8 : i64
          %49 = llvm.add %47, %36  : i64
          %50 = llvm.select %48, %49, %47 : i1, i64
          %51 = llvm.mul %50, %3  : i64
          %52 = llvm.add %19, %51  : i64
          %53 = llvm.icmp "sgt" %52, %6 : i64
          %54 = llvm.select %53, %6, %52 : i1, i64
          %55 = nvvm.read.ptx.sreg.tid.x : i32
          %56 = llvm.sext %55 : i32 to i64
          %57 = nvvm.read.ptx.sreg.tid.y : i32
          %58 = llvm.sext %57 : i32 to i64
          %59 = llvm.icmp "sle" %46, %8 : i64
          %60 = llvm.sub %8, %46  : i64
          %61 = llvm.sub %46, %9  : i64
          %62 = llvm.select %59, %60, %61 : i1, i64
          %63 = llvm.sdiv %62, %2  : i64
          %64 = llvm.sub %8, %63  : i64
          %65 = llvm.add %63, %9  : i64
          %66 = llvm.select %59, %64, %65 : i1, i64
          %67 = llvm.mul %58, %66  : i64
          %68 = llvm.sub %46, %67  : i64
          %69 = llvm.icmp "slt" %68, %66 : i64
          %70 = llvm.select %69, %68, %66 : i1, i64
          %71 = llvm.icmp "slt" %70, %8 : i64
          %72 = llvm.select %71, %8, %70 : i1, i64
          %73 = llvm.icmp "sle" %54, %8 : i64
          %74 = llvm.sub %8, %54  : i64
          %75 = llvm.sub %54, %9  : i64
          %76 = llvm.select %73, %74, %75 : i1, i64
          %77 = llvm.sdiv %76, %7  : i64
          %78 = llvm.sub %8, %77  : i64
          %79 = llvm.add %77, %9  : i64
          %80 = llvm.select %73, %78, %79 : i1, i64
          %81 = llvm.mul %56, %80  : i64
          %82 = llvm.sub %54, %81  : i64
          %83 = llvm.icmp "slt" %82, %80 : i64
          %84 = llvm.select %83, %82, %80 : i1, i64
          %85 = llvm.icmp "slt" %84, %8 : i64
          %86 = llvm.select %85, %8, %84 : i1, i64
          %87 = llvm.mul %42, %7  : i64
          %88 = llvm.add %87, %67  : i64
          %89 = llvm.mul %50, %6  : i64
          %90 = llvm.add %89, %81  : i64
          llvm.br ^bb1(%8 : i64)
        ^bb1(%91: i64):  // 2 preds: ^bb0, ^bb5
          %92 = llvm.icmp "slt" %91, %72 : i64
          llvm.cond_br %92, ^bb2, ^bb6(%8 : i64)
        ^bb2:  // pred: ^bb1
          %93 = llvm.add %88, %91  : i64
          llvm.br ^bb3(%8 : i64)
        ^bb3(%94: i64):  // 2 preds: ^bb2, ^bb4
          %95 = llvm.icmp "slt" %94, %86 : i64
          llvm.cond_br %95, ^bb4, ^bb5
        ^bb4:  // pred: ^bb3
          %96 = llvm.add %90, %94  : i64
          %97 = llvm.mul %93, %20  : i64
          %98 = llvm.add %97, %96  : i64
          %99 = llvm.getelementptr %arg1[%98] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          llvm.store %11, %99 : f32, !llvm.ptr<1>
          %100 = llvm.add %94, %9  : i64
          llvm.br ^bb3(%100 : i64)
        ^bb5:  // pred: ^bb3
          %101 = llvm.add %91, %9  : i64
          llvm.br ^bb1(%101 : i64)
        ^bb6(%102: i64):  // 2 preds: ^bb1, ^bb12
          %103 = llvm.icmp "slt" %102, %19 : i64
          llvm.cond_br %103, ^bb7(%8 : i64), ^bb13
        ^bb7(%104: i64):  // 2 preds: ^bb6, ^bb11
          %105 = llvm.icmp "slt" %104, %72 : i64
          llvm.cond_br %105, ^bb8, ^bb12
        ^bb8:  // pred: ^bb7
          %106 = llvm.add %88, %104  : i64
          llvm.br ^bb9(%8 : i64)
        ^bb9(%107: i64):  // 2 preds: ^bb8, ^bb10
          %108 = llvm.icmp "slt" %107, %86 : i64
          llvm.cond_br %108, ^bb10, ^bb11
        ^bb10:  // pred: ^bb9
          %109 = llvm.mul %106, %20  : i64
          %110 = llvm.add %109, %102  : i64
          %111 = llvm.getelementptr %arg0[%110] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %112 = llvm.load %111 : !llvm.ptr<1> -> f32
          %113 = llvm.add %90, %107  : i64
          %114 = llvm.mul %102, %20  : i64
          %115 = llvm.add %114, %113  : i64
          %116 = llvm.getelementptr %arg0[%115] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %117 = llvm.load %116 : !llvm.ptr<1> -> f32
          %118 = llvm.add %109, %113  : i64
          %119 = llvm.getelementptr %arg1[%118] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %120 = llvm.load %119 : !llvm.ptr<1> -> f32
          %121 = llvm.fmul %112, %117  : f32
          %122 = llvm.fadd %120, %121  : f32
          llvm.store %122, %119 : f32, !llvm.ptr<1>
          %123 = llvm.add %107, %9  : i64
          llvm.br ^bb9(%123 : i64)
        ^bb11:  // pred: ^bb9
          %124 = llvm.add %104, %9  : i64
          llvm.br ^bb7(%124 : i64)
        ^bb12:  // pred: ^bb7
          %125 = llvm.add %102, %9  : i64
          llvm.br ^bb6(%125 : i64)
        ^bb13:  // pred: ^bb6
          llvm.return
        }
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c32_i64 = arith.constant 32 : i64
    %c-1_i64 = arith.constant -1 : i64
    %c0_i64 = arith.constant 0 : i64
    %c-1_i32 = arith.constant -1 : i32
    %c-1 = arith.constant -1 : index
    %c1 = arith.constant 1 : index
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %4 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%3}
    %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    %5 = arith.index_castui %0 : index to i64
    %6 = arith.trunci %5 : i64 to i32
    %7 = arith.shrui %5, %c32_i64 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %1 : index to i64
    %10 = arith.trunci %9 : i64 to i32
    %11 = arith.shrui %9, %c32_i64 : i64
    %12 = arith.trunci %11 : i64 to i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    %13 = arith.select %_device_query_0, %c0, %c-1 : index
    scf.index_switch %13 
    case 0 {
      %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
      hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout) offset(0) values([%6, %8, %10, %12]) : i32, i32, i32, i32
      hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
        %c0 = (%buffer : !hal.buffer)[%c0, %3], 
        %c1 = (%transient_buffer : !hal.buffer)[%c0, %3]
      ])
      %14 = affine.apply #map()[%1, %0]
      %_executable_main_dispatch_0 = util.global.load @_executable_main_dispatch_0 : !hal.executable
      hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_main_dispatch_0 : !hal.executable)[0] workgroups([%14, %c1, %c1])
      scf.yield
    }
    default {
    }
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_0 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status_1 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence_0) commands([%cmd])
    %status_2 = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status_2, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %3] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::HAL::ElideRedundantCommandsPass (iree-hal-elide-redundant-commands) //----- //
util.initializer {
  %device = hal.ex.shared_device : !hal.device
  %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
  util.global.store %value, @_device_query_0 : i1
  util.initializer.return
}

// -----// IR Dump After mlir::iree_compiler::IREE::HAL::ElideRedundantCommandsPass (iree-hal-elide-redundant-commands) //----- //
util.initializer {
  %device = hal.ex.shared_device : !hal.device
  %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer>]) : !hal.descriptor_set_layout
  util.global.store %descriptor_set_layout, @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  util.initializer.return
}

// -----// IR Dump After mlir::iree_compiler::IREE::HAL::ElideRedundantCommandsPass (iree-hal-elide-redundant-commands) //----- //
util.initializer {
  %_descriptor_set_layout_0 = util.global.load @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  %device = hal.ex.shared_device : !hal.device
  %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(4) layouts([%_descriptor_set_layout_0]) : !hal.pipeline_layout
  util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
  util.initializer.return
}

// -----// IR Dump After mlir::iree_compiler::IREE::HAL::ElideRedundantCommandsPass (iree-hal-elide-redundant-commands) //----- //
util.initializer {
  %c-1 = arith.constant -1 : index
  %c0 = arith.constant 0 : index
  %_device_query_0 = util.global.load @_device_query_0 : i1
  %device = hal.ex.shared_device : !hal.device
  %0 = arith.select %_device_query_0, %c0, %c-1 : index
  %1 = scf.index_switch %0 -> !hal.executable 
  case 0 {
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device : !hal.device) target(@main_dispatch_0::@cuda_nvptx_fb) layouts([%_pipeline_layout_0]) : !hal.executable
    scf.yield %exe : !hal.executable
  }
  default {
    %2 = util.null : !hal.executable
    scf.yield %2 : !hal.executable
  }
  util.global.store %1, @_executable_main_dispatch_0 : !hal.executable
  util.initializer.return
}

// -----// IR Dump After mlir::iree_compiler::IREE::HAL::ElideRedundantCommandsPass (iree-hal-elide-redundant-commands) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c553648160_i32 = arith.constant 553648160 : i32
  %c1_i32 = arith.constant 1 : i32
  %c0 = arith.constant 0 : index
  %c4 = arith.constant 4 : index
  %c32_i64 = arith.constant 32 : i64
  %c-1_i64 = arith.constant -1 : i64
  %c0_i64 = arith.constant 0 : i64
  %c-1_i32 = arith.constant -1 : i32
  %c-1 = arith.constant -1 : index
  %c1 = arith.constant 1 : index
  %_device_query_0 = util.global.load @_device_query_0 : i1
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %device = hal.ex.shared_device : !hal.device
  %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %4 = util.null : !hal.fence
  %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
  %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%3}
  %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
  %5 = arith.index_castui %0 : index to i64
  %6 = arith.trunci %5 : i64 to i32
  %7 = arith.shrui %5, %c32_i64 : i64
  %8 = arith.trunci %7 : i64 to i32
  %9 = arith.index_castui %1 : index to i64
  %10 = arith.trunci %9 : i64 to i32
  %11 = arith.shrui %9, %c32_i64 : i64
  %12 = arith.trunci %11 : i64 to i32
  %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
  %13 = arith.select %_device_query_0, %c0, %c-1 : index
  scf.index_switch %13 
  case 0 {
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout) offset(0) values([%6, %8, %10, %12]) : i32, i32, i32, i32
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%buffer : !hal.buffer)[%c0, %3], 
      %c1 = (%transient_buffer : !hal.buffer)[%c0, %3]
    ])
    %14 = affine.apply affine_map<()[s0, s1] -> ((s0 ceildiv 128) * (s1 ceildiv 32))>()[%1, %0]
    %_executable_main_dispatch_0 = util.global.load @_executable_main_dispatch_0 : !hal.executable
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_main_dispatch_0 : !hal.executable)[0] workgroups([%14, %c1, %c1])
    scf.yield
  }
  default {
  }
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  %fence_0 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
  %status_1 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
  hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence_0) commands([%cmd])
  %status_2 = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) : i32
  util.status.check_ok %status_2, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %3] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
  return %view : !hal.buffer_view
}

// -----// IR Dump After ConvertAffineToStandard (lower-affine) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#pipeline_layout = #hal.pipeline.layout<push_constants = 4, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer>]>]>
#translation = #iree_codegen.translation_info<LLVMGPUMatmulSimt>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private @_device_query_0 : i1
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    util.global.store %value, @_device_query_0 : i1
    util.initializer.return
  }
  util.global private @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer>]) : !hal.descriptor_set_layout
    util.global.store %descriptor_set_layout, @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    util.initializer.return
  }
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.initializer {
    %_descriptor_set_layout_0 = util.global.load @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    %device = hal.ex.shared_device : !hal.device
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(4) layouts([%_descriptor_set_layout_0]) : !hal.pipeline_layout
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    util.initializer.return
  }
  util.global private @_executable_main_dispatch_0 : !hal.executable
  util.initializer {
    %c-1 = arith.constant -1 : index
    %c0 = arith.constant 0 : index
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %device = hal.ex.shared_device : !hal.device
    %0 = arith.select %_device_query_0, %c0, %c-1 : index
    %1 = scf.index_switch %0 -> !hal.executable 
    case 0 {
      %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
      %exe = hal.executable.create device(%device : !hal.device) target(@main_dispatch_0::@cuda_nvptx_fb) layouts([%_pipeline_layout_0]) : !hal.executable
      scf.yield %exe : !hal.executable
    }
    default {
      %2 = util.null : !hal.executable
      scf.yield %2 : !hal.executable
    }
    util.global.store %1, @_executable_main_dispatch_0 : !hal.executable
    util.initializer.return
  }
  hal.executable private @main_dispatch_0 {
    hal.executable.variant public @cuda_nvptx_fb target(#executable_target_cuda_nvptx_fb) {
      hal.executable.export public @main_dispatch_0_matmul_DxDxD_f32 ordinal(0) layout(#pipeline_layout) attributes {translation_info = #translation, workgroup_size = [32 : index, 8 : index, 1 : index]} {
      ^bb0(%arg0: !hal.device, %arg1: index, %arg2: index):
        %c1 = arith.constant 1 : index
        %c128 = arith.constant 128 : index
        %c0 = arith.constant 0 : index
        %c1_0 = arith.constant 1 : index
        %0 = arith.cmpi sle, %arg2, %c0 : index
        %1 = arith.subi %c0, %arg2 : index
        %2 = arith.subi %arg2, %c1_0 : index
        %3 = arith.select %0, %1, %2 : index
        %4 = arith.divsi %3, %c128 : index
        %5 = arith.subi %c0, %4 : index
        %6 = arith.addi %4, %c1_0 : index
        %7 = arith.select %0, %5, %6 : index
        %c32 = arith.constant 32 : index
        %c0_1 = arith.constant 0 : index
        %c1_2 = arith.constant 1 : index
        %8 = arith.cmpi sle, %arg1, %c0_1 : index
        %9 = arith.subi %c0_1, %arg1 : index
        %10 = arith.subi %arg1, %c1_2 : index
        %11 = arith.select %8, %9, %10 : index
        %12 = arith.divsi %11, %c32 : index
        %13 = arith.subi %c0_1, %12 : index
        %14 = arith.addi %12, %c1_2 : index
        %15 = arith.select %8, %13, %14 : index
        %16 = arith.muli %7, %15 : index
        hal.return %16, %c1, %c1 : index, index, index
      }
      builtin.module {
        llvm.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias}, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32) {
          %0 = llvm.mlir.constant(63 : index) : i64
          %1 = llvm.mlir.constant(1 : i64) : i64
          %2 = llvm.mlir.constant(8 : index) : i64
          %3 = llvm.mlir.constant(-128 : index) : i64
          %4 = llvm.mlir.constant(-32 : index) : i64
          %5 = llvm.mlir.constant(-1 : index) : i64
          %6 = llvm.mlir.constant(128 : index) : i64
          %7 = llvm.mlir.constant(32 : index) : i64
          %8 = llvm.mlir.constant(0 : index) : i64
          %9 = llvm.mlir.constant(1 : index) : i64
          %10 = llvm.mlir.constant(32 : i64) : i64
          %11 = llvm.mlir.constant(0.000000e+00 : f32) : f32
          %12 = llvm.zext %arg2 : i32 to i64
          %13 = llvm.zext %arg3 : i32 to i64
          %14 = llvm.shl %13, %10  : i64
          %15 = llvm.or %12, %14  : i64
          %16 = llvm.zext %arg4 : i32 to i64
          %17 = llvm.zext %arg5 : i32 to i64
          %18 = llvm.shl %17, %10  : i64
          %19 = llvm.or %16, %18  : i64
          %20 = llvm.mul %19, %1  : i64
          %21 = llvm.ptrtoint %arg0 : !llvm.ptr<1> to i64
          %22 = llvm.and %21, %0  : i64
          %23 = llvm.icmp "eq" %22, %8 : i64
          "llvm.intr.assume"(%23) : (i1) -> ()
          %24 = llvm.ptrtoint %arg1 : !llvm.ptr<1> to i64
          %25 = llvm.and %24, %0  : i64
          %26 = llvm.icmp "eq" %25, %8 : i64
          "llvm.intr.assume"(%26) : (i1) -> ()
          %27 = nvvm.read.ptx.sreg.ctaid.x : i32
          %28 = llvm.sext %27 : i32 to i64
          %29 = llvm.icmp "sle" %19, %8 : i64
          %30 = llvm.sub %8, %19  : i64
          %31 = llvm.sub %19, %9  : i64
          %32 = llvm.select %29, %30, %31 : i1, i64
          %33 = llvm.sdiv %32, %6  : i64
          %34 = llvm.sub %8, %33  : i64
          %35 = llvm.add %33, %9  : i64
          %36 = llvm.select %29, %34, %35 : i1, i64
          %37 = llvm.icmp "slt" %28, %8 : i64
          %38 = llvm.sub %5, %28  : i64
          %39 = llvm.select %37, %38, %28 : i1, i64
          %40 = llvm.sdiv %39, %36  : i64
          %41 = llvm.sub %5, %40  : i64
          %42 = llvm.select %37, %41, %40 : i1, i64
          %43 = llvm.mul %42, %4  : i64
          %44 = llvm.add %15, %43  : i64
          %45 = llvm.icmp "sgt" %44, %7 : i64
          %46 = llvm.select %45, %7, %44 : i1, i64
          %47 = llvm.srem %28, %36  : i64
          %48 = llvm.icmp "slt" %47, %8 : i64
          %49 = llvm.add %47, %36  : i64
          %50 = llvm.select %48, %49, %47 : i1, i64
          %51 = llvm.mul %50, %3  : i64
          %52 = llvm.add %19, %51  : i64
          %53 = llvm.icmp "sgt" %52, %6 : i64
          %54 = llvm.select %53, %6, %52 : i1, i64
          %55 = nvvm.read.ptx.sreg.tid.x : i32
          %56 = llvm.sext %55 : i32 to i64
          %57 = nvvm.read.ptx.sreg.tid.y : i32
          %58 = llvm.sext %57 : i32 to i64
          %59 = llvm.icmp "sle" %46, %8 : i64
          %60 = llvm.sub %8, %46  : i64
          %61 = llvm.sub %46, %9  : i64
          %62 = llvm.select %59, %60, %61 : i1, i64
          %63 = llvm.sdiv %62, %2  : i64
          %64 = llvm.sub %8, %63  : i64
          %65 = llvm.add %63, %9  : i64
          %66 = llvm.select %59, %64, %65 : i1, i64
          %67 = llvm.mul %58, %66  : i64
          %68 = llvm.sub %46, %67  : i64
          %69 = llvm.icmp "slt" %68, %66 : i64
          %70 = llvm.select %69, %68, %66 : i1, i64
          %71 = llvm.icmp "slt" %70, %8 : i64
          %72 = llvm.select %71, %8, %70 : i1, i64
          %73 = llvm.icmp "sle" %54, %8 : i64
          %74 = llvm.sub %8, %54  : i64
          %75 = llvm.sub %54, %9  : i64
          %76 = llvm.select %73, %74, %75 : i1, i64
          %77 = llvm.sdiv %76, %7  : i64
          %78 = llvm.sub %8, %77  : i64
          %79 = llvm.add %77, %9  : i64
          %80 = llvm.select %73, %78, %79 : i1, i64
          %81 = llvm.mul %56, %80  : i64
          %82 = llvm.sub %54, %81  : i64
          %83 = llvm.icmp "slt" %82, %80 : i64
          %84 = llvm.select %83, %82, %80 : i1, i64
          %85 = llvm.icmp "slt" %84, %8 : i64
          %86 = llvm.select %85, %8, %84 : i1, i64
          %87 = llvm.mul %42, %7  : i64
          %88 = llvm.add %87, %67  : i64
          %89 = llvm.mul %50, %6  : i64
          %90 = llvm.add %89, %81  : i64
          llvm.br ^bb1(%8 : i64)
        ^bb1(%91: i64):  // 2 preds: ^bb0, ^bb5
          %92 = llvm.icmp "slt" %91, %72 : i64
          llvm.cond_br %92, ^bb2, ^bb6(%8 : i64)
        ^bb2:  // pred: ^bb1
          %93 = llvm.add %88, %91  : i64
          llvm.br ^bb3(%8 : i64)
        ^bb3(%94: i64):  // 2 preds: ^bb2, ^bb4
          %95 = llvm.icmp "slt" %94, %86 : i64
          llvm.cond_br %95, ^bb4, ^bb5
        ^bb4:  // pred: ^bb3
          %96 = llvm.add %90, %94  : i64
          %97 = llvm.mul %93, %20  : i64
          %98 = llvm.add %97, %96  : i64
          %99 = llvm.getelementptr %arg1[%98] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          llvm.store %11, %99 : f32, !llvm.ptr<1>
          %100 = llvm.add %94, %9  : i64
          llvm.br ^bb3(%100 : i64)
        ^bb5:  // pred: ^bb3
          %101 = llvm.add %91, %9  : i64
          llvm.br ^bb1(%101 : i64)
        ^bb6(%102: i64):  // 2 preds: ^bb1, ^bb12
          %103 = llvm.icmp "slt" %102, %19 : i64
          llvm.cond_br %103, ^bb7(%8 : i64), ^bb13
        ^bb7(%104: i64):  // 2 preds: ^bb6, ^bb11
          %105 = llvm.icmp "slt" %104, %72 : i64
          llvm.cond_br %105, ^bb8, ^bb12
        ^bb8:  // pred: ^bb7
          %106 = llvm.add %88, %104  : i64
          llvm.br ^bb9(%8 : i64)
        ^bb9(%107: i64):  // 2 preds: ^bb8, ^bb10
          %108 = llvm.icmp "slt" %107, %86 : i64
          llvm.cond_br %108, ^bb10, ^bb11
        ^bb10:  // pred: ^bb9
          %109 = llvm.mul %106, %20  : i64
          %110 = llvm.add %109, %102  : i64
          %111 = llvm.getelementptr %arg0[%110] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %112 = llvm.load %111 : !llvm.ptr<1> -> f32
          %113 = llvm.add %90, %107  : i64
          %114 = llvm.mul %102, %20  : i64
          %115 = llvm.add %114, %113  : i64
          %116 = llvm.getelementptr %arg0[%115] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %117 = llvm.load %116 : !llvm.ptr<1> -> f32
          %118 = llvm.add %109, %113  : i64
          %119 = llvm.getelementptr %arg1[%118] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %120 = llvm.load %119 : !llvm.ptr<1> -> f32
          %121 = llvm.fmul %112, %117  : f32
          %122 = llvm.fadd %120, %121  : f32
          llvm.store %122, %119 : f32, !llvm.ptr<1>
          %123 = llvm.add %107, %9  : i64
          llvm.br ^bb9(%123 : i64)
        ^bb11:  // pred: ^bb9
          %124 = llvm.add %104, %9  : i64
          llvm.br ^bb7(%124 : i64)
        ^bb12:  // pred: ^bb7
          %125 = llvm.add %102, %9  : i64
          llvm.br ^bb6(%125 : i64)
        ^bb13:  // pred: ^bb6
          llvm.return
        }
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c32_i64 = arith.constant 32 : i64
    %c-1_i64 = arith.constant -1 : i64
    %c0_i64 = arith.constant 0 : i64
    %c-1_i32 = arith.constant -1 : i32
    %c-1 = arith.constant -1 : index
    %c1 = arith.constant 1 : index
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %4 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%3}
    %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    %5 = arith.index_castui %0 : index to i64
    %6 = arith.trunci %5 : i64 to i32
    %7 = arith.shrui %5, %c32_i64 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %1 : index to i64
    %10 = arith.trunci %9 : i64 to i32
    %11 = arith.shrui %9, %c32_i64 : i64
    %12 = arith.trunci %11 : i64 to i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    %13 = arith.select %_device_query_0, %c0, %c-1 : index
    scf.index_switch %13 
    case 0 {
      %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
      hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout) offset(0) values([%6, %8, %10, %12]) : i32, i32, i32, i32
      hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
        %c0 = (%buffer : !hal.buffer)[%c0, %3], 
        %c1 = (%transient_buffer : !hal.buffer)[%c0, %3]
      ])
      %c128 = arith.constant 128 : index
      %c0_3 = arith.constant 0 : index
      %c1_4 = arith.constant 1 : index
      %14 = arith.cmpi sle, %1, %c0_3 : index
      %15 = arith.subi %c0_3, %1 : index
      %16 = arith.subi %1, %c1_4 : index
      %17 = arith.select %14, %15, %16 : index
      %18 = arith.divsi %17, %c128 : index
      %19 = arith.subi %c0_3, %18 : index
      %20 = arith.addi %18, %c1_4 : index
      %21 = arith.select %14, %19, %20 : index
      %c32 = arith.constant 32 : index
      %c0_5 = arith.constant 0 : index
      %c1_6 = arith.constant 1 : index
      %22 = arith.cmpi sle, %0, %c0_5 : index
      %23 = arith.subi %c0_5, %0 : index
      %24 = arith.subi %0, %c1_6 : index
      %25 = arith.select %22, %23, %24 : index
      %26 = arith.divsi %25, %c32 : index
      %27 = arith.subi %c0_5, %26 : index
      %28 = arith.addi %26, %c1_6 : index
      %29 = arith.select %22, %27, %28 : index
      %30 = arith.muli %21, %29 : index
      %_executable_main_dispatch_0 = util.global.load @_executable_main_dispatch_0 : !hal.executable
      hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_main_dispatch_0 : !hal.executable)[0] workgroups([%30, %c1, %c1])
      scf.yield
    }
    default {
    }
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_0 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status_1 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence_0) commands([%cmd])
    %status_2 = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status_2, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %3] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After SCFToControlFlow (convert-scf-to-cf) //----- //
util.initializer {
  %device = hal.ex.shared_device : !hal.device
  %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
  util.global.store %value, @_device_query_0 : i1
  util.initializer.return
}

// -----// IR Dump After SCFToControlFlow (convert-scf-to-cf) //----- //
util.initializer {
  %device = hal.ex.shared_device : !hal.device
  %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer>]) : !hal.descriptor_set_layout
  util.global.store %descriptor_set_layout, @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  util.initializer.return
}

// -----// IR Dump After SCFToControlFlow (convert-scf-to-cf) //----- //
util.initializer {
  %_descriptor_set_layout_0 = util.global.load @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  %device = hal.ex.shared_device : !hal.device
  %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(4) layouts([%_descriptor_set_layout_0]) : !hal.pipeline_layout
  util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
  util.initializer.return
}

// -----// IR Dump After SCFToControlFlow (convert-scf-to-cf) //----- //
util.initializer {
  %c-1 = arith.constant -1 : index
  %c0 = arith.constant 0 : index
  %_device_query_0 = util.global.load @_device_query_0 : i1
  %device = hal.ex.shared_device : !hal.device
  %0 = arith.select %_device_query_0, %c0, %c-1 : index
  %1 = arith.index_cast %0 : index to i32
  cf.switch %1 : i32, [
    default: ^bb2,
    0: ^bb1
  ]
^bb1:  // pred: ^bb0
  %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
  %exe = hal.executable.create device(%device : !hal.device) target(@main_dispatch_0::@cuda_nvptx_fb) layouts([%_pipeline_layout_0]) : !hal.executable
  cf.br ^bb3(%exe : !hal.executable)
^bb2:  // pred: ^bb0
  %2 = util.null : !hal.executable
  cf.br ^bb3(%2 : !hal.executable)
^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
  util.global.store %3, @_executable_main_dispatch_0 : !hal.executable
  util.initializer.return
}

// -----// IR Dump After SCFToControlFlow (convert-scf-to-cf) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c553648160_i32 = arith.constant 553648160 : i32
  %c1_i32 = arith.constant 1 : i32
  %c0 = arith.constant 0 : index
  %c4 = arith.constant 4 : index
  %c32_i64 = arith.constant 32 : i64
  %c-1_i64 = arith.constant -1 : i64
  %c0_i64 = arith.constant 0 : i64
  %c-1_i32 = arith.constant -1 : i32
  %c-1 = arith.constant -1 : index
  %c1 = arith.constant 1 : index
  %_device_query_0 = util.global.load @_device_query_0 : i1
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %device = hal.ex.shared_device : !hal.device
  %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %4 = util.null : !hal.fence
  %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
  %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%3}
  %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
  %5 = arith.index_castui %0 : index to i64
  %6 = arith.trunci %5 : i64 to i32
  %7 = arith.shrui %5, %c32_i64 : i64
  %8 = arith.trunci %7 : i64 to i32
  %9 = arith.index_castui %1 : index to i64
  %10 = arith.trunci %9 : i64 to i32
  %11 = arith.shrui %9, %c32_i64 : i64
  %12 = arith.trunci %11 : i64 to i32
  %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
  %13 = arith.select %_device_query_0, %c0, %c-1 : index
  %14 = arith.index_cast %13 : index to i32
  cf.switch %14 : i32, [
    default: ^bb2,
    0: ^bb1
  ]
^bb1:  // pred: ^bb0
  %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
  hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout) offset(0) values([%6, %8, %10, %12]) : i32, i32, i32, i32
  hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
    %c0 = (%buffer : !hal.buffer)[%c0, %3], 
    %c1 = (%transient_buffer : !hal.buffer)[%c0, %3]
  ])
  %c128 = arith.constant 128 : index
  %c0_0 = arith.constant 0 : index
  %c1_1 = arith.constant 1 : index
  %15 = arith.cmpi sle, %1, %c0_0 : index
  %16 = arith.subi %c0_0, %1 : index
  %17 = arith.subi %1, %c1_1 : index
  %18 = arith.select %15, %16, %17 : index
  %19 = arith.divsi %18, %c128 : index
  %20 = arith.subi %c0_0, %19 : index
  %21 = arith.addi %19, %c1_1 : index
  %22 = arith.select %15, %20, %21 : index
  %c32 = arith.constant 32 : index
  %c0_2 = arith.constant 0 : index
  %c1_3 = arith.constant 1 : index
  %23 = arith.cmpi sle, %0, %c0_2 : index
  %24 = arith.subi %c0_2, %0 : index
  %25 = arith.subi %0, %c1_3 : index
  %26 = arith.select %23, %24, %25 : index
  %27 = arith.divsi %26, %c32 : index
  %28 = arith.subi %c0_2, %27 : index
  %29 = arith.addi %27, %c1_3 : index
  %30 = arith.select %23, %28, %29 : index
  %31 = arith.muli %22, %30 : index
  %_executable_main_dispatch_0 = util.global.load @_executable_main_dispatch_0 : !hal.executable
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_main_dispatch_0 : !hal.executable)[0] workgroups([%31, %c1, %c1])
  cf.br ^bb3
^bb2:  // pred: ^bb0
  cf.br ^bb3
^bb3:  // 2 preds: ^bb1, ^bb2
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  %fence_4 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
  %status_5 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
  hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence_4) commands([%cmd])
  %status_6 = hal.fence.await until([%fence_4]) timeout_millis(%c-1_i32) : i32
  util.status.check_ok %status_6, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %3] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
  return %view : !hal.buffer_view
}

// -----// IR Dump After CombineInitializers (iree-util-combine-initializers) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#pipeline_layout = #hal.pipeline.layout<push_constants = 4, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer>]>]>
#translation = #iree_codegen.translation_info<LLVMGPUMatmulSimt>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private @_device_query_0 : i1
  util.global private @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.global private @_executable_main_dispatch_0 : !hal.executable
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    util.global.store %value, @_device_query_0 : i1
    %device_0 = hal.ex.shared_device : !hal.device
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device_0 : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer>]) : !hal.descriptor_set_layout
    util.global.store %descriptor_set_layout, @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    %_descriptor_set_layout_0 = util.global.load @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    %device_1 = hal.ex.shared_device : !hal.device
    %pipeline_layout = hal.pipeline_layout.create device(%device_1 : !hal.device) push_constants(4) layouts([%_descriptor_set_layout_0]) : !hal.pipeline_layout
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    %c-1 = arith.constant -1 : index
    %c0 = arith.constant 0 : index
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %device_2 = hal.ex.shared_device : !hal.device
    %0 = arith.select %_device_query_0, %c0, %c-1 : index
    %1 = arith.index_cast %0 : index to i32
    cf.switch %1 : i32, [
      default: ^bb2,
      0: ^bb1
    ]
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device_2 : !hal.device) target(@main_dispatch_0::@cuda_nvptx_fb) layouts([%_pipeline_layout_0]) : !hal.executable
    cf.br ^bb3(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %2 = util.null : !hal.executable
    cf.br ^bb3(%2 : !hal.executable)
  ^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %3, @_executable_main_dispatch_0 : !hal.executable
    cf.br ^bb4
  ^bb4:  // pred: ^bb3
    util.initializer.return
  }
  hal.executable private @main_dispatch_0 {
    hal.executable.variant public @cuda_nvptx_fb target(#executable_target_cuda_nvptx_fb) {
      hal.executable.export public @main_dispatch_0_matmul_DxDxD_f32 ordinal(0) layout(#pipeline_layout) attributes {translation_info = #translation, workgroup_size = [32 : index, 8 : index, 1 : index]} {
      ^bb0(%arg0: !hal.device, %arg1: index, %arg2: index):
        %c1 = arith.constant 1 : index
        %c128 = arith.constant 128 : index
        %c0 = arith.constant 0 : index
        %c1_0 = arith.constant 1 : index
        %0 = arith.cmpi sle, %arg2, %c0 : index
        %1 = arith.subi %c0, %arg2 : index
        %2 = arith.subi %arg2, %c1_0 : index
        %3 = arith.select %0, %1, %2 : index
        %4 = arith.divsi %3, %c128 : index
        %5 = arith.subi %c0, %4 : index
        %6 = arith.addi %4, %c1_0 : index
        %7 = arith.select %0, %5, %6 : index
        %c32 = arith.constant 32 : index
        %c0_1 = arith.constant 0 : index
        %c1_2 = arith.constant 1 : index
        %8 = arith.cmpi sle, %arg1, %c0_1 : index
        %9 = arith.subi %c0_1, %arg1 : index
        %10 = arith.subi %arg1, %c1_2 : index
        %11 = arith.select %8, %9, %10 : index
        %12 = arith.divsi %11, %c32 : index
        %13 = arith.subi %c0_1, %12 : index
        %14 = arith.addi %12, %c1_2 : index
        %15 = arith.select %8, %13, %14 : index
        %16 = arith.muli %7, %15 : index
        hal.return %16, %c1, %c1 : index, index, index
      }
      builtin.module {
        llvm.func @main_dispatch_0_matmul_DxDxD_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias}, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32) {
          %0 = llvm.mlir.constant(63 : index) : i64
          %1 = llvm.mlir.constant(1 : i64) : i64
          %2 = llvm.mlir.constant(8 : index) : i64
          %3 = llvm.mlir.constant(-128 : index) : i64
          %4 = llvm.mlir.constant(-32 : index) : i64
          %5 = llvm.mlir.constant(-1 : index) : i64
          %6 = llvm.mlir.constant(128 : index) : i64
          %7 = llvm.mlir.constant(32 : index) : i64
          %8 = llvm.mlir.constant(0 : index) : i64
          %9 = llvm.mlir.constant(1 : index) : i64
          %10 = llvm.mlir.constant(32 : i64) : i64
          %11 = llvm.mlir.constant(0.000000e+00 : f32) : f32
          %12 = llvm.zext %arg2 : i32 to i64
          %13 = llvm.zext %arg3 : i32 to i64
          %14 = llvm.shl %13, %10  : i64
          %15 = llvm.or %12, %14  : i64
          %16 = llvm.zext %arg4 : i32 to i64
          %17 = llvm.zext %arg5 : i32 to i64
          %18 = llvm.shl %17, %10  : i64
          %19 = llvm.or %16, %18  : i64
          %20 = llvm.mul %19, %1  : i64
          %21 = llvm.ptrtoint %arg0 : !llvm.ptr<1> to i64
          %22 = llvm.and %21, %0  : i64
          %23 = llvm.icmp "eq" %22, %8 : i64
          "llvm.intr.assume"(%23) : (i1) -> ()
          %24 = llvm.ptrtoint %arg1 : !llvm.ptr<1> to i64
          %25 = llvm.and %24, %0  : i64
          %26 = llvm.icmp "eq" %25, %8 : i64
          "llvm.intr.assume"(%26) : (i1) -> ()
          %27 = nvvm.read.ptx.sreg.ctaid.x : i32
          %28 = llvm.sext %27 : i32 to i64
          %29 = llvm.icmp "sle" %19, %8 : i64
          %30 = llvm.sub %8, %19  : i64
          %31 = llvm.sub %19, %9  : i64
          %32 = llvm.select %29, %30, %31 : i1, i64
          %33 = llvm.sdiv %32, %6  : i64
          %34 = llvm.sub %8, %33  : i64
          %35 = llvm.add %33, %9  : i64
          %36 = llvm.select %29, %34, %35 : i1, i64
          %37 = llvm.icmp "slt" %28, %8 : i64
          %38 = llvm.sub %5, %28  : i64
          %39 = llvm.select %37, %38, %28 : i1, i64
          %40 = llvm.sdiv %39, %36  : i64
          %41 = llvm.sub %5, %40  : i64
          %42 = llvm.select %37, %41, %40 : i1, i64
          %43 = llvm.mul %42, %4  : i64
          %44 = llvm.add %15, %43  : i64
          %45 = llvm.icmp "sgt" %44, %7 : i64
          %46 = llvm.select %45, %7, %44 : i1, i64
          %47 = llvm.srem %28, %36  : i64
          %48 = llvm.icmp "slt" %47, %8 : i64
          %49 = llvm.add %47, %36  : i64
          %50 = llvm.select %48, %49, %47 : i1, i64
          %51 = llvm.mul %50, %3  : i64
          %52 = llvm.add %19, %51  : i64
          %53 = llvm.icmp "sgt" %52, %6 : i64
          %54 = llvm.select %53, %6, %52 : i1, i64
          %55 = nvvm.read.ptx.sreg.tid.x : i32
          %56 = llvm.sext %55 : i32 to i64
          %57 = nvvm.read.ptx.sreg.tid.y : i32
          %58 = llvm.sext %57 : i32 to i64
          %59 = llvm.icmp "sle" %46, %8 : i64
          %60 = llvm.sub %8, %46  : i64
          %61 = llvm.sub %46, %9  : i64
          %62 = llvm.select %59, %60, %61 : i1, i64
          %63 = llvm.sdiv %62, %2  : i64
          %64 = llvm.sub %8, %63  : i64
          %65 = llvm.add %63, %9  : i64
          %66 = llvm.select %59, %64, %65 : i1, i64
          %67 = llvm.mul %58, %66  : i64
          %68 = llvm.sub %46, %67  : i64
          %69 = llvm.icmp "slt" %68, %66 : i64
          %70 = llvm.select %69, %68, %66 : i1, i64
          %71 = llvm.icmp "slt" %70, %8 : i64
          %72 = llvm.select %71, %8, %70 : i1, i64
          %73 = llvm.icmp "sle" %54, %8 : i64
          %74 = llvm.sub %8, %54  : i64
          %75 = llvm.sub %54, %9  : i64
          %76 = llvm.select %73, %74, %75 : i1, i64
          %77 = llvm.sdiv %76, %7  : i64
          %78 = llvm.sub %8, %77  : i64
          %79 = llvm.add %77, %9  : i64
          %80 = llvm.select %73, %78, %79 : i1, i64
          %81 = llvm.mul %56, %80  : i64
          %82 = llvm.sub %54, %81  : i64
          %83 = llvm.icmp "slt" %82, %80 : i64
          %84 = llvm.select %83, %82, %80 : i1, i64
          %85 = llvm.icmp "slt" %84, %8 : i64
          %86 = llvm.select %85, %8, %84 : i1, i64
          %87 = llvm.mul %42, %7  : i64
          %88 = llvm.add %87, %67  : i64
          %89 = llvm.mul %50, %6  : i64
          %90 = llvm.add %89, %81  : i64
          llvm.br ^bb1(%8 : i64)
        ^bb1(%91: i64):  // 2 preds: ^bb0, ^bb5
          %92 = llvm.icmp "slt" %91, %72 : i64
          llvm.cond_br %92, ^bb2, ^bb6(%8 : i64)
        ^bb2:  // pred: ^bb1
          %93 = llvm.add %88, %91  : i64
          llvm.br ^bb3(%8 : i64)
        ^bb3(%94: i64):  // 2 preds: ^bb2, ^bb4
          %95 = llvm.icmp "slt" %94, %86 : i64
          llvm.cond_br %95, ^bb4, ^bb5
        ^bb4:  // pred: ^bb3
          %96 = llvm.add %90, %94  : i64
          %97 = llvm.mul %93, %20  : i64
          %98 = llvm.add %97, %96  : i64
          %99 = llvm.getelementptr %arg1[%98] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          llvm.store %11, %99 : f32, !llvm.ptr<1>
          %100 = llvm.add %94, %9  : i64
          llvm.br ^bb3(%100 : i64)
        ^bb5:  // pred: ^bb3
          %101 = llvm.add %91, %9  : i64
          llvm.br ^bb1(%101 : i64)
        ^bb6(%102: i64):  // 2 preds: ^bb1, ^bb12
          %103 = llvm.icmp "slt" %102, %19 : i64
          llvm.cond_br %103, ^bb7(%8 : i64), ^bb13
        ^bb7(%104: i64):  // 2 preds: ^bb6, ^bb11
          %105 = llvm.icmp "slt" %104, %72 : i64
          llvm.cond_br %105, ^bb8, ^bb12
        ^bb8:  // pred: ^bb7
          %106 = llvm.add %88, %104  : i64
          llvm.br ^bb9(%8 : i64)
        ^bb9(%107: i64):  // 2 preds: ^bb8, ^bb10
          %108 = llvm.icmp "slt" %107, %86 : i64
          llvm.cond_br %108, ^bb10, ^bb11
        ^bb10:  // pred: ^bb9
          %109 = llvm.mul %106, %20  : i64
          %110 = llvm.add %109, %102  : i64
          %111 = llvm.getelementptr %arg0[%110] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %112 = llvm.load %111 : !llvm.ptr<1> -> f32
          %113 = llvm.add %90, %107  : i64
          %114 = llvm.mul %102, %20  : i64
          %115 = llvm.add %114, %113  : i64
          %116 = llvm.getelementptr %arg0[%115] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %117 = llvm.load %116 : !llvm.ptr<1> -> f32
          %118 = llvm.add %109, %113  : i64
          %119 = llvm.getelementptr %arg1[%118] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %120 = llvm.load %119 : !llvm.ptr<1> -> f32
          %121 = llvm.fmul %112, %117  : f32
          %122 = llvm.fadd %120, %121  : f32
          llvm.store %122, %119 : f32, !llvm.ptr<1>
          %123 = llvm.add %107, %9  : i64
          llvm.br ^bb9(%123 : i64)
        ^bb11:  // pred: ^bb9
          %124 = llvm.add %104, %9  : i64
          llvm.br ^bb7(%124 : i64)
        ^bb12:  // pred: ^bb7
          %125 = llvm.add %102, %9  : i64
          llvm.br ^bb6(%125 : i64)
        ^bb13:  // pred: ^bb6
          llvm.return
        }
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c32_i64 = arith.constant 32 : i64
    %c-1_i64 = arith.constant -1 : i64
    %c0_i64 = arith.constant 0 : i64
    %c-1_i32 = arith.constant -1 : i32
    %c-1 = arith.constant -1 : index
    %c1 = arith.constant 1 : index
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %4 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%3}
    %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    %5 = arith.index_castui %0 : index to i64
    %6 = arith.trunci %5 : i64 to i32
    %7 = arith.shrui %5, %c32_i64 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %1 : index to i64
    %10 = arith.trunci %9 : i64 to i32
    %11 = arith.shrui %9, %c32_i64 : i64
    %12 = arith.trunci %11 : i64 to i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    %13 = arith.select %_device_query_0, %c0, %c-1 : index
    %14 = arith.index_cast %13 : index to i32
    cf.switch %14 : i32, [
      default: ^bb2,
      0: ^bb1
    ]
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout) offset(0) values([%6, %8, %10, %12]) : i32, i32, i32, i32
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%buffer : !hal.buffer)[%c0, %3], 
      %c1 = (%transient_buffer : !hal.buffer)[%c0, %3]
    ])
    %c128 = arith.constant 128 : index
    %c0_0 = arith.constant 0 : index
    %c1_1 = arith.constant 1 : index
    %15 = arith.cmpi sle, %1, %c0_0 : index
    %16 = arith.subi %c0_0, %1 : index
    %17 = arith.subi %1, %c1_1 : index
    %18 = arith.select %15, %16, %17 : index
    %19 = arith.divsi %18, %c128 : index
    %20 = arith.subi %c0_0, %19 : index
    %21 = arith.addi %19, %c1_1 : index
    %22 = arith.select %15, %20, %21 : index
    %c32 = arith.constant 32 : index
    %c0_2 = arith.constant 0 : index
    %c1_3 = arith.constant 1 : index
    %23 = arith.cmpi sle, %0, %c0_2 : index
    %24 = arith.subi %c0_2, %0 : index
    %25 = arith.subi %0, %c1_3 : index
    %26 = arith.select %23, %24, %25 : index
    %27 = arith.divsi %26, %c32 : index
    %28 = arith.subi %c0_2, %27 : index
    %29 = arith.addi %27, %c1_3 : index
    %30 = arith.select %23, %28, %29 : index
    %31 = arith.muli %22, %30 : index
    %_executable_main_dispatch_0 = util.global.load @_executable_main_dispatch_0 : !hal.executable
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_main_dispatch_0 : !hal.executable)[0] workgroups([%31, %c1, %c1])
    cf.br ^bb3
  ^bb2:  // pred: ^bb0
    cf.br ^bb3
  ^bb3:  // 2 preds: ^bb1, ^bb2
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_4 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status_5 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence_4) commands([%cmd])
    %status_6 = hal.fence.await until([%fence_4]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status_6, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %3] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


//
// Generated by LLVM NVPTX Back-End
//

.version 7.5
.target sm_75
.address_size 64

	// .globl	main_dispatch_0_matmul_DxDxD_f32

.visible .entry main_dispatch_0_matmul_DxDxD_f32(
	.param .u64 main_dispatch_0_matmul_DxDxD_f32_param_0,
	.param .u64 main_dispatch_0_matmul_DxDxD_f32_param_1,
	.param .u32 main_dispatch_0_matmul_DxDxD_f32_param_2,
	.param .u32 main_dispatch_0_matmul_DxDxD_f32_param_3,
	.param .u32 main_dispatch_0_matmul_DxDxD_f32_param_4,
	.param .u32 main_dispatch_0_matmul_DxDxD_f32_param_5
)
.maxntid 32, 8, 1
{
	.reg .pred 	%p<21>;
	.reg .b32 	%r<10>;
	.reg .f32 	%f<14>;
	.reg .b64 	%rd<165>;

	ld.param.u32 	%rd61, [main_dispatch_0_matmul_DxDxD_f32_param_2];
	ld.param.u32 	%rd62, [main_dispatch_0_matmul_DxDxD_f32_param_3];
	shl.b64 	%rd63, %rd62, 32;
	or.b64  	%rd1, %rd63, %rd61;
	ld.param.u32 	%rd2, [main_dispatch_0_matmul_DxDxD_f32_param_4];
	ld.param.u32 	%rd3, [main_dispatch_0_matmul_DxDxD_f32_param_5];
	shl.b64 	%rd64, %rd3, 32;
	or.b64  	%rd4, %rd64, %rd2;
	mov.u32 	%r1, %ctaid.x;
	cvt.u64.u32 	%rd5, %r1;
	setp.lt.s64 	%p1, %rd4, 1;
	neg.s64 	%rd65, %rd4;
	add.s64 	%rd66, %rd4, -1;
	selp.b64 	%rd67, %rd65, %rd66, %p1;
	shr.s64 	%rd68, %rd67, 63;
	shr.u64 	%rd69, %rd68, 57;
	add.s64 	%rd70, %rd67, %rd69;
	shr.s64 	%rd71, %rd70, 7;
	neg.s64 	%rd72, %rd71;
	add.s64 	%rd73, %rd71, 1;
	selp.b64 	%rd74, %rd72, %rd73, %p1;
	and.b64  	%rd75, %rd74, -4294967296;
	setp.ne.s64 	%p2, %rd75, 0;
	@%p2 bra 	$L__BB0_2;
	bra.uni 	$L__BB0_1;
$L__BB0_2:
	div.s64 	%rd148, %rd5, %rd74;
	bra.uni 	$L__BB0_3;
$L__BB0_1:
	cvt.u32.u64 	%r3, %rd74;
	cvt.u32.u64 	%r4, %rd5;
	div.u32 	%r5, %r4, %r3;
	cvt.u64.u32 	%rd148, %r5;
$L__BB0_3:
	ld.param.u64 	%rd60, [main_dispatch_0_matmul_DxDxD_f32_param_1];
	shl.b64 	%rd76, %rd148, 5;
	sub.s64 	%rd77, %rd1, %rd76;
	min.s64 	%rd78, %rd77, 32;
	mul.lo.s64 	%rd79, %rd148, %rd74;
	sub.s64 	%rd80, %rd5, %rd79;
	shl.b64 	%rd81, %rd80, 7;
	sub.s64 	%rd82, %rd4, %rd81;
	min.s64 	%rd83, %rd82, 128;
	mov.u32 	%r6, %tid.x;
	cvt.u64.u32 	%rd84, %r6;
	mov.u32 	%r7, %tid.y;
	cvt.u64.u32 	%rd85, %r7;
	setp.lt.s64 	%p3, %rd77, 1;
	neg.s64 	%rd86, %rd78;
	add.s64 	%rd87, %rd78, -1;
	selp.b64 	%rd88, %rd86, %rd87, %p3;
	shr.s64 	%rd89, %rd88, 63;
	shr.u64 	%rd90, %rd89, 61;
	add.s64 	%rd91, %rd88, %rd90;
	shr.s64 	%rd92, %rd91, 3;
	neg.s64 	%rd93, %rd92;
	add.s64 	%rd94, %rd92, 1;
	selp.b64 	%rd95, %rd93, %rd94, %p3;
	mul.lo.s64 	%rd96, %rd95, %rd85;
	sub.s64 	%rd97, %rd78, %rd96;
	min.s64 	%rd10, %rd97, %rd95;
	setp.lt.s64 	%p4, %rd82, 1;
	neg.s64 	%rd98, %rd83;
	add.s64 	%rd99, %rd83, -1;
	selp.b64 	%rd100, %rd98, %rd99, %p4;
	shr.s64 	%rd101, %rd100, 63;
	shr.u64 	%rd102, %rd101, 59;
	add.s64 	%rd103, %rd100, %rd102;
	shr.s64 	%rd104, %rd103, 5;
	neg.s64 	%rd105, %rd104;
	add.s64 	%rd106, %rd104, 1;
	selp.b64 	%rd107, %rd105, %rd106, %p4;
	mul.lo.s64 	%rd108, %rd107, %rd84;
	sub.s64 	%rd109, %rd83, %rd108;
	min.s64 	%rd11, %rd109, %rd107;
	add.s64 	%rd12, %rd96, %rd76;
	add.s64 	%rd13, %rd108, %rd81;
	setp.lt.s64 	%p5, %rd10, 1;
	mul.lo.s64 	%rd143, %rd12, %rd4;
	shl.b64 	%rd144, %rd13, 2;
	shl.b64 	%rd145, %rd3, 34;
	shl.b64 	%rd146, %rd2, 2;
	setp.lt.s64 	%p20, %rd11, 1;
	@%p5 bra 	$L__BB0_13;
	mov.u64 	%rd151, 0;
	and.b64  	%rd19, %rd11, 7;
	and.b64  	%rd15, %rd11, -8;
	shl.b64 	%rd112, %rd143, 2;
	add.s64 	%rd114, %rd112, %rd144;
	add.s64 	%rd149, %rd60, %rd114;
	add.s64 	%rd150, %rd149, 16;
	or.b64  	%rd17, %rd145, %rd146;
	setp.lt.u64 	%p7, %rd11, 8;
	mov.b32 	%r9, 0;
	bra.uni 	$L__BB0_5;
$L__BB0_12:
	add.s64 	%rd151, %rd151, 1;
	add.s64 	%rd150, %rd150, %rd17;
	add.s64 	%rd149, %rd149, %rd17;
	setp.eq.s64 	%p11, %rd10, %rd151;
	@%p11 bra 	$L__BB0_13;
$L__BB0_5:
	@%p20 bra 	$L__BB0_12;
	mov.u64 	%rd154, 0;
	@%p7 bra 	$L__BB0_9;
	mov.u64 	%rd154, 0;
	mov.u64 	%rd152, %rd150;
$L__BB0_8:
	st.global.u32 	[%rd152+-16], %r9;
	st.global.u32 	[%rd152+-12], %r9;
	st.global.u32 	[%rd152+-8], %r9;
	st.global.u32 	[%rd152+-4], %r9;
	st.global.u32 	[%rd152], %r9;
	st.global.u32 	[%rd152+4], %r9;
	st.global.u32 	[%rd152+8], %r9;
	st.global.u32 	[%rd152+12], %r9;
	add.s64 	%rd154, %rd154, 8;
	add.s64 	%rd152, %rd152, 32;
	setp.ne.s64 	%p8, %rd15, %rd154;
	@%p8 bra 	$L__BB0_8;
$L__BB0_9:
	setp.eq.s64 	%p9, %rd19, 0;
	@%p9 bra 	$L__BB0_12;
	shl.b64 	%rd119, %rd154, 2;
	add.s64 	%rd156, %rd149, %rd119;
	mov.u64 	%rd155, %rd19;
$L__BB0_11:
	.pragma "nounroll";
	st.global.u32 	[%rd156], %r9;
	add.s64 	%rd156, %rd156, 4;
	add.s64 	%rd155, %rd155, -1;
	setp.ne.s64 	%p10, %rd155, 0;
	@%p10 bra 	$L__BB0_11;
	bra.uni 	$L__BB0_12;
$L__BB0_13:
	@%p1 bra 	$L__BB0_25;
	ld.param.u64 	%rd59, [main_dispatch_0_matmul_DxDxD_f32_param_0];
	and.b64  	%rd20, %rd11, 1;
	and.b64  	%rd21, %rd11, -2;
	shl.b64 	%rd122, %rd143, 2;
	add.s64 	%rd124, %rd122, %rd144;
	add.s64 	%rd125, %rd124, %rd60;
	add.s64 	%rd22, %rd125, 4;
	or.b64  	%rd23, %rd145, %rd146;
	add.s64 	%rd128, %rd144, %rd59;
	add.s64 	%rd157, %rd128, 4;
	mov.u64 	%rd158, 0;
	setp.eq.s64 	%p15, %rd11, 1;
	setp.eq.s64 	%p17, %rd20, 0;
	bra.uni 	$L__BB0_15;
$L__BB0_24:
	add.s64 	%rd158, %rd158, 1;
	add.s64 	%rd157, %rd157, %rd23;
	setp.ne.s64 	%p19, %rd158, %rd4;
	@%p19 bra 	$L__BB0_15;
	bra.uni 	$L__BB0_25;
$L__BB0_15:
	@%p5 bra 	$L__BB0_24;
	shl.b64 	%rd130, %rd158, 2;
	add.s64 	%rd43, %rd59, %rd130;
	mul.lo.s64 	%rd131, %rd158, %rd4;
	shl.b64 	%rd132, %rd131, 2;
	add.s64 	%rd44, %rd59, %rd132;
	mov.u64 	%rd160, 0;
	mov.u64 	%rd159, %rd22;
	bra.uni 	$L__BB0_17;
$L__BB0_23:
	add.s64 	%rd160, %rd160, 1;
	add.s64 	%rd159, %rd159, %rd23;
	setp.ne.s64 	%p18, %rd10, %rd160;
	@%p18 bra 	$L__BB0_17;
	bra.uni 	$L__BB0_24;
$L__BB0_17:
	@%p20 bra 	$L__BB0_23;
	add.s64 	%rd134, %rd160, %rd12;
	mul.lo.s64 	%rd135, %rd134, %rd4;
	shl.b64 	%rd136, %rd135, 2;
	add.s64 	%rd137, %rd43, %rd136;
	ld.global.nc.f32 	%f1, [%rd137];
	mov.u64 	%rd164, 0;
	@%p15 bra 	$L__BB0_21;
	mov.u64 	%rd164, 0;
	mov.u64 	%rd161, %rd157;
	mov.u64 	%rd162, %rd159;
$L__BB0_20:
	ld.global.nc.f32 	%f2, [%rd161+-4];
	ld.global.f32 	%f3, [%rd162+-4];
	mul.rn.f32 	%f4, %f1, %f2;
	add.rn.f32 	%f5, %f3, %f4;
	st.global.f32 	[%rd162+-4], %f5;
	ld.global.nc.f32 	%f6, [%rd161];
	ld.global.f32 	%f7, [%rd162];
	mul.rn.f32 	%f8, %f1, %f6;
	add.rn.f32 	%f9, %f7, %f8;
	st.global.f32 	[%rd162], %f9;
	add.s64 	%rd164, %rd164, 2;
	add.s64 	%rd162, %rd162, 8;
	add.s64 	%rd161, %rd161, 8;
	setp.ne.s64 	%p16, %rd21, %rd164;
	@%p16 bra 	$L__BB0_20;
$L__BB0_21:
	@%p17 bra 	$L__BB0_23;
	add.s64 	%rd47, %rd60, %rd136;
	add.s64 	%rd139, %rd164, %rd13;
	shl.b64 	%rd140, %rd139, 2;
	add.s64 	%rd141, %rd44, %rd140;
	ld.global.nc.f32 	%f10, [%rd141];
	add.s64 	%rd142, %rd47, %rd140;
	ld.global.f32 	%f11, [%rd142];
	mul.rn.f32 	%f12, %f1, %f10;
	add.rn.f32 	%f13, %f11, %f12;
	st.global.f32 	[%rd142], %f13;
	bra.uni 	$L__BB0_23;
$L__BB0_25:
	ret;

}
// -----// IR Dump After mlir::iree_compiler::IREE::HAL::SerializeTargetExecutablesPass (iree-hal-serialize-target-executables) //----- //
hal.executable private @main_dispatch_0 {
  hal.executable.binary public @cuda_nvptx_fb attributes {data = dense<"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vector<6926xi8>, format = "cuda-nvptx-fb", mime_type = "application/x-flatbuffers"}
}

// -----// IR Dump After mlir::iree_compiler::IREE::HAL::SerializeExecutablesPass (iree-hal-serialize-executables) //----- //
hal.executable private @main_dispatch_0 {
  hal.executable.binary public @cuda_nvptx_fb attributes {data = dense<"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vector<6926xi8>, format = "cuda-nvptx-fb", mime_type = "application/x-flatbuffers"}
}

// -----// IR Dump After SymbolDCE (symbol-dce) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private @_device_query_0 : i1
  util.global private @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.global private @_executable_main_dispatch_0 : !hal.executable
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    util.global.store %value, @_device_query_0 : i1
    %device_0 = hal.ex.shared_device : !hal.device
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device_0 : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer>]) : !hal.descriptor_set_layout
    util.global.store %descriptor_set_layout, @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    %_descriptor_set_layout_0 = util.global.load @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    %device_1 = hal.ex.shared_device : !hal.device
    %pipeline_layout = hal.pipeline_layout.create device(%device_1 : !hal.device) push_constants(4) layouts([%_descriptor_set_layout_0]) : !hal.pipeline_layout
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    %c-1 = arith.constant -1 : index
    %c0 = arith.constant 0 : index
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %device_2 = hal.ex.shared_device : !hal.device
    %0 = arith.select %_device_query_0, %c0, %c-1 : index
    %1 = arith.index_cast %0 : index to i32
    cf.switch %1 : i32, [
      default: ^bb2,
      0: ^bb1
    ]
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device_2 : !hal.device) target(@main_dispatch_0::@cuda_nvptx_fb) layouts([%_pipeline_layout_0]) : !hal.executable
    cf.br ^bb3(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %2 = util.null : !hal.executable
    cf.br ^bb3(%2 : !hal.executable)
  ^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %3, @_executable_main_dispatch_0 : !hal.executable
    cf.br ^bb4
  ^bb4:  // pred: ^bb3
    util.initializer.return
  }
  hal.executable private @main_dispatch_0 {
    hal.executable.binary public @cuda_nvptx_fb attributes {data = dense<"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vector<6926xi8>, format = "cuda-nvptx-fb", mime_type = "application/x-flatbuffers"}
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c32_i64 = arith.constant 32 : i64
    %c-1_i64 = arith.constant -1 : i64
    %c0_i64 = arith.constant 0 : i64
    %c-1_i32 = arith.constant -1 : i32
    %c-1 = arith.constant -1 : index
    %c1 = arith.constant 1 : index
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %4 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%3}
    %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    %5 = arith.index_castui %0 : index to i64
    %6 = arith.trunci %5 : i64 to i32
    %7 = arith.shrui %5, %c32_i64 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %1 : index to i64
    %10 = arith.trunci %9 : i64 to i32
    %11 = arith.shrui %9, %c32_i64 : i64
    %12 = arith.trunci %11 : i64 to i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    %13 = arith.select %_device_query_0, %c0, %c-1 : index
    %14 = arith.index_cast %13 : index to i32
    cf.switch %14 : i32, [
      default: ^bb2,
      0: ^bb1
    ]
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout) offset(0) values([%6, %8, %10, %12]) : i32, i32, i32, i32
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%buffer : !hal.buffer)[%c0, %3], 
      %c1 = (%transient_buffer : !hal.buffer)[%c0, %3]
    ])
    %c128 = arith.constant 128 : index
    %c0_0 = arith.constant 0 : index
    %c1_1 = arith.constant 1 : index
    %15 = arith.cmpi sle, %1, %c0_0 : index
    %16 = arith.subi %c0_0, %1 : index
    %17 = arith.subi %1, %c1_1 : index
    %18 = arith.select %15, %16, %17 : index
    %19 = arith.divsi %18, %c128 : index
    %20 = arith.subi %c0_0, %19 : index
    %21 = arith.addi %19, %c1_1 : index
    %22 = arith.select %15, %20, %21 : index
    %c32 = arith.constant 32 : index
    %c0_2 = arith.constant 0 : index
    %c1_3 = arith.constant 1 : index
    %23 = arith.cmpi sle, %0, %c0_2 : index
    %24 = arith.subi %c0_2, %0 : index
    %25 = arith.subi %0, %c1_3 : index
    %26 = arith.select %23, %24, %25 : index
    %27 = arith.divsi %26, %c32 : index
    %28 = arith.subi %c0_2, %27 : index
    %29 = arith.addi %27, %c1_3 : index
    %30 = arith.select %23, %28, %29 : index
    %31 = arith.muli %22, %30 : index
    %_executable_main_dispatch_0 = util.global.load @_executable_main_dispatch_0 : !hal.executable
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_main_dispatch_0 : !hal.executable)[0] workgroups([%31, %c1, %c1])
    cf.br ^bb3
  ^bb2:  // pred: ^bb0
    cf.br ^bb3
  ^bb3:  // 2 preds: ^bb1, ^bb2
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_4 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status_5 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence_4) commands([%cmd])
    %status_6 = hal.fence.await until([%fence_4]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status_6, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %3] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After CSE (cse) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda], iree.fixedpoint.iteration = 0 : index} {
  util.global private @_device_query_0 : i1
  util.global private @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.global private @_executable_main_dispatch_0 : !hal.executable
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    util.global.store %value, @_device_query_0 : i1
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer>]) : !hal.descriptor_set_layout
    util.global.store %descriptor_set_layout, @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    %_descriptor_set_layout_0 = util.global.load @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(4) layouts([%_descriptor_set_layout_0]) : !hal.pipeline_layout
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    %c-1 = arith.constant -1 : index
    %c0 = arith.constant 0 : index
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %0 = arith.select %_device_query_0, %c0, %c-1 : index
    %1 = arith.index_cast %0 : index to i32
    cf.switch %1 : i32, [
      default: ^bb2,
      0: ^bb1
    ]
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device : !hal.device) target(@main_dispatch_0::@cuda_nvptx_fb) layouts([%_pipeline_layout_0]) : !hal.executable
    cf.br ^bb3(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %2 = util.null : !hal.executable
    cf.br ^bb3(%2 : !hal.executable)
  ^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %3, @_executable_main_dispatch_0 : !hal.executable
    cf.br ^bb4
  ^bb4:  // pred: ^bb3
    util.initializer.return
  }
  hal.executable private @main_dispatch_0 {
    hal.executable.binary public @cuda_nvptx_fb attributes {data = dense<"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vector<6926xi8>, format = "cuda-nvptx-fb", mime_type = "application/x-flatbuffers"}
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c32_i64 = arith.constant 32 : i64
    %c-1_i64 = arith.constant -1 : i64
    %c0_i64 = arith.constant 0 : i64
    %c-1_i32 = arith.constant -1 : i32
    %c-1 = arith.constant -1 : index
    %c1 = arith.constant 1 : index
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %4 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%3}
    %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    %5 = arith.index_castui %0 : index to i64
    %6 = arith.trunci %5 : i64 to i32
    %7 = arith.shrui %5, %c32_i64 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %1 : index to i64
    %10 = arith.trunci %9 : i64 to i32
    %11 = arith.shrui %9, %c32_i64 : i64
    %12 = arith.trunci %11 : i64 to i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    %13 = arith.select %_device_query_0, %c0, %c-1 : index
    %14 = arith.index_cast %13 : index to i32
    cf.switch %14 : i32, [
      default: ^bb2,
      0: ^bb1
    ]
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout) offset(0) values([%6, %8, %10, %12]) : i32, i32, i32, i32
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%buffer : !hal.buffer)[%c0, %3], 
      %c1 = (%transient_buffer : !hal.buffer)[%c0, %3]
    ])
    %c128 = arith.constant 128 : index
    %15 = arith.cmpi sle, %1, %c0 : index
    %16 = arith.subi %c0, %1 : index
    %17 = arith.subi %1, %c1 : index
    %18 = arith.select %15, %16, %17 : index
    %19 = arith.divsi %18, %c128 : index
    %20 = arith.subi %c0, %19 : index
    %21 = arith.addi %19, %c1 : index
    %22 = arith.select %15, %20, %21 : index
    %c32 = arith.constant 32 : index
    %23 = arith.cmpi sle, %0, %c0 : index
    %24 = arith.subi %c0, %0 : index
    %25 = arith.subi %0, %c1 : index
    %26 = arith.select %23, %24, %25 : index
    %27 = arith.divsi %26, %c32 : index
    %28 = arith.subi %c0, %27 : index
    %29 = arith.addi %27, %c1 : index
    %30 = arith.select %23, %28, %29 : index
    %31 = arith.muli %22, %30 : index
    %_executable_main_dispatch_0 = util.global.load @_executable_main_dispatch_0 : !hal.executable
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_main_dispatch_0 : !hal.executable)[0] workgroups([%31, %c1, %c1])
    cf.br ^bb3
  ^bb2:  // pred: ^bb0
    cf.br ^bb3
  ^bb3:  // 2 preds: ^bb1, ^bb2
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_0 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status_1 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence_0) commands([%cmd])
    %status_2 = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status_2, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %3] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda], iree.fixedpoint.iteration = 0 : index} {
  util.global private @_device_query_0 : i1
  util.global private @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.global private @_executable_main_dispatch_0 : !hal.executable
  util.initializer {
    %c0 = arith.constant 0 : index
    %c-1 = arith.constant -1 : index
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    util.global.store %value, @_device_query_0 : i1
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer>]) : !hal.descriptor_set_layout
    util.global.store %descriptor_set_layout, @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    %_descriptor_set_layout_0 = util.global.load @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(4) layouts([%_descriptor_set_layout_0]) : !hal.pipeline_layout
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %0 = arith.select %_device_query_0, %c0, %c-1 : index
    %1 = arith.index_cast %0 : index to i32
    cf.switch %1 : i32, [
      default: ^bb2,
      0: ^bb1
    ]
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device : !hal.device) target(@main_dispatch_0::@cuda_nvptx_fb) layouts([%_pipeline_layout_0]) : !hal.executable
    cf.br ^bb3(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %2 = util.null : !hal.executable
    cf.br ^bb3(%2 : !hal.executable)
  ^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %3, @_executable_main_dispatch_0 : !hal.executable
    util.initializer.return
  }
  hal.executable private @main_dispatch_0 {
    hal.executable.binary public @cuda_nvptx_fb attributes {data = dense<"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vector<6926xi8>, format = "cuda-nvptx-fb", mime_type = "application/x-flatbuffers"}
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c32 = arith.constant 32 : index
    %c128 = arith.constant 128 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c32_i64 = arith.constant 32 : i64
    %c-1_i64 = arith.constant -1 : i64
    %c0_i64 = arith.constant 0 : i64
    %c-1_i32 = arith.constant -1 : i32
    %c-1 = arith.constant -1 : index
    %c1 = arith.constant 1 : index
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %4 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%3}
    %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    %5 = arith.index_castui %0 : index to i64
    %6 = arith.trunci %5 : i64 to i32
    %7 = arith.shrui %5, %c32_i64 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %1 : index to i64
    %10 = arith.trunci %9 : i64 to i32
    %11 = arith.shrui %9, %c32_i64 : i64
    %12 = arith.trunci %11 : i64 to i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    %13 = arith.select %_device_query_0, %c0, %c-1 : index
    %14 = arith.index_cast %13 : index to i32
    cf.switch %14 : i32, [
      default: ^bb2,
      0: ^bb1
    ]
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout) offset(0) values([%6, %8, %10, %12]) : i32, i32, i32, i32
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%buffer : !hal.buffer)[%c0, %3], 
      %c1 = (%transient_buffer : !hal.buffer)[%c0, %3]
    ])
    %15 = arith.cmpi sle, %1, %c0 : index
    %16 = arith.subi %c0, %1 : index
    %17 = arith.subi %1, %c1 : index
    %18 = arith.select %15, %16, %17 : index
    %19 = arith.divsi %18, %c128 : index
    %20 = arith.subi %c0, %19 : index
    %21 = arith.addi %19, %c1 : index
    %22 = arith.select %15, %20, %21 : index
    %23 = arith.cmpi sle, %0, %c0 : index
    %24 = arith.subi %c0, %0 : index
    %25 = arith.subi %0, %c1 : index
    %26 = arith.select %23, %24, %25 : index
    %27 = arith.divsi %26, %c32 : index
    %28 = arith.subi %c0, %27 : index
    %29 = arith.addi %27, %c1 : index
    %30 = arith.select %23, %28, %29 : index
    %31 = arith.muli %22, %30 : index
    %_executable_main_dispatch_0 = util.global.load @_executable_main_dispatch_0 : !hal.executable
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_main_dispatch_0 : !hal.executable)[0] workgroups([%31, %c1, %c1])
    cf.br ^bb2
  ^bb2:  // 2 preds: ^bb0, ^bb1
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_0 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status_1 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence_0) commands([%cmd])
    %status_2 = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status_2, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %3] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After CSE (cse) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda], iree.fixedpoint.iteration = 0 : index} {
  util.global private @_device_query_0 : i1
  util.global private @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.global private @_executable_main_dispatch_0 : !hal.executable
  util.initializer {
    %c0 = arith.constant 0 : index
    %c-1 = arith.constant -1 : index
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    util.global.store %value, @_device_query_0 : i1
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer>]) : !hal.descriptor_set_layout
    util.global.store %descriptor_set_layout, @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    %_descriptor_set_layout_0 = util.global.load @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(4) layouts([%_descriptor_set_layout_0]) : !hal.pipeline_layout
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %0 = arith.select %_device_query_0, %c0, %c-1 : index
    %1 = arith.index_cast %0 : index to i32
    cf.switch %1 : i32, [
      default: ^bb2,
      0: ^bb1
    ]
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device : !hal.device) target(@main_dispatch_0::@cuda_nvptx_fb) layouts([%_pipeline_layout_0]) : !hal.executable
    cf.br ^bb3(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %2 = util.null : !hal.executable
    cf.br ^bb3(%2 : !hal.executable)
  ^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %3, @_executable_main_dispatch_0 : !hal.executable
    util.initializer.return
  }
  hal.executable private @main_dispatch_0 {
    hal.executable.binary public @cuda_nvptx_fb attributes {data = dense<"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vector<6926xi8>, format = "cuda-nvptx-fb", mime_type = "application/x-flatbuffers"}
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c32 = arith.constant 32 : index
    %c128 = arith.constant 128 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c32_i64 = arith.constant 32 : i64
    %c-1_i64 = arith.constant -1 : i64
    %c0_i64 = arith.constant 0 : i64
    %c-1_i32 = arith.constant -1 : i32
    %c-1 = arith.constant -1 : index
    %c1 = arith.constant 1 : index
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %4 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%3}
    %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    %5 = arith.index_castui %0 : index to i64
    %6 = arith.trunci %5 : i64 to i32
    %7 = arith.shrui %5, %c32_i64 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %1 : index to i64
    %10 = arith.trunci %9 : i64 to i32
    %11 = arith.shrui %9, %c32_i64 : i64
    %12 = arith.trunci %11 : i64 to i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    %13 = arith.select %_device_query_0, %c0, %c-1 : index
    %14 = arith.index_cast %13 : index to i32
    cf.switch %14 : i32, [
      default: ^bb2,
      0: ^bb1
    ]
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout) offset(0) values([%6, %8, %10, %12]) : i32, i32, i32, i32
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%buffer : !hal.buffer)[%c0, %3], 
      %c1 = (%transient_buffer : !hal.buffer)[%c0, %3]
    ])
    %15 = arith.cmpi sle, %1, %c0 : index
    %16 = arith.subi %c0, %1 : index
    %17 = arith.subi %1, %c1 : index
    %18 = arith.select %15, %16, %17 : index
    %19 = arith.divsi %18, %c128 : index
    %20 = arith.subi %c0, %19 : index
    %21 = arith.addi %19, %c1 : index
    %22 = arith.select %15, %20, %21 : index
    %23 = arith.cmpi sle, %0, %c0 : index
    %24 = arith.subi %c0, %0 : index
    %25 = arith.subi %0, %c1 : index
    %26 = arith.select %23, %24, %25 : index
    %27 = arith.divsi %26, %c32 : index
    %28 = arith.subi %c0, %27 : index
    %29 = arith.addi %27, %c1 : index
    %30 = arith.select %23, %28, %29 : index
    %31 = arith.muli %22, %30 : index
    %_executable_main_dispatch_0 = util.global.load @_executable_main_dispatch_0 : !hal.executable
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_main_dispatch_0 : !hal.executable)[0] workgroups([%31, %c1, %c1])
    cf.br ^bb2
  ^bb2:  // 2 preds: ^bb0, ^bb1
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_0 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status_1 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence_0) commands([%cmd])
    %status_2 = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status_2, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %3] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.initializer {
  %c0 = arith.constant 0 : index
  %c-1 = arith.constant -1 : index
  %device = hal.ex.shared_device : !hal.device
  %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
  %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer>]) : !hal.descriptor_set_layout
  %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(4) layouts([%descriptor_set_layout]) : !hal.pipeline_layout
  %0 = arith.select %value, %c0, %c-1 : index
  %1 = arith.index_cast %0 : index to i32
  util.global.store %descriptor_set_layout, @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  util.global.store %value, @_device_query_0 : i1
  util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
  cf.switch %1 : i32, [
    default: ^bb2,
    0: ^bb1
  ]
^bb1:  // pred: ^bb0
  %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
  %exe = hal.executable.create device(%device : !hal.device) target(@main_dispatch_0::@cuda_nvptx_fb) layouts([%_pipeline_layout_0]) : !hal.executable
  cf.br ^bb3(%exe : !hal.executable)
^bb2:  // pred: ^bb0
  %2 = util.null : !hal.executable
  cf.br ^bb3(%2 : !hal.executable)
^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
  util.global.store %3, @_executable_main_dispatch_0 : !hal.executable
  util.initializer.return
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %_device_query_0 = util.global.load @_device_query_0 : i1
  %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
  %_executable_main_dispatch_0 = util.global.load @_executable_main_dispatch_0 : !hal.executable
  %c32 = arith.constant 32 : index
  %c128 = arith.constant 128 : index
  %c553648160_i32 = arith.constant 553648160 : i32
  %c1_i32 = arith.constant 1 : i32
  %c0 = arith.constant 0 : index
  %c4 = arith.constant 4 : index
  %c32_i64 = arith.constant 32 : i64
  %c-1_i64 = arith.constant -1 : i64
  %c0_i64 = arith.constant 0 : i64
  %c-1_i32 = arith.constant -1 : i32
  %c-1 = arith.constant -1 : index
  %c1 = arith.constant 1 : index
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %device = hal.ex.shared_device : !hal.device
  %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %4 = util.null : !hal.fence
  %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
  %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%3}
  %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
  %5 = arith.index_castui %0 : index to i64
  %6 = arith.trunci %5 : i64 to i32
  %7 = arith.shrui %5, %c32_i64 : i64
  %8 = arith.trunci %7 : i64 to i32
  %9 = arith.index_castui %1 : index to i64
  %10 = arith.trunci %9 : i64 to i32
  %11 = arith.shrui %9, %c32_i64 : i64
  %12 = arith.trunci %11 : i64 to i32
  %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
  %13 = arith.select %_device_query_0, %c0, %c-1 : index
  %14 = arith.index_cast %13 : index to i32
  cf.switch %14 : i32, [
    default: ^bb2,
    0: ^bb1
  ]
^bb1:  // pred: ^bb0
  hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout) offset(0) values([%6, %8, %10, %12]) : i32, i32, i32, i32
  hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
    %c0 = (%buffer : !hal.buffer)[%c0, %3], 
    %c1 = (%transient_buffer : !hal.buffer)[%c0, %3]
  ])
  %15 = arith.cmpi sle, %1, %c0 : index
  %16 = arith.subi %c0, %1 : index
  %17 = arith.subi %1, %c1 : index
  %18 = arith.select %15, %16, %17 : index
  %19 = arith.divsi %18, %c128 : index
  %20 = arith.subi %c0, %19 : index
  %21 = arith.addi %19, %c1 : index
  %22 = arith.select %15, %20, %21 : index
  %23 = arith.cmpi sle, %0, %c0 : index
  %24 = arith.subi %c0, %0 : index
  %25 = arith.subi %0, %c1 : index
  %26 = arith.select %23, %24, %25 : index
  %27 = arith.divsi %26, %c32 : index
  %28 = arith.subi %c0, %27 : index
  %29 = arith.addi %27, %c1 : index
  %30 = arith.select %23, %28, %29 : index
  %31 = arith.muli %22, %30 : index
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_main_dispatch_0 : !hal.executable)[0] workgroups([%31, %c1, %c1])
  cf.br ^bb2
^bb2:  // 2 preds: ^bb0, ^bb1
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  %fence_0 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
  %status_1 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
  hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence_0) commands([%cmd])
  %status_2 = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) : i32
  util.status.check_ok %status_2, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %3] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
  return %view : !hal.buffer_view
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda], iree.fixedpoint.iteration = 0 : index} {
  util.global private @_device_query_0 : i1
  util.global private @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.global private @_executable_main_dispatch_0 : !hal.executable
  util.initializer {
    %c0 = arith.constant 0 : index
    %c-1 = arith.constant -1 : index
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer>]) : !hal.descriptor_set_layout
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(4) layouts([%descriptor_set_layout]) : !hal.pipeline_layout
    %0 = arith.select %value, %c0, %c-1 : index
    %1 = arith.index_cast %0 : index to i32
    util.global.store %descriptor_set_layout, @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    util.global.store %value, @_device_query_0 : i1
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    cf.switch %1 : i32, [
      default: ^bb2,
      0: ^bb1
    ]
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device : !hal.device) target(@main_dispatch_0::@cuda_nvptx_fb) layouts([%_pipeline_layout_0]) : !hal.executable
    cf.br ^bb3(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %2 = util.null : !hal.executable
    cf.br ^bb3(%2 : !hal.executable)
  ^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %3, @_executable_main_dispatch_0 : !hal.executable
    util.initializer.return
  }
  hal.executable private @main_dispatch_0 {
    hal.executable.binary public @cuda_nvptx_fb attributes {data = dense<"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vector<6926xi8>, format = "cuda-nvptx-fb", mime_type = "application/x-flatbuffers"}
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c1 = arith.constant 1 : index
    %c-1 = arith.constant -1 : index
    %c-1_i32 = arith.constant -1 : i32
    %c0_i64 = arith.constant 0 : i64
    %c-1_i64 = arith.constant -1 : i64
    %c32_i64 = arith.constant 32 : i64
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %c128 = arith.constant 128 : index
    %c32 = arith.constant 32 : index
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %_executable_main_dispatch_0 = util.global.load @_executable_main_dispatch_0 : !hal.executable
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %4 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%3}
    %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    %5 = arith.index_castui %0 : index to i64
    %6 = arith.trunci %5 : i64 to i32
    %7 = arith.shrui %5, %c32_i64 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %1 : index to i64
    %10 = arith.trunci %9 : i64 to i32
    %11 = arith.shrui %9, %c32_i64 : i64
    %12 = arith.trunci %11 : i64 to i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    %13 = arith.select %_device_query_0, %c0, %c-1 : index
    %14 = arith.index_cast %13 : index to i32
    cf.switch %14 : i32, [
      default: ^bb2,
      0: ^bb1
    ]
  ^bb1:  // pred: ^bb0
    hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout) offset(0) values([%6, %8, %10, %12]) : i32, i32, i32, i32
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%buffer : !hal.buffer)[%c0, %3], 
      %c1 = (%transient_buffer : !hal.buffer)[%c0, %3]
    ])
    %15 = arith.cmpi sle, %1, %c0 : index
    %16 = arith.subi %c0, %1 : index
    %17 = arith.subi %1, %c1 : index
    %18 = arith.select %15, %16, %17 : index
    %19 = arith.divsi %18, %c128 : index
    %20 = arith.subi %c0, %19 : index
    %21 = arith.addi %19, %c1 : index
    %22 = arith.select %15, %20, %21 : index
    %23 = arith.cmpi sle, %0, %c0 : index
    %24 = arith.subi %c0, %0 : index
    %25 = arith.subi %0, %c1 : index
    %26 = arith.select %23, %24, %25 : index
    %27 = arith.divsi %26, %c32 : index
    %28 = arith.subi %c0, %27 : index
    %29 = arith.addi %27, %c1 : index
    %30 = arith.select %23, %28, %29 : index
    %31 = arith.muli %22, %30 : index
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_main_dispatch_0 : !hal.executable)[0] workgroups([%31, %c1, %c1])
    cf.br ^bb2
  ^bb2:  // 2 preds: ^bb0, ^bb1
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_0 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status_1 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence_0) commands([%cmd])
    %status_2 = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status_2, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %3] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda], iree.fixedpoint.iteration = 0 : index} {
  util.global private @_device_query_0 : i1
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.global private @_executable_main_dispatch_0 : !hal.executable
  util.initializer {
    %c0 = arith.constant 0 : index
    %c-1 = arith.constant -1 : index
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer>]) : !hal.descriptor_set_layout
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(4) layouts([%descriptor_set_layout]) : !hal.pipeline_layout
    %0 = arith.select %value, %c0, %c-1 : index
    %1 = arith.index_cast %0 : index to i32
    util.global.store %value, @_device_query_0 : i1
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    cf.switch %1 : i32, [
      default: ^bb2,
      0: ^bb1
    ]
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device : !hal.device) target(@main_dispatch_0::@cuda_nvptx_fb) layouts([%_pipeline_layout_0]) : !hal.executable
    cf.br ^bb3(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %2 = util.null : !hal.executable
    cf.br ^bb3(%2 : !hal.executable)
  ^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %3, @_executable_main_dispatch_0 : !hal.executable
    util.initializer.return
  }
  hal.executable private @main_dispatch_0 {
    hal.executable.binary public @cuda_nvptx_fb attributes {data = dense<"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vector<6926xi8>, format = "cuda-nvptx-fb", mime_type = "application/x-flatbuffers"}
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c1 = arith.constant 1 : index
    %c-1 = arith.constant -1 : index
    %c-1_i32 = arith.constant -1 : i32
    %c0_i64 = arith.constant 0 : i64
    %c-1_i64 = arith.constant -1 : i64
    %c32_i64 = arith.constant 32 : i64
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %c128 = arith.constant 128 : index
    %c32 = arith.constant 32 : index
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %_executable_main_dispatch_0 = util.global.load @_executable_main_dispatch_0 : !hal.executable
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %4 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%3}
    %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    %5 = arith.index_castui %0 : index to i64
    %6 = arith.trunci %5 : i64 to i32
    %7 = arith.shrui %5, %c32_i64 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %1 : index to i64
    %10 = arith.trunci %9 : i64 to i32
    %11 = arith.shrui %9, %c32_i64 : i64
    %12 = arith.trunci %11 : i64 to i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    %13 = arith.select %_device_query_0, %c0, %c-1 : index
    %14 = arith.index_cast %13 : index to i32
    cf.switch %14 : i32, [
      default: ^bb2,
      0: ^bb1
    ]
  ^bb1:  // pred: ^bb0
    hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout) offset(0) values([%6, %8, %10, %12]) : i32, i32, i32, i32
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%buffer : !hal.buffer)[%c0, %3], 
      %c1 = (%transient_buffer : !hal.buffer)[%c0, %3]
    ])
    %15 = arith.cmpi sle, %1, %c0 : index
    %16 = arith.subi %c0, %1 : index
    %17 = arith.subi %1, %c1 : index
    %18 = arith.select %15, %16, %17 : index
    %19 = arith.divsi %18, %c128 : index
    %20 = arith.subi %c0, %19 : index
    %21 = arith.addi %19, %c1 : index
    %22 = arith.select %15, %20, %21 : index
    %23 = arith.cmpi sle, %0, %c0 : index
    %24 = arith.subi %c0, %0 : index
    %25 = arith.subi %0, %c1 : index
    %26 = arith.select %23, %24, %25 : index
    %27 = arith.divsi %26, %c32 : index
    %28 = arith.subi %c0, %27 : index
    %29 = arith.addi %27, %c1 : index
    %30 = arith.select %23, %28, %29 : index
    %31 = arith.muli %22, %30 : index
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_main_dispatch_0 : !hal.executable)[0] workgroups([%31, %c1, %c1])
    cf.br ^bb2
  ^bb2:  // 2 preds: ^bb0, ^bb1
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_0 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status_1 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence_0) commands([%cmd])
    %status_2 = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status_2, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %3] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda], iree.fixedpoint.iteration = 0 : index} {
  util.global private @_device_query_0 : i1
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.global private @_executable_main_dispatch_0 : !hal.executable
  util.initializer {
    %c0 = arith.constant 0 : index
    %c-1 = arith.constant -1 : index
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer>]) : !hal.descriptor_set_layout
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(4) layouts([%descriptor_set_layout]) : !hal.pipeline_layout
    %0 = arith.select %value, %c0, %c-1 : index
    %1 = arith.index_cast %0 : index to i32
    util.global.store %value, @_device_query_0 : i1
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    cf.switch %1 : i32, [
      default: ^bb2,
      0: ^bb1
    ]
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device : !hal.device) target(@main_dispatch_0::@cuda_nvptx_fb) layouts([%_pipeline_layout_0]) : !hal.executable
    cf.br ^bb3(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %2 = util.null : !hal.executable
    cf.br ^bb3(%2 : !hal.executable)
  ^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %3, @_executable_main_dispatch_0 : !hal.executable
    util.initializer.return
  }
  hal.executable private @main_dispatch_0 {
    hal.executable.binary public @cuda_nvptx_fb attributes {data = dense<"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vector<6926xi8>, format = "cuda-nvptx-fb", mime_type = "application/x-flatbuffers"}
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c1 = arith.constant 1 : index
    %c-1 = arith.constant -1 : index
    %c-1_i32 = arith.constant -1 : i32
    %c0_i64 = arith.constant 0 : i64
    %c-1_i64 = arith.constant -1 : i64
    %c32_i64 = arith.constant 32 : i64
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %c128 = arith.constant 128 : index
    %c32 = arith.constant 32 : index
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %_executable_main_dispatch_0 = util.global.load @_executable_main_dispatch_0 : !hal.executable
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %4 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%3}
    %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    %5 = arith.index_castui %0 : index to i64
    %6 = arith.trunci %5 : i64 to i32
    %7 = arith.shrui %5, %c32_i64 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %1 : index to i64
    %10 = arith.trunci %9 : i64 to i32
    %11 = arith.shrui %9, %c32_i64 : i64
    %12 = arith.trunci %11 : i64 to i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    %13 = arith.select %_device_query_0, %c0, %c-1 : index
    %14 = arith.index_cast %13 : index to i32
    cf.switch %14 : i32, [
      default: ^bb2,
      0: ^bb1
    ]
  ^bb1:  // pred: ^bb0
    hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout) offset(0) values([%6, %8, %10, %12]) : i32, i32, i32, i32
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%buffer : !hal.buffer)[%c0, %3], 
      %c1 = (%transient_buffer : !hal.buffer)[%c0, %3]
    ])
    %15 = arith.cmpi sle, %1, %c0 : index
    %16 = arith.subi %c0, %1 : index
    %17 = arith.subi %1, %c1 : index
    %18 = arith.select %15, %16, %17 : index
    %19 = arith.divsi %18, %c128 : index
    %20 = arith.subi %c0, %19 : index
    %21 = arith.addi %19, %c1 : index
    %22 = arith.select %15, %20, %21 : index
    %23 = arith.cmpi sle, %0, %c0 : index
    %24 = arith.subi %c0, %0 : index
    %25 = arith.subi %0, %c1 : index
    %26 = arith.select %23, %24, %25 : index
    %27 = arith.divsi %26, %c32 : index
    %28 = arith.subi %c0, %27 : index
    %29 = arith.addi %27, %c1 : index
    %30 = arith.select %23, %28, %29 : index
    %31 = arith.muli %22, %30 : index
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_main_dispatch_0 : !hal.executable)[0] workgroups([%31, %c1, %c1])
    cf.br ^bb2
  ^bb2:  // 2 preds: ^bb0, ^bb1
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_0 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status_1 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence_0) commands([%cmd])
    %status_2 = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status_2, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %3] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda], iree.fixedpoint.iteration = 0 : index} {
  util.global private @_device_query_0 : i1
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.global private @_executable_main_dispatch_0 : !hal.executable
  util.initializer {
    %c0 = arith.constant 0 : index
    %c-1 = arith.constant -1 : index
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer>]) : !hal.descriptor_set_layout
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(4) layouts([%descriptor_set_layout]) : !hal.pipeline_layout
    %0 = arith.select %value, %c0, %c-1 : index
    %1 = arith.index_cast %0 : index to i32
    util.global.store %value, @_device_query_0 : i1
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    cf.switch %1 : i32, [
      default: ^bb2,
      0: ^bb1
    ]
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device : !hal.device) target(@main_dispatch_0::@cuda_nvptx_fb) layouts([%_pipeline_layout_0]) : !hal.executable
    cf.br ^bb3(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %2 = util.null : !hal.executable
    cf.br ^bb3(%2 : !hal.executable)
  ^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %3, @_executable_main_dispatch_0 : !hal.executable
    util.initializer.return
  }
  hal.executable private @main_dispatch_0 {
    hal.executable.binary public @cuda_nvptx_fb attributes {data = dense<"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vector<6926xi8>, format = "cuda-nvptx-fb", mime_type = "application/x-flatbuffers"}
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c1 = arith.constant 1 : index
    %c-1 = arith.constant -1 : index
    %c-1_i32 = arith.constant -1 : i32
    %c0_i64 = arith.constant 0 : i64
    %c-1_i64 = arith.constant -1 : i64
    %c32_i64 = arith.constant 32 : i64
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %c128 = arith.constant 128 : index
    %c32 = arith.constant 32 : index
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %_executable_main_dispatch_0 = util.global.load @_executable_main_dispatch_0 : !hal.executable
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %4 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%3}
    %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    %5 = arith.index_castui %0 : index to i64
    %6 = arith.trunci %5 : i64 to i32
    %7 = arith.shrui %5, %c32_i64 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %1 : index to i64
    %10 = arith.trunci %9 : i64 to i32
    %11 = arith.shrui %9, %c32_i64 : i64
    %12 = arith.trunci %11 : i64 to i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    %13 = arith.select %_device_query_0, %c0, %c-1 : index
    %14 = arith.index_cast %13 : index to i32
    cf.switch %14 : i32, [
      default: ^bb2,
      0: ^bb1
    ]
  ^bb1:  // pred: ^bb0
    hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout) offset(0) values([%6, %8, %10, %12]) : i32, i32, i32, i32
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%buffer : !hal.buffer)[%c0, %3], 
      %c1 = (%transient_buffer : !hal.buffer)[%c0, %3]
    ])
    %15 = arith.cmpi sle, %1, %c0 : index
    %16 = arith.subi %c0, %1 : index
    %17 = arith.subi %1, %c1 : index
    %18 = arith.select %15, %16, %17 : index
    %19 = arith.divsi %18, %c128 : index
    %20 = arith.subi %c0, %19 : index
    %21 = arith.addi %19, %c1 : index
    %22 = arith.select %15, %20, %21 : index
    %23 = arith.cmpi sle, %0, %c0 : index
    %24 = arith.subi %c0, %0 : index
    %25 = arith.subi %0, %c1 : index
    %26 = arith.select %23, %24, %25 : index
    %27 = arith.divsi %26, %c32 : index
    %28 = arith.subi %c0, %27 : index
    %29 = arith.addi %27, %c1 : index
    %30 = arith.select %23, %28, %29 : index
    %31 = arith.muli %22, %30 : index
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_main_dispatch_0 : !hal.executable)[0] workgroups([%31, %c1, %c1])
    cf.br ^bb2
  ^bb2:  // 2 preds: ^bb0, ^bb1
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_0 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status_1 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence_0) commands([%cmd])
    %status_2 = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status_2, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %3] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After FixedPointIterator (iree-util-fixed-point-iterator) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private @_device_query_0 : i1
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.global private @_executable_main_dispatch_0 : !hal.executable
  util.initializer {
    %c0 = arith.constant 0 : index
    %c-1 = arith.constant -1 : index
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer>]) : !hal.descriptor_set_layout
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(4) layouts([%descriptor_set_layout]) : !hal.pipeline_layout
    %0 = arith.select %value, %c0, %c-1 : index
    %1 = arith.index_cast %0 : index to i32
    util.global.store %value, @_device_query_0 : i1
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    cf.switch %1 : i32, [
      default: ^bb2,
      0: ^bb1
    ]
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device : !hal.device) target(@main_dispatch_0::@cuda_nvptx_fb) layouts([%_pipeline_layout_0]) : !hal.executable
    cf.br ^bb3(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %2 = util.null : !hal.executable
    cf.br ^bb3(%2 : !hal.executable)
  ^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %3, @_executable_main_dispatch_0 : !hal.executable
    util.initializer.return
  }
  hal.executable private @main_dispatch_0 {
    hal.executable.binary public @cuda_nvptx_fb attributes {data = dense<"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vector<6926xi8>, format = "cuda-nvptx-fb", mime_type = "application/x-flatbuffers"}
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c1 = arith.constant 1 : index
    %c-1 = arith.constant -1 : index
    %c-1_i32 = arith.constant -1 : i32
    %c0_i64 = arith.constant 0 : i64
    %c-1_i64 = arith.constant -1 : i64
    %c32_i64 = arith.constant 32 : i64
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %c128 = arith.constant 128 : index
    %c32 = arith.constant 32 : index
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %_executable_main_dispatch_0 = util.global.load @_executable_main_dispatch_0 : !hal.executable
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %4 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%3}
    %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    %5 = arith.index_castui %0 : index to i64
    %6 = arith.trunci %5 : i64 to i32
    %7 = arith.shrui %5, %c32_i64 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %1 : index to i64
    %10 = arith.trunci %9 : i64 to i32
    %11 = arith.shrui %9, %c32_i64 : i64
    %12 = arith.trunci %11 : i64 to i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    %13 = arith.select %_device_query_0, %c0, %c-1 : index
    %14 = arith.index_cast %13 : index to i32
    cf.switch %14 : i32, [
      default: ^bb2,
      0: ^bb1
    ]
  ^bb1:  // pred: ^bb0
    hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout) offset(0) values([%6, %8, %10, %12]) : i32, i32, i32, i32
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%buffer : !hal.buffer)[%c0, %3], 
      %c1 = (%transient_buffer : !hal.buffer)[%c0, %3]
    ])
    %15 = arith.cmpi sle, %1, %c0 : index
    %16 = arith.subi %c0, %1 : index
    %17 = arith.subi %1, %c1 : index
    %18 = arith.select %15, %16, %17 : index
    %19 = arith.divsi %18, %c128 : index
    %20 = arith.subi %c0, %19 : index
    %21 = arith.addi %19, %c1 : index
    %22 = arith.select %15, %20, %21 : index
    %23 = arith.cmpi sle, %0, %c0 : index
    %24 = arith.subi %c0, %0 : index
    %25 = arith.subi %0, %c1 : index
    %26 = arith.select %23, %24, %25 : index
    %27 = arith.divsi %26, %c32 : index
    %28 = arith.subi %c0, %27 : index
    %29 = arith.addi %27, %c1 : index
    %30 = arith.select %23, %28, %29 : index
    %31 = arith.muli %22, %30 : index
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_main_dispatch_0 : !hal.executable)[0] workgroups([%31, %c1, %c1])
    cf.br ^bb2
  ^bb2:  // 2 preds: ^bb0, ^bb1
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_0 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status_1 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence_0) commands([%cmd])
    %status_2 = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status_2, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %3] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.initializer {
  %c0 = arith.constant 0 : index
  %c-1 = arith.constant -1 : index
  %device = hal.ex.shared_device : !hal.device
  %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
  %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer>]) : !hal.descriptor_set_layout
  %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(4) layouts([%descriptor_set_layout]) : !hal.pipeline_layout
  %0 = arith.select %value, %c0, %c-1 : index
  %1 = arith.index_cast %0 : index to i32
  util.global.store %value, @_device_query_0 : i1
  util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
  cf.switch %1 : i32, [
    default: ^bb2,
    0: ^bb1
  ]
^bb1:  // pred: ^bb0
  %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
  %exe = hal.executable.create device(%device : !hal.device) target(@main_dispatch_0::@cuda_nvptx_fb) layouts([%_pipeline_layout_0]) : !hal.executable
  cf.br ^bb3(%exe : !hal.executable)
^bb2:  // pred: ^bb0
  %2 = util.null : !hal.executable
  cf.br ^bb3(%2 : !hal.executable)
^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
  util.global.store %3, @_executable_main_dispatch_0 : !hal.executable
  util.initializer.return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c1 = arith.constant 1 : index
  %c-1 = arith.constant -1 : index
  %c-1_i32 = arith.constant -1 : i32
  %c0_i64 = arith.constant 0 : i64
  %c-1_i64 = arith.constant -1 : i64
  %c32_i64 = arith.constant 32 : i64
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %c128 = arith.constant 128 : index
  %c32 = arith.constant 32 : index
  %_device_query_0 = util.global.load @_device_query_0 : i1
  %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
  %_executable_main_dispatch_0 = util.global.load @_executable_main_dispatch_0 : !hal.executable
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %device = hal.ex.shared_device : !hal.device
  %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %4 = util.null : !hal.fence
  %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
  %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%3}
  %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
  %5 = arith.index_castui %0 : index to i64
  %6 = arith.trunci %5 : i64 to i32
  %7 = arith.shrui %5, %c32_i64 : i64
  %8 = arith.trunci %7 : i64 to i32
  %9 = arith.index_castui %1 : index to i64
  %10 = arith.trunci %9 : i64 to i32
  %11 = arith.shrui %9, %c32_i64 : i64
  %12 = arith.trunci %11 : i64 to i32
  %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
  %13 = arith.select %_device_query_0, %c0, %c-1 : index
  %14 = arith.index_cast %13 : index to i32
  cf.switch %14 : i32, [
    default: ^bb2,
    0: ^bb1
  ]
^bb1:  // pred: ^bb0
  hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout) offset(0) values([%6, %8, %10, %12]) : i32, i32, i32, i32
  hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
    %c0 = (%buffer : !hal.buffer)[%c0, %3], 
    %c1 = (%transient_buffer : !hal.buffer)[%c0, %3]
  ])
  %15 = arith.cmpi sle, %1, %c0 : index
  %16 = arith.subi %c0, %1 : index
  %17 = arith.subi %1, %c1 : index
  %18 = arith.select %15, %16, %17 : index
  %19 = arith.divsi %18, %c128 : index
  %20 = arith.subi %c0, %19 : index
  %21 = arith.addi %19, %c1 : index
  %22 = arith.select %15, %20, %21 : index
  %23 = arith.cmpi sle, %0, %c0 : index
  %24 = arith.subi %c0, %0 : index
  %25 = arith.subi %0, %c1 : index
  %26 = arith.select %23, %24, %25 : index
  %27 = arith.divsi %26, %c32 : index
  %28 = arith.subi %c0, %27 : index
  %29 = arith.addi %27, %c1 : index
  %30 = arith.select %23, %28, %29 : index
  %31 = arith.muli %22, %30 : index
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_main_dispatch_0 : !hal.executable)[0] workgroups([%31, %c1, %c1])
  cf.br ^bb2
^bb2:  // 2 preds: ^bb0, ^bb1
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  %fence_0 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
  %status_1 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
  hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence_0) commands([%cmd])
  %status_2 = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) : i32
  util.status.check_ok %status_2, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %3] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
  return %view : !hal.buffer_view
}

// -----// IR Dump After Inliner (inline) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private @_device_query_0 : i1
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.global private @_executable_main_dispatch_0 : !hal.executable
  util.initializer {
    %c0 = arith.constant 0 : index
    %c-1 = arith.constant -1 : index
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer>]) : !hal.descriptor_set_layout
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(4) layouts([%descriptor_set_layout]) : !hal.pipeline_layout
    %0 = arith.select %value, %c0, %c-1 : index
    %1 = arith.index_cast %0 : index to i32
    util.global.store %value, @_device_query_0 : i1
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    cf.switch %1 : i32, [
      default: ^bb2,
      0: ^bb1
    ]
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device : !hal.device) target(@main_dispatch_0::@cuda_nvptx_fb) layouts([%_pipeline_layout_0]) : !hal.executable
    cf.br ^bb3(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %2 = util.null : !hal.executable
    cf.br ^bb3(%2 : !hal.executable)
  ^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %3, @_executable_main_dispatch_0 : !hal.executable
    util.initializer.return
  }
  hal.executable private @main_dispatch_0 {
    hal.executable.binary public @cuda_nvptx_fb attributes {data = dense<"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vector<6926xi8>, format = "cuda-nvptx-fb", mime_type = "application/x-flatbuffers"}
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c1 = arith.constant 1 : index
    %c-1 = arith.constant -1 : index
    %c-1_i32 = arith.constant -1 : i32
    %c0_i64 = arith.constant 0 : i64
    %c-1_i64 = arith.constant -1 : i64
    %c32_i64 = arith.constant 32 : i64
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %c128 = arith.constant 128 : index
    %c32 = arith.constant 32 : index
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %_executable_main_dispatch_0 = util.global.load @_executable_main_dispatch_0 : !hal.executable
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %4 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%3}
    %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    %5 = arith.index_castui %0 : index to i64
    %6 = arith.trunci %5 : i64 to i32
    %7 = arith.shrui %5, %c32_i64 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %1 : index to i64
    %10 = arith.trunci %9 : i64 to i32
    %11 = arith.shrui %9, %c32_i64 : i64
    %12 = arith.trunci %11 : i64 to i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    %13 = arith.select %_device_query_0, %c0, %c-1 : index
    %14 = arith.index_cast %13 : index to i32
    cf.switch %14 : i32, [
      default: ^bb2,
      0: ^bb1
    ]
  ^bb1:  // pred: ^bb0
    hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout) offset(0) values([%6, %8, %10, %12]) : i32, i32, i32, i32
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%buffer : !hal.buffer)[%c0, %3], 
      %c1 = (%transient_buffer : !hal.buffer)[%c0, %3]
    ])
    %15 = arith.cmpi sle, %1, %c0 : index
    %16 = arith.subi %c0, %1 : index
    %17 = arith.subi %1, %c1 : index
    %18 = arith.select %15, %16, %17 : index
    %19 = arith.divsi %18, %c128 : index
    %20 = arith.subi %c0, %19 : index
    %21 = arith.addi %19, %c1 : index
    %22 = arith.select %15, %20, %21 : index
    %23 = arith.cmpi sle, %0, %c0 : index
    %24 = arith.subi %c0, %0 : index
    %25 = arith.subi %0, %c1 : index
    %26 = arith.select %23, %24, %25 : index
    %27 = arith.divsi %26, %c32 : index
    %28 = arith.subi %c0, %27 : index
    %29 = arith.addi %27, %c1 : index
    %30 = arith.select %23, %28, %29 : index
    %31 = arith.muli %22, %30 : index
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_main_dispatch_0 : !hal.executable)[0] workgroups([%31, %c1, %c1])
    cf.br ^bb2
  ^bb2:  // 2 preds: ^bb0, ^bb1
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_0 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status_1 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence_0) commands([%cmd])
    %status_2 = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status_2, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %3] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After SymbolDCE (symbol-dce) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private @_device_query_0 : i1
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.global private @_executable_main_dispatch_0 : !hal.executable
  util.initializer {
    %c0 = arith.constant 0 : index
    %c-1 = arith.constant -1 : index
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer>]) : !hal.descriptor_set_layout
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(4) layouts([%descriptor_set_layout]) : !hal.pipeline_layout
    %0 = arith.select %value, %c0, %c-1 : index
    %1 = arith.index_cast %0 : index to i32
    util.global.store %value, @_device_query_0 : i1
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    cf.switch %1 : i32, [
      default: ^bb2,
      0: ^bb1
    ]
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device : !hal.device) target(@main_dispatch_0::@cuda_nvptx_fb) layouts([%_pipeline_layout_0]) : !hal.executable
    cf.br ^bb3(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %2 = util.null : !hal.executable
    cf.br ^bb3(%2 : !hal.executable)
  ^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %3, @_executable_main_dispatch_0 : !hal.executable
    util.initializer.return
  }
  hal.executable private @main_dispatch_0 {
    hal.executable.binary public @cuda_nvptx_fb attributes {data = dense<"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vector<6926xi8>, format = "cuda-nvptx-fb", mime_type = "application/x-flatbuffers"}
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c1 = arith.constant 1 : index
    %c-1 = arith.constant -1 : index
    %c-1_i32 = arith.constant -1 : i32
    %c0_i64 = arith.constant 0 : i64
    %c-1_i64 = arith.constant -1 : i64
    %c32_i64 = arith.constant 32 : i64
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %c128 = arith.constant 128 : index
    %c32 = arith.constant 32 : index
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %_executable_main_dispatch_0 = util.global.load @_executable_main_dispatch_0 : !hal.executable
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %4 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%3}
    %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    %5 = arith.index_castui %0 : index to i64
    %6 = arith.trunci %5 : i64 to i32
    %7 = arith.shrui %5, %c32_i64 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %1 : index to i64
    %10 = arith.trunci %9 : i64 to i32
    %11 = arith.shrui %9, %c32_i64 : i64
    %12 = arith.trunci %11 : i64 to i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    %13 = arith.select %_device_query_0, %c0, %c-1 : index
    %14 = arith.index_cast %13 : index to i32
    cf.switch %14 : i32, [
      default: ^bb2,
      0: ^bb1
    ]
  ^bb1:  // pred: ^bb0
    hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout) offset(0) values([%6, %8, %10, %12]) : i32, i32, i32, i32
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%buffer : !hal.buffer)[%c0, %3], 
      %c1 = (%transient_buffer : !hal.buffer)[%c0, %3]
    ])
    %15 = arith.cmpi sle, %1, %c0 : index
    %16 = arith.subi %c0, %1 : index
    %17 = arith.subi %1, %c1 : index
    %18 = arith.select %15, %16, %17 : index
    %19 = arith.divsi %18, %c128 : index
    %20 = arith.subi %c0, %19 : index
    %21 = arith.addi %19, %c1 : index
    %22 = arith.select %15, %20, %21 : index
    %23 = arith.cmpi sle, %0, %c0 : index
    %24 = arith.subi %c0, %0 : index
    %25 = arith.subi %0, %c1 : index
    %26 = arith.select %23, %24, %25 : index
    %27 = arith.divsi %26, %c32 : index
    %28 = arith.subi %c0, %27 : index
    %29 = arith.addi %27, %c1 : index
    %30 = arith.select %23, %28, %29 : index
    %31 = arith.muli %22, %30 : index
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_main_dispatch_0 : !hal.executable)[0] workgroups([%31, %c1, %c1])
    cf.br ^bb2
  ^bb2:  // 2 preds: ^bb0, ^bb1
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_0 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status_1 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence_0) commands([%cmd])
    %status_2 = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status_2, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %3] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After SCFForLoopCanonicalization (scf-for-loop-canonicalization) //----- //
util.initializer {
  %c0 = arith.constant 0 : index
  %c-1 = arith.constant -1 : index
  %device = hal.ex.shared_device : !hal.device
  %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
  %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer>]) : !hal.descriptor_set_layout
  %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(4) layouts([%descriptor_set_layout]) : !hal.pipeline_layout
  %0 = arith.select %value, %c0, %c-1 : index
  %1 = arith.index_cast %0 : index to i32
  util.global.store %value, @_device_query_0 : i1
  util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
  cf.switch %1 : i32, [
    default: ^bb2,
    0: ^bb1
  ]
^bb1:  // pred: ^bb0
  %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
  %exe = hal.executable.create device(%device : !hal.device) target(@main_dispatch_0::@cuda_nvptx_fb) layouts([%_pipeline_layout_0]) : !hal.executable
  cf.br ^bb3(%exe : !hal.executable)
^bb2:  // pred: ^bb0
  %2 = util.null : !hal.executable
  cf.br ^bb3(%2 : !hal.executable)
^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
  util.global.store %3, @_executable_main_dispatch_0 : !hal.executable
  util.initializer.return
}

// -----// IR Dump After SCFForLoopCanonicalization (scf-for-loop-canonicalization) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c1 = arith.constant 1 : index
  %c-1 = arith.constant -1 : index
  %c-1_i32 = arith.constant -1 : i32
  %c0_i64 = arith.constant 0 : i64
  %c-1_i64 = arith.constant -1 : i64
  %c32_i64 = arith.constant 32 : i64
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %c128 = arith.constant 128 : index
  %c32 = arith.constant 32 : index
  %_device_query_0 = util.global.load @_device_query_0 : i1
  %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
  %_executable_main_dispatch_0 = util.global.load @_executable_main_dispatch_0 : !hal.executable
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %device = hal.ex.shared_device : !hal.device
  %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %4 = util.null : !hal.fence
  %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
  %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%3}
  %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
  %5 = arith.index_castui %0 : index to i64
  %6 = arith.trunci %5 : i64 to i32
  %7 = arith.shrui %5, %c32_i64 : i64
  %8 = arith.trunci %7 : i64 to i32
  %9 = arith.index_castui %1 : index to i64
  %10 = arith.trunci %9 : i64 to i32
  %11 = arith.shrui %9, %c32_i64 : i64
  %12 = arith.trunci %11 : i64 to i32
  %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
  %13 = arith.select %_device_query_0, %c0, %c-1 : index
  %14 = arith.index_cast %13 : index to i32
  cf.switch %14 : i32, [
    default: ^bb2,
    0: ^bb1
  ]
^bb1:  // pred: ^bb0
  hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout) offset(0) values([%6, %8, %10, %12]) : i32, i32, i32, i32
  hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
    %c0 = (%buffer : !hal.buffer)[%c0, %3], 
    %c1 = (%transient_buffer : !hal.buffer)[%c0, %3]
  ])
  %15 = arith.cmpi sle, %1, %c0 : index
  %16 = arith.subi %c0, %1 : index
  %17 = arith.subi %1, %c1 : index
  %18 = arith.select %15, %16, %17 : index
  %19 = arith.divsi %18, %c128 : index
  %20 = arith.subi %c0, %19 : index
  %21 = arith.addi %19, %c1 : index
  %22 = arith.select %15, %20, %21 : index
  %23 = arith.cmpi sle, %0, %c0 : index
  %24 = arith.subi %c0, %0 : index
  %25 = arith.subi %0, %c1 : index
  %26 = arith.select %23, %24, %25 : index
  %27 = arith.divsi %26, %c32 : index
  %28 = arith.subi %c0, %27 : index
  %29 = arith.addi %27, %c1 : index
  %30 = arith.select %23, %28, %29 : index
  %31 = arith.muli %22, %30 : index
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_main_dispatch_0 : !hal.executable)[0] workgroups([%31, %c1, %c1])
  cf.br ^bb2
^bb2:  // 2 preds: ^bb0, ^bb1
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  %fence_0 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
  %status_1 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
  hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence_0) commands([%cmd])
  %status_2 = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) : i32
  util.status.check_ok %status_2, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %3] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
  return %view : !hal.buffer_view
}

// -----// IR Dump After LoopInvariantCodeMotion (loop-invariant-code-motion) //----- //
util.initializer {
  %c0 = arith.constant 0 : index
  %c-1 = arith.constant -1 : index
  %device = hal.ex.shared_device : !hal.device
  %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
  %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer>]) : !hal.descriptor_set_layout
  %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(4) layouts([%descriptor_set_layout]) : !hal.pipeline_layout
  %0 = arith.select %value, %c0, %c-1 : index
  %1 = arith.index_cast %0 : index to i32
  util.global.store %value, @_device_query_0 : i1
  util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
  cf.switch %1 : i32, [
    default: ^bb2,
    0: ^bb1
  ]
^bb1:  // pred: ^bb0
  %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
  %exe = hal.executable.create device(%device : !hal.device) target(@main_dispatch_0::@cuda_nvptx_fb) layouts([%_pipeline_layout_0]) : !hal.executable
  cf.br ^bb3(%exe : !hal.executable)
^bb2:  // pred: ^bb0
  %2 = util.null : !hal.executable
  cf.br ^bb3(%2 : !hal.executable)
^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
  util.global.store %3, @_executable_main_dispatch_0 : !hal.executable
  util.initializer.return
}

// -----// IR Dump After LoopCoalescing (affine-loop-coalescing) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c1 = arith.constant 1 : index
  %c-1 = arith.constant -1 : index
  %c-1_i32 = arith.constant -1 : i32
  %c0_i64 = arith.constant 0 : i64
  %c-1_i64 = arith.constant -1 : i64
  %c32_i64 = arith.constant 32 : i64
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %c128 = arith.constant 128 : index
  %c32 = arith.constant 32 : index
  %_device_query_0 = util.global.load @_device_query_0 : i1
  %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
  %_executable_main_dispatch_0 = util.global.load @_executable_main_dispatch_0 : !hal.executable
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %device = hal.ex.shared_device : !hal.device
  %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %4 = util.null : !hal.fence
  %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
  %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%3}
  %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
  %5 = arith.index_castui %0 : index to i64
  %6 = arith.trunci %5 : i64 to i32
  %7 = arith.shrui %5, %c32_i64 : i64
  %8 = arith.trunci %7 : i64 to i32
  %9 = arith.index_castui %1 : index to i64
  %10 = arith.trunci %9 : i64 to i32
  %11 = arith.shrui %9, %c32_i64 : i64
  %12 = arith.trunci %11 : i64 to i32
  %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
  %13 = arith.select %_device_query_0, %c0, %c-1 : index
  %14 = arith.index_cast %13 : index to i32
  cf.switch %14 : i32, [
    default: ^bb2,
    0: ^bb1
  ]
^bb1:  // pred: ^bb0
  hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout) offset(0) values([%6, %8, %10, %12]) : i32, i32, i32, i32
  hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
    %c0 = (%buffer : !hal.buffer)[%c0, %3], 
    %c1 = (%transient_buffer : !hal.buffer)[%c0, %3]
  ])
  %15 = arith.cmpi sle, %1, %c0 : index
  %16 = arith.subi %c0, %1 : index
  %17 = arith.subi %1, %c1 : index
  %18 = arith.select %15, %16, %17 : index
  %19 = arith.divsi %18, %c128 : index
  %20 = arith.subi %c0, %19 : index
  %21 = arith.addi %19, %c1 : index
  %22 = arith.select %15, %20, %21 : index
  %23 = arith.cmpi sle, %0, %c0 : index
  %24 = arith.subi %c0, %0 : index
  %25 = arith.subi %0, %c1 : index
  %26 = arith.select %23, %24, %25 : index
  %27 = arith.divsi %26, %c32 : index
  %28 = arith.subi %c0, %27 : index
  %29 = arith.addi %27, %c1 : index
  %30 = arith.select %23, %28, %29 : index
  %31 = arith.muli %22, %30 : index
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_main_dispatch_0 : !hal.executable)[0] workgroups([%31, %c1, %c1])
  cf.br ^bb2
^bb2:  // 2 preds: ^bb0, ^bb1
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  %fence_0 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
  %status_1 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
  hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence_0) commands([%cmd])
  %status_2 = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) : i32
  util.status.check_ok %status_2, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %3] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
  return %view : !hal.buffer_view
}

// -----// IR Dump After SCFToControlFlow (convert-scf-to-cf) //----- //
util.initializer {
  %c0 = arith.constant 0 : index
  %c-1 = arith.constant -1 : index
  %device = hal.ex.shared_device : !hal.device
  %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
  %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer>]) : !hal.descriptor_set_layout
  %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(4) layouts([%descriptor_set_layout]) : !hal.pipeline_layout
  %0 = arith.select %value, %c0, %c-1 : index
  %1 = arith.index_cast %0 : index to i32
  util.global.store %value, @_device_query_0 : i1
  util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
  cf.switch %1 : i32, [
    default: ^bb2,
    0: ^bb1
  ]
^bb1:  // pred: ^bb0
  %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
  %exe = hal.executable.create device(%device : !hal.device) target(@main_dispatch_0::@cuda_nvptx_fb) layouts([%_pipeline_layout_0]) : !hal.executable
  cf.br ^bb3(%exe : !hal.executable)
^bb2:  // pred: ^bb0
  %2 = util.null : !hal.executable
  cf.br ^bb3(%2 : !hal.executable)
^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
  util.global.store %3, @_executable_main_dispatch_0 : !hal.executable
  util.initializer.return
}

// -----// IR Dump After LoopInvariantCodeMotion (loop-invariant-code-motion) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c1 = arith.constant 1 : index
  %c-1 = arith.constant -1 : index
  %c-1_i32 = arith.constant -1 : i32
  %c0_i64 = arith.constant 0 : i64
  %c-1_i64 = arith.constant -1 : i64
  %c32_i64 = arith.constant 32 : i64
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %c128 = arith.constant 128 : index
  %c32 = arith.constant 32 : index
  %_device_query_0 = util.global.load @_device_query_0 : i1
  %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
  %_executable_main_dispatch_0 = util.global.load @_executable_main_dispatch_0 : !hal.executable
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %device = hal.ex.shared_device : !hal.device
  %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %4 = util.null : !hal.fence
  %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
  %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%3}
  %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
  %5 = arith.index_castui %0 : index to i64
  %6 = arith.trunci %5 : i64 to i32
  %7 = arith.shrui %5, %c32_i64 : i64
  %8 = arith.trunci %7 : i64 to i32
  %9 = arith.index_castui %1 : index to i64
  %10 = arith.trunci %9 : i64 to i32
  %11 = arith.shrui %9, %c32_i64 : i64
  %12 = arith.trunci %11 : i64 to i32
  %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
  %13 = arith.select %_device_query_0, %c0, %c-1 : index
  %14 = arith.index_cast %13 : index to i32
  cf.switch %14 : i32, [
    default: ^bb2,
    0: ^bb1
  ]
^bb1:  // pred: ^bb0
  hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout) offset(0) values([%6, %8, %10, %12]) : i32, i32, i32, i32
  hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
    %c0 = (%buffer : !hal.buffer)[%c0, %3], 
    %c1 = (%transient_buffer : !hal.buffer)[%c0, %3]
  ])
  %15 = arith.cmpi sle, %1, %c0 : index
  %16 = arith.subi %c0, %1 : index
  %17 = arith.subi %1, %c1 : index
  %18 = arith.select %15, %16, %17 : index
  %19 = arith.divsi %18, %c128 : index
  %20 = arith.subi %c0, %19 : index
  %21 = arith.addi %19, %c1 : index
  %22 = arith.select %15, %20, %21 : index
  %23 = arith.cmpi sle, %0, %c0 : index
  %24 = arith.subi %c0, %0 : index
  %25 = arith.subi %0, %c1 : index
  %26 = arith.select %23, %24, %25 : index
  %27 = arith.divsi %26, %c32 : index
  %28 = arith.subi %c0, %27 : index
  %29 = arith.addi %27, %c1 : index
  %30 = arith.select %23, %28, %29 : index
  %31 = arith.muli %22, %30 : index
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_main_dispatch_0 : !hal.executable)[0] workgroups([%31, %c1, %c1])
  cf.br ^bb2
^bb2:  // 2 preds: ^bb0, ^bb1
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  %fence_0 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
  %status_1 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
  hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence_0) commands([%cmd])
  %status_2 = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) : i32
  util.status.check_ok %status_2, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %3] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
  return %view : !hal.buffer_view
}

// -----// IR Dump After ConvertAffineToStandard (lower-affine) //----- //
util.initializer {
  %c0 = arith.constant 0 : index
  %c-1 = arith.constant -1 : index
  %device = hal.ex.shared_device : !hal.device
  %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
  %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer>]) : !hal.descriptor_set_layout
  %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(4) layouts([%descriptor_set_layout]) : !hal.pipeline_layout
  %0 = arith.select %value, %c0, %c-1 : index
  %1 = arith.index_cast %0 : index to i32
  util.global.store %value, @_device_query_0 : i1
  util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
  cf.switch %1 : i32, [
    default: ^bb2,
    0: ^bb1
  ]
^bb1:  // pred: ^bb0
  %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
  %exe = hal.executable.create device(%device : !hal.device) target(@main_dispatch_0::@cuda_nvptx_fb) layouts([%_pipeline_layout_0]) : !hal.executable
  cf.br ^bb3(%exe : !hal.executable)
^bb2:  // pred: ^bb0
  %2 = util.null : !hal.executable
  cf.br ^bb3(%2 : !hal.executable)
^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
  util.global.store %3, @_executable_main_dispatch_0 : !hal.executable
  util.initializer.return
}

// -----// IR Dump After SCFToControlFlow (convert-scf-to-cf) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c1 = arith.constant 1 : index
  %c-1 = arith.constant -1 : index
  %c-1_i32 = arith.constant -1 : i32
  %c0_i64 = arith.constant 0 : i64
  %c-1_i64 = arith.constant -1 : i64
  %c32_i64 = arith.constant 32 : i64
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %c128 = arith.constant 128 : index
  %c32 = arith.constant 32 : index
  %_device_query_0 = util.global.load @_device_query_0 : i1
  %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
  %_executable_main_dispatch_0 = util.global.load @_executable_main_dispatch_0 : !hal.executable
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %device = hal.ex.shared_device : !hal.device
  %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %4 = util.null : !hal.fence
  %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
  %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%3}
  %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
  %5 = arith.index_castui %0 : index to i64
  %6 = arith.trunci %5 : i64 to i32
  %7 = arith.shrui %5, %c32_i64 : i64
  %8 = arith.trunci %7 : i64 to i32
  %9 = arith.index_castui %1 : index to i64
  %10 = arith.trunci %9 : i64 to i32
  %11 = arith.shrui %9, %c32_i64 : i64
  %12 = arith.trunci %11 : i64 to i32
  %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
  %13 = arith.select %_device_query_0, %c0, %c-1 : index
  %14 = arith.index_cast %13 : index to i32
  cf.switch %14 : i32, [
    default: ^bb2,
    0: ^bb1
  ]
^bb1:  // pred: ^bb0
  hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout) offset(0) values([%6, %8, %10, %12]) : i32, i32, i32, i32
  hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
    %c0 = (%buffer : !hal.buffer)[%c0, %3], 
    %c1 = (%transient_buffer : !hal.buffer)[%c0, %3]
  ])
  %15 = arith.cmpi sle, %1, %c0 : index
  %16 = arith.subi %c0, %1 : index
  %17 = arith.subi %1, %c1 : index
  %18 = arith.select %15, %16, %17 : index
  %19 = arith.divsi %18, %c128 : index
  %20 = arith.subi %c0, %19 : index
  %21 = arith.addi %19, %c1 : index
  %22 = arith.select %15, %20, %21 : index
  %23 = arith.cmpi sle, %0, %c0 : index
  %24 = arith.subi %c0, %0 : index
  %25 = arith.subi %0, %c1 : index
  %26 = arith.select %23, %24, %25 : index
  %27 = arith.divsi %26, %c32 : index
  %28 = arith.subi %c0, %27 : index
  %29 = arith.addi %27, %c1 : index
  %30 = arith.select %23, %28, %29 : index
  %31 = arith.muli %22, %30 : index
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_main_dispatch_0 : !hal.executable)[0] workgroups([%31, %c1, %c1])
  cf.br ^bb2
^bb2:  // 2 preds: ^bb0, ^bb1
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  %fence_0 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
  %status_1 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
  hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence_0) commands([%cmd])
  %status_2 = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) : i32
  util.status.check_ok %status_2, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %3] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
  return %view : !hal.buffer_view
}

// -----// IR Dump After ArithUnsignedWhenEquivalent (arith-unsigned-when-equivalent) //----- //
util.initializer {
  %c0 = arith.constant 0 : index
  %c-1 = arith.constant -1 : index
  %device = hal.ex.shared_device : !hal.device
  %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
  %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer>]) : !hal.descriptor_set_layout
  %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(4) layouts([%descriptor_set_layout]) : !hal.pipeline_layout
  %0 = arith.select %value, %c0, %c-1 : index
  %1 = arith.index_cast %0 : index to i32
  util.global.store %value, @_device_query_0 : i1
  util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
  cf.switch %1 : i32, [
    default: ^bb2,
    0: ^bb1
  ]
^bb1:  // pred: ^bb0
  %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
  %exe = hal.executable.create device(%device : !hal.device) target(@main_dispatch_0::@cuda_nvptx_fb) layouts([%_pipeline_layout_0]) : !hal.executable
  cf.br ^bb3(%exe : !hal.executable)
^bb2:  // pred: ^bb0
  %2 = util.null : !hal.executable
  cf.br ^bb3(%2 : !hal.executable)
^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
  util.global.store %3, @_executable_main_dispatch_0 : !hal.executable
  util.initializer.return
}

// -----// IR Dump After ConvertAffineToStandard (lower-affine) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c1 = arith.constant 1 : index
  %c-1 = arith.constant -1 : index
  %c-1_i32 = arith.constant -1 : i32
  %c0_i64 = arith.constant 0 : i64
  %c-1_i64 = arith.constant -1 : i64
  %c32_i64 = arith.constant 32 : i64
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %c128 = arith.constant 128 : index
  %c32 = arith.constant 32 : index
  %_device_query_0 = util.global.load @_device_query_0 : i1
  %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
  %_executable_main_dispatch_0 = util.global.load @_executable_main_dispatch_0 : !hal.executable
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %device = hal.ex.shared_device : !hal.device
  %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %4 = util.null : !hal.fence
  %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
  %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%3}
  %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
  %5 = arith.index_castui %0 : index to i64
  %6 = arith.trunci %5 : i64 to i32
  %7 = arith.shrui %5, %c32_i64 : i64
  %8 = arith.trunci %7 : i64 to i32
  %9 = arith.index_castui %1 : index to i64
  %10 = arith.trunci %9 : i64 to i32
  %11 = arith.shrui %9, %c32_i64 : i64
  %12 = arith.trunci %11 : i64 to i32
  %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
  %13 = arith.select %_device_query_0, %c0, %c-1 : index
  %14 = arith.index_cast %13 : index to i32
  cf.switch %14 : i32, [
    default: ^bb2,
    0: ^bb1
  ]
^bb1:  // pred: ^bb0
  hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout) offset(0) values([%6, %8, %10, %12]) : i32, i32, i32, i32
  hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
    %c0 = (%buffer : !hal.buffer)[%c0, %3], 
    %c1 = (%transient_buffer : !hal.buffer)[%c0, %3]
  ])
  %15 = arith.cmpi sle, %1, %c0 : index
  %16 = arith.subi %c0, %1 : index
  %17 = arith.subi %1, %c1 : index
  %18 = arith.select %15, %16, %17 : index
  %19 = arith.divsi %18, %c128 : index
  %20 = arith.subi %c0, %19 : index
  %21 = arith.addi %19, %c1 : index
  %22 = arith.select %15, %20, %21 : index
  %23 = arith.cmpi sle, %0, %c0 : index
  %24 = arith.subi %c0, %0 : index
  %25 = arith.subi %0, %c1 : index
  %26 = arith.select %23, %24, %25 : index
  %27 = arith.divsi %26, %c32 : index
  %28 = arith.subi %c0, %27 : index
  %29 = arith.addi %27, %c1 : index
  %30 = arith.select %23, %28, %29 : index
  %31 = arith.muli %22, %30 : index
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_main_dispatch_0 : !hal.executable)[0] workgroups([%31, %c1, %c1])
  cf.br ^bb2
^bb2:  // 2 preds: ^bb0, ^bb1
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  %fence_0 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
  %status_1 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
  hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence_0) commands([%cmd])
  %status_2 = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) : i32
  util.status.check_ok %status_2, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %3] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
  return %view : !hal.buffer_view
}

// -----// IR Dump After ArithUnsignedWhenEquivalent (arith-unsigned-when-equivalent) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c1 = arith.constant 1 : index
  %c-1 = arith.constant -1 : index
  %c-1_i32 = arith.constant -1 : i32
  %c0_i64 = arith.constant 0 : i64
  %c-1_i64 = arith.constant -1 : i64
  %c32_i64 = arith.constant 32 : i64
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %c128 = arith.constant 128 : index
  %c32 = arith.constant 32 : index
  %_device_query_0 = util.global.load @_device_query_0 : i1
  %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
  %_executable_main_dispatch_0 = util.global.load @_executable_main_dispatch_0 : !hal.executable
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %device = hal.ex.shared_device : !hal.device
  %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %4 = util.null : !hal.fence
  %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
  %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%3}
  %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
  %5 = arith.index_castui %0 : index to i64
  %6 = arith.trunci %5 : i64 to i32
  %7 = arith.shrui %5, %c32_i64 : i64
  %8 = arith.trunci %7 : i64 to i32
  %9 = arith.index_castui %1 : index to i64
  %10 = arith.trunci %9 : i64 to i32
  %11 = arith.shrui %9, %c32_i64 : i64
  %12 = arith.trunci %11 : i64 to i32
  %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
  %13 = arith.select %_device_query_0, %c0, %c-1 : index
  %14 = arith.index_cast %13 : index to i32
  cf.switch %14 : i32, [
    default: ^bb2,
    0: ^bb1
  ]
^bb1:  // pred: ^bb0
  hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout) offset(0) values([%6, %8, %10, %12]) : i32, i32, i32, i32
  hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
    %c0 = (%buffer : !hal.buffer)[%c0, %3], 
    %c1 = (%transient_buffer : !hal.buffer)[%c0, %3]
  ])
  %15 = arith.cmpi sle, %1, %c0 : index
  %16 = arith.subi %c0, %1 : index
  %17 = arith.subi %1, %c1 : index
  %18 = arith.select %15, %16, %17 : index
  %19 = arith.divsi %18, %c128 : index
  %20 = arith.subi %c0, %19 : index
  %21 = arith.addi %19, %c1 : index
  %22 = arith.select %15, %20, %21 : index
  %23 = arith.cmpi sle, %0, %c0 : index
  %24 = arith.subi %c0, %0 : index
  %25 = arith.subi %0, %c1 : index
  %26 = arith.select %23, %24, %25 : index
  %27 = arith.divsi %26, %c32 : index
  %28 = arith.subi %c0, %27 : index
  %29 = arith.addi %27, %c1 : index
  %30 = arith.select %23, %28, %29 : index
  %31 = arith.muli %22, %30 : index
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_main_dispatch_0 : !hal.executable)[0] workgroups([%31, %c1, %c1])
  cf.br ^bb2
^bb2:  // 2 preds: ^bb0, ^bb1
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  %fence_0 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
  %status_1 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
  hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence_0) commands([%cmd])
  %status_2 = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) : i32
  util.status.check_ok %status_2, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %3] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
  return %view : !hal.buffer_view
}

// -----// IR Dump After PropagateSubranges (iree-util-propagate-subranges) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private @_device_query_0 : i1
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.global private @_executable_main_dispatch_0 : !hal.executable
  util.initializer {
    %c0 = arith.constant 0 : index
    %c-1 = arith.constant -1 : index
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer>]) : !hal.descriptor_set_layout
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(4) layouts([%descriptor_set_layout]) : !hal.pipeline_layout
    %0 = arith.select %value, %c0, %c-1 : index
    %1 = arith.index_cast %0 : index to i32
    util.global.store %value, @_device_query_0 : i1
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    cf.switch %1 : i32, [
      default: ^bb2,
      0: ^bb1
    ]
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device : !hal.device) target(@main_dispatch_0::@cuda_nvptx_fb) layouts([%_pipeline_layout_0]) : !hal.executable
    cf.br ^bb3(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %2 = util.null : !hal.executable
    cf.br ^bb3(%2 : !hal.executable)
  ^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %3, @_executable_main_dispatch_0 : !hal.executable
    util.initializer.return
  }
  hal.executable private @main_dispatch_0 {
    hal.executable.binary public @cuda_nvptx_fb attributes {data = dense<"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vector<6926xi8>, format = "cuda-nvptx-fb", mime_type = "application/x-flatbuffers"}
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c1 = arith.constant 1 : index
    %c-1 = arith.constant -1 : index
    %c-1_i32 = arith.constant -1 : i32
    %c0_i64 = arith.constant 0 : i64
    %c-1_i64 = arith.constant -1 : i64
    %c32_i64 = arith.constant 32 : i64
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %c128 = arith.constant 128 : index
    %c32 = arith.constant 32 : index
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %_executable_main_dispatch_0 = util.global.load @_executable_main_dispatch_0 : !hal.executable
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %4 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%3}
    %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    %5 = arith.index_castui %0 : index to i64
    %6 = arith.trunci %5 : i64 to i32
    %7 = arith.shrui %5, %c32_i64 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %1 : index to i64
    %10 = arith.trunci %9 : i64 to i32
    %11 = arith.shrui %9, %c32_i64 : i64
    %12 = arith.trunci %11 : i64 to i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    %13 = arith.select %_device_query_0, %c0, %c-1 : index
    %14 = arith.index_cast %13 : index to i32
    cf.switch %14 : i32, [
      default: ^bb2,
      0: ^bb1
    ]
  ^bb1:  // pred: ^bb0
    hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout) offset(0) values([%6, %8, %10, %12]) : i32, i32, i32, i32
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%buffer : !hal.buffer)[%c0, %3], 
      %c1 = (%transient_buffer : !hal.buffer)[%c0, %3]
    ])
    %15 = arith.cmpi sle, %1, %c0 : index
    %16 = arith.subi %c0, %1 : index
    %17 = arith.subi %1, %c1 : index
    %18 = arith.select %15, %16, %17 : index
    %19 = arith.divsi %18, %c128 : index
    %20 = arith.subi %c0, %19 : index
    %21 = arith.addi %19, %c1 : index
    %22 = arith.select %15, %20, %21 : index
    %23 = arith.cmpi sle, %0, %c0 : index
    %24 = arith.subi %c0, %0 : index
    %25 = arith.subi %0, %c1 : index
    %26 = arith.select %23, %24, %25 : index
    %27 = arith.divsi %26, %c32 : index
    %28 = arith.subi %c0, %27 : index
    %29 = arith.addi %27, %c1 : index
    %30 = arith.select %23, %28, %29 : index
    %31 = arith.muli %22, %30 : index
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_main_dispatch_0 : !hal.executable)[0] workgroups([%31, %c1, %c1])
    cf.br ^bb2
  ^bb2:  // 2 preds: ^bb0, ^bb1
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_0 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status_1 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence_0) commands([%cmd])
    %status_2 = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status_2, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %3] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private @_device_query_0 : i1
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.global private @_executable_main_dispatch_0 : !hal.executable
  util.initializer {
    %c0 = arith.constant 0 : index
    %c-1 = arith.constant -1 : index
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer>]) : !hal.descriptor_set_layout
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(4) layouts([%descriptor_set_layout]) : !hal.pipeline_layout
    %0 = arith.select %value, %c0, %c-1 : index
    %1 = arith.index_cast %0 : index to i32
    util.global.store %value, @_device_query_0 : i1
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    cf.switch %1 : i32, [
      default: ^bb2,
      0: ^bb1
    ]
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device : !hal.device) target(@main_dispatch_0::@cuda_nvptx_fb) layouts([%_pipeline_layout_0]) : !hal.executable
    cf.br ^bb3(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %2 = util.null : !hal.executable
    cf.br ^bb3(%2 : !hal.executable)
  ^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %3, @_executable_main_dispatch_0 : !hal.executable
    util.initializer.return
  }
  hal.executable private @main_dispatch_0 {
    hal.executable.binary public @cuda_nvptx_fb attributes {data = dense<"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vector<6926xi8>, format = "cuda-nvptx-fb", mime_type = "application/x-flatbuffers"}
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c1 = arith.constant 1 : index
    %c-1 = arith.constant -1 : index
    %c-1_i32 = arith.constant -1 : i32
    %c0_i64 = arith.constant 0 : i64
    %c-1_i64 = arith.constant -1 : i64
    %c32_i64 = arith.constant 32 : i64
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %c128 = arith.constant 128 : index
    %c32 = arith.constant 32 : index
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %_executable_main_dispatch_0 = util.global.load @_executable_main_dispatch_0 : !hal.executable
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %4 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%3}
    %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    %5 = arith.index_castui %0 : index to i64
    %6 = arith.trunci %5 : i64 to i32
    %7 = arith.shrui %5, %c32_i64 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %1 : index to i64
    %10 = arith.trunci %9 : i64 to i32
    %11 = arith.shrui %9, %c32_i64 : i64
    %12 = arith.trunci %11 : i64 to i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    %13 = arith.select %_device_query_0, %c0, %c-1 : index
    %14 = arith.index_cast %13 : index to i32
    cf.switch %14 : i32, [
      default: ^bb2,
      0: ^bb1
    ]
  ^bb1:  // pred: ^bb0
    hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout) offset(0) values([%6, %8, %10, %12]) : i32, i32, i32, i32
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%buffer : !hal.buffer)[%c0, %3], 
      %c1 = (%transient_buffer : !hal.buffer)[%c0, %3]
    ])
    %15 = arith.cmpi sle, %1, %c0 : index
    %16 = arith.subi %c0, %1 : index
    %17 = arith.subi %1, %c1 : index
    %18 = arith.select %15, %16, %17 : index
    %19 = arith.divsi %18, %c128 : index
    %20 = arith.subi %c0, %19 : index
    %21 = arith.addi %19, %c1 : index
    %22 = arith.select %15, %20, %21 : index
    %23 = arith.cmpi sle, %0, %c0 : index
    %24 = arith.subi %c0, %0 : index
    %25 = arith.subi %0, %c1 : index
    %26 = arith.select %23, %24, %25 : index
    %27 = arith.divsi %26, %c32 : index
    %28 = arith.subi %c0, %27 : index
    %29 = arith.addi %27, %c1 : index
    %30 = arith.select %23, %28, %29 : index
    %31 = arith.muli %22, %30 : index
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_main_dispatch_0 : !hal.executable)[0] workgroups([%31, %c1, %c1])
    cf.br ^bb2
  ^bb2:  // 2 preds: ^bb0, ^bb1
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_0 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status_1 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence_0) commands([%cmd])
    %status_2 = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status_2, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %3] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After CSE (cse) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private @_device_query_0 : i1
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.global private @_executable_main_dispatch_0 : !hal.executable
  util.initializer {
    %c0 = arith.constant 0 : index
    %c-1 = arith.constant -1 : index
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer>]) : !hal.descriptor_set_layout
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(4) layouts([%descriptor_set_layout]) : !hal.pipeline_layout
    %0 = arith.select %value, %c0, %c-1 : index
    %1 = arith.index_cast %0 : index to i32
    util.global.store %value, @_device_query_0 : i1
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    cf.switch %1 : i32, [
      default: ^bb2,
      0: ^bb1
    ]
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device : !hal.device) target(@main_dispatch_0::@cuda_nvptx_fb) layouts([%_pipeline_layout_0]) : !hal.executable
    cf.br ^bb3(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %2 = util.null : !hal.executable
    cf.br ^bb3(%2 : !hal.executable)
  ^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %3, @_executable_main_dispatch_0 : !hal.executable
    util.initializer.return
  }
  hal.executable private @main_dispatch_0 {
    hal.executable.binary public @cuda_nvptx_fb attributes {data = dense<"0x080000004355444108E5FFFF1C0000005000000044000000580000000400000001000000B81A00000100000004000000200000006D61696E5F64697370617463685F305F6D61746D756C5F44784478445F66333200000000010000000000000001000000200000000800000001000000641A00002F2F0A2F2F2047656E657261746564206279204C4C564D204E56505458204261636B2D456E640A2F2F0A0A2E76657273696F6E20372E350A2E74617267657420736D5F37350A2E616464726573735F73697A652036340A0A092F2F202E676C6F626C096D61696E5F64697370617463685F305F6D61746D756C5F44784478445F6633320A0A2E76697369626C65202E656E747279206D61696E5F64697370617463685F305F6D61746D756C5F44784478445F663332280A092E706172616D202E753634206D61696E5F64697370617463685F305F6D61746D756C5F44784478445F6633325F706172616D5F302C0A092E706172616D202E753634206D61696E5F64697370617463685F305F6D61746D756C5F44784478445F6633325F706172616D5F312C0A092E706172616D202E753332206D61696E5F64697370617463685F305F6D61746D756C5F44784478445F6633325F706172616D5F322C0A092E706172616D202E753332206D61696E5F64697370617463685F305F6D61746D756C5F44784478445F6633325F706172616D5F332C0A092E706172616D202E753332206D61696E5F64697370617463685F305F6D61746D756C5F44784478445F6633325F706172616D5F342C0A092E706172616D202E753332206D61696E5F64697370617463685F305F6D61746D756C5F44784478445F6633325F706172616D5F350A290A2E6D61786E7469642033322C20382C20310A7B0A092E726567202E70726564200925703C32313E3B0A092E726567202E623332200925723C31303E3B0A092E726567202E663332200925663C31343E3B0A092E726567202E62363420092572643C3136353E3B0A0A096C642E706172616D2E753332200925726436312C205B6D61696E5F64697370617463685F305F6D61746D756C5F44784478445F6633325F706172616D5F325D3B0A096C642E706172616D2E753332200925726436322C205B6D61696E5F64697370617463685F305F6D61746D756C5F44784478445F6633325F706172616D5F335D3B0A0973686C2E623634200925726436332C2025726436322C2033323B0A096F722E623634202009257264312C2025726436332C2025726436313B0A096C642E706172616D2E7533322009257264322C205B6D61696E5F64697370617463685F305F6D61746D756C5F44784478445F6633325F706172616D5F345D3B0A096C642E706172616D2E7533322009257264332C205B6D61696E5F64697370617463685F305F6D61746D756C5F44784478445F6633325F706172616D5F355D3B0A0973686C2E623634200925726436342C20257264332C2033323B0A096F722E623634202009257264342C2025726436342C20257264323B0A096D6F762E75333220092572312C202563746169642E783B0A096376742E7536342E7533322009257264352C202572313B0A09736574702E6C742E73363420092570312C20257264342C20313B0A096E65672E733634200925726436352C20257264343B0A096164642E733634200925726436362C20257264342C202D313B0A0973656C702E623634200925726436372C2025726436352C2025726436362C202570313B0A097368722E733634200925726436382C2025726436372C2036333B0A097368722E753634200925726436392C2025726436382C2035373B0A096164642E733634200925726437302C2025726436372C2025726436393B0A097368722E733634200925726437312C2025726437302C20373B0A096E65672E733634200925726437322C2025726437313B0A096164642E733634200925726437332C2025726437312C20313B0A0973656C702E623634200925726437342C2025726437322C2025726437332C202570313B0A09616E642E62363420200925726437352C2025726437342C202D343239343936373239363B0A09736574702E6E652E73363420092570322C2025726437352C20303B0A0940257032206272612009244C5F5F4242305F323B0A096272612E756E692009244C5F5F4242305F313B0A244C5F5F4242305F323A0A096469762E73363420092572643134382C20257264352C2025726437343B0A096272612E756E692009244C5F5F4242305F333B0A244C5F5F4242305F313A0A096376742E7533322E75363420092572332C2025726437343B0A096376742E7533322E75363420092572342C20257264353B0A096469762E75333220092572352C202572342C202572333B0A096376742E7536342E75333220092572643134382C202572353B0A244C5F5F4242305F333A0A096C642E706172616D2E753634200925726436302C205B6D61696E5F64697370617463685F305F6D61746D756C5F44784478445F6633325F706172616D5F315D3B0A0973686C2E623634200925726437362C202572643134382C20353B0A097375622E733634200925726437372C20257264312C2025726437363B0A096D696E2E733634200925726437382C2025726437372C2033323B0A096D756C2E6C6F2E733634200925726437392C202572643134382C2025726437343B0A097375622E733634200925726438302C20257264352C2025726437393B0A0973686C2E623634200925726438312C2025726438302C20373B0A097375622E733634200925726438322C20257264342C2025726438313B0A096D696E2E733634200925726438332C2025726438322C203132383B0A096D6F762E75333220092572362C20257469642E783B0A096376742E7536342E753332200925726438342C202572363B0A096D6F762E75333220092572372C20257469642E793B0A096376742E7536342E753332200925726438352C202572373B0A09736574702E6C742E73363420092570332C2025726437372C20313B0A096E65672E733634200925726438362C2025726437383B0A096164642E733634200925726438372C2025726437382C202D313B0A0973656C702E623634200925726438382C2025726438362C2025726438372C202570333B0A097368722E733634200925726438392C2025726438382C2036333B0A097368722E753634200925726439302C2025726438392C2036313B0A096164642E733634200925726439312C2025726438382C2025726439303B0A097368722E733634200925726439322C2025726439312C20333B0A096E65672E733634200925726439332C2025726439323B0A096164642E733634200925726439342C2025726439322C20313B0A0973656C702E623634200925726439352C2025726439332C2025726439342C202570333B0A096D756C2E6C6F2E733634200925726439362C2025726439352C2025726438353B0A097375622E733634200925726439372C2025726437382C2025726439363B0A096D696E2E733634200925726431302C2025726439372C2025726439353B0A09736574702E6C742E73363420092570342C2025726438322C20313B0A096E65672E733634200925726439382C2025726438333B0A096164642E733634200925726439392C2025726438332C202D313B0A0973656C702E62363420092572643130302C2025726439382C2025726439392C202570343B0A097368722E73363420092572643130312C202572643130302C2036333B0A097368722E75363420092572643130322C202572643130312C2035393B0A096164642E73363420092572643130332C202572643130302C202572643130323B0A097368722E73363420092572643130342C202572643130332C20353B0A096E65672E73363420092572643130352C202572643130343B0A096164642E73363420092572643130362C202572643130342C20313B0A0973656C702E62363420092572643130372C202572643130352C202572643130362C202570343B0A096D756C2E6C6F2E73363420092572643130382C202572643130372C2025726438343B0A097375622E73363420092572643130392C2025726438332C202572643130383B0A096D696E2E733634200925726431312C202572643130392C202572643130373B0A096164642E733634200925726431322C2025726439362C2025726437363B0A096164642E733634200925726431332C202572643130382C2025726438313B0A09736574702E6C742E73363420092570352C2025726431302C20313B0A096D756C2E6C6F2E73363420092572643134332C2025726431322C20257264343B0A0973686C2E62363420092572643134342C2025726431332C20323B0A0973686C2E62363420092572643134352C20257264332C2033343B0A0973686C2E62363420092572643134362C20257264322C20323B0A09736574702E6C742E7336342009257032302C2025726431312C20313B0A0940257035206272612009244C5F5F4242305F31333B0A096D6F762E75363420092572643135312C20303B0A09616E642E62363420200925726431392C2025726431312C20373B0A09616E642E62363420200925726431352C2025726431312C202D383B0A0973686C2E62363420092572643131322C202572643134332C20323B0A096164642E73363420092572643131342C202572643131322C202572643134343B0A096164642E73363420092572643134392C2025726436302C202572643131343B0A096164642E73363420092572643135302C202572643134392C2031363B0A096F722E62363420200925726431372C202572643134352C202572643134363B0A09736574702E6C742E75363420092570372C2025726431312C20383B0A096D6F762E62333220092572392C20303B0A096272612E756E692009244C5F5F4242305F353B0A244C5F5F4242305F31323A0A096164642E73363420092572643135312C202572643135312C20313B0A096164642E73363420092572643135302C202572643135302C2025726431373B0A096164642E73363420092572643134392C202572643134392C2025726431373B0A09736574702E65712E7336342009257031312C2025726431302C202572643135313B0A094025703131206272612009244C5F5F4242305F31333B0A244C5F5F4242305F353A0A094025703230206272612009244C5F5F4242305F31323B0A096D6F762E75363420092572643135342C20303B0A0940257037206272612009244C5F5F4242305F393B0A096D6F762E75363420092572643135342C20303B0A096D6F762E75363420092572643135322C202572643135303B0A244C5F5F4242305F383A0A0973742E676C6F62616C2E75333220095B2572643135322B2D31365D2C202572393B0A0973742E676C6F62616C2E75333220095B2572643135322B2D31325D2C202572393B0A0973742E676C6F62616C2E75333220095B2572643135322B2D385D2C202572393B0A0973742E676C6F62616C2E75333220095B2572643135322B2D345D2C202572393B0A0973742E676C6F62616C2E75333220095B2572643135325D2C202572393B0A0973742E676C6F62616C2E75333220095B2572643135322B345D2C202572393B0A0973742E676C6F62616C2E75333220095B2572643135322B385D2C202572393B0A0973742E676C6F62616C2E75333220095B2572643135322B31325D2C202572393B0A096164642E73363420092572643135342C202572643135342C20383B0A096164642E73363420092572643135322C202572643135322C2033323B0A09736574702E6E652E73363420092570382C2025726431352C202572643135343B0A0940257038206272612009244C5F5F4242305F383B0A244C5F5F4242305F393A0A09736574702E65712E73363420092570392C2025726431392C20303B0A0940257039206272612009244C5F5F4242305F31323B0A0973686C2E62363420092572643131392C202572643135342C20323B0A096164642E73363420092572643135362C202572643134392C202572643131393B0A096D6F762E75363420092572643135352C2025726431393B0A244C5F5F4242305F31313A0A092E707261676D6120226E6F756E726F6C6C223B0A0973742E676C6F62616C2E75333220095B2572643135365D2C202572393B0A096164642E73363420092572643135362C202572643135362C20343B0A096164642E73363420092572643135352C202572643135352C202D313B0A09736574702E6E652E7336342009257031302C202572643135352C20303B0A094025703130206272612009244C5F5F4242305F31313B0A096272612E756E692009244C5F5F4242305F31323B0A244C5F5F4242305F31333A0A0940257031206272612009244C5F5F4242305F32353B0A096C642E706172616D2E753634200925726435392C205B6D61696E5F64697370617463685F305F6D61746D756C5F44784478445F6633325F706172616D5F305D3B0A09616E642E62363420200925726432302C2025726431312C20313B0A09616E642E62363420200925726432312C2025726431312C202D323B0A0973686C2E62363420092572643132322C202572643134332C20323B0A096164642E73363420092572643132342C202572643132322C202572643134343B0A096164642E73363420092572643132352C202572643132342C2025726436303B0A096164642E733634200925726432322C202572643132352C20343B0A096F722E62363420200925726432332C202572643134352C202572643134363B0A096164642E73363420092572643132382C202572643134342C2025726435393B0A096164642E73363420092572643135372C202572643132382C20343B0A096D6F762E75363420092572643135382C20303B0A09736574702E65712E7336342009257031352C2025726431312C20313B0A09736574702E65712E7336342009257031372C2025726432302C20303B0A096272612E756E692009244C5F5F4242305F31353B0A244C5F5F4242305F32343A0A096164642E73363420092572643135382C202572643135382C20313B0A096164642E73363420092572643135372C202572643135372C2025726432333B0A09736574702E6E652E7336342009257031392C202572643135382C20257264343B0A094025703139206272612009244C5F5F4242305F31353B0A096272612E756E692009244C5F5F4242305F32353B0A244C5F5F4242305F31353A0A0940257035206272612009244C5F5F4242305F32343B0A0973686C2E62363420092572643133302C202572643135382C20323B0A096164642E733634200925726434332C2025726435392C202572643133303B0A096D756C2E6C6F2E73363420092572643133312C202572643135382C20257264343B0A0973686C2E62363420092572643133322C202572643133312C20323B0A096164642E733634200925726434342C2025726435392C202572643133323B0A096D6F762E75363420092572643136302C20303B0A096D6F762E75363420092572643135392C2025726432323B0A096272612E756E692009244C5F5F4242305F31373B0A244C5F5F4242305F32333A0A096164642E73363420092572643136302C202572643136302C20313B0A096164642E73363420092572643135392C202572643135392C2025726432333B0A09736574702E6E652E7336342009257031382C2025726431302C202572643136303B0A094025703138206272612009244C5F5F4242305F31373B0A096272612E756E692009244C5F5F4242305F32343B0A244C5F5F4242305F31373A0A094025703230206272612009244C5F5F4242305F32333B0A096164642E73363420092572643133342C202572643136302C2025726431323B0A096D756C2E6C6F2E73363420092572643133352C202572643133342C20257264343B0A0973686C2E62363420092572643133362C202572643133352C20323B0A096164642E73363420092572643133372C2025726434332C202572643133363B0A096C642E676C6F62616C2E6E632E66333220092566312C205B2572643133375D3B0A096D6F762E75363420092572643136342C20303B0A094025703135206272612009244C5F5F4242305F32313B0A096D6F762E75363420092572643136342C20303B0A096D6F762E75363420092572643136312C202572643135373B0A096D6F762E75363420092572643136322C202572643135393B0A244C5F5F4242305F32303A0A096C642E676C6F62616C2E6E632E66333220092566322C205B2572643136312B2D345D3B0A096C642E676C6F62616C2E66333220092566332C205B2572643136322B2D345D3B0A096D756C2E726E2E66333220092566342C202566312C202566323B0A096164642E726E2E66333220092566352C202566332C202566343B0A0973742E676C6F62616C2E66333220095B2572643136322B2D345D2C202566353B0A096C642E676C6F62616C2E6E632E66333220092566362C205B2572643136315D3B0A096C642E676C6F62616C2E66333220092566372C205B2572643136325D3B0A096D756C2E726E2E66333220092566382C202566312C202566363B0A096164642E726E2E66333220092566392C202566372C202566383B0A0973742E676C6F62616C2E66333220095B2572643136325D2C202566393B0A096164642E73363420092572643136342C202572643136342C20323B0A096164642E73363420092572643136322C202572643136322C20383B0A096164642E73363420092572643136312C202572643136312C20383B0A09736574702E6E652E7336342009257031362C2025726432312C202572643136343B0A094025703136206272612009244C5F5F4242305F32303B0A244C5F5F4242305F32313A0A094025703137206272612009244C5F5F4242305F32333B0A096164642E733634200925726434372C2025726436302C202572643133363B0A096164642E73363420092572643133392C202572643136342C2025726431333B0A0973686C2E62363420092572643134302C202572643133392C20323B0A096164642E73363420092572643134312C2025726434342C202572643134303B0A096C642E676C6F62616C2E6E632E6633322009256631302C205B2572643134315D3B0A096164642E73363420092572643134322C2025726434372C202572643134303B0A096C642E676C6F62616C2E6633322009256631312C205B2572643134325D3B0A096D756C2E726E2E6633322009256631322C202566312C20256631303B0A096164642E726E2E6633322009256631332C20256631312C20256631323B0A0973742E676C6F62616C2E66333220095B2572643134325D2C20256631333B0A096272612E756E692009244C5F5F4242305F32333B0A244C5F5F4242305F32353A0A097265743B0A0A7D0A00000000E4FFFFFF08000000020000000B000000696E707574322E6D6C69720008000C00040008000E001800040008000C0010001400"> : vector<6926xi8>, format = "cuda-nvptx-fb", mime_type = "application/x-flatbuffers"}
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c1 = arith.constant 1 : index
    %c-1 = arith.constant -1 : index
    %c-1_i32 = arith.constant -1 : i32
    %c0_i64 = arith.constant 0 : i64
    %c-1_i64 = arith.constant -1 : i64
    %c32_i64 = arith.constant 32 : i64
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %c128 = arith.constant 128 : index
    %c32 = arith.constant 32 : index
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %_executable_main_dispatch_0 = util.global.load @_executable_main_dispatch_0 : !hal.executable
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %4 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%3}
    %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    %5 = arith.index_castui %0 : index to i64
    %6 = arith.trunci %5 : i64 to i32
    %7 = arith.shrui %5, %c32_i64 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %1 : index to i64
    %10 = arith.trunci %9 : i64 to i32
    %11 = arith.shrui %9, %c32_i64 : i64
    %12 = arith.trunci %11 : i64 to i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    %13 = arith.select %_device_query_0, %c0, %c-1 : index
    %14 = arith.index_cast %13 : index to i32
    cf.switch %14 : i32, [
      default: ^bb2,
      0: ^bb1
    ]
  ^bb1:  // pred: ^bb0
    hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout) offset(0) values([%6, %8, %10, %12]) : i32, i32, i32, i32
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%buffer : !hal.buffer)[%c0, %3], 
      %c1 = (%transient_buffer : !hal.buffer)[%c0, %3]
    ])
    %15 = arith.cmpi sle, %1, %c0 : index
    %16 = arith.subi %c0, %1 : index
    %17 = arith.subi %1, %c1 : index
    %18 = arith.select %15, %16, %17 : index
    %19 = arith.divsi %18, %c128 : index
    %20 = arith.subi %c0, %19 : index
    %21 = arith.addi %19, %c1 : index
    %22 = arith.select %15, %20, %21 : index
    %23 = arith.cmpi sle, %0, %c0 : index
    %24 = arith.subi %c0, %0 : index
    %25 = arith.subi %0, %c1 : index
    %26 = arith.select %23, %24, %25 : index
    %27 = arith.divsi %26, %c32 : index
    %28 = arith.subi %c0, %27 : index
    %29 = arith.addi %27, %c1 : index
    %30 = arith.select %23, %28, %29 : index
    %31 = arith.muli %22, %30 : index
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_main_dispatch_0 : !hal.executable)[0] workgroups([%31, %c1, %c1])
    cf.br ^bb2
  ^bb2:  // 2 preds: ^bb0, ^bb1
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_0 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status_1 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence_0) commands([%cmd])
    %status_2 = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status_2, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %3] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.initializer {
  %c0 = arith.constant 0 : index
  %c-1 = arith.constant -1 : index
  %device = hal.ex.shared_device : !hal.device
  %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
  %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer>]) : !hal.descriptor_set_layout
  %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(4) layouts([%descriptor_set_layout]) : !hal.pipeline_layout
  %0 = arith.select %value, %c0, %c-1 : index
  %1 = arith.index_cast %0 : index to i32
  util.global.store %value, @_device_query_0 : i1
  util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
  cf.switch %1 : i32, [
    default: ^bb2,
    0: ^bb1
  ]
^bb1:  // pred: ^bb0
  %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
  %exe = hal.executable.create device(%device : !hal.device) target(@main_dispatch_0::@cuda_nvptx_fb) layouts([%_pipeline_layout_0]) : !hal.executable
  cf.br ^bb3(%exe : !hal.executable)
^bb2:  // pred: ^bb0
  %2 = util.null : !hal.executable
  cf.br ^bb3(%2 : !hal.executable)
^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
  util.global.store %3, @_executable_main_dispatch_0 : !hal.executable
  util.initializer.return
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %_device_query_0 = util.global.load @_device_query_0 : i1
  %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
  %_executable_main_dispatch_0 = util.global.load @_executable_main_dispatch_0 : !hal.executable
  %c1 = arith.constant 1 : index
  %c-1 = arith.constant -1 : index
  %c-1_i32 = arith.constant -1 : i32
  %c0_i64 = arith.constant 0 : i64
  %c-1_i64 = arith.constant -1 : i64
  %c32_i64 = arith.constant 32 : i64
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %c128 = arith.constant 128 : index
  %c32 = arith.constant 32 : index
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %device = hal.ex.shared_device : !hal.device
  %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %4 = util.null : !hal.fence
  %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
  %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%3}
  %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
  %5 = arith.index_castui %0 : index to i64
  %6 = arith.trunci %5 : i64 to i32
  %7 = arith.shrui %5, %c32_i64 : i64
  %8 = arith.trunci %7 : i64 to i32
  %9 = arith.index_castui %1 : index to i64
  %10 = arith.trunci %9 : i64 to i32
  %11 = arith.shrui %9, %c32_i64 : i64
  %12 = arith.trunci %11 : i64 to i32
  %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
  %13 = arith.select %_device_query_0, %c0, %c-1 : index
  %14 = arith.index_cast %13 : index to i32
  cf.switch %14 : i32, [
    default: ^bb2,
    0: ^bb1
  ]
^bb1:  // pred: ^bb0
  hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout) offset(0) values([%6, %8, %10, %12]) : i32, i32, i32, i32
  hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
    %c0 = (%buffer : !hal.buffer)[%c0, %3], 
    %c1 = (%transient_buffer : !hal.buffer)[%c0, %3]
  ])
  %15 = arith.cmpi sle, %1, %c0 : index
  %16 = arith.subi %c0, %1 : index
  %17 = arith.subi %1, %c1 : index
  %18 = arith.select %15, %16, %17 : index
  %19 = arith.divsi %18, %c128 : index
  %20 = arith.subi %c0, %19 : index
  %21 = arith.addi %19, %c1 : index
  %22 = arith.select %15, %20, %21 : index
  %23 = arith.cmpi sle, %0, %c0 : index
  %24 = arith.subi %c0, %0 : index
  %25 = arith.subi %0, %c1 : index
  %26 = arith.select %23, %24, %25 : index
  %27 = arith.divsi %26, %c32 : index
  %28 = arith.subi %c0, %27 : index
  %29 = arith.addi %27, %c1 : index
  %30 = arith.select %23, %28, %29 : index
  %31 = arith.muli %22, %30 : index
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_main_dispatch_0 : !hal.executable)[0] workgroups([%31, %c1, %c1])
  cf.br ^bb2
^bb2:  // 2 preds: ^bb0, ^bb1
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  %fence_0 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
  %status_1 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
  hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence_0) commands([%cmd])
  %status_2 = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) : i32
  util.status.check_ok %status_2, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %3] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
  return %view : !hal.buffer_view
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private @_device_query_0 : i1
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.global private @_executable_main_dispatch_0 : !hal.executable
  util.initializer {
    %c0 = arith.constant 0 : index
    %c-1 = arith.constant -1 : index
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer>]) : !hal.descriptor_set_layout
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(4) layouts([%descriptor_set_layout]) : !hal.pipeline_layout
    %0 = arith.select %value, %c0, %c-1 : index
    %1 = arith.index_cast %0 : index to i32
    util.global.store %value, @_device_query_0 : i1
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    cf.switch %1 : i32, [
      default: ^bb2,
      0: ^bb1
    ]
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device : !hal.device) target(@main_dispatch_0::@cuda_nvptx_fb) layouts([%_pipeline_layout_0]) : !hal.executable
    cf.br ^bb3(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %2 = util.null : !hal.executable
    cf.br ^bb3(%2 : !hal.executable)
  ^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %3, @_executable_main_dispatch_0 : !hal.executable
    util.initializer.return
  }
  hal.executable private @main_dispatch_0 {
    hal.executable.binary public @cuda_nvptx_fb attributes {data = dense<"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vector<6926xi8>, format = "cuda-nvptx-fb", mime_type = "application/x-flatbuffers"}
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c32 = arith.constant 32 : index
    %c128 = arith.constant 128 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c32_i64 = arith.constant 32 : i64
    %c-1_i64 = arith.constant -1 : i64
    %c0_i64 = arith.constant 0 : i64
    %c-1_i32 = arith.constant -1 : i32
    %c-1 = arith.constant -1 : index
    %c1 = arith.constant 1 : index
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %_executable_main_dispatch_0 = util.global.load @_executable_main_dispatch_0 : !hal.executable
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %4 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%3}
    %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    %5 = arith.index_castui %0 : index to i64
    %6 = arith.trunci %5 : i64 to i32
    %7 = arith.shrui %5, %c32_i64 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %1 : index to i64
    %10 = arith.trunci %9 : i64 to i32
    %11 = arith.shrui %9, %c32_i64 : i64
    %12 = arith.trunci %11 : i64 to i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    %13 = arith.select %_device_query_0, %c0, %c-1 : index
    %14 = arith.index_cast %13 : index to i32
    cf.switch %14 : i32, [
      default: ^bb2,
      0: ^bb1
    ]
  ^bb1:  // pred: ^bb0
    hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout) offset(0) values([%6, %8, %10, %12]) : i32, i32, i32, i32
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%buffer : !hal.buffer)[%c0, %3], 
      %c1 = (%transient_buffer : !hal.buffer)[%c0, %3]
    ])
    %15 = arith.cmpi sle, %1, %c0 : index
    %16 = arith.subi %c0, %1 : index
    %17 = arith.subi %1, %c1 : index
    %18 = arith.select %15, %16, %17 : index
    %19 = arith.divsi %18, %c128 : index
    %20 = arith.subi %c0, %19 : index
    %21 = arith.addi %19, %c1 : index
    %22 = arith.select %15, %20, %21 : index
    %23 = arith.cmpi sle, %0, %c0 : index
    %24 = arith.subi %c0, %0 : index
    %25 = arith.subi %0, %c1 : index
    %26 = arith.select %23, %24, %25 : index
    %27 = arith.divsi %26, %c32 : index
    %28 = arith.subi %c0, %27 : index
    %29 = arith.addi %27, %c1 : index
    %30 = arith.select %23, %28, %29 : index
    %31 = arith.muli %22, %30 : index
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_main_dispatch_0 : !hal.executable)[0] workgroups([%31, %c1, %c1])
    cf.br ^bb2
  ^bb2:  // 2 preds: ^bb0, ^bb1
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_0 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status_1 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence_0) commands([%cmd])
    %status_2 = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status_2, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %3] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private @_device_query_0 : i1
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.global private @_executable_main_dispatch_0 : !hal.executable
  util.initializer {
    %c0 = arith.constant 0 : index
    %c-1 = arith.constant -1 : index
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer>]) : !hal.descriptor_set_layout
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(4) layouts([%descriptor_set_layout]) : !hal.pipeline_layout
    %0 = arith.select %value, %c0, %c-1 : index
    %1 = arith.index_cast %0 : index to i32
    util.global.store %value, @_device_query_0 : i1
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    cf.switch %1 : i32, [
      default: ^bb2,
      0: ^bb1
    ]
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device : !hal.device) target(@main_dispatch_0::@cuda_nvptx_fb) layouts([%_pipeline_layout_0]) : !hal.executable
    cf.br ^bb3(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %2 = util.null : !hal.executable
    cf.br ^bb3(%2 : !hal.executable)
  ^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %3, @_executable_main_dispatch_0 : !hal.executable
    util.initializer.return
  }
  hal.executable private @main_dispatch_0 {
    hal.executable.binary public @cuda_nvptx_fb attributes {data = dense<"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vector<6926xi8>, format = "cuda-nvptx-fb", mime_type = "application/x-flatbuffers"}
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c32 = arith.constant 32 : index
    %c128 = arith.constant 128 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c32_i64 = arith.constant 32 : i64
    %c-1_i64 = arith.constant -1 : i64
    %c0_i64 = arith.constant 0 : i64
    %c-1_i32 = arith.constant -1 : i32
    %c-1 = arith.constant -1 : index
    %c1 = arith.constant 1 : index
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %_executable_main_dispatch_0 = util.global.load @_executable_main_dispatch_0 : !hal.executable
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %4 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%3}
    %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    %5 = arith.index_castui %0 : index to i64
    %6 = arith.trunci %5 : i64 to i32
    %7 = arith.shrui %5, %c32_i64 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %1 : index to i64
    %10 = arith.trunci %9 : i64 to i32
    %11 = arith.shrui %9, %c32_i64 : i64
    %12 = arith.trunci %11 : i64 to i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    %13 = arith.select %_device_query_0, %c0, %c-1 : index
    %14 = arith.index_cast %13 : index to i32
    cf.switch %14 : i32, [
      default: ^bb2,
      0: ^bb1
    ]
  ^bb1:  // pred: ^bb0
    hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout) offset(0) values([%6, %8, %10, %12]) : i32, i32, i32, i32
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%buffer : !hal.buffer)[%c0, %3], 
      %c1 = (%transient_buffer : !hal.buffer)[%c0, %3]
    ])
    %15 = arith.cmpi sle, %1, %c0 : index
    %16 = arith.subi %c0, %1 : index
    %17 = arith.subi %1, %c1 : index
    %18 = arith.select %15, %16, %17 : index
    %19 = arith.divsi %18, %c128 : index
    %20 = arith.subi %c0, %19 : index
    %21 = arith.addi %19, %c1 : index
    %22 = arith.select %15, %20, %21 : index
    %23 = arith.cmpi sle, %0, %c0 : index
    %24 = arith.subi %c0, %0 : index
    %25 = arith.subi %0, %c1 : index
    %26 = arith.select %23, %24, %25 : index
    %27 = arith.divsi %26, %c32 : index
    %28 = arith.subi %c0, %27 : index
    %29 = arith.addi %27, %c1 : index
    %30 = arith.select %23, %28, %29 : index
    %31 = arith.muli %22, %30 : index
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_main_dispatch_0 : !hal.executable)[0] workgroups([%31, %c1, %c1])
    cf.br ^bb2
  ^bb2:  // 2 preds: ^bb0, ^bb1
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_0 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status_1 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence_0) commands([%cmd])
    %status_2 = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status_2, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %3] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private @_device_query_0 : i1
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.global private @_executable_main_dispatch_0 : !hal.executable
  util.initializer {
    %c0 = arith.constant 0 : index
    %c-1 = arith.constant -1 : index
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer>]) : !hal.descriptor_set_layout
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(4) layouts([%descriptor_set_layout]) : !hal.pipeline_layout
    %0 = arith.select %value, %c0, %c-1 : index
    %1 = arith.index_cast %0 : index to i32
    util.global.store %value, @_device_query_0 : i1
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    cf.switch %1 : i32, [
      default: ^bb2,
      0: ^bb1
    ]
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device : !hal.device) target(@main_dispatch_0::@cuda_nvptx_fb) layouts([%_pipeline_layout_0]) : !hal.executable
    cf.br ^bb3(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %2 = util.null : !hal.executable
    cf.br ^bb3(%2 : !hal.executable)
  ^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %3, @_executable_main_dispatch_0 : !hal.executable
    util.initializer.return
  }
  hal.executable private @main_dispatch_0 {
    hal.executable.binary public @cuda_nvptx_fb attributes {data = dense<"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vector<6926xi8>, format = "cuda-nvptx-fb", mime_type = "application/x-flatbuffers"}
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c32 = arith.constant 32 : index
    %c128 = arith.constant 128 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c32_i64 = arith.constant 32 : i64
    %c-1_i64 = arith.constant -1 : i64
    %c0_i64 = arith.constant 0 : i64
    %c-1_i32 = arith.constant -1 : i32
    %c-1 = arith.constant -1 : index
    %c1 = arith.constant 1 : index
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %_executable_main_dispatch_0 = util.global.load @_executable_main_dispatch_0 : !hal.executable
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %4 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%3}
    %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    %5 = arith.index_castui %0 : index to i64
    %6 = arith.trunci %5 : i64 to i32
    %7 = arith.shrui %5, %c32_i64 : i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.index_castui %1 : index to i64
    %10 = arith.trunci %9 : i64 to i32
    %11 = arith.shrui %9, %c32_i64 : i64
    %12 = arith.trunci %11 : i64 to i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    %13 = arith.select %_device_query_0, %c0, %c-1 : index
    %14 = arith.index_cast %13 : index to i32
    cf.switch %14 : i32, [
      default: ^bb2,
      0: ^bb1
    ]
  ^bb1:  // pred: ^bb0
    hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout) offset(0) values([%6, %8, %10, %12]) : i32, i32, i32, i32
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%buffer : !hal.buffer)[%c0, %3], 
      %c1 = (%transient_buffer : !hal.buffer)[%c0, %3]
    ])
    %15 = arith.cmpi sle, %1, %c0 : index
    %16 = arith.subi %c0, %1 : index
    %17 = arith.subi %1, %c1 : index
    %18 = arith.select %15, %16, %17 : index
    %19 = arith.divsi %18, %c128 : index
    %20 = arith.subi %c0, %19 : index
    %21 = arith.addi %19, %c1 : index
    %22 = arith.select %15, %20, %21 : index
    %23 = arith.cmpi sle, %0, %c0 : index
    %24 = arith.subi %c0, %0 : index
    %25 = arith.subi %0, %c1 : index
    %26 = arith.select %23, %24, %25 : index
    %27 = arith.divsi %26, %c32 : index
    %28 = arith.subi %c0, %27 : index
    %29 = arith.addi %27, %c1 : index
    %30 = arith.select %23, %28, %29 : index
    %31 = arith.muli %22, %30 : index
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_main_dispatch_0 : !hal.executable)[0] workgroups([%31, %c1, %c1])
    cf.br ^bb2
  ^bb2:  // 2 preds: ^bb0, ^bb1
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_0 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status_1 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence_0) commands([%cmd])
    %status_2 = hal.fence.await until([%fence_0]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status_2, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %3] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::VM::ConversionPass (iree-vm-conversion) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda], vm.toplevel} {
  vm.module public @LinearModule {
    vm.global.i32 private @_device_query_0 : i32
    vm.global.ref private @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.global.ref private @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
    vm.rodata private @main_dispatch_0_cuda_nvptx_fb {alignment = 16 : i64, mime_type = "application/x-flatbuffers"} dense<"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vector<6926xi8>
    vm.initializer {
      %zero = vm.const.i64.zero
      %c-1 = vm.const.i64 -1
      %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %buffer = vm.rodata.inline "_utf8_hal_executable_format_EAB228F999C2D3A1" {alignment = 1 : i64} : !vm.buffer = "hal.executable.format"
      %buffer_0 = vm.rodata.inline "_utf8_cuda_nvptx_fb_B15B42B96FDBACC" {alignment = 1 : i64} : !vm.buffer = "cuda-nvptx-fb"
      %0:2 = vm.call @hal.device.query.i64(%ref, %buffer, %buffer_0) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
      %c1 = vm.const.i32 1
      %2 = vm.and.i32 %1, %c1 : i32
      %zero_1 = vm.const.i32.zero
      %3 = vm.select.i32 %0#0, %2, %zero_1 : i32
      %c1_2 = vm.const.i32 1
      %zero_3 = vm.const.i32.zero
      %zero_4 = vm.const.i32.zero
      %c7 = vm.const.i32 7
      %c1_5 = vm.const.i32 1
      %c1_6 = vm.const.i32 1
      %c7_7 = vm.const.i32 7
      %zero_8 = vm.const.i32.zero
      %ref_9 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero_3, [(%zero_4, %c7, %c1_5), (%c1_6, %c7_7, %zero_8)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
      %c4 = vm.const.i32 4
      %ref_10 = vm.call.variadic @hal.pipeline_layout.create(%ref, %c4, [%ref_9]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
      %4 = vm.select.i64 %3, %zero, %c-1 : i64
      %5 = vm.trunc.i64.i32 %4 : i64 -> i32
      vm.global.store.i32 %3, @_device_query_0 : i32
      vm.global.store.ref %ref_10, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      vm.br_table %5 {
        default: ^bb2,
        0: ^bb1
      }
    ^bb1:  // pred: ^bb0
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %main_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @main_dispatch_0_cuda_nvptx_fb : !vm.buffer
      %buffer_11 = vm.rodata.inline "_utf8_cuda_nvptx_fb_B15B42B96FDBACC" {alignment = 1 : i64} : !vm.buffer = "cuda-nvptx-fb"
      %null = vm.const.ref.zero : !vm.buffer
      %ref_12 = vm.call.variadic @hal.executable.create(%ref, %buffer_11, %main_dispatch_0_cuda_nvptx_fb, %null, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
      vm.br ^bb3(%ref_12 : !vm.ref<!hal.executable>)
    ^bb2:  // pred: ^bb0
      %null_13 = vm.const.ref.zero : !vm.ref<!hal.executable>
      vm.br ^bb3(%null_13 : !vm.ref<!hal.executable>)
    ^bb3(%6: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
      vm.global.store.ref %6, @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
      vm.return
    }
    vm.import private @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects}
    vm.import private @hal.ex.file.from_memory(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %access : i32, %buffer : !vm.buffer, %offset : i64, %length : i64, %flags : i32) -> !vm.ref<!hal.file>
    vm.import private @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
    vm.import private @hal.allocator.import(%allocator : !vm.ref<!hal.allocator>, %try : i32, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %source : !vm.buffer, %offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
    vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
    vm.import private @hal.buffer.subspan(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.buffer.length(%buffer : !vm.ref<!hal.buffer>) -> i64 attributes {nosideeffects}
    vm.import private @hal.buffer.load(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i32) -> i32
    vm.import private @hal.buffer.store(%value : i32, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i32)
    vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
    vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
    vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.buffer_view.element_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
    vm.import private @hal.buffer_view.encoding_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
    vm.import private @hal.buffer_view.rank(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
    vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
    vm.import private @hal.buffer_view.trace(%key : !vm.buffer, %operands : !vm.ref<!hal.buffer_view> ...)
    vm.import private @hal.channel.create(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %flags : i32, %id : !vm.buffer, %group : !vm.buffer, %rank : i32, %count : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects}
    vm.import private @hal.channel.split(%channel : !vm.ref<!hal.channel>, %color : i32, %key : i32, %flags : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects}
    vm.import private @hal.channel.rank_and_count(%channel : !vm.ref<!hal.channel>) -> (i32, i32) attributes {nosideeffects}
    vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer>
    vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.begin_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>, %label : !vm.buffer)
    vm.import private @hal.command_buffer.end_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
    vm.import private @hal.command_buffer.fill_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %pattern : i32, %pattern_length : i32)
    vm.import private @hal.command_buffer.copy_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64)
    vm.import private @hal.command_buffer.collective(%command_buffer : !vm.ref<!hal.command_buffer>, %channel : !vm.ref<!hal.channel>, %op : i32, %param : i32, %send_buffer : !vm.ref<!hal.buffer>, %send_offset : i64, %send_length : i64, %recv_buffer : !vm.ref<!hal.buffer>, %recv_offset : i64, %recv_length : i64, %element_count : i64)
    vm.import private @hal.command_buffer.push_constants(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %offset : i32, %values : i32 ...)
    vm.import private @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32)
    vm.import private @hal.command_buffer.dispatch.indirect(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroups_buffer : !vm.ref<!hal.buffer>, %workgroups_offset : i64)
    vm.import private @hal.command_buffer.execute.commands(%command_buffer : !vm.ref<!hal.command_buffer>, %commands : !vm.ref<!hal.command_buffer>, %bindings : tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects}
    vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
    vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
    vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
    vm.import private @hal.device.queue.dealloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %buffer : !vm.ref<!hal.buffer>)
    vm.import private @hal.device.queue.read(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_file : !vm.ref<!hal.file>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i32)
    vm.import private @hal.device.queue.write(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_file : !vm.ref<!hal.file>, %target_offset : i64, %length : i64, %flags : i32)
    vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
    vm.import private @hal.device.queue.flush(%device : !vm.ref<!hal.device>, %queue_affinity : i64)
    vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects}
    vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
    vm.import private @hal.fence.join(%fences : !vm.ref<!hal.fence> ...) -> !vm.ref<!hal.fence> attributes {nosideeffects}
    vm.import private @hal.fence.query(%fence : !vm.ref<!hal.fence>) -> i32
    vm.import private @hal.fence.signal(%fence : !vm.ref<!hal.fence>)
    vm.import private @hal.fence.fail(%fence : !vm.ref<!hal.fence>, %status : i32)
    vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
    vm.import private @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects}
    vm.func private @main(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
      %c32 = vm.const.i64 32
      %c128 = vm.const.i64 128
      %c553648160 = vm.const.i32 553648160
      %c1 = vm.const.i32 1
      %zero = vm.const.i64.zero
      %c4 = vm.const.i64 4
      %c32_0 = vm.const.i64 32
      %c-1 = vm.const.i64 -1
      %zero_1 = vm.const.i64.zero
      %c-1_2 = vm.const.i32 -1
      %c-1_3 = vm.const.i64 -1
      %c1_4 = vm.const.i64 1
      %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %_executable_main_dispatch_0 = vm.global.load.ref @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
      %zero_5 = vm.const.i32.zero
      %0 = vm.call @hal.buffer_view.dim(%arg0, %zero_5) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %c1_6 = vm.const.i32 1
      %1 = vm.call @hal.buffer_view.dim(%arg0, %c1_6) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %buffer = vm.rodata.inline "_utf8_input_0_5FD512E67BEFDEEC" {alignment = 1 : i64} : !vm.buffer = "input 0"
      vm.call.variadic @hal.buffer_view.assert(%arg0, %buffer, %c553648160, %c1, [%0, %1]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %2 = vm.mul.i64 %0, %c4 : i64
      %3 = vm.mul.i64 %2, %1 : i64
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_7 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %ref_8 = vm.call @hal.device.allocator(%ref_7) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %buffer_9 = vm.rodata.inline "_utf8_tensor_3C6209B4FD120BDC" {alignment = 1 : i64} : !vm.buffer = "tensor"
      %c16 = vm.const.i32 16
      %c3075 = vm.const.i32 3075
      vm.call @hal.buffer.assert(%ref, %buffer_9, %ref_8, %3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %zero_10 = vm.const.i32.zero
      %ref_11 = vm.call @hal.fence.create(%ref_7, %zero_10) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      %zero_12 = vm.const.i32.zero
      %c48 = vm.const.i32 48
      %c3075_13 = vm.const.i32 3075
      %ref_14 = vm.call @hal.device.queue.alloca(%ref_7, %c-1, %null, %ref_11, %zero_12, %c48, %c3075_13, %3) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
      %4 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_11]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      %5 = vm.trunc.i64.i32 %0 : i64 -> i32
      %c32_15 = vm.const.i32 32
      %6 = vm.shr.i64.u %0, %c32_15 : i64
      %7 = vm.trunc.i64.i32 %6 : i64 -> i32
      %8 = vm.trunc.i64.i32 %1 : i64 -> i32
      %c32_16 = vm.const.i32 32
      %9 = vm.shr.i64.u %1, %c32_16 : i64
      %10 = vm.trunc.i64.i32 %9 : i64 -> i32
      %c17 = vm.const.i32 17
      %c3 = vm.const.i32 3
      %zero_17 = vm.const.i32.zero
      %ref_18 = vm.call @hal.command_buffer.create(%ref_7, %c17, %c3, %zero_17) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
      %11 = vm.select.i64 %_device_query_0, %zero, %c-1_3 : i64
      %12 = vm.trunc.i64.i32 %11 : i64 -> i32
      vm.br_table %12 {
        default: ^bb2,
        0: ^bb1
      }
    ^bb1:  // pred: ^bb0
      %zero_19 = vm.const.i32.zero
      vm.call.variadic @hal.command_buffer.push_constants(%ref_18, %_pipeline_layout_0, %zero_19, [%5, %7, %8, %10]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, i32 ...)
      %zero_20 = vm.const.i32.zero
      %zero_21 = vm.const.i32.zero
      %zero_22 = vm.const.i32.zero
      %c1_23 = vm.const.i32 1
      vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_18, %_pipeline_layout_0, %zero_20, [(%zero_21, %zero_22, %ref, %zero, %3), (%c1_23, %zero_22, %ref_14, %zero, %3)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      %slte = vm.cmp.lte.i64.s %1, %zero : i64
      %13 = vm.sub.i64 %zero, %1 : i64
      %14 = vm.sub.i64 %1, %c1_4 : i64
      %15 = vm.select.i64 %slte, %13, %14 : i64
      %16 = vm.div.i64.s %15, %c128 : i64
      %17 = vm.sub.i64 %zero, %16 : i64
      %18 = vm.add.i64 %16, %c1_4 : i64
      %19 = vm.select.i64 %slte, %17, %18 : i64
      %slte_24 = vm.cmp.lte.i64.s %0, %zero : i64
      %20 = vm.sub.i64 %zero, %0 : i64
      %21 = vm.sub.i64 %0, %c1_4 : i64
      %22 = vm.select.i64 %slte_24, %20, %21 : i64
      %23 = vm.div.i64.s %22, %c32 : i64
      %24 = vm.sub.i64 %zero, %23 : i64
      %25 = vm.add.i64 %23, %c1_4 : i64
      %26 = vm.select.i64 %slte_24, %24, %25 : i64
      %27 = vm.mul.i64 %19, %26 : i64
      %zero_25 = vm.const.i32.zero
      %28 = vm.trunc.i64.i32 %27 : i64 -> i32
      %c1_26 = vm.const.i32 1
      %c1_27 = vm.const.i32 1
      vm.call @hal.command_buffer.dispatch(%ref_18, %_executable_main_dispatch_0, %zero_25, %28, %c1_26, %c1_27) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
      vm.br ^bb2
    ^bb2:  // 2 preds: ^bb0, ^bb1
      %c28 = vm.const.i32 28
      %c13 = vm.const.i32 13
      %zero_28 = vm.const.i32.zero
      vm.call @hal.command_buffer.execution_barrier(%ref_18, %c28, %c13, %zero_28) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.finalize(%ref_18) : (!vm.ref<!hal.command_buffer>) -> ()
      %zero_29 = vm.const.i32.zero
      %ref_30 = vm.call @hal.fence.create(%ref_7, %zero_29) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      %29 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_11]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.call.variadic @hal.device.queue.execute(%ref_7, %c-1, %null, %ref_30, [%ref_18]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
      %30 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_30]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_fail %30, "failed to wait on timepoint"
      %ref_31 = vm.call.variadic @hal.buffer_view.create(%ref_14, %zero, %3, %c553648160, %c1, [%0, %1]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_31 : !vm.ref<!hal.buffer_view>
    }
    vm.export @main attributes {iree.abi.stub}
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::VM::HoistInlinedRodataPass (iree-vm-hoist-inlined-rodata) //----- //
vm.module public @LinearModule {
  vm.global.i32 private @_device_query_0 : i32
  vm.global.ref private @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
  vm.global.ref private @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
  vm.rodata private @main_dispatch_0_cuda_nvptx_fb {alignment = 16 : i64, mime_type = "application/x-flatbuffers"} dense<"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vector<6926xi8>
  vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
  vm.rodata private @_utf8_cuda_nvptx_fb_B15B42B96FDBACC {alignment = 1 : i64} "cuda-nvptx-fb"
  vm.rodata private @_utf8_cuda_nvptx_fb_B15B42B96FDBACC_0 {alignment = 1 : i64} "cuda-nvptx-fb"
  vm.initializer {
    %zero = vm.const.i64.zero
    %c-1 = vm.const.i64 -1
    %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
    %_utf8_cuda_nvptx_fb_B15B42B96FDBACC = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
    %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
    %c1 = vm.const.i32 1
    %2 = vm.and.i32 %1, %c1 : i32
    %zero_0 = vm.const.i32.zero
    %3 = vm.select.i32 %0#0, %2, %zero_0 : i32
    %c1_1 = vm.const.i32 1
    %zero_2 = vm.const.i32.zero
    %zero_3 = vm.const.i32.zero
    %c7 = vm.const.i32 7
    %c1_4 = vm.const.i32 1
    %c1_5 = vm.const.i32 1
    %c7_6 = vm.const.i32 7
    %zero_7 = vm.const.i32.zero
    %ref_8 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero_2, [(%zero_3, %c7, %c1_4), (%c1_5, %c7_6, %zero_7)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
    %c4 = vm.const.i32 4
    %ref_9 = vm.call.variadic @hal.pipeline_layout.create(%ref, %c4, [%ref_8]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
    %4 = vm.select.i64 %3, %zero, %c-1 : i64
    %5 = vm.trunc.i64.i32 %4 : i64 -> i32
    vm.global.store.i32 %3, @_device_query_0 : i32
    vm.global.store.ref %ref_9, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.br_table %5 {
      default: ^bb2,
      0: ^bb1
    }
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %main_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @main_dispatch_0_cuda_nvptx_fb : !vm.buffer
    %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_0 = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC_0 : !vm.buffer
    %null = vm.const.ref.zero : !vm.buffer
    %ref_10 = vm.call.variadic @hal.executable.create(%ref, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_0, %main_dispatch_0_cuda_nvptx_fb, %null, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
    vm.br ^bb3(%ref_10 : !vm.ref<!hal.executable>)
  ^bb2:  // pred: ^bb0
    %null_11 = vm.const.ref.zero : !vm.ref<!hal.executable>
    vm.br ^bb3(%null_11 : !vm.ref<!hal.executable>)
  ^bb3(%6: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
    vm.global.store.ref %6, @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
    vm.return
  }
  vm.import private @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects}
  vm.import private @hal.ex.file.from_memory(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %access : i32, %buffer : !vm.buffer, %offset : i64, %length : i64, %flags : i32) -> !vm.ref<!hal.file>
  vm.import private @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
  vm.import private @hal.allocator.import(%allocator : !vm.ref<!hal.allocator>, %try : i32, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %source : !vm.buffer, %offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
  vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
  vm.import private @hal.buffer.subspan(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
  vm.import private @hal.buffer.length(%buffer : !vm.ref<!hal.buffer>) -> i64 attributes {nosideeffects}
  vm.import private @hal.buffer.load(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i32) -> i32
  vm.import private @hal.buffer.store(%value : i32, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i32)
  vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
  vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
  vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
  vm.import private @hal.buffer_view.element_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
  vm.import private @hal.buffer_view.encoding_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
  vm.import private @hal.buffer_view.rank(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
  vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
  vm.import private @hal.buffer_view.trace(%key : !vm.buffer, %operands : !vm.ref<!hal.buffer_view> ...)
  vm.import private @hal.channel.create(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %flags : i32, %id : !vm.buffer, %group : !vm.buffer, %rank : i32, %count : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects}
  vm.import private @hal.channel.split(%channel : !vm.ref<!hal.channel>, %color : i32, %key : i32, %flags : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects}
  vm.import private @hal.channel.rank_and_count(%channel : !vm.ref<!hal.channel>) -> (i32, i32) attributes {nosideeffects}
  vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer>
  vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
  vm.import private @hal.command_buffer.begin_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>, %label : !vm.buffer)
  vm.import private @hal.command_buffer.end_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>)
  vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
  vm.import private @hal.command_buffer.fill_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %pattern : i32, %pattern_length : i32)
  vm.import private @hal.command_buffer.copy_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64)
  vm.import private @hal.command_buffer.collective(%command_buffer : !vm.ref<!hal.command_buffer>, %channel : !vm.ref<!hal.channel>, %op : i32, %param : i32, %send_buffer : !vm.ref<!hal.buffer>, %send_offset : i64, %send_length : i64, %recv_buffer : !vm.ref<!hal.buffer>, %recv_offset : i64, %recv_length : i64, %element_count : i64)
  vm.import private @hal.command_buffer.push_constants(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %offset : i32, %values : i32 ...)
  vm.import private @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32)
  vm.import private @hal.command_buffer.dispatch.indirect(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroups_buffer : !vm.ref<!hal.buffer>, %workgroups_offset : i64)
  vm.import private @hal.command_buffer.execute.commands(%command_buffer : !vm.ref<!hal.command_buffer>, %commands : !vm.ref<!hal.command_buffer>, %bindings : tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects}
  vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
  vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
  vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
  vm.import private @hal.device.queue.dealloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %buffer : !vm.ref<!hal.buffer>)
  vm.import private @hal.device.queue.read(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_file : !vm.ref<!hal.file>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i32)
  vm.import private @hal.device.queue.write(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_file : !vm.ref<!hal.file>, %target_offset : i64, %length : i64, %flags : i32)
  vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
  vm.import private @hal.device.queue.flush(%device : !vm.ref<!hal.device>, %queue_affinity : i64)
  vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects}
  vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
  vm.import private @hal.fence.join(%fences : !vm.ref<!hal.fence> ...) -> !vm.ref<!hal.fence> attributes {nosideeffects}
  vm.import private @hal.fence.query(%fence : !vm.ref<!hal.fence>) -> i32
  vm.import private @hal.fence.signal(%fence : !vm.ref<!hal.fence>)
  vm.import private @hal.fence.fail(%fence : !vm.ref<!hal.fence>, %status : i32)
  vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
  vm.import private @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects}
  vm.rodata private @_utf8_input_0_5FD512E67BEFDEEC {alignment = 1 : i64} "input 0"
  vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
  vm.func private @main(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
    %c32 = vm.const.i64 32
    %c128 = vm.const.i64 128
    %c553648160 = vm.const.i32 553648160
    %c1 = vm.const.i32 1
    %zero = vm.const.i64.zero
    %c4 = vm.const.i64 4
    %c32_0 = vm.const.i64 32
    %c-1 = vm.const.i64 -1
    %zero_1 = vm.const.i64.zero
    %c-1_2 = vm.const.i32 -1
    %c-1_3 = vm.const.i64 -1
    %c1_4 = vm.const.i64 1
    %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %_executable_main_dispatch_0 = vm.global.load.ref @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
    %zero_5 = vm.const.i32.zero
    %0 = vm.call @hal.buffer_view.dim(%arg0, %zero_5) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %c1_6 = vm.const.i32 1
    %1 = vm.call @hal.buffer_view.dim(%arg0, %c1_6) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1, [%0, %1]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %2 = vm.mul.i64 %0, %c4 : i64
    %3 = vm.mul.i64 %2, %1 : i64
    %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %ref_7 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %ref_8 = vm.call @hal.device.allocator(%ref_7) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
    %c16 = vm.const.i32 16
    %c3075 = vm.const.i32 3075
    vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_8, %3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %null = vm.const.ref.zero : !vm.ref<!hal.fence>
    %zero_9 = vm.const.i32.zero
    %ref_10 = vm.call @hal.fence.create(%ref_7, %zero_9) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    %zero_11 = vm.const.i32.zero
    %c48 = vm.const.i32 48
    %c3075_12 = vm.const.i32 3075
    %ref_13 = vm.call @hal.device.queue.alloca(%ref_7, %c-1, %null, %ref_10, %zero_11, %c48, %c3075_12, %3) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
    %4 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_10]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    %5 = vm.trunc.i64.i32 %0 : i64 -> i32
    %c32_14 = vm.const.i32 32
    %6 = vm.shr.i64.u %0, %c32_14 : i64
    %7 = vm.trunc.i64.i32 %6 : i64 -> i32
    %8 = vm.trunc.i64.i32 %1 : i64 -> i32
    %c32_15 = vm.const.i32 32
    %9 = vm.shr.i64.u %1, %c32_15 : i64
    %10 = vm.trunc.i64.i32 %9 : i64 -> i32
    %c17 = vm.const.i32 17
    %c3 = vm.const.i32 3
    %zero_16 = vm.const.i32.zero
    %ref_17 = vm.call @hal.command_buffer.create(%ref_7, %c17, %c3, %zero_16) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
    %11 = vm.select.i64 %_device_query_0, %zero, %c-1_3 : i64
    %12 = vm.trunc.i64.i32 %11 : i64 -> i32
    vm.br_table %12 {
      default: ^bb2,
      0: ^bb1
    }
  ^bb1:  // pred: ^bb0
    %zero_18 = vm.const.i32.zero
    vm.call.variadic @hal.command_buffer.push_constants(%ref_17, %_pipeline_layout_0, %zero_18, [%5, %7, %8, %10]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, i32 ...)
    %zero_19 = vm.const.i32.zero
    %zero_20 = vm.const.i32.zero
    %zero_21 = vm.const.i32.zero
    %c1_22 = vm.const.i32 1
    vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_17, %_pipeline_layout_0, %zero_19, [(%zero_20, %zero_21, %ref, %zero, %3), (%c1_22, %zero_21, %ref_13, %zero, %3)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    %slte = vm.cmp.lte.i64.s %1, %zero : i64
    %13 = vm.sub.i64 %zero, %1 : i64
    %14 = vm.sub.i64 %1, %c1_4 : i64
    %15 = vm.select.i64 %slte, %13, %14 : i64
    %16 = vm.div.i64.s %15, %c128 : i64
    %17 = vm.sub.i64 %zero, %16 : i64
    %18 = vm.add.i64 %16, %c1_4 : i64
    %19 = vm.select.i64 %slte, %17, %18 : i64
    %slte_23 = vm.cmp.lte.i64.s %0, %zero : i64
    %20 = vm.sub.i64 %zero, %0 : i64
    %21 = vm.sub.i64 %0, %c1_4 : i64
    %22 = vm.select.i64 %slte_23, %20, %21 : i64
    %23 = vm.div.i64.s %22, %c32 : i64
    %24 = vm.sub.i64 %zero, %23 : i64
    %25 = vm.add.i64 %23, %c1_4 : i64
    %26 = vm.select.i64 %slte_23, %24, %25 : i64
    %27 = vm.mul.i64 %19, %26 : i64
    %zero_24 = vm.const.i32.zero
    %28 = vm.trunc.i64.i32 %27 : i64 -> i32
    %c1_25 = vm.const.i32 1
    %c1_26 = vm.const.i32 1
    vm.call @hal.command_buffer.dispatch(%ref_17, %_executable_main_dispatch_0, %zero_24, %28, %c1_25, %c1_26) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
    vm.br ^bb2
  ^bb2:  // 2 preds: ^bb0, ^bb1
    %c28 = vm.const.i32 28
    %c13 = vm.const.i32 13
    %zero_27 = vm.const.i32.zero
    vm.call @hal.command_buffer.execution_barrier(%ref_17, %c28, %c13, %zero_27) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
    vm.call @hal.command_buffer.finalize(%ref_17) : (!vm.ref<!hal.command_buffer>) -> ()
    %zero_28 = vm.const.i32.zero
    %ref_29 = vm.call @hal.fence.create(%ref_7, %zero_28) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    %29 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_10]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    vm.call.variadic @hal.device.queue.execute(%ref_7, %c-1, %null, %ref_29, [%ref_17]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
    %30 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_29]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    vm.cond_fail %30, "failed to wait on timepoint"
    %ref_30 = vm.call.variadic @hal.buffer_view.create(%ref_13, %zero, %3, %c553648160, %c1, [%0, %1]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
    vm.return %ref_30 : !vm.ref<!hal.buffer_view>
  }
  vm.export @main attributes {iree.abi.stub}
}

// -----// IR Dump After mlir::iree_compiler::IREE::VM::DeduplicateRodataPass (iree-vm-deduplicate-rodata) //----- //
vm.module public @LinearModule {
  vm.global.i32 private @_device_query_0 : i32
  vm.global.ref private @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
  vm.global.ref private @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
  vm.rodata private @main_dispatch_0_cuda_nvptx_fb {alignment = 16 : i64, mime_type = "application/x-flatbuffers"} dense<"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vector<6926xi8>
  vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
  vm.rodata private @_utf8_cuda_nvptx_fb_B15B42B96FDBACC {alignment = 1 : i64} "cuda-nvptx-fb"
  vm.initializer {
    %zero = vm.const.i64.zero
    %c-1 = vm.const.i64 -1
    %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
    %_utf8_cuda_nvptx_fb_B15B42B96FDBACC = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
    %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
    %c1 = vm.const.i32 1
    %2 = vm.and.i32 %1, %c1 : i32
    %zero_0 = vm.const.i32.zero
    %3 = vm.select.i32 %0#0, %2, %zero_0 : i32
    %c1_1 = vm.const.i32 1
    %zero_2 = vm.const.i32.zero
    %zero_3 = vm.const.i32.zero
    %c7 = vm.const.i32 7
    %c1_4 = vm.const.i32 1
    %c1_5 = vm.const.i32 1
    %c7_6 = vm.const.i32 7
    %zero_7 = vm.const.i32.zero
    %ref_8 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero_2, [(%zero_3, %c7, %c1_4), (%c1_5, %c7_6, %zero_7)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
    %c4 = vm.const.i32 4
    %ref_9 = vm.call.variadic @hal.pipeline_layout.create(%ref, %c4, [%ref_8]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
    %4 = vm.select.i64 %3, %zero, %c-1 : i64
    %5 = vm.trunc.i64.i32 %4 : i64 -> i32
    vm.global.store.i32 %3, @_device_query_0 : i32
    vm.global.store.ref %ref_9, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.br_table %5 {
      default: ^bb2,
      0: ^bb1
    }
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %main_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @main_dispatch_0_cuda_nvptx_fb : !vm.buffer
    %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_10 = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
    %null = vm.const.ref.zero : !vm.buffer
    %ref_11 = vm.call.variadic @hal.executable.create(%ref, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_10, %main_dispatch_0_cuda_nvptx_fb, %null, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
    vm.br ^bb3(%ref_11 : !vm.ref<!hal.executable>)
  ^bb2:  // pred: ^bb0
    %null_12 = vm.const.ref.zero : !vm.ref<!hal.executable>
    vm.br ^bb3(%null_12 : !vm.ref<!hal.executable>)
  ^bb3(%6: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
    vm.global.store.ref %6, @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
    vm.return
  }
  vm.import private @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects}
  vm.import private @hal.ex.file.from_memory(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %access : i32, %buffer : !vm.buffer, %offset : i64, %length : i64, %flags : i32) -> !vm.ref<!hal.file>
  vm.import private @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
  vm.import private @hal.allocator.import(%allocator : !vm.ref<!hal.allocator>, %try : i32, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %source : !vm.buffer, %offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
  vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
  vm.import private @hal.buffer.subspan(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
  vm.import private @hal.buffer.length(%buffer : !vm.ref<!hal.buffer>) -> i64 attributes {nosideeffects}
  vm.import private @hal.buffer.load(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i32) -> i32
  vm.import private @hal.buffer.store(%value : i32, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i32)
  vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
  vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
  vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
  vm.import private @hal.buffer_view.element_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
  vm.import private @hal.buffer_view.encoding_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
  vm.import private @hal.buffer_view.rank(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
  vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
  vm.import private @hal.buffer_view.trace(%key : !vm.buffer, %operands : !vm.ref<!hal.buffer_view> ...)
  vm.import private @hal.channel.create(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %flags : i32, %id : !vm.buffer, %group : !vm.buffer, %rank : i32, %count : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects}
  vm.import private @hal.channel.split(%channel : !vm.ref<!hal.channel>, %color : i32, %key : i32, %flags : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects}
  vm.import private @hal.channel.rank_and_count(%channel : !vm.ref<!hal.channel>) -> (i32, i32) attributes {nosideeffects}
  vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer>
  vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
  vm.import private @hal.command_buffer.begin_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>, %label : !vm.buffer)
  vm.import private @hal.command_buffer.end_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>)
  vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
  vm.import private @hal.command_buffer.fill_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %pattern : i32, %pattern_length : i32)
  vm.import private @hal.command_buffer.copy_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64)
  vm.import private @hal.command_buffer.collective(%command_buffer : !vm.ref<!hal.command_buffer>, %channel : !vm.ref<!hal.channel>, %op : i32, %param : i32, %send_buffer : !vm.ref<!hal.buffer>, %send_offset : i64, %send_length : i64, %recv_buffer : !vm.ref<!hal.buffer>, %recv_offset : i64, %recv_length : i64, %element_count : i64)
  vm.import private @hal.command_buffer.push_constants(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %offset : i32, %values : i32 ...)
  vm.import private @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32)
  vm.import private @hal.command_buffer.dispatch.indirect(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroups_buffer : !vm.ref<!hal.buffer>, %workgroups_offset : i64)
  vm.import private @hal.command_buffer.execute.commands(%command_buffer : !vm.ref<!hal.command_buffer>, %commands : !vm.ref<!hal.command_buffer>, %bindings : tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects}
  vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
  vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
  vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
  vm.import private @hal.device.queue.dealloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %buffer : !vm.ref<!hal.buffer>)
  vm.import private @hal.device.queue.read(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_file : !vm.ref<!hal.file>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i32)
  vm.import private @hal.device.queue.write(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_file : !vm.ref<!hal.file>, %target_offset : i64, %length : i64, %flags : i32)
  vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
  vm.import private @hal.device.queue.flush(%device : !vm.ref<!hal.device>, %queue_affinity : i64)
  vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects}
  vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
  vm.import private @hal.fence.join(%fences : !vm.ref<!hal.fence> ...) -> !vm.ref<!hal.fence> attributes {nosideeffects}
  vm.import private @hal.fence.query(%fence : !vm.ref<!hal.fence>) -> i32
  vm.import private @hal.fence.signal(%fence : !vm.ref<!hal.fence>)
  vm.import private @hal.fence.fail(%fence : !vm.ref<!hal.fence>, %status : i32)
  vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
  vm.import private @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects}
  vm.rodata private @_utf8_input_0_5FD512E67BEFDEEC {alignment = 1 : i64} "input 0"
  vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
  vm.func private @main(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
    %c32 = vm.const.i64 32
    %c128 = vm.const.i64 128
    %c553648160 = vm.const.i32 553648160
    %c1 = vm.const.i32 1
    %zero = vm.const.i64.zero
    %c4 = vm.const.i64 4
    %c32_0 = vm.const.i64 32
    %c-1 = vm.const.i64 -1
    %zero_1 = vm.const.i64.zero
    %c-1_2 = vm.const.i32 -1
    %c-1_3 = vm.const.i64 -1
    %c1_4 = vm.const.i64 1
    %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %_executable_main_dispatch_0 = vm.global.load.ref @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
    %zero_5 = vm.const.i32.zero
    %0 = vm.call @hal.buffer_view.dim(%arg0, %zero_5) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %c1_6 = vm.const.i32 1
    %1 = vm.call @hal.buffer_view.dim(%arg0, %c1_6) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1, [%0, %1]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %2 = vm.mul.i64 %0, %c4 : i64
    %3 = vm.mul.i64 %2, %1 : i64
    %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %ref_7 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %ref_8 = vm.call @hal.device.allocator(%ref_7) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
    %c16 = vm.const.i32 16
    %c3075 = vm.const.i32 3075
    vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_8, %3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %null = vm.const.ref.zero : !vm.ref<!hal.fence>
    %zero_9 = vm.const.i32.zero
    %ref_10 = vm.call @hal.fence.create(%ref_7, %zero_9) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    %zero_11 = vm.const.i32.zero
    %c48 = vm.const.i32 48
    %c3075_12 = vm.const.i32 3075
    %ref_13 = vm.call @hal.device.queue.alloca(%ref_7, %c-1, %null, %ref_10, %zero_11, %c48, %c3075_12, %3) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
    %4 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_10]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    %5 = vm.trunc.i64.i32 %0 : i64 -> i32
    %c32_14 = vm.const.i32 32
    %6 = vm.shr.i64.u %0, %c32_14 : i64
    %7 = vm.trunc.i64.i32 %6 : i64 -> i32
    %8 = vm.trunc.i64.i32 %1 : i64 -> i32
    %c32_15 = vm.const.i32 32
    %9 = vm.shr.i64.u %1, %c32_15 : i64
    %10 = vm.trunc.i64.i32 %9 : i64 -> i32
    %c17 = vm.const.i32 17
    %c3 = vm.const.i32 3
    %zero_16 = vm.const.i32.zero
    %ref_17 = vm.call @hal.command_buffer.create(%ref_7, %c17, %c3, %zero_16) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
    %11 = vm.select.i64 %_device_query_0, %zero, %c-1_3 : i64
    %12 = vm.trunc.i64.i32 %11 : i64 -> i32
    vm.br_table %12 {
      default: ^bb2,
      0: ^bb1
    }
  ^bb1:  // pred: ^bb0
    %zero_18 = vm.const.i32.zero
    vm.call.variadic @hal.command_buffer.push_constants(%ref_17, %_pipeline_layout_0, %zero_18, [%5, %7, %8, %10]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, i32 ...)
    %zero_19 = vm.const.i32.zero
    %zero_20 = vm.const.i32.zero
    %zero_21 = vm.const.i32.zero
    %c1_22 = vm.const.i32 1
    vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_17, %_pipeline_layout_0, %zero_19, [(%zero_20, %zero_21, %ref, %zero, %3), (%c1_22, %zero_21, %ref_13, %zero, %3)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    %slte = vm.cmp.lte.i64.s %1, %zero : i64
    %13 = vm.sub.i64 %zero, %1 : i64
    %14 = vm.sub.i64 %1, %c1_4 : i64
    %15 = vm.select.i64 %slte, %13, %14 : i64
    %16 = vm.div.i64.s %15, %c128 : i64
    %17 = vm.sub.i64 %zero, %16 : i64
    %18 = vm.add.i64 %16, %c1_4 : i64
    %19 = vm.select.i64 %slte, %17, %18 : i64
    %slte_23 = vm.cmp.lte.i64.s %0, %zero : i64
    %20 = vm.sub.i64 %zero, %0 : i64
    %21 = vm.sub.i64 %0, %c1_4 : i64
    %22 = vm.select.i64 %slte_23, %20, %21 : i64
    %23 = vm.div.i64.s %22, %c32 : i64
    %24 = vm.sub.i64 %zero, %23 : i64
    %25 = vm.add.i64 %23, %c1_4 : i64
    %26 = vm.select.i64 %slte_23, %24, %25 : i64
    %27 = vm.mul.i64 %19, %26 : i64
    %zero_24 = vm.const.i32.zero
    %28 = vm.trunc.i64.i32 %27 : i64 -> i32
    %c1_25 = vm.const.i32 1
    %c1_26 = vm.const.i32 1
    vm.call @hal.command_buffer.dispatch(%ref_17, %_executable_main_dispatch_0, %zero_24, %28, %c1_25, %c1_26) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
    vm.br ^bb2
  ^bb2:  // 2 preds: ^bb0, ^bb1
    %c28 = vm.const.i32 28
    %c13 = vm.const.i32 13
    %zero_27 = vm.const.i32.zero
    vm.call @hal.command_buffer.execution_barrier(%ref_17, %c28, %c13, %zero_27) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
    vm.call @hal.command_buffer.finalize(%ref_17) : (!vm.ref<!hal.command_buffer>) -> ()
    %zero_28 = vm.const.i32.zero
    %ref_29 = vm.call @hal.fence.create(%ref_7, %zero_28) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    %29 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_10]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    vm.call.variadic @hal.device.queue.execute(%ref_7, %c-1, %null, %ref_29, [%ref_17]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
    %30 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_29]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    vm.cond_fail %30, "failed to wait on timepoint"
    %ref_30 = vm.call.variadic @hal.buffer_view.create(%ref_13, %zero, %3, %c553648160, %c1, [%0, %1]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
    vm.return %ref_30 : !vm.ref<!hal.buffer_view>
  }
  vm.export @main attributes {iree.abi.stub}
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda], vm.toplevel} {
  vm.module public @LinearModule {
    vm.global.i32 private @_device_query_0 : i32
    vm.global.ref private @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.global.ref private @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
    vm.rodata private @main_dispatch_0_cuda_nvptx_fb {alignment = 16 : i64, mime_type = "application/x-flatbuffers"} dense<"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vector<6926xi8>
    vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
    vm.rodata private @_utf8_cuda_nvptx_fb_B15B42B96FDBACC {alignment = 1 : i64} "cuda-nvptx-fb"
    vm.initializer {
      %null = vm.const.ref.zero : !vm.ref<!hal.executable>
      %null_0 = vm.const.ref.zero : !vm.buffer
      %c4 = vm.const.i32 4
      %c7 = vm.const.i32 7
      %zero = vm.const.i32.zero
      %c1 = vm.const.i32 1
      %zero_1 = vm.const.i64.zero
      %c-1 = vm.const.i64 -1
      %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
      %_utf8_cuda_nvptx_fb_B15B42B96FDBACC = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
      %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
      %2 = vm.and.i32 %1, %c1 : i32
      %3 = vm.select.i32 %0#0, %2, %zero : i32
      %ref_2 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero, [(%zero, %c7, %c1), (%c1, %c7, %zero)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
      %ref_3 = vm.call.variadic @hal.pipeline_layout.create(%ref, %c4, [%ref_2]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
      %4 = vm.select.i64 %3, %zero_1, %c-1 : i64
      %5 = vm.trunc.i64.i32 %4 : i64 -> i32
      vm.global.store.i32 %3, @_device_query_0 : i32
      vm.global.store.ref %ref_3, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      vm.br_table %5 {
        default: ^bb2,
        0: ^bb1
      }
    ^bb1:  // pred: ^bb0
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %main_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @main_dispatch_0_cuda_nvptx_fb : !vm.buffer
      %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_4 = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
      %ref_5 = vm.call.variadic @hal.executable.create(%ref, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_4, %main_dispatch_0_cuda_nvptx_fb, %null_0, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
      vm.br ^bb3(%ref_5 : !vm.ref<!hal.executable>)
    ^bb2:  // pred: ^bb0
      vm.br ^bb3(%null : !vm.ref<!hal.executable>)
    ^bb3(%6: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
      vm.global.store.ref %6, @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
      vm.return
    }
    vm.import private @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects}
    vm.import private @hal.ex.file.from_memory(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %access : i32, %buffer : !vm.buffer, %offset : i64, %length : i64, %flags : i32) -> !vm.ref<!hal.file>
    vm.import private @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
    vm.import private @hal.allocator.import(%allocator : !vm.ref<!hal.allocator>, %try : i32, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %source : !vm.buffer, %offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
    vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
    vm.import private @hal.buffer.subspan(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.buffer.length(%buffer : !vm.ref<!hal.buffer>) -> i64 attributes {nosideeffects}
    vm.import private @hal.buffer.load(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i32) -> i32
    vm.import private @hal.buffer.store(%value : i32, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i32)
    vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
    vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
    vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.buffer_view.element_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
    vm.import private @hal.buffer_view.encoding_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
    vm.import private @hal.buffer_view.rank(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
    vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
    vm.import private @hal.buffer_view.trace(%key : !vm.buffer, %operands : !vm.ref<!hal.buffer_view> ...)
    vm.import private @hal.channel.create(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %flags : i32, %id : !vm.buffer, %group : !vm.buffer, %rank : i32, %count : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects}
    vm.import private @hal.channel.split(%channel : !vm.ref<!hal.channel>, %color : i32, %key : i32, %flags : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects}
    vm.import private @hal.channel.rank_and_count(%channel : !vm.ref<!hal.channel>) -> (i32, i32) attributes {nosideeffects}
    vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer>
    vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.begin_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>, %label : !vm.buffer)
    vm.import private @hal.command_buffer.end_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
    vm.import private @hal.command_buffer.fill_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %pattern : i32, %pattern_length : i32)
    vm.import private @hal.command_buffer.copy_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64)
    vm.import private @hal.command_buffer.collective(%command_buffer : !vm.ref<!hal.command_buffer>, %channel : !vm.ref<!hal.channel>, %op : i32, %param : i32, %send_buffer : !vm.ref<!hal.buffer>, %send_offset : i64, %send_length : i64, %recv_buffer : !vm.ref<!hal.buffer>, %recv_offset : i64, %recv_length : i64, %element_count : i64)
    vm.import private @hal.command_buffer.push_constants(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %offset : i32, %values : i32 ...)
    vm.import private @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32)
    vm.import private @hal.command_buffer.dispatch.indirect(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroups_buffer : !vm.ref<!hal.buffer>, %workgroups_offset : i64)
    vm.import private @hal.command_buffer.execute.commands(%command_buffer : !vm.ref<!hal.command_buffer>, %commands : !vm.ref<!hal.command_buffer>, %bindings : tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects}
    vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
    vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
    vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
    vm.import private @hal.device.queue.dealloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %buffer : !vm.ref<!hal.buffer>)
    vm.import private @hal.device.queue.read(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_file : !vm.ref<!hal.file>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i32)
    vm.import private @hal.device.queue.write(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_file : !vm.ref<!hal.file>, %target_offset : i64, %length : i64, %flags : i32)
    vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
    vm.import private @hal.device.queue.flush(%device : !vm.ref<!hal.device>, %queue_affinity : i64)
    vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects}
    vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
    vm.import private @hal.fence.join(%fences : !vm.ref<!hal.fence> ...) -> !vm.ref<!hal.fence> attributes {nosideeffects}
    vm.import private @hal.fence.query(%fence : !vm.ref<!hal.fence>) -> i32
    vm.import private @hal.fence.signal(%fence : !vm.ref<!hal.fence>)
    vm.import private @hal.fence.fail(%fence : !vm.ref<!hal.fence>, %status : i32)
    vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
    vm.import private @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects}
    vm.rodata private @_utf8_input_0_5FD512E67BEFDEEC {alignment = 1 : i64} "input 0"
    vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
    vm.func private @main(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
      %c13 = vm.const.i32 13
      %c28 = vm.const.i32 28
      %c3 = vm.const.i32 3
      %c17 = vm.const.i32 17
      %c32 = vm.const.i32 32
      %c48 = vm.const.i32 48
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %c3075 = vm.const.i32 3075
      %c16 = vm.const.i32 16
      %zero = vm.const.i32.zero
      %c32_0 = vm.const.i64 32
      %c128 = vm.const.i64 128
      %c553648160 = vm.const.i32 553648160
      %c1 = vm.const.i32 1
      %zero_1 = vm.const.i64.zero
      %c4 = vm.const.i64 4
      %c-1 = vm.const.i64 -1
      %c-1_2 = vm.const.i32 -1
      %c1_3 = vm.const.i64 1
      %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %_executable_main_dispatch_0 = vm.global.load.ref @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
      %0 = vm.call @hal.buffer_view.dim(%arg0, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %1 = vm.call @hal.buffer_view.dim(%arg0, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1, [%0, %1]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %2 = vm.mul.i64 %0, %c4 : i64
      %3 = vm.mul.i64 %2, %1 : i64
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %ref_6 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      %ref_7 = vm.call @hal.device.queue.alloca(%ref_4, %c-1, %null, %ref_6, %zero, %c48, %c3075, %3) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
      %4 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      %5 = vm.trunc.i64.i32 %0 : i64 -> i32
      %6 = vm.shr.i64.u %0, %c32 : i64
      %7 = vm.trunc.i64.i32 %6 : i64 -> i32
      %8 = vm.trunc.i64.i32 %1 : i64 -> i32
      %9 = vm.shr.i64.u %1, %c32 : i64
      %10 = vm.trunc.i64.i32 %9 : i64 -> i32
      %ref_8 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
      %11 = vm.select.i64 %_device_query_0, %zero_1, %c-1 : i64
      %12 = vm.trunc.i64.i32 %11 : i64 -> i32
      vm.br_table %12 {
        default: ^bb2,
        0: ^bb1
      }
    ^bb1:  // pred: ^bb0
      vm.call.variadic @hal.command_buffer.push_constants(%ref_8, %_pipeline_layout_0, %zero, [%5, %7, %8, %10]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, i32 ...)
      vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_8, %_pipeline_layout_0, %zero, [(%zero, %zero, %ref, %zero_1, %3), (%c1, %zero, %ref_7, %zero_1, %3)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      %slt = vm.cmp.lt.i64.s %zero_1, %1 : i64
      %13 = vm.xor.i32 %slt, %c1 : i32
      %14 = vm.sub.i64 %zero_1, %1 : i64
      %15 = vm.sub.i64 %1, %c1_3 : i64
      %16 = vm.select.i64 %13, %14, %15 : i64
      %17 = vm.div.i64.s %16, %c128 : i64
      %18 = vm.sub.i64 %zero_1, %17 : i64
      %19 = vm.add.i64 %17, %c1_3 : i64
      %20 = vm.select.i64 %13, %18, %19 : i64
      %slt_9 = vm.cmp.lt.i64.s %zero_1, %0 : i64
      %21 = vm.xor.i32 %slt_9, %c1 : i32
      %22 = vm.sub.i64 %zero_1, %0 : i64
      %23 = vm.sub.i64 %0, %c1_3 : i64
      %24 = vm.select.i64 %21, %22, %23 : i64
      %25 = vm.div.i64.s %24, %c32_0 : i64
      %26 = vm.sub.i64 %zero_1, %25 : i64
      %27 = vm.add.i64 %25, %c1_3 : i64
      %28 = vm.select.i64 %21, %26, %27 : i64
      %29 = vm.mul.i64 %20, %28 : i64
      %30 = vm.trunc.i64.i32 %29 : i64 -> i32
      vm.call @hal.command_buffer.dispatch(%ref_8, %_executable_main_dispatch_0, %zero, %30, %c1, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
      vm.br ^bb2
    ^bb2:  // 2 preds: ^bb0, ^bb1
      vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
      %ref_10 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      %31 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1, %null, %ref_10, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
      %32 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_10]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_br %32, ^bb4(%32 : i32), ^bb3
    ^bb3:  // pred: ^bb2
      %ref_11 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_1, %3, %c553648160, %c1, [%0, %1]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_11 : !vm.ref<!hal.buffer_view>
    ^bb4(%33: i32):  // pred: ^bb2
      vm.fail %33, "failed to wait on timepoint"
    }
    vm.export @main attributes {iree.abi.stub}
  }
}


// -----// IR Dump After CSE (cse) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda], vm.toplevel} {
  vm.module public @LinearModule {
    vm.global.i32 private @_device_query_0 : i32
    vm.global.ref private @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.global.ref private @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
    vm.rodata private @main_dispatch_0_cuda_nvptx_fb {alignment = 16 : i64, mime_type = "application/x-flatbuffers"} dense<"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vector<6926xi8>
    vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
    vm.rodata private @_utf8_cuda_nvptx_fb_B15B42B96FDBACC {alignment = 1 : i64} "cuda-nvptx-fb"
    vm.initializer {
      %null = vm.const.ref.zero : !vm.ref<!hal.executable>
      %null_0 = vm.const.ref.zero : !vm.buffer
      %c4 = vm.const.i32 4
      %c7 = vm.const.i32 7
      %zero = vm.const.i32.zero
      %c1 = vm.const.i32 1
      %zero_1 = vm.const.i64.zero
      %c-1 = vm.const.i64 -1
      %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
      %_utf8_cuda_nvptx_fb_B15B42B96FDBACC = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
      %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
      %2 = vm.and.i32 %1, %c1 : i32
      %3 = vm.select.i32 %0#0, %2, %zero : i32
      %ref_2 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero, [(%zero, %c7, %c1), (%c1, %c7, %zero)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
      %ref_3 = vm.call.variadic @hal.pipeline_layout.create(%ref, %c4, [%ref_2]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
      %4 = vm.select.i64 %3, %zero_1, %c-1 : i64
      %5 = vm.trunc.i64.i32 %4 : i64 -> i32
      vm.global.store.i32 %3, @_device_query_0 : i32
      vm.global.store.ref %ref_3, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      vm.br_table %5 {
        default: ^bb2,
        0: ^bb1
      }
    ^bb1:  // pred: ^bb0
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %main_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @main_dispatch_0_cuda_nvptx_fb : !vm.buffer
      %ref_4 = vm.call.variadic @hal.executable.create(%ref, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC, %main_dispatch_0_cuda_nvptx_fb, %null_0, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
      vm.br ^bb3(%ref_4 : !vm.ref<!hal.executable>)
    ^bb2:  // pred: ^bb0
      vm.br ^bb3(%null : !vm.ref<!hal.executable>)
    ^bb3(%6: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
      vm.global.store.ref %6, @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
      vm.return
    }
    vm.import private @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects}
    vm.import private @hal.ex.file.from_memory(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %access : i32, %buffer : !vm.buffer, %offset : i64, %length : i64, %flags : i32) -> !vm.ref<!hal.file>
    vm.import private @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
    vm.import private @hal.allocator.import(%allocator : !vm.ref<!hal.allocator>, %try : i32, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %source : !vm.buffer, %offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
    vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
    vm.import private @hal.buffer.subspan(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.buffer.length(%buffer : !vm.ref<!hal.buffer>) -> i64 attributes {nosideeffects}
    vm.import private @hal.buffer.load(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i32) -> i32
    vm.import private @hal.buffer.store(%value : i32, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i32)
    vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
    vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
    vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.buffer_view.element_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
    vm.import private @hal.buffer_view.encoding_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
    vm.import private @hal.buffer_view.rank(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
    vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
    vm.import private @hal.buffer_view.trace(%key : !vm.buffer, %operands : !vm.ref<!hal.buffer_view> ...)
    vm.import private @hal.channel.create(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %flags : i32, %id : !vm.buffer, %group : !vm.buffer, %rank : i32, %count : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects}
    vm.import private @hal.channel.split(%channel : !vm.ref<!hal.channel>, %color : i32, %key : i32, %flags : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects}
    vm.import private @hal.channel.rank_and_count(%channel : !vm.ref<!hal.channel>) -> (i32, i32) attributes {nosideeffects}
    vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer>
    vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.begin_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>, %label : !vm.buffer)
    vm.import private @hal.command_buffer.end_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
    vm.import private @hal.command_buffer.fill_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %pattern : i32, %pattern_length : i32)
    vm.import private @hal.command_buffer.copy_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64)
    vm.import private @hal.command_buffer.collective(%command_buffer : !vm.ref<!hal.command_buffer>, %channel : !vm.ref<!hal.channel>, %op : i32, %param : i32, %send_buffer : !vm.ref<!hal.buffer>, %send_offset : i64, %send_length : i64, %recv_buffer : !vm.ref<!hal.buffer>, %recv_offset : i64, %recv_length : i64, %element_count : i64)
    vm.import private @hal.command_buffer.push_constants(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %offset : i32, %values : i32 ...)
    vm.import private @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32)
    vm.import private @hal.command_buffer.dispatch.indirect(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroups_buffer : !vm.ref<!hal.buffer>, %workgroups_offset : i64)
    vm.import private @hal.command_buffer.execute.commands(%command_buffer : !vm.ref<!hal.command_buffer>, %commands : !vm.ref<!hal.command_buffer>, %bindings : tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects}
    vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
    vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
    vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
    vm.import private @hal.device.queue.dealloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %buffer : !vm.ref<!hal.buffer>)
    vm.import private @hal.device.queue.read(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_file : !vm.ref<!hal.file>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i32)
    vm.import private @hal.device.queue.write(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_file : !vm.ref<!hal.file>, %target_offset : i64, %length : i64, %flags : i32)
    vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
    vm.import private @hal.device.queue.flush(%device : !vm.ref<!hal.device>, %queue_affinity : i64)
    vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects}
    vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
    vm.import private @hal.fence.join(%fences : !vm.ref<!hal.fence> ...) -> !vm.ref<!hal.fence> attributes {nosideeffects}
    vm.import private @hal.fence.query(%fence : !vm.ref<!hal.fence>) -> i32
    vm.import private @hal.fence.signal(%fence : !vm.ref<!hal.fence>)
    vm.import private @hal.fence.fail(%fence : !vm.ref<!hal.fence>, %status : i32)
    vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
    vm.import private @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects}
    vm.rodata private @_utf8_input_0_5FD512E67BEFDEEC {alignment = 1 : i64} "input 0"
    vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
    vm.func private @main(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
      %c13 = vm.const.i32 13
      %c28 = vm.const.i32 28
      %c3 = vm.const.i32 3
      %c17 = vm.const.i32 17
      %c32 = vm.const.i32 32
      %c48 = vm.const.i32 48
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %c3075 = vm.const.i32 3075
      %c16 = vm.const.i32 16
      %zero = vm.const.i32.zero
      %c32_0 = vm.const.i64 32
      %c128 = vm.const.i64 128
      %c553648160 = vm.const.i32 553648160
      %c1 = vm.const.i32 1
      %zero_1 = vm.const.i64.zero
      %c4 = vm.const.i64 4
      %c-1 = vm.const.i64 -1
      %c-1_2 = vm.const.i32 -1
      %c1_3 = vm.const.i64 1
      %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %_executable_main_dispatch_0 = vm.global.load.ref @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
      %0 = vm.call @hal.buffer_view.dim(%arg0, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %1 = vm.call @hal.buffer_view.dim(%arg0, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1, [%0, %1]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %2 = vm.mul.i64 %0, %c4 : i64
      %3 = vm.mul.i64 %2, %1 : i64
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %ref_6 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      %ref_7 = vm.call @hal.device.queue.alloca(%ref_4, %c-1, %null, %ref_6, %zero, %c48, %c3075, %3) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
      %4 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      %5 = vm.trunc.i64.i32 %0 : i64 -> i32
      %6 = vm.shr.i64.u %0, %c32 : i64
      %7 = vm.trunc.i64.i32 %6 : i64 -> i32
      %8 = vm.trunc.i64.i32 %1 : i64 -> i32
      %9 = vm.shr.i64.u %1, %c32 : i64
      %10 = vm.trunc.i64.i32 %9 : i64 -> i32
      %ref_8 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
      %11 = vm.select.i64 %_device_query_0, %zero_1, %c-1 : i64
      %12 = vm.trunc.i64.i32 %11 : i64 -> i32
      vm.br_table %12 {
        default: ^bb2,
        0: ^bb1
      }
    ^bb1:  // pred: ^bb0
      vm.call.variadic @hal.command_buffer.push_constants(%ref_8, %_pipeline_layout_0, %zero, [%5, %7, %8, %10]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, i32 ...)
      vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_8, %_pipeline_layout_0, %zero, [(%zero, %zero, %ref, %zero_1, %3), (%c1, %zero, %ref_7, %zero_1, %3)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      %slt = vm.cmp.lt.i64.s %zero_1, %1 : i64
      %13 = vm.xor.i32 %slt, %c1 : i32
      %14 = vm.sub.i64 %zero_1, %1 : i64
      %15 = vm.sub.i64 %1, %c1_3 : i64
      %16 = vm.select.i64 %13, %14, %15 : i64
      %17 = vm.div.i64.s %16, %c128 : i64
      %18 = vm.sub.i64 %zero_1, %17 : i64
      %19 = vm.add.i64 %17, %c1_3 : i64
      %20 = vm.select.i64 %13, %18, %19 : i64
      %slt_9 = vm.cmp.lt.i64.s %zero_1, %0 : i64
      %21 = vm.xor.i32 %slt_9, %c1 : i32
      %22 = vm.sub.i64 %zero_1, %0 : i64
      %23 = vm.sub.i64 %0, %c1_3 : i64
      %24 = vm.select.i64 %21, %22, %23 : i64
      %25 = vm.div.i64.s %24, %c32_0 : i64
      %26 = vm.sub.i64 %zero_1, %25 : i64
      %27 = vm.add.i64 %25, %c1_3 : i64
      %28 = vm.select.i64 %21, %26, %27 : i64
      %29 = vm.mul.i64 %20, %28 : i64
      %30 = vm.trunc.i64.i32 %29 : i64 -> i32
      vm.call @hal.command_buffer.dispatch(%ref_8, %_executable_main_dispatch_0, %zero, %30, %c1, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
      vm.br ^bb2
    ^bb2:  // 2 preds: ^bb0, ^bb1
      vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
      %ref_10 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      %31 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1, %null, %ref_10, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
      %32 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_10]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_br %32, ^bb4(%32 : i32), ^bb3
    ^bb3:  // pred: ^bb2
      %ref_11 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_1, %3, %c553648160, %c1, [%0, %1]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_11 : !vm.ref<!hal.buffer_view>
    ^bb4(%33: i32):  // pred: ^bb2
      vm.fail %33, "failed to wait on timepoint"
    }
    vm.export @main attributes {iree.abi.stub}
  }
}


// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda], vm.toplevel} {
  vm.module public @LinearModule {
    vm.global.i32 private @_device_query_0 : i32
    vm.global.ref private @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.global.ref private @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
    vm.rodata private @main_dispatch_0_cuda_nvptx_fb {alignment = 16 : i64, mime_type = "application/x-flatbuffers"} dense<"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vector<6926xi8>
    vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
    vm.rodata private @_utf8_cuda_nvptx_fb_B15B42B96FDBACC {alignment = 1 : i64} "cuda-nvptx-fb"
    vm.initializer {
      %null = vm.const.ref.zero : !vm.ref<!hal.executable>
      %null_0 = vm.const.ref.zero : !vm.buffer
      %c4 = vm.const.i32 4
      %c7 = vm.const.i32 7
      %zero = vm.const.i32.zero
      %c1 = vm.const.i32 1
      %zero_1 = vm.const.i64.zero
      %c-1 = vm.const.i64 -1
      %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
      %_utf8_cuda_nvptx_fb_B15B42B96FDBACC = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
      %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
      %2 = vm.and.i32 %1, %c1 : i32
      %3 = vm.select.i32 %0#0, %2, %zero : i32
      %ref_2 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero, [(%zero, %c7, %c1), (%c1, %c7, %zero)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
      %ref_3 = vm.call.variadic @hal.pipeline_layout.create(%ref, %c4, [%ref_2]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
      %4 = vm.select.i64 %3, %zero_1, %c-1 : i64
      %5 = vm.trunc.i64.i32 %4 : i64 -> i32
      vm.global.store.i32 %3, @_device_query_0 : i32
      vm.global.store.ref %ref_3, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      vm.br_table %5 {
        default: ^bb2,
        0: ^bb1
      }
    ^bb1:  // pred: ^bb0
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %main_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @main_dispatch_0_cuda_nvptx_fb : !vm.buffer
      %ref_4 = vm.call.variadic @hal.executable.create(%ref, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC, %main_dispatch_0_cuda_nvptx_fb, %null_0, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
      vm.br ^bb3(%ref_4 : !vm.ref<!hal.executable>)
    ^bb2:  // pred: ^bb0
      vm.br ^bb3(%null : !vm.ref<!hal.executable>)
    ^bb3(%6: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
      vm.global.store.ref %6, @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
      vm.return
    }
    vm.import private @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects}
    vm.import private @hal.ex.file.from_memory(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %access : i32, %buffer : !vm.buffer, %offset : i64, %length : i64, %flags : i32) -> !vm.ref<!hal.file>
    vm.import private @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
    vm.import private @hal.allocator.import(%allocator : !vm.ref<!hal.allocator>, %try : i32, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %source : !vm.buffer, %offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
    vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
    vm.import private @hal.buffer.subspan(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.buffer.length(%buffer : !vm.ref<!hal.buffer>) -> i64 attributes {nosideeffects}
    vm.import private @hal.buffer.load(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i32) -> i32
    vm.import private @hal.buffer.store(%value : i32, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i32)
    vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
    vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
    vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.buffer_view.element_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
    vm.import private @hal.buffer_view.encoding_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
    vm.import private @hal.buffer_view.rank(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
    vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
    vm.import private @hal.buffer_view.trace(%key : !vm.buffer, %operands : !vm.ref<!hal.buffer_view> ...)
    vm.import private @hal.channel.create(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %flags : i32, %id : !vm.buffer, %group : !vm.buffer, %rank : i32, %count : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects}
    vm.import private @hal.channel.split(%channel : !vm.ref<!hal.channel>, %color : i32, %key : i32, %flags : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects}
    vm.import private @hal.channel.rank_and_count(%channel : !vm.ref<!hal.channel>) -> (i32, i32) attributes {nosideeffects}
    vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer>
    vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.begin_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>, %label : !vm.buffer)
    vm.import private @hal.command_buffer.end_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
    vm.import private @hal.command_buffer.fill_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %pattern : i32, %pattern_length : i32)
    vm.import private @hal.command_buffer.copy_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64)
    vm.import private @hal.command_buffer.collective(%command_buffer : !vm.ref<!hal.command_buffer>, %channel : !vm.ref<!hal.channel>, %op : i32, %param : i32, %send_buffer : !vm.ref<!hal.buffer>, %send_offset : i64, %send_length : i64, %recv_buffer : !vm.ref<!hal.buffer>, %recv_offset : i64, %recv_length : i64, %element_count : i64)
    vm.import private @hal.command_buffer.push_constants(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %offset : i32, %values : i32 ...)
    vm.import private @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32)
    vm.import private @hal.command_buffer.dispatch.indirect(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroups_buffer : !vm.ref<!hal.buffer>, %workgroups_offset : i64)
    vm.import private @hal.command_buffer.execute.commands(%command_buffer : !vm.ref<!hal.command_buffer>, %commands : !vm.ref<!hal.command_buffer>, %bindings : tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects}
    vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
    vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
    vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
    vm.import private @hal.device.queue.dealloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %buffer : !vm.ref<!hal.buffer>)
    vm.import private @hal.device.queue.read(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_file : !vm.ref<!hal.file>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i32)
    vm.import private @hal.device.queue.write(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_file : !vm.ref<!hal.file>, %target_offset : i64, %length : i64, %flags : i32)
    vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
    vm.import private @hal.device.queue.flush(%device : !vm.ref<!hal.device>, %queue_affinity : i64)
    vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects}
    vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
    vm.import private @hal.fence.join(%fences : !vm.ref<!hal.fence> ...) -> !vm.ref<!hal.fence> attributes {nosideeffects}
    vm.import private @hal.fence.query(%fence : !vm.ref<!hal.fence>) -> i32
    vm.import private @hal.fence.signal(%fence : !vm.ref<!hal.fence>)
    vm.import private @hal.fence.fail(%fence : !vm.ref<!hal.fence>, %status : i32)
    vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
    vm.import private @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects}
    vm.rodata private @_utf8_input_0_5FD512E67BEFDEEC {alignment = 1 : i64} "input 0"
    vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
    vm.func private @main(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
      %c13 = vm.const.i32 13
      %c28 = vm.const.i32 28
      %c3 = vm.const.i32 3
      %c17 = vm.const.i32 17
      %c32 = vm.const.i32 32
      %c48 = vm.const.i32 48
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %c3075 = vm.const.i32 3075
      %c16 = vm.const.i32 16
      %zero = vm.const.i32.zero
      %c32_0 = vm.const.i64 32
      %c128 = vm.const.i64 128
      %c553648160 = vm.const.i32 553648160
      %c1 = vm.const.i32 1
      %zero_1 = vm.const.i64.zero
      %c4 = vm.const.i64 4
      %c-1 = vm.const.i64 -1
      %c-1_2 = vm.const.i32 -1
      %c1_3 = vm.const.i64 1
      %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %_executable_main_dispatch_0 = vm.global.load.ref @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
      %0 = vm.call @hal.buffer_view.dim(%arg0, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %1 = vm.call @hal.buffer_view.dim(%arg0, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1, [%0, %1]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %2 = vm.mul.i64 %0, %c4 : i64
      %3 = vm.mul.i64 %2, %1 : i64
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %ref_6 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      %ref_7 = vm.call @hal.device.queue.alloca(%ref_4, %c-1, %null, %ref_6, %zero, %c48, %c3075, %3) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
      %4 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      %5 = vm.trunc.i64.i32 %0 : i64 -> i32
      %6 = vm.shr.i64.u %0, %c32 : i64
      %7 = vm.trunc.i64.i32 %6 : i64 -> i32
      %8 = vm.trunc.i64.i32 %1 : i64 -> i32
      %9 = vm.shr.i64.u %1, %c32 : i64
      %10 = vm.trunc.i64.i32 %9 : i64 -> i32
      %ref_8 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
      %11 = vm.select.i64 %_device_query_0, %zero_1, %c-1 : i64
      %12 = vm.trunc.i64.i32 %11 : i64 -> i32
      vm.br_table %12 {
        default: ^bb2,
        0: ^bb1
      }
    ^bb1:  // pred: ^bb0
      vm.call.variadic @hal.command_buffer.push_constants(%ref_8, %_pipeline_layout_0, %zero, [%5, %7, %8, %10]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, i32 ...)
      vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_8, %_pipeline_layout_0, %zero, [(%zero, %zero, %ref, %zero_1, %3), (%c1, %zero, %ref_7, %zero_1, %3)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      %slt = vm.cmp.lt.i64.s %zero_1, %1 : i64
      %13 = vm.xor.i32 %slt, %c1 : i32
      %14 = vm.sub.i64 %zero_1, %1 : i64
      %15 = vm.sub.i64 %1, %c1_3 : i64
      %16 = vm.select.i64 %13, %14, %15 : i64
      %17 = vm.div.i64.s %16, %c128 : i64
      %18 = vm.sub.i64 %zero_1, %17 : i64
      %19 = vm.add.i64 %17, %c1_3 : i64
      %20 = vm.select.i64 %13, %18, %19 : i64
      %slt_9 = vm.cmp.lt.i64.s %zero_1, %0 : i64
      %21 = vm.xor.i32 %slt_9, %c1 : i32
      %22 = vm.sub.i64 %zero_1, %0 : i64
      %23 = vm.sub.i64 %0, %c1_3 : i64
      %24 = vm.select.i64 %21, %22, %23 : i64
      %25 = vm.div.i64.s %24, %c32_0 : i64
      %26 = vm.sub.i64 %zero_1, %25 : i64
      %27 = vm.add.i64 %25, %c1_3 : i64
      %28 = vm.select.i64 %21, %26, %27 : i64
      %29 = vm.mul.i64 %20, %28 : i64
      %30 = vm.trunc.i64.i32 %29 : i64 -> i32
      vm.call @hal.command_buffer.dispatch(%ref_8, %_executable_main_dispatch_0, %zero, %30, %c1, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
      vm.br ^bb2
    ^bb2:  // 2 preds: ^bb0, ^bb1
      vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
      %ref_10 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      %31 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1, %null, %ref_10, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
      %32 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_10]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_br %32, ^bb4, ^bb3
    ^bb3:  // pred: ^bb2
      %ref_11 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_1, %3, %c553648160, %c1, [%0, %1]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_11 : !vm.ref<!hal.buffer_view>
    ^bb4:  // pred: ^bb2
      vm.fail %32, "failed to wait on timepoint"
    }
    vm.export @main attributes {iree.abi.stub}
  }
}


// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda], vm.toplevel} {
  vm.module public @LinearModule {
    vm.global.i32 private @_device_query_0 : i32
    vm.global.ref private @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.global.ref private @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
    vm.rodata private @main_dispatch_0_cuda_nvptx_fb {alignment = 16 : i64, mime_type = "application/x-flatbuffers"} dense<"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vector<6926xi8>
    vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
    vm.rodata private @_utf8_cuda_nvptx_fb_B15B42B96FDBACC {alignment = 1 : i64} "cuda-nvptx-fb"
    vm.initializer {
      %null = vm.const.ref.zero : !vm.ref<!hal.executable>
      %null_0 = vm.const.ref.zero : !vm.buffer
      %c4 = vm.const.i32 4
      %c7 = vm.const.i32 7
      %zero = vm.const.i32.zero
      %c1 = vm.const.i32 1
      %zero_1 = vm.const.i64.zero
      %c-1 = vm.const.i64 -1
      %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
      %_utf8_cuda_nvptx_fb_B15B42B96FDBACC = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
      %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
      %2 = vm.and.i32 %1, %c1 : i32
      %3 = vm.select.i32 %0#0, %2, %zero : i32
      %ref_2 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero, [(%zero, %c7, %c1), (%c1, %c7, %zero)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
      %ref_3 = vm.call.variadic @hal.pipeline_layout.create(%ref, %c4, [%ref_2]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
      %4 = vm.select.i64 %3, %zero_1, %c-1 : i64
      %5 = vm.trunc.i64.i32 %4 : i64 -> i32
      vm.global.store.i32 %3, @_device_query_0 : i32
      vm.global.store.ref %ref_3, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      vm.br_table %5 {
        default: ^bb2,
        0: ^bb1
      }
    ^bb1:  // pred: ^bb0
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %main_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @main_dispatch_0_cuda_nvptx_fb : !vm.buffer
      %ref_4 = vm.call.variadic @hal.executable.create(%ref, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC, %main_dispatch_0_cuda_nvptx_fb, %null_0, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
      vm.br ^bb3(%ref_4 : !vm.ref<!hal.executable>)
    ^bb2:  // pred: ^bb0
      vm.br ^bb3(%null : !vm.ref<!hal.executable>)
    ^bb3(%6: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
      vm.global.store.ref %6, @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
      vm.return
    }
    vm.import private @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects}
    vm.import private @hal.ex.file.from_memory(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %access : i32, %buffer : !vm.buffer, %offset : i64, %length : i64, %flags : i32) -> !vm.ref<!hal.file>
    vm.import private @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
    vm.import private @hal.allocator.import(%allocator : !vm.ref<!hal.allocator>, %try : i32, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %source : !vm.buffer, %offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
    vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
    vm.import private @hal.buffer.subspan(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.buffer.length(%buffer : !vm.ref<!hal.buffer>) -> i64 attributes {nosideeffects}
    vm.import private @hal.buffer.load(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i32) -> i32
    vm.import private @hal.buffer.store(%value : i32, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i32)
    vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
    vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
    vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.buffer_view.element_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
    vm.import private @hal.buffer_view.encoding_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
    vm.import private @hal.buffer_view.rank(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
    vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
    vm.import private @hal.buffer_view.trace(%key : !vm.buffer, %operands : !vm.ref<!hal.buffer_view> ...)
    vm.import private @hal.channel.create(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %flags : i32, %id : !vm.buffer, %group : !vm.buffer, %rank : i32, %count : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects}
    vm.import private @hal.channel.split(%channel : !vm.ref<!hal.channel>, %color : i32, %key : i32, %flags : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects}
    vm.import private @hal.channel.rank_and_count(%channel : !vm.ref<!hal.channel>) -> (i32, i32) attributes {nosideeffects}
    vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer>
    vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.begin_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>, %label : !vm.buffer)
    vm.import private @hal.command_buffer.end_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
    vm.import private @hal.command_buffer.fill_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %pattern : i32, %pattern_length : i32)
    vm.import private @hal.command_buffer.copy_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64)
    vm.import private @hal.command_buffer.collective(%command_buffer : !vm.ref<!hal.command_buffer>, %channel : !vm.ref<!hal.channel>, %op : i32, %param : i32, %send_buffer : !vm.ref<!hal.buffer>, %send_offset : i64, %send_length : i64, %recv_buffer : !vm.ref<!hal.buffer>, %recv_offset : i64, %recv_length : i64, %element_count : i64)
    vm.import private @hal.command_buffer.push_constants(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %offset : i32, %values : i32 ...)
    vm.import private @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32)
    vm.import private @hal.command_buffer.dispatch.indirect(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroups_buffer : !vm.ref<!hal.buffer>, %workgroups_offset : i64)
    vm.import private @hal.command_buffer.execute.commands(%command_buffer : !vm.ref<!hal.command_buffer>, %commands : !vm.ref<!hal.command_buffer>, %bindings : tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects}
    vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
    vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
    vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
    vm.import private @hal.device.queue.dealloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %buffer : !vm.ref<!hal.buffer>)
    vm.import private @hal.device.queue.read(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_file : !vm.ref<!hal.file>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i32)
    vm.import private @hal.device.queue.write(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_file : !vm.ref<!hal.file>, %target_offset : i64, %length : i64, %flags : i32)
    vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
    vm.import private @hal.device.queue.flush(%device : !vm.ref<!hal.device>, %queue_affinity : i64)
    vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects}
    vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
    vm.import private @hal.fence.join(%fences : !vm.ref<!hal.fence> ...) -> !vm.ref<!hal.fence> attributes {nosideeffects}
    vm.import private @hal.fence.query(%fence : !vm.ref<!hal.fence>) -> i32
    vm.import private @hal.fence.signal(%fence : !vm.ref<!hal.fence>)
    vm.import private @hal.fence.fail(%fence : !vm.ref<!hal.fence>, %status : i32)
    vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
    vm.import private @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects}
    vm.rodata private @_utf8_input_0_5FD512E67BEFDEEC {alignment = 1 : i64} "input 0"
    vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
    vm.func private @main(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
      %c13 = vm.const.i32 13
      %c28 = vm.const.i32 28
      %c3 = vm.const.i32 3
      %c17 = vm.const.i32 17
      %c32 = vm.const.i32 32
      %c48 = vm.const.i32 48
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %c3075 = vm.const.i32 3075
      %c16 = vm.const.i32 16
      %zero = vm.const.i32.zero
      %c32_0 = vm.const.i64 32
      %c128 = vm.const.i64 128
      %c553648160 = vm.const.i32 553648160
      %c1 = vm.const.i32 1
      %zero_1 = vm.const.i64.zero
      %c4 = vm.const.i64 4
      %c-1 = vm.const.i64 -1
      %c-1_2 = vm.const.i32 -1
      %c1_3 = vm.const.i64 1
      %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %_executable_main_dispatch_0 = vm.global.load.ref @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
      %0 = vm.call @hal.buffer_view.dim(%arg0, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %1 = vm.call @hal.buffer_view.dim(%arg0, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1, [%0, %1]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %2 = vm.mul.i64 %0, %c4 : i64
      %3 = vm.mul.i64 %2, %1 : i64
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %ref_6 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      %ref_7 = vm.call @hal.device.queue.alloca(%ref_4, %c-1, %null, %ref_6, %zero, %c48, %c3075, %3) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
      %4 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      %5 = vm.trunc.i64.i32 %0 : i64 -> i32
      %6 = vm.shr.i64.u %0, %c32 : i64
      %7 = vm.trunc.i64.i32 %6 : i64 -> i32
      %8 = vm.trunc.i64.i32 %1 : i64 -> i32
      %9 = vm.shr.i64.u %1, %c32 : i64
      %10 = vm.trunc.i64.i32 %9 : i64 -> i32
      %ref_8 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
      %11 = vm.select.i64 %_device_query_0, %zero_1, %c-1 : i64
      %12 = vm.trunc.i64.i32 %11 : i64 -> i32
      vm.br_table %12 {
        default: ^bb2,
        0: ^bb1
      }
    ^bb1:  // pred: ^bb0
      vm.call.variadic @hal.command_buffer.push_constants(%ref_8, %_pipeline_layout_0, %zero, [%5, %7, %8, %10]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, i32 ...)
      vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_8, %_pipeline_layout_0, %zero, [(%zero, %zero, %ref, %zero_1, %3), (%c1, %zero, %ref_7, %zero_1, %3)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      %slt = vm.cmp.lt.i64.s %zero_1, %1 : i64
      %13 = vm.xor.i32 %slt, %c1 : i32
      %14 = vm.sub.i64 %zero_1, %1 : i64
      %15 = vm.sub.i64 %1, %c1_3 : i64
      %16 = vm.select.i64 %13, %14, %15 : i64
      %17 = vm.div.i64.s %16, %c128 : i64
      %18 = vm.sub.i64 %zero_1, %17 : i64
      %19 = vm.add.i64 %17, %c1_3 : i64
      %20 = vm.select.i64 %13, %18, %19 : i64
      %slt_9 = vm.cmp.lt.i64.s %zero_1, %0 : i64
      %21 = vm.xor.i32 %slt_9, %c1 : i32
      %22 = vm.sub.i64 %zero_1, %0 : i64
      %23 = vm.sub.i64 %0, %c1_3 : i64
      %24 = vm.select.i64 %21, %22, %23 : i64
      %25 = vm.div.i64.s %24, %c32_0 : i64
      %26 = vm.sub.i64 %zero_1, %25 : i64
      %27 = vm.add.i64 %25, %c1_3 : i64
      %28 = vm.select.i64 %21, %26, %27 : i64
      %29 = vm.mul.i64 %20, %28 : i64
      %30 = vm.trunc.i64.i32 %29 : i64 -> i32
      vm.call @hal.command_buffer.dispatch(%ref_8, %_executable_main_dispatch_0, %zero, %30, %c1, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
      vm.br ^bb2
    ^bb2:  // 2 preds: ^bb0, ^bb1
      vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
      %ref_10 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      %31 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1, %null, %ref_10, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
      %32 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_10]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_br %32, ^bb4, ^bb3
    ^bb3:  // pred: ^bb2
      %ref_11 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_1, %3, %c553648160, %c1, [%0, %1]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_11 : !vm.ref<!hal.buffer_view>
    ^bb4:  // pred: ^bb2
      vm.fail %32, "failed to wait on timepoint"
    }
    vm.export @main attributes {iree.abi.stub}
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda], vm.toplevel} {
  vm.module public @LinearModule {
    vm.global.i32 private @_device_query_0 : i32
    vm.global.ref private @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.global.ref private @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
    vm.rodata private @main_dispatch_0_cuda_nvptx_fb {alignment = 16 : i64, mime_type = "application/x-flatbuffers"} dense<"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vector<6926xi8>
    vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
    vm.rodata private @_utf8_cuda_nvptx_fb_B15B42B96FDBACC {alignment = 1 : i64} "cuda-nvptx-fb"
    vm.initializer {
      %null = vm.const.ref.zero : !vm.ref<!hal.executable>
      %null_0 = vm.const.ref.zero : !vm.buffer
      %c4 = vm.const.i32 4
      %c7 = vm.const.i32 7
      %zero = vm.const.i32.zero
      %c1 = vm.const.i32 1
      %zero_1 = vm.const.i64.zero
      %c-1 = vm.const.i64 -1
      %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
      %_utf8_cuda_nvptx_fb_B15B42B96FDBACC = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
      %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
      %2 = vm.and.i32 %1, %c1 : i32
      %3 = vm.select.i32 %0#0, %2, %zero : i32
      %ref_2 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero, [(%zero, %c7, %c1), (%c1, %c7, %zero)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
      %ref_3 = vm.call.variadic @hal.pipeline_layout.create(%ref, %c4, [%ref_2]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
      %4 = vm.select.i64 %3, %zero_1, %c-1 : i64
      %5 = vm.trunc.i64.i32 %4 : i64 -> i32
      vm.global.store.i32 %3, @_device_query_0 : i32
      vm.global.store.ref %ref_3, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      vm.br_table %5 {
        default: ^bb2,
        0: ^bb1
      }
    ^bb1:  // pred: ^bb0
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %main_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @main_dispatch_0_cuda_nvptx_fb : !vm.buffer
      %ref_4 = vm.call.variadic @hal.executable.create(%ref, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC, %main_dispatch_0_cuda_nvptx_fb, %null_0, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
      vm.br ^bb3(%ref_4 : !vm.ref<!hal.executable>)
    ^bb2:  // pred: ^bb0
      vm.br ^bb3(%null : !vm.ref<!hal.executable>)
    ^bb3(%6: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
      vm.global.store.ref %6, @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
      vm.return
    }
    vm.import private @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects}
    vm.import private @hal.ex.file.from_memory(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %access : i32, %buffer : !vm.buffer, %offset : i64, %length : i64, %flags : i32) -> !vm.ref<!hal.file>
    vm.import private @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
    vm.import private @hal.allocator.import(%allocator : !vm.ref<!hal.allocator>, %try : i32, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %source : !vm.buffer, %offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
    vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
    vm.import private @hal.buffer.subspan(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.buffer.length(%buffer : !vm.ref<!hal.buffer>) -> i64 attributes {nosideeffects}
    vm.import private @hal.buffer.load(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i32) -> i32
    vm.import private @hal.buffer.store(%value : i32, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i32)
    vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
    vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
    vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.buffer_view.element_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
    vm.import private @hal.buffer_view.encoding_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
    vm.import private @hal.buffer_view.rank(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
    vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
    vm.import private @hal.buffer_view.trace(%key : !vm.buffer, %operands : !vm.ref<!hal.buffer_view> ...)
    vm.import private @hal.channel.create(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %flags : i32, %id : !vm.buffer, %group : !vm.buffer, %rank : i32, %count : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects}
    vm.import private @hal.channel.split(%channel : !vm.ref<!hal.channel>, %color : i32, %key : i32, %flags : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects}
    vm.import private @hal.channel.rank_and_count(%channel : !vm.ref<!hal.channel>) -> (i32, i32) attributes {nosideeffects}
    vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer>
    vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.begin_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>, %label : !vm.buffer)
    vm.import private @hal.command_buffer.end_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
    vm.import private @hal.command_buffer.fill_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %pattern : i32, %pattern_length : i32)
    vm.import private @hal.command_buffer.copy_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64)
    vm.import private @hal.command_buffer.collective(%command_buffer : !vm.ref<!hal.command_buffer>, %channel : !vm.ref<!hal.channel>, %op : i32, %param : i32, %send_buffer : !vm.ref<!hal.buffer>, %send_offset : i64, %send_length : i64, %recv_buffer : !vm.ref<!hal.buffer>, %recv_offset : i64, %recv_length : i64, %element_count : i64)
    vm.import private @hal.command_buffer.push_constants(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %offset : i32, %values : i32 ...)
    vm.import private @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32)
    vm.import private @hal.command_buffer.dispatch.indirect(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroups_buffer : !vm.ref<!hal.buffer>, %workgroups_offset : i64)
    vm.import private @hal.command_buffer.execute.commands(%command_buffer : !vm.ref<!hal.command_buffer>, %commands : !vm.ref<!hal.command_buffer>, %bindings : tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects}
    vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
    vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
    vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
    vm.import private @hal.device.queue.dealloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %buffer : !vm.ref<!hal.buffer>)
    vm.import private @hal.device.queue.read(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_file : !vm.ref<!hal.file>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i32)
    vm.import private @hal.device.queue.write(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_file : !vm.ref<!hal.file>, %target_offset : i64, %length : i64, %flags : i32)
    vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
    vm.import private @hal.device.queue.flush(%device : !vm.ref<!hal.device>, %queue_affinity : i64)
    vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects}
    vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
    vm.import private @hal.fence.join(%fences : !vm.ref<!hal.fence> ...) -> !vm.ref<!hal.fence> attributes {nosideeffects}
    vm.import private @hal.fence.query(%fence : !vm.ref<!hal.fence>) -> i32
    vm.import private @hal.fence.signal(%fence : !vm.ref<!hal.fence>)
    vm.import private @hal.fence.fail(%fence : !vm.ref<!hal.fence>, %status : i32)
    vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
    vm.import private @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects}
    vm.rodata private @_utf8_input_0_5FD512E67BEFDEEC {alignment = 1 : i64} "input 0"
    vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
    vm.func private @main(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
      %c13 = vm.const.i32 13
      %c28 = vm.const.i32 28
      %c3 = vm.const.i32 3
      %c17 = vm.const.i32 17
      %c32 = vm.const.i32 32
      %c48 = vm.const.i32 48
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %c3075 = vm.const.i32 3075
      %c16 = vm.const.i32 16
      %zero = vm.const.i32.zero
      %c32_0 = vm.const.i64 32
      %c128 = vm.const.i64 128
      %c553648160 = vm.const.i32 553648160
      %c1 = vm.const.i32 1
      %zero_1 = vm.const.i64.zero
      %c4 = vm.const.i64 4
      %c-1 = vm.const.i64 -1
      %c-1_2 = vm.const.i32 -1
      %c1_3 = vm.const.i64 1
      %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %_executable_main_dispatch_0 = vm.global.load.ref @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
      %0 = vm.call @hal.buffer_view.dim(%arg0, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %1 = vm.call @hal.buffer_view.dim(%arg0, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1, [%0, %1]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %2 = vm.mul.i64 %0, %c4 : i64
      %3 = vm.mul.i64 %2, %1 : i64
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %ref_6 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      %ref_7 = vm.call @hal.device.queue.alloca(%ref_4, %c-1, %null, %ref_6, %zero, %c48, %c3075, %3) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
      %4 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      %5 = vm.trunc.i64.i32 %0 : i64 -> i32
      %6 = vm.shr.i64.u %0, %c32 : i64
      %7 = vm.trunc.i64.i32 %6 : i64 -> i32
      %8 = vm.trunc.i64.i32 %1 : i64 -> i32
      %9 = vm.shr.i64.u %1, %c32 : i64
      %10 = vm.trunc.i64.i32 %9 : i64 -> i32
      %ref_8 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
      %11 = vm.select.i64 %_device_query_0, %zero_1, %c-1 : i64
      %12 = vm.trunc.i64.i32 %11 : i64 -> i32
      vm.br_table %12 {
        default: ^bb2,
        0: ^bb1
      }
    ^bb1:  // pred: ^bb0
      vm.call.variadic @hal.command_buffer.push_constants(%ref_8, %_pipeline_layout_0, %zero, [%5, %7, %8, %10]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, i32 ...)
      vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_8, %_pipeline_layout_0, %zero, [(%zero, %zero, %ref, %zero_1, %3), (%c1, %zero, %ref_7, %zero_1, %3)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      %slt = vm.cmp.lt.i64.s %zero_1, %1 : i64
      %13 = vm.xor.i32 %slt, %c1 : i32
      %14 = vm.sub.i64 %zero_1, %1 : i64
      %15 = vm.sub.i64 %1, %c1_3 : i64
      %16 = vm.select.i64 %13, %14, %15 : i64
      %17 = vm.div.i64.s %16, %c128 : i64
      %18 = vm.sub.i64 %zero_1, %17 : i64
      %19 = vm.add.i64 %17, %c1_3 : i64
      %20 = vm.select.i64 %13, %18, %19 : i64
      %slt_9 = vm.cmp.lt.i64.s %zero_1, %0 : i64
      %21 = vm.xor.i32 %slt_9, %c1 : i32
      %22 = vm.sub.i64 %zero_1, %0 : i64
      %23 = vm.sub.i64 %0, %c1_3 : i64
      %24 = vm.select.i64 %21, %22, %23 : i64
      %25 = vm.div.i64.s %24, %c32_0 : i64
      %26 = vm.sub.i64 %zero_1, %25 : i64
      %27 = vm.add.i64 %25, %c1_3 : i64
      %28 = vm.select.i64 %21, %26, %27 : i64
      %29 = vm.mul.i64 %20, %28 : i64
      %30 = vm.trunc.i64.i32 %29 : i64 -> i32
      vm.call @hal.command_buffer.dispatch(%ref_8, %_executable_main_dispatch_0, %zero, %30, %c1, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
      vm.br ^bb2
    ^bb2:  // 2 preds: ^bb0, ^bb1
      vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
      %ref_10 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      %31 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1, %null, %ref_10, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
      %32 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_10]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_br %32, ^bb4, ^bb3
    ^bb3:  // pred: ^bb2
      %ref_11 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_1, %3, %c553648160, %c1, [%0, %1]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_11 : !vm.ref<!hal.buffer_view>
    ^bb4:  // pred: ^bb2
      vm.fail %32, "failed to wait on timepoint"
    }
    vm.export @main attributes {iree.abi.stub}
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::VM::ResolveRodataLoadsPass (iree-vm-resolve-rodata-loads) //----- //
vm.module public @LinearModule {
  vm.global.i32 private @_device_query_0 : i32
  vm.global.ref private @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
  vm.global.ref private @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
  vm.rodata private @main_dispatch_0_cuda_nvptx_fb {alignment = 16 : i64, mime_type = "application/x-flatbuffers"} dense<"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vector<6926xi8>
  vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
  vm.rodata private @_utf8_cuda_nvptx_fb_B15B42B96FDBACC {alignment = 1 : i64} "cuda-nvptx-fb"
  vm.initializer {
    %null = vm.const.ref.zero : !vm.ref<!hal.executable>
    %null_0 = vm.const.ref.zero : !vm.buffer
    %c4 = vm.const.i32 4
    %c7 = vm.const.i32 7
    %zero = vm.const.i32.zero
    %c1 = vm.const.i32 1
    %zero_1 = vm.const.i64.zero
    %c-1 = vm.const.i64 -1
    %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
    %_utf8_cuda_nvptx_fb_B15B42B96FDBACC = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
    %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
    %2 = vm.and.i32 %1, %c1 : i32
    %3 = vm.select.i32 %0#0, %2, %zero : i32
    %ref_2 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero, [(%zero, %c7, %c1), (%c1, %c7, %zero)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
    %ref_3 = vm.call.variadic @hal.pipeline_layout.create(%ref, %c4, [%ref_2]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
    %4 = vm.select.i64 %3, %zero_1, %c-1 : i64
    %5 = vm.trunc.i64.i32 %4 : i64 -> i32
    vm.global.store.i32 %3, @_device_query_0 : i32
    vm.global.store.ref %ref_3, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.br_table %5 {
      default: ^bb2,
      0: ^bb1
    }
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %main_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @main_dispatch_0_cuda_nvptx_fb : !vm.buffer
    %ref_4 = vm.call.variadic @hal.executable.create(%ref, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC, %main_dispatch_0_cuda_nvptx_fb, %null_0, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
    vm.br ^bb3(%ref_4 : !vm.ref<!hal.executable>)
  ^bb2:  // pred: ^bb0
    vm.br ^bb3(%null : !vm.ref<!hal.executable>)
  ^bb3(%6: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
    vm.global.store.ref %6, @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
    vm.return
  }
  vm.import private @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects}
  vm.import private @hal.ex.file.from_memory(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %access : i32, %buffer : !vm.buffer, %offset : i64, %length : i64, %flags : i32) -> !vm.ref<!hal.file>
  vm.import private @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
  vm.import private @hal.allocator.import(%allocator : !vm.ref<!hal.allocator>, %try : i32, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %source : !vm.buffer, %offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
  vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
  vm.import private @hal.buffer.subspan(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
  vm.import private @hal.buffer.length(%buffer : !vm.ref<!hal.buffer>) -> i64 attributes {nosideeffects}
  vm.import private @hal.buffer.load(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i32) -> i32
  vm.import private @hal.buffer.store(%value : i32, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i32)
  vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
  vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
  vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
  vm.import private @hal.buffer_view.element_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
  vm.import private @hal.buffer_view.encoding_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
  vm.import private @hal.buffer_view.rank(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
  vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
  vm.import private @hal.buffer_view.trace(%key : !vm.buffer, %operands : !vm.ref<!hal.buffer_view> ...)
  vm.import private @hal.channel.create(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %flags : i32, %id : !vm.buffer, %group : !vm.buffer, %rank : i32, %count : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects}
  vm.import private @hal.channel.split(%channel : !vm.ref<!hal.channel>, %color : i32, %key : i32, %flags : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects}
  vm.import private @hal.channel.rank_and_count(%channel : !vm.ref<!hal.channel>) -> (i32, i32) attributes {nosideeffects}
  vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer>
  vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
  vm.import private @hal.command_buffer.begin_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>, %label : !vm.buffer)
  vm.import private @hal.command_buffer.end_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>)
  vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
  vm.import private @hal.command_buffer.fill_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %pattern : i32, %pattern_length : i32)
  vm.import private @hal.command_buffer.copy_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64)
  vm.import private @hal.command_buffer.collective(%command_buffer : !vm.ref<!hal.command_buffer>, %channel : !vm.ref<!hal.channel>, %op : i32, %param : i32, %send_buffer : !vm.ref<!hal.buffer>, %send_offset : i64, %send_length : i64, %recv_buffer : !vm.ref<!hal.buffer>, %recv_offset : i64, %recv_length : i64, %element_count : i64)
  vm.import private @hal.command_buffer.push_constants(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %offset : i32, %values : i32 ...)
  vm.import private @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32)
  vm.import private @hal.command_buffer.dispatch.indirect(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroups_buffer : !vm.ref<!hal.buffer>, %workgroups_offset : i64)
  vm.import private @hal.command_buffer.execute.commands(%command_buffer : !vm.ref<!hal.command_buffer>, %commands : !vm.ref<!hal.command_buffer>, %bindings : tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects}
  vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
  vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
  vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
  vm.import private @hal.device.queue.dealloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %buffer : !vm.ref<!hal.buffer>)
  vm.import private @hal.device.queue.read(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_file : !vm.ref<!hal.file>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i32)
  vm.import private @hal.device.queue.write(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_file : !vm.ref<!hal.file>, %target_offset : i64, %length : i64, %flags : i32)
  vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
  vm.import private @hal.device.queue.flush(%device : !vm.ref<!hal.device>, %queue_affinity : i64)
  vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects}
  vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
  vm.import private @hal.fence.join(%fences : !vm.ref<!hal.fence> ...) -> !vm.ref<!hal.fence> attributes {nosideeffects}
  vm.import private @hal.fence.query(%fence : !vm.ref<!hal.fence>) -> i32
  vm.import private @hal.fence.signal(%fence : !vm.ref<!hal.fence>)
  vm.import private @hal.fence.fail(%fence : !vm.ref<!hal.fence>, %status : i32)
  vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
  vm.import private @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects}
  vm.rodata private @_utf8_input_0_5FD512E67BEFDEEC {alignment = 1 : i64} "input 0"
  vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
  vm.func private @main(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
    %c13 = vm.const.i32 13
    %c28 = vm.const.i32 28
    %c3 = vm.const.i32 3
    %c17 = vm.const.i32 17
    %c32 = vm.const.i32 32
    %c48 = vm.const.i32 48
    %null = vm.const.ref.zero : !vm.ref<!hal.fence>
    %c3075 = vm.const.i32 3075
    %c16 = vm.const.i32 16
    %zero = vm.const.i32.zero
    %c32_0 = vm.const.i64 32
    %c128 = vm.const.i64 128
    %c553648160 = vm.const.i32 553648160
    %c1 = vm.const.i32 1
    %zero_1 = vm.const.i64.zero
    %c4 = vm.const.i64 4
    %c-1 = vm.const.i64 -1
    %c-1_2 = vm.const.i32 -1
    %c1_3 = vm.const.i64 1
    %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %_executable_main_dispatch_0 = vm.global.load.ref @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
    %0 = vm.call @hal.buffer_view.dim(%arg0, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %1 = vm.call @hal.buffer_view.dim(%arg0, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1, [%0, %1]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %2 = vm.mul.i64 %0, %c4 : i64
    %3 = vm.mul.i64 %2, %1 : i64
    %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
    vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %ref_6 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    %ref_7 = vm.call @hal.device.queue.alloca(%ref_4, %c-1, %null, %ref_6, %zero, %c48, %c3075, %3) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
    %4 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    %5 = vm.trunc.i64.i32 %0 : i64 -> i32
    %6 = vm.shr.i64.u %0, %c32 : i64
    %7 = vm.trunc.i64.i32 %6 : i64 -> i32
    %8 = vm.trunc.i64.i32 %1 : i64 -> i32
    %9 = vm.shr.i64.u %1, %c32 : i64
    %10 = vm.trunc.i64.i32 %9 : i64 -> i32
    %ref_8 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
    %11 = vm.select.i64 %_device_query_0, %zero_1, %c-1 : i64
    %12 = vm.trunc.i64.i32 %11 : i64 -> i32
    vm.br_table %12 {
      default: ^bb2,
      0: ^bb1
    }
  ^bb1:  // pred: ^bb0
    vm.call.variadic @hal.command_buffer.push_constants(%ref_8, %_pipeline_layout_0, %zero, [%5, %7, %8, %10]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, i32 ...)
    vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_8, %_pipeline_layout_0, %zero, [(%zero, %zero, %ref, %zero_1, %3), (%c1, %zero, %ref_7, %zero_1, %3)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    %slt = vm.cmp.lt.i64.s %zero_1, %1 : i64
    %13 = vm.xor.i32 %slt, %c1 : i32
    %14 = vm.sub.i64 %zero_1, %1 : i64
    %15 = vm.sub.i64 %1, %c1_3 : i64
    %16 = vm.select.i64 %13, %14, %15 : i64
    %17 = vm.div.i64.s %16, %c128 : i64
    %18 = vm.sub.i64 %zero_1, %17 : i64
    %19 = vm.add.i64 %17, %c1_3 : i64
    %20 = vm.select.i64 %13, %18, %19 : i64
    %slt_9 = vm.cmp.lt.i64.s %zero_1, %0 : i64
    %21 = vm.xor.i32 %slt_9, %c1 : i32
    %22 = vm.sub.i64 %zero_1, %0 : i64
    %23 = vm.sub.i64 %0, %c1_3 : i64
    %24 = vm.select.i64 %21, %22, %23 : i64
    %25 = vm.div.i64.s %24, %c32_0 : i64
    %26 = vm.sub.i64 %zero_1, %25 : i64
    %27 = vm.add.i64 %25, %c1_3 : i64
    %28 = vm.select.i64 %21, %26, %27 : i64
    %29 = vm.mul.i64 %20, %28 : i64
    %30 = vm.trunc.i64.i32 %29 : i64 -> i32
    vm.call @hal.command_buffer.dispatch(%ref_8, %_executable_main_dispatch_0, %zero, %30, %c1, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
    vm.br ^bb2
  ^bb2:  // 2 preds: ^bb0, ^bb1
    vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
    vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
    %ref_10 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    %31 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1, %null, %ref_10, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
    %32 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_10]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    vm.cond_br %32, ^bb4, ^bb3
  ^bb3:  // pred: ^bb2
    %ref_11 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_1, %3, %c553648160, %c1, [%0, %1]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
    vm.return %ref_11 : !vm.ref<!hal.buffer_view>
  ^bb4:  // pred: ^bb2
    vm.fail %32, "failed to wait on timepoint"
  }
  vm.export @main attributes {iree.abi.stub}
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
vm.initializer {
  %null = vm.const.ref.zero : !vm.ref<!hal.executable>
  %null_0 = vm.const.ref.zero : !vm.buffer
  %c4 = vm.const.i32 4
  %c7 = vm.const.i32 7
  %zero = vm.const.i32.zero
  %c1 = vm.const.i32 1
  %zero_1 = vm.const.i64.zero
  %c-1 = vm.const.i64 -1
  %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
  %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
  %_utf8_cuda_nvptx_fb_B15B42B96FDBACC = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
  %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
  %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
  %2 = vm.and.i32 %1, %c1 : i32
  %3 = vm.select.i32 %0#0, %2, %zero : i32
  %ref_2 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero, [(%zero, %c7, %c1), (%c1, %c7, %zero)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
  %ref_3 = vm.call.variadic @hal.pipeline_layout.create(%ref, %c4, [%ref_2]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
  %4 = vm.select.i64 %3, %zero_1, %c-1 : i64
  %5 = vm.trunc.i64.i32 %4 : i64 -> i32
  vm.global.store.i32 %3, @_device_query_0 : i32
  vm.global.store.ref %ref_3, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
  vm.br_table %5 {
    default: ^bb2,
    0: ^bb1
  }
^bb1:  // pred: ^bb0
  %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
  %main_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @main_dispatch_0_cuda_nvptx_fb : !vm.buffer
  %ref_4 = vm.call.variadic @hal.executable.create(%ref, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC, %main_dispatch_0_cuda_nvptx_fb, %null_0, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
  vm.br ^bb3(%ref_4 : !vm.ref<!hal.executable>)
^bb2:  // pred: ^bb0
  vm.br ^bb3(%null : !vm.ref<!hal.executable>)
^bb3(%6: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
  vm.global.store.ref %6, @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
  vm.return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
vm.func private @main(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
  %c13 = vm.const.i32 13
  %c28 = vm.const.i32 28
  %c3 = vm.const.i32 3
  %c17 = vm.const.i32 17
  %c32 = vm.const.i32 32
  %c48 = vm.const.i32 48
  %null = vm.const.ref.zero : !vm.ref<!hal.fence>
  %c3075 = vm.const.i32 3075
  %c16 = vm.const.i32 16
  %zero = vm.const.i32.zero
  %c32_0 = vm.const.i64 32
  %c128 = vm.const.i64 128
  %c553648160 = vm.const.i32 553648160
  %c1 = vm.const.i32 1
  %zero_1 = vm.const.i64.zero
  %c4 = vm.const.i64 4
  %c-1 = vm.const.i64 -1
  %c-1_2 = vm.const.i32 -1
  %c1_3 = vm.const.i64 1
  %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
  %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
  %_executable_main_dispatch_0 = vm.global.load.ref @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
  %0 = vm.call @hal.buffer_view.dim(%arg0, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
  %1 = vm.call @hal.buffer_view.dim(%arg0, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
  %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
  vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1, [%0, %1]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
  %2 = vm.mul.i64 %0, %c4 : i64
  %3 = vm.mul.i64 %2, %1 : i64
  %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
  %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
  %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
  %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
  vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
  %ref_6 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
  %ref_7 = vm.call @hal.device.queue.alloca(%ref_4, %c-1, %null, %ref_6, %zero, %c48, %c3075, %3) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
  %4 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
  %5 = vm.trunc.i64.i32 %0 : i64 -> i32
  %6 = vm.shr.i64.u %0, %c32 : i64
  %7 = vm.trunc.i64.i32 %6 : i64 -> i32
  %8 = vm.trunc.i64.i32 %1 : i64 -> i32
  %9 = vm.shr.i64.u %1, %c32 : i64
  %10 = vm.trunc.i64.i32 %9 : i64 -> i32
  %ref_8 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
  %11 = vm.select.i64 %_device_query_0, %zero_1, %c-1 : i64
  %12 = vm.trunc.i64.i32 %11 : i64 -> i32
  vm.br_table %12 {
    default: ^bb2,
    0: ^bb1
  }
^bb1:  // pred: ^bb0
  vm.call.variadic @hal.command_buffer.push_constants(%ref_8, %_pipeline_layout_0, %zero, [%5, %7, %8, %10]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, i32 ...)
  vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_8, %_pipeline_layout_0, %zero, [(%zero, %zero, %ref, %zero_1, %3), (%c1, %zero, %ref_7, %zero_1, %3)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
  %slt = vm.cmp.lt.i64.s %zero_1, %1 : i64
  %13 = vm.xor.i32 %slt, %c1 : i32
  %14 = vm.sub.i64 %zero_1, %1 : i64
  %15 = vm.sub.i64 %1, %c1_3 : i64
  %16 = vm.select.i64 %13, %14, %15 : i64
  %17 = vm.div.i64.s %16, %c128 : i64
  %18 = vm.sub.i64 %zero_1, %17 : i64
  %19 = vm.add.i64 %17, %c1_3 : i64
  %20 = vm.select.i64 %13, %18, %19 : i64
  %slt_9 = vm.cmp.lt.i64.s %zero_1, %0 : i64
  %21 = vm.xor.i32 %slt_9, %c1 : i32
  %22 = vm.sub.i64 %zero_1, %0 : i64
  %23 = vm.sub.i64 %0, %c1_3 : i64
  %24 = vm.select.i64 %21, %22, %23 : i64
  %25 = vm.div.i64.s %24, %c32_0 : i64
  %26 = vm.sub.i64 %zero_1, %25 : i64
  %27 = vm.add.i64 %25, %c1_3 : i64
  %28 = vm.select.i64 %21, %26, %27 : i64
  %29 = vm.mul.i64 %20, %28 : i64
  %30 = vm.trunc.i64.i32 %29 : i64 -> i32
  vm.call @hal.command_buffer.dispatch(%ref_8, %_executable_main_dispatch_0, %zero, %30, %c1, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
  vm.br ^bb2
^bb2:  // 2 preds: ^bb0, ^bb1
  vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
  vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
  %ref_10 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
  %31 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
  vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1, %null, %ref_10, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
  %32 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_10]) : (i32, !vm.ref<!hal.fence> ...) -> i32
  vm.cond_br %32, ^bb4, ^bb3
^bb3:  // pred: ^bb2
  %ref_11 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_1, %3, %c553648160, %c1, [%0, %1]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
  vm.return %ref_11 : !vm.ref<!hal.buffer_view>
^bb4:  // pred: ^bb2
  vm.fail %32, "failed to wait on timepoint"
}

// -----// IR Dump After Inliner (inline) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda], vm.toplevel} {
  vm.module public @LinearModule {
    vm.global.i32 private @_device_query_0 : i32
    vm.global.ref private @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.global.ref private @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
    vm.rodata private @main_dispatch_0_cuda_nvptx_fb {alignment = 16 : i64, mime_type = "application/x-flatbuffers"} dense<"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vector<6926xi8>
    vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
    vm.rodata private @_utf8_cuda_nvptx_fb_B15B42B96FDBACC {alignment = 1 : i64} "cuda-nvptx-fb"
    vm.initializer {
      %null = vm.const.ref.zero : !vm.ref<!hal.executable>
      %null_0 = vm.const.ref.zero : !vm.buffer
      %c4 = vm.const.i32 4
      %c7 = vm.const.i32 7
      %zero = vm.const.i32.zero
      %c1 = vm.const.i32 1
      %zero_1 = vm.const.i64.zero
      %c-1 = vm.const.i64 -1
      %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
      %_utf8_cuda_nvptx_fb_B15B42B96FDBACC = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
      %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
      %2 = vm.and.i32 %1, %c1 : i32
      %3 = vm.select.i32 %0#0, %2, %zero : i32
      %ref_2 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero, [(%zero, %c7, %c1), (%c1, %c7, %zero)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
      %ref_3 = vm.call.variadic @hal.pipeline_layout.create(%ref, %c4, [%ref_2]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
      %4 = vm.select.i64 %3, %zero_1, %c-1 : i64
      %5 = vm.trunc.i64.i32 %4 : i64 -> i32
      vm.global.store.i32 %3, @_device_query_0 : i32
      vm.global.store.ref %ref_3, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      vm.br_table %5 {
        default: ^bb2,
        0: ^bb1
      }
    ^bb1:  // pred: ^bb0
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %main_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @main_dispatch_0_cuda_nvptx_fb : !vm.buffer
      %ref_4 = vm.call.variadic @hal.executable.create(%ref, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC, %main_dispatch_0_cuda_nvptx_fb, %null_0, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
      vm.br ^bb3(%ref_4 : !vm.ref<!hal.executable>)
    ^bb2:  // pred: ^bb0
      vm.br ^bb3(%null : !vm.ref<!hal.executable>)
    ^bb3(%6: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
      vm.global.store.ref %6, @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
      vm.return
    }
    vm.import private @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects}
    vm.import private @hal.ex.file.from_memory(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %access : i32, %buffer : !vm.buffer, %offset : i64, %length : i64, %flags : i32) -> !vm.ref<!hal.file>
    vm.import private @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
    vm.import private @hal.allocator.import(%allocator : !vm.ref<!hal.allocator>, %try : i32, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %source : !vm.buffer, %offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
    vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
    vm.import private @hal.buffer.subspan(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.buffer.length(%buffer : !vm.ref<!hal.buffer>) -> i64 attributes {nosideeffects}
    vm.import private @hal.buffer.load(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i32) -> i32
    vm.import private @hal.buffer.store(%value : i32, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i32)
    vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
    vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
    vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.buffer_view.element_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
    vm.import private @hal.buffer_view.encoding_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
    vm.import private @hal.buffer_view.rank(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
    vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
    vm.import private @hal.buffer_view.trace(%key : !vm.buffer, %operands : !vm.ref<!hal.buffer_view> ...)
    vm.import private @hal.channel.create(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %flags : i32, %id : !vm.buffer, %group : !vm.buffer, %rank : i32, %count : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects}
    vm.import private @hal.channel.split(%channel : !vm.ref<!hal.channel>, %color : i32, %key : i32, %flags : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects}
    vm.import private @hal.channel.rank_and_count(%channel : !vm.ref<!hal.channel>) -> (i32, i32) attributes {nosideeffects}
    vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer>
    vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.begin_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>, %label : !vm.buffer)
    vm.import private @hal.command_buffer.end_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
    vm.import private @hal.command_buffer.fill_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %pattern : i32, %pattern_length : i32)
    vm.import private @hal.command_buffer.copy_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64)
    vm.import private @hal.command_buffer.collective(%command_buffer : !vm.ref<!hal.command_buffer>, %channel : !vm.ref<!hal.channel>, %op : i32, %param : i32, %send_buffer : !vm.ref<!hal.buffer>, %send_offset : i64, %send_length : i64, %recv_buffer : !vm.ref<!hal.buffer>, %recv_offset : i64, %recv_length : i64, %element_count : i64)
    vm.import private @hal.command_buffer.push_constants(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %offset : i32, %values : i32 ...)
    vm.import private @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32)
    vm.import private @hal.command_buffer.dispatch.indirect(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroups_buffer : !vm.ref<!hal.buffer>, %workgroups_offset : i64)
    vm.import private @hal.command_buffer.execute.commands(%command_buffer : !vm.ref<!hal.command_buffer>, %commands : !vm.ref<!hal.command_buffer>, %bindings : tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects}
    vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
    vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
    vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
    vm.import private @hal.device.queue.dealloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %buffer : !vm.ref<!hal.buffer>)
    vm.import private @hal.device.queue.read(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_file : !vm.ref<!hal.file>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i32)
    vm.import private @hal.device.queue.write(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_file : !vm.ref<!hal.file>, %target_offset : i64, %length : i64, %flags : i32)
    vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
    vm.import private @hal.device.queue.flush(%device : !vm.ref<!hal.device>, %queue_affinity : i64)
    vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects}
    vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
    vm.import private @hal.fence.join(%fences : !vm.ref<!hal.fence> ...) -> !vm.ref<!hal.fence> attributes {nosideeffects}
    vm.import private @hal.fence.query(%fence : !vm.ref<!hal.fence>) -> i32
    vm.import private @hal.fence.signal(%fence : !vm.ref<!hal.fence>)
    vm.import private @hal.fence.fail(%fence : !vm.ref<!hal.fence>, %status : i32)
    vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
    vm.import private @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects}
    vm.rodata private @_utf8_input_0_5FD512E67BEFDEEC {alignment = 1 : i64} "input 0"
    vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
    vm.func private @main(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
      %c13 = vm.const.i32 13
      %c28 = vm.const.i32 28
      %c3 = vm.const.i32 3
      %c17 = vm.const.i32 17
      %c32 = vm.const.i32 32
      %c48 = vm.const.i32 48
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %c3075 = vm.const.i32 3075
      %c16 = vm.const.i32 16
      %zero = vm.const.i32.zero
      %c32_0 = vm.const.i64 32
      %c128 = vm.const.i64 128
      %c553648160 = vm.const.i32 553648160
      %c1 = vm.const.i32 1
      %zero_1 = vm.const.i64.zero
      %c4 = vm.const.i64 4
      %c-1 = vm.const.i64 -1
      %c-1_2 = vm.const.i32 -1
      %c1_3 = vm.const.i64 1
      %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %_executable_main_dispatch_0 = vm.global.load.ref @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
      %0 = vm.call @hal.buffer_view.dim(%arg0, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %1 = vm.call @hal.buffer_view.dim(%arg0, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1, [%0, %1]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %2 = vm.mul.i64 %0, %c4 : i64
      %3 = vm.mul.i64 %2, %1 : i64
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %ref_6 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      %ref_7 = vm.call @hal.device.queue.alloca(%ref_4, %c-1, %null, %ref_6, %zero, %c48, %c3075, %3) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
      %4 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      %5 = vm.trunc.i64.i32 %0 : i64 -> i32
      %6 = vm.shr.i64.u %0, %c32 : i64
      %7 = vm.trunc.i64.i32 %6 : i64 -> i32
      %8 = vm.trunc.i64.i32 %1 : i64 -> i32
      %9 = vm.shr.i64.u %1, %c32 : i64
      %10 = vm.trunc.i64.i32 %9 : i64 -> i32
      %ref_8 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
      %11 = vm.select.i64 %_device_query_0, %zero_1, %c-1 : i64
      %12 = vm.trunc.i64.i32 %11 : i64 -> i32
      vm.br_table %12 {
        default: ^bb2,
        0: ^bb1
      }
    ^bb1:  // pred: ^bb0
      vm.call.variadic @hal.command_buffer.push_constants(%ref_8, %_pipeline_layout_0, %zero, [%5, %7, %8, %10]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, i32 ...)
      vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_8, %_pipeline_layout_0, %zero, [(%zero, %zero, %ref, %zero_1, %3), (%c1, %zero, %ref_7, %zero_1, %3)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      %slt = vm.cmp.lt.i64.s %zero_1, %1 : i64
      %13 = vm.xor.i32 %slt, %c1 : i32
      %14 = vm.sub.i64 %zero_1, %1 : i64
      %15 = vm.sub.i64 %1, %c1_3 : i64
      %16 = vm.select.i64 %13, %14, %15 : i64
      %17 = vm.div.i64.s %16, %c128 : i64
      %18 = vm.sub.i64 %zero_1, %17 : i64
      %19 = vm.add.i64 %17, %c1_3 : i64
      %20 = vm.select.i64 %13, %18, %19 : i64
      %slt_9 = vm.cmp.lt.i64.s %zero_1, %0 : i64
      %21 = vm.xor.i32 %slt_9, %c1 : i32
      %22 = vm.sub.i64 %zero_1, %0 : i64
      %23 = vm.sub.i64 %0, %c1_3 : i64
      %24 = vm.select.i64 %21, %22, %23 : i64
      %25 = vm.div.i64.s %24, %c32_0 : i64
      %26 = vm.sub.i64 %zero_1, %25 : i64
      %27 = vm.add.i64 %25, %c1_3 : i64
      %28 = vm.select.i64 %21, %26, %27 : i64
      %29 = vm.mul.i64 %20, %28 : i64
      %30 = vm.trunc.i64.i32 %29 : i64 -> i32
      vm.call @hal.command_buffer.dispatch(%ref_8, %_executable_main_dispatch_0, %zero, %30, %c1, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
      vm.br ^bb2
    ^bb2:  // 2 preds: ^bb0, ^bb1
      vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
      %ref_10 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      %31 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1, %null, %ref_10, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
      %32 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_10]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_br %32, ^bb4, ^bb3
    ^bb3:  // pred: ^bb2
      %ref_11 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_1, %3, %c553648160, %c1, [%0, %1]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_11 : !vm.ref<!hal.buffer_view>
    ^bb4:  // pred: ^bb2
      vm.fail %32, "failed to wait on timepoint"
    }
    vm.export @main attributes {iree.abi.stub}
  }
}


// -----// IR Dump After SymbolDCE (symbol-dce) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda], vm.toplevel} {
  vm.module public @LinearModule {
    vm.global.i32 private @_device_query_0 : i32
    vm.global.ref private @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.global.ref private @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
    vm.rodata private @main_dispatch_0_cuda_nvptx_fb {alignment = 16 : i64, mime_type = "application/x-flatbuffers"} dense<"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vector<6926xi8>
    vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
    vm.rodata private @_utf8_cuda_nvptx_fb_B15B42B96FDBACC {alignment = 1 : i64} "cuda-nvptx-fb"
    vm.initializer {
      %null = vm.const.ref.zero : !vm.ref<!hal.executable>
      %null_0 = vm.const.ref.zero : !vm.buffer
      %c4 = vm.const.i32 4
      %c7 = vm.const.i32 7
      %zero = vm.const.i32.zero
      %c1 = vm.const.i32 1
      %zero_1 = vm.const.i64.zero
      %c-1 = vm.const.i64 -1
      %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
      %_utf8_cuda_nvptx_fb_B15B42B96FDBACC = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
      %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
      %2 = vm.and.i32 %1, %c1 : i32
      %3 = vm.select.i32 %0#0, %2, %zero : i32
      %ref_2 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero, [(%zero, %c7, %c1), (%c1, %c7, %zero)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
      %ref_3 = vm.call.variadic @hal.pipeline_layout.create(%ref, %c4, [%ref_2]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
      %4 = vm.select.i64 %3, %zero_1, %c-1 : i64
      %5 = vm.trunc.i64.i32 %4 : i64 -> i32
      vm.global.store.i32 %3, @_device_query_0 : i32
      vm.global.store.ref %ref_3, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      vm.br_table %5 {
        default: ^bb2,
        0: ^bb1
      }
    ^bb1:  // pred: ^bb0
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %main_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @main_dispatch_0_cuda_nvptx_fb : !vm.buffer
      %ref_4 = vm.call.variadic @hal.executable.create(%ref, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC, %main_dispatch_0_cuda_nvptx_fb, %null_0, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
      vm.br ^bb3(%ref_4 : !vm.ref<!hal.executable>)
    ^bb2:  // pred: ^bb0
      vm.br ^bb3(%null : !vm.ref<!hal.executable>)
    ^bb3(%6: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
      vm.global.store.ref %6, @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
      vm.return
    }
    vm.import private @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects}
    vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
    vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
    vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
    vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
    vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer>
    vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
    vm.import private @hal.command_buffer.push_constants(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %offset : i32, %values : i32 ...)
    vm.import private @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32)
    vm.import private @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects}
    vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
    vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
    vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
    vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
    vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects}
    vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
    vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
    vm.import private @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects}
    vm.rodata private @_utf8_input_0_5FD512E67BEFDEEC {alignment = 1 : i64} "input 0"
    vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
    vm.func private @main(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
      %c13 = vm.const.i32 13
      %c28 = vm.const.i32 28
      %c3 = vm.const.i32 3
      %c17 = vm.const.i32 17
      %c32 = vm.const.i32 32
      %c48 = vm.const.i32 48
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %c3075 = vm.const.i32 3075
      %c16 = vm.const.i32 16
      %zero = vm.const.i32.zero
      %c32_0 = vm.const.i64 32
      %c128 = vm.const.i64 128
      %c553648160 = vm.const.i32 553648160
      %c1 = vm.const.i32 1
      %zero_1 = vm.const.i64.zero
      %c4 = vm.const.i64 4
      %c-1 = vm.const.i64 -1
      %c-1_2 = vm.const.i32 -1
      %c1_3 = vm.const.i64 1
      %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %_executable_main_dispatch_0 = vm.global.load.ref @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
      %0 = vm.call @hal.buffer_view.dim(%arg0, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %1 = vm.call @hal.buffer_view.dim(%arg0, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1, [%0, %1]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %2 = vm.mul.i64 %0, %c4 : i64
      %3 = vm.mul.i64 %2, %1 : i64
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %ref_6 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      %ref_7 = vm.call @hal.device.queue.alloca(%ref_4, %c-1, %null, %ref_6, %zero, %c48, %c3075, %3) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
      %4 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      %5 = vm.trunc.i64.i32 %0 : i64 -> i32
      %6 = vm.shr.i64.u %0, %c32 : i64
      %7 = vm.trunc.i64.i32 %6 : i64 -> i32
      %8 = vm.trunc.i64.i32 %1 : i64 -> i32
      %9 = vm.shr.i64.u %1, %c32 : i64
      %10 = vm.trunc.i64.i32 %9 : i64 -> i32
      %ref_8 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
      %11 = vm.select.i64 %_device_query_0, %zero_1, %c-1 : i64
      %12 = vm.trunc.i64.i32 %11 : i64 -> i32
      vm.br_table %12 {
        default: ^bb2,
        0: ^bb1
      }
    ^bb1:  // pred: ^bb0
      vm.call.variadic @hal.command_buffer.push_constants(%ref_8, %_pipeline_layout_0, %zero, [%5, %7, %8, %10]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, i32 ...)
      vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_8, %_pipeline_layout_0, %zero, [(%zero, %zero, %ref, %zero_1, %3), (%c1, %zero, %ref_7, %zero_1, %3)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      %slt = vm.cmp.lt.i64.s %zero_1, %1 : i64
      %13 = vm.xor.i32 %slt, %c1 : i32
      %14 = vm.sub.i64 %zero_1, %1 : i64
      %15 = vm.sub.i64 %1, %c1_3 : i64
      %16 = vm.select.i64 %13, %14, %15 : i64
      %17 = vm.div.i64.s %16, %c128 : i64
      %18 = vm.sub.i64 %zero_1, %17 : i64
      %19 = vm.add.i64 %17, %c1_3 : i64
      %20 = vm.select.i64 %13, %18, %19 : i64
      %slt_9 = vm.cmp.lt.i64.s %zero_1, %0 : i64
      %21 = vm.xor.i32 %slt_9, %c1 : i32
      %22 = vm.sub.i64 %zero_1, %0 : i64
      %23 = vm.sub.i64 %0, %c1_3 : i64
      %24 = vm.select.i64 %21, %22, %23 : i64
      %25 = vm.div.i64.s %24, %c32_0 : i64
      %26 = vm.sub.i64 %zero_1, %25 : i64
      %27 = vm.add.i64 %25, %c1_3 : i64
      %28 = vm.select.i64 %21, %26, %27 : i64
      %29 = vm.mul.i64 %20, %28 : i64
      %30 = vm.trunc.i64.i32 %29 : i64 -> i32
      vm.call @hal.command_buffer.dispatch(%ref_8, %_executable_main_dispatch_0, %zero, %30, %c1, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
      vm.br ^bb2
    ^bb2:  // 2 preds: ^bb0, ^bb1
      vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
      %ref_10 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      %31 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1, %null, %ref_10, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
      %32 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_10]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_br %32, ^bb4, ^bb3
    ^bb3:  // pred: ^bb2
      %ref_11 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_1, %3, %c553648160, %c1, [%0, %1]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_11 : !vm.ref<!hal.buffer_view>
    ^bb4:  // pred: ^bb2
      vm.fail %32, "failed to wait on timepoint"
    }
    vm.export @main attributes {iree.abi.stub}
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda], vm.toplevel} {
  vm.module public @LinearModule {
    vm.global.i32 private @_device_query_0 : i32
    vm.global.ref private @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.global.ref private @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
    vm.rodata private @main_dispatch_0_cuda_nvptx_fb {alignment = 16 : i64, mime_type = "application/x-flatbuffers"} dense<"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vector<6926xi8>
    vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
    vm.rodata private @_utf8_cuda_nvptx_fb_B15B42B96FDBACC {alignment = 1 : i64} "cuda-nvptx-fb"
    vm.initializer {
      %null = vm.const.ref.zero : !vm.ref<!hal.executable>
      %null_0 = vm.const.ref.zero : !vm.buffer
      %c4 = vm.const.i32 4
      %c7 = vm.const.i32 7
      %zero = vm.const.i32.zero
      %c1 = vm.const.i32 1
      %zero_1 = vm.const.i64.zero
      %c-1 = vm.const.i64 -1
      %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
      %_utf8_cuda_nvptx_fb_B15B42B96FDBACC = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
      %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
      %2 = vm.and.i32 %1, %c1 : i32
      %3 = vm.select.i32 %0#0, %2, %zero : i32
      %ref_2 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero, [(%zero, %c7, %c1), (%c1, %c7, %zero)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
      %ref_3 = vm.call.variadic @hal.pipeline_layout.create(%ref, %c4, [%ref_2]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
      %4 = vm.select.i64 %3, %zero_1, %c-1 : i64
      %5 = vm.trunc.i64.i32 %4 : i64 -> i32
      vm.global.store.i32 %3, @_device_query_0 : i32
      vm.global.store.ref %ref_3, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      vm.br_table %5 {
        default: ^bb2,
        0: ^bb1
      }
    ^bb1:  // pred: ^bb0
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %main_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @main_dispatch_0_cuda_nvptx_fb : !vm.buffer
      %ref_4 = vm.call.variadic @hal.executable.create(%ref, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC, %main_dispatch_0_cuda_nvptx_fb, %null_0, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
      vm.br ^bb3(%ref_4 : !vm.ref<!hal.executable>)
    ^bb2:  // pred: ^bb0
      vm.br ^bb3(%null : !vm.ref<!hal.executable>)
    ^bb3(%6: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
      vm.global.store.ref %6, @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
      vm.return
    }
    vm.import private @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects}
    vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
    vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
    vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
    vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
    vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer>
    vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
    vm.import private @hal.command_buffer.push_constants(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %offset : i32, %values : i32 ...)
    vm.import private @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32)
    vm.import private @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects}
    vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
    vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
    vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
    vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
    vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects}
    vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
    vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
    vm.import private @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects}
    vm.rodata private @_utf8_input_0_5FD512E67BEFDEEC {alignment = 1 : i64} "input 0"
    vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
    vm.func private @main(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
      %c13 = vm.const.i32 13
      %c28 = vm.const.i32 28
      %c3 = vm.const.i32 3
      %c17 = vm.const.i32 17
      %c32 = vm.const.i32 32
      %c48 = vm.const.i32 48
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %c3075 = vm.const.i32 3075
      %c16 = vm.const.i32 16
      %zero = vm.const.i32.zero
      %c32_0 = vm.const.i64 32
      %c128 = vm.const.i64 128
      %c553648160 = vm.const.i32 553648160
      %c1 = vm.const.i32 1
      %zero_1 = vm.const.i64.zero
      %c4 = vm.const.i64 4
      %c-1 = vm.const.i64 -1
      %c-1_2 = vm.const.i32 -1
      %c1_3 = vm.const.i64 1
      %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %_executable_main_dispatch_0 = vm.global.load.ref @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
      %0 = vm.call @hal.buffer_view.dim(%arg0, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %1 = vm.call @hal.buffer_view.dim(%arg0, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1, [%0, %1]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %2 = vm.mul.i64 %0, %c4 : i64
      %3 = vm.mul.i64 %2, %1 : i64
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %ref_6 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      %ref_7 = vm.call @hal.device.queue.alloca(%ref_4, %c-1, %null, %ref_6, %zero, %c48, %c3075, %3) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
      %4 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      %5 = vm.trunc.i64.i32 %0 : i64 -> i32
      %6 = vm.shr.i64.u %0, %c32 : i64
      %7 = vm.trunc.i64.i32 %6 : i64 -> i32
      %8 = vm.trunc.i64.i32 %1 : i64 -> i32
      %9 = vm.shr.i64.u %1, %c32 : i64
      %10 = vm.trunc.i64.i32 %9 : i64 -> i32
      %ref_8 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
      %11 = vm.select.i64 %_device_query_0, %zero_1, %c-1 : i64
      %12 = vm.trunc.i64.i32 %11 : i64 -> i32
      vm.br_table %12 {
        default: ^bb2,
        0: ^bb1
      }
    ^bb1:  // pred: ^bb0
      vm.call.variadic @hal.command_buffer.push_constants(%ref_8, %_pipeline_layout_0, %zero, [%5, %7, %8, %10]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, i32 ...)
      vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_8, %_pipeline_layout_0, %zero, [(%zero, %zero, %ref, %zero_1, %3), (%c1, %zero, %ref_7, %zero_1, %3)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      %slt = vm.cmp.lt.i64.s %zero_1, %1 : i64
      %13 = vm.xor.i32 %slt, %c1 : i32
      %14 = vm.sub.i64 %zero_1, %1 : i64
      %15 = vm.sub.i64 %1, %c1_3 : i64
      %16 = vm.select.i64 %13, %14, %15 : i64
      %17 = vm.div.i64.s %16, %c128 : i64
      %18 = vm.sub.i64 %zero_1, %17 : i64
      %19 = vm.add.i64 %17, %c1_3 : i64
      %20 = vm.select.i64 %13, %18, %19 : i64
      %slt_9 = vm.cmp.lt.i64.s %zero_1, %0 : i64
      %21 = vm.xor.i32 %slt_9, %c1 : i32
      %22 = vm.sub.i64 %zero_1, %0 : i64
      %23 = vm.sub.i64 %0, %c1_3 : i64
      %24 = vm.select.i64 %21, %22, %23 : i64
      %25 = vm.div.i64.s %24, %c32_0 : i64
      %26 = vm.sub.i64 %zero_1, %25 : i64
      %27 = vm.add.i64 %25, %c1_3 : i64
      %28 = vm.select.i64 %21, %26, %27 : i64
      %29 = vm.mul.i64 %20, %28 : i64
      %30 = vm.trunc.i64.i32 %29 : i64 -> i32
      vm.call @hal.command_buffer.dispatch(%ref_8, %_executable_main_dispatch_0, %zero, %30, %c1, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
      vm.br ^bb2
    ^bb2:  // 2 preds: ^bb0, ^bb1
      vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
      %ref_10 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      %31 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1, %null, %ref_10, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
      %32 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_10]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_br %32, ^bb4, ^bb3
    ^bb3:  // pred: ^bb2
      %ref_11 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_1, %3, %c553648160, %c1, [%0, %1]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_11 : !vm.ref<!hal.buffer_view>
    ^bb4:  // pred: ^bb2
      vm.fail %32, "failed to wait on timepoint"
    }
    vm.export @main attributes {iree.abi.stub}
  }
}


// -----// IR Dump After CSE (cse) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda], vm.toplevel} {
  vm.module public @LinearModule {
    vm.global.i32 private @_device_query_0 : i32
    vm.global.ref private @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.global.ref private @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
    vm.rodata private @main_dispatch_0_cuda_nvptx_fb {alignment = 16 : i64, mime_type = "application/x-flatbuffers"} dense<"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vector<6926xi8>
    vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
    vm.rodata private @_utf8_cuda_nvptx_fb_B15B42B96FDBACC {alignment = 1 : i64} "cuda-nvptx-fb"
    vm.initializer {
      %null = vm.const.ref.zero : !vm.ref<!hal.executable>
      %null_0 = vm.const.ref.zero : !vm.buffer
      %c4 = vm.const.i32 4
      %c7 = vm.const.i32 7
      %zero = vm.const.i32.zero
      %c1 = vm.const.i32 1
      %zero_1 = vm.const.i64.zero
      %c-1 = vm.const.i64 -1
      %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
      %_utf8_cuda_nvptx_fb_B15B42B96FDBACC = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
      %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
      %2 = vm.and.i32 %1, %c1 : i32
      %3 = vm.select.i32 %0#0, %2, %zero : i32
      %ref_2 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero, [(%zero, %c7, %c1), (%c1, %c7, %zero)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
      %ref_3 = vm.call.variadic @hal.pipeline_layout.create(%ref, %c4, [%ref_2]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
      %4 = vm.select.i64 %3, %zero_1, %c-1 : i64
      %5 = vm.trunc.i64.i32 %4 : i64 -> i32
      vm.global.store.i32 %3, @_device_query_0 : i32
      vm.global.store.ref %ref_3, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      vm.br_table %5 {
        default: ^bb2,
        0: ^bb1
      }
    ^bb1:  // pred: ^bb0
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %main_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @main_dispatch_0_cuda_nvptx_fb : !vm.buffer
      %ref_4 = vm.call.variadic @hal.executable.create(%ref, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC, %main_dispatch_0_cuda_nvptx_fb, %null_0, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
      vm.br ^bb3(%ref_4 : !vm.ref<!hal.executable>)
    ^bb2:  // pred: ^bb0
      vm.br ^bb3(%null : !vm.ref<!hal.executable>)
    ^bb3(%6: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
      vm.global.store.ref %6, @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
      vm.return
    }
    vm.import private @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects}
    vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
    vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
    vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
    vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
    vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer>
    vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
    vm.import private @hal.command_buffer.push_constants(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %offset : i32, %values : i32 ...)
    vm.import private @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32)
    vm.import private @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects}
    vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
    vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
    vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
    vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
    vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects}
    vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
    vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
    vm.import private @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects}
    vm.rodata private @_utf8_input_0_5FD512E67BEFDEEC {alignment = 1 : i64} "input 0"
    vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
    vm.func private @main(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
      %c13 = vm.const.i32 13
      %c28 = vm.const.i32 28
      %c3 = vm.const.i32 3
      %c17 = vm.const.i32 17
      %c32 = vm.const.i32 32
      %c48 = vm.const.i32 48
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %c3075 = vm.const.i32 3075
      %c16 = vm.const.i32 16
      %zero = vm.const.i32.zero
      %c32_0 = vm.const.i64 32
      %c128 = vm.const.i64 128
      %c553648160 = vm.const.i32 553648160
      %c1 = vm.const.i32 1
      %zero_1 = vm.const.i64.zero
      %c4 = vm.const.i64 4
      %c-1 = vm.const.i64 -1
      %c-1_2 = vm.const.i32 -1
      %c1_3 = vm.const.i64 1
      %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %_executable_main_dispatch_0 = vm.global.load.ref @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
      %0 = vm.call @hal.buffer_view.dim(%arg0, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %1 = vm.call @hal.buffer_view.dim(%arg0, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1, [%0, %1]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %2 = vm.mul.i64 %0, %c4 : i64
      %3 = vm.mul.i64 %2, %1 : i64
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %ref_6 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      %ref_7 = vm.call @hal.device.queue.alloca(%ref_4, %c-1, %null, %ref_6, %zero, %c48, %c3075, %3) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
      %4 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      %5 = vm.trunc.i64.i32 %0 : i64 -> i32
      %6 = vm.shr.i64.u %0, %c32 : i64
      %7 = vm.trunc.i64.i32 %6 : i64 -> i32
      %8 = vm.trunc.i64.i32 %1 : i64 -> i32
      %9 = vm.shr.i64.u %1, %c32 : i64
      %10 = vm.trunc.i64.i32 %9 : i64 -> i32
      %ref_8 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
      %11 = vm.select.i64 %_device_query_0, %zero_1, %c-1 : i64
      %12 = vm.trunc.i64.i32 %11 : i64 -> i32
      vm.br_table %12 {
        default: ^bb2,
        0: ^bb1
      }
    ^bb1:  // pred: ^bb0
      vm.call.variadic @hal.command_buffer.push_constants(%ref_8, %_pipeline_layout_0, %zero, [%5, %7, %8, %10]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, i32 ...)
      vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_8, %_pipeline_layout_0, %zero, [(%zero, %zero, %ref, %zero_1, %3), (%c1, %zero, %ref_7, %zero_1, %3)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      %slt = vm.cmp.lt.i64.s %zero_1, %1 : i64
      %13 = vm.xor.i32 %slt, %c1 : i32
      %14 = vm.sub.i64 %zero_1, %1 : i64
      %15 = vm.sub.i64 %1, %c1_3 : i64
      %16 = vm.select.i64 %13, %14, %15 : i64
      %17 = vm.div.i64.s %16, %c128 : i64
      %18 = vm.sub.i64 %zero_1, %17 : i64
      %19 = vm.add.i64 %17, %c1_3 : i64
      %20 = vm.select.i64 %13, %18, %19 : i64
      %slt_9 = vm.cmp.lt.i64.s %zero_1, %0 : i64
      %21 = vm.xor.i32 %slt_9, %c1 : i32
      %22 = vm.sub.i64 %zero_1, %0 : i64
      %23 = vm.sub.i64 %0, %c1_3 : i64
      %24 = vm.select.i64 %21, %22, %23 : i64
      %25 = vm.div.i64.s %24, %c32_0 : i64
      %26 = vm.sub.i64 %zero_1, %25 : i64
      %27 = vm.add.i64 %25, %c1_3 : i64
      %28 = vm.select.i64 %21, %26, %27 : i64
      %29 = vm.mul.i64 %20, %28 : i64
      %30 = vm.trunc.i64.i32 %29 : i64 -> i32
      vm.call @hal.command_buffer.dispatch(%ref_8, %_executable_main_dispatch_0, %zero, %30, %c1, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
      vm.br ^bb2
    ^bb2:  // 2 preds: ^bb0, ^bb1
      vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
      %ref_10 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      %31 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1, %null, %ref_10, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
      %32 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_10]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_br %32, ^bb4, ^bb3
    ^bb3:  // pred: ^bb2
      %ref_11 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_1, %3, %c553648160, %c1, [%0, %1]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_11 : !vm.ref<!hal.buffer_view>
    ^bb4:  // pred: ^bb2
      vm.fail %32, "failed to wait on timepoint"
    }
    vm.export @main attributes {iree.abi.stub}
  }
}


// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda], vm.toplevel} {
  vm.module public @LinearModule {
    vm.global.i32 private @_device_query_0 : i32
    vm.global.ref private @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.global.ref private @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
    vm.rodata private @main_dispatch_0_cuda_nvptx_fb {alignment = 16 : i64, mime_type = "application/x-flatbuffers"} dense<"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vector<6926xi8>
    vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
    vm.rodata private @_utf8_cuda_nvptx_fb_B15B42B96FDBACC {alignment = 1 : i64} "cuda-nvptx-fb"
    vm.initializer {
      %null = vm.const.ref.zero : !vm.ref<!hal.executable>
      %null_0 = vm.const.ref.zero : !vm.buffer
      %c4 = vm.const.i32 4
      %c7 = vm.const.i32 7
      %zero = vm.const.i32.zero
      %c1 = vm.const.i32 1
      %zero_1 = vm.const.i64.zero
      %c-1 = vm.const.i64 -1
      %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
      %_utf8_cuda_nvptx_fb_B15B42B96FDBACC = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
      %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
      %2 = vm.and.i32 %1, %c1 : i32
      %3 = vm.select.i32 %0#0, %2, %zero : i32
      %ref_2 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero, [(%zero, %c7, %c1), (%c1, %c7, %zero)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
      %ref_3 = vm.call.variadic @hal.pipeline_layout.create(%ref, %c4, [%ref_2]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
      %4 = vm.select.i64 %3, %zero_1, %c-1 : i64
      %5 = vm.trunc.i64.i32 %4 : i64 -> i32
      vm.global.store.i32 %3, @_device_query_0 : i32
      vm.global.store.ref %ref_3, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      vm.br_table %5 {
        default: ^bb2,
        0: ^bb1
      }
    ^bb1:  // pred: ^bb0
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %main_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @main_dispatch_0_cuda_nvptx_fb : !vm.buffer
      %ref_4 = vm.call.variadic @hal.executable.create(%ref, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC, %main_dispatch_0_cuda_nvptx_fb, %null_0, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
      vm.br ^bb3(%ref_4 : !vm.ref<!hal.executable>)
    ^bb2:  // pred: ^bb0
      vm.br ^bb3(%null : !vm.ref<!hal.executable>)
    ^bb3(%6: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
      vm.global.store.ref %6, @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
      vm.return
    }
    vm.import private @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects}
    vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
    vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
    vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
    vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
    vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer>
    vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
    vm.import private @hal.command_buffer.push_constants(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %offset : i32, %values : i32 ...)
    vm.import private @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32)
    vm.import private @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects}
    vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
    vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
    vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
    vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
    vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects}
    vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
    vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
    vm.import private @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects}
    vm.rodata private @_utf8_input_0_5FD512E67BEFDEEC {alignment = 1 : i64} "input 0"
    vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
    vm.func private @main(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
      %c13 = vm.const.i32 13
      %c28 = vm.const.i32 28
      %c3 = vm.const.i32 3
      %c17 = vm.const.i32 17
      %c32 = vm.const.i32 32
      %c48 = vm.const.i32 48
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %c3075 = vm.const.i32 3075
      %c16 = vm.const.i32 16
      %zero = vm.const.i32.zero
      %c32_0 = vm.const.i64 32
      %c128 = vm.const.i64 128
      %c553648160 = vm.const.i32 553648160
      %c1 = vm.const.i32 1
      %zero_1 = vm.const.i64.zero
      %c4 = vm.const.i64 4
      %c-1 = vm.const.i64 -1
      %c-1_2 = vm.const.i32 -1
      %c1_3 = vm.const.i64 1
      %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %_executable_main_dispatch_0 = vm.global.load.ref @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
      %0 = vm.call @hal.buffer_view.dim(%arg0, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %1 = vm.call @hal.buffer_view.dim(%arg0, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1, [%0, %1]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %2 = vm.mul.i64 %0, %c4 : i64
      %3 = vm.mul.i64 %2, %1 : i64
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %ref_6 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      %ref_7 = vm.call @hal.device.queue.alloca(%ref_4, %c-1, %null, %ref_6, %zero, %c48, %c3075, %3) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
      %4 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      %5 = vm.trunc.i64.i32 %0 : i64 -> i32
      %6 = vm.shr.i64.u %0, %c32 : i64
      %7 = vm.trunc.i64.i32 %6 : i64 -> i32
      %8 = vm.trunc.i64.i32 %1 : i64 -> i32
      %9 = vm.shr.i64.u %1, %c32 : i64
      %10 = vm.trunc.i64.i32 %9 : i64 -> i32
      %ref_8 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
      %11 = vm.select.i64 %_device_query_0, %zero_1, %c-1 : i64
      %12 = vm.trunc.i64.i32 %11 : i64 -> i32
      vm.br_table %12 {
        default: ^bb2,
        0: ^bb1
      }
    ^bb1:  // pred: ^bb0
      vm.call.variadic @hal.command_buffer.push_constants(%ref_8, %_pipeline_layout_0, %zero, [%5, %7, %8, %10]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, i32 ...)
      vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_8, %_pipeline_layout_0, %zero, [(%zero, %zero, %ref, %zero_1, %3), (%c1, %zero, %ref_7, %zero_1, %3)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      %slt = vm.cmp.lt.i64.s %zero_1, %1 : i64
      %13 = vm.xor.i32 %slt, %c1 : i32
      %14 = vm.sub.i64 %zero_1, %1 : i64
      %15 = vm.sub.i64 %1, %c1_3 : i64
      %16 = vm.select.i64 %13, %14, %15 : i64
      %17 = vm.div.i64.s %16, %c128 : i64
      %18 = vm.sub.i64 %zero_1, %17 : i64
      %19 = vm.add.i64 %17, %c1_3 : i64
      %20 = vm.select.i64 %13, %18, %19 : i64
      %slt_9 = vm.cmp.lt.i64.s %zero_1, %0 : i64
      %21 = vm.xor.i32 %slt_9, %c1 : i32
      %22 = vm.sub.i64 %zero_1, %0 : i64
      %23 = vm.sub.i64 %0, %c1_3 : i64
      %24 = vm.select.i64 %21, %22, %23 : i64
      %25 = vm.div.i64.s %24, %c32_0 : i64
      %26 = vm.sub.i64 %zero_1, %25 : i64
      %27 = vm.add.i64 %25, %c1_3 : i64
      %28 = vm.select.i64 %21, %26, %27 : i64
      %29 = vm.mul.i64 %20, %28 : i64
      %30 = vm.trunc.i64.i32 %29 : i64 -> i32
      vm.call @hal.command_buffer.dispatch(%ref_8, %_executable_main_dispatch_0, %zero, %30, %c1, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
      vm.br ^bb2
    ^bb2:  // 2 preds: ^bb0, ^bb1
      vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
      %ref_10 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      %31 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1, %null, %ref_10, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
      %32 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_10]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_br %32, ^bb4, ^bb3
    ^bb3:  // pred: ^bb2
      %ref_11 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_1, %3, %c553648160, %c1, [%0, %1]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_11 : !vm.ref<!hal.buffer_view>
    ^bb4:  // pred: ^bb2
      vm.fail %32, "failed to wait on timepoint"
    }
    vm.export @main attributes {iree.abi.stub}
  }
}


// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda], vm.toplevel} {
  vm.module public @LinearModule {
    vm.global.i32 private @_device_query_0 : i32
    vm.global.ref private @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.global.ref private @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
    vm.rodata private @main_dispatch_0_cuda_nvptx_fb {alignment = 16 : i64, mime_type = "application/x-flatbuffers"} dense<"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vector<6926xi8>
    vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
    vm.rodata private @_utf8_cuda_nvptx_fb_B15B42B96FDBACC {alignment = 1 : i64} "cuda-nvptx-fb"
    vm.initializer {
      %null = vm.const.ref.zero : !vm.ref<!hal.executable>
      %null_0 = vm.const.ref.zero : !vm.buffer
      %c4 = vm.const.i32 4
      %c7 = vm.const.i32 7
      %zero = vm.const.i32.zero
      %c1 = vm.const.i32 1
      %zero_1 = vm.const.i64.zero
      %c-1 = vm.const.i64 -1
      %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
      %_utf8_cuda_nvptx_fb_B15B42B96FDBACC = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
      %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
      %2 = vm.and.i32 %1, %c1 : i32
      %3 = vm.select.i32 %0#0, %2, %zero : i32
      %ref_2 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero, [(%zero, %c7, %c1), (%c1, %c7, %zero)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
      %ref_3 = vm.call.variadic @hal.pipeline_layout.create(%ref, %c4, [%ref_2]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
      %4 = vm.select.i64 %3, %zero_1, %c-1 : i64
      %5 = vm.trunc.i64.i32 %4 : i64 -> i32
      vm.global.store.i32 %3, @_device_query_0 : i32
      vm.global.store.ref %ref_3, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      vm.br_table %5 {
        default: ^bb2,
        0: ^bb1
      }
    ^bb1:  // pred: ^bb0
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %main_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @main_dispatch_0_cuda_nvptx_fb : !vm.buffer
      %ref_4 = vm.call.variadic @hal.executable.create(%ref, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC, %main_dispatch_0_cuda_nvptx_fb, %null_0, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
      vm.br ^bb3(%ref_4 : !vm.ref<!hal.executable>)
    ^bb2:  // pred: ^bb0
      vm.br ^bb3(%null : !vm.ref<!hal.executable>)
    ^bb3(%6: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
      vm.global.store.ref %6, @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
      vm.return
    }
    vm.import private @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects}
    vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
    vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
    vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
    vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
    vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer>
    vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
    vm.import private @hal.command_buffer.push_constants(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %offset : i32, %values : i32 ...)
    vm.import private @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32)
    vm.import private @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects}
    vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
    vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
    vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
    vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
    vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects}
    vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
    vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
    vm.import private @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects}
    vm.rodata private @_utf8_input_0_5FD512E67BEFDEEC {alignment = 1 : i64} "input 0"
    vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
    vm.func private @main(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
      %c13 = vm.const.i32 13
      %c28 = vm.const.i32 28
      %c3 = vm.const.i32 3
      %c17 = vm.const.i32 17
      %c32 = vm.const.i32 32
      %c48 = vm.const.i32 48
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %c3075 = vm.const.i32 3075
      %c16 = vm.const.i32 16
      %zero = vm.const.i32.zero
      %c32_0 = vm.const.i64 32
      %c128 = vm.const.i64 128
      %c553648160 = vm.const.i32 553648160
      %c1 = vm.const.i32 1
      %zero_1 = vm.const.i64.zero
      %c4 = vm.const.i64 4
      %c-1 = vm.const.i64 -1
      %c-1_2 = vm.const.i32 -1
      %c1_3 = vm.const.i64 1
      %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %_executable_main_dispatch_0 = vm.global.load.ref @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
      %0 = vm.call @hal.buffer_view.dim(%arg0, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %1 = vm.call @hal.buffer_view.dim(%arg0, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1, [%0, %1]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %2 = vm.mul.i64 %0, %c4 : i64
      %3 = vm.mul.i64 %2, %1 : i64
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %ref_6 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      %ref_7 = vm.call @hal.device.queue.alloca(%ref_4, %c-1, %null, %ref_6, %zero, %c48, %c3075, %3) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
      %4 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      %5 = vm.trunc.i64.i32 %0 : i64 -> i32
      %6 = vm.shr.i64.u %0, %c32 : i64
      %7 = vm.trunc.i64.i32 %6 : i64 -> i32
      %8 = vm.trunc.i64.i32 %1 : i64 -> i32
      %9 = vm.shr.i64.u %1, %c32 : i64
      %10 = vm.trunc.i64.i32 %9 : i64 -> i32
      %ref_8 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
      %11 = vm.select.i64 %_device_query_0, %zero_1, %c-1 : i64
      %12 = vm.trunc.i64.i32 %11 : i64 -> i32
      vm.br_table %12 {
        default: ^bb2,
        0: ^bb1
      }
    ^bb1:  // pred: ^bb0
      vm.call.variadic @hal.command_buffer.push_constants(%ref_8, %_pipeline_layout_0, %zero, [%5, %7, %8, %10]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, i32 ...)
      vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_8, %_pipeline_layout_0, %zero, [(%zero, %zero, %ref, %zero_1, %3), (%c1, %zero, %ref_7, %zero_1, %3)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      %slt = vm.cmp.lt.i64.s %zero_1, %1 : i64
      %13 = vm.xor.i32 %slt, %c1 : i32
      %14 = vm.sub.i64 %zero_1, %1 : i64
      %15 = vm.sub.i64 %1, %c1_3 : i64
      %16 = vm.select.i64 %13, %14, %15 : i64
      %17 = vm.div.i64.s %16, %c128 : i64
      %18 = vm.sub.i64 %zero_1, %17 : i64
      %19 = vm.add.i64 %17, %c1_3 : i64
      %20 = vm.select.i64 %13, %18, %19 : i64
      %slt_9 = vm.cmp.lt.i64.s %zero_1, %0 : i64
      %21 = vm.xor.i32 %slt_9, %c1 : i32
      %22 = vm.sub.i64 %zero_1, %0 : i64
      %23 = vm.sub.i64 %0, %c1_3 : i64
      %24 = vm.select.i64 %21, %22, %23 : i64
      %25 = vm.div.i64.s %24, %c32_0 : i64
      %26 = vm.sub.i64 %zero_1, %25 : i64
      %27 = vm.add.i64 %25, %c1_3 : i64
      %28 = vm.select.i64 %21, %26, %27 : i64
      %29 = vm.mul.i64 %20, %28 : i64
      %30 = vm.trunc.i64.i32 %29 : i64 -> i32
      vm.call @hal.command_buffer.dispatch(%ref_8, %_executable_main_dispatch_0, %zero, %30, %c1, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
      vm.br ^bb2
    ^bb2:  // 2 preds: ^bb0, ^bb1
      vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
      %ref_10 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      %31 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1, %null, %ref_10, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
      %32 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_10]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_br %32, ^bb4, ^bb3
    ^bb3:  // pred: ^bb2
      %ref_11 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_1, %3, %c553648160, %c1, [%0, %1]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_11 : !vm.ref<!hal.buffer_view>
    ^bb4:  // pred: ^bb2
      vm.fail %32, "failed to wait on timepoint"
    }
    vm.export @main attributes {iree.abi.stub}
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda], vm.toplevel} {
  vm.module public @LinearModule {
    vm.global.i32 private @_device_query_0 : i32
    vm.global.ref private @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.global.ref private @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
    vm.rodata private @main_dispatch_0_cuda_nvptx_fb {alignment = 16 : i64, mime_type = "application/x-flatbuffers"} dense<"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vector<6926xi8>
    vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
    vm.rodata private @_utf8_cuda_nvptx_fb_B15B42B96FDBACC {alignment = 1 : i64} "cuda-nvptx-fb"
    vm.initializer {
      %null = vm.const.ref.zero : !vm.ref<!hal.executable>
      %null_0 = vm.const.ref.zero : !vm.buffer
      %c4 = vm.const.i32 4
      %c7 = vm.const.i32 7
      %zero = vm.const.i32.zero
      %c1 = vm.const.i32 1
      %zero_1 = vm.const.i64.zero
      %c-1 = vm.const.i64 -1
      %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
      %_utf8_cuda_nvptx_fb_B15B42B96FDBACC = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
      %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
      %2 = vm.and.i32 %1, %c1 : i32
      %3 = vm.select.i32 %0#0, %2, %zero : i32
      %ref_2 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero, [(%zero, %c7, %c1), (%c1, %c7, %zero)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
      %ref_3 = vm.call.variadic @hal.pipeline_layout.create(%ref, %c4, [%ref_2]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
      %4 = vm.select.i64 %3, %zero_1, %c-1 : i64
      %5 = vm.trunc.i64.i32 %4 : i64 -> i32
      vm.global.store.i32 %3, @_device_query_0 : i32
      vm.global.store.ref %ref_3, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      vm.br_table %5 {
        default: ^bb2,
        0: ^bb1
      }
    ^bb1:  // pred: ^bb0
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %main_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @main_dispatch_0_cuda_nvptx_fb : !vm.buffer
      %ref_4 = vm.call.variadic @hal.executable.create(%ref, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC, %main_dispatch_0_cuda_nvptx_fb, %null_0, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
      vm.br ^bb3(%ref_4 : !vm.ref<!hal.executable>)
    ^bb2:  // pred: ^bb0
      vm.br ^bb3(%null : !vm.ref<!hal.executable>)
    ^bb3(%6: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
      vm.global.store.ref %6, @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
      vm.return
    }
    vm.import private @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects}
    vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
    vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
    vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
    vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
    vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer>
    vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
    vm.import private @hal.command_buffer.push_constants(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %offset : i32, %values : i32 ...)
    vm.import private @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32)
    vm.import private @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects}
    vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
    vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
    vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
    vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
    vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects}
    vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
    vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
    vm.import private @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects}
    vm.rodata private @_utf8_input_0_5FD512E67BEFDEEC {alignment = 1 : i64} "input 0"
    vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
    vm.func private @main(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
      %c13 = vm.const.i32 13
      %c28 = vm.const.i32 28
      %c3 = vm.const.i32 3
      %c17 = vm.const.i32 17
      %c32 = vm.const.i32 32
      %c48 = vm.const.i32 48
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %c3075 = vm.const.i32 3075
      %c16 = vm.const.i32 16
      %zero = vm.const.i32.zero
      %c32_0 = vm.const.i64 32
      %c128 = vm.const.i64 128
      %c553648160 = vm.const.i32 553648160
      %c1 = vm.const.i32 1
      %zero_1 = vm.const.i64.zero
      %c4 = vm.const.i64 4
      %c-1 = vm.const.i64 -1
      %c-1_2 = vm.const.i32 -1
      %c1_3 = vm.const.i64 1
      %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %_executable_main_dispatch_0 = vm.global.load.ref @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
      %0 = vm.call @hal.buffer_view.dim(%arg0, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %1 = vm.call @hal.buffer_view.dim(%arg0, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1, [%0, %1]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %2 = vm.mul.i64 %0, %c4 : i64
      %3 = vm.mul.i64 %2, %1 : i64
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %ref_6 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      %ref_7 = vm.call @hal.device.queue.alloca(%ref_4, %c-1, %null, %ref_6, %zero, %c48, %c3075, %3) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
      %4 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      %5 = vm.trunc.i64.i32 %0 : i64 -> i32
      %6 = vm.shr.i64.u %0, %c32 : i64
      %7 = vm.trunc.i64.i32 %6 : i64 -> i32
      %8 = vm.trunc.i64.i32 %1 : i64 -> i32
      %9 = vm.shr.i64.u %1, %c32 : i64
      %10 = vm.trunc.i64.i32 %9 : i64 -> i32
      %ref_8 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
      %11 = vm.select.i64 %_device_query_0, %zero_1, %c-1 : i64
      %12 = vm.trunc.i64.i32 %11 : i64 -> i32
      vm.br_table %12 {
        default: ^bb2,
        0: ^bb1
      }
    ^bb1:  // pred: ^bb0
      vm.call.variadic @hal.command_buffer.push_constants(%ref_8, %_pipeline_layout_0, %zero, [%5, %7, %8, %10]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, i32 ...)
      vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_8, %_pipeline_layout_0, %zero, [(%zero, %zero, %ref, %zero_1, %3), (%c1, %zero, %ref_7, %zero_1, %3)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      %slt = vm.cmp.lt.i64.s %zero_1, %1 : i64
      %13 = vm.xor.i32 %slt, %c1 : i32
      %14 = vm.sub.i64 %zero_1, %1 : i64
      %15 = vm.sub.i64 %1, %c1_3 : i64
      %16 = vm.select.i64 %13, %14, %15 : i64
      %17 = vm.div.i64.s %16, %c128 : i64
      %18 = vm.sub.i64 %zero_1, %17 : i64
      %19 = vm.add.i64 %17, %c1_3 : i64
      %20 = vm.select.i64 %13, %18, %19 : i64
      %slt_9 = vm.cmp.lt.i64.s %zero_1, %0 : i64
      %21 = vm.xor.i32 %slt_9, %c1 : i32
      %22 = vm.sub.i64 %zero_1, %0 : i64
      %23 = vm.sub.i64 %0, %c1_3 : i64
      %24 = vm.select.i64 %21, %22, %23 : i64
      %25 = vm.div.i64.s %24, %c32_0 : i64
      %26 = vm.sub.i64 %zero_1, %25 : i64
      %27 = vm.add.i64 %25, %c1_3 : i64
      %28 = vm.select.i64 %21, %26, %27 : i64
      %29 = vm.mul.i64 %20, %28 : i64
      %30 = vm.trunc.i64.i32 %29 : i64 -> i32
      vm.call @hal.command_buffer.dispatch(%ref_8, %_executable_main_dispatch_0, %zero, %30, %c1, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
      vm.br ^bb2
    ^bb2:  // 2 preds: ^bb0, ^bb1
      vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
      %ref_10 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      %31 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1, %null, %ref_10, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
      %32 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_10]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_br %32, ^bb4, ^bb3
    ^bb3:  // pred: ^bb2
      %ref_11 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_1, %3, %c553648160, %c1, [%0, %1]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_11 : !vm.ref<!hal.buffer_view>
    ^bb4:  // pred: ^bb2
      vm.fail %32, "failed to wait on timepoint"
    }
    vm.export @main attributes {iree.abi.stub}
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::VM::GlobalInitializationPass (iree-vm-global-initialization) //----- //
vm.module public @LinearModule {
  vm.global.i32 private mutable @_device_query_0 : i32
  vm.global.ref private mutable @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
  vm.global.ref private mutable @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
  vm.rodata private @main_dispatch_0_cuda_nvptx_fb {alignment = 16 : i64, mime_type = "application/x-flatbuffers"} dense<"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vector<6926xi8>
  vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
  vm.rodata private @_utf8_cuda_nvptx_fb_B15B42B96FDBACC {alignment = 1 : i64} "cuda-nvptx-fb"
  vm.import private @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects}
  vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
  vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
  vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
  vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
  vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
  vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer>
  vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
  vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
  vm.import private @hal.command_buffer.push_constants(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %offset : i32, %values : i32 ...)
  vm.import private @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32)
  vm.import private @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects}
  vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
  vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
  vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
  vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
  vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects}
  vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
  vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
  vm.import private @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects}
  vm.rodata private @_utf8_input_0_5FD512E67BEFDEEC {alignment = 1 : i64} "input 0"
  vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
  vm.func private @main(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
    %c13 = vm.const.i32 13
    %c28 = vm.const.i32 28
    %c3 = vm.const.i32 3
    %c17 = vm.const.i32 17
    %c32 = vm.const.i32 32
    %c48 = vm.const.i32 48
    %null = vm.const.ref.zero : !vm.ref<!hal.fence>
    %c3075 = vm.const.i32 3075
    %c16 = vm.const.i32 16
    %zero = vm.const.i32.zero
    %c32_0 = vm.const.i64 32
    %c128 = vm.const.i64 128
    %c553648160 = vm.const.i32 553648160
    %c1 = vm.const.i32 1
    %zero_1 = vm.const.i64.zero
    %c4 = vm.const.i64 4
    %c-1 = vm.const.i64 -1
    %c-1_2 = vm.const.i32 -1
    %c1_3 = vm.const.i64 1
    %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %_executable_main_dispatch_0 = vm.global.load.ref @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
    %0 = vm.call @hal.buffer_view.dim(%arg0, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %1 = vm.call @hal.buffer_view.dim(%arg0, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1, [%0, %1]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %2 = vm.mul.i64 %0, %c4 : i64
    %3 = vm.mul.i64 %2, %1 : i64
    %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
    vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %ref_6 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    %ref_7 = vm.call @hal.device.queue.alloca(%ref_4, %c-1, %null, %ref_6, %zero, %c48, %c3075, %3) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
    %4 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    %5 = vm.trunc.i64.i32 %0 : i64 -> i32
    %6 = vm.shr.i64.u %0, %c32 : i64
    %7 = vm.trunc.i64.i32 %6 : i64 -> i32
    %8 = vm.trunc.i64.i32 %1 : i64 -> i32
    %9 = vm.shr.i64.u %1, %c32 : i64
    %10 = vm.trunc.i64.i32 %9 : i64 -> i32
    %ref_8 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
    %11 = vm.select.i64 %_device_query_0, %zero_1, %c-1 : i64
    %12 = vm.trunc.i64.i32 %11 : i64 -> i32
    vm.br_table %12 {
      default: ^bb2,
      0: ^bb1
    }
  ^bb1:  // pred: ^bb0
    vm.call.variadic @hal.command_buffer.push_constants(%ref_8, %_pipeline_layout_0, %zero, [%5, %7, %8, %10]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, i32 ...)
    vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_8, %_pipeline_layout_0, %zero, [(%zero, %zero, %ref, %zero_1, %3), (%c1, %zero, %ref_7, %zero_1, %3)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    %slt = vm.cmp.lt.i64.s %zero_1, %1 : i64
    %13 = vm.xor.i32 %slt, %c1 : i32
    %14 = vm.sub.i64 %zero_1, %1 : i64
    %15 = vm.sub.i64 %1, %c1_3 : i64
    %16 = vm.select.i64 %13, %14, %15 : i64
    %17 = vm.div.i64.s %16, %c128 : i64
    %18 = vm.sub.i64 %zero_1, %17 : i64
    %19 = vm.add.i64 %17, %c1_3 : i64
    %20 = vm.select.i64 %13, %18, %19 : i64
    %slt_9 = vm.cmp.lt.i64.s %zero_1, %0 : i64
    %21 = vm.xor.i32 %slt_9, %c1 : i32
    %22 = vm.sub.i64 %zero_1, %0 : i64
    %23 = vm.sub.i64 %0, %c1_3 : i64
    %24 = vm.select.i64 %21, %22, %23 : i64
    %25 = vm.div.i64.s %24, %c32_0 : i64
    %26 = vm.sub.i64 %zero_1, %25 : i64
    %27 = vm.add.i64 %25, %c1_3 : i64
    %28 = vm.select.i64 %21, %26, %27 : i64
    %29 = vm.mul.i64 %20, %28 : i64
    %30 = vm.trunc.i64.i32 %29 : i64 -> i32
    vm.call @hal.command_buffer.dispatch(%ref_8, %_executable_main_dispatch_0, %zero, %30, %c1, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
    vm.br ^bb2
  ^bb2:  // 2 preds: ^bb0, ^bb1
    vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
    vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
    %ref_10 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    %31 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1, %null, %ref_10, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
    %32 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_10]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    vm.cond_br %32, ^bb4, ^bb3
  ^bb3:  // pred: ^bb2
    %ref_11 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_1, %3, %c553648160, %c1, [%0, %1]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
    vm.return %ref_11 : !vm.ref<!hal.buffer_view>
  ^bb4:  // pred: ^bb2
    vm.fail %32, "failed to wait on timepoint"
  }
  vm.export @main attributes {iree.abi.stub}
  vm.export @__init
  vm.func private @__init() {
    %null = vm.const.ref.zero : !vm.ref<!hal.executable>
    %null_0 = vm.const.ref.zero : !vm.buffer
    %c4 = vm.const.i32 4
    %c7 = vm.const.i32 7
    %zero = vm.const.i32.zero
    %c1 = vm.const.i32 1
    %zero_1 = vm.const.i64.zero
    %c-1 = vm.const.i64 -1
    %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
    %_utf8_cuda_nvptx_fb_B15B42B96FDBACC = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
    %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
    %2 = vm.and.i32 %1, %c1 : i32
    %3 = vm.select.i32 %0#0, %2, %zero : i32
    %ref_2 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero, [(%zero, %c7, %c1), (%c1, %c7, %zero)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
    %ref_3 = vm.call.variadic @hal.pipeline_layout.create(%ref, %c4, [%ref_2]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
    %4 = vm.select.i64 %3, %zero_1, %c-1 : i64
    %5 = vm.trunc.i64.i32 %4 : i64 -> i32
    vm.global.store.i32 %3, @_device_query_0 : i32
    vm.global.store.ref %ref_3, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.br_table %5 {
      default: ^bb2,
      0: ^bb1
    }
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %main_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @main_dispatch_0_cuda_nvptx_fb : !vm.buffer
    %ref_4 = vm.call.variadic @hal.executable.create(%ref, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC, %main_dispatch_0_cuda_nvptx_fb, %null_0, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
    vm.br ^bb3(%ref_4 : !vm.ref<!hal.executable>)
  ^bb2:  // pred: ^bb0
    vm.br ^bb3(%null : !vm.ref<!hal.executable>)
  ^bb3(%6: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
    vm.global.store.ref %6, @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
    vm.br ^bb4
  ^bb4:  // pred: ^bb3
    vm.return
  }
  vm.export @__deinit
  vm.func private @__deinit() {
    vm.return
  }
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda], vm.toplevel} {
  vm.module public @LinearModule {
    vm.global.i32 private mutable @_device_query_0 : i32
    vm.global.ref private mutable @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.global.ref private mutable @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
    vm.rodata private @main_dispatch_0_cuda_nvptx_fb {alignment = 16 : i64, mime_type = "application/x-flatbuffers"} dense<"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vector<6926xi8>
    vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
    vm.rodata private @_utf8_cuda_nvptx_fb_B15B42B96FDBACC {alignment = 1 : i64} "cuda-nvptx-fb"
    vm.import private @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects}
    vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
    vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
    vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
    vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
    vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer>
    vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
    vm.import private @hal.command_buffer.push_constants(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %offset : i32, %values : i32 ...)
    vm.import private @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32)
    vm.import private @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects}
    vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
    vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
    vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
    vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
    vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects}
    vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
    vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
    vm.import private @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects}
    vm.rodata private @_utf8_input_0_5FD512E67BEFDEEC {alignment = 1 : i64} "input 0"
    vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
    vm.func private @main(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
      %c13 = vm.const.i32 13
      %c28 = vm.const.i32 28
      %c3 = vm.const.i32 3
      %c17 = vm.const.i32 17
      %c32 = vm.const.i32 32
      %c48 = vm.const.i32 48
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %c3075 = vm.const.i32 3075
      %c16 = vm.const.i32 16
      %zero = vm.const.i32.zero
      %c32_0 = vm.const.i64 32
      %c128 = vm.const.i64 128
      %c553648160 = vm.const.i32 553648160
      %c1 = vm.const.i32 1
      %zero_1 = vm.const.i64.zero
      %c4 = vm.const.i64 4
      %c-1 = vm.const.i64 -1
      %c-1_2 = vm.const.i32 -1
      %c1_3 = vm.const.i64 1
      %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %_executable_main_dispatch_0 = vm.global.load.ref @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
      %0 = vm.call @hal.buffer_view.dim(%arg0, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %1 = vm.call @hal.buffer_view.dim(%arg0, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1, [%0, %1]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %2 = vm.mul.i64 %0, %c4 : i64
      %3 = vm.mul.i64 %2, %1 : i64
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %ref_6 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      %ref_7 = vm.call @hal.device.queue.alloca(%ref_4, %c-1, %null, %ref_6, %zero, %c48, %c3075, %3) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
      %4 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      %5 = vm.trunc.i64.i32 %0 : i64 -> i32
      %6 = vm.shr.i64.u %0, %c32 : i64
      %7 = vm.trunc.i64.i32 %6 : i64 -> i32
      %8 = vm.trunc.i64.i32 %1 : i64 -> i32
      %9 = vm.shr.i64.u %1, %c32 : i64
      %10 = vm.trunc.i64.i32 %9 : i64 -> i32
      %ref_8 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
      %11 = vm.select.i64 %_device_query_0, %zero_1, %c-1 : i64
      %12 = vm.trunc.i64.i32 %11 : i64 -> i32
      vm.br_table %12 {
        default: ^bb2,
        0: ^bb1
      }
    ^bb1:  // pred: ^bb0
      vm.call.variadic @hal.command_buffer.push_constants(%ref_8, %_pipeline_layout_0, %zero, [%5, %7, %8, %10]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, i32 ...)
      vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_8, %_pipeline_layout_0, %zero, [(%zero, %zero, %ref, %zero_1, %3), (%c1, %zero, %ref_7, %zero_1, %3)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      %slt = vm.cmp.lt.i64.s %zero_1, %1 : i64
      %13 = vm.xor.i32 %slt, %c1 : i32
      %14 = vm.sub.i64 %zero_1, %1 : i64
      %15 = vm.sub.i64 %1, %c1_3 : i64
      %16 = vm.select.i64 %13, %14, %15 : i64
      %17 = vm.div.i64.s %16, %c128 : i64
      %18 = vm.sub.i64 %zero_1, %17 : i64
      %19 = vm.add.i64 %17, %c1_3 : i64
      %20 = vm.select.i64 %13, %18, %19 : i64
      %slt_9 = vm.cmp.lt.i64.s %zero_1, %0 : i64
      %21 = vm.xor.i32 %slt_9, %c1 : i32
      %22 = vm.sub.i64 %zero_1, %0 : i64
      %23 = vm.sub.i64 %0, %c1_3 : i64
      %24 = vm.select.i64 %21, %22, %23 : i64
      %25 = vm.div.i64.s %24, %c32_0 : i64
      %26 = vm.sub.i64 %zero_1, %25 : i64
      %27 = vm.add.i64 %25, %c1_3 : i64
      %28 = vm.select.i64 %21, %26, %27 : i64
      %29 = vm.mul.i64 %20, %28 : i64
      %30 = vm.trunc.i64.i32 %29 : i64 -> i32
      vm.call @hal.command_buffer.dispatch(%ref_8, %_executable_main_dispatch_0, %zero, %30, %c1, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
      vm.br ^bb2
    ^bb2:  // 2 preds: ^bb0, ^bb1
      vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
      %ref_10 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      %31 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1, %null, %ref_10, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
      %32 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_10]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_br %32, ^bb4, ^bb3
    ^bb3:  // pred: ^bb2
      %ref_11 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_1, %3, %c553648160, %c1, [%0, %1]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_11 : !vm.ref<!hal.buffer_view>
    ^bb4:  // pred: ^bb2
      vm.fail %32, "failed to wait on timepoint"
    }
    vm.export @main attributes {iree.abi.stub}
    vm.export @__init
    vm.func private @__init() {
      %null = vm.const.ref.zero : !vm.ref<!hal.executable>
      %null_0 = vm.const.ref.zero : !vm.buffer
      %c4 = vm.const.i32 4
      %c7 = vm.const.i32 7
      %zero = vm.const.i32.zero
      %c1 = vm.const.i32 1
      %zero_1 = vm.const.i64.zero
      %c-1 = vm.const.i64 -1
      %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
      %_utf8_cuda_nvptx_fb_B15B42B96FDBACC = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
      %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
      %2 = vm.and.i32 %1, %c1 : i32
      %3 = vm.select.i32 %0#0, %2, %zero : i32
      %ref_2 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero, [(%zero, %c7, %c1), (%c1, %c7, %zero)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
      %ref_3 = vm.call.variadic @hal.pipeline_layout.create(%ref, %c4, [%ref_2]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
      %4 = vm.select.i64 %3, %zero_1, %c-1 : i64
      %5 = vm.trunc.i64.i32 %4 : i64 -> i32
      vm.global.store.i32 %3, @_device_query_0 : i32
      vm.global.store.ref %ref_3, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      vm.br_table %5 {
        default: ^bb2,
        0: ^bb1
      }
    ^bb1:  // pred: ^bb0
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %main_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @main_dispatch_0_cuda_nvptx_fb : !vm.buffer
      %ref_4 = vm.call.variadic @hal.executable.create(%ref, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC, %main_dispatch_0_cuda_nvptx_fb, %null_0, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
      vm.br ^bb3(%ref_4 : !vm.ref<!hal.executable>)
    ^bb2:  // pred: ^bb0
      vm.br ^bb3(%null : !vm.ref<!hal.executable>)
    ^bb3(%6: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
      vm.global.store.ref %6, @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
      vm.return
    }
    vm.export @__deinit
    vm.func private @__deinit() {
      vm.return
    }
  }
}


// -----// IR Dump After CSE (cse) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda], vm.toplevel} {
  vm.module public @LinearModule {
    vm.global.i32 private mutable @_device_query_0 : i32
    vm.global.ref private mutable @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.global.ref private mutable @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
    vm.rodata private @main_dispatch_0_cuda_nvptx_fb {alignment = 16 : i64, mime_type = "application/x-flatbuffers"} dense<"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vector<6926xi8>
    vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
    vm.rodata private @_utf8_cuda_nvptx_fb_B15B42B96FDBACC {alignment = 1 : i64} "cuda-nvptx-fb"
    vm.import private @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects}
    vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
    vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
    vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
    vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
    vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer>
    vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
    vm.import private @hal.command_buffer.push_constants(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %offset : i32, %values : i32 ...)
    vm.import private @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32)
    vm.import private @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects}
    vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
    vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
    vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
    vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
    vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects}
    vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
    vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
    vm.import private @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects}
    vm.rodata private @_utf8_input_0_5FD512E67BEFDEEC {alignment = 1 : i64} "input 0"
    vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
    vm.func private @main(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
      %c13 = vm.const.i32 13
      %c28 = vm.const.i32 28
      %c3 = vm.const.i32 3
      %c17 = vm.const.i32 17
      %c32 = vm.const.i32 32
      %c48 = vm.const.i32 48
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %c3075 = vm.const.i32 3075
      %c16 = vm.const.i32 16
      %zero = vm.const.i32.zero
      %c32_0 = vm.const.i64 32
      %c128 = vm.const.i64 128
      %c553648160 = vm.const.i32 553648160
      %c1 = vm.const.i32 1
      %zero_1 = vm.const.i64.zero
      %c4 = vm.const.i64 4
      %c-1 = vm.const.i64 -1
      %c-1_2 = vm.const.i32 -1
      %c1_3 = vm.const.i64 1
      %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %_executable_main_dispatch_0 = vm.global.load.ref @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
      %0 = vm.call @hal.buffer_view.dim(%arg0, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %1 = vm.call @hal.buffer_view.dim(%arg0, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1, [%0, %1]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %2 = vm.mul.i64 %0, %c4 : i64
      %3 = vm.mul.i64 %2, %1 : i64
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %ref_6 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      %ref_7 = vm.call @hal.device.queue.alloca(%ref_4, %c-1, %null, %ref_6, %zero, %c48, %c3075, %3) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
      %4 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      %5 = vm.trunc.i64.i32 %0 : i64 -> i32
      %6 = vm.shr.i64.u %0, %c32 : i64
      %7 = vm.trunc.i64.i32 %6 : i64 -> i32
      %8 = vm.trunc.i64.i32 %1 : i64 -> i32
      %9 = vm.shr.i64.u %1, %c32 : i64
      %10 = vm.trunc.i64.i32 %9 : i64 -> i32
      %ref_8 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
      %11 = vm.select.i64 %_device_query_0, %zero_1, %c-1 : i64
      %12 = vm.trunc.i64.i32 %11 : i64 -> i32
      vm.br_table %12 {
        default: ^bb2,
        0: ^bb1
      }
    ^bb1:  // pred: ^bb0
      vm.call.variadic @hal.command_buffer.push_constants(%ref_8, %_pipeline_layout_0, %zero, [%5, %7, %8, %10]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, i32 ...)
      vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_8, %_pipeline_layout_0, %zero, [(%zero, %zero, %ref, %zero_1, %3), (%c1, %zero, %ref_7, %zero_1, %3)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      %slt = vm.cmp.lt.i64.s %zero_1, %1 : i64
      %13 = vm.xor.i32 %slt, %c1 : i32
      %14 = vm.sub.i64 %zero_1, %1 : i64
      %15 = vm.sub.i64 %1, %c1_3 : i64
      %16 = vm.select.i64 %13, %14, %15 : i64
      %17 = vm.div.i64.s %16, %c128 : i64
      %18 = vm.sub.i64 %zero_1, %17 : i64
      %19 = vm.add.i64 %17, %c1_3 : i64
      %20 = vm.select.i64 %13, %18, %19 : i64
      %slt_9 = vm.cmp.lt.i64.s %zero_1, %0 : i64
      %21 = vm.xor.i32 %slt_9, %c1 : i32
      %22 = vm.sub.i64 %zero_1, %0 : i64
      %23 = vm.sub.i64 %0, %c1_3 : i64
      %24 = vm.select.i64 %21, %22, %23 : i64
      %25 = vm.div.i64.s %24, %c32_0 : i64
      %26 = vm.sub.i64 %zero_1, %25 : i64
      %27 = vm.add.i64 %25, %c1_3 : i64
      %28 = vm.select.i64 %21, %26, %27 : i64
      %29 = vm.mul.i64 %20, %28 : i64
      %30 = vm.trunc.i64.i32 %29 : i64 -> i32
      vm.call @hal.command_buffer.dispatch(%ref_8, %_executable_main_dispatch_0, %zero, %30, %c1, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
      vm.br ^bb2
    ^bb2:  // 2 preds: ^bb0, ^bb1
      vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
      %ref_10 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      %31 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1, %null, %ref_10, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
      %32 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_10]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_br %32, ^bb4, ^bb3
    ^bb3:  // pred: ^bb2
      %ref_11 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_1, %3, %c553648160, %c1, [%0, %1]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_11 : !vm.ref<!hal.buffer_view>
    ^bb4:  // pred: ^bb2
      vm.fail %32, "failed to wait on timepoint"
    }
    vm.export @main attributes {iree.abi.stub}
    vm.export @__init
    vm.func private @__init() {
      %null = vm.const.ref.zero : !vm.ref<!hal.executable>
      %null_0 = vm.const.ref.zero : !vm.buffer
      %c4 = vm.const.i32 4
      %c7 = vm.const.i32 7
      %zero = vm.const.i32.zero
      %c1 = vm.const.i32 1
      %zero_1 = vm.const.i64.zero
      %c-1 = vm.const.i64 -1
      %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
      %_utf8_cuda_nvptx_fb_B15B42B96FDBACC = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
      %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
      %2 = vm.and.i32 %1, %c1 : i32
      %3 = vm.select.i32 %0#0, %2, %zero : i32
      %ref_2 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero, [(%zero, %c7, %c1), (%c1, %c7, %zero)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
      %ref_3 = vm.call.variadic @hal.pipeline_layout.create(%ref, %c4, [%ref_2]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
      %4 = vm.select.i64 %3, %zero_1, %c-1 : i64
      %5 = vm.trunc.i64.i32 %4 : i64 -> i32
      vm.global.store.i32 %3, @_device_query_0 : i32
      vm.global.store.ref %ref_3, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      vm.br_table %5 {
        default: ^bb2,
        0: ^bb1
      }
    ^bb1:  // pred: ^bb0
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %main_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @main_dispatch_0_cuda_nvptx_fb : !vm.buffer
      %ref_4 = vm.call.variadic @hal.executable.create(%ref, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC, %main_dispatch_0_cuda_nvptx_fb, %null_0, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
      vm.br ^bb3(%ref_4 : !vm.ref<!hal.executable>)
    ^bb2:  // pred: ^bb0
      vm.br ^bb3(%null : !vm.ref<!hal.executable>)
    ^bb3(%6: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
      vm.global.store.ref %6, @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
      vm.return
    }
    vm.export @__deinit
    vm.func private @__deinit() {
      vm.return
    }
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda], vm.toplevel} {
  vm.module public @LinearModule {
    vm.global.i32 private mutable @_device_query_0 : i32
    vm.global.ref private mutable @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.global.ref private mutable @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
    vm.rodata private @main_dispatch_0_cuda_nvptx_fb {alignment = 16 : i64, mime_type = "application/x-flatbuffers"} dense<"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vector<6926xi8>
    vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
    vm.rodata private @_utf8_cuda_nvptx_fb_B15B42B96FDBACC {alignment = 1 : i64} "cuda-nvptx-fb"
    vm.import private @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects}
    vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
    vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
    vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
    vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
    vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer>
    vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
    vm.import private @hal.command_buffer.push_constants(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %offset : i32, %values : i32 ...)
    vm.import private @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32)
    vm.import private @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects}
    vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
    vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
    vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
    vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
    vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects}
    vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
    vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
    vm.import private @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects}
    vm.rodata private @_utf8_input_0_5FD512E67BEFDEEC {alignment = 1 : i64} "input 0"
    vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
    vm.func private @main(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
      %c13 = vm.const.i32 13
      %c28 = vm.const.i32 28
      %c3 = vm.const.i32 3
      %c17 = vm.const.i32 17
      %c32 = vm.const.i32 32
      %c48 = vm.const.i32 48
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %c3075 = vm.const.i32 3075
      %c16 = vm.const.i32 16
      %zero = vm.const.i32.zero
      %c32_0 = vm.const.i64 32
      %c128 = vm.const.i64 128
      %c553648160 = vm.const.i32 553648160
      %c1 = vm.const.i32 1
      %zero_1 = vm.const.i64.zero
      %c4 = vm.const.i64 4
      %c-1 = vm.const.i64 -1
      %c-1_2 = vm.const.i32 -1
      %c1_3 = vm.const.i64 1
      %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %_executable_main_dispatch_0 = vm.global.load.ref @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
      %0 = vm.call @hal.buffer_view.dim(%arg0, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %1 = vm.call @hal.buffer_view.dim(%arg0, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1, [%0, %1]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %2 = vm.mul.i64 %0, %c4 : i64
      %3 = vm.mul.i64 %2, %1 : i64
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %ref_6 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      %ref_7 = vm.call @hal.device.queue.alloca(%ref_4, %c-1, %null, %ref_6, %zero, %c48, %c3075, %3) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
      %4 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      %5 = vm.trunc.i64.i32 %0 : i64 -> i32
      %6 = vm.shr.i64.u %0, %c32 : i64
      %7 = vm.trunc.i64.i32 %6 : i64 -> i32
      %8 = vm.trunc.i64.i32 %1 : i64 -> i32
      %9 = vm.shr.i64.u %1, %c32 : i64
      %10 = vm.trunc.i64.i32 %9 : i64 -> i32
      %ref_8 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
      %11 = vm.select.i64 %_device_query_0, %zero_1, %c-1 : i64
      %12 = vm.trunc.i64.i32 %11 : i64 -> i32
      vm.br_table %12 {
        default: ^bb2,
        0: ^bb1
      }
    ^bb1:  // pred: ^bb0
      vm.call.variadic @hal.command_buffer.push_constants(%ref_8, %_pipeline_layout_0, %zero, [%5, %7, %8, %10]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, i32 ...)
      vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_8, %_pipeline_layout_0, %zero, [(%zero, %zero, %ref, %zero_1, %3), (%c1, %zero, %ref_7, %zero_1, %3)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      %slt = vm.cmp.lt.i64.s %zero_1, %1 : i64
      %13 = vm.xor.i32 %slt, %c1 : i32
      %14 = vm.sub.i64 %zero_1, %1 : i64
      %15 = vm.sub.i64 %1, %c1_3 : i64
      %16 = vm.select.i64 %13, %14, %15 : i64
      %17 = vm.div.i64.s %16, %c128 : i64
      %18 = vm.sub.i64 %zero_1, %17 : i64
      %19 = vm.add.i64 %17, %c1_3 : i64
      %20 = vm.select.i64 %13, %18, %19 : i64
      %slt_9 = vm.cmp.lt.i64.s %zero_1, %0 : i64
      %21 = vm.xor.i32 %slt_9, %c1 : i32
      %22 = vm.sub.i64 %zero_1, %0 : i64
      %23 = vm.sub.i64 %0, %c1_3 : i64
      %24 = vm.select.i64 %21, %22, %23 : i64
      %25 = vm.div.i64.s %24, %c32_0 : i64
      %26 = vm.sub.i64 %zero_1, %25 : i64
      %27 = vm.add.i64 %25, %c1_3 : i64
      %28 = vm.select.i64 %21, %26, %27 : i64
      %29 = vm.mul.i64 %20, %28 : i64
      %30 = vm.trunc.i64.i32 %29 : i64 -> i32
      vm.call @hal.command_buffer.dispatch(%ref_8, %_executable_main_dispatch_0, %zero, %30, %c1, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
      vm.br ^bb2
    ^bb2:  // 2 preds: ^bb0, ^bb1
      vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
      %ref_10 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      %31 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1, %null, %ref_10, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
      %32 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_10]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_br %32, ^bb4, ^bb3
    ^bb3:  // pred: ^bb2
      %ref_11 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_1, %3, %c553648160, %c1, [%0, %1]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_11 : !vm.ref<!hal.buffer_view>
    ^bb4:  // pred: ^bb2
      vm.fail %32, "failed to wait on timepoint"
    }
    vm.export @main attributes {iree.abi.stub}
    vm.export @__init
    vm.func private @__init() {
      %null = vm.const.ref.zero : !vm.ref<!hal.executable>
      %null_0 = vm.const.ref.zero : !vm.buffer
      %c4 = vm.const.i32 4
      %c7 = vm.const.i32 7
      %zero = vm.const.i32.zero
      %c1 = vm.const.i32 1
      %zero_1 = vm.const.i64.zero
      %c-1 = vm.const.i64 -1
      %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
      %_utf8_cuda_nvptx_fb_B15B42B96FDBACC = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
      %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
      %2 = vm.and.i32 %1, %c1 : i32
      %3 = vm.select.i32 %0#0, %2, %zero : i32
      %ref_2 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero, [(%zero, %c7, %c1), (%c1, %c7, %zero)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
      %ref_3 = vm.call.variadic @hal.pipeline_layout.create(%ref, %c4, [%ref_2]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
      %4 = vm.select.i64 %3, %zero_1, %c-1 : i64
      %5 = vm.trunc.i64.i32 %4 : i64 -> i32
      vm.global.store.i32 %3, @_device_query_0 : i32
      vm.global.store.ref %ref_3, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      vm.br_table %5 {
        default: ^bb2,
        0: ^bb1
      }
    ^bb1:  // pred: ^bb0
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %main_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @main_dispatch_0_cuda_nvptx_fb : !vm.buffer
      %ref_4 = vm.call.variadic @hal.executable.create(%ref, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC, %main_dispatch_0_cuda_nvptx_fb, %null_0, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
      vm.br ^bb3(%ref_4 : !vm.ref<!hal.executable>)
    ^bb2:  // pred: ^bb0
      vm.br ^bb3(%null : !vm.ref<!hal.executable>)
    ^bb3(%6: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
      vm.global.store.ref %6, @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
      vm.return
    }
    vm.export @__deinit
    vm.func private @__deinit() {
      vm.return
    }
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::VM::DropEmptyModuleInitializersPass (iree-vm-drop-empty-module-initializers) //----- //
vm.module public @LinearModule {
  vm.global.i32 private mutable @_device_query_0 : i32
  vm.global.ref private mutable @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
  vm.global.ref private mutable @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
  vm.rodata private @main_dispatch_0_cuda_nvptx_fb {alignment = 16 : i64, mime_type = "application/x-flatbuffers"} dense<"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vector<6926xi8>
  vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
  vm.rodata private @_utf8_cuda_nvptx_fb_B15B42B96FDBACC {alignment = 1 : i64} "cuda-nvptx-fb"
  vm.import private @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects}
  vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
  vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
  vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
  vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
  vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
  vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer>
  vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
  vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
  vm.import private @hal.command_buffer.push_constants(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %offset : i32, %values : i32 ...)
  vm.import private @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32)
  vm.import private @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects}
  vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
  vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
  vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
  vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
  vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects}
  vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
  vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
  vm.import private @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects}
  vm.rodata private @_utf8_input_0_5FD512E67BEFDEEC {alignment = 1 : i64} "input 0"
  vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
  vm.func private @main(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
    %c13 = vm.const.i32 13
    %c28 = vm.const.i32 28
    %c3 = vm.const.i32 3
    %c17 = vm.const.i32 17
    %c32 = vm.const.i32 32
    %c48 = vm.const.i32 48
    %null = vm.const.ref.zero : !vm.ref<!hal.fence>
    %c3075 = vm.const.i32 3075
    %c16 = vm.const.i32 16
    %zero = vm.const.i32.zero
    %c32_0 = vm.const.i64 32
    %c128 = vm.const.i64 128
    %c553648160 = vm.const.i32 553648160
    %c1 = vm.const.i32 1
    %zero_1 = vm.const.i64.zero
    %c4 = vm.const.i64 4
    %c-1 = vm.const.i64 -1
    %c-1_2 = vm.const.i32 -1
    %c1_3 = vm.const.i64 1
    %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %_executable_main_dispatch_0 = vm.global.load.ref @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
    %0 = vm.call @hal.buffer_view.dim(%arg0, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %1 = vm.call @hal.buffer_view.dim(%arg0, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1, [%0, %1]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %2 = vm.mul.i64 %0, %c4 : i64
    %3 = vm.mul.i64 %2, %1 : i64
    %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
    vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %ref_6 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    %ref_7 = vm.call @hal.device.queue.alloca(%ref_4, %c-1, %null, %ref_6, %zero, %c48, %c3075, %3) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
    %4 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    %5 = vm.trunc.i64.i32 %0 : i64 -> i32
    %6 = vm.shr.i64.u %0, %c32 : i64
    %7 = vm.trunc.i64.i32 %6 : i64 -> i32
    %8 = vm.trunc.i64.i32 %1 : i64 -> i32
    %9 = vm.shr.i64.u %1, %c32 : i64
    %10 = vm.trunc.i64.i32 %9 : i64 -> i32
    %ref_8 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
    %11 = vm.select.i64 %_device_query_0, %zero_1, %c-1 : i64
    %12 = vm.trunc.i64.i32 %11 : i64 -> i32
    vm.br_table %12 {
      default: ^bb2,
      0: ^bb1
    }
  ^bb1:  // pred: ^bb0
    vm.call.variadic @hal.command_buffer.push_constants(%ref_8, %_pipeline_layout_0, %zero, [%5, %7, %8, %10]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, i32 ...)
    vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_8, %_pipeline_layout_0, %zero, [(%zero, %zero, %ref, %zero_1, %3), (%c1, %zero, %ref_7, %zero_1, %3)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    %slt = vm.cmp.lt.i64.s %zero_1, %1 : i64
    %13 = vm.xor.i32 %slt, %c1 : i32
    %14 = vm.sub.i64 %zero_1, %1 : i64
    %15 = vm.sub.i64 %1, %c1_3 : i64
    %16 = vm.select.i64 %13, %14, %15 : i64
    %17 = vm.div.i64.s %16, %c128 : i64
    %18 = vm.sub.i64 %zero_1, %17 : i64
    %19 = vm.add.i64 %17, %c1_3 : i64
    %20 = vm.select.i64 %13, %18, %19 : i64
    %slt_9 = vm.cmp.lt.i64.s %zero_1, %0 : i64
    %21 = vm.xor.i32 %slt_9, %c1 : i32
    %22 = vm.sub.i64 %zero_1, %0 : i64
    %23 = vm.sub.i64 %0, %c1_3 : i64
    %24 = vm.select.i64 %21, %22, %23 : i64
    %25 = vm.div.i64.s %24, %c32_0 : i64
    %26 = vm.sub.i64 %zero_1, %25 : i64
    %27 = vm.add.i64 %25, %c1_3 : i64
    %28 = vm.select.i64 %21, %26, %27 : i64
    %29 = vm.mul.i64 %20, %28 : i64
    %30 = vm.trunc.i64.i32 %29 : i64 -> i32
    vm.call @hal.command_buffer.dispatch(%ref_8, %_executable_main_dispatch_0, %zero, %30, %c1, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
    vm.br ^bb2
  ^bb2:  // 2 preds: ^bb0, ^bb1
    vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
    vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
    %ref_10 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    %31 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1, %null, %ref_10, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
    %32 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_10]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    vm.cond_br %32, ^bb4, ^bb3
  ^bb3:  // pred: ^bb2
    %ref_11 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_1, %3, %c553648160, %c1, [%0, %1]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
    vm.return %ref_11 : !vm.ref<!hal.buffer_view>
  ^bb4:  // pred: ^bb2
    vm.fail %32, "failed to wait on timepoint"
  }
  vm.export @main attributes {iree.abi.stub}
  vm.export @__init
  vm.func private @__init() {
    %null = vm.const.ref.zero : !vm.ref<!hal.executable>
    %null_0 = vm.const.ref.zero : !vm.buffer
    %c4 = vm.const.i32 4
    %c7 = vm.const.i32 7
    %zero = vm.const.i32.zero
    %c1 = vm.const.i32 1
    %zero_1 = vm.const.i64.zero
    %c-1 = vm.const.i64 -1
    %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
    %_utf8_cuda_nvptx_fb_B15B42B96FDBACC = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
    %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
    %2 = vm.and.i32 %1, %c1 : i32
    %3 = vm.select.i32 %0#0, %2, %zero : i32
    %ref_2 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero, [(%zero, %c7, %c1), (%c1, %c7, %zero)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
    %ref_3 = vm.call.variadic @hal.pipeline_layout.create(%ref, %c4, [%ref_2]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
    %4 = vm.select.i64 %3, %zero_1, %c-1 : i64
    %5 = vm.trunc.i64.i32 %4 : i64 -> i32
    vm.global.store.i32 %3, @_device_query_0 : i32
    vm.global.store.ref %ref_3, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.br_table %5 {
      default: ^bb2,
      0: ^bb1
    }
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %main_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @main_dispatch_0_cuda_nvptx_fb : !vm.buffer
    %ref_4 = vm.call.variadic @hal.executable.create(%ref, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC, %main_dispatch_0_cuda_nvptx_fb, %null_0, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
    vm.br ^bb3(%ref_4 : !vm.ref<!hal.executable>)
  ^bb2:  // pred: ^bb0
    vm.br ^bb3(%null : !vm.ref<!hal.executable>)
  ^bb3(%6: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
    vm.global.store.ref %6, @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
    vm.return
  }
}

// -----// IR Dump After DropCompilerHints (iree-util-drop-compiler-hints) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda], vm.toplevel} {
  vm.module public @LinearModule {
    vm.global.i32 private mutable @_device_query_0 : i32
    vm.global.ref private mutable @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.global.ref private mutable @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
    vm.rodata private @main_dispatch_0_cuda_nvptx_fb {alignment = 16 : i64, mime_type = "application/x-flatbuffers"} dense<"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vector<6926xi8>
    vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
    vm.rodata private @_utf8_cuda_nvptx_fb_B15B42B96FDBACC {alignment = 1 : i64} "cuda-nvptx-fb"
    vm.import private @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects}
    vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
    vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
    vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
    vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
    vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer>
    vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
    vm.import private @hal.command_buffer.push_constants(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %offset : i32, %values : i32 ...)
    vm.import private @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32)
    vm.import private @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects}
    vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
    vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
    vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
    vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
    vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects}
    vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
    vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
    vm.import private @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects}
    vm.rodata private @_utf8_input_0_5FD512E67BEFDEEC {alignment = 1 : i64} "input 0"
    vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
    vm.func private @main(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
      %c13 = vm.const.i32 13
      %c28 = vm.const.i32 28
      %c3 = vm.const.i32 3
      %c17 = vm.const.i32 17
      %c32 = vm.const.i32 32
      %c48 = vm.const.i32 48
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %c3075 = vm.const.i32 3075
      %c16 = vm.const.i32 16
      %zero = vm.const.i32.zero
      %c32_0 = vm.const.i64 32
      %c128 = vm.const.i64 128
      %c553648160 = vm.const.i32 553648160
      %c1 = vm.const.i32 1
      %zero_1 = vm.const.i64.zero
      %c4 = vm.const.i64 4
      %c-1 = vm.const.i64 -1
      %c-1_2 = vm.const.i32 -1
      %c1_3 = vm.const.i64 1
      %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %_executable_main_dispatch_0 = vm.global.load.ref @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
      %0 = vm.call @hal.buffer_view.dim(%arg0, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %1 = vm.call @hal.buffer_view.dim(%arg0, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1, [%0, %1]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %2 = vm.mul.i64 %0, %c4 : i64
      %3 = vm.mul.i64 %2, %1 : i64
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %ref_6 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      %ref_7 = vm.call @hal.device.queue.alloca(%ref_4, %c-1, %null, %ref_6, %zero, %c48, %c3075, %3) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
      %4 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      %5 = vm.trunc.i64.i32 %0 : i64 -> i32
      %6 = vm.shr.i64.u %0, %c32 : i64
      %7 = vm.trunc.i64.i32 %6 : i64 -> i32
      %8 = vm.trunc.i64.i32 %1 : i64 -> i32
      %9 = vm.shr.i64.u %1, %c32 : i64
      %10 = vm.trunc.i64.i32 %9 : i64 -> i32
      %ref_8 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
      %11 = vm.select.i64 %_device_query_0, %zero_1, %c-1 : i64
      %12 = vm.trunc.i64.i32 %11 : i64 -> i32
      vm.br_table %12 {
        default: ^bb2,
        0: ^bb1
      }
    ^bb1:  // pred: ^bb0
      vm.call.variadic @hal.command_buffer.push_constants(%ref_8, %_pipeline_layout_0, %zero, [%5, %7, %8, %10]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, i32 ...)
      vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_8, %_pipeline_layout_0, %zero, [(%zero, %zero, %ref, %zero_1, %3), (%c1, %zero, %ref_7, %zero_1, %3)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      %slt = vm.cmp.lt.i64.s %zero_1, %1 : i64
      %13 = vm.xor.i32 %slt, %c1 : i32
      %14 = vm.sub.i64 %zero_1, %1 : i64
      %15 = vm.sub.i64 %1, %c1_3 : i64
      %16 = vm.select.i64 %13, %14, %15 : i64
      %17 = vm.div.i64.s %16, %c128 : i64
      %18 = vm.sub.i64 %zero_1, %17 : i64
      %19 = vm.add.i64 %17, %c1_3 : i64
      %20 = vm.select.i64 %13, %18, %19 : i64
      %slt_9 = vm.cmp.lt.i64.s %zero_1, %0 : i64
      %21 = vm.xor.i32 %slt_9, %c1 : i32
      %22 = vm.sub.i64 %zero_1, %0 : i64
      %23 = vm.sub.i64 %0, %c1_3 : i64
      %24 = vm.select.i64 %21, %22, %23 : i64
      %25 = vm.div.i64.s %24, %c32_0 : i64
      %26 = vm.sub.i64 %zero_1, %25 : i64
      %27 = vm.add.i64 %25, %c1_3 : i64
      %28 = vm.select.i64 %21, %26, %27 : i64
      %29 = vm.mul.i64 %20, %28 : i64
      %30 = vm.trunc.i64.i32 %29 : i64 -> i32
      vm.call @hal.command_buffer.dispatch(%ref_8, %_executable_main_dispatch_0, %zero, %30, %c1, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
      vm.br ^bb2
    ^bb2:  // 2 preds: ^bb0, ^bb1
      vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
      %ref_10 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      %31 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1, %null, %ref_10, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
      %32 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_10]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_br %32, ^bb4, ^bb3
    ^bb3:  // pred: ^bb2
      %ref_11 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_1, %3, %c553648160, %c1, [%0, %1]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_11 : !vm.ref<!hal.buffer_view>
    ^bb4:  // pred: ^bb2
      vm.fail %32, "failed to wait on timepoint"
    }
    vm.export @main attributes {iree.abi.stub}
    vm.export @__init
    vm.func private @__init() {
      %null = vm.const.ref.zero : !vm.ref<!hal.executable>
      %null_0 = vm.const.ref.zero : !vm.buffer
      %c4 = vm.const.i32 4
      %c7 = vm.const.i32 7
      %zero = vm.const.i32.zero
      %c1 = vm.const.i32 1
      %zero_1 = vm.const.i64.zero
      %c-1 = vm.const.i64 -1
      %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
      %_utf8_cuda_nvptx_fb_B15B42B96FDBACC = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
      %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
      %2 = vm.and.i32 %1, %c1 : i32
      %3 = vm.select.i32 %0#0, %2, %zero : i32
      %ref_2 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero, [(%zero, %c7, %c1), (%c1, %c7, %zero)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
      %ref_3 = vm.call.variadic @hal.pipeline_layout.create(%ref, %c4, [%ref_2]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
      %4 = vm.select.i64 %3, %zero_1, %c-1 : i64
      %5 = vm.trunc.i64.i32 %4 : i64 -> i32
      vm.global.store.i32 %3, @_device_query_0 : i32
      vm.global.store.ref %ref_3, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      vm.br_table %5 {
        default: ^bb2,
        0: ^bb1
      }
    ^bb1:  // pred: ^bb0
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %main_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @main_dispatch_0_cuda_nvptx_fb : !vm.buffer
      %ref_4 = vm.call.variadic @hal.executable.create(%ref, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC, %main_dispatch_0_cuda_nvptx_fb, %null_0, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
      vm.br ^bb3(%ref_4 : !vm.ref<!hal.executable>)
    ^bb2:  // pred: ^bb0
      vm.br ^bb3(%null : !vm.ref<!hal.executable>)
    ^bb3(%6: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
      vm.global.store.ref %6, @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
      vm.return
    }
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::VM::GlobalInitializationPass (iree-vm-global-initialization) //----- //
vm.module public @LinearModule {
  vm.global.i32 private mutable @_device_query_0 : i32
  vm.global.ref private mutable @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
  vm.global.ref private mutable @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
  vm.rodata private @main_dispatch_0_cuda_nvptx_fb {alignment = 16 : i64, mime_type = "application/x-flatbuffers"} dense<"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vector<6926xi8>
  vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
  vm.rodata private @_utf8_cuda_nvptx_fb_B15B42B96FDBACC {alignment = 1 : i64} "cuda-nvptx-fb"
  vm.import private @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects}
  vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
  vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
  vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
  vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
  vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
  vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer>
  vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
  vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
  vm.import private @hal.command_buffer.push_constants(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %offset : i32, %values : i32 ...)
  vm.import private @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32)
  vm.import private @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects}
  vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
  vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
  vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
  vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
  vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects}
  vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
  vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
  vm.import private @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects}
  vm.rodata private @_utf8_input_0_5FD512E67BEFDEEC {alignment = 1 : i64} "input 0"
  vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
  vm.func private @main(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
    %c13 = vm.const.i32 13
    %c28 = vm.const.i32 28
    %c3 = vm.const.i32 3
    %c17 = vm.const.i32 17
    %c32 = vm.const.i32 32
    %c48 = vm.const.i32 48
    %null = vm.const.ref.zero : !vm.ref<!hal.fence>
    %c3075 = vm.const.i32 3075
    %c16 = vm.const.i32 16
    %zero = vm.const.i32.zero
    %c32_0 = vm.const.i64 32
    %c128 = vm.const.i64 128
    %c553648160 = vm.const.i32 553648160
    %c1 = vm.const.i32 1
    %zero_1 = vm.const.i64.zero
    %c4 = vm.const.i64 4
    %c-1 = vm.const.i64 -1
    %c-1_2 = vm.const.i32 -1
    %c1_3 = vm.const.i64 1
    %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %_executable_main_dispatch_0 = vm.global.load.ref @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
    %0 = vm.call @hal.buffer_view.dim(%arg0, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %1 = vm.call @hal.buffer_view.dim(%arg0, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1, [%0, %1]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %2 = vm.mul.i64 %0, %c4 : i64
    %3 = vm.mul.i64 %2, %1 : i64
    %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
    vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %ref_6 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    %ref_7 = vm.call @hal.device.queue.alloca(%ref_4, %c-1, %null, %ref_6, %zero, %c48, %c3075, %3) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
    %4 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    %5 = vm.trunc.i64.i32 %0 : i64 -> i32
    %6 = vm.shr.i64.u %0, %c32 : i64
    %7 = vm.trunc.i64.i32 %6 : i64 -> i32
    %8 = vm.trunc.i64.i32 %1 : i64 -> i32
    %9 = vm.shr.i64.u %1, %c32 : i64
    %10 = vm.trunc.i64.i32 %9 : i64 -> i32
    %ref_8 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
    %11 = vm.select.i64 %_device_query_0, %zero_1, %c-1 : i64
    %12 = vm.trunc.i64.i32 %11 : i64 -> i32
    vm.br_table %12 {
      default: ^bb2,
      0: ^bb1
    }
  ^bb1:  // pred: ^bb0
    vm.call.variadic @hal.command_buffer.push_constants(%ref_8, %_pipeline_layout_0, %zero, [%5, %7, %8, %10]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, i32 ...)
    vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_8, %_pipeline_layout_0, %zero, [(%zero, %zero, %ref, %zero_1, %3), (%c1, %zero, %ref_7, %zero_1, %3)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    %slt = vm.cmp.lt.i64.s %zero_1, %1 : i64
    %13 = vm.xor.i32 %slt, %c1 : i32
    %14 = vm.sub.i64 %zero_1, %1 : i64
    %15 = vm.sub.i64 %1, %c1_3 : i64
    %16 = vm.select.i64 %13, %14, %15 : i64
    %17 = vm.div.i64.s %16, %c128 : i64
    %18 = vm.sub.i64 %zero_1, %17 : i64
    %19 = vm.add.i64 %17, %c1_3 : i64
    %20 = vm.select.i64 %13, %18, %19 : i64
    %slt_9 = vm.cmp.lt.i64.s %zero_1, %0 : i64
    %21 = vm.xor.i32 %slt_9, %c1 : i32
    %22 = vm.sub.i64 %zero_1, %0 : i64
    %23 = vm.sub.i64 %0, %c1_3 : i64
    %24 = vm.select.i64 %21, %22, %23 : i64
    %25 = vm.div.i64.s %24, %c32_0 : i64
    %26 = vm.sub.i64 %zero_1, %25 : i64
    %27 = vm.add.i64 %25, %c1_3 : i64
    %28 = vm.select.i64 %21, %26, %27 : i64
    %29 = vm.mul.i64 %20, %28 : i64
    %30 = vm.trunc.i64.i32 %29 : i64 -> i32
    vm.call @hal.command_buffer.dispatch(%ref_8, %_executable_main_dispatch_0, %zero, %30, %c1, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
    vm.br ^bb2
  ^bb2:  // 2 preds: ^bb0, ^bb1
    vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
    vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
    %ref_10 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    %31 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1, %null, %ref_10, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
    %32 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_10]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    vm.cond_br %32, ^bb4, ^bb3
  ^bb3:  // pred: ^bb2
    %ref_11 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_1, %3, %c553648160, %c1, [%0, %1]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
    vm.return %ref_11 : !vm.ref<!hal.buffer_view>
  ^bb4:  // pred: ^bb2
    vm.fail %32, "failed to wait on timepoint"
  }
  vm.export @main attributes {iree.abi.stub}
  vm.export @__init
  vm.func private @__init() {
    %null = vm.const.ref.zero : !vm.ref<!hal.executable>
    %null_0 = vm.const.ref.zero : !vm.buffer
    %c4 = vm.const.i32 4
    %c7 = vm.const.i32 7
    %zero = vm.const.i32.zero
    %c1 = vm.const.i32 1
    %zero_1 = vm.const.i64.zero
    %c-1 = vm.const.i64 -1
    %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
    %_utf8_cuda_nvptx_fb_B15B42B96FDBACC = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
    %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
    %2 = vm.and.i32 %1, %c1 : i32
    %3 = vm.select.i32 %0#0, %2, %zero : i32
    %ref_2 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero, [(%zero, %c7, %c1), (%c1, %c7, %zero)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
    %ref_3 = vm.call.variadic @hal.pipeline_layout.create(%ref, %c4, [%ref_2]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
    %4 = vm.select.i64 %3, %zero_1, %c-1 : i64
    %5 = vm.trunc.i64.i32 %4 : i64 -> i32
    vm.global.store.i32 %3, @_device_query_0 : i32
    vm.global.store.ref %ref_3, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.br_table %5 {
      default: ^bb2,
      0: ^bb1
    }
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %main_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @main_dispatch_0_cuda_nvptx_fb : !vm.buffer
    %ref_4 = vm.call.variadic @hal.executable.create(%ref, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC, %main_dispatch_0_cuda_nvptx_fb, %null_0, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
    vm.br ^bb3(%ref_4 : !vm.ref<!hal.executable>)
  ^bb2:  // pred: ^bb0
    vm.br ^bb3(%null : !vm.ref<!hal.executable>)
  ^bb3(%6: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
    vm.global.store.ref %6, @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
    vm.br ^bb4
  ^bb4:  // pred: ^bb3
    vm.return
  }
  vm.export @__deinit
  vm.func private @__deinit() {
    vm.return
  }
}

// -----// IR Dump After mlir::iree_compiler::IREE::VM::DropEmptyModuleInitializersPass (iree-vm-drop-empty-module-initializers) //----- //
vm.module public @LinearModule {
  vm.global.i32 private mutable @_device_query_0 : i32
  vm.global.ref private mutable @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
  vm.global.ref private mutable @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
  vm.rodata private @main_dispatch_0_cuda_nvptx_fb {alignment = 16 : i64, mime_type = "application/x-flatbuffers"} dense<"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vector<6926xi8>
  vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
  vm.rodata private @_utf8_cuda_nvptx_fb_B15B42B96FDBACC {alignment = 1 : i64} "cuda-nvptx-fb"
  vm.import private @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects}
  vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
  vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
  vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
  vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
  vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
  vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer>
  vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
  vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
  vm.import private @hal.command_buffer.push_constants(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %offset : i32, %values : i32 ...)
  vm.import private @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32)
  vm.import private @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects}
  vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
  vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
  vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
  vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
  vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects}
  vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
  vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
  vm.import private @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects}
  vm.rodata private @_utf8_input_0_5FD512E67BEFDEEC {alignment = 1 : i64} "input 0"
  vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
  vm.func private @main(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
    %c13 = vm.const.i32 13
    %c28 = vm.const.i32 28
    %c3 = vm.const.i32 3
    %c17 = vm.const.i32 17
    %c32 = vm.const.i32 32
    %c48 = vm.const.i32 48
    %null = vm.const.ref.zero : !vm.ref<!hal.fence>
    %c3075 = vm.const.i32 3075
    %c16 = vm.const.i32 16
    %zero = vm.const.i32.zero
    %c32_0 = vm.const.i64 32
    %c128 = vm.const.i64 128
    %c553648160 = vm.const.i32 553648160
    %c1 = vm.const.i32 1
    %zero_1 = vm.const.i64.zero
    %c4 = vm.const.i64 4
    %c-1 = vm.const.i64 -1
    %c-1_2 = vm.const.i32 -1
    %c1_3 = vm.const.i64 1
    %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %_executable_main_dispatch_0 = vm.global.load.ref @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
    %0 = vm.call @hal.buffer_view.dim(%arg0, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %1 = vm.call @hal.buffer_view.dim(%arg0, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1, [%0, %1]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %2 = vm.mul.i64 %0, %c4 : i64
    %3 = vm.mul.i64 %2, %1 : i64
    %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
    vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %ref_6 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    %ref_7 = vm.call @hal.device.queue.alloca(%ref_4, %c-1, %null, %ref_6, %zero, %c48, %c3075, %3) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
    %4 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    %5 = vm.trunc.i64.i32 %0 : i64 -> i32
    %6 = vm.shr.i64.u %0, %c32 : i64
    %7 = vm.trunc.i64.i32 %6 : i64 -> i32
    %8 = vm.trunc.i64.i32 %1 : i64 -> i32
    %9 = vm.shr.i64.u %1, %c32 : i64
    %10 = vm.trunc.i64.i32 %9 : i64 -> i32
    %ref_8 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
    %11 = vm.select.i64 %_device_query_0, %zero_1, %c-1 : i64
    %12 = vm.trunc.i64.i32 %11 : i64 -> i32
    vm.br_table %12 {
      default: ^bb2,
      0: ^bb1
    }
  ^bb1:  // pred: ^bb0
    vm.call.variadic @hal.command_buffer.push_constants(%ref_8, %_pipeline_layout_0, %zero, [%5, %7, %8, %10]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, i32 ...)
    vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_8, %_pipeline_layout_0, %zero, [(%zero, %zero, %ref, %zero_1, %3), (%c1, %zero, %ref_7, %zero_1, %3)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    %slt = vm.cmp.lt.i64.s %zero_1, %1 : i64
    %13 = vm.xor.i32 %slt, %c1 : i32
    %14 = vm.sub.i64 %zero_1, %1 : i64
    %15 = vm.sub.i64 %1, %c1_3 : i64
    %16 = vm.select.i64 %13, %14, %15 : i64
    %17 = vm.div.i64.s %16, %c128 : i64
    %18 = vm.sub.i64 %zero_1, %17 : i64
    %19 = vm.add.i64 %17, %c1_3 : i64
    %20 = vm.select.i64 %13, %18, %19 : i64
    %slt_9 = vm.cmp.lt.i64.s %zero_1, %0 : i64
    %21 = vm.xor.i32 %slt_9, %c1 : i32
    %22 = vm.sub.i64 %zero_1, %0 : i64
    %23 = vm.sub.i64 %0, %c1_3 : i64
    %24 = vm.select.i64 %21, %22, %23 : i64
    %25 = vm.div.i64.s %24, %c32_0 : i64
    %26 = vm.sub.i64 %zero_1, %25 : i64
    %27 = vm.add.i64 %25, %c1_3 : i64
    %28 = vm.select.i64 %21, %26, %27 : i64
    %29 = vm.mul.i64 %20, %28 : i64
    %30 = vm.trunc.i64.i32 %29 : i64 -> i32
    vm.call @hal.command_buffer.dispatch(%ref_8, %_executable_main_dispatch_0, %zero, %30, %c1, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
    vm.br ^bb2
  ^bb2:  // 2 preds: ^bb0, ^bb1
    vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
    vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
    %ref_10 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    %31 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1, %null, %ref_10, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
    %32 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_10]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    vm.cond_br %32, ^bb4, ^bb3
  ^bb3:  // pred: ^bb2
    %ref_11 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_1, %3, %c553648160, %c1, [%0, %1]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
    vm.return %ref_11 : !vm.ref<!hal.buffer_view>
  ^bb4:  // pred: ^bb2
    vm.fail %32, "failed to wait on timepoint"
  }
  vm.export @main attributes {iree.abi.stub}
  vm.export @__init
  vm.func private @__init() {
    %null = vm.const.ref.zero : !vm.ref<!hal.executable>
    %null_0 = vm.const.ref.zero : !vm.buffer
    %c4 = vm.const.i32 4
    %c7 = vm.const.i32 7
    %zero = vm.const.i32.zero
    %c1 = vm.const.i32 1
    %zero_1 = vm.const.i64.zero
    %c-1 = vm.const.i64 -1
    %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
    %_utf8_cuda_nvptx_fb_B15B42B96FDBACC = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
    %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
    %2 = vm.and.i32 %1, %c1 : i32
    %3 = vm.select.i32 %0#0, %2, %zero : i32
    %ref_2 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero, [(%zero, %c7, %c1), (%c1, %c7, %zero)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
    %ref_3 = vm.call.variadic @hal.pipeline_layout.create(%ref, %c4, [%ref_2]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
    %4 = vm.select.i64 %3, %zero_1, %c-1 : i64
    %5 = vm.trunc.i64.i32 %4 : i64 -> i32
    vm.global.store.i32 %3, @_device_query_0 : i32
    vm.global.store.ref %ref_3, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.br_table %5 {
      default: ^bb2,
      0: ^bb1
    }
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %main_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @main_dispatch_0_cuda_nvptx_fb : !vm.buffer
    %ref_4 = vm.call.variadic @hal.executable.create(%ref, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC, %main_dispatch_0_cuda_nvptx_fb, %null_0, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
    vm.br ^bb3(%ref_4 : !vm.ref<!hal.executable>)
  ^bb2:  // pred: ^bb0
    vm.br ^bb3(%null : !vm.ref<!hal.executable>)
  ^bb3(%6: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
    vm.global.store.ref %6, @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
    vm.br ^bb4
  ^bb4:  // pred: ^bb3
    vm.return
  }
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
vm.func private @main(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
  %c13 = vm.const.i32 13
  %c28 = vm.const.i32 28
  %c3 = vm.const.i32 3
  %c17 = vm.const.i32 17
  %c32 = vm.const.i32 32
  %c48 = vm.const.i32 48
  %null = vm.const.ref.zero : !vm.ref<!hal.fence>
  %c3075 = vm.const.i32 3075
  %c16 = vm.const.i32 16
  %zero = vm.const.i32.zero
  %c32_0 = vm.const.i64 32
  %c128 = vm.const.i64 128
  %c553648160 = vm.const.i32 553648160
  %c1 = vm.const.i32 1
  %zero_1 = vm.const.i64.zero
  %c4 = vm.const.i64 4
  %c-1 = vm.const.i64 -1
  %c-1_2 = vm.const.i32 -1
  %c1_3 = vm.const.i64 1
  %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
  %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
  %_executable_main_dispatch_0 = vm.global.load.ref @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
  %0 = vm.call @hal.buffer_view.dim(%arg0, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
  %1 = vm.call @hal.buffer_view.dim(%arg0, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
  %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
  vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1, [%0, %1]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
  %2 = vm.mul.i64 %0, %c4 : i64
  %3 = vm.mul.i64 %2, %1 : i64
  %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
  %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
  %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
  %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
  vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
  %ref_6 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
  %ref_7 = vm.call @hal.device.queue.alloca(%ref_4, %c-1, %null, %ref_6, %zero, %c48, %c3075, %3) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
  %4 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
  %5 = vm.trunc.i64.i32 %0 : i64 -> i32
  %6 = vm.shr.i64.u %0, %c32 : i64
  %7 = vm.trunc.i64.i32 %6 : i64 -> i32
  %8 = vm.trunc.i64.i32 %1 : i64 -> i32
  %9 = vm.shr.i64.u %1, %c32 : i64
  %10 = vm.trunc.i64.i32 %9 : i64 -> i32
  %ref_8 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
  %11 = vm.select.i64 %_device_query_0, %zero_1, %c-1 : i64
  %12 = vm.trunc.i64.i32 %11 : i64 -> i32
  vm.br_table %12 {
    default: ^bb2,
    0: ^bb1
  }
^bb1:  // pred: ^bb0
  vm.call.variadic @hal.command_buffer.push_constants(%ref_8, %_pipeline_layout_0, %zero, [%5, %7, %8, %10]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, i32 ...)
  vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_8, %_pipeline_layout_0, %zero, [(%zero, %zero, %ref, %zero_1, %3), (%c1, %zero, %ref_7, %zero_1, %3)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
  %slt = vm.cmp.lt.i64.s %zero_1, %1 : i64
  %13 = vm.xor.i32 %slt, %c1 : i32
  %14 = vm.sub.i64 %zero_1, %1 : i64
  %15 = vm.sub.i64 %1, %c1_3 : i64
  %16 = vm.select.i64 %13, %14, %15 : i64
  %17 = vm.div.i64.s %16, %c128 : i64
  %18 = vm.sub.i64 %zero_1, %17 : i64
  %19 = vm.add.i64 %17, %c1_3 : i64
  %20 = vm.select.i64 %13, %18, %19 : i64
  %slt_9 = vm.cmp.lt.i64.s %zero_1, %0 : i64
  %21 = vm.xor.i32 %slt_9, %c1 : i32
  %22 = vm.sub.i64 %zero_1, %0 : i64
  %23 = vm.sub.i64 %0, %c1_3 : i64
  %24 = vm.select.i64 %21, %22, %23 : i64
  %25 = vm.div.i64.s %24, %c32_0 : i64
  %26 = vm.sub.i64 %zero_1, %25 : i64
  %27 = vm.add.i64 %25, %c1_3 : i64
  %28 = vm.select.i64 %21, %26, %27 : i64
  %29 = vm.mul.i64 %20, %28 : i64
  %30 = vm.trunc.i64.i32 %29 : i64 -> i32
  vm.call @hal.command_buffer.dispatch(%ref_8, %_executable_main_dispatch_0, %zero, %30, %c1, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
  vm.br ^bb2
^bb2:  // 2 preds: ^bb0, ^bb1
  vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
  vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
  %ref_10 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
  %31 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
  vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1, %null, %ref_10, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
  %32 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_10]) : (i32, !vm.ref<!hal.fence> ...) -> i32
  vm.cond_br %32, ^bb4, ^bb3
^bb3:  // pred: ^bb2
  %ref_11 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_1, %3, %c553648160, %c1, [%0, %1]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
  vm.return %ref_11 : !vm.ref<!hal.buffer_view>
^bb4:  // pred: ^bb2
  vm.fail %32, "failed to wait on timepoint"
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
vm.func private @__init() {
  %null = vm.const.ref.zero : !vm.ref<!hal.executable>
  %null_0 = vm.const.ref.zero : !vm.buffer
  %c4 = vm.const.i32 4
  %c7 = vm.const.i32 7
  %zero = vm.const.i32.zero
  %c1 = vm.const.i32 1
  %zero_1 = vm.const.i64.zero
  %c-1 = vm.const.i64 -1
  %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
  %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
  %_utf8_cuda_nvptx_fb_B15B42B96FDBACC = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
  %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
  %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
  %2 = vm.and.i32 %1, %c1 : i32
  %3 = vm.select.i32 %0#0, %2, %zero : i32
  %ref_2 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero, [(%zero, %c7, %c1), (%c1, %c7, %zero)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
  %ref_3 = vm.call.variadic @hal.pipeline_layout.create(%ref, %c4, [%ref_2]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
  %4 = vm.select.i64 %3, %zero_1, %c-1 : i64
  %5 = vm.trunc.i64.i32 %4 : i64 -> i32
  vm.global.store.i32 %3, @_device_query_0 : i32
  vm.global.store.ref %ref_3, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
  vm.br_table %5 {
    default: ^bb2,
    0: ^bb1
  }
^bb1:  // pred: ^bb0
  %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
  %main_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @main_dispatch_0_cuda_nvptx_fb : !vm.buffer
  %ref_4 = vm.call.variadic @hal.executable.create(%ref, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC, %main_dispatch_0_cuda_nvptx_fb, %null_0, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
  vm.br ^bb3(%ref_4 : !vm.ref<!hal.executable>)
^bb2:  // pred: ^bb0
  vm.br ^bb3(%null : !vm.ref<!hal.executable>)
^bb3(%6: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
  vm.global.store.ref %6, @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
  vm.return
}

// -----// IR Dump After Inliner (inline) //----- //
vm.module public @LinearModule {
  vm.global.i32 private mutable @_device_query_0 : i32
  vm.global.ref private mutable @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
  vm.global.ref private mutable @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
  vm.rodata private @main_dispatch_0_cuda_nvptx_fb {alignment = 16 : i64, mime_type = "application/x-flatbuffers"} dense<"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vector<6926xi8>
  vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
  vm.rodata private @_utf8_cuda_nvptx_fb_B15B42B96FDBACC {alignment = 1 : i64} "cuda-nvptx-fb"
  vm.import private @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects}
  vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
  vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
  vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
  vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
  vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
  vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer>
  vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
  vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
  vm.import private @hal.command_buffer.push_constants(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %offset : i32, %values : i32 ...)
  vm.import private @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32)
  vm.import private @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects}
  vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
  vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
  vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
  vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
  vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects}
  vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
  vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
  vm.import private @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects}
  vm.rodata private @_utf8_input_0_5FD512E67BEFDEEC {alignment = 1 : i64} "input 0"
  vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
  vm.func private @main(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
    %c13 = vm.const.i32 13
    %c28 = vm.const.i32 28
    %c3 = vm.const.i32 3
    %c17 = vm.const.i32 17
    %c32 = vm.const.i32 32
    %c48 = vm.const.i32 48
    %null = vm.const.ref.zero : !vm.ref<!hal.fence>
    %c3075 = vm.const.i32 3075
    %c16 = vm.const.i32 16
    %zero = vm.const.i32.zero
    %c32_0 = vm.const.i64 32
    %c128 = vm.const.i64 128
    %c553648160 = vm.const.i32 553648160
    %c1 = vm.const.i32 1
    %zero_1 = vm.const.i64.zero
    %c4 = vm.const.i64 4
    %c-1 = vm.const.i64 -1
    %c-1_2 = vm.const.i32 -1
    %c1_3 = vm.const.i64 1
    %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %_executable_main_dispatch_0 = vm.global.load.ref @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
    %0 = vm.call @hal.buffer_view.dim(%arg0, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %1 = vm.call @hal.buffer_view.dim(%arg0, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1, [%0, %1]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %2 = vm.mul.i64 %0, %c4 : i64
    %3 = vm.mul.i64 %2, %1 : i64
    %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
    vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %ref_6 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    %ref_7 = vm.call @hal.device.queue.alloca(%ref_4, %c-1, %null, %ref_6, %zero, %c48, %c3075, %3) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
    %4 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    %5 = vm.trunc.i64.i32 %0 : i64 -> i32
    %6 = vm.shr.i64.u %0, %c32 : i64
    %7 = vm.trunc.i64.i32 %6 : i64 -> i32
    %8 = vm.trunc.i64.i32 %1 : i64 -> i32
    %9 = vm.shr.i64.u %1, %c32 : i64
    %10 = vm.trunc.i64.i32 %9 : i64 -> i32
    %ref_8 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
    %11 = vm.select.i64 %_device_query_0, %zero_1, %c-1 : i64
    %12 = vm.trunc.i64.i32 %11 : i64 -> i32
    vm.br_table %12 {
      default: ^bb2,
      0: ^bb1
    }
  ^bb1:  // pred: ^bb0
    vm.call.variadic @hal.command_buffer.push_constants(%ref_8, %_pipeline_layout_0, %zero, [%5, %7, %8, %10]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, i32 ...)
    vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_8, %_pipeline_layout_0, %zero, [(%zero, %zero, %ref, %zero_1, %3), (%c1, %zero, %ref_7, %zero_1, %3)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    %slt = vm.cmp.lt.i64.s %zero_1, %1 : i64
    %13 = vm.xor.i32 %slt, %c1 : i32
    %14 = vm.sub.i64 %zero_1, %1 : i64
    %15 = vm.sub.i64 %1, %c1_3 : i64
    %16 = vm.select.i64 %13, %14, %15 : i64
    %17 = vm.div.i64.s %16, %c128 : i64
    %18 = vm.sub.i64 %zero_1, %17 : i64
    %19 = vm.add.i64 %17, %c1_3 : i64
    %20 = vm.select.i64 %13, %18, %19 : i64
    %slt_9 = vm.cmp.lt.i64.s %zero_1, %0 : i64
    %21 = vm.xor.i32 %slt_9, %c1 : i32
    %22 = vm.sub.i64 %zero_1, %0 : i64
    %23 = vm.sub.i64 %0, %c1_3 : i64
    %24 = vm.select.i64 %21, %22, %23 : i64
    %25 = vm.div.i64.s %24, %c32_0 : i64
    %26 = vm.sub.i64 %zero_1, %25 : i64
    %27 = vm.add.i64 %25, %c1_3 : i64
    %28 = vm.select.i64 %21, %26, %27 : i64
    %29 = vm.mul.i64 %20, %28 : i64
    %30 = vm.trunc.i64.i32 %29 : i64 -> i32
    vm.call @hal.command_buffer.dispatch(%ref_8, %_executable_main_dispatch_0, %zero, %30, %c1, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
    vm.br ^bb2
  ^bb2:  // 2 preds: ^bb0, ^bb1
    vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
    vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
    %ref_10 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    %31 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1, %null, %ref_10, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
    %32 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_10]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    vm.cond_br %32, ^bb4, ^bb3
  ^bb3:  // pred: ^bb2
    %ref_11 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_1, %3, %c553648160, %c1, [%0, %1]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
    vm.return %ref_11 : !vm.ref<!hal.buffer_view>
  ^bb4:  // pred: ^bb2
    vm.fail %32, "failed to wait on timepoint"
  }
  vm.export @main attributes {iree.abi.stub}
  vm.export @__init
  vm.func private @__init() {
    %null = vm.const.ref.zero : !vm.ref<!hal.executable>
    %null_0 = vm.const.ref.zero : !vm.buffer
    %c4 = vm.const.i32 4
    %c7 = vm.const.i32 7
    %zero = vm.const.i32.zero
    %c1 = vm.const.i32 1
    %zero_1 = vm.const.i64.zero
    %c-1 = vm.const.i64 -1
    %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
    %_utf8_cuda_nvptx_fb_B15B42B96FDBACC = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
    %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
    %2 = vm.and.i32 %1, %c1 : i32
    %3 = vm.select.i32 %0#0, %2, %zero : i32
    %ref_2 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero, [(%zero, %c7, %c1), (%c1, %c7, %zero)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
    %ref_3 = vm.call.variadic @hal.pipeline_layout.create(%ref, %c4, [%ref_2]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
    %4 = vm.select.i64 %3, %zero_1, %c-1 : i64
    %5 = vm.trunc.i64.i32 %4 : i64 -> i32
    vm.global.store.i32 %3, @_device_query_0 : i32
    vm.global.store.ref %ref_3, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.br_table %5 {
      default: ^bb2,
      0: ^bb1
    }
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %main_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @main_dispatch_0_cuda_nvptx_fb : !vm.buffer
    %ref_4 = vm.call.variadic @hal.executable.create(%ref, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC, %main_dispatch_0_cuda_nvptx_fb, %null_0, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
    vm.br ^bb3(%ref_4 : !vm.ref<!hal.executable>)
  ^bb2:  // pred: ^bb0
    vm.br ^bb3(%null : !vm.ref<!hal.executable>)
  ^bb3(%6: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
    vm.global.store.ref %6, @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
    vm.return
  }
}

// -----// IR Dump After CSE (cse) //----- //
vm.module public @LinearModule {
  vm.global.i32 private mutable @_device_query_0 : i32
  vm.global.ref private mutable @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
  vm.global.ref private mutable @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
  vm.rodata private @main_dispatch_0_cuda_nvptx_fb {alignment = 16 : i64, mime_type = "application/x-flatbuffers"} dense<"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vector<6926xi8>
  vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
  vm.rodata private @_utf8_cuda_nvptx_fb_B15B42B96FDBACC {alignment = 1 : i64} "cuda-nvptx-fb"
  vm.import private @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects}
  vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
  vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
  vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
  vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
  vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
  vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer>
  vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
  vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
  vm.import private @hal.command_buffer.push_constants(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %offset : i32, %values : i32 ...)
  vm.import private @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32)
  vm.import private @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects}
  vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
  vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
  vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
  vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
  vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects}
  vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
  vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
  vm.import private @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects}
  vm.rodata private @_utf8_input_0_5FD512E67BEFDEEC {alignment = 1 : i64} "input 0"
  vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
  vm.func private @main(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
    %c13 = vm.const.i32 13
    %c28 = vm.const.i32 28
    %c3 = vm.const.i32 3
    %c17 = vm.const.i32 17
    %c32 = vm.const.i32 32
    %c48 = vm.const.i32 48
    %null = vm.const.ref.zero : !vm.ref<!hal.fence>
    %c3075 = vm.const.i32 3075
    %c16 = vm.const.i32 16
    %zero = vm.const.i32.zero
    %c32_0 = vm.const.i64 32
    %c128 = vm.const.i64 128
    %c553648160 = vm.const.i32 553648160
    %c1 = vm.const.i32 1
    %zero_1 = vm.const.i64.zero
    %c4 = vm.const.i64 4
    %c-1 = vm.const.i64 -1
    %c-1_2 = vm.const.i32 -1
    %c1_3 = vm.const.i64 1
    %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %_executable_main_dispatch_0 = vm.global.load.ref @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
    %0 = vm.call @hal.buffer_view.dim(%arg0, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %1 = vm.call @hal.buffer_view.dim(%arg0, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1, [%0, %1]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %2 = vm.mul.i64 %0, %c4 : i64
    %3 = vm.mul.i64 %2, %1 : i64
    %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
    vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %ref_6 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    %ref_7 = vm.call @hal.device.queue.alloca(%ref_4, %c-1, %null, %ref_6, %zero, %c48, %c3075, %3) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
    %4 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    %5 = vm.trunc.i64.i32 %0 : i64 -> i32
    %6 = vm.shr.i64.u %0, %c32 : i64
    %7 = vm.trunc.i64.i32 %6 : i64 -> i32
    %8 = vm.trunc.i64.i32 %1 : i64 -> i32
    %9 = vm.shr.i64.u %1, %c32 : i64
    %10 = vm.trunc.i64.i32 %9 : i64 -> i32
    %ref_8 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
    %11 = vm.select.i64 %_device_query_0, %zero_1, %c-1 : i64
    %12 = vm.trunc.i64.i32 %11 : i64 -> i32
    vm.br_table %12 {
      default: ^bb2,
      0: ^bb1
    }
  ^bb1:  // pred: ^bb0
    vm.call.variadic @hal.command_buffer.push_constants(%ref_8, %_pipeline_layout_0, %zero, [%5, %7, %8, %10]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, i32 ...)
    vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_8, %_pipeline_layout_0, %zero, [(%zero, %zero, %ref, %zero_1, %3), (%c1, %zero, %ref_7, %zero_1, %3)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    %slt = vm.cmp.lt.i64.s %zero_1, %1 : i64
    %13 = vm.xor.i32 %slt, %c1 : i32
    %14 = vm.sub.i64 %zero_1, %1 : i64
    %15 = vm.sub.i64 %1, %c1_3 : i64
    %16 = vm.select.i64 %13, %14, %15 : i64
    %17 = vm.div.i64.s %16, %c128 : i64
    %18 = vm.sub.i64 %zero_1, %17 : i64
    %19 = vm.add.i64 %17, %c1_3 : i64
    %20 = vm.select.i64 %13, %18, %19 : i64
    %slt_9 = vm.cmp.lt.i64.s %zero_1, %0 : i64
    %21 = vm.xor.i32 %slt_9, %c1 : i32
    %22 = vm.sub.i64 %zero_1, %0 : i64
    %23 = vm.sub.i64 %0, %c1_3 : i64
    %24 = vm.select.i64 %21, %22, %23 : i64
    %25 = vm.div.i64.s %24, %c32_0 : i64
    %26 = vm.sub.i64 %zero_1, %25 : i64
    %27 = vm.add.i64 %25, %c1_3 : i64
    %28 = vm.select.i64 %21, %26, %27 : i64
    %29 = vm.mul.i64 %20, %28 : i64
    %30 = vm.trunc.i64.i32 %29 : i64 -> i32
    vm.call @hal.command_buffer.dispatch(%ref_8, %_executable_main_dispatch_0, %zero, %30, %c1, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
    vm.br ^bb2
  ^bb2:  // 2 preds: ^bb0, ^bb1
    vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
    vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
    %ref_10 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    %31 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1, %null, %ref_10, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
    %32 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_10]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    vm.cond_br %32, ^bb4, ^bb3
  ^bb3:  // pred: ^bb2
    %ref_11 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_1, %3, %c553648160, %c1, [%0, %1]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
    vm.return %ref_11 : !vm.ref<!hal.buffer_view>
  ^bb4:  // pred: ^bb2
    vm.fail %32, "failed to wait on timepoint"
  }
  vm.export @main attributes {iree.abi.stub}
  vm.export @__init
  vm.func private @__init() {
    %null = vm.const.ref.zero : !vm.ref<!hal.executable>
    %null_0 = vm.const.ref.zero : !vm.buffer
    %c4 = vm.const.i32 4
    %c7 = vm.const.i32 7
    %zero = vm.const.i32.zero
    %c1 = vm.const.i32 1
    %zero_1 = vm.const.i64.zero
    %c-1 = vm.const.i64 -1
    %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
    %_utf8_cuda_nvptx_fb_B15B42B96FDBACC = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
    %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
    %2 = vm.and.i32 %1, %c1 : i32
    %3 = vm.select.i32 %0#0, %2, %zero : i32
    %ref_2 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero, [(%zero, %c7, %c1), (%c1, %c7, %zero)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
    %ref_3 = vm.call.variadic @hal.pipeline_layout.create(%ref, %c4, [%ref_2]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
    %4 = vm.select.i64 %3, %zero_1, %c-1 : i64
    %5 = vm.trunc.i64.i32 %4 : i64 -> i32
    vm.global.store.i32 %3, @_device_query_0 : i32
    vm.global.store.ref %ref_3, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.br_table %5 {
      default: ^bb2,
      0: ^bb1
    }
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %main_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @main_dispatch_0_cuda_nvptx_fb : !vm.buffer
    %ref_4 = vm.call.variadic @hal.executable.create(%ref, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC, %main_dispatch_0_cuda_nvptx_fb, %null_0, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
    vm.br ^bb3(%ref_4 : !vm.ref<!hal.executable>)
  ^bb2:  // pred: ^bb0
    vm.br ^bb3(%null : !vm.ref<!hal.executable>)
  ^bb3(%6: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
    vm.global.store.ref %6, @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
    vm.return
  }
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
vm.module public @LinearModule {
  vm.global.i32 private mutable @_device_query_0 : i32
  vm.global.ref private mutable @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
  vm.global.ref private mutable @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
  vm.rodata private @main_dispatch_0_cuda_nvptx_fb {alignment = 16 : i64, mime_type = "application/x-flatbuffers"} dense<"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vector<6926xi8>
  vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
  vm.rodata private @_utf8_cuda_nvptx_fb_B15B42B96FDBACC {alignment = 1 : i64} "cuda-nvptx-fb"
  vm.import private @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects}
  vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
  vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
  vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
  vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
  vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
  vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer>
  vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
  vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
  vm.import private @hal.command_buffer.push_constants(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %offset : i32, %values : i32 ...)
  vm.import private @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32)
  vm.import private @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects}
  vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
  vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
  vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
  vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
  vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects}
  vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
  vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
  vm.import private @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects}
  vm.rodata private @_utf8_input_0_5FD512E67BEFDEEC {alignment = 1 : i64} "input 0"
  vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
  vm.func private @main(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
    %c13 = vm.const.i32 13
    %c28 = vm.const.i32 28
    %c3 = vm.const.i32 3
    %c17 = vm.const.i32 17
    %c32 = vm.const.i32 32
    %c48 = vm.const.i32 48
    %null = vm.const.ref.zero : !vm.ref<!hal.fence>
    %c3075 = vm.const.i32 3075
    %c16 = vm.const.i32 16
    %zero = vm.const.i32.zero
    %c32_0 = vm.const.i64 32
    %c128 = vm.const.i64 128
    %c553648160 = vm.const.i32 553648160
    %c1 = vm.const.i32 1
    %zero_1 = vm.const.i64.zero
    %c4 = vm.const.i64 4
    %c-1 = vm.const.i64 -1
    %c-1_2 = vm.const.i32 -1
    %c1_3 = vm.const.i64 1
    %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %_executable_main_dispatch_0 = vm.global.load.ref @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
    %0 = vm.call @hal.buffer_view.dim(%arg0, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %1 = vm.call @hal.buffer_view.dim(%arg0, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1, [%0, %1]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %2 = vm.mul.i64 %0, %c4 : i64
    %3 = vm.mul.i64 %2, %1 : i64
    %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
    vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %ref_6 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    %ref_7 = vm.call @hal.device.queue.alloca(%ref_4, %c-1, %null, %ref_6, %zero, %c48, %c3075, %3) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
    %4 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    %5 = vm.trunc.i64.i32 %0 : i64 -> i32
    %6 = vm.shr.i64.u %0, %c32 : i64
    %7 = vm.trunc.i64.i32 %6 : i64 -> i32
    %8 = vm.trunc.i64.i32 %1 : i64 -> i32
    %9 = vm.shr.i64.u %1, %c32 : i64
    %10 = vm.trunc.i64.i32 %9 : i64 -> i32
    %ref_8 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
    %11 = vm.select.i64 %_device_query_0, %zero_1, %c-1 : i64
    %12 = vm.trunc.i64.i32 %11 : i64 -> i32
    vm.br_table %12 {
      default: ^bb2,
      0: ^bb1
    }
  ^bb1:  // pred: ^bb0
    vm.call.variadic @hal.command_buffer.push_constants(%ref_8, %_pipeline_layout_0, %zero, [%5, %7, %8, %10]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, i32 ...)
    vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_8, %_pipeline_layout_0, %zero, [(%zero, %zero, %ref, %zero_1, %3), (%c1, %zero, %ref_7, %zero_1, %3)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    %slt = vm.cmp.lt.i64.s %zero_1, %1 : i64
    %13 = vm.xor.i32 %slt, %c1 : i32
    %14 = vm.sub.i64 %zero_1, %1 : i64
    %15 = vm.sub.i64 %1, %c1_3 : i64
    %16 = vm.select.i64 %13, %14, %15 : i64
    %17 = vm.div.i64.s %16, %c128 : i64
    %18 = vm.sub.i64 %zero_1, %17 : i64
    %19 = vm.add.i64 %17, %c1_3 : i64
    %20 = vm.select.i64 %13, %18, %19 : i64
    %slt_9 = vm.cmp.lt.i64.s %zero_1, %0 : i64
    %21 = vm.xor.i32 %slt_9, %c1 : i32
    %22 = vm.sub.i64 %zero_1, %0 : i64
    %23 = vm.sub.i64 %0, %c1_3 : i64
    %24 = vm.select.i64 %21, %22, %23 : i64
    %25 = vm.div.i64.s %24, %c32_0 : i64
    %26 = vm.sub.i64 %zero_1, %25 : i64
    %27 = vm.add.i64 %25, %c1_3 : i64
    %28 = vm.select.i64 %21, %26, %27 : i64
    %29 = vm.mul.i64 %20, %28 : i64
    %30 = vm.trunc.i64.i32 %29 : i64 -> i32
    vm.call @hal.command_buffer.dispatch(%ref_8, %_executable_main_dispatch_0, %zero, %30, %c1, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
    vm.br ^bb2
  ^bb2:  // 2 preds: ^bb0, ^bb1
    vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
    vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
    %ref_10 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    %31 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1, %null, %ref_10, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
    %32 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_10]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    vm.cond_br %32, ^bb4, ^bb3
  ^bb3:  // pred: ^bb2
    %ref_11 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_1, %3, %c553648160, %c1, [%0, %1]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
    vm.return %ref_11 : !vm.ref<!hal.buffer_view>
  ^bb4:  // pred: ^bb2
    vm.fail %32, "failed to wait on timepoint"
  }
  vm.export @main attributes {iree.abi.stub}
  vm.export @__init
  vm.func private @__init() {
    %null = vm.const.ref.zero : !vm.ref<!hal.executable>
    %null_0 = vm.const.ref.zero : !vm.buffer
    %c4 = vm.const.i32 4
    %c7 = vm.const.i32 7
    %zero = vm.const.i32.zero
    %c1 = vm.const.i32 1
    %zero_1 = vm.const.i64.zero
    %c-1 = vm.const.i64 -1
    %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
    %_utf8_cuda_nvptx_fb_B15B42B96FDBACC = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
    %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
    %2 = vm.and.i32 %1, %c1 : i32
    %3 = vm.select.i32 %0#0, %2, %zero : i32
    %ref_2 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero, [(%zero, %c7, %c1), (%c1, %c7, %zero)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
    %ref_3 = vm.call.variadic @hal.pipeline_layout.create(%ref, %c4, [%ref_2]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
    %4 = vm.select.i64 %3, %zero_1, %c-1 : i64
    %5 = vm.trunc.i64.i32 %4 : i64 -> i32
    vm.global.store.i32 %3, @_device_query_0 : i32
    vm.global.store.ref %ref_3, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.br_table %5 {
      default: ^bb2,
      0: ^bb1
    }
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %main_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @main_dispatch_0_cuda_nvptx_fb : !vm.buffer
    %ref_4 = vm.call.variadic @hal.executable.create(%ref, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC, %main_dispatch_0_cuda_nvptx_fb, %null_0, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
    vm.br ^bb3(%ref_4 : !vm.ref<!hal.executable>)
  ^bb2:  // pred: ^bb0
    vm.br ^bb3(%null : !vm.ref<!hal.executable>)
  ^bb3(%6: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
    vm.global.store.ref %6, @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
    vm.return
  }
}

// -----// IR Dump After DropCompilerHints (iree-util-drop-compiler-hints) //----- //
vm.module public @LinearModule {
  vm.global.i32 private mutable @_device_query_0 : i32
  vm.global.ref private mutable @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
  vm.global.ref private mutable @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
  vm.rodata private @main_dispatch_0_cuda_nvptx_fb {alignment = 16 : i64, mime_type = "application/x-flatbuffers"} dense<"0x080000004355444108E5FFFF1C0000005000000044000000580000000400000001000000B81A00000100000004000000200000006D61696E5F64697370617463685F305F6D61746D756C5F44784478445F66333200000000010000000000000001000000200000000800000001000000641A00002F2F0A2F2F2047656E657261746564206279204C4C564D204E56505458204261636B2D456E640A2F2F0A0A2E76657273696F6E20372E350A2E74617267657420736D5F37350A2E616464726573735F73697A652036340A0A092F2F202E676C6F626C096D61696E5F64697370617463685F305F6D61746D756C5F44784478445F6633320A0A2E76697369626C65202E656E747279206D61696E5F64697370617463685F305F6D61746D756C5F44784478445F663332280A092E706172616D202E753634206D61696E5F64697370617463685F305F6D61746D756C5F44784478445F6633325F706172616D5F302C0A092E706172616D202E753634206D61696E5F64697370617463685F305F6D61746D756C5F44784478445F6633325F706172616D5F312C0A092E706172616D202E753332206D61696E5F64697370617463685F305F6D61746D756C5F44784478445F6633325F706172616D5F322C0A092E706172616D202E753332206D61696E5F64697370617463685F305F6D61746D756C5F44784478445F6633325F706172616D5F332C0A092E706172616D202E753332206D61696E5F64697370617463685F305F6D61746D756C5F44784478445F6633325F706172616D5F342C0A092E706172616D202E753332206D61696E5F64697370617463685F305F6D61746D756C5F44784478445F6633325F706172616D5F350A290A2E6D61786E7469642033322C20382C20310A7B0A092E726567202E70726564200925703C32313E3B0A092E726567202E623332200925723C31303E3B0A092E726567202E663332200925663C31343E3B0A092E726567202E62363420092572643C3136353E3B0A0A096C642E706172616D2E753332200925726436312C205B6D61696E5F64697370617463685F305F6D61746D756C5F44784478445F6633325F706172616D5F325D3B0A096C642E706172616D2E753332200925726436322C205B6D61696E5F64697370617463685F305F6D61746D756C5F44784478445F6633325F706172616D5F335D3B0A0973686C2E623634200925726436332C2025726436322C2033323B0A096F722E623634202009257264312C2025726436332C2025726436313B0A096C642E706172616D2E7533322009257264322C205B6D61696E5F64697370617463685F305F6D61746D756C5F44784478445F6633325F706172616D5F345D3B0A096C642E706172616D2E7533322009257264332C205B6D61696E5F64697370617463685F305F6D61746D756C5F44784478445F6633325F706172616D5F355D3B0A0973686C2E623634200925726436342C20257264332C2033323B0A096F722E623634202009257264342C2025726436342C20257264323B0A096D6F762E75333220092572312C202563746169642E783B0A096376742E7536342E7533322009257264352C202572313B0A09736574702E6C742E73363420092570312C20257264342C20313B0A096E65672E733634200925726436352C20257264343B0A096164642E733634200925726436362C20257264342C202D313B0A0973656C702E623634200925726436372C2025726436352C2025726436362C202570313B0A097368722E733634200925726436382C2025726436372C2036333B0A097368722E753634200925726436392C2025726436382C2035373B0A096164642E733634200925726437302C2025726436372C2025726436393B0A097368722E733634200925726437312C2025726437302C20373B0A096E65672E733634200925726437322C2025726437313B0A096164642E733634200925726437332C2025726437312C20313B0A0973656C702E623634200925726437342C2025726437322C2025726437332C202570313B0A09616E642E62363420200925726437352C2025726437342C202D343239343936373239363B0A09736574702E6E652E73363420092570322C2025726437352C20303B0A0940257032206272612009244C5F5F4242305F323B0A096272612E756E692009244C5F5F4242305F313B0A244C5F5F4242305F323A0A096469762E73363420092572643134382C20257264352C2025726437343B0A096272612E756E692009244C5F5F4242305F333B0A244C5F5F4242305F313A0A096376742E7533322E75363420092572332C2025726437343B0A096376742E7533322E75363420092572342C20257264353B0A096469762E75333220092572352C202572342C202572333B0A096376742E7536342E75333220092572643134382C202572353B0A244C5F5F4242305F333A0A096C642E706172616D2E753634200925726436302C205B6D61696E5F64697370617463685F305F6D61746D756C5F44784478445F6633325F706172616D5F315D3B0A0973686C2E623634200925726437362C202572643134382C20353B0A097375622E733634200925726437372C20257264312C2025726437363B0A096D696E2E733634200925726437382C2025726437372C2033323B0A096D756C2E6C6F2E733634200925726437392C202572643134382C2025726437343B0A097375622E733634200925726438302C20257264352C2025726437393B0A0973686C2E623634200925726438312C2025726438302C20373B0A097375622E733634200925726438322C20257264342C2025726438313B0A096D696E2E733634200925726438332C2025726438322C203132383B0A096D6F762E75333220092572362C20257469642E783B0A096376742E7536342E753332200925726438342C202572363B0A096D6F762E75333220092572372C20257469642E793B0A096376742E7536342E753332200925726438352C202572373B0A09736574702E6C742E73363420092570332C2025726437372C20313B0A096E65672E733634200925726438362C2025726437383B0A096164642E733634200925726438372C2025726437382C202D313B0A0973656C702E623634200925726438382C2025726438362C2025726438372C202570333B0A097368722E733634200925726438392C2025726438382C2036333B0A097368722E753634200925726439302C2025726438392C2036313B0A096164642E733634200925726439312C2025726438382C2025726439303B0A097368722E733634200925726439322C2025726439312C20333B0A096E65672E733634200925726439332C2025726439323B0A096164642E733634200925726439342C2025726439322C20313B0A0973656C702E623634200925726439352C2025726439332C2025726439342C202570333B0A096D756C2E6C6F2E733634200925726439362C2025726439352C2025726438353B0A097375622E733634200925726439372C2025726437382C2025726439363B0A096D696E2E733634200925726431302C2025726439372C2025726439353B0A09736574702E6C742E73363420092570342C2025726438322C20313B0A096E65672E733634200925726439382C2025726438333B0A096164642E733634200925726439392C2025726438332C202D313B0A0973656C702E62363420092572643130302C2025726439382C2025726439392C202570343B0A097368722E73363420092572643130312C202572643130302C2036333B0A097368722E75363420092572643130322C202572643130312C2035393B0A096164642E73363420092572643130332C202572643130302C202572643130323B0A097368722E73363420092572643130342C202572643130332C20353B0A096E65672E73363420092572643130352C202572643130343B0A096164642E73363420092572643130362C202572643130342C20313B0A0973656C702E62363420092572643130372C202572643130352C202572643130362C202570343B0A096D756C2E6C6F2E73363420092572643130382C202572643130372C2025726438343B0A097375622E73363420092572643130392C2025726438332C202572643130383B0A096D696E2E733634200925726431312C202572643130392C202572643130373B0A096164642E733634200925726431322C2025726439362C2025726437363B0A096164642E733634200925726431332C202572643130382C2025726438313B0A09736574702E6C742E73363420092570352C2025726431302C20313B0A096D756C2E6C6F2E73363420092572643134332C2025726431322C20257264343B0A0973686C2E62363420092572643134342C2025726431332C20323B0A0973686C2E62363420092572643134352C20257264332C2033343B0A0973686C2E62363420092572643134362C20257264322C20323B0A09736574702E6C742E7336342009257032302C2025726431312C20313B0A0940257035206272612009244C5F5F4242305F31333B0A096D6F762E75363420092572643135312C20303B0A09616E642E62363420200925726431392C2025726431312C20373B0A09616E642E62363420200925726431352C2025726431312C202D383B0A0973686C2E62363420092572643131322C202572643134332C20323B0A096164642E73363420092572643131342C202572643131322C202572643134343B0A096164642E73363420092572643134392C2025726436302C202572643131343B0A096164642E73363420092572643135302C202572643134392C2031363B0A096F722E62363420200925726431372C202572643134352C202572643134363B0A09736574702E6C742E75363420092570372C2025726431312C20383B0A096D6F762E62333220092572392C20303B0A096272612E756E692009244C5F5F4242305F353B0A244C5F5F4242305F31323A0A096164642E73363420092572643135312C202572643135312C20313B0A096164642E73363420092572643135302C202572643135302C2025726431373B0A096164642E73363420092572643134392C202572643134392C2025726431373B0A09736574702E65712E7336342009257031312C2025726431302C202572643135313B0A094025703131206272612009244C5F5F4242305F31333B0A244C5F5F4242305F353A0A094025703230206272612009244C5F5F4242305F31323B0A096D6F762E75363420092572643135342C20303B0A0940257037206272612009244C5F5F4242305F393B0A096D6F762E75363420092572643135342C20303B0A096D6F762E75363420092572643135322C202572643135303B0A244C5F5F4242305F383A0A0973742E676C6F62616C2E75333220095B2572643135322B2D31365D2C202572393B0A0973742E676C6F62616C2E75333220095B2572643135322B2D31325D2C202572393B0A0973742E676C6F62616C2E75333220095B2572643135322B2D385D2C202572393B0A0973742E676C6F62616C2E75333220095B2572643135322B2D345D2C202572393B0A0973742E676C6F62616C2E75333220095B2572643135325D2C202572393B0A0973742E676C6F62616C2E75333220095B2572643135322B345D2C202572393B0A0973742E676C6F62616C2E75333220095B2572643135322B385D2C202572393B0A0973742E676C6F62616C2E75333220095B2572643135322B31325D2C202572393B0A096164642E73363420092572643135342C202572643135342C20383B0A096164642E73363420092572643135322C202572643135322C2033323B0A09736574702E6E652E73363420092570382C2025726431352C202572643135343B0A0940257038206272612009244C5F5F4242305F383B0A244C5F5F4242305F393A0A09736574702E65712E73363420092570392C2025726431392C20303B0A0940257039206272612009244C5F5F4242305F31323B0A0973686C2E62363420092572643131392C202572643135342C20323B0A096164642E73363420092572643135362C202572643134392C202572643131393B0A096D6F762E75363420092572643135352C2025726431393B0A244C5F5F4242305F31313A0A092E707261676D6120226E6F756E726F6C6C223B0A0973742E676C6F62616C2E75333220095B2572643135365D2C202572393B0A096164642E73363420092572643135362C202572643135362C20343B0A096164642E73363420092572643135352C202572643135352C202D313B0A09736574702E6E652E7336342009257031302C202572643135352C20303B0A094025703130206272612009244C5F5F4242305F31313B0A096272612E756E692009244C5F5F4242305F31323B0A244C5F5F4242305F31333A0A0940257031206272612009244C5F5F4242305F32353B0A096C642E706172616D2E753634200925726435392C205B6D61696E5F64697370617463685F305F6D61746D756C5F44784478445F6633325F706172616D5F305D3B0A09616E642E62363420200925726432302C2025726431312C20313B0A09616E642E62363420200925726432312C2025726431312C202D323B0A0973686C2E62363420092572643132322C202572643134332C20323B0A096164642E73363420092572643132342C202572643132322C202572643134343B0A096164642E73363420092572643132352C202572643132342C2025726436303B0A096164642E733634200925726432322C202572643132352C20343B0A096F722E62363420200925726432332C202572643134352C202572643134363B0A096164642E73363420092572643132382C202572643134342C2025726435393B0A096164642E73363420092572643135372C202572643132382C20343B0A096D6F762E75363420092572643135382C20303B0A09736574702E65712E7336342009257031352C2025726431312C20313B0A09736574702E65712E7336342009257031372C2025726432302C20303B0A096272612E756E692009244C5F5F4242305F31353B0A244C5F5F4242305F32343A0A096164642E73363420092572643135382C202572643135382C20313B0A096164642E73363420092572643135372C202572643135372C2025726432333B0A09736574702E6E652E7336342009257031392C202572643135382C20257264343B0A094025703139206272612009244C5F5F4242305F31353B0A096272612E756E692009244C5F5F4242305F32353B0A244C5F5F4242305F31353A0A0940257035206272612009244C5F5F4242305F32343B0A0973686C2E62363420092572643133302C202572643135382C20323B0A096164642E733634200925726434332C2025726435392C202572643133303B0A096D756C2E6C6F2E73363420092572643133312C202572643135382C20257264343B0A0973686C2E62363420092572643133322C202572643133312C20323B0A096164642E733634200925726434342C2025726435392C202572643133323B0A096D6F762E75363420092572643136302C20303B0A096D6F762E75363420092572643135392C2025726432323B0A096272612E756E692009244C5F5F4242305F31373B0A244C5F5F4242305F32333A0A096164642E73363420092572643136302C202572643136302C20313B0A096164642E73363420092572643135392C202572643135392C2025726432333B0A09736574702E6E652E7336342009257031382C2025726431302C202572643136303B0A094025703138206272612009244C5F5F4242305F31373B0A096272612E756E692009244C5F5F4242305F32343B0A244C5F5F4242305F31373A0A094025703230206272612009244C5F5F4242305F32333B0A096164642E73363420092572643133342C202572643136302C2025726431323B0A096D756C2E6C6F2E73363420092572643133352C202572643133342C20257264343B0A0973686C2E62363420092572643133362C202572643133352C20323B0A096164642E73363420092572643133372C2025726434332C202572643133363B0A096C642E676C6F62616C2E6E632E66333220092566312C205B2572643133375D3B0A096D6F762E75363420092572643136342C20303B0A094025703135206272612009244C5F5F4242305F32313B0A096D6F762E75363420092572643136342C20303B0A096D6F762E75363420092572643136312C202572643135373B0A096D6F762E75363420092572643136322C202572643135393B0A244C5F5F4242305F32303A0A096C642E676C6F62616C2E6E632E66333220092566322C205B2572643136312B2D345D3B0A096C642E676C6F62616C2E66333220092566332C205B2572643136322B2D345D3B0A096D756C2E726E2E66333220092566342C202566312C202566323B0A096164642E726E2E66333220092566352C202566332C202566343B0A0973742E676C6F62616C2E66333220095B2572643136322B2D345D2C202566353B0A096C642E676C6F62616C2E6E632E66333220092566362C205B2572643136315D3B0A096C642E676C6F62616C2E66333220092566372C205B2572643136325D3B0A096D756C2E726E2E66333220092566382C202566312C202566363B0A096164642E726E2E66333220092566392C202566372C202566383B0A0973742E676C6F62616C2E66333220095B2572643136325D2C202566393B0A096164642E73363420092572643136342C202572643136342C20323B0A096164642E73363420092572643136322C202572643136322C20383B0A096164642E73363420092572643136312C202572643136312C20383B0A09736574702E6E652E7336342009257031362C2025726432312C202572643136343B0A094025703136206272612009244C5F5F4242305F32303B0A244C5F5F4242305F32313A0A094025703137206272612009244C5F5F4242305F32333B0A096164642E733634200925726434372C2025726436302C202572643133363B0A096164642E73363420092572643133392C202572643136342C2025726431333B0A0973686C2E62363420092572643134302C202572643133392C20323B0A096164642E73363420092572643134312C2025726434342C202572643134303B0A096C642E676C6F62616C2E6E632E6633322009256631302C205B2572643134315D3B0A096164642E73363420092572643134322C2025726434372C202572643134303B0A096C642E676C6F62616C2E6633322009256631312C205B2572643134325D3B0A096D756C2E726E2E6633322009256631322C202566312C20256631303B0A096164642E726E2E6633322009256631332C20256631312C20256631323B0A0973742E676C6F62616C2E66333220095B2572643134325D2C20256631333B0A096272612E756E692009244C5F5F4242305F32333B0A244C5F5F4242305F32353A0A097265743B0A0A7D0A00000000E4FFFFFF08000000020000000B000000696E707574322E6D6C69720008000C00040008000E001800040008000C0010001400"> : vector<6926xi8>
  vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
  vm.rodata private @_utf8_cuda_nvptx_fb_B15B42B96FDBACC {alignment = 1 : i64} "cuda-nvptx-fb"
  vm.import private @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects}
  vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
  vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
  vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
  vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
  vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
  vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer>
  vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
  vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
  vm.import private @hal.command_buffer.push_constants(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %offset : i32, %values : i32 ...)
  vm.import private @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32)
  vm.import private @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects}
  vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
  vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
  vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
  vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
  vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects}
  vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
  vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
  vm.import private @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects}
  vm.rodata private @_utf8_input_0_5FD512E67BEFDEEC {alignment = 1 : i64} "input 0"
  vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
  vm.func private @main(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
    %c13 = vm.const.i32 13
    %c28 = vm.const.i32 28
    %c3 = vm.const.i32 3
    %c17 = vm.const.i32 17
    %c32 = vm.const.i32 32
    %c48 = vm.const.i32 48
    %null = vm.const.ref.zero : !vm.ref<!hal.fence>
    %c3075 = vm.const.i32 3075
    %c16 = vm.const.i32 16
    %zero = vm.const.i32.zero
    %c32_0 = vm.const.i64 32
    %c128 = vm.const.i64 128
    %c553648160 = vm.const.i32 553648160
    %c1 = vm.const.i32 1
    %zero_1 = vm.const.i64.zero
    %c4 = vm.const.i64 4
    %c-1 = vm.const.i64 -1
    %c-1_2 = vm.const.i32 -1
    %c1_3 = vm.const.i64 1
    %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %_executable_main_dispatch_0 = vm.global.load.ref @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
    %0 = vm.call @hal.buffer_view.dim(%arg0, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %1 = vm.call @hal.buffer_view.dim(%arg0, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1, [%0, %1]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %2 = vm.mul.i64 %0, %c4 : i64
    %3 = vm.mul.i64 %2, %1 : i64
    %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
    vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %ref_6 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    %ref_7 = vm.call @hal.device.queue.alloca(%ref_4, %c-1, %null, %ref_6, %zero, %c48, %c3075, %3) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
    %4 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    %5 = vm.trunc.i64.i32 %0 : i64 -> i32
    %6 = vm.shr.i64.u %0, %c32 : i64
    %7 = vm.trunc.i64.i32 %6 : i64 -> i32
    %8 = vm.trunc.i64.i32 %1 : i64 -> i32
    %9 = vm.shr.i64.u %1, %c32 : i64
    %10 = vm.trunc.i64.i32 %9 : i64 -> i32
    %ref_8 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
    %11 = vm.select.i64 %_device_query_0, %zero_1, %c-1 : i64
    %12 = vm.trunc.i64.i32 %11 : i64 -> i32
    vm.br_table %12 {
      default: ^bb2,
      0: ^bb1
    }
  ^bb1:  // pred: ^bb0
    vm.call.variadic @hal.command_buffer.push_constants(%ref_8, %_pipeline_layout_0, %zero, [%5, %7, %8, %10]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, i32 ...)
    vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_8, %_pipeline_layout_0, %zero, [(%zero, %zero, %ref, %zero_1, %3), (%c1, %zero, %ref_7, %zero_1, %3)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    %slt = vm.cmp.lt.i64.s %zero_1, %1 : i64
    %13 = vm.xor.i32 %slt, %c1 : i32
    %14 = vm.sub.i64 %zero_1, %1 : i64
    %15 = vm.sub.i64 %1, %c1_3 : i64
    %16 = vm.select.i64 %13, %14, %15 : i64
    %17 = vm.div.i64.s %16, %c128 : i64
    %18 = vm.sub.i64 %zero_1, %17 : i64
    %19 = vm.add.i64 %17, %c1_3 : i64
    %20 = vm.select.i64 %13, %18, %19 : i64
    %slt_9 = vm.cmp.lt.i64.s %zero_1, %0 : i64
    %21 = vm.xor.i32 %slt_9, %c1 : i32
    %22 = vm.sub.i64 %zero_1, %0 : i64
    %23 = vm.sub.i64 %0, %c1_3 : i64
    %24 = vm.select.i64 %21, %22, %23 : i64
    %25 = vm.div.i64.s %24, %c32_0 : i64
    %26 = vm.sub.i64 %zero_1, %25 : i64
    %27 = vm.add.i64 %25, %c1_3 : i64
    %28 = vm.select.i64 %21, %26, %27 : i64
    %29 = vm.mul.i64 %20, %28 : i64
    %30 = vm.trunc.i64.i32 %29 : i64 -> i32
    vm.call @hal.command_buffer.dispatch(%ref_8, %_executable_main_dispatch_0, %zero, %30, %c1, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
    vm.br ^bb2
  ^bb2:  // 2 preds: ^bb0, ^bb1
    vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
    vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
    %ref_10 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    %31 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1, %null, %ref_10, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
    %32 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_10]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    vm.cond_br %32, ^bb4, ^bb3
  ^bb3:  // pred: ^bb2
    %ref_11 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_1, %3, %c553648160, %c1, [%0, %1]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
    vm.return %ref_11 : !vm.ref<!hal.buffer_view>
  ^bb4:  // pred: ^bb2
    vm.fail %32, "failed to wait on timepoint"
  }
  vm.export @main attributes {iree.abi.stub}
  vm.export @__init
  vm.func private @__init() {
    %null = vm.const.ref.zero : !vm.ref<!hal.executable>
    %null_0 = vm.const.ref.zero : !vm.buffer
    %c4 = vm.const.i32 4
    %c7 = vm.const.i32 7
    %zero = vm.const.i32.zero
    %c1 = vm.const.i32 1
    %zero_1 = vm.const.i64.zero
    %c-1 = vm.const.i64 -1
    %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
    %_utf8_cuda_nvptx_fb_B15B42B96FDBACC = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
    %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
    %2 = vm.and.i32 %1, %c1 : i32
    %3 = vm.select.i32 %0#0, %2, %zero : i32
    %ref_2 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero, [(%zero, %c7, %c1), (%c1, %c7, %zero)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
    %ref_3 = vm.call.variadic @hal.pipeline_layout.create(%ref, %c4, [%ref_2]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
    %4 = vm.select.i64 %3, %zero_1, %c-1 : i64
    %5 = vm.trunc.i64.i32 %4 : i64 -> i32
    vm.global.store.i32 %3, @_device_query_0 : i32
    vm.global.store.ref %ref_3, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.br_table %5 {
      default: ^bb2,
      0: ^bb1
    }
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %main_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @main_dispatch_0_cuda_nvptx_fb : !vm.buffer
    %ref_4 = vm.call.variadic @hal.executable.create(%ref, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC, %main_dispatch_0_cuda_nvptx_fb, %null_0, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
    vm.br ^bb3(%ref_4 : !vm.ref<!hal.executable>)
  ^bb2:  // pred: ^bb0
    vm.br ^bb3(%null : !vm.ref<!hal.executable>)
  ^bb3(%6: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
    vm.global.store.ref %6, @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
    vm.return
  }
}

// -----// IR Dump After mlir::iree_compiler::IREE::VM::OrdinalAllocationPass (iree-vm-ordinal-allocation) //----- //
vm.module public @LinearModule attributes {ordinal_counts = #vm.ordinal_counts<import_funcs = 21, export_funcs = 2, internal_funcs = 2, global_bytes = 4, global_refs = 2, rodatas = 5, rwdatas = 0>} {
  vm.global.i32 private mutable @_device_query_0 {ordinal = 0 : i32} : i32
  vm.global.ref private mutable @_pipeline_layout_0 {ordinal = 0 : i32} : !vm.ref<!hal.pipeline_layout>
  vm.global.ref private mutable @_executable_main_dispatch_0 {ordinal = 1 : i32} : !vm.ref<!hal.executable>
  vm.rodata private @main_dispatch_0_cuda_nvptx_fb {alignment = 16 : i64, mime_type = "application/x-flatbuffers", ordinal = 0 : i32} dense<"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vector<6926xi8>
  vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64, ordinal = 1 : i32} "hal.executable.format"
  vm.rodata private @_utf8_cuda_nvptx_fb_B15B42B96FDBACC {alignment = 1 : i64, ordinal = 2 : i32} "cuda-nvptx-fb"
  vm.import private @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects, ordinal = 0 : i32}
  vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32) attributes {ordinal = 1 : i32}
  vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects, ordinal = 2 : i32}
  vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...) attributes {ordinal = 3 : i32}
  vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects, ordinal = 4 : i32}
  vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects, ordinal = 5 : i32}
  vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {ordinal = 6 : i32}
  vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>) attributes {ordinal = 7 : i32}
  vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32) attributes {ordinal = 8 : i32}
  vm.import private @hal.command_buffer.push_constants(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %offset : i32, %values : i32 ...) attributes {ordinal = 9 : i32}
  vm.import private @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...) attributes {ordinal = 10 : i32}
  vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32) attributes {ordinal = 11 : i32}
  vm.import private @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects, ordinal = 12 : i32}
  vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects, ordinal = 13 : i32}
  vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects, ordinal = 14 : i32}
  vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {ordinal = 15 : i32}
  vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...) attributes {ordinal = 16 : i32}
  vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects, ordinal = 17 : i32}
  vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence> attributes {ordinal = 18 : i32}
  vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {ordinal = 19 : i32, vm.yield}
  vm.import private @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects, ordinal = 20 : i32}
  vm.rodata private @_utf8_input_0_5FD512E67BEFDEEC {alignment = 1 : i64, ordinal = 3 : i32} "input 0"
  vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64, ordinal = 4 : i32} "tensor"
  vm.func private @main(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> attributes {ordinal = 0 : i32} {
    %c13 = vm.const.i32 13
    %c28 = vm.const.i32 28
    %c3 = vm.const.i32 3
    %c17 = vm.const.i32 17
    %c32 = vm.const.i32 32
    %c48 = vm.const.i32 48
    %null = vm.const.ref.zero : !vm.ref<!hal.fence>
    %c3075 = vm.const.i32 3075
    %c16 = vm.const.i32 16
    %zero = vm.const.i32.zero
    %c32_0 = vm.const.i64 32
    %c128 = vm.const.i64 128
    %c553648160 = vm.const.i32 553648160
    %c1 = vm.const.i32 1
    %zero_1 = vm.const.i64.zero
    %c4 = vm.const.i64 4
    %c-1 = vm.const.i64 -1
    %c-1_2 = vm.const.i32 -1
    %c1_3 = vm.const.i64 1
    %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %_executable_main_dispatch_0 = vm.global.load.ref @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
    %0 = vm.call @hal.buffer_view.dim(%arg0, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %1 = vm.call @hal.buffer_view.dim(%arg0, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1, [%0, %1]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %2 = vm.mul.i64 %0, %c4 : i64
    %3 = vm.mul.i64 %2, %1 : i64
    %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
    vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %ref_6 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    %ref_7 = vm.call @hal.device.queue.alloca(%ref_4, %c-1, %null, %ref_6, %zero, %c48, %c3075, %3) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
    %4 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    %5 = vm.trunc.i64.i32 %0 : i64 -> i32
    %6 = vm.shr.i64.u %0, %c32 : i64
    %7 = vm.trunc.i64.i32 %6 : i64 -> i32
    %8 = vm.trunc.i64.i32 %1 : i64 -> i32
    %9 = vm.shr.i64.u %1, %c32 : i64
    %10 = vm.trunc.i64.i32 %9 : i64 -> i32
    %ref_8 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
    %11 = vm.select.i64 %_device_query_0, %zero_1, %c-1 : i64
    %12 = vm.trunc.i64.i32 %11 : i64 -> i32
    vm.br_table %12 {
      default: ^bb2,
      0: ^bb1
    }
  ^bb1:  // pred: ^bb0
    vm.call.variadic @hal.command_buffer.push_constants(%ref_8, %_pipeline_layout_0, %zero, [%5, %7, %8, %10]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, i32 ...)
    vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_8, %_pipeline_layout_0, %zero, [(%zero, %zero, %ref, %zero_1, %3), (%c1, %zero, %ref_7, %zero_1, %3)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    %slt = vm.cmp.lt.i64.s %zero_1, %1 : i64
    %13 = vm.xor.i32 %slt, %c1 : i32
    %14 = vm.sub.i64 %zero_1, %1 : i64
    %15 = vm.sub.i64 %1, %c1_3 : i64
    %16 = vm.select.i64 %13, %14, %15 : i64
    %17 = vm.div.i64.s %16, %c128 : i64
    %18 = vm.sub.i64 %zero_1, %17 : i64
    %19 = vm.add.i64 %17, %c1_3 : i64
    %20 = vm.select.i64 %13, %18, %19 : i64
    %slt_9 = vm.cmp.lt.i64.s %zero_1, %0 : i64
    %21 = vm.xor.i32 %slt_9, %c1 : i32
    %22 = vm.sub.i64 %zero_1, %0 : i64
    %23 = vm.sub.i64 %0, %c1_3 : i64
    %24 = vm.select.i64 %21, %22, %23 : i64
    %25 = vm.div.i64.s %24, %c32_0 : i64
    %26 = vm.sub.i64 %zero_1, %25 : i64
    %27 = vm.add.i64 %25, %c1_3 : i64
    %28 = vm.select.i64 %21, %26, %27 : i64
    %29 = vm.mul.i64 %20, %28 : i64
    %30 = vm.trunc.i64.i32 %29 : i64 -> i32
    vm.call @hal.command_buffer.dispatch(%ref_8, %_executable_main_dispatch_0, %zero, %30, %c1, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
    vm.br ^bb2
  ^bb2:  // 2 preds: ^bb0, ^bb1
    vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
    vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
    %ref_10 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    %31 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1, %null, %ref_10, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
    %32 = vm.call.variadic @hal.fence.await(%c-1_2, [%ref_10]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    vm.cond_br %32, ^bb4, ^bb3
  ^bb3:  // pred: ^bb2
    %ref_11 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_1, %3, %c553648160, %c1, [%0, %1]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
    vm.return %ref_11 : !vm.ref<!hal.buffer_view>
  ^bb4:  // pred: ^bb2
    vm.fail %32, "failed to wait on timepoint"
  }
  vm.export @main attributes {iree.abi.stub, ordinal = 0 : i32}
  vm.export @__init attributes {ordinal = 1 : i32}
  vm.func private @__init() attributes {ordinal = 1 : i32} {
    %null = vm.const.ref.zero : !vm.ref<!hal.executable>
    %null_0 = vm.const.ref.zero : !vm.buffer
    %c4 = vm.const.i32 4
    %c7 = vm.const.i32 7
    %zero = vm.const.i32.zero
    %c1 = vm.const.i32 1
    %zero_1 = vm.const.i64.zero
    %c-1 = vm.const.i64 -1
    %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
    %_utf8_cuda_nvptx_fb_B15B42B96FDBACC = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
    %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
    %2 = vm.and.i32 %1, %c1 : i32
    %3 = vm.select.i32 %0#0, %2, %zero : i32
    %ref_2 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero, [(%zero, %c7, %c1), (%c1, %c7, %zero)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
    %ref_3 = vm.call.variadic @hal.pipeline_layout.create(%ref, %c4, [%ref_2]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
    %4 = vm.select.i64 %3, %zero_1, %c-1 : i64
    %5 = vm.trunc.i64.i32 %4 : i64 -> i32
    vm.global.store.i32 %3, @_device_query_0 : i32
    vm.global.store.ref %ref_3, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.br_table %5 {
      default: ^bb2,
      0: ^bb1
    }
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %main_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @main_dispatch_0_cuda_nvptx_fb : !vm.buffer
    %ref_4 = vm.call.variadic @hal.executable.create(%ref, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC, %main_dispatch_0_cuda_nvptx_fb, %null_0, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
    vm.br ^bb3(%ref_4 : !vm.ref<!hal.executable>)
  ^bb2:  // pred: ^bb0
    vm.br ^bb3(%null : !vm.ref<!hal.executable>)
  ^bb3(%6: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
    vm.global.store.ref %6, @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
    vm.return
  }
}

