// -----// IR Dump After mlir::iree_compiler::IREE::HAL::AssignTargetDevicesPass (iree-hal-assign-target-devices) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private @_params.weight {noinline} = dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>
  util.global private @_params.bias {noinline} = dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>
  func.func @main(%arg0: tensor<4xf32>) -> tensor<3xf32> attributes {torch.args_schema = "[1, {\22type\22: \22builtins.tuple\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: \22builtins.list\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: null, \22context\22: null, \22children_spec\22: []}]}, {\22type\22: \22builtins.dict\22, \22context\22: \22[]\22, \22children_spec\22: []}]}]", torch.return_schema = "[1, {\22type\22: null, \22context\22: null, \22children_spec\22: []}]"} {
    %0 = torch_c.from_builtin_tensor %arg0 : tensor<4xf32> -> !torch.vtensor<[4],f32>
    %1 = call @forward(%0) : (!torch.vtensor<[4],f32>) -> !torch.vtensor<[3],f32>
    %2 = torch_c.to_builtin_tensor %1 : !torch.vtensor<[3],f32> -> tensor<3xf32>
    return %2 : tensor<3xf32>
  }
  func.func private @forward(%arg0: !torch.vtensor<[4],f32>) -> !torch.vtensor<[3],f32> {
    %int0 = torch.constant.int 0
    %0 = torch.aten.unsqueeze %arg0, %int0 : !torch.vtensor<[4],f32>, !torch.int -> !torch.vtensor<[1,4],f32>
    %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
    %1 = torch_c.from_builtin_tensor %_params.weight : tensor<4x3xf32> -> !torch.vtensor<[4,3],f32>
    %2 = torch.aten.mm %0, %1 : !torch.vtensor<[1,4],f32>, !torch.vtensor<[4,3],f32> -> !torch.vtensor<[1,3],f32>
    %int0_0 = torch.constant.int 0
    %3 = torch.aten.squeeze.dim %2, %int0_0 : !torch.vtensor<[1,3],f32>, !torch.int -> !torch.vtensor<[3],f32>
    %_params.bias = util.global.load @_params.bias : tensor<3xf32>
    %4 = torch_c.from_builtin_tensor %_params.bias : tensor<3xf32> -> !torch.vtensor<[3],f32>
    %int1 = torch.constant.int 1
    %5 = torch.aten.add.Tensor %3, %4, %int1 : !torch.vtensor<[3],f32>, !torch.vtensor<[3],f32>, !torch.int -> !torch.vtensor<[3],f32>
    return %5 : !torch.vtensor<[3],f32>
  }
}


// -----// IR Dump After SetStrictSymbolicShapesPass (torch-iree-set-strict-symbolic-shapes) //----- //
func.func @main(%arg0: tensor<4xf32>) -> tensor<3xf32> attributes {torch.args_schema = "[1, {\22type\22: \22builtins.tuple\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: \22builtins.list\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: null, \22context\22: null, \22children_spec\22: []}]}, {\22type\22: \22builtins.dict\22, \22context\22: \22[]\22, \22children_spec\22: []}]}]", torch.assume_strict_symbolic_shapes, torch.return_schema = "[1, {\22type\22: null, \22context\22: null, \22children_spec\22: []}]"} {
  %0 = torch_c.from_builtin_tensor %arg0 : tensor<4xf32> -> !torch.vtensor<[4],f32>
  %1 = call @forward(%0) : (!torch.vtensor<[4],f32>) -> !torch.vtensor<[3],f32>
  %2 = torch_c.to_builtin_tensor %1 : !torch.vtensor<[3],f32> -> tensor<3xf32>
  return %2 : tensor<3xf32>
}

// -----// IR Dump After SetStrictSymbolicShapesPass (torch-iree-set-strict-symbolic-shapes) //----- //
func.func private @forward(%arg0: !torch.vtensor<[4],f32>) -> !torch.vtensor<[3],f32> attributes {torch.assume_strict_symbolic_shapes} {
  %int0 = torch.constant.int 0
  %0 = torch.aten.unsqueeze %arg0, %int0 : !torch.vtensor<[4],f32>, !torch.int -> !torch.vtensor<[1,4],f32>
  %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
  %1 = torch_c.from_builtin_tensor %_params.weight : tensor<4x3xf32> -> !torch.vtensor<[4,3],f32>
  %2 = torch.aten.mm %0, %1 : !torch.vtensor<[1,4],f32>, !torch.vtensor<[4,3],f32> -> !torch.vtensor<[1,3],f32>
  %int0_0 = torch.constant.int 0
  %3 = torch.aten.squeeze.dim %2, %int0_0 : !torch.vtensor<[1,3],f32>, !torch.int -> !torch.vtensor<[3],f32>
  %_params.bias = util.global.load @_params.bias : tensor<3xf32>
  %4 = torch_c.from_builtin_tensor %_params.bias : tensor<3xf32> -> !torch.vtensor<[3],f32>
  %int1 = torch.constant.int 1
  %5 = torch.aten.add.Tensor %3, %4, %int1 : !torch.vtensor<[3],f32>, !torch.vtensor<[3],f32>, !torch.int -> !torch.vtensor<[3],f32>
  return %5 : !torch.vtensor<[3],f32>
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main(%arg0: tensor<4xf32>) -> tensor<3xf32> attributes {torch.args_schema = "[1, {\22type\22: \22builtins.tuple\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: \22builtins.list\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: null, \22context\22: null, \22children_spec\22: []}]}, {\22type\22: \22builtins.dict\22, \22context\22: \22[]\22, \22children_spec\22: []}]}]", torch.assume_strict_symbolic_shapes, torch.return_schema = "[1, {\22type\22: null, \22context\22: null, \22children_spec\22: []}]"} {
  %0 = torch_c.from_builtin_tensor %arg0 : tensor<4xf32> -> !torch.vtensor<[4],f32>
  %1 = call @forward(%0) : (!torch.vtensor<[4],f32>) -> !torch.vtensor<[3],f32>
  %2 = torch_c.to_builtin_tensor %1 : !torch.vtensor<[3],f32> -> tensor<3xf32>
  return %2 : tensor<3xf32>
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func private @forward(%arg0: !torch.vtensor<[4],f32>) -> !torch.vtensor<[3],f32> attributes {torch.assume_strict_symbolic_shapes} {
  %int1 = torch.constant.int 1
  %int0 = torch.constant.int 0
  %0 = torch.aten.unsqueeze %arg0, %int0 : !torch.vtensor<[4],f32>, !torch.int -> !torch.vtensor<[1,4],f32>
  %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
  %1 = torch_c.from_builtin_tensor %_params.weight : tensor<4x3xf32> -> !torch.vtensor<[4,3],f32>
  %2 = torch.aten.mm %0, %1 : !torch.vtensor<[1,4],f32>, !torch.vtensor<[4,3],f32> -> !torch.vtensor<[1,3],f32>
  %3 = torch.aten.squeeze.dim %2, %int0 : !torch.vtensor<[1,3],f32>, !torch.int -> !torch.vtensor<[3],f32>
  %_params.bias = util.global.load @_params.bias : tensor<3xf32>
  %4 = torch_c.from_builtin_tensor %_params.bias : tensor<3xf32> -> !torch.vtensor<[3],f32>
  %5 = torch.aten.add.Tensor %3, %4, %int1 : !torch.vtensor<[3],f32>, !torch.vtensor<[3],f32>, !torch.int -> !torch.vtensor<[3],f32>
  return %5 : !torch.vtensor<[3],f32>
}

// -----// IR Dump After BitCastQuantTensorPass (torch-iree-bitcast-quant-tensor) //----- //
func.func @main(%arg0: tensor<4xf32>) -> tensor<3xf32> attributes {torch.args_schema = "[1, {\22type\22: \22builtins.tuple\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: \22builtins.list\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: null, \22context\22: null, \22children_spec\22: []}]}, {\22type\22: \22builtins.dict\22, \22context\22: \22[]\22, \22children_spec\22: []}]}]", torch.assume_strict_symbolic_shapes, torch.return_schema = "[1, {\22type\22: null, \22context\22: null, \22children_spec\22: []}]"} {
  %0 = torch_c.from_builtin_tensor %arg0 : tensor<4xf32> -> !torch.vtensor<[4],f32>
  %1 = call @forward(%0) : (!torch.vtensor<[4],f32>) -> !torch.vtensor<[3],f32>
  %2 = torch_c.to_builtin_tensor %1 : !torch.vtensor<[3],f32> -> tensor<3xf32>
  return %2 : tensor<3xf32>
}

// -----// IR Dump After BitCastQuantTensorPass (torch-iree-bitcast-quant-tensor) //----- //
func.func private @forward(%arg0: !torch.vtensor<[4],f32>) -> !torch.vtensor<[3],f32> attributes {torch.assume_strict_symbolic_shapes} {
  %int1 = torch.constant.int 1
  %int0 = torch.constant.int 0
  %0 = torch.aten.unsqueeze %arg0, %int0 : !torch.vtensor<[4],f32>, !torch.int -> !torch.vtensor<[1,4],f32>
  %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
  %1 = torch_c.from_builtin_tensor %_params.weight : tensor<4x3xf32> -> !torch.vtensor<[4,3],f32>
  %2 = torch.aten.mm %0, %1 : !torch.vtensor<[1,4],f32>, !torch.vtensor<[4,3],f32> -> !torch.vtensor<[1,3],f32>
  %3 = torch.aten.squeeze.dim %2, %int0 : !torch.vtensor<[1,3],f32>, !torch.int -> !torch.vtensor<[3],f32>
  %_params.bias = util.global.load @_params.bias : tensor<3xf32>
  %4 = torch_c.from_builtin_tensor %_params.bias : tensor<3xf32> -> !torch.vtensor<[3],f32>
  %5 = torch.aten.add.Tensor %3, %4, %int1 : !torch.vtensor<[3],f32>, !torch.vtensor<[3],f32>, !torch.int -> !torch.vtensor<[3],f32>
  return %5 : !torch.vtensor<[3],f32>
}

// -----// IR Dump After ConvertCustomQuantOp (torch-convert-custom-quant-op) //----- //
func.func @main(%arg0: tensor<4xf32>) -> tensor<3xf32> attributes {torch.args_schema = "[1, {\22type\22: \22builtins.tuple\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: \22builtins.list\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: null, \22context\22: null, \22children_spec\22: []}]}, {\22type\22: \22builtins.dict\22, \22context\22: \22[]\22, \22children_spec\22: []}]}]", torch.assume_strict_symbolic_shapes, torch.return_schema = "[1, {\22type\22: null, \22context\22: null, \22children_spec\22: []}]"} {
  %0 = torch_c.from_builtin_tensor %arg0 : tensor<4xf32> -> !torch.vtensor<[4],f32>
  %1 = call @forward(%0) : (!torch.vtensor<[4],f32>) -> !torch.vtensor<[3],f32>
  %2 = torch_c.to_builtin_tensor %1 : !torch.vtensor<[3],f32> -> tensor<3xf32>
  return %2 : tensor<3xf32>
}

// -----// IR Dump After ConvertCustomQuantOp (torch-convert-custom-quant-op) //----- //
func.func private @forward(%arg0: !torch.vtensor<[4],f32>) -> !torch.vtensor<[3],f32> attributes {torch.assume_strict_symbolic_shapes} {
  %int1 = torch.constant.int 1
  %int0 = torch.constant.int 0
  %0 = torch.aten.unsqueeze %arg0, %int0 : !torch.vtensor<[4],f32>, !torch.int -> !torch.vtensor<[1,4],f32>
  %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
  %1 = torch_c.from_builtin_tensor %_params.weight : tensor<4x3xf32> -> !torch.vtensor<[4,3],f32>
  %2 = torch.aten.mm %0, %1 : !torch.vtensor<[1,4],f32>, !torch.vtensor<[4,3],f32> -> !torch.vtensor<[1,3],f32>
  %3 = torch.aten.squeeze.dim %2, %int0 : !torch.vtensor<[1,3],f32>, !torch.int -> !torch.vtensor<[3],f32>
  %_params.bias = util.global.load @_params.bias : tensor<3xf32>
  %4 = torch_c.from_builtin_tensor %_params.bias : tensor<3xf32> -> !torch.vtensor<[3],f32>
  %5 = torch.aten.add.Tensor %3, %4, %int1 : !torch.vtensor<[3],f32>, !torch.vtensor<[3],f32>, !torch.int -> !torch.vtensor<[3],f32>
  return %5 : !torch.vtensor<[3],f32>
}

// -----// IR Dump After DecomposeComplexOps (torch-decompose-complex-ops) //----- //
func.func @main(%arg0: tensor<4xf32>) -> tensor<3xf32> attributes {torch.args_schema = "[1, {\22type\22: \22builtins.tuple\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: \22builtins.list\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: null, \22context\22: null, \22children_spec\22: []}]}, {\22type\22: \22builtins.dict\22, \22context\22: \22[]\22, \22children_spec\22: []}]}]", torch.assume_strict_symbolic_shapes, torch.return_schema = "[1, {\22type\22: null, \22context\22: null, \22children_spec\22: []}]"} {
  %0 = torch_c.from_builtin_tensor %arg0 : tensor<4xf32> -> !torch.vtensor<[4],f32>
  %1 = call @forward(%0) : (!torch.vtensor<[4],f32>) -> !torch.vtensor<[3],f32>
  %2 = torch_c.to_builtin_tensor %1 : !torch.vtensor<[3],f32> -> tensor<3xf32>
  return %2 : tensor<3xf32>
}

// -----// IR Dump After DecomposeComplexOps (torch-decompose-complex-ops) //----- //
func.func private @forward(%arg0: !torch.vtensor<[4],f32>) -> !torch.vtensor<[3],f32> attributes {torch.assume_strict_symbolic_shapes} {
  %int1 = torch.constant.int 1
  %int0 = torch.constant.int 0
  %0 = torch.aten.unsqueeze %arg0, %int0 : !torch.vtensor<[4],f32>, !torch.int -> !torch.vtensor<[1,4],f32>
  %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
  %1 = torch_c.from_builtin_tensor %_params.weight : tensor<4x3xf32> -> !torch.vtensor<[4,3],f32>
  %2 = torch.aten.mm %0, %1 : !torch.vtensor<[1,4],f32>, !torch.vtensor<[4,3],f32> -> !torch.vtensor<[1,3],f32>
  %3 = torch.aten.squeeze.dim %2, %int0 : !torch.vtensor<[1,3],f32>, !torch.int -> !torch.vtensor<[3],f32>
  %_params.bias = util.global.load @_params.bias : tensor<3xf32>
  %4 = torch_c.from_builtin_tensor %_params.bias : tensor<3xf32> -> !torch.vtensor<[3],f32>
  %5 = torch.aten.add.Tensor %3, %4, %int1 : !torch.vtensor<[3],f32>, !torch.vtensor<[3],f32>, !torch.int -> !torch.vtensor<[3],f32>
  return %5 : !torch.vtensor<[3],f32>
}

// -----// IR Dump After ConvertTorchToTMTensor (convert-torch-to-tmtensor) //----- //
func.func @main(%arg0: tensor<4xf32>) -> tensor<3xf32> attributes {torch.args_schema = "[1, {\22type\22: \22builtins.tuple\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: \22builtins.list\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: null, \22context\22: null, \22children_spec\22: []}]}, {\22type\22: \22builtins.dict\22, \22context\22: \22[]\22, \22children_spec\22: []}]}]", torch.assume_strict_symbolic_shapes, torch.return_schema = "[1, {\22type\22: null, \22context\22: null, \22children_spec\22: []}]"} {
  %0 = torch_c.from_builtin_tensor %arg0 : tensor<4xf32> -> !torch.vtensor<[4],f32>
  %1 = call @forward(%0) : (!torch.vtensor<[4],f32>) -> !torch.vtensor<[3],f32>
  %2 = torch_c.to_builtin_tensor %1 : !torch.vtensor<[3],f32> -> tensor<3xf32>
  return %2 : tensor<3xf32>
}

// -----// IR Dump After ConvertTorchToTMTensor (convert-torch-to-tmtensor) //----- //
func.func private @forward(%arg0: !torch.vtensor<[4],f32>) -> !torch.vtensor<[3],f32> attributes {torch.assume_strict_symbolic_shapes} {
  %int1 = torch.constant.int 1
  %int0 = torch.constant.int 0
  %0 = torch.aten.unsqueeze %arg0, %int0 : !torch.vtensor<[4],f32>, !torch.int -> !torch.vtensor<[1,4],f32>
  %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
  %1 = torch_c.from_builtin_tensor %_params.weight : tensor<4x3xf32> -> !torch.vtensor<[4,3],f32>
  %2 = torch.aten.mm %0, %1 : !torch.vtensor<[1,4],f32>, !torch.vtensor<[4,3],f32> -> !torch.vtensor<[1,3],f32>
  %3 = torch.aten.squeeze.dim %2, %int0 : !torch.vtensor<[1,3],f32>, !torch.int -> !torch.vtensor<[3],f32>
  %_params.bias = util.global.load @_params.bias : tensor<3xf32>
  %4 = torch_c.from_builtin_tensor %_params.bias : tensor<3xf32> -> !torch.vtensor<[3],f32>
  %5 = torch.aten.add.Tensor %3, %4, %int1 : !torch.vtensor<[3],f32>, !torch.vtensor<[3],f32>, !torch.int -> !torch.vtensor<[3],f32>
  return %5 : !torch.vtensor<[3],f32>
}

// -----// IR Dump After ConvertTorchToLinalg (convert-torch-to-linalg) //----- //
func.func @main(%arg0: tensor<4xf32>) -> tensor<3xf32> attributes {torch.args_schema = "[1, {\22type\22: \22builtins.tuple\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: \22builtins.list\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: null, \22context\22: null, \22children_spec\22: []}]}, {\22type\22: \22builtins.dict\22, \22context\22: \22[]\22, \22children_spec\22: []}]}]", torch.assume_strict_symbolic_shapes, torch.return_schema = "[1, {\22type\22: null, \22context\22: null, \22children_spec\22: []}]"} {
  %0 = torch_c.from_builtin_tensor %arg0 : tensor<4xf32> -> !torch.vtensor<[4],f32>
  %1 = call @forward(%0) : (!torch.vtensor<[4],f32>) -> !torch.vtensor<[3],f32>
  %2 = torch_c.to_builtin_tensor %1 : !torch.vtensor<[3],f32> -> tensor<3xf32>
  return %2 : tensor<3xf32>
}

// -----// IR Dump After ConvertTorchToLinalg (convert-torch-to-linalg) //----- //
func.func private @forward(%arg0: !torch.vtensor<[4],f32>) -> !torch.vtensor<[3],f32> attributes {torch.assume_strict_symbolic_shapes} {
  %0 = torch_c.to_builtin_tensor %arg0 : !torch.vtensor<[4],f32> -> tensor<4xf32>
  %int1 = torch.constant.int 1
  %1 = torch_c.to_i64 %int1
  %int0 = torch.constant.int 0
  %expanded = tensor.expand_shape %0 [[0, 1]] : tensor<4xf32> into tensor<1x4xf32>
  %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
  %2 = torch_c.from_builtin_tensor %_params.weight : tensor<4x3xf32> -> !torch.vtensor<[4,3],f32>
  %3 = torch_c.to_builtin_tensor %2 : !torch.vtensor<[4,3],f32> -> tensor<4x3xf32>
  %c0 = arith.constant 0 : index
  %dim = tensor.dim %expanded, %c0 : tensor<1x4xf32>
  %c1 = arith.constant 1 : index
  %dim_0 = tensor.dim %3, %c1 : tensor<4x3xf32>
  %4 = tensor.empty(%dim, %dim_0) : tensor<?x?xf32>
  %cst = arith.constant 0.000000e+00 : f32
  %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %6 = linalg.matmul ins(%expanded, %3 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%5 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %cast = tensor.cast %6 : tensor<?x?xf32> to tensor<1x3xf32>
  %collapsed = tensor.collapse_shape %cast [[0, 1]] : tensor<1x3xf32> into tensor<3xf32>
  %_params.bias = util.global.load @_params.bias : tensor<3xf32>
  %7 = torch_c.from_builtin_tensor %_params.bias : tensor<3xf32> -> !torch.vtensor<[3],f32>
  %8 = torch_c.to_builtin_tensor %7 : !torch.vtensor<[3],f32> -> tensor<3xf32>
  %c1_1 = arith.constant 1 : index
  %c0_2 = arith.constant 0 : index
  %c3 = arith.constant 3 : index
  %c0_3 = arith.constant 0 : index
  %c3_4 = arith.constant 3 : index
  %9 = tensor.empty() : tensor<3xf32>
  %10 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%collapsed, %8 : tensor<3xf32>, tensor<3xf32>) outs(%9 : tensor<3xf32>) {
  ^bb0(%in: f32, %in_6: f32, %out: f32):
    %12 = arith.sitofp %1 : i64 to f32
    %13 = arith.mulf %in_6, %12 : f32
    %14 = arith.addf %in, %13 : f32
    linalg.yield %14 : f32
  } -> tensor<3xf32>
  %cast_5 = tensor.cast %10 : tensor<3xf32> to tensor<3xf32>
  %11 = torch_c.from_builtin_tensor %cast_5 : tensor<3xf32> -> !torch.vtensor<[3],f32>
  return %11 : !torch.vtensor<[3],f32>
}

// -----// IR Dump After ConvertTorchToSCF (convert-torch-to-scf) //----- //
func.func @main(%arg0: tensor<4xf32>) -> tensor<3xf32> attributes {torch.args_schema = "[1, {\22type\22: \22builtins.tuple\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: \22builtins.list\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: null, \22context\22: null, \22children_spec\22: []}]}, {\22type\22: \22builtins.dict\22, \22context\22: \22[]\22, \22children_spec\22: []}]}]", torch.assume_strict_symbolic_shapes, torch.return_schema = "[1, {\22type\22: null, \22context\22: null, \22children_spec\22: []}]"} {
  %0 = torch_c.from_builtin_tensor %arg0 : tensor<4xf32> -> !torch.vtensor<[4],f32>
  %1 = call @forward(%0) : (!torch.vtensor<[4],f32>) -> !torch.vtensor<[3],f32>
  %2 = torch_c.to_builtin_tensor %1 : !torch.vtensor<[3],f32> -> tensor<3xf32>
  return %2 : tensor<3xf32>
}

// -----// IR Dump After ConvertTorchToSCF (convert-torch-to-scf) //----- //
func.func private @forward(%arg0: !torch.vtensor<[4],f32>) -> !torch.vtensor<[3],f32> attributes {torch.assume_strict_symbolic_shapes} {
  %0 = torch_c.to_builtin_tensor %arg0 : !torch.vtensor<[4],f32> -> tensor<4xf32>
  %int1 = torch.constant.int 1
  %1 = torch_c.to_i64 %int1
  %int0 = torch.constant.int 0
  %expanded = tensor.expand_shape %0 [[0, 1]] : tensor<4xf32> into tensor<1x4xf32>
  %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
  %2 = torch_c.from_builtin_tensor %_params.weight : tensor<4x3xf32> -> !torch.vtensor<[4,3],f32>
  %3 = torch_c.to_builtin_tensor %2 : !torch.vtensor<[4,3],f32> -> tensor<4x3xf32>
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c1_0 = arith.constant 1 : index
  %c3 = arith.constant 3 : index
  %4 = tensor.empty(%c1, %c3) : tensor<?x?xf32>
  %cst = arith.constant 0.000000e+00 : f32
  %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %6 = linalg.matmul ins(%expanded, %3 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%5 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %cast = tensor.cast %6 : tensor<?x?xf32> to tensor<1x3xf32>
  %collapsed = tensor.collapse_shape %cast [[0, 1]] : tensor<1x3xf32> into tensor<3xf32>
  %_params.bias = util.global.load @_params.bias : tensor<3xf32>
  %7 = torch_c.from_builtin_tensor %_params.bias : tensor<3xf32> -> !torch.vtensor<[3],f32>
  %8 = torch_c.to_builtin_tensor %7 : !torch.vtensor<[3],f32> -> tensor<3xf32>
  %c1_1 = arith.constant 1 : index
  %c0_2 = arith.constant 0 : index
  %c3_3 = arith.constant 3 : index
  %c0_4 = arith.constant 0 : index
  %c3_5 = arith.constant 3 : index
  %9 = tensor.empty() : tensor<3xf32>
  %10 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%collapsed, %8 : tensor<3xf32>, tensor<3xf32>) outs(%9 : tensor<3xf32>) {
  ^bb0(%in: f32, %in_6: f32, %out: f32):
    %12 = arith.sitofp %1 : i64 to f32
    %13 = arith.mulf %in_6, %12 : f32
    %14 = arith.addf %in, %13 : f32
    linalg.yield %14 : f32
  } -> tensor<3xf32>
  %11 = torch_c.from_builtin_tensor %10 : tensor<3xf32> -> !torch.vtensor<[3],f32>
  return %11 : !torch.vtensor<[3],f32>
}

// -----// IR Dump After ConvertTorchToArith (convert-torch-to-arith) //----- //
func.func @main(%arg0: tensor<4xf32>) -> tensor<3xf32> attributes {torch.args_schema = "[1, {\22type\22: \22builtins.tuple\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: \22builtins.list\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: null, \22context\22: null, \22children_spec\22: []}]}, {\22type\22: \22builtins.dict\22, \22context\22: \22[]\22, \22children_spec\22: []}]}]", torch.assume_strict_symbolic_shapes, torch.return_schema = "[1, {\22type\22: null, \22context\22: null, \22children_spec\22: []}]"} {
  %0 = torch_c.from_builtin_tensor %arg0 : tensor<4xf32> -> !torch.vtensor<[4],f32>
  %1 = call @forward(%0) : (!torch.vtensor<[4],f32>) -> !torch.vtensor<[3],f32>
  %2 = torch_c.to_builtin_tensor %1 : !torch.vtensor<[3],f32> -> tensor<3xf32>
  return %2 : tensor<3xf32>
}

// -----// IR Dump After ConvertTorchToArith (convert-torch-to-arith) //----- //
func.func private @forward(%arg0: !torch.vtensor<[4],f32>) -> !torch.vtensor<[3],f32> attributes {torch.assume_strict_symbolic_shapes} {
  %0 = torch_c.to_builtin_tensor %arg0 : !torch.vtensor<[4],f32> -> tensor<4xf32>
  %c1_i64 = arith.constant 1 : i64
  %1 = torch_c.from_i64 %c1_i64
  %2 = torch_c.to_i64 %1
  %c0_i64 = arith.constant 0 : i64
  %expanded = tensor.expand_shape %0 [[0, 1]] : tensor<4xf32> into tensor<1x4xf32>
  %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
  %3 = torch_c.from_builtin_tensor %_params.weight : tensor<4x3xf32> -> !torch.vtensor<[4,3],f32>
  %4 = torch_c.to_builtin_tensor %3 : !torch.vtensor<[4,3],f32> -> tensor<4x3xf32>
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c1_0 = arith.constant 1 : index
  %c3 = arith.constant 3 : index
  %5 = tensor.empty(%c1, %c3) : tensor<?x?xf32>
  %cst = arith.constant 0.000000e+00 : f32
  %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %7 = linalg.matmul ins(%expanded, %4 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%6 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %cast = tensor.cast %7 : tensor<?x?xf32> to tensor<1x3xf32>
  %collapsed = tensor.collapse_shape %cast [[0, 1]] : tensor<1x3xf32> into tensor<3xf32>
  %_params.bias = util.global.load @_params.bias : tensor<3xf32>
  %8 = torch_c.from_builtin_tensor %_params.bias : tensor<3xf32> -> !torch.vtensor<[3],f32>
  %9 = torch_c.to_builtin_tensor %8 : !torch.vtensor<[3],f32> -> tensor<3xf32>
  %c1_1 = arith.constant 1 : index
  %c0_2 = arith.constant 0 : index
  %c3_3 = arith.constant 3 : index
  %c0_4 = arith.constant 0 : index
  %c3_5 = arith.constant 3 : index
  %10 = tensor.empty() : tensor<3xf32>
  %11 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%collapsed, %9 : tensor<3xf32>, tensor<3xf32>) outs(%10 : tensor<3xf32>) {
  ^bb0(%in: f32, %in_6: f32, %out: f32):
    %13 = arith.sitofp %2 : i64 to f32
    %14 = arith.mulf %in_6, %13 : f32
    %15 = arith.addf %in, %14 : f32
    linalg.yield %15 : f32
  } -> tensor<3xf32>
  %12 = torch_c.from_builtin_tensor %11 : tensor<3xf32> -> !torch.vtensor<[3],f32>
  return %12 : !torch.vtensor<[3],f32>
}

// -----// IR Dump After ConvertTorchConversionToMLProgram (convert-torch-conversion-to-mlprogram) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  ml_program.global private mutable @global_seed(dense<0> : tensor<i64>) : tensor<i64>
  util.global private @_params.weight {noinline} = dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>
  util.global private @_params.bias {noinline} = dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>
  func.func @main(%arg0: tensor<4xf32>) -> tensor<3xf32> attributes {torch.args_schema = "[1, {\22type\22: \22builtins.tuple\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: \22builtins.list\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: null, \22context\22: null, \22children_spec\22: []}]}, {\22type\22: \22builtins.dict\22, \22context\22: \22[]\22, \22children_spec\22: []}]}]", torch.assume_strict_symbolic_shapes, torch.return_schema = "[1, {\22type\22: null, \22context\22: null, \22children_spec\22: []}]"} {
    %0 = torch_c.from_builtin_tensor %arg0 : tensor<4xf32> -> !torch.vtensor<[4],f32>
    %1 = call @forward(%0) : (!torch.vtensor<[4],f32>) -> !torch.vtensor<[3],f32>
    %2 = torch_c.to_builtin_tensor %1 : !torch.vtensor<[3],f32> -> tensor<3xf32>
    return %2 : tensor<3xf32>
  }
  func.func private @forward(%arg0: !torch.vtensor<[4],f32>) -> !torch.vtensor<[3],f32> attributes {torch.assume_strict_symbolic_shapes} {
    %0 = torch_c.to_builtin_tensor %arg0 : !torch.vtensor<[4],f32> -> tensor<4xf32>
    %c1_i64 = arith.constant 1 : i64
    %1 = torch_c.from_i64 %c1_i64
    %2 = torch_c.to_i64 %1
    %c0_i64 = arith.constant 0 : i64
    %expanded = tensor.expand_shape %0 [[0, 1]] : tensor<4xf32> into tensor<1x4xf32>
    %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
    %3 = torch_c.from_builtin_tensor %_params.weight : tensor<4x3xf32> -> !torch.vtensor<[4,3],f32>
    %4 = torch_c.to_builtin_tensor %3 : !torch.vtensor<[4,3],f32> -> tensor<4x3xf32>
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c1_0 = arith.constant 1 : index
    %c3 = arith.constant 3 : index
    %5 = tensor.empty(%c1, %c3) : tensor<?x?xf32>
    %cst = arith.constant 0.000000e+00 : f32
    %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<?x?xf32>) -> tensor<?x?xf32>
    %7 = linalg.matmul ins(%expanded, %4 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%6 : tensor<?x?xf32>) -> tensor<?x?xf32>
    %cast = tensor.cast %7 : tensor<?x?xf32> to tensor<1x3xf32>
    %collapsed = tensor.collapse_shape %cast [[0, 1]] : tensor<1x3xf32> into tensor<3xf32>
    %_params.bias = util.global.load @_params.bias : tensor<3xf32>
    %8 = torch_c.from_builtin_tensor %_params.bias : tensor<3xf32> -> !torch.vtensor<[3],f32>
    %9 = torch_c.to_builtin_tensor %8 : !torch.vtensor<[3],f32> -> tensor<3xf32>
    %c1_1 = arith.constant 1 : index
    %c0_2 = arith.constant 0 : index
    %c3_3 = arith.constant 3 : index
    %c0_4 = arith.constant 0 : index
    %c3_5 = arith.constant 3 : index
    %10 = tensor.empty() : tensor<3xf32>
    %11 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%collapsed, %9 : tensor<3xf32>, tensor<3xf32>) outs(%10 : tensor<3xf32>) {
    ^bb0(%in: f32, %in_6: f32, %out: f32):
      %13 = arith.sitofp %2 : i64 to f32
      %14 = arith.mulf %in_6, %13 : f32
      %15 = arith.addf %in, %14 : f32
      linalg.yield %15 : f32
    } -> tensor<3xf32>
    %12 = torch_c.from_builtin_tensor %11 : tensor<3xf32> -> !torch.vtensor<[3],f32>
    return %12 : !torch.vtensor<[3],f32>
  }
}


// -----// IR Dump After ExpandOps (memref-expand) //----- //
func.func @main(%arg0: tensor<4xf32>) -> tensor<3xf32> attributes {torch.args_schema = "[1, {\22type\22: \22builtins.tuple\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: \22builtins.list\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: null, \22context\22: null, \22children_spec\22: []}]}, {\22type\22: \22builtins.dict\22, \22context\22: \22[]\22, \22children_spec\22: []}]}]", torch.assume_strict_symbolic_shapes, torch.return_schema = "[1, {\22type\22: null, \22context\22: null, \22children_spec\22: []}]"} {
  %0 = torch_c.from_builtin_tensor %arg0 : tensor<4xf32> -> !torch.vtensor<[4],f32>
  %1 = call @forward(%0) : (!torch.vtensor<[4],f32>) -> !torch.vtensor<[3],f32>
  %2 = torch_c.to_builtin_tensor %1 : !torch.vtensor<[3],f32> -> tensor<3xf32>
  return %2 : tensor<3xf32>
}

// -----// IR Dump After ExpandOps (memref-expand) //----- //
func.func private @forward(%arg0: !torch.vtensor<[4],f32>) -> !torch.vtensor<[3],f32> attributes {torch.assume_strict_symbolic_shapes} {
  %0 = torch_c.to_builtin_tensor %arg0 : !torch.vtensor<[4],f32> -> tensor<4xf32>
  %c1_i64 = arith.constant 1 : i64
  %1 = torch_c.from_i64 %c1_i64
  %2 = torch_c.to_i64 %1
  %c0_i64 = arith.constant 0 : i64
  %expanded = tensor.expand_shape %0 [[0, 1]] : tensor<4xf32> into tensor<1x4xf32>
  %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
  %3 = torch_c.from_builtin_tensor %_params.weight : tensor<4x3xf32> -> !torch.vtensor<[4,3],f32>
  %4 = torch_c.to_builtin_tensor %3 : !torch.vtensor<[4,3],f32> -> tensor<4x3xf32>
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c1_0 = arith.constant 1 : index
  %c3 = arith.constant 3 : index
  %5 = tensor.empty(%c1, %c3) : tensor<?x?xf32>
  %cst = arith.constant 0.000000e+00 : f32
  %6 = linalg.fill ins(%cst : f32) outs(%5 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %7 = linalg.matmul ins(%expanded, %4 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%6 : tensor<?x?xf32>) -> tensor<?x?xf32>
  %cast = tensor.cast %7 : tensor<?x?xf32> to tensor<1x3xf32>
  %collapsed = tensor.collapse_shape %cast [[0, 1]] : tensor<1x3xf32> into tensor<3xf32>
  %_params.bias = util.global.load @_params.bias : tensor<3xf32>
  %8 = torch_c.from_builtin_tensor %_params.bias : tensor<3xf32> -> !torch.vtensor<[3],f32>
  %9 = torch_c.to_builtin_tensor %8 : !torch.vtensor<[3],f32> -> tensor<3xf32>
  %c1_1 = arith.constant 1 : index
  %c0_2 = arith.constant 0 : index
  %c3_3 = arith.constant 3 : index
  %c0_4 = arith.constant 0 : index
  %c3_5 = arith.constant 3 : index
  %10 = tensor.empty() : tensor<3xf32>
  %11 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%collapsed, %9 : tensor<3xf32>, tensor<3xf32>) outs(%10 : tensor<3xf32>) {
  ^bb0(%in: f32, %in_6: f32, %out: f32):
    %13 = arith.sitofp %2 : i64 to f32
    %14 = arith.mulf %in_6, %13 : f32
    %15 = arith.addf %in, %14 : f32
    linalg.yield %15 : f32
  } -> tensor<3xf32>
  %12 = torch_c.from_builtin_tensor %11 : tensor<3xf32> -> !torch.vtensor<[3],f32>
  return %12 : !torch.vtensor<[3],f32>
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main(%arg0: tensor<4xf32>) -> tensor<3xf32> attributes {torch.args_schema = "[1, {\22type\22: \22builtins.tuple\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: \22builtins.list\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: null, \22context\22: null, \22children_spec\22: []}]}, {\22type\22: \22builtins.dict\22, \22context\22: \22[]\22, \22children_spec\22: []}]}]", torch.assume_strict_symbolic_shapes, torch.return_schema = "[1, {\22type\22: null, \22context\22: null, \22children_spec\22: []}]"} {
  %0 = torch_c.from_builtin_tensor %arg0 : tensor<4xf32> -> !torch.vtensor<[4],f32>
  %1 = call @forward(%0) : (!torch.vtensor<[4],f32>) -> !torch.vtensor<[3],f32>
  %2 = torch_c.to_builtin_tensor %1 : !torch.vtensor<[3],f32> -> tensor<3xf32>
  return %2 : tensor<3xf32>
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func private @forward(%arg0: !torch.vtensor<[4],f32>) -> !torch.vtensor<[3],f32> attributes {torch.assume_strict_symbolic_shapes} {
  %cst = arith.constant 0.000000e+00 : f32
  %0 = torch_c.to_builtin_tensor %arg0 : !torch.vtensor<[4],f32> -> tensor<4xf32>
  %expanded = tensor.expand_shape %0 [[0, 1]] : tensor<4xf32> into tensor<1x4xf32>
  %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
  %1 = torch_c.from_builtin_tensor %_params.weight : tensor<4x3xf32> -> !torch.vtensor<[4,3],f32>
  %2 = torch_c.to_builtin_tensor %1 : !torch.vtensor<[4,3],f32> -> tensor<4x3xf32>
  %3 = tensor.empty() : tensor<1x3xf32>
  %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<1x3xf32>) -> tensor<1x3xf32>
  %5 = linalg.matmul ins(%expanded, %2 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%4 : tensor<1x3xf32>) -> tensor<1x3xf32>
  %collapsed = tensor.collapse_shape %5 [[0, 1]] : tensor<1x3xf32> into tensor<3xf32>
  %_params.bias = util.global.load @_params.bias : tensor<3xf32>
  %6 = torch_c.from_builtin_tensor %_params.bias : tensor<3xf32> -> !torch.vtensor<[3],f32>
  %7 = torch_c.to_builtin_tensor %6 : !torch.vtensor<[3],f32> -> tensor<3xf32>
  %8 = tensor.empty() : tensor<3xf32>
  %9 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%collapsed, %7 : tensor<3xf32>, tensor<3xf32>) outs(%8 : tensor<3xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %11 = arith.addf %in, %in_0 : f32
    linalg.yield %11 : f32
  } -> tensor<3xf32>
  %10 = torch_c.from_builtin_tensor %9 : tensor<3xf32> -> !torch.vtensor<[3],f32>
  return %10 : !torch.vtensor<[3],f32>
}

// -----// IR Dump After ResolveShapedTypeResultDims (resolve-shaped-type-result-dims) //----- //
func.func @main(%arg0: tensor<4xf32>) -> tensor<3xf32> attributes {torch.args_schema = "[1, {\22type\22: \22builtins.tuple\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: \22builtins.list\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: null, \22context\22: null, \22children_spec\22: []}]}, {\22type\22: \22builtins.dict\22, \22context\22: \22[]\22, \22children_spec\22: []}]}]", torch.assume_strict_symbolic_shapes, torch.return_schema = "[1, {\22type\22: null, \22context\22: null, \22children_spec\22: []}]"} {
  %0 = torch_c.from_builtin_tensor %arg0 : tensor<4xf32> -> !torch.vtensor<[4],f32>
  %1 = call @forward(%0) : (!torch.vtensor<[4],f32>) -> !torch.vtensor<[3],f32>
  %2 = torch_c.to_builtin_tensor %1 : !torch.vtensor<[3],f32> -> tensor<3xf32>
  return %2 : tensor<3xf32>
}

// -----// IR Dump After CSE (cse) //----- //
func.func @main(%arg0: tensor<4xf32>) -> tensor<3xf32> attributes {torch.args_schema = "[1, {\22type\22: \22builtins.tuple\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: \22builtins.list\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: null, \22context\22: null, \22children_spec\22: []}]}, {\22type\22: \22builtins.dict\22, \22context\22: \22[]\22, \22children_spec\22: []}]}]", torch.assume_strict_symbolic_shapes, torch.return_schema = "[1, {\22type\22: null, \22context\22: null, \22children_spec\22: []}]"} {
  %0 = torch_c.from_builtin_tensor %arg0 : tensor<4xf32> -> !torch.vtensor<[4],f32>
  %1 = call @forward(%0) : (!torch.vtensor<[4],f32>) -> !torch.vtensor<[3],f32>
  %2 = torch_c.to_builtin_tensor %1 : !torch.vtensor<[3],f32> -> tensor<3xf32>
  return %2 : tensor<3xf32>
}

// -----// IR Dump After ResolveShapedTypeResultDims (resolve-shaped-type-result-dims) //----- //
func.func private @forward(%arg0: !torch.vtensor<[4],f32>) -> !torch.vtensor<[3],f32> attributes {torch.assume_strict_symbolic_shapes} {
  %cst = arith.constant 0.000000e+00 : f32
  %0 = torch_c.to_builtin_tensor %arg0 : !torch.vtensor<[4],f32> -> tensor<4xf32>
  %expanded = tensor.expand_shape %0 [[0, 1]] : tensor<4xf32> into tensor<1x4xf32>
  %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
  %1 = torch_c.from_builtin_tensor %_params.weight : tensor<4x3xf32> -> !torch.vtensor<[4,3],f32>
  %2 = torch_c.to_builtin_tensor %1 : !torch.vtensor<[4,3],f32> -> tensor<4x3xf32>
  %3 = tensor.empty() : tensor<1x3xf32>
  %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<1x3xf32>) -> tensor<1x3xf32>
  %5 = linalg.matmul ins(%expanded, %2 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%4 : tensor<1x3xf32>) -> tensor<1x3xf32>
  %collapsed = tensor.collapse_shape %5 [[0, 1]] : tensor<1x3xf32> into tensor<3xf32>
  %_params.bias = util.global.load @_params.bias : tensor<3xf32>
  %6 = torch_c.from_builtin_tensor %_params.bias : tensor<3xf32> -> !torch.vtensor<[3],f32>
  %7 = torch_c.to_builtin_tensor %6 : !torch.vtensor<[3],f32> -> tensor<3xf32>
  %8 = tensor.empty() : tensor<3xf32>
  %9 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%collapsed, %7 : tensor<3xf32>, tensor<3xf32>) outs(%8 : tensor<3xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %11 = arith.addf %in, %in_0 : f32
    linalg.yield %11 : f32
  } -> tensor<3xf32>
  %10 = torch_c.from_builtin_tensor %9 : tensor<3xf32> -> !torch.vtensor<[3],f32>
  return %10 : !torch.vtensor<[3],f32>
}

// -----// IR Dump After CSE (cse) //----- //
func.func private @forward(%arg0: !torch.vtensor<[4],f32>) -> !torch.vtensor<[3],f32> attributes {torch.assume_strict_symbolic_shapes} {
  %cst = arith.constant 0.000000e+00 : f32
  %0 = torch_c.to_builtin_tensor %arg0 : !torch.vtensor<[4],f32> -> tensor<4xf32>
  %expanded = tensor.expand_shape %0 [[0, 1]] : tensor<4xf32> into tensor<1x4xf32>
  %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
  %1 = torch_c.from_builtin_tensor %_params.weight : tensor<4x3xf32> -> !torch.vtensor<[4,3],f32>
  %2 = torch_c.to_builtin_tensor %1 : !torch.vtensor<[4,3],f32> -> tensor<4x3xf32>
  %3 = tensor.empty() : tensor<1x3xf32>
  %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<1x3xf32>) -> tensor<1x3xf32>
  %5 = linalg.matmul ins(%expanded, %2 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%4 : tensor<1x3xf32>) -> tensor<1x3xf32>
  %collapsed = tensor.collapse_shape %5 [[0, 1]] : tensor<1x3xf32> into tensor<3xf32>
  %_params.bias = util.global.load @_params.bias : tensor<3xf32>
  %6 = torch_c.from_builtin_tensor %_params.bias : tensor<3xf32> -> !torch.vtensor<[3],f32>
  %7 = torch_c.to_builtin_tensor %6 : !torch.vtensor<[3],f32> -> tensor<3xf32>
  %8 = tensor.empty() : tensor<3xf32>
  %9 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%collapsed, %7 : tensor<3xf32>, tensor<3xf32>) outs(%8 : tensor<3xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %11 = arith.addf %in, %in_0 : f32
    linalg.yield %11 : f32
  } -> tensor<3xf32>
  %10 = torch_c.from_builtin_tensor %9 : tensor<3xf32> -> !torch.vtensor<[3],f32>
  return %10 : !torch.vtensor<[3],f32>
}

// -----// IR Dump After FuncBackendTypeConversion (torch-func-backend-type-conversion) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  ml_program.global private mutable @global_seed(dense<0> : tensor<i64>) : tensor<i64>
  util.global private @_params.weight {noinline} = dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>
  util.global private @_params.bias {noinline} = dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>
  func.func @main(%arg0: tensor<4xf32>) -> tensor<3xf32> attributes {torch.args_schema = "[1, {\22type\22: \22builtins.tuple\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: \22builtins.list\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: null, \22context\22: null, \22children_spec\22: []}]}, {\22type\22: \22builtins.dict\22, \22context\22: \22[]\22, \22children_spec\22: []}]}]", torch.assume_strict_symbolic_shapes, torch.return_schema = "[1, {\22type\22: null, \22context\22: null, \22children_spec\22: []}]"} {
    %0 = torch_c.from_builtin_tensor %arg0 : tensor<4xf32> -> !torch.vtensor<[4],f32>
    %1 = torch_c.to_builtin_tensor %0 : !torch.vtensor<[4],f32> -> tensor<4xf32>
    %2 = call @forward(%1) : (tensor<4xf32>) -> tensor<3xf32>
    %3 = torch_c.from_builtin_tensor %2 : tensor<3xf32> -> !torch.vtensor<[3],f32>
    %4 = torch_c.to_builtin_tensor %3 : !torch.vtensor<[3],f32> -> tensor<3xf32>
    return %4 : tensor<3xf32>
  }
  func.func private @forward(%arg0: tensor<4xf32>) -> tensor<3xf32> attributes {torch.assume_strict_symbolic_shapes} {
    %0 = torch_c.from_builtin_tensor %arg0 : tensor<4xf32> -> !torch.vtensor<[4],f32>
    %cst = arith.constant 0.000000e+00 : f32
    %1 = torch_c.to_builtin_tensor %0 : !torch.vtensor<[4],f32> -> tensor<4xf32>
    %expanded = tensor.expand_shape %1 [[0, 1]] : tensor<4xf32> into tensor<1x4xf32>
    %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
    %2 = torch_c.from_builtin_tensor %_params.weight : tensor<4x3xf32> -> !torch.vtensor<[4,3],f32>
    %3 = torch_c.to_builtin_tensor %2 : !torch.vtensor<[4,3],f32> -> tensor<4x3xf32>
    %4 = tensor.empty() : tensor<1x3xf32>
    %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<1x3xf32>) -> tensor<1x3xf32>
    %6 = linalg.matmul ins(%expanded, %3 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%5 : tensor<1x3xf32>) -> tensor<1x3xf32>
    %collapsed = tensor.collapse_shape %6 [[0, 1]] : tensor<1x3xf32> into tensor<3xf32>
    %_params.bias = util.global.load @_params.bias : tensor<3xf32>
    %7 = torch_c.from_builtin_tensor %_params.bias : tensor<3xf32> -> !torch.vtensor<[3],f32>
    %8 = torch_c.to_builtin_tensor %7 : !torch.vtensor<[3],f32> -> tensor<3xf32>
    %9 = tensor.empty() : tensor<3xf32>
    %10 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%collapsed, %8 : tensor<3xf32>, tensor<3xf32>) outs(%9 : tensor<3xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %13 = arith.addf %in, %in_0 : f32
      linalg.yield %13 : f32
    } -> tensor<3xf32>
    %11 = torch_c.from_builtin_tensor %10 : tensor<3xf32> -> !torch.vtensor<[3],f32>
    %12 = torch_c.to_builtin_tensor %11 : !torch.vtensor<[3],f32> -> tensor<3xf32>
    return %12 : tensor<3xf32>
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main(%arg0: tensor<4xf32>) -> tensor<3xf32> attributes {torch.args_schema = "[1, {\22type\22: \22builtins.tuple\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: \22builtins.list\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: null, \22context\22: null, \22children_spec\22: []}]}, {\22type\22: \22builtins.dict\22, \22context\22: \22[]\22, \22children_spec\22: []}]}]", torch.assume_strict_symbolic_shapes, torch.return_schema = "[1, {\22type\22: null, \22context\22: null, \22children_spec\22: []}]"} {
  %0 = torch_c.from_builtin_tensor %arg0 : tensor<4xf32> -> !torch.vtensor<[4],f32>
  %1 = torch_c.to_builtin_tensor %0 : !torch.vtensor<[4],f32> -> tensor<4xf32>
  %2 = call @forward(%1) : (tensor<4xf32>) -> tensor<3xf32>
  %3 = torch_c.from_builtin_tensor %2 : tensor<3xf32> -> !torch.vtensor<[3],f32>
  %4 = torch_c.to_builtin_tensor %3 : !torch.vtensor<[3],f32> -> tensor<3xf32>
  return %4 : tensor<3xf32>
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func private @forward(%arg0: tensor<4xf32>) -> tensor<3xf32> attributes {torch.assume_strict_symbolic_shapes} {
  %cst = arith.constant 0.000000e+00 : f32
  %0 = torch_c.from_builtin_tensor %arg0 : tensor<4xf32> -> !torch.vtensor<[4],f32>
  %1 = torch_c.to_builtin_tensor %0 : !torch.vtensor<[4],f32> -> tensor<4xf32>
  %expanded = tensor.expand_shape %1 [[0, 1]] : tensor<4xf32> into tensor<1x4xf32>
  %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
  %2 = torch_c.from_builtin_tensor %_params.weight : tensor<4x3xf32> -> !torch.vtensor<[4,3],f32>
  %3 = torch_c.to_builtin_tensor %2 : !torch.vtensor<[4,3],f32> -> tensor<4x3xf32>
  %4 = tensor.empty() : tensor<1x3xf32>
  %5 = linalg.fill ins(%cst : f32) outs(%4 : tensor<1x3xf32>) -> tensor<1x3xf32>
  %6 = linalg.matmul ins(%expanded, %3 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%5 : tensor<1x3xf32>) -> tensor<1x3xf32>
  %collapsed = tensor.collapse_shape %6 [[0, 1]] : tensor<1x3xf32> into tensor<3xf32>
  %_params.bias = util.global.load @_params.bias : tensor<3xf32>
  %7 = torch_c.from_builtin_tensor %_params.bias : tensor<3xf32> -> !torch.vtensor<[3],f32>
  %8 = torch_c.to_builtin_tensor %7 : !torch.vtensor<[3],f32> -> tensor<3xf32>
  %9 = tensor.empty() : tensor<3xf32>
  %10 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%collapsed, %8 : tensor<3xf32>, tensor<3xf32>) outs(%9 : tensor<3xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %13 = arith.addf %in, %in_0 : f32
    linalg.yield %13 : f32
  } -> tensor<3xf32>
  %11 = torch_c.from_builtin_tensor %10 : tensor<3xf32> -> !torch.vtensor<[3],f32>
  %12 = torch_c.to_builtin_tensor %11 : !torch.vtensor<[3],f32> -> tensor<3xf32>
  return %12 : tensor<3xf32>
}

// -----// IR Dump After FinalizingBackendTypeConversion (torch-finalizing-backend-type-conversion) //----- //
func.func @main(%arg0: tensor<4xf32>) -> tensor<3xf32> attributes {torch.args_schema = "[1, {\22type\22: \22builtins.tuple\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: \22builtins.list\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: null, \22context\22: null, \22children_spec\22: []}]}, {\22type\22: \22builtins.dict\22, \22context\22: \22[]\22, \22children_spec\22: []}]}]", torch.assume_strict_symbolic_shapes, torch.return_schema = "[1, {\22type\22: null, \22context\22: null, \22children_spec\22: []}]"} {
  %0 = call @forward(%arg0) : (tensor<4xf32>) -> tensor<3xf32>
  return %0 : tensor<3xf32>
}

// -----// IR Dump After FinalizingBackendTypeConversion (torch-finalizing-backend-type-conversion) //----- //
func.func private @forward(%arg0: tensor<4xf32>) -> tensor<3xf32> attributes {torch.assume_strict_symbolic_shapes} {
  %cst = arith.constant 0.000000e+00 : f32
  %expanded = tensor.expand_shape %arg0 [[0, 1]] : tensor<4xf32> into tensor<1x4xf32>
  %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
  %0 = tensor.empty() : tensor<1x3xf32>
  %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x3xf32>) -> tensor<1x3xf32>
  %2 = linalg.matmul ins(%expanded, %_params.weight : tensor<1x4xf32>, tensor<4x3xf32>) outs(%1 : tensor<1x3xf32>) -> tensor<1x3xf32>
  %collapsed = tensor.collapse_shape %2 [[0, 1]] : tensor<1x3xf32> into tensor<3xf32>
  %_params.bias = util.global.load @_params.bias : tensor<3xf32>
  %3 = tensor.empty() : tensor<3xf32>
  %4 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%collapsed, %_params.bias : tensor<3xf32>, tensor<3xf32>) outs(%3 : tensor<3xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %5 = arith.addf %in, %in_0 : f32
    linalg.yield %5 : f32
  } -> tensor<3xf32>
  return %4 : tensor<3xf32>
}

// -----// IR Dump After SymbolDCE (symbol-dce) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private @_params.weight {noinline} = dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>
  util.global private @_params.bias {noinline} = dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>
  func.func @main(%arg0: tensor<4xf32>) -> tensor<3xf32> attributes {torch.args_schema = "[1, {\22type\22: \22builtins.tuple\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: \22builtins.list\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: null, \22context\22: null, \22children_spec\22: []}]}, {\22type\22: \22builtins.dict\22, \22context\22: \22[]\22, \22children_spec\22: []}]}]", torch.assume_strict_symbolic_shapes, torch.return_schema = "[1, {\22type\22: null, \22context\22: null, \22children_spec\22: []}]"} {
    %0 = call @forward(%arg0) : (tensor<4xf32>) -> tensor<3xf32>
    return %0 : tensor<3xf32>
  }
  func.func private @forward(%arg0: tensor<4xf32>) -> tensor<3xf32> attributes {torch.assume_strict_symbolic_shapes} {
    %cst = arith.constant 0.000000e+00 : f32
    %expanded = tensor.expand_shape %arg0 [[0, 1]] : tensor<4xf32> into tensor<1x4xf32>
    %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
    %0 = tensor.empty() : tensor<1x3xf32>
    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x3xf32>) -> tensor<1x3xf32>
    %2 = linalg.matmul ins(%expanded, %_params.weight : tensor<1x4xf32>, tensor<4x3xf32>) outs(%1 : tensor<1x3xf32>) -> tensor<1x3xf32>
    %collapsed = tensor.collapse_shape %2 [[0, 1]] : tensor<1x3xf32> into tensor<3xf32>
    %_params.bias = util.global.load @_params.bias : tensor<3xf32>
    %3 = tensor.empty() : tensor<3xf32>
    %4 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%collapsed, %_params.bias : tensor<3xf32>, tensor<3xf32>) outs(%3 : tensor<3xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %5 = arith.addf %in, %in_0 : f32
      linalg.yield %5 : f32
    } -> tensor<3xf32>
    return %4 : tensor<3xf32>
  }
}


// -----// IR Dump After ConvertTMTensorToLinalgExt (torch-iree-tm-tensor-to-linalg-ext) //----- //
func.func @main(%arg0: tensor<4xf32>) -> tensor<3xf32> attributes {torch.args_schema = "[1, {\22type\22: \22builtins.tuple\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: \22builtins.list\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: null, \22context\22: null, \22children_spec\22: []}]}, {\22type\22: \22builtins.dict\22, \22context\22: \22[]\22, \22children_spec\22: []}]}]", torch.assume_strict_symbolic_shapes, torch.return_schema = "[1, {\22type\22: null, \22context\22: null, \22children_spec\22: []}]"} {
  %0 = call @forward(%arg0) : (tensor<4xf32>) -> tensor<3xf32>
  return %0 : tensor<3xf32>
}

// -----// IR Dump After ConvertTMTensorToLinalgExt (torch-iree-tm-tensor-to-linalg-ext) //----- //
func.func private @forward(%arg0: tensor<4xf32>) -> tensor<3xf32> attributes {torch.assume_strict_symbolic_shapes} {
  %cst = arith.constant 0.000000e+00 : f32
  %expanded = tensor.expand_shape %arg0 [[0, 1]] : tensor<4xf32> into tensor<1x4xf32>
  %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
  %0 = tensor.empty() : tensor<1x3xf32>
  %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x3xf32>) -> tensor<1x3xf32>
  %2 = linalg.matmul ins(%expanded, %_params.weight : tensor<1x4xf32>, tensor<4x3xf32>) outs(%1 : tensor<1x3xf32>) -> tensor<1x3xf32>
  %collapsed = tensor.collapse_shape %2 [[0, 1]] : tensor<1x3xf32> into tensor<3xf32>
  %_params.bias = util.global.load @_params.bias : tensor<3xf32>
  %3 = tensor.empty() : tensor<3xf32>
  %4 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%collapsed, %_params.bias : tensor<3xf32>, tensor<3xf32>) outs(%3 : tensor<3xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %5 = arith.addf %in, %in_0 : f32
    linalg.yield %5 : f32
  } -> tensor<3xf32>
  return %4 : tensor<3xf32>
}

// -----// IR Dump After IREEImportPublic (iree-import-public) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private @_params.weight {noinline} = dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>
  util.global private @_params.bias {noinline} = dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>
  func.func @main(%arg0: tensor<4xf32>) -> tensor<3xf32> attributes {torch.args_schema = "[1, {\22type\22: \22builtins.tuple\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: \22builtins.list\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: null, \22context\22: null, \22children_spec\22: []}]}, {\22type\22: \22builtins.dict\22, \22context\22: \22[]\22, \22children_spec\22: []}]}]", torch.assume_strict_symbolic_shapes, torch.return_schema = "[1, {\22type\22: null, \22context\22: null, \22children_spec\22: []}]"} {
    %0 = call @forward(%arg0) : (tensor<4xf32>) -> tensor<3xf32>
    return %0 : tensor<3xf32>
  }
  func.func private @forward(%arg0: tensor<4xf32>) -> tensor<3xf32> attributes {torch.assume_strict_symbolic_shapes} {
    %cst = arith.constant 0.000000e+00 : f32
    %expanded = tensor.expand_shape %arg0 [[0, 1]] : tensor<4xf32> into tensor<1x4xf32>
    %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
    %0 = tensor.empty() : tensor<1x3xf32>
    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x3xf32>) -> tensor<1x3xf32>
    %2 = linalg.matmul ins(%expanded, %_params.weight : tensor<1x4xf32>, tensor<4x3xf32>) outs(%1 : tensor<1x3xf32>) -> tensor<1x3xf32>
    %collapsed = tensor.collapse_shape %2 [[0, 1]] : tensor<1x3xf32> into tensor<3xf32>
    %_params.bias = util.global.load @_params.bias : tensor<3xf32>
    %3 = tensor.empty() : tensor<3xf32>
    %4 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%collapsed, %_params.bias : tensor<3xf32>, tensor<3xf32>) outs(%3 : tensor<3xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %5 = arith.addf %in, %in_0 : f32
      linalg.yield %5 : f32
    } -> tensor<3xf32>
    return %4 : tensor<3xf32>
  }
}


// -----// IR Dump After ImportMLProgram (iree-import-ml-program) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private @_params.weight {noinline} = dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>
  util.global private @_params.bias {noinline} = dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>
  func.func @main(%arg0: tensor<4xf32>) -> tensor<3xf32> attributes {torch.args_schema = "[1, {\22type\22: \22builtins.tuple\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: \22builtins.list\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: null, \22context\22: null, \22children_spec\22: []}]}, {\22type\22: \22builtins.dict\22, \22context\22: \22[]\22, \22children_spec\22: []}]}]", torch.assume_strict_symbolic_shapes, torch.return_schema = "[1, {\22type\22: null, \22context\22: null, \22children_spec\22: []}]"} {
    %0 = call @forward(%arg0) : (tensor<4xf32>) -> tensor<3xf32>
    return %0 : tensor<3xf32>
  }
  func.func private @forward(%arg0: tensor<4xf32>) -> tensor<3xf32> attributes {torch.assume_strict_symbolic_shapes} {
    %cst = arith.constant 0.000000e+00 : f32
    %expanded = tensor.expand_shape %arg0 [[0, 1]] : tensor<4xf32> into tensor<1x4xf32>
    %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
    %0 = tensor.empty() : tensor<1x3xf32>
    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x3xf32>) -> tensor<1x3xf32>
    %2 = linalg.matmul ins(%expanded, %_params.weight : tensor<1x4xf32>, tensor<4x3xf32>) outs(%1 : tensor<1x3xf32>) -> tensor<1x3xf32>
    %collapsed = tensor.collapse_shape %2 [[0, 1]] : tensor<1x3xf32> into tensor<3xf32>
    %_params.bias = util.global.load @_params.bias : tensor<3xf32>
    %3 = tensor.empty() : tensor<3xf32>
    %4 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%collapsed, %_params.bias : tensor<3xf32>, tensor<3xf32>) outs(%3 : tensor<3xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %5 = arith.addf %in, %in_0 : f32
      linalg.yield %5 : f32
    } -> tensor<3xf32>
    return %4 : tensor<3xf32>
  }
}


// -----// IR Dump After SanitizeModuleNames (iree-sanitize-module-names) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private @_params.weight {noinline} = dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>
  util.global private @_params.bias {noinline} = dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>
  func.func @main(%arg0: tensor<4xf32>) -> tensor<3xf32> attributes {torch.args_schema = "[1, {\22type\22: \22builtins.tuple\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: \22builtins.list\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: null, \22context\22: null, \22children_spec\22: []}]}, {\22type\22: \22builtins.dict\22, \22context\22: \22[]\22, \22children_spec\22: []}]}]", torch.assume_strict_symbolic_shapes, torch.return_schema = "[1, {\22type\22: null, \22context\22: null, \22children_spec\22: []}]"} {
    %0 = call @forward(%arg0) : (tensor<4xf32>) -> tensor<3xf32>
    return %0 : tensor<3xf32>
  }
  func.func private @forward(%arg0: tensor<4xf32>) -> tensor<3xf32> attributes {torch.assume_strict_symbolic_shapes} {
    %cst = arith.constant 0.000000e+00 : f32
    %expanded = tensor.expand_shape %arg0 [[0, 1]] : tensor<4xf32> into tensor<1x4xf32>
    %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
    %0 = tensor.empty() : tensor<1x3xf32>
    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x3xf32>) -> tensor<1x3xf32>
    %2 = linalg.matmul ins(%expanded, %_params.weight : tensor<1x4xf32>, tensor<4x3xf32>) outs(%1 : tensor<1x3xf32>) -> tensor<1x3xf32>
    %collapsed = tensor.collapse_shape %2 [[0, 1]] : tensor<1x3xf32> into tensor<3xf32>
    %_params.bias = util.global.load @_params.bias : tensor<3xf32>
    %3 = tensor.empty() : tensor<3xf32>
    %4 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%collapsed, %_params.bias : tensor<3xf32>, tensor<3xf32>) outs(%3 : tensor<3xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %5 = arith.addf %in, %in_0 : f32
      linalg.yield %5 : f32
    } -> tensor<3xf32>
    return %4 : tensor<3xf32>
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::ABI::ConvertStreamableOpsPass (iree-abi-convert-streamable-ops) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private @_params.weight {noinline} = dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>
  util.global private @_params.bias {noinline} = dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>
  func.func @main(%arg0: tensor<4xf32>) -> tensor<3xf32> attributes {torch.args_schema = "[1, {\22type\22: \22builtins.tuple\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: \22builtins.list\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: null, \22context\22: null, \22children_spec\22: []}]}, {\22type\22: \22builtins.dict\22, \22context\22: \22[]\22, \22children_spec\22: []}]}]", torch.assume_strict_symbolic_shapes, torch.return_schema = "[1, {\22type\22: null, \22context\22: null, \22children_spec\22: []}]"} {
    %0 = call @forward(%arg0) : (tensor<4xf32>) -> tensor<3xf32>
    return %0 : tensor<3xf32>
  }
  func.func private @forward(%arg0: tensor<4xf32>) -> tensor<3xf32> attributes {torch.assume_strict_symbolic_shapes} {
    %cst = arith.constant 0.000000e+00 : f32
    %expanded = tensor.expand_shape %arg0 [[0, 1]] : tensor<4xf32> into tensor<1x4xf32>
    %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
    %0 = tensor.empty() : tensor<1x3xf32>
    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x3xf32>) -> tensor<1x3xf32>
    %2 = linalg.matmul ins(%expanded, %_params.weight : tensor<1x4xf32>, tensor<4x3xf32>) outs(%1 : tensor<1x3xf32>) -> tensor<1x3xf32>
    %collapsed = tensor.collapse_shape %2 [[0, 1]] : tensor<1x3xf32> into tensor<3xf32>
    %_params.bias = util.global.load @_params.bias : tensor<3xf32>
    %3 = tensor.empty() : tensor<3xf32>
    %4 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%collapsed, %_params.bias : tensor<3xf32>, tensor<3xf32>) outs(%3 : tensor<3xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %5 = arith.addf %in, %in_0 : f32
      linalg.yield %5 : f32
    } -> tensor<3xf32>
    return %4 : tensor<3xf32>
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::ABI::WrapEntryPointsPass (iree-abi-wrap-entry-points) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private @_params.weight {noinline} = dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>
  util.global private @_params.bias {noinline} = dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %0 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<4xf32>
    %1 = call @_main(%0) : (tensor<4xf32>) -> tensor<3xf32>
    %2 = hal.tensor.export %1 "output 0" : tensor<3xf32> -> !hal.buffer_view
    return %2 : !hal.buffer_view
  }
  func.func private @_main(%arg0: tensor<4xf32>) -> tensor<3xf32> attributes {torch.args_schema = "[1, {\22type\22: \22builtins.tuple\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: \22builtins.list\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: null, \22context\22: null, \22children_spec\22: []}]}, {\22type\22: \22builtins.dict\22, \22context\22: \22[]\22, \22children_spec\22: []}]}]", torch.assume_strict_symbolic_shapes, torch.return_schema = "[1, {\22type\22: null, \22context\22: null, \22children_spec\22: []}]"} {
    %0 = call @forward(%arg0) : (tensor<4xf32>) -> tensor<3xf32>
    return %0 : tensor<3xf32>
  }
  func.func private @forward(%arg0: tensor<4xf32>) -> tensor<3xf32> attributes {torch.assume_strict_symbolic_shapes} {
    %cst = arith.constant 0.000000e+00 : f32
    %expanded = tensor.expand_shape %arg0 [[0, 1]] : tensor<4xf32> into tensor<1x4xf32>
    %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
    %0 = tensor.empty() : tensor<1x3xf32>
    %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x3xf32>) -> tensor<1x3xf32>
    %2 = linalg.matmul ins(%expanded, %_params.weight : tensor<1x4xf32>, tensor<4x3xf32>) outs(%1 : tensor<1x3xf32>) -> tensor<1x3xf32>
    %collapsed = tensor.collapse_shape %2 [[0, 1]] : tensor<1x3xf32> into tensor<3xf32>
    %_params.bias = util.global.load @_params.bias : tensor<3xf32>
    %3 = tensor.empty() : tensor<3xf32>
    %4 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%collapsed, %_params.bias : tensor<3xf32>, tensor<3xf32>) outs(%3 : tensor<3xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %5 = arith.addf %in, %in_0 : f32
      linalg.yield %5 : f32
    } -> tensor<3xf32>
    return %4 : tensor<3xf32>
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func private @forward(%arg0: tensor<4xf32>) -> tensor<3xf32> attributes {torch.assume_strict_symbolic_shapes} {
  %cst = arith.constant 0.000000e+00 : f32
  %expanded = tensor.expand_shape %arg0 [[0, 1]] : tensor<4xf32> into tensor<1x4xf32>
  %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
  %0 = tensor.empty() : tensor<1x3xf32>
  %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x3xf32>) -> tensor<1x3xf32>
  %2 = linalg.matmul ins(%expanded, %_params.weight : tensor<1x4xf32>, tensor<4x3xf32>) outs(%1 : tensor<1x3xf32>) -> tensor<1x3xf32>
  %collapsed = tensor.collapse_shape %2 [[0, 1]] : tensor<1x3xf32> into tensor<3xf32>
  %_params.bias = util.global.load @_params.bias : tensor<3xf32>
  %3 = tensor.empty() : tensor<3xf32>
  %4 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%collapsed, %_params.bias : tensor<3xf32>, tensor<3xf32>) outs(%3 : tensor<3xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %5 = arith.addf %in, %in_0 : f32
    linalg.yield %5 : f32
  } -> tensor<3xf32>
  return %4 : tensor<3xf32>
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func private @_main(%arg0: tensor<4xf32>) -> tensor<3xf32> attributes {torch.args_schema = "[1, {\22type\22: \22builtins.tuple\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: \22builtins.list\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: null, \22context\22: null, \22children_spec\22: []}]}, {\22type\22: \22builtins.dict\22, \22context\22: \22[]\22, \22children_spec\22: []}]}]", torch.assume_strict_symbolic_shapes, torch.return_schema = "[1, {\22type\22: null, \22context\22: null, \22children_spec\22: []}]"} {
  %0 = call @forward(%arg0) : (tensor<4xf32>) -> tensor<3xf32>
  return %0 : tensor<3xf32>
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func private @_main(%arg0: tensor<4xf32>) -> tensor<3xf32> attributes {torch.args_schema = "[1, {\22type\22: \22builtins.tuple\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: \22builtins.list\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: null, \22context\22: null, \22children_spec\22: []}]}, {\22type\22: \22builtins.dict\22, \22context\22: \22[]\22, \22children_spec\22: []}]}]", torch.assume_strict_symbolic_shapes, torch.return_schema = "[1, {\22type\22: null, \22context\22: null, \22children_spec\22: []}]"} {
  %cst = arith.constant 0.000000e+00 : f32
  %expanded = tensor.expand_shape %arg0 [[0, 1]] : tensor<4xf32> into tensor<1x4xf32>
  %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
  %0 = tensor.empty() : tensor<1x3xf32>
  %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1x3xf32>) -> tensor<1x3xf32>
  %2 = linalg.matmul ins(%expanded, %_params.weight : tensor<1x4xf32>, tensor<4x3xf32>) outs(%1 : tensor<1x3xf32>) -> tensor<1x3xf32>
  %collapsed = tensor.collapse_shape %2 [[0, 1]] : tensor<1x3xf32> into tensor<3xf32>
  %_params.bias = util.global.load @_params.bias : tensor<3xf32>
  %3 = tensor.empty() : tensor<3xf32>
  %4 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%collapsed, %_params.bias : tensor<3xf32>, tensor<3xf32>) outs(%3 : tensor<3xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %5 = arith.addf %in, %in_0 : f32
    linalg.yield %5 : f32
  } -> tensor<3xf32>
  return %4 : tensor<3xf32>
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %0 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<4xf32>
  %1 = call @_main(%0) : (tensor<4xf32>) -> tensor<3xf32>
  %2 = hal.tensor.export %1 "output 0" : tensor<3xf32> -> !hal.buffer_view
  return %2 : !hal.buffer_view
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<4xf32>
  %expanded = tensor.expand_shape %0 [[0, 1]] : tensor<4xf32> into tensor<1x4xf32>
  %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
  %1 = tensor.empty() : tensor<1x3xf32>
  %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<1x3xf32>) -> tensor<1x3xf32>
  %3 = linalg.matmul ins(%expanded, %_params.weight : tensor<1x4xf32>, tensor<4x3xf32>) outs(%2 : tensor<1x3xf32>) -> tensor<1x3xf32>
  %collapsed = tensor.collapse_shape %3 [[0, 1]] : tensor<1x3xf32> into tensor<3xf32>
  %_params.bias = util.global.load @_params.bias : tensor<3xf32>
  %4 = tensor.empty() : tensor<3xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%collapsed, %_params.bias : tensor<3xf32>, tensor<3xf32>) outs(%4 : tensor<3xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %7 = arith.addf %in, %in_0 : f32
    linalg.yield %7 : f32
  } -> tensor<3xf32>
  %6 = hal.tensor.export %5 "output 0" : tensor<3xf32> -> !hal.buffer_view
  return %6 : !hal.buffer_view
}

// -----// IR Dump After Inliner (inline) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private @_params.weight {noinline} = dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>
  util.global private @_params.bias {noinline} = dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<4xf32>
    %expanded = tensor.expand_shape %0 [[0, 1]] : tensor<4xf32> into tensor<1x4xf32>
    %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
    %1 = tensor.empty() : tensor<1x3xf32>
    %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<1x3xf32>) -> tensor<1x3xf32>
    %3 = linalg.matmul ins(%expanded, %_params.weight : tensor<1x4xf32>, tensor<4x3xf32>) outs(%2 : tensor<1x3xf32>) -> tensor<1x3xf32>
    %collapsed = tensor.collapse_shape %3 [[0, 1]] : tensor<1x3xf32> into tensor<3xf32>
    %_params.bias = util.global.load @_params.bias : tensor<3xf32>
    %4 = tensor.empty() : tensor<3xf32>
    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%collapsed, %_params.bias : tensor<3xf32>, tensor<3xf32>) outs(%4 : tensor<3xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %7 = arith.addf %in, %in_0 : f32
      linalg.yield %7 : f32
    } -> tensor<3xf32>
    %6 = hal.tensor.export %5 "output 0" : tensor<3xf32> -> !hal.buffer_view
    return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<4xf32>
  %expanded = tensor.expand_shape %0 [[0, 1]] : tensor<4xf32> into tensor<1x4xf32>
  %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
  %1 = tensor.empty() : tensor<1x3xf32>
  %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<1x3xf32>) -> tensor<1x3xf32>
  %3 = linalg.matmul ins(%expanded, %_params.weight : tensor<1x4xf32>, tensor<4x3xf32>) outs(%2 : tensor<1x3xf32>) -> tensor<1x3xf32>
  %collapsed = tensor.collapse_shape %3 [[0, 1]] : tensor<1x3xf32> into tensor<3xf32>
  %_params.bias = util.global.load @_params.bias : tensor<3xf32>
  %4 = tensor.empty() : tensor<3xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%collapsed, %_params.bias : tensor<3xf32>, tensor<3xf32>) outs(%4 : tensor<3xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %7 = arith.addf %in, %in_0 : f32
    linalg.yield %7 : f32
  } -> tensor<3xf32>
  %6 = hal.tensor.export %5 "output 0" : tensor<3xf32> -> !hal.buffer_view
  return %6 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<4xf32>
  %expanded = tensor.expand_shape %0 [[0, 1]] : tensor<4xf32> into tensor<1x4xf32>
  %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
  %1 = tensor.empty() : tensor<1x3xf32>
  %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<1x3xf32>) -> tensor<1x3xf32>
  %3 = linalg.matmul ins(%expanded, %_params.weight : tensor<1x4xf32>, tensor<4x3xf32>) outs(%2 : tensor<1x3xf32>) -> tensor<1x3xf32>
  %collapsed = tensor.collapse_shape %3 [[0, 1]] : tensor<1x3xf32> into tensor<3xf32>
  %_params.bias = util.global.load @_params.bias : tensor<3xf32>
  %4 = tensor.empty() : tensor<3xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%collapsed, %_params.bias : tensor<3xf32>, tensor<3xf32>) outs(%4 : tensor<3xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %7 = arith.addf %in, %in_0 : f32
    linalg.yield %7 : f32
  } -> tensor<3xf32>
  %6 = hal.tensor.export %5 "output 0" : tensor<3xf32> -> !hal.buffer_view
  return %6 : !hal.buffer_view
}

// -----// IR Dump After SymbolDCE (symbol-dce) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private @_params.weight {noinline} = dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>
  util.global private @_params.bias {noinline} = dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<4xf32>
    %expanded = tensor.expand_shape %0 [[0, 1]] : tensor<4xf32> into tensor<1x4xf32>
    %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
    %1 = tensor.empty() : tensor<1x3xf32>
    %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<1x3xf32>) -> tensor<1x3xf32>
    %3 = linalg.matmul ins(%expanded, %_params.weight : tensor<1x4xf32>, tensor<4x3xf32>) outs(%2 : tensor<1x3xf32>) -> tensor<1x3xf32>
    %collapsed = tensor.collapse_shape %3 [[0, 1]] : tensor<1x3xf32> into tensor<3xf32>
    %_params.bias = util.global.load @_params.bias : tensor<3xf32>
    %4 = tensor.empty() : tensor<3xf32>
    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%collapsed, %_params.bias : tensor<3xf32>, tensor<3xf32>) outs(%4 : tensor<3xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %7 = arith.addf %in, %in_0 : f32
      linalg.yield %7 : f32
    } -> tensor<3xf32>
    %6 = hal.tensor.export %5 "output 0" : tensor<3xf32> -> !hal.buffer_view
    return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After DemoteF64ToF32 (iree-util-demote-f64-to-f32) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private @_params.weight {noinline} = dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>
  util.global private @_params.bias {noinline} = dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<4xf32>
    %expanded = tensor.expand_shape %0 [[0, 1]] : tensor<4xf32> into tensor<1x4xf32>
    %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
    %1 = tensor.empty() : tensor<1x3xf32>
    %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<1x3xf32>) -> tensor<1x3xf32>
    %3 = linalg.matmul ins(%expanded, %_params.weight : tensor<1x4xf32>, tensor<4x3xf32>) outs(%2 : tensor<1x3xf32>) -> tensor<1x3xf32>
    %collapsed = tensor.collapse_shape %3 [[0, 1]] : tensor<1x3xf32> into tensor<3xf32>
    %_params.bias = util.global.load @_params.bias : tensor<3xf32>
    %4 = tensor.empty() : tensor<3xf32>
    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%collapsed, %_params.bias : tensor<3xf32>, tensor<3xf32>) outs(%4 : tensor<3xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %7 = arith.addf %in, %in_0 : f32
      linalg.yield %7 : f32
    } -> tensor<3xf32>
    %6 = hal.tensor.export %5 "output 0" : tensor<3xf32> -> !hal.buffer_view
    return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After RemoveZeroExtentTensors (iree-global-opt-remove-zero-extent-tensors) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<4xf32>
  %expanded = tensor.expand_shape %0 [[0, 1]] : tensor<4xf32> into tensor<1x4xf32>
  %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
  %1 = tensor.empty() : tensor<1x3xf32>
  %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<1x3xf32>) -> tensor<1x3xf32>
  %3 = linalg.matmul ins(%expanded, %_params.weight : tensor<1x4xf32>, tensor<4x3xf32>) outs(%2 : tensor<1x3xf32>) -> tensor<1x3xf32>
  %collapsed = tensor.collapse_shape %3 [[0, 1]] : tensor<1x3xf32> into tensor<3xf32>
  %_params.bias = util.global.load @_params.bias : tensor<3xf32>
  %4 = tensor.empty() : tensor<3xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%collapsed, %_params.bias : tensor<3xf32>, tensor<3xf32>) outs(%4 : tensor<3xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %7 = arith.addf %in, %in_0 : f32
    linalg.yield %7 : f32
  } -> tensor<3xf32>
  %6 = hal.tensor.export %5 "output 0" : tensor<3xf32> -> !hal.buffer_view
  return %6 : !hal.buffer_view
}

// -----// IR Dump After DetachElementwiseFromNamedOps (iree-global-opt-detach-elementwise-from-named-ops) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<4xf32>
  %expanded = tensor.expand_shape %0 [[0, 1]] : tensor<4xf32> into tensor<1x4xf32>
  %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
  %1 = tensor.empty() : tensor<1x3xf32>
  %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<1x3xf32>) -> tensor<1x3xf32>
  %3 = linalg.matmul ins(%expanded, %_params.weight : tensor<1x4xf32>, tensor<4x3xf32>) outs(%2 : tensor<1x3xf32>) -> tensor<1x3xf32>
  %collapsed = tensor.collapse_shape %3 [[0, 1]] : tensor<1x3xf32> into tensor<3xf32>
  %_params.bias = util.global.load @_params.bias : tensor<3xf32>
  %4 = tensor.empty() : tensor<3xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%collapsed, %_params.bias : tensor<3xf32>, tensor<3xf32>) outs(%4 : tensor<3xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %7 = arith.addf %in, %in_0 : f32
    linalg.yield %7 : f32
  } -> tensor<3xf32>
  %6 = hal.tensor.export %5 "output 0" : tensor<3xf32> -> !hal.buffer_view
  return %6 : !hal.buffer_view
}

// -----// IR Dump After LinalgNamedOpConversion (linalg-named-op-conversion) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<4xf32>
  %expanded = tensor.expand_shape %0 [[0, 1]] : tensor<4xf32> into tensor<1x4xf32>
  %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
  %1 = tensor.empty() : tensor<1x3xf32>
  %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<1x3xf32>) -> tensor<1x3xf32>
  %3 = linalg.matmul ins(%expanded, %_params.weight : tensor<1x4xf32>, tensor<4x3xf32>) outs(%2 : tensor<1x3xf32>) -> tensor<1x3xf32>
  %collapsed = tensor.collapse_shape %3 [[0, 1]] : tensor<1x3xf32> into tensor<3xf32>
  %_params.bias = util.global.load @_params.bias : tensor<3xf32>
  %4 = tensor.empty() : tensor<3xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%collapsed, %_params.bias : tensor<3xf32>, tensor<3xf32>) outs(%4 : tensor<3xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %7 = arith.addf %in, %in_0 : f32
    linalg.yield %7 : f32
  } -> tensor<3xf32>
  %6 = hal.tensor.export %5 "output 0" : tensor<3xf32> -> !hal.buffer_view
  return %6 : !hal.buffer_view
}

// -----// IR Dump After Convert1X1FilterConv2DToMatmul (iree-global-opt-convert-1x1-filter-conv2d-to-matmul) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<4xf32>
  %expanded = tensor.expand_shape %0 [[0, 1]] : tensor<4xf32> into tensor<1x4xf32>
  %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
  %1 = tensor.empty() : tensor<1x3xf32>
  %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<1x3xf32>) -> tensor<1x3xf32>
  %3 = linalg.matmul ins(%expanded, %_params.weight : tensor<1x4xf32>, tensor<4x3xf32>) outs(%2 : tensor<1x3xf32>) -> tensor<1x3xf32>
  %collapsed = tensor.collapse_shape %3 [[0, 1]] : tensor<1x3xf32> into tensor<3xf32>
  %_params.bias = util.global.load @_params.bias : tensor<3xf32>
  %4 = tensor.empty() : tensor<3xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%collapsed, %_params.bias : tensor<3xf32>, tensor<3xf32>) outs(%4 : tensor<3xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %7 = arith.addf %in, %in_0 : f32
    linalg.yield %7 : f32
  } -> tensor<3xf32>
  %6 = hal.tensor.export %5 "output 0" : tensor<3xf32> -> !hal.buffer_view
  return %6 : !hal.buffer_view
}

// -----// IR Dump After EraseUnusedLinalgOperands (iree-global-opt-erase-unused-linalg-operands) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private @_params.weight {noinline} = dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>
  util.global private @_params.bias {noinline} = dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<4xf32>
    %expanded = tensor.expand_shape %0 [[0, 1]] : tensor<4xf32> into tensor<1x4xf32>
    %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
    %1 = tensor.empty() : tensor<1x3xf32>
    %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<1x3xf32>) -> tensor<1x3xf32>
    %3 = linalg.matmul ins(%expanded, %_params.weight : tensor<1x4xf32>, tensor<4x3xf32>) outs(%2 : tensor<1x3xf32>) -> tensor<1x3xf32>
    %collapsed = tensor.collapse_shape %3 [[0, 1]] : tensor<1x3xf32> into tensor<3xf32>
    %_params.bias = util.global.load @_params.bias : tensor<3xf32>
    %4 = tensor.empty() : tensor<3xf32>
    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%collapsed, %_params.bias : tensor<3xf32>, tensor<3xf32>) outs(%4 : tensor<3xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %7 = arith.addf %in, %in_0 : f32
      linalg.yield %7 : f32
    } -> tensor<3xf32>
    %6 = hal.tensor.export %5 "output 0" : tensor<3xf32> -> !hal.buffer_view
    return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After ExpandTensorShapes (iree-flow-expand-tensor-shapes) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private @_params.weight {noinline} = dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>
  util.global private @_params.bias {noinline} = dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<4xf32>
    %expanded = tensor.expand_shape %0 [[0, 1]] : tensor<4xf32> into tensor<1x4xf32>
    %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
    %1 = tensor.empty() : tensor<1x3xf32>
    %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<1x3xf32>) -> tensor<1x3xf32>
    %3 = linalg.matmul ins(%expanded, %_params.weight : tensor<1x4xf32>, tensor<4x3xf32>) outs(%2 : tensor<1x3xf32>) -> tensor<1x3xf32>
    %collapsed = tensor.collapse_shape %3 [[0, 1]] : tensor<1x3xf32> into tensor<3xf32>
    %_params.bias = util.global.load @_params.bias : tensor<3xf32>
    %4 = tensor.empty() : tensor<3xf32>
    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%collapsed, %_params.bias : tensor<3xf32>, tensor<3xf32>) outs(%4 : tensor<3xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %7 = arith.addf %in, %in_0 : f32
      linalg.yield %7 : f32
    } -> tensor<3xf32>
    %6 = hal.tensor.export %5 "output 0" : tensor<3xf32> -> !hal.buffer_view
    return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After ConvertElementwiseToLinalg (convert-elementwise-to-linalg) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<4xf32>
  %expanded = tensor.expand_shape %0 [[0, 1]] : tensor<4xf32> into tensor<1x4xf32>
  %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
  %1 = tensor.empty() : tensor<1x3xf32>
  %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<1x3xf32>) -> tensor<1x3xf32>
  %3 = linalg.matmul ins(%expanded, %_params.weight : tensor<1x4xf32>, tensor<4x3xf32>) outs(%2 : tensor<1x3xf32>) -> tensor<1x3xf32>
  %collapsed = tensor.collapse_shape %3 [[0, 1]] : tensor<1x3xf32> into tensor<3xf32>
  %_params.bias = util.global.load @_params.bias : tensor<3xf32>
  %4 = tensor.empty() : tensor<3xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%collapsed, %_params.bias : tensor<3xf32>, tensor<3xf32>) outs(%4 : tensor<3xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %7 = arith.addf %in, %in_0 : f32
    linalg.yield %7 : f32
  } -> tensor<3xf32>
  %6 = hal.tensor.export %5 "output 0" : tensor<3xf32> -> !hal.buffer_view
  return %6 : !hal.buffer_view
}

// -----// IR Dump After GeneralizeLinalgNamedOps (iree-flow-generalize-linalg-named-ops) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<4xf32>
  %expanded = tensor.expand_shape %0 [[0, 1]] : tensor<4xf32> into tensor<1x4xf32>
  %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
  %1 = tensor.empty() : tensor<1x3xf32>
  %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<1x3xf32>) -> tensor<1x3xf32>
  %3 = linalg.matmul ins(%expanded, %_params.weight : tensor<1x4xf32>, tensor<4x3xf32>) outs(%2 : tensor<1x3xf32>) -> tensor<1x3xf32>
  %collapsed = tensor.collapse_shape %3 [[0, 1]] : tensor<1x3xf32> into tensor<3xf32>
  %_params.bias = util.global.load @_params.bias : tensor<3xf32>
  %4 = tensor.empty() : tensor<3xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%collapsed, %_params.bias : tensor<3xf32>, tensor<3xf32>) outs(%4 : tensor<3xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %7 = arith.addf %in, %in_0 : f32
    linalg.yield %7 : f32
  } -> tensor<3xf32>
  %6 = hal.tensor.export %5 "output 0" : tensor<3xf32> -> !hal.buffer_view
  return %6 : !hal.buffer_view
}

// -----// IR Dump After RaiseSpecialOps (iree-flow-raise-special-ops) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<4xf32>
  %expanded = tensor.expand_shape %0 [[0, 1]] : tensor<4xf32> into tensor<1x4xf32>
  %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
  %1 = tensor.empty() : tensor<1x3xf32>
  %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<1x3xf32>) -> tensor<1x3xf32>
  %3 = linalg.matmul ins(%expanded, %_params.weight : tensor<1x4xf32>, tensor<4x3xf32>) outs(%2 : tensor<1x3xf32>) -> tensor<1x3xf32>
  %collapsed = tensor.collapse_shape %3 [[0, 1]] : tensor<1x3xf32> into tensor<3xf32>
  %_params.bias = util.global.load @_params.bias : tensor<3xf32>
  %4 = tensor.empty() : tensor<3xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%collapsed, %_params.bias : tensor<3xf32>, tensor<3xf32>) outs(%4 : tensor<3xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %7 = arith.addf %in, %in_0 : f32
    linalg.yield %7 : f32
  } -> tensor<3xf32>
  %6 = hal.tensor.export %5 "output 0" : tensor<3xf32> -> !hal.buffer_view
  return %6 : !hal.buffer_view
}

// -----// IR Dump After FoldUnitExtentDims (iree-flow-fold-unit-extent-dims) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<4xf32>
  %expanded = tensor.expand_shape %0 [[0, 1]] : tensor<4xf32> into tensor<1x4xf32>
  %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
  %1 = tensor.empty() : tensor<1x3xf32>
  %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<1x3xf32>) -> tensor<1x3xf32>
  %3 = linalg.matmul ins(%expanded, %_params.weight : tensor<1x4xf32>, tensor<4x3xf32>) outs(%2 : tensor<1x3xf32>) -> tensor<1x3xf32>
  %collapsed = tensor.collapse_shape %3 [[0, 1]] : tensor<1x3xf32> into tensor<3xf32>
  %_params.bias = util.global.load @_params.bias : tensor<3xf32>
  %4 = tensor.empty() : tensor<3xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%collapsed, %_params.bias : tensor<3xf32>, tensor<3xf32>) outs(%4 : tensor<3xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %7 = arith.addf %in, %in_0 : f32
    linalg.yield %7 : f32
  } -> tensor<3xf32>
  %6 = hal.tensor.export %5 "output 0" : tensor<3xf32> -> !hal.buffer_view
  return %6 : !hal.buffer_view
}

// -----// IR Dump After FuseDequantizationMatmul (iree-flow-fuse-dequantization-matmul) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<4xf32>
  %expanded = tensor.expand_shape %0 [[0, 1]] : tensor<4xf32> into tensor<1x4xf32>
  %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
  %1 = tensor.empty() : tensor<1x3xf32>
  %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<1x3xf32>) -> tensor<1x3xf32>
  %3 = linalg.matmul ins(%expanded, %_params.weight : tensor<1x4xf32>, tensor<4x3xf32>) outs(%2 : tensor<1x3xf32>) -> tensor<1x3xf32>
  %collapsed = tensor.collapse_shape %3 [[0, 1]] : tensor<1x3xf32> into tensor<3xf32>
  %_params.bias = util.global.load @_params.bias : tensor<3xf32>
  %4 = tensor.empty() : tensor<3xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%collapsed, %_params.bias : tensor<3xf32>, tensor<3xf32>) outs(%4 : tensor<3xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %7 = arith.addf %in, %in_0 : f32
    linalg.yield %7 : f32
  } -> tensor<3xf32>
  %6 = hal.tensor.export %5 "output 0" : tensor<3xf32> -> !hal.buffer_view
  return %6 : !hal.buffer_view
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<4xf32>
  %expanded = tensor.expand_shape %0 [[0, 1]] : tensor<4xf32> into tensor<1x4xf32>
  %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
  %1 = tensor.empty() : tensor<1x3xf32>
  %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<1x3xf32>) -> tensor<1x3xf32>
  %3 = linalg.matmul ins(%expanded, %_params.weight : tensor<1x4xf32>, tensor<4x3xf32>) outs(%2 : tensor<1x3xf32>) -> tensor<1x3xf32>
  %collapsed = tensor.collapse_shape %3 [[0, 1]] : tensor<1x3xf32> into tensor<3xf32>
  %_params.bias = util.global.load @_params.bias : tensor<3xf32>
  %4 = tensor.empty() : tensor<3xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%collapsed, %_params.bias : tensor<3xf32>, tensor<3xf32>) outs(%4 : tensor<3xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %7 = arith.addf %in, %in_0 : f32
    linalg.yield %7 : f32
  } -> tensor<3xf32>
  %6 = hal.tensor.export %5 "output 0" : tensor<3xf32> -> !hal.buffer_view
  return %6 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<4xf32>
  %expanded = tensor.expand_shape %0 [[0, 1]] : tensor<4xf32> into tensor<1x4xf32>
  %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
  %1 = tensor.empty() : tensor<1x3xf32>
  %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<1x3xf32>) -> tensor<1x3xf32>
  %3 = linalg.matmul ins(%expanded, %_params.weight : tensor<1x4xf32>, tensor<4x3xf32>) outs(%2 : tensor<1x3xf32>) -> tensor<1x3xf32>
  %collapsed = tensor.collapse_shape %3 [[0, 1]] : tensor<1x3xf32> into tensor<3xf32>
  %_params.bias = util.global.load @_params.bias : tensor<3xf32>
  %4 = tensor.empty() : tensor<3xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%collapsed, %_params.bias : tensor<3xf32>, tensor<3xf32>) outs(%4 : tensor<3xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %7 = arith.addf %in, %in_0 : f32
    linalg.yield %7 : f32
  } -> tensor<3xf32>
  %6 = hal.tensor.export %5 "output 0" : tensor<3xf32> -> !hal.buffer_view
  return %6 : !hal.buffer_view
}

// -----// IR Dump After MaterializeHomogeneousEncodings (iree-global-opt-materialize-homogeneous-encodings) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private @_params.weight {noinline} = dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>
  util.global private @_params.bias {noinline} = dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<4xf32>
    %expanded = tensor.expand_shape %0 [[0, 1]] : tensor<4xf32> into tensor<1x4xf32>
    %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
    %1 = tensor.empty() : tensor<1x3xf32>
    %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<1x3xf32>) -> tensor<1x3xf32>
    %3 = linalg.matmul ins(%expanded, %_params.weight : tensor<1x4xf32>, tensor<4x3xf32>) outs(%2 : tensor<1x3xf32>) -> tensor<1x3xf32>
    %collapsed = tensor.collapse_shape %3 [[0, 1]] : tensor<1x3xf32> into tensor<3xf32>
    %_params.bias = util.global.load @_params.bias : tensor<3xf32>
    %4 = tensor.empty() : tensor<3xf32>
    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%collapsed, %_params.bias : tensor<3xf32>, tensor<3xf32>) outs(%4 : tensor<3xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %7 = arith.addf %in, %in_0 : f32
      linalg.yield %7 : f32
    } -> tensor<3xf32>
    %6 = hal.tensor.export %5 "output 0" : tensor<3xf32> -> !hal.buffer_view
    return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
  %_params.bias = util.global.load @_params.bias : tensor<3xf32>
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<4xf32>
  %expanded = tensor.expand_shape %0 [[0, 1]] : tensor<4xf32> into tensor<1x4xf32>
  %1 = tensor.empty() : tensor<1x3xf32>
  %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<1x3xf32>) -> tensor<1x3xf32>
  %3 = linalg.matmul ins(%expanded, %_params.weight : tensor<1x4xf32>, tensor<4x3xf32>) outs(%2 : tensor<1x3xf32>) -> tensor<1x3xf32>
  %collapsed = tensor.collapse_shape %3 [[0, 1]] : tensor<1x3xf32> into tensor<3xf32>
  %4 = tensor.empty() : tensor<3xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%collapsed, %_params.bias : tensor<3xf32>, tensor<3xf32>) outs(%4 : tensor<3xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %7 = arith.addf %in, %in_0 : f32
    linalg.yield %7 : f32
  } -> tensor<3xf32>
  %6 = hal.tensor.export %5 "output 0" : tensor<3xf32> -> !hal.buffer_view
  return %6 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda], iree.fixedpoint.iteration = 0 : index} {
  util.global private @_params.weight {noinline} = dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>
  util.global private @_params.bias {noinline} = dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %cst = arith.constant 0.000000e+00 : f32
    %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
    %_params.bias = util.global.load @_params.bias : tensor<3xf32>
    %0 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<4xf32>
    %expanded = tensor.expand_shape %0 [[0, 1]] : tensor<4xf32> into tensor<1x4xf32>
    %1 = tensor.empty() : tensor<1x3xf32>
    %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<1x3xf32>) -> tensor<1x3xf32>
    %3 = linalg.matmul ins(%expanded, %_params.weight : tensor<1x4xf32>, tensor<4x3xf32>) outs(%2 : tensor<1x3xf32>) -> tensor<1x3xf32>
    %collapsed = tensor.collapse_shape %3 [[0, 1]] : tensor<1x3xf32> into tensor<3xf32>
    %4 = tensor.empty() : tensor<3xf32>
    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%collapsed, %_params.bias : tensor<3xf32>, tensor<3xf32>) outs(%4 : tensor<3xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %7 = arith.addf %in, %in_0 : f32
      linalg.yield %7 : f32
    } -> tensor<3xf32>
    %6 = hal.tensor.export %5 "output 0" : tensor<3xf32> -> !hal.buffer_view
    return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda], iree.fixedpoint.iteration = 0 : index} {
  util.global private @_params.weight {noinline} = dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>
  util.global private @_params.bias {noinline} = dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %cst = arith.constant 0.000000e+00 : f32
    %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
    %_params.bias = util.global.load @_params.bias : tensor<3xf32>
    %0 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<4xf32>
    %expanded = tensor.expand_shape %0 [[0, 1]] : tensor<4xf32> into tensor<1x4xf32>
    %1 = tensor.empty() : tensor<1x3xf32>
    %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<1x3xf32>) -> tensor<1x3xf32>
    %3 = linalg.matmul ins(%expanded, %_params.weight : tensor<1x4xf32>, tensor<4x3xf32>) outs(%2 : tensor<1x3xf32>) -> tensor<1x3xf32>
    %collapsed = tensor.collapse_shape %3 [[0, 1]] : tensor<1x3xf32> into tensor<3xf32>
    %4 = tensor.empty() : tensor<3xf32>
    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%collapsed, %_params.bias : tensor<3xf32>, tensor<3xf32>) outs(%4 : tensor<3xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %7 = arith.addf %in, %in_0 : f32
      linalg.yield %7 : f32
    } -> tensor<3xf32>
    %6 = hal.tensor.export %5 "output 0" : tensor<3xf32> -> !hal.buffer_view
    return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda], iree.fixedpoint.iteration = 0 : index} {
  util.global private @_params.weight {noinline} = dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>
  util.global private @_params.bias {noinline} = dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %cst = arith.constant 0.000000e+00 : f32
    %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
    %_params.bias = util.global.load @_params.bias : tensor<3xf32>
    %0 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<4xf32>
    %expanded = tensor.expand_shape %0 [[0, 1]] : tensor<4xf32> into tensor<1x4xf32>
    %1 = tensor.empty() : tensor<1x3xf32>
    %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<1x3xf32>) -> tensor<1x3xf32>
    %3 = linalg.matmul ins(%expanded, %_params.weight : tensor<1x4xf32>, tensor<4x3xf32>) outs(%2 : tensor<1x3xf32>) -> tensor<1x3xf32>
    %collapsed = tensor.collapse_shape %3 [[0, 1]] : tensor<1x3xf32> into tensor<3xf32>
    %4 = tensor.empty() : tensor<3xf32>
    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%collapsed, %_params.bias : tensor<3xf32>, tensor<3xf32>) outs(%4 : tensor<3xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %7 = arith.addf %in, %in_0 : f32
      linalg.yield %7 : f32
    } -> tensor<3xf32>
    %6 = hal.tensor.export %5 "output 0" : tensor<3xf32> -> !hal.buffer_view
    return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After HoistIntoGlobals (iree-util-hoist-into-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda], iree.fixedpoint.iteration = 0 : index} {
  util.global private @_params.weight {noinline} = dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>
  util.global private @_params.bias {noinline} = dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %cst = arith.constant 0.000000e+00 : f32
    %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
    %_params.bias = util.global.load @_params.bias : tensor<3xf32>
    %0 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<4xf32>
    %expanded = tensor.expand_shape %0 [[0, 1]] : tensor<4xf32> into tensor<1x4xf32>
    %1 = tensor.empty() : tensor<1x3xf32>
    %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<1x3xf32>) -> tensor<1x3xf32>
    %3 = linalg.matmul ins(%expanded, %_params.weight : tensor<1x4xf32>, tensor<4x3xf32>) outs(%2 : tensor<1x3xf32>) -> tensor<1x3xf32>
    %collapsed = tensor.collapse_shape %3 [[0, 1]] : tensor<1x3xf32> into tensor<3xf32>
    %4 = tensor.empty() : tensor<3xf32>
    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%collapsed, %_params.bias : tensor<3xf32>, tensor<3xf32>) outs(%4 : tensor<3xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %7 = arith.addf %in, %in_0 : f32
      linalg.yield %7 : f32
    } -> tensor<3xf32>
    %6 = hal.tensor.export %5 "output 0" : tensor<3xf32> -> !hal.buffer_view
    return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After JitGlobals (iree-consteval-jit-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda], iree.fixedpoint.iteration = 0 : index} {
  util.global private @_params.weight {noinline} = dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>
  util.global private @_params.bias {noinline} = dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %cst = arith.constant 0.000000e+00 : f32
    %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
    %_params.bias = util.global.load @_params.bias : tensor<3xf32>
    %0 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<4xf32>
    %expanded = tensor.expand_shape %0 [[0, 1]] : tensor<4xf32> into tensor<1x4xf32>
    %1 = tensor.empty() : tensor<1x3xf32>
    %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<1x3xf32>) -> tensor<1x3xf32>
    %3 = linalg.matmul ins(%expanded, %_params.weight : tensor<1x4xf32>, tensor<4x3xf32>) outs(%2 : tensor<1x3xf32>) -> tensor<1x3xf32>
    %collapsed = tensor.collapse_shape %3 [[0, 1]] : tensor<1x3xf32> into tensor<3xf32>
    %4 = tensor.empty() : tensor<3xf32>
    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%collapsed, %_params.bias : tensor<3xf32>, tensor<3xf32>) outs(%4 : tensor<3xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %7 = arith.addf %in, %in_0 : f32
      linalg.yield %7 : f32
    } -> tensor<3xf32>
    %6 = hal.tensor.export %5 "output 0" : tensor<3xf32> -> !hal.buffer_view
    return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %cst = arith.constant 0.000000e+00 : f32
  %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
  %_params.bias = util.global.load @_params.bias : tensor<3xf32>
  %0 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<4xf32>
  %expanded = tensor.expand_shape %0 [[0, 1]] : tensor<4xf32> into tensor<1x4xf32>
  %1 = tensor.empty() : tensor<1x3xf32>
  %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<1x3xf32>) -> tensor<1x3xf32>
  %3 = linalg.matmul ins(%expanded, %_params.weight : tensor<1x4xf32>, tensor<4x3xf32>) outs(%2 : tensor<1x3xf32>) -> tensor<1x3xf32>
  %collapsed = tensor.collapse_shape %3 [[0, 1]] : tensor<1x3xf32> into tensor<3xf32>
  %4 = tensor.empty() : tensor<3xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%collapsed, %_params.bias : tensor<3xf32>, tensor<3xf32>) outs(%4 : tensor<3xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %7 = arith.addf %in, %in_0 : f32
    linalg.yield %7 : f32
  } -> tensor<3xf32>
  %6 = hal.tensor.export %5 "output 0" : tensor<3xf32> -> !hal.buffer_view
  return %6 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %cst = arith.constant 0.000000e+00 : f32
  %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
  %_params.bias = util.global.load @_params.bias : tensor<3xf32>
  %0 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<4xf32>
  %expanded = tensor.expand_shape %0 [[0, 1]] : tensor<4xf32> into tensor<1x4xf32>
  %1 = tensor.empty() : tensor<1x3xf32>
  %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<1x3xf32>) -> tensor<1x3xf32>
  %3 = linalg.matmul ins(%expanded, %_params.weight : tensor<1x4xf32>, tensor<4x3xf32>) outs(%2 : tensor<1x3xf32>) -> tensor<1x3xf32>
  %collapsed = tensor.collapse_shape %3 [[0, 1]] : tensor<1x3xf32> into tensor<3xf32>
  %4 = tensor.empty() : tensor<3xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%collapsed, %_params.bias : tensor<3xf32>, tensor<3xf32>) outs(%4 : tensor<3xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %7 = arith.addf %in, %in_0 : f32
    linalg.yield %7 : f32
  } -> tensor<3xf32>
  %6 = hal.tensor.export %5 "output 0" : tensor<3xf32> -> !hal.buffer_view
  return %6 : !hal.buffer_view
}

// -----// IR Dump After FixedPointIterator (iree-util-fixed-point-iterator) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private @_params.weight {noinline} = dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>
  util.global private @_params.bias {noinline} = dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %cst = arith.constant 0.000000e+00 : f32
    %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
    %_params.bias = util.global.load @_params.bias : tensor<3xf32>
    %0 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<4xf32>
    %expanded = tensor.expand_shape %0 [[0, 1]] : tensor<4xf32> into tensor<1x4xf32>
    %1 = tensor.empty() : tensor<1x3xf32>
    %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<1x3xf32>) -> tensor<1x3xf32>
    %3 = linalg.matmul ins(%expanded, %_params.weight : tensor<1x4xf32>, tensor<4x3xf32>) outs(%2 : tensor<1x3xf32>) -> tensor<1x3xf32>
    %collapsed = tensor.collapse_shape %3 [[0, 1]] : tensor<1x3xf32> into tensor<3xf32>
    %4 = tensor.empty() : tensor<3xf32>
    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%collapsed, %_params.bias : tensor<3xf32>, tensor<3xf32>) outs(%4 : tensor<3xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %7 = arith.addf %in, %in_0 : f32
      linalg.yield %7 : f32
    } -> tensor<3xf32>
    %6 = hal.tensor.export %5 "output 0" : tensor<3xf32> -> !hal.buffer_view
    return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After VerifyInputLegality (iree-verify-input-legality) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private @_params.weight {noinline} = dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>
  util.global private @_params.bias {noinline} = dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %cst = arith.constant 0.000000e+00 : f32
    %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
    %_params.bias = util.global.load @_params.bias : tensor<3xf32>
    %0 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<4xf32>
    %expanded = tensor.expand_shape %0 [[0, 1]] : tensor<4xf32> into tensor<1x4xf32>
    %1 = tensor.empty() : tensor<1x3xf32>
    %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<1x3xf32>) -> tensor<1x3xf32>
    %3 = linalg.matmul ins(%expanded, %_params.weight : tensor<1x4xf32>, tensor<4x3xf32>) outs(%2 : tensor<1x3xf32>) -> tensor<1x3xf32>
    %collapsed = tensor.collapse_shape %3 [[0, 1]] : tensor<1x3xf32> into tensor<3xf32>
    %4 = tensor.empty() : tensor<3xf32>
    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%collapsed, %_params.bias : tensor<3xf32>, tensor<3xf32>) outs(%4 : tensor<3xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %7 = arith.addf %in, %in_0 : f32
      linalg.yield %7 : f32
    } -> tensor<3xf32>
    %6 = hal.tensor.export %5 "output 0" : tensor<3xf32> -> !hal.buffer_view
    return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After TensorPadToTensorInsertSlice (iree-flow-tensor-pad-to-tensor-insert-slice) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0) -> (d0)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private @_params.weight {noinline} = dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>
  util.global private @_params.bias {noinline} = dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %cst = arith.constant 0.000000e+00 : f32
    %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
    %_params.bias = util.global.load @_params.bias : tensor<3xf32>
    %0 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<4xf32>
    %expanded = tensor.expand_shape %0 [[0, 1]] : tensor<4xf32> into tensor<1x4xf32>
    %1 = tensor.empty() : tensor<1x3xf32>
    %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<1x3xf32>) -> tensor<1x3xf32>
    %3 = linalg.matmul ins(%expanded, %_params.weight : tensor<1x4xf32>, tensor<4x3xf32>) outs(%2 : tensor<1x3xf32>) -> tensor<1x3xf32>
    %collapsed = tensor.collapse_shape %3 [[0, 1]] : tensor<1x3xf32> into tensor<3xf32>
    %4 = tensor.empty() : tensor<3xf32>
    %5 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel"]} ins(%collapsed, %_params.bias : tensor<3xf32>, tensor<3xf32>) outs(%4 : tensor<3xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %7 = arith.addf %in, %in_0 : f32
      linalg.yield %7 : f32
    } -> tensor<3xf32>
    %6 = hal.tensor.export %5 "output 0" : tensor<3xf32> -> !hal.buffer_view
    return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After RaiseSpecialOps (iree-flow-raise-special-ops) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %cst = arith.constant 0.000000e+00 : f32
  %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
  %_params.bias = util.global.load @_params.bias : tensor<3xf32>
  %0 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<4xf32>
  %expanded = tensor.expand_shape %0 [[0, 1]] : tensor<4xf32> into tensor<1x4xf32>
  %1 = tensor.empty() : tensor<1x3xf32>
  %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<1x3xf32>) -> tensor<1x3xf32>
  %3 = linalg.matmul ins(%expanded, %_params.weight : tensor<1x4xf32>, tensor<4x3xf32>) outs(%2 : tensor<1x3xf32>) -> tensor<1x3xf32>
  %collapsed = tensor.collapse_shape %3 [[0, 1]] : tensor<1x3xf32> into tensor<3xf32>
  %4 = tensor.empty() : tensor<3xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%collapsed, %_params.bias : tensor<3xf32>, tensor<3xf32>) outs(%4 : tensor<3xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %7 = arith.addf %in, %in_0 : f32
    linalg.yield %7 : f32
  } -> tensor<3xf32>
  %6 = hal.tensor.export %5 "output 0" : tensor<3xf32> -> !hal.buffer_view
  return %6 : !hal.buffer_view
}

// -----// IR Dump After InterchangeGenericOps (iree-flow-interchange-generic-ops) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %cst = arith.constant 0.000000e+00 : f32
  %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
  %_params.bias = util.global.load @_params.bias : tensor<3xf32>
  %0 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<4xf32>
  %expanded = tensor.expand_shape %0 [[0, 1]] : tensor<4xf32> into tensor<1x4xf32>
  %1 = tensor.empty() : tensor<1x3xf32>
  %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<1x3xf32>) -> tensor<1x3xf32>
  %3 = linalg.matmul ins(%expanded, %_params.weight : tensor<1x4xf32>, tensor<4x3xf32>) outs(%2 : tensor<1x3xf32>) -> tensor<1x3xf32>
  %collapsed = tensor.collapse_shape %3 [[0, 1]] : tensor<1x3xf32> into tensor<3xf32>
  %4 = tensor.empty() : tensor<3xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%collapsed, %_params.bias : tensor<3xf32>, tensor<3xf32>) outs(%4 : tensor<3xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %7 = arith.addf %in, %in_0 : f32
    linalg.yield %7 : f32
  } -> tensor<3xf32>
  %6 = hal.tensor.export %5 "output 0" : tensor<3xf32> -> !hal.buffer_view
  return %6 : !hal.buffer_view
}

// -----// IR Dump After CollapseDims (iree-flow-collapse-dims) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %cst = arith.constant 0.000000e+00 : f32
  %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
  %_params.bias = util.global.load @_params.bias : tensor<3xf32>
  %0 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<4xf32>
  %expanded = tensor.expand_shape %0 [[0, 1]] : tensor<4xf32> into tensor<1x4xf32>
  %1 = tensor.empty() : tensor<1x3xf32>
  %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<1x3xf32>) -> tensor<1x3xf32>
  %3 = linalg.matmul ins(%expanded, %_params.weight : tensor<1x4xf32>, tensor<4x3xf32>) outs(%2 : tensor<1x3xf32>) -> tensor<1x3xf32>
  %collapsed = tensor.collapse_shape %3 [[0, 1]] : tensor<1x3xf32> into tensor<3xf32>
  %4 = tensor.empty() : tensor<3xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%collapsed, %_params.bias : tensor<3xf32>, tensor<3xf32>) outs(%4 : tensor<3xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %7 = arith.addf %in, %in_0 : f32
    linalg.yield %7 : f32
  } -> tensor<3xf32>
  %6 = hal.tensor.export %5 "output 0" : tensor<3xf32> -> !hal.buffer_view
  return %6 : !hal.buffer_view
}

// -----// IR Dump After ResolveShapedTypeResultDims (resolve-shaped-type-result-dims) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %cst = arith.constant 0.000000e+00 : f32
  %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
  %_params.bias = util.global.load @_params.bias : tensor<3xf32>
  %0 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<4xf32>
  %expanded = tensor.expand_shape %0 [[0, 1]] : tensor<4xf32> into tensor<1x4xf32>
  %1 = tensor.empty() : tensor<1x3xf32>
  %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<1x3xf32>) -> tensor<1x3xf32>
  %3 = linalg.matmul ins(%expanded, %_params.weight : tensor<1x4xf32>, tensor<4x3xf32>) outs(%2 : tensor<1x3xf32>) -> tensor<1x3xf32>
  %collapsed = tensor.collapse_shape %3 [[0, 1]] : tensor<1x3xf32> into tensor<3xf32>
  %4 = tensor.empty() : tensor<3xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%collapsed, %_params.bias : tensor<3xf32>, tensor<3xf32>) outs(%4 : tensor<3xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %7 = arith.addf %in, %in_0 : f32
    linalg.yield %7 : f32
  } -> tensor<3xf32>
  %6 = hal.tensor.export %5 "output 0" : tensor<3xf32> -> !hal.buffer_view
  return %6 : !hal.buffer_view
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %cst = arith.constant 0.000000e+00 : f32
  %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
  %_params.bias = util.global.load @_params.bias : tensor<3xf32>
  %0 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<4xf32>
  %expanded = tensor.expand_shape %0 [[0, 1]] : tensor<4xf32> into tensor<1x4xf32>
  %1 = tensor.empty() : tensor<1x3xf32>
  %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<1x3xf32>) -> tensor<1x3xf32>
  %3 = linalg.matmul ins(%expanded, %_params.weight : tensor<1x4xf32>, tensor<4x3xf32>) outs(%2 : tensor<1x3xf32>) -> tensor<1x3xf32>
  %collapsed = tensor.collapse_shape %3 [[0, 1]] : tensor<1x3xf32> into tensor<3xf32>
  %4 = tensor.empty() : tensor<3xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%collapsed, %_params.bias : tensor<3xf32>, tensor<3xf32>) outs(%4 : tensor<3xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %7 = arith.addf %in, %in_0 : f32
    linalg.yield %7 : f32
  } -> tensor<3xf32>
  %6 = hal.tensor.export %5 "output 0" : tensor<3xf32> -> !hal.buffer_view
  return %6 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %cst = arith.constant 0.000000e+00 : f32
  %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
  %_params.bias = util.global.load @_params.bias : tensor<3xf32>
  %0 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<4xf32>
  %expanded = tensor.expand_shape %0 [[0, 1]] : tensor<4xf32> into tensor<1x4xf32>
  %1 = tensor.empty() : tensor<1x3xf32>
  %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<1x3xf32>) -> tensor<1x3xf32>
  %3 = linalg.matmul ins(%expanded, %_params.weight : tensor<1x4xf32>, tensor<4x3xf32>) outs(%2 : tensor<1x3xf32>) -> tensor<1x3xf32>
  %collapsed = tensor.collapse_shape %3 [[0, 1]] : tensor<1x3xf32> into tensor<3xf32>
  %4 = tensor.empty() : tensor<3xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>, affine_map<(d0) -> (d0)>], iterator_types = ["parallel"]} ins(%collapsed, %_params.bias : tensor<3xf32>, tensor<3xf32>) outs(%4 : tensor<3xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %7 = arith.addf %in, %in_0 : f32
    linalg.yield %7 : f32
  } -> tensor<3xf32>
  %6 = hal.tensor.export %5 "output 0" : tensor<3xf32> -> !hal.buffer_view
  return %6 : !hal.buffer_view
}

// -----// IR Dump After FusionOfTensorOps (iree-flow-fusion-of-tensor-ops) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %cst = arith.constant 0.000000e+00 : f32
  %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
  %_params.bias = util.global.load @_params.bias : tensor<3xf32>
  %0 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<4xf32>
  %expanded = tensor.expand_shape %0 [[0, 1]] : tensor<4xf32> into tensor<1x4xf32>
  %1 = tensor.empty() : tensor<1x3xf32>
  %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<1x3xf32>) -> tensor<1x3xf32>
  %3 = linalg.matmul ins(%expanded, %_params.weight : tensor<1x4xf32>, tensor<4x3xf32>) outs(%2 : tensor<1x3xf32>) -> tensor<1x3xf32>
  %expanded_0 = tensor.expand_shape %_params.bias [[0, 1]] : tensor<3xf32> into tensor<1x3xf32>
  %4 = tensor.empty() : tensor<1x3xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%3, %expanded_0 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%4 : tensor<1x3xf32>) {
  ^bb0(%in: f32, %in_1: f32, %out: f32):
    %7 = arith.addf %in, %in_1 : f32
    linalg.yield %7 : f32
  } -> tensor<1x3xf32>
  %collapsed = tensor.collapse_shape %5 [[0, 1]] : tensor<1x3xf32> into tensor<3xf32>
  %6 = hal.tensor.export %collapsed "output 0" : tensor<3xf32> -> !hal.buffer_view
  return %6 : !hal.buffer_view
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %cst = arith.constant 0.000000e+00 : f32
  %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
  %_params.bias = util.global.load @_params.bias : tensor<3xf32>
  %0 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<4xf32>
  %expanded = tensor.expand_shape %0 [[0, 1]] : tensor<4xf32> into tensor<1x4xf32>
  %1 = tensor.empty() : tensor<1x3xf32>
  %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<1x3xf32>) -> tensor<1x3xf32>
  %3 = linalg.matmul ins(%expanded, %_params.weight : tensor<1x4xf32>, tensor<4x3xf32>) outs(%2 : tensor<1x3xf32>) -> tensor<1x3xf32>
  %expanded_0 = tensor.expand_shape %_params.bias [[0, 1]] : tensor<3xf32> into tensor<1x3xf32>
  %4 = tensor.empty() : tensor<1x3xf32>
  %5 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%3, %expanded_0 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%4 : tensor<1x3xf32>) {
  ^bb0(%in: f32, %in_1: f32, %out: f32):
    %7 = arith.addf %in, %in_1 : f32
    linalg.yield %7 : f32
  } -> tensor<1x3xf32>
  %collapsed = tensor.collapse_shape %5 [[0, 1]] : tensor<1x3xf32> into tensor<3xf32>
  %6 = hal.tensor.export %collapsed "output 0" : tensor<3xf32> -> !hal.buffer_view
  return %6 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %cst = arith.constant 0.000000e+00 : f32
  %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
  %_params.bias = util.global.load @_params.bias : tensor<3xf32>
  %0 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<4xf32>
  %expanded = tensor.expand_shape %0 [[0, 1]] : tensor<4xf32> into tensor<1x4xf32>
  %1 = tensor.empty() : tensor<1x3xf32>
  %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<1x3xf32>) -> tensor<1x3xf32>
  %3 = linalg.matmul ins(%expanded, %_params.weight : tensor<1x4xf32>, tensor<4x3xf32>) outs(%2 : tensor<1x3xf32>) -> tensor<1x3xf32>
  %expanded_0 = tensor.expand_shape %_params.bias [[0, 1]] : tensor<3xf32> into tensor<1x3xf32>
  %4 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%3, %expanded_0 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%1 : tensor<1x3xf32>) {
  ^bb0(%in: f32, %in_1: f32, %out: f32):
    %6 = arith.addf %in, %in_1 : f32
    linalg.yield %6 : f32
  } -> tensor<1x3xf32>
  %collapsed = tensor.collapse_shape %4 [[0, 1]] : tensor<1x3xf32> into tensor<3xf32>
  %5 = hal.tensor.export %collapsed "output 0" : tensor<3xf32> -> !hal.buffer_view
  return %5 : !hal.buffer_view
}

// -----// IR Dump After SplitReduction (iree-flow-split-reduction-ops) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %cst = arith.constant 0.000000e+00 : f32
  %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
  %_params.bias = util.global.load @_params.bias : tensor<3xf32>
  %0 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<4xf32>
  %expanded = tensor.expand_shape %0 [[0, 1]] : tensor<4xf32> into tensor<1x4xf32>
  %1 = tensor.empty() : tensor<1x3xf32>
  %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<1x3xf32>) -> tensor<1x3xf32>
  %3 = linalg.matmul ins(%expanded, %_params.weight : tensor<1x4xf32>, tensor<4x3xf32>) outs(%2 : tensor<1x3xf32>) -> tensor<1x3xf32>
  %expanded_0 = tensor.expand_shape %_params.bias [[0, 1]] : tensor<3xf32> into tensor<1x3xf32>
  %4 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%3, %expanded_0 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%1 : tensor<1x3xf32>) {
  ^bb0(%in: f32, %in_1: f32, %out: f32):
    %6 = arith.addf %in, %in_1 : f32
    linalg.yield %6 : f32
  } -> tensor<1x3xf32>
  %collapsed = tensor.collapse_shape %4 [[0, 1]] : tensor<1x3xf32> into tensor<3xf32>
  %5 = hal.tensor.export %collapsed "output 0" : tensor<3xf32> -> !hal.buffer_view
  return %5 : !hal.buffer_view
}

// -----// IR Dump After InterchangeGenericOps (iree-flow-interchange-generic-ops) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %cst = arith.constant 0.000000e+00 : f32
  %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
  %_params.bias = util.global.load @_params.bias : tensor<3xf32>
  %0 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<4xf32>
  %expanded = tensor.expand_shape %0 [[0, 1]] : tensor<4xf32> into tensor<1x4xf32>
  %1 = tensor.empty() : tensor<1x3xf32>
  %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<1x3xf32>) -> tensor<1x3xf32>
  %3 = linalg.matmul ins(%expanded, %_params.weight : tensor<1x4xf32>, tensor<4x3xf32>) outs(%2 : tensor<1x3xf32>) -> tensor<1x3xf32>
  %expanded_0 = tensor.expand_shape %_params.bias [[0, 1]] : tensor<3xf32> into tensor<1x3xf32>
  %4 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%3, %expanded_0 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%1 : tensor<1x3xf32>) {
  ^bb0(%in: f32, %in_1: f32, %out: f32):
    %6 = arith.addf %in, %in_1 : f32
    linalg.yield %6 : f32
  } -> tensor<1x3xf32>
  %collapsed = tensor.collapse_shape %4 [[0, 1]] : tensor<1x3xf32> into tensor<3xf32>
  %5 = hal.tensor.export %collapsed "output 0" : tensor<3xf32> -> !hal.buffer_view
  return %5 : !hal.buffer_view
}

// -----// IR Dump After FormScalarDispatches (iree-flow-form-scalar-dispatches) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %cst = arith.constant 0.000000e+00 : f32
  %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
  %_params.bias = util.global.load @_params.bias : tensor<3xf32>
  %0 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<4xf32>
  %expanded = tensor.expand_shape %0 [[0, 1]] : tensor<4xf32> into tensor<1x4xf32>
  %1 = tensor.empty() : tensor<1x3xf32>
  %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<1x3xf32>) -> tensor<1x3xf32>
  %3 = linalg.matmul ins(%expanded, %_params.weight : tensor<1x4xf32>, tensor<4x3xf32>) outs(%2 : tensor<1x3xf32>) -> tensor<1x3xf32>
  %expanded_0 = tensor.expand_shape %_params.bias [[0, 1]] : tensor<3xf32> into tensor<1x3xf32>
  %4 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%3, %expanded_0 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%1 : tensor<1x3xf32>) {
  ^bb0(%in: f32, %in_1: f32, %out: f32):
    %6 = arith.addf %in, %in_1 : f32
    linalg.yield %6 : f32
  } -> tensor<1x3xf32>
  %collapsed = tensor.collapse_shape %4 [[0, 1]] : tensor<1x3xf32> into tensor<3xf32>
  %5 = hal.tensor.export %collapsed "output 0" : tensor<3xf32> -> !hal.buffer_view
  return %5 : !hal.buffer_view
}

// -----// IR Dump After FormDispatchRegions (iree-flow-form-dispatch-regions) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %cst = arith.constant 0.000000e+00 : f32
  %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
  %_params.bias = util.global.load @_params.bias : tensor<3xf32>
  %0 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<4xf32>
  %expanded = tensor.expand_shape %0 [[0, 1]] : tensor<4xf32> into tensor<1x4xf32>
  %1 = tensor.empty() : tensor<1x3xf32>
  %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<1x3xf32>) -> tensor<1x3xf32>
  %expanded_0 = tensor.expand_shape %_params.bias [[0, 1]] : tensor<3xf32> into tensor<1x3xf32>
  %3 = flow.dispatch.region -> (tensor<1x3xf32>) {
    %5 = linalg.matmul ins(%expanded, %_params.weight : tensor<1x4xf32>, tensor<4x3xf32>) outs(%2 : tensor<1x3xf32>) -> tensor<1x3xf32>
    %6 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%5, %expanded_0 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%1 : tensor<1x3xf32>) {
    ^bb0(%in: f32, %in_1: f32, %out: f32):
      %7 = arith.addf %in, %in_1 : f32
      linalg.yield %7 : f32
    } -> tensor<1x3xf32>
    flow.return %6 : tensor<1x3xf32>
  }
  %collapsed = tensor.collapse_shape %3 [[0, 1]] : tensor<1x3xf32> into tensor<3xf32>
  %4 = hal.tensor.export %collapsed "output 0" : tensor<3xf32> -> !hal.buffer_view
  return %4 : !hal.buffer_view
}

// -----// IR Dump After CollapseDimensions (iree-flow-collapse-dimensions) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %cst = arith.constant 0.000000e+00 : f32
  %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
  %_params.bias = util.global.load @_params.bias : tensor<3xf32>
  %0 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<4xf32>
  %expanded = tensor.expand_shape %0 [[0, 1]] : tensor<4xf32> into tensor<1x4xf32>
  %1 = tensor.empty() : tensor<1x3xf32>
  %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<1x3xf32>) -> tensor<1x3xf32>
  %expanded_0 = tensor.expand_shape %_params.bias [[0, 1]] : tensor<3xf32> into tensor<1x3xf32>
  %3 = flow.dispatch.region -> (tensor<1x3xf32>) {
    %5 = linalg.matmul ins(%expanded, %_params.weight : tensor<1x4xf32>, tensor<4x3xf32>) outs(%2 : tensor<1x3xf32>) -> tensor<1x3xf32>
    %6 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%5, %expanded_0 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%1 : tensor<1x3xf32>) {
    ^bb0(%in: f32, %in_1: f32, %out: f32):
      %7 = arith.addf %in, %in_1 : f32
      linalg.yield %7 : f32
    } -> tensor<1x3xf32>
    flow.return %6 : tensor<1x3xf32>
  }
  %collapsed = tensor.collapse_shape %3 [[0, 1]] : tensor<1x3xf32> into tensor<3xf32>
  %4 = hal.tensor.export %collapsed "output 0" : tensor<3xf32> -> !hal.buffer_view
  return %4 : !hal.buffer_view
}

// -----// IR Dump After CloneProducersIntoDispatchRegions (iree-flow-clone-producers-into-dispatch-regions) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %cst = arith.constant 0.000000e+00 : f32
  %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
  %_params.bias = util.global.load @_params.bias : tensor<3xf32>
  %0 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<4xf32>
  %expanded = tensor.expand_shape %0 [[0, 1]] : tensor<4xf32> into tensor<1x4xf32>
  %1 = tensor.empty() : tensor<1x3xf32>
  %2 = linalg.fill ins(%cst : f32) outs(%1 : tensor<1x3xf32>) -> tensor<1x3xf32>
  %expanded_0 = tensor.expand_shape %_params.bias [[0, 1]] : tensor<3xf32> into tensor<1x3xf32>
  %3 = flow.dispatch.region -> (tensor<1x3xf32>) {
    %5 = tensor.empty() : tensor<1x3xf32>
    %cst_1 = arith.constant 0.000000e+00 : f32
    %6 = linalg.fill ins(%cst_1 : f32) outs(%5 : tensor<1x3xf32>) -> tensor<1x3xf32>
    %7 = linalg.matmul ins(%expanded, %_params.weight : tensor<1x4xf32>, tensor<4x3xf32>) outs(%6 : tensor<1x3xf32>) -> tensor<1x3xf32>
    %8 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%7, %expanded_0 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%5 : tensor<1x3xf32>) {
    ^bb0(%in: f32, %in_2: f32, %out: f32):
      %9 = arith.addf %in, %in_2 : f32
      linalg.yield %9 : f32
    } -> tensor<1x3xf32>
    flow.return %8 : tensor<1x3xf32>
  }
  %collapsed = tensor.collapse_shape %3 [[0, 1]] : tensor<1x3xf32> into tensor<3xf32>
  %4 = hal.tensor.export %collapsed "output 0" : tensor<3xf32> -> !hal.buffer_view
  return %4 : !hal.buffer_view
}

// -----// IR Dump After FormDispatchWorkgroups (iree-flow-form-dispatch-workgroups) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
  %_params.bias = util.global.load @_params.bias : tensor<3xf32>
  %0 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<4xf32>
  %1 = flow.tensor.reshape %0 : tensor<4xf32> -> tensor<1x4xf32>
  %2 = flow.tensor.reshape %_params.bias : tensor<3xf32> -> tensor<1x3xf32>
  %3 = flow.dispatch.workgroups(%1, %_params.weight, %2) : (tensor<1x4xf32>, tensor<4x3xf32>, tensor<1x3xf32>) -> tensor<1x3xf32> =
      (%arg1: !flow.dispatch.tensor<readonly:tensor<1x4xf32>>, %arg2: !flow.dispatch.tensor<readonly:tensor<4x3xf32>>, %arg3: !flow.dispatch.tensor<readonly:tensor<1x3xf32>>, %arg4: !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>) {
    %cst = arith.constant 0.000000e+00 : f32
    %6 = flow.dispatch.tensor.load %arg1, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
    %7 = flow.dispatch.tensor.load %arg2, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
    %8 = flow.dispatch.tensor.load %arg3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
    %9 = tensor.empty() : tensor<1x3xf32>
    %10 = linalg.fill ins(%cst : f32) outs(%9 : tensor<1x3xf32>) -> tensor<1x3xf32>
    %11 = linalg.matmul ins(%6, %7 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%10 : tensor<1x3xf32>) -> tensor<1x3xf32>
    %12 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%11, %8 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%9 : tensor<1x3xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %13 = arith.addf %in, %in_0 : f32
      linalg.yield %13 : f32
    } -> tensor<1x3xf32>
    flow.dispatch.tensor.store %12, %arg4, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
    flow.return
  } count() -> (index, index, index) {
    %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
    flow.return %x, %y, %z : index, index, index
  }
  %4 = flow.tensor.reshape %3 : tensor<1x3xf32> -> tensor<3xf32>
  %5 = hal.tensor.export %4 "output 0" : tensor<3xf32> -> !hal.buffer_view
  return %5 : !hal.buffer_view
}

// -----// IR Dump After CaptureDispatchDynamicDims (iree-flow-capture-dispatch-dynamic-dims) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
  %_params.bias = util.global.load @_params.bias : tensor<3xf32>
  %0 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<4xf32>
  %1 = flow.tensor.reshape %0 : tensor<4xf32> -> tensor<1x4xf32>
  %2 = flow.tensor.reshape %_params.bias : tensor<3xf32> -> tensor<1x3xf32>
  %3 = flow.dispatch.workgroups(%1, %_params.weight, %2) : (tensor<1x4xf32>, tensor<4x3xf32>, tensor<1x3xf32>) -> tensor<1x3xf32> =
      (%arg1: !flow.dispatch.tensor<readonly:tensor<1x4xf32>>, %arg2: !flow.dispatch.tensor<readonly:tensor<4x3xf32>>, %arg3: !flow.dispatch.tensor<readonly:tensor<1x3xf32>>, %arg4: !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>) {
    %cst = arith.constant 0.000000e+00 : f32
    %6 = flow.dispatch.tensor.load %arg1, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
    %7 = flow.dispatch.tensor.load %arg2, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
    %8 = flow.dispatch.tensor.load %arg3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
    %9 = tensor.empty() : tensor<1x3xf32>
    %10 = linalg.fill ins(%cst : f32) outs(%9 : tensor<1x3xf32>) -> tensor<1x3xf32>
    %11 = linalg.matmul ins(%6, %7 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%10 : tensor<1x3xf32>) -> tensor<1x3xf32>
    %12 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%11, %8 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%9 : tensor<1x3xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %13 = arith.addf %in, %in_0 : f32
      linalg.yield %13 : f32
    } -> tensor<1x3xf32>
    flow.dispatch.tensor.store %12, %arg4, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
    flow.return
  } count() -> (index, index, index) {
    %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
    flow.return %x, %y, %z : index, index, index
  }
  %4 = flow.tensor.reshape %3 : tensor<1x3xf32> -> tensor<3xf32>
  %5 = hal.tensor.export %4 "output 0" : tensor<3xf32> -> !hal.buffer_view
  return %5 : !hal.buffer_view
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
  %_params.bias = util.global.load @_params.bias : tensor<3xf32>
  %0 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<4xf32>
  %1 = flow.tensor.reshape %0 : tensor<4xf32> -> tensor<1x4xf32>
  %2 = flow.tensor.reshape %_params.bias : tensor<3xf32> -> tensor<1x3xf32>
  %3 = flow.dispatch.workgroups(%1, %_params.weight, %2) : (tensor<1x4xf32>, tensor<4x3xf32>, tensor<1x3xf32>) -> tensor<1x3xf32> =
      (%arg1: !flow.dispatch.tensor<readonly:tensor<1x4xf32>>, %arg2: !flow.dispatch.tensor<readonly:tensor<4x3xf32>>, %arg3: !flow.dispatch.tensor<readonly:tensor<1x3xf32>>, %arg4: !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>) {
    %cst = arith.constant 0.000000e+00 : f32
    %6 = flow.dispatch.tensor.load %arg1, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
    %7 = flow.dispatch.tensor.load %arg2, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
    %8 = flow.dispatch.tensor.load %arg3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
    %9 = tensor.empty() : tensor<1x3xf32>
    %10 = linalg.fill ins(%cst : f32) outs(%9 : tensor<1x3xf32>) -> tensor<1x3xf32>
    %11 = linalg.matmul ins(%6, %7 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%10 : tensor<1x3xf32>) -> tensor<1x3xf32>
    %12 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%11, %8 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%9 : tensor<1x3xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %13 = arith.addf %in, %in_0 : f32
      linalg.yield %13 : f32
    } -> tensor<1x3xf32>
    flow.dispatch.tensor.store %12, %arg4, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
    flow.return
  } count() -> (index, index, index) {
    %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
    flow.return %x, %y, %z : index, index, index
  }
  %4 = flow.tensor.reshape %3 : tensor<1x3xf32> -> tensor<3xf32>
  %5 = hal.tensor.export %4 "output 0" : tensor<3xf32> -> !hal.buffer_view
  return %5 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
  %_params.bias = util.global.load @_params.bias : tensor<3xf32>
  %0 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<4xf32>
  %1 = flow.tensor.reshape %0 : tensor<4xf32> -> tensor<1x4xf32>
  %2 = flow.tensor.reshape %_params.bias : tensor<3xf32> -> tensor<1x3xf32>
  %3 = flow.dispatch.workgroups(%1, %_params.weight, %2) : (tensor<1x4xf32>, tensor<4x3xf32>, tensor<1x3xf32>) -> tensor<1x3xf32> =
      (%arg1: !flow.dispatch.tensor<readonly:tensor<1x4xf32>>, %arg2: !flow.dispatch.tensor<readonly:tensor<4x3xf32>>, %arg3: !flow.dispatch.tensor<readonly:tensor<1x3xf32>>, %arg4: !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>) {
    %cst = arith.constant 0.000000e+00 : f32
    %6 = flow.dispatch.tensor.load %arg1, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
    %7 = flow.dispatch.tensor.load %arg2, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
    %8 = flow.dispatch.tensor.load %arg3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
    %9 = tensor.empty() : tensor<1x3xf32>
    %10 = linalg.fill ins(%cst : f32) outs(%9 : tensor<1x3xf32>) -> tensor<1x3xf32>
    %11 = linalg.matmul ins(%6, %7 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%10 : tensor<1x3xf32>) -> tensor<1x3xf32>
    %12 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%11, %8 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%9 : tensor<1x3xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %13 = arith.addf %in, %in_0 : f32
      linalg.yield %13 : f32
    } -> tensor<1x3xf32>
    flow.dispatch.tensor.store %12, %arg4, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
    flow.return
  } count() -> (index, index, index) {
    %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
    flow.return %x, %y, %z : index, index, index
  }
  %4 = flow.tensor.reshape %3 : tensor<1x3xf32> -> tensor<3xf32>
  %5 = hal.tensor.export %4 "output 0" : tensor<3xf32> -> !hal.buffer_view
  return %5 : !hal.buffer_view
}

// -----// IR Dump After InitializeEmptyTensors (iree-flow-initialize-empty-tensors) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
  %_params.bias = util.global.load @_params.bias : tensor<3xf32>
  %0 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<4xf32>
  %1 = flow.tensor.reshape %0 : tensor<4xf32> -> tensor<1x4xf32>
  %2 = flow.tensor.reshape %_params.bias : tensor<3xf32> -> tensor<1x3xf32>
  %3 = flow.dispatch.workgroups(%1, %_params.weight, %2) : (tensor<1x4xf32>, tensor<4x3xf32>, tensor<1x3xf32>) -> tensor<1x3xf32> =
      (%arg1: !flow.dispatch.tensor<readonly:tensor<1x4xf32>>, %arg2: !flow.dispatch.tensor<readonly:tensor<4x3xf32>>, %arg3: !flow.dispatch.tensor<readonly:tensor<1x3xf32>>, %arg4: !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>) {
    %cst = arith.constant 0.000000e+00 : f32
    %6 = flow.dispatch.tensor.load %arg1, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
    %7 = flow.dispatch.tensor.load %arg2, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
    %8 = flow.dispatch.tensor.load %arg3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
    %9 = tensor.empty() : tensor<1x3xf32>
    %10 = linalg.fill ins(%cst : f32) outs(%9 : tensor<1x3xf32>) -> tensor<1x3xf32>
    %11 = linalg.matmul ins(%6, %7 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%10 : tensor<1x3xf32>) -> tensor<1x3xf32>
    %12 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%11, %8 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%9 : tensor<1x3xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %13 = arith.addf %in, %in_0 : f32
      linalg.yield %13 : f32
    } -> tensor<1x3xf32>
    flow.dispatch.tensor.store %12, %arg4, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
    flow.return
  } count() -> (index, index, index) {
    %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
    flow.return %x, %y, %z : index, index, index
  }
  %4 = flow.tensor.reshape %3 : tensor<1x3xf32> -> tensor<3xf32>
  %5 = hal.tensor.export %4 "output 0" : tensor<3xf32> -> !hal.buffer_view
  return %5 : !hal.buffer_view
}

// -----// IR Dump After OutlineDispatchRegions (iree-flow-outline-dispatch-regions) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private @_params.weight {noinline} = dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>
  util.global private @_params.bias {noinline} = dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>
  flow.executable private @main_dispatch_0 {
    flow.executable.export public @main_dispatch_0 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0(%arg0: !flow.dispatch.tensor<readonly:tensor<1x4xf32>>, %arg1: !flow.dispatch.tensor<readonly:tensor<4x3xf32>>, %arg2: !flow.dispatch.tensor<readonly:tensor<1x3xf32>>, %arg3: !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>) {
        %cst = arith.constant 0.000000e+00 : f32
        %0 = flow.dispatch.tensor.load %arg0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
        %1 = flow.dispatch.tensor.load %arg1, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
        %2 = flow.dispatch.tensor.load %arg2, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
        %3 = tensor.empty() : tensor<1x3xf32>
        %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %5 = linalg.matmul ins(%0, %1 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%4 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %6 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%5, %2 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%3 : tensor<1x3xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %7 = arith.addf %in, %in_0 : f32
          linalg.yield %7 : f32
        } -> tensor<1x3xf32>
        flow.dispatch.tensor.store %6, %arg3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
    %_params.bias = util.global.load @_params.bias : tensor<3xf32>
    %0 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<4xf32>
    %1 = flow.tensor.reshape %0 : tensor<4xf32> -> tensor<1x4xf32>
    %2 = flow.tensor.reshape %_params.bias : tensor<3xf32> -> tensor<1x3xf32>
    %3 = flow.dispatch @main_dispatch_0::@main_dispatch_0(%1, %_params.weight, %2) : (tensor<1x4xf32>, tensor<4x3xf32>, tensor<1x3xf32>) -> tensor<1x3xf32>
    %4 = flow.tensor.reshape %3 : tensor<1x3xf32> -> tensor<3xf32>
    %5 = hal.tensor.export %4 "output 0" : tensor<3xf32> -> !hal.buffer_view
    return %5 : !hal.buffer_view
  }
}


// -----// IR Dump After AnnotateDispatches (iree-flow-annotate-dispatches) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private @_params.weight {noinline} = dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>
  util.global private @_params.bias {noinline} = dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>
  flow.executable private @main_dispatch_0 {
    flow.executable.export public @main_dispatch_0_matmul_1x3x4_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !flow.dispatch.tensor<readonly:tensor<1x4xf32>>, %arg1: !flow.dispatch.tensor<readonly:tensor<4x3xf32>>, %arg2: !flow.dispatch.tensor<readonly:tensor<1x3xf32>>, %arg3: !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>) {
        %cst = arith.constant 0.000000e+00 : f32
        %0 = flow.dispatch.tensor.load %arg0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
        %1 = flow.dispatch.tensor.load %arg1, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
        %2 = flow.dispatch.tensor.load %arg2, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
        %3 = tensor.empty() : tensor<1x3xf32>
        %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %5 = linalg.matmul ins(%0, %1 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%4 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %6 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%5, %2 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%3 : tensor<1x3xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %7 = arith.addf %in, %in_0 : f32
          linalg.yield %7 : f32
        } -> tensor<1x3xf32>
        flow.dispatch.tensor.store %6, %arg3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
    %_params.bias = util.global.load @_params.bias : tensor<3xf32>
    %0 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<4xf32>
    %1 = flow.tensor.reshape %0 : tensor<4xf32> -> tensor<1x4xf32>
    %2 = flow.tensor.reshape %_params.bias : tensor<3xf32> -> tensor<1x3xf32>
    %3 = flow.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32(%1, %_params.weight, %2) : (tensor<1x4xf32>, tensor<4x3xf32>, tensor<1x3xf32>) -> tensor<1x3xf32>
    %4 = flow.tensor.reshape %3 : tensor<1x3xf32> -> tensor<3xf32>
    %5 = hal.tensor.export %4 "output 0" : tensor<3xf32> -> !hal.buffer_view
    return %5 : !hal.buffer_view
  }
}


// -----// IR Dump After StripDebugOps (iree-util-strip-debug-ops) //----- //
flow.executable private @main_dispatch_0 {
  flow.executable.export public @main_dispatch_0_matmul_1x3x4_f32 workgroups() -> (index, index, index) {
    %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
    flow.return %x, %y, %z : index, index, index
  }
  builtin.module {
    func.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !flow.dispatch.tensor<readonly:tensor<1x4xf32>>, %arg1: !flow.dispatch.tensor<readonly:tensor<4x3xf32>>, %arg2: !flow.dispatch.tensor<readonly:tensor<1x3xf32>>, %arg3: !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>) {
      %cst = arith.constant 0.000000e+00 : f32
      %0 = flow.dispatch.tensor.load %arg0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
      %1 = flow.dispatch.tensor.load %arg1, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
      %2 = flow.dispatch.tensor.load %arg2, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
      %3 = tensor.empty() : tensor<1x3xf32>
      %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<1x3xf32>) -> tensor<1x3xf32>
      %5 = linalg.matmul ins(%0, %1 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%4 : tensor<1x3xf32>) -> tensor<1x3xf32>
      %6 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%5, %2 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%3 : tensor<1x3xf32>) {
      ^bb0(%in: f32, %in_0: f32, %out: f32):
        %7 = arith.addf %in, %in_0 : f32
        linalg.yield %7 : f32
      } -> tensor<1x3xf32>
      flow.dispatch.tensor.store %6, %arg3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
      return
    }
  }
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
  %_params.bias = util.global.load @_params.bias : tensor<3xf32>
  %0 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<4xf32>
  %1 = flow.tensor.reshape %0 : tensor<4xf32> -> tensor<1x4xf32>
  %2 = flow.tensor.reshape %_params.bias : tensor<3xf32> -> tensor<1x3xf32>
  %3 = flow.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32(%1, %_params.weight, %2) : (tensor<1x4xf32>, tensor<4x3xf32>, tensor<1x3xf32>) -> tensor<1x3xf32>
  %4 = flow.tensor.reshape %3 : tensor<1x3xf32> -> tensor<3xf32>
  %5 = hal.tensor.export %4 "output 0" : tensor<3xf32> -> !hal.buffer_view
  return %5 : !hal.buffer_view
}

// -----// IR Dump After DeduplicateExecutables (iree-flow-deduplicate-executables) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private @_params.weight {noinline} = dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>
  util.global private @_params.bias {noinline} = dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>
  flow.executable private @main_dispatch_0 {
    flow.executable.export public @main_dispatch_0_matmul_1x3x4_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !flow.dispatch.tensor<readonly:tensor<1x4xf32>>, %arg1: !flow.dispatch.tensor<readonly:tensor<4x3xf32>>, %arg2: !flow.dispatch.tensor<readonly:tensor<1x3xf32>>, %arg3: !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>) {
        %cst = arith.constant 0.000000e+00 : f32
        %0 = flow.dispatch.tensor.load %arg0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
        %1 = flow.dispatch.tensor.load %arg1, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
        %2 = flow.dispatch.tensor.load %arg2, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
        %3 = tensor.empty() : tensor<1x3xf32>
        %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %5 = linalg.matmul ins(%0, %1 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%4 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %6 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%5, %2 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%3 : tensor<1x3xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %7 = arith.addf %in, %in_0 : f32
          linalg.yield %7 : f32
        } -> tensor<1x3xf32>
        flow.dispatch.tensor.store %6, %arg3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
    %_params.bias = util.global.load @_params.bias : tensor<3xf32>
    %0 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<4xf32>
    %1 = flow.tensor.reshape %0 : tensor<4xf32> -> tensor<1x4xf32>
    %2 = flow.tensor.reshape %_params.bias : tensor<3xf32> -> tensor<1x3xf32>
    %3 = flow.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32(%1, %_params.weight, %2) : (tensor<1x4xf32>, tensor<4x3xf32>, tensor<1x3xf32>) -> tensor<1x3xf32>
    %4 = flow.tensor.reshape %3 : tensor<1x3xf32> -> tensor<3xf32>
    %5 = hal.tensor.export %4 "output 0" : tensor<3xf32> -> !hal.buffer_view
    return %5 : !hal.buffer_view
  }
}


// -----// IR Dump After CleanupTensorShapes (iree-flow-cleanup-tensor-shapes) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
  %_params.bias = util.global.load @_params.bias : tensor<3xf32>
  %0 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<4xf32>
  %1 = flow.tensor.reshape %0 : tensor<4xf32> -> tensor<1x4xf32>
  %2 = flow.tensor.reshape %_params.bias : tensor<3xf32> -> tensor<1x3xf32>
  %3 = flow.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32(%1, %_params.weight, %2) : (tensor<1x4xf32>, tensor<4x3xf32>, tensor<1x3xf32>) -> tensor<1x3xf32>
  %4 = flow.tensor.reshape %3 : tensor<1x3xf32> -> tensor<3xf32>
  %5 = hal.tensor.export %4 "output 0" : tensor<3xf32> -> !hal.buffer_view
  return %5 : !hal.buffer_view
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
flow.executable private @main_dispatch_0 {
  flow.executable.export public @main_dispatch_0_matmul_1x3x4_f32 workgroups() -> (index, index, index) {
    %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
    flow.return %x, %y, %z : index, index, index
  }
  builtin.module {
    func.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !flow.dispatch.tensor<readonly:tensor<1x4xf32>>, %arg1: !flow.dispatch.tensor<readonly:tensor<4x3xf32>>, %arg2: !flow.dispatch.tensor<readonly:tensor<1x3xf32>>, %arg3: !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>) {
      %cst = arith.constant 0.000000e+00 : f32
      %0 = flow.dispatch.tensor.load %arg0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
      %1 = flow.dispatch.tensor.load %arg1, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
      %2 = flow.dispatch.tensor.load %arg2, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
      %3 = tensor.empty() : tensor<1x3xf32>
      %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<1x3xf32>) -> tensor<1x3xf32>
      %5 = linalg.matmul ins(%0, %1 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%4 : tensor<1x3xf32>) -> tensor<1x3xf32>
      %6 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%5, %2 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%3 : tensor<1x3xf32>) {
      ^bb0(%in: f32, %in_0: f32, %out: f32):
        %7 = arith.addf %in, %in_0 : f32
        linalg.yield %7 : f32
      } -> tensor<1x3xf32>
      flow.dispatch.tensor.store %6, %arg3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
      return
    }
  }
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
  %_params.bias = util.global.load @_params.bias : tensor<3xf32>
  %0 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<4xf32>
  %1 = flow.tensor.reshape %0 : tensor<4xf32> -> tensor<1x4xf32>
  %2 = flow.tensor.reshape %_params.bias : tensor<3xf32> -> tensor<1x3xf32>
  %3 = flow.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32(%1, %_params.weight, %2) : (tensor<1x4xf32>, tensor<4x3xf32>, tensor<1x3xf32>) -> tensor<1x3xf32>
  %4 = flow.tensor.reshape %3 : tensor<1x3xf32> -> tensor<3xf32>
  %5 = hal.tensor.export %4 "output 0" : tensor<3xf32> -> !hal.buffer_view
  return %5 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
  %_params.bias = util.global.load @_params.bias : tensor<3xf32>
  %0 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<4xf32>
  %1 = flow.tensor.reshape %0 : tensor<4xf32> -> tensor<1x4xf32>
  %2 = flow.tensor.reshape %_params.bias : tensor<3xf32> -> tensor<1x3xf32>
  %3 = flow.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32(%1, %_params.weight, %2) : (tensor<1x4xf32>, tensor<4x3xf32>, tensor<1x3xf32>) -> tensor<1x3xf32>
  %4 = flow.tensor.reshape %3 : tensor<1x3xf32> -> tensor<3xf32>
  %5 = hal.tensor.export %4 "output 0" : tensor<3xf32> -> !hal.buffer_view
  return %5 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
flow.executable private @main_dispatch_0 {
  flow.executable.export public @main_dispatch_0_matmul_1x3x4_f32 workgroups() -> (index, index, index) {
    %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
    flow.return %x, %y, %z : index, index, index
  }
  builtin.module {
    func.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !flow.dispatch.tensor<readonly:tensor<1x4xf32>>, %arg1: !flow.dispatch.tensor<readonly:tensor<4x3xf32>>, %arg2: !flow.dispatch.tensor<readonly:tensor<1x3xf32>>, %arg3: !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>) {
      %cst = arith.constant 0.000000e+00 : f32
      %0 = flow.dispatch.tensor.load %arg0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
      %1 = flow.dispatch.tensor.load %arg1, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
      %2 = flow.dispatch.tensor.load %arg2, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
      %3 = tensor.empty() : tensor<1x3xf32>
      %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<1x3xf32>) -> tensor<1x3xf32>
      %5 = linalg.matmul ins(%0, %1 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%4 : tensor<1x3xf32>) -> tensor<1x3xf32>
      %6 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%5, %2 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%3 : tensor<1x3xf32>) {
      ^bb0(%in: f32, %in_0: f32, %out: f32):
        %7 = arith.addf %in, %in_0 : f32
        linalg.yield %7 : f32
      } -> tensor<1x3xf32>
      flow.dispatch.tensor.store %6, %arg3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
      return
    }
  }
}

// -----// IR Dump After SymbolDCE (symbol-dce) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private @_params.weight {noinline} = dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>
  util.global private @_params.bias {noinline} = dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>
  flow.executable private @main_dispatch_0 {
    flow.executable.export public @main_dispatch_0_matmul_1x3x4_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !flow.dispatch.tensor<readonly:tensor<1x4xf32>>, %arg1: !flow.dispatch.tensor<readonly:tensor<4x3xf32>>, %arg2: !flow.dispatch.tensor<readonly:tensor<1x3xf32>>, %arg3: !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>) {
        %cst = arith.constant 0.000000e+00 : f32
        %0 = flow.dispatch.tensor.load %arg0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
        %1 = flow.dispatch.tensor.load %arg1, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
        %2 = flow.dispatch.tensor.load %arg2, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
        %3 = tensor.empty() : tensor<1x3xf32>
        %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %5 = linalg.matmul ins(%0, %1 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%4 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %6 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%5, %2 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%3 : tensor<1x3xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %7 = arith.addf %in, %in_0 : f32
          linalg.yield %7 : f32
        } -> tensor<1x3xf32>
        flow.dispatch.tensor.store %6, %arg3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
    %_params.bias = util.global.load @_params.bias : tensor<3xf32>
    %0 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<4xf32>
    %1 = flow.tensor.reshape %0 : tensor<4xf32> -> tensor<1x4xf32>
    %2 = flow.tensor.reshape %_params.bias : tensor<3xf32> -> tensor<1x3xf32>
    %3 = flow.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32(%1, %_params.weight, %2) : (tensor<1x4xf32>, tensor<4x3xf32>, tensor<1x3xf32>) -> tensor<1x3xf32>
    %4 = flow.tensor.reshape %3 : tensor<1x3xf32> -> tensor<3xf32>
    %5 = hal.tensor.export %4 "output 0" : tensor<3xf32> -> !hal.buffer_view
    return %5 : !hal.buffer_view
  }
}


// -----// IR Dump After VerifyInput (iree-stream-verify-input) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private @_params.weight {noinline} = dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>
  util.global private @_params.bias {noinline} = dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>
  flow.executable private @main_dispatch_0 {
    flow.executable.export public @main_dispatch_0_matmul_1x3x4_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !flow.dispatch.tensor<readonly:tensor<1x4xf32>>, %arg1: !flow.dispatch.tensor<readonly:tensor<4x3xf32>>, %arg2: !flow.dispatch.tensor<readonly:tensor<1x3xf32>>, %arg3: !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>) {
        %cst = arith.constant 0.000000e+00 : f32
        %0 = flow.dispatch.tensor.load %arg0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
        %1 = flow.dispatch.tensor.load %arg1, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
        %2 = flow.dispatch.tensor.load %arg2, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
        %3 = tensor.empty() : tensor<1x3xf32>
        %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %5 = linalg.matmul ins(%0, %1 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%4 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %6 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%5, %2 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%3 : tensor<1x3xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %7 = arith.addf %in, %in_0 : f32
          linalg.yield %7 : f32
        } -> tensor<1x3xf32>
        flow.dispatch.tensor.store %6, %arg3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
    %_params.bias = util.global.load @_params.bias : tensor<3xf32>
    %0 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<4xf32>
    %1 = flow.tensor.reshape %0 : tensor<4xf32> -> tensor<1x4xf32>
    %2 = flow.tensor.reshape %_params.bias : tensor<3xf32> -> tensor<1x3xf32>
    %3 = flow.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32(%1, %_params.weight, %2) : (tensor<1x4xf32>, tensor<4x3xf32>, tensor<1x3xf32>) -> tensor<1x3xf32>
    %4 = flow.tensor.reshape %3 : tensor<1x3xf32> -> tensor<3xf32>
    %5 = hal.tensor.export %4 "output 0" : tensor<3xf32> -> !hal.buffer_view
    return %5 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
  %_params.bias = util.global.load @_params.bias : tensor<3xf32>
  %0 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<4xf32>
  %1 = flow.tensor.reshape %0 : tensor<4xf32> -> tensor<1x4xf32>
  %2 = flow.tensor.reshape %_params.bias : tensor<3xf32> -> tensor<1x3xf32>
  %3 = flow.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32(%1, %_params.weight, %2) : (tensor<1x4xf32>, tensor<4x3xf32>, tensor<1x3xf32>) -> tensor<1x3xf32>
  %4 = flow.tensor.reshape %3 : tensor<1x3xf32> -> tensor<3xf32>
  %5 = hal.tensor.export %4 "output 0" : tensor<3xf32> -> !hal.buffer_view
  return %5 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
  %_params.bias = util.global.load @_params.bias : tensor<3xf32>
  %0 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<4xf32>
  %1 = flow.tensor.reshape %0 : tensor<4xf32> -> tensor<1x4xf32>
  %2 = flow.tensor.reshape %_params.bias : tensor<3xf32> -> tensor<1x3xf32>
  %3 = flow.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32(%1, %_params.weight, %2) : (tensor<1x4xf32>, tensor<4x3xf32>, tensor<1x3xf32>) -> tensor<1x3xf32>
  %4 = flow.tensor.reshape %3 : tensor<1x3xf32> -> tensor<3xf32>
  %5 = hal.tensor.export %4 "output 0" : tensor<3xf32> -> !hal.buffer_view
  return %5 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
  %_params.bias = util.global.load @_params.bias : tensor<3xf32>
  %0 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<4xf32>
  %1 = flow.tensor.reshape %0 : tensor<4xf32> -> tensor<1x4xf32>
  %2 = flow.tensor.reshape %_params.bias : tensor<3xf32> -> tensor<1x3xf32>
  %3 = flow.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32(%1, %_params.weight, %2) : (tensor<1x4xf32>, tensor<4x3xf32>, tensor<1x3xf32>) -> tensor<1x3xf32>
  %4 = flow.tensor.reshape %3 : tensor<1x3xf32> -> tensor<3xf32>
  %5 = hal.tensor.export %4 "output 0" : tensor<3xf32> -> !hal.buffer_view
  return %5 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private @_params.weight {noinline} = dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>
  util.global private @_params.bias {noinline} = dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>
  flow.executable private @main_dispatch_0 {
    flow.executable.export public @main_dispatch_0_matmul_1x3x4_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !flow.dispatch.tensor<readonly:tensor<1x4xf32>>, %arg1: !flow.dispatch.tensor<readonly:tensor<4x3xf32>>, %arg2: !flow.dispatch.tensor<readonly:tensor<1x3xf32>>, %arg3: !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>) {
        %cst = arith.constant 0.000000e+00 : f32
        %0 = flow.dispatch.tensor.load %arg0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
        %1 = flow.dispatch.tensor.load %arg1, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
        %2 = flow.dispatch.tensor.load %arg2, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
        %3 = tensor.empty() : tensor<1x3xf32>
        %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %5 = linalg.matmul ins(%0, %1 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%4 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %6 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%5, %2 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%3 : tensor<1x3xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %7 = arith.addf %in, %in_0 : f32
          linalg.yield %7 : f32
        } -> tensor<1x3xf32>
        flow.dispatch.tensor.store %6, %arg3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
    %_params.bias = util.global.load @_params.bias : tensor<3xf32>
    %0 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<4xf32>
    %1 = flow.tensor.reshape %0 : tensor<4xf32> -> tensor<1x4xf32>
    %2 = flow.tensor.reshape %_params.bias : tensor<3xf32> -> tensor<1x3xf32>
    %3 = flow.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32(%1, %_params.weight, %2) : (tensor<1x4xf32>, tensor<4x3xf32>, tensor<1x3xf32>) -> tensor<1x3xf32>
    %4 = flow.tensor.reshape %3 : tensor<1x3xf32> -> tensor<3xf32>
    %5 = hal.tensor.export %4 "output 0" : tensor<3xf32> -> !hal.buffer_view
    return %5 : !hal.buffer_view
  }
}


// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private @_params.weight {noinline} = dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>
  util.global private @_params.bias {noinline} = dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>
  flow.executable private @main_dispatch_0 {
    flow.executable.export public @main_dispatch_0_matmul_1x3x4_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !flow.dispatch.tensor<readonly:tensor<1x4xf32>>, %arg1: !flow.dispatch.tensor<readonly:tensor<4x3xf32>>, %arg2: !flow.dispatch.tensor<readonly:tensor<1x3xf32>>, %arg3: !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>) {
        %cst = arith.constant 0.000000e+00 : f32
        %0 = flow.dispatch.tensor.load %arg0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
        %1 = flow.dispatch.tensor.load %arg1, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
        %2 = flow.dispatch.tensor.load %arg2, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
        %3 = tensor.empty() : tensor<1x3xf32>
        %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %5 = linalg.matmul ins(%0, %1 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%4 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %6 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%5, %2 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%3 : tensor<1x3xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %7 = arith.addf %in, %in_0 : f32
          linalg.yield %7 : f32
        } -> tensor<1x3xf32>
        flow.dispatch.tensor.store %6, %arg3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
    %_params.bias = util.global.load @_params.bias : tensor<3xf32>
    %0 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<4xf32>
    %1 = flow.tensor.reshape %0 : tensor<4xf32> -> tensor<1x4xf32>
    %2 = flow.tensor.reshape %_params.bias : tensor<3xf32> -> tensor<1x3xf32>
    %3 = flow.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32(%1, %_params.weight, %2) : (tensor<1x4xf32>, tensor<4x3xf32>, tensor<1x3xf32>) -> tensor<1x3xf32>
    %4 = flow.tensor.reshape %3 : tensor<1x3xf32> -> tensor<3xf32>
    %5 = hal.tensor.export %4 "output 0" : tensor<3xf32> -> !hal.buffer_view
    return %5 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private @_params.weight {noinline} = dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>
  util.global private @_params.bias {noinline} = dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>
  flow.executable private @main_dispatch_0 {
    flow.executable.export public @main_dispatch_0_matmul_1x3x4_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !flow.dispatch.tensor<readonly:tensor<1x4xf32>>, %arg1: !flow.dispatch.tensor<readonly:tensor<4x3xf32>>, %arg2: !flow.dispatch.tensor<readonly:tensor<1x3xf32>>, %arg3: !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>) {
        %cst = arith.constant 0.000000e+00 : f32
        %0 = flow.dispatch.tensor.load %arg0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
        %1 = flow.dispatch.tensor.load %arg1, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
        %2 = flow.dispatch.tensor.load %arg2, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
        %3 = tensor.empty() : tensor<1x3xf32>
        %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %5 = linalg.matmul ins(%0, %1 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%4 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %6 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%5, %2 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%3 : tensor<1x3xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %7 = arith.addf %in, %in_0 : f32
          linalg.yield %7 : f32
        } -> tensor<1x3xf32>
        flow.dispatch.tensor.store %6, %arg3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
    %_params.bias = util.global.load @_params.bias : tensor<3xf32>
    %0 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<4xf32>
    %1 = flow.tensor.reshape %0 : tensor<4xf32> -> tensor<1x4xf32>
    %2 = flow.tensor.reshape %_params.bias : tensor<3xf32> -> tensor<1x3xf32>
    %3 = flow.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32(%1, %_params.weight, %2) : (tensor<1x4xf32>, tensor<4x3xf32>, tensor<1x3xf32>) -> tensor<1x3xf32>
    %4 = flow.tensor.reshape %3 : tensor<1x3xf32> -> tensor<3xf32>
    %5 = hal.tensor.export %4 "output 0" : tensor<3xf32> -> !hal.buffer_view
    return %5 : !hal.buffer_view
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private @_params.weight {noinline} = dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>
  util.global private @_params.bias {noinline} = dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>
  flow.executable private @main_dispatch_0 {
    flow.executable.export public @main_dispatch_0_matmul_1x3x4_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !flow.dispatch.tensor<readonly:tensor<1x4xf32>>, %arg1: !flow.dispatch.tensor<readonly:tensor<4x3xf32>>, %arg2: !flow.dispatch.tensor<readonly:tensor<1x3xf32>>, %arg3: !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>) {
        %cst = arith.constant 0.000000e+00 : f32
        %0 = flow.dispatch.tensor.load %arg0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
        %1 = flow.dispatch.tensor.load %arg1, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
        %2 = flow.dispatch.tensor.load %arg2, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
        %3 = tensor.empty() : tensor<1x3xf32>
        %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %5 = linalg.matmul ins(%0, %1 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%4 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %6 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%5, %2 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%3 : tensor<1x3xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %7 = arith.addf %in, %in_0 : f32
          linalg.yield %7 : f32
        } -> tensor<1x3xf32>
        flow.dispatch.tensor.store %6, %arg3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
    %_params.bias = util.global.load @_params.bias : tensor<3xf32>
    %0 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<4xf32>
    %1 = flow.tensor.reshape %0 : tensor<4xf32> -> tensor<1x4xf32>
    %2 = flow.tensor.reshape %_params.bias : tensor<3xf32> -> tensor<1x3xf32>
    %3 = flow.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32(%1, %_params.weight, %2) : (tensor<1x4xf32>, tensor<4x3xf32>, tensor<1x3xf32>) -> tensor<1x3xf32>
    %4 = flow.tensor.reshape %3 : tensor<1x3xf32> -> tensor<3xf32>
    %5 = hal.tensor.export %4 "output 0" : tensor<3xf32> -> !hal.buffer_view
    return %5 : !hal.buffer_view
  }
}


// -----// IR Dump After OutlineConstants (iree-util-outline-constants) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private @_params.weight {noinline} = dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>
  util.global private @_params.bias {noinline} = dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>
  flow.executable private @main_dispatch_0 {
    flow.executable.export public @main_dispatch_0_matmul_1x3x4_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !flow.dispatch.tensor<readonly:tensor<1x4xf32>>, %arg1: !flow.dispatch.tensor<readonly:tensor<4x3xf32>>, %arg2: !flow.dispatch.tensor<readonly:tensor<1x3xf32>>, %arg3: !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>) {
        %cst = arith.constant 0.000000e+00 : f32
        %0 = flow.dispatch.tensor.load %arg0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
        %1 = flow.dispatch.tensor.load %arg1, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
        %2 = flow.dispatch.tensor.load %arg2, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
        %3 = tensor.empty() : tensor<1x3xf32>
        %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %5 = linalg.matmul ins(%0, %1 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%4 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %6 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%5, %2 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%3 : tensor<1x3xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %7 = arith.addf %in, %in_0 : f32
          linalg.yield %7 : f32
        } -> tensor<1x3xf32>
        flow.dispatch.tensor.store %6, %arg3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
    %_params.bias = util.global.load @_params.bias : tensor<3xf32>
    %0 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<4xf32>
    %1 = flow.tensor.reshape %0 : tensor<4xf32> -> tensor<1x4xf32>
    %2 = flow.tensor.reshape %_params.bias : tensor<3xf32> -> tensor<1x3xf32>
    %3 = flow.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32(%1, %_params.weight, %2) : (tensor<1x4xf32>, tensor<4x3xf32>, tensor<1x3xf32>) -> tensor<1x3xf32>
    %4 = flow.tensor.reshape %3 : tensor<1x3xf32> -> tensor<3xf32>
    %5 = hal.tensor.export %4 "output 0" : tensor<3xf32> -> !hal.buffer_view
    return %5 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
  %_params.bias = util.global.load @_params.bias : tensor<3xf32>
  %0 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<4xf32>
  %1 = flow.tensor.reshape %0 : tensor<4xf32> -> tensor<1x4xf32>
  %2 = flow.tensor.reshape %_params.bias : tensor<3xf32> -> tensor<1x3xf32>
  %3 = flow.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32(%1, %_params.weight, %2) : (tensor<1x4xf32>, tensor<4x3xf32>, tensor<1x3xf32>) -> tensor<1x3xf32>
  %4 = flow.tensor.reshape %3 : tensor<1x3xf32> -> tensor<3xf32>
  %5 = hal.tensor.export %4 "output 0" : tensor<3xf32> -> !hal.buffer_view
  return %5 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
  %_params.bias = util.global.load @_params.bias : tensor<3xf32>
  %0 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<4xf32>
  %1 = flow.tensor.reshape %0 : tensor<4xf32> -> tensor<1x4xf32>
  %2 = flow.tensor.reshape %_params.bias : tensor<3xf32> -> tensor<1x3xf32>
  %3 = flow.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32(%1, %_params.weight, %2) : (tensor<1x4xf32>, tensor<4x3xf32>, tensor<1x3xf32>) -> tensor<1x3xf32>
  %4 = flow.tensor.reshape %3 : tensor<1x3xf32> -> tensor<3xf32>
  %5 = hal.tensor.export %4 "output 0" : tensor<3xf32> -> !hal.buffer_view
  return %5 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
  %_params.bias = util.global.load @_params.bias : tensor<3xf32>
  %0 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<4xf32>
  %1 = flow.tensor.reshape %0 : tensor<4xf32> -> tensor<1x4xf32>
  %2 = flow.tensor.reshape %_params.bias : tensor<3xf32> -> tensor<1x3xf32>
  %3 = flow.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32(%1, %_params.weight, %2) : (tensor<1x4xf32>, tensor<4x3xf32>, tensor<1x3xf32>) -> tensor<1x3xf32>
  %4 = flow.tensor.reshape %3 : tensor<1x3xf32> -> tensor<3xf32>
  %5 = hal.tensor.export %4 "output 0" : tensor<3xf32> -> !hal.buffer_view
  return %5 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private @_params.weight {noinline} = dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>
  util.global private @_params.bias {noinline} = dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>
  flow.executable private @main_dispatch_0 {
    flow.executable.export public @main_dispatch_0_matmul_1x3x4_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !flow.dispatch.tensor<readonly:tensor<1x4xf32>>, %arg1: !flow.dispatch.tensor<readonly:tensor<4x3xf32>>, %arg2: !flow.dispatch.tensor<readonly:tensor<1x3xf32>>, %arg3: !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>) {
        %cst = arith.constant 0.000000e+00 : f32
        %0 = flow.dispatch.tensor.load %arg0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
        %1 = flow.dispatch.tensor.load %arg1, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
        %2 = flow.dispatch.tensor.load %arg2, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
        %3 = tensor.empty() : tensor<1x3xf32>
        %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %5 = linalg.matmul ins(%0, %1 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%4 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %6 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%5, %2 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%3 : tensor<1x3xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %7 = arith.addf %in, %in_0 : f32
          linalg.yield %7 : f32
        } -> tensor<1x3xf32>
        flow.dispatch.tensor.store %6, %arg3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
    %_params.bias = util.global.load @_params.bias : tensor<3xf32>
    %0 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<4xf32>
    %1 = flow.tensor.reshape %0 : tensor<4xf32> -> tensor<1x4xf32>
    %2 = flow.tensor.reshape %_params.bias : tensor<3xf32> -> tensor<1x3xf32>
    %3 = flow.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32(%1, %_params.weight, %2) : (tensor<1x4xf32>, tensor<4x3xf32>, tensor<1x3xf32>) -> tensor<1x3xf32>
    %4 = flow.tensor.reshape %3 : tensor<1x3xf32> -> tensor<3xf32>
    %5 = hal.tensor.export %4 "output 0" : tensor<3xf32> -> !hal.buffer_view
    return %5 : !hal.buffer_view
  }
}


// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private @_params.weight {noinline} = dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>
  util.global private @_params.bias {noinline} = dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>
  flow.executable private @main_dispatch_0 {
    flow.executable.export public @main_dispatch_0_matmul_1x3x4_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !flow.dispatch.tensor<readonly:tensor<1x4xf32>>, %arg1: !flow.dispatch.tensor<readonly:tensor<4x3xf32>>, %arg2: !flow.dispatch.tensor<readonly:tensor<1x3xf32>>, %arg3: !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>) {
        %cst = arith.constant 0.000000e+00 : f32
        %0 = flow.dispatch.tensor.load %arg0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
        %1 = flow.dispatch.tensor.load %arg1, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
        %2 = flow.dispatch.tensor.load %arg2, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
        %3 = tensor.empty() : tensor<1x3xf32>
        %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %5 = linalg.matmul ins(%0, %1 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%4 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %6 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%5, %2 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%3 : tensor<1x3xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %7 = arith.addf %in, %in_0 : f32
          linalg.yield %7 : f32
        } -> tensor<1x3xf32>
        flow.dispatch.tensor.store %6, %arg3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
    %_params.bias = util.global.load @_params.bias : tensor<3xf32>
    %0 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<4xf32>
    %1 = flow.tensor.reshape %0 : tensor<4xf32> -> tensor<1x4xf32>
    %2 = flow.tensor.reshape %_params.bias : tensor<3xf32> -> tensor<1x3xf32>
    %3 = flow.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32(%1, %_params.weight, %2) : (tensor<1x4xf32>, tensor<4x3xf32>, tensor<1x3xf32>) -> tensor<1x3xf32>
    %4 = flow.tensor.reshape %3 : tensor<1x3xf32> -> tensor<3xf32>
    %5 = hal.tensor.export %4 "output 0" : tensor<3xf32> -> !hal.buffer_view
    return %5 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private @_params.weight {noinline} = dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>
  util.global private @_params.bias {noinline} = dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>
  flow.executable private @main_dispatch_0 {
    flow.executable.export public @main_dispatch_0_matmul_1x3x4_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !flow.dispatch.tensor<readonly:tensor<1x4xf32>>, %arg1: !flow.dispatch.tensor<readonly:tensor<4x3xf32>>, %arg2: !flow.dispatch.tensor<readonly:tensor<1x3xf32>>, %arg3: !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>) {
        %cst = arith.constant 0.000000e+00 : f32
        %0 = flow.dispatch.tensor.load %arg0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
        %1 = flow.dispatch.tensor.load %arg1, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
        %2 = flow.dispatch.tensor.load %arg2, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
        %3 = tensor.empty() : tensor<1x3xf32>
        %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %5 = linalg.matmul ins(%0, %1 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%4 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %6 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%5, %2 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%3 : tensor<1x3xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %7 = arith.addf %in, %in_0 : f32
          linalg.yield %7 : f32
        } -> tensor<1x3xf32>
        flow.dispatch.tensor.store %6, %arg3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
    %_params.bias = util.global.load @_params.bias : tensor<3xf32>
    %0 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<4xf32>
    %1 = flow.tensor.reshape %0 : tensor<4xf32> -> tensor<1x4xf32>
    %2 = flow.tensor.reshape %_params.bias : tensor<3xf32> -> tensor<1x3xf32>
    %3 = flow.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32(%1, %_params.weight, %2) : (tensor<1x4xf32>, tensor<4x3xf32>, tensor<1x3xf32>) -> tensor<1x3xf32>
    %4 = flow.tensor.reshape %3 : tensor<1x3xf32> -> tensor<3xf32>
    %5 = hal.tensor.export %4 "output 0" : tensor<3xf32> -> !hal.buffer_view
    return %5 : !hal.buffer_view
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private @_params.weight {noinline} = dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>
  util.global private @_params.bias {noinline} = dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>
  flow.executable private @main_dispatch_0 {
    flow.executable.export public @main_dispatch_0_matmul_1x3x4_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !flow.dispatch.tensor<readonly:tensor<1x4xf32>>, %arg1: !flow.dispatch.tensor<readonly:tensor<4x3xf32>>, %arg2: !flow.dispatch.tensor<readonly:tensor<1x3xf32>>, %arg3: !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>) {
        %cst = arith.constant 0.000000e+00 : f32
        %0 = flow.dispatch.tensor.load %arg0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
        %1 = flow.dispatch.tensor.load %arg1, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
        %2 = flow.dispatch.tensor.load %arg2, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
        %3 = tensor.empty() : tensor<1x3xf32>
        %4 = linalg.fill ins(%cst : f32) outs(%3 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %5 = linalg.matmul ins(%0, %1 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%4 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %6 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%5, %2 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%3 : tensor<1x3xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %7 = arith.addf %in, %in_0 : f32
          linalg.yield %7 : f32
        } -> tensor<1x3xf32>
        flow.dispatch.tensor.store %6, %arg3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %_params.weight = util.global.load @_params.weight : tensor<4x3xf32>
    %_params.bias = util.global.load @_params.bias : tensor<3xf32>
    %0 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<4xf32>
    %1 = flow.tensor.reshape %0 : tensor<4xf32> -> tensor<1x4xf32>
    %2 = flow.tensor.reshape %_params.bias : tensor<3xf32> -> tensor<1x3xf32>
    %3 = flow.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32(%1, %_params.weight, %2) : (tensor<1x4xf32>, tensor<4x3xf32>, tensor<1x3xf32>) -> tensor<1x3xf32>
    %4 = flow.tensor.reshape %3 : tensor<1x3xf32> -> tensor<3xf32>
    %5 = hal.tensor.export %4 "output 0" : tensor<3xf32> -> !hal.buffer_view
    return %5 : !hal.buffer_view
  }
}


// -----// IR Dump After ConvertToStream (iree-stream-conversion) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private @_params.weight : !stream.resource<constant>
  util.global private @_params.weight__size : index
  util.initializer {
    %cst = stream.tensor.constant : tensor<4x3xf32> in !stream.resource<constant> = dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>
    %0 = stream.resource.size %cst : !stream.resource<constant>
    util.global.store %cst, @_params.weight : !stream.resource<constant>
    util.global.store %0, @_params.weight__size : index
    util.initializer.return
  }
  util.global private @_params.bias : !stream.resource<constant>
  util.global private @_params.bias__size : index
  util.initializer {
    %cst = stream.tensor.constant : tensor<3xf32> in !stream.resource<constant> = dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>
    %0 = stream.resource.size %cst : !stream.resource<constant>
    util.global.store %cst, @_params.bias : !stream.resource<constant>
    util.global.store %0, @_params.bias__size : index
    util.initializer.return
  }
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_1x3x4_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        %cst = arith.constant 0.000000e+00 : f32
        %4 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
        %5 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
        %6 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
        %7 = tensor.empty() : tensor<1x3xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%7 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %9 = linalg.matmul ins(%4, %5 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%8 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %10 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%9, %6 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%7 : tensor<1x3xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %11 = arith.addf %in, %in_0 : f32
          linalg.yield %11 : f32
        } -> tensor<1x3xf32>
        flow.dispatch.tensor.store %10, %3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
    %_params.weight__size = util.global.load @_params.weight__size : index
    %0 = stream.async.transfer %_params.weight : !stream.resource<constant>{%_params.weight__size} -> !stream.resource<*>{%_params.weight__size}
    %_params.bias = util.global.load @_params.bias : !stream.resource<constant>
    %_params.bias__size = util.global.load @_params.bias__size : index
    %1 = stream.async.transfer %_params.bias : !stream.resource<constant>{%_params.bias__size} -> !stream.resource<*>{%_params.bias__size}
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c4 = arith.constant 4 : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = stream.tensor.sizeof tensor<4xf32> : index
    %3 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%2}
    %4 = stream.async.transfer %3 : !stream.resource<external>{%2} -> !stream.resource<*>{%2}
    %5 = stream.tensor.sizeof tensor<1x4xf32> : index
    %6 = stream.tensor.clone %4 : tensor<4xf32> in !stream.resource<*>{%2} -> tensor<1x4xf32> in !stream.resource<*>{%5}
    %7 = stream.tensor.sizeof tensor<1x3xf32> : index
    %8 = stream.tensor.clone %1 : tensor<3xf32> in !stream.resource<*>{%_params.bias__size} -> tensor<1x3xf32> in !stream.resource<*>{%7}
    %c0 = arith.constant 0 : index
    %9 = stream.tensor.sizeof tensor<1x3xf32> : index
    %10 = stream.async.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32(%6[%c0 to %5 for %5], %0[%c0 to %_params.weight__size for %_params.weight__size], %8[%c0 to %7 for %7]) : (!stream.resource<*>{%5}, !stream.resource<*>{%_params.weight__size}, !stream.resource<*>{%7}) -> !stream.resource<*>{%9}
    %11 = stream.tensor.sizeof tensor<3xf32> : index
    %12 = stream.tensor.clone %10 : tensor<1x3xf32> in !stream.resource<*>{%9} -> tensor<3xf32> in !stream.resource<*>{%11}
    %13 = stream.async.transfer %12 : !stream.resource<*>{%11} -> !stream.resource<external>{%11}
    %14 = stream.tensor.export %13 : tensor<3xf32> in !stream.resource<external>{%11} -> !hal.buffer_view
    return %14 : !hal.buffer_view
  }
}


// -----// IR Dump After VerifyLoweringToTensors (iree-stream-verify-lowering-to-tensors) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private @_params.weight : !stream.resource<constant>
  util.global private @_params.weight__size : index
  util.initializer {
    %cst = stream.tensor.constant : tensor<4x3xf32> in !stream.resource<constant> = dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>
    %0 = stream.resource.size %cst : !stream.resource<constant>
    util.global.store %cst, @_params.weight : !stream.resource<constant>
    util.global.store %0, @_params.weight__size : index
    util.initializer.return
  }
  util.global private @_params.bias : !stream.resource<constant>
  util.global private @_params.bias__size : index
  util.initializer {
    %cst = stream.tensor.constant : tensor<3xf32> in !stream.resource<constant> = dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>
    %0 = stream.resource.size %cst : !stream.resource<constant>
    util.global.store %cst, @_params.bias : !stream.resource<constant>
    util.global.store %0, @_params.bias__size : index
    util.initializer.return
  }
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_1x3x4_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        %cst = arith.constant 0.000000e+00 : f32
        %4 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
        %5 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
        %6 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
        %7 = tensor.empty() : tensor<1x3xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%7 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %9 = linalg.matmul ins(%4, %5 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%8 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %10 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%9, %6 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%7 : tensor<1x3xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %11 = arith.addf %in, %in_0 : f32
          linalg.yield %11 : f32
        } -> tensor<1x3xf32>
        flow.dispatch.tensor.store %10, %3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
    %_params.weight__size = util.global.load @_params.weight__size : index
    %0 = stream.async.transfer %_params.weight : !stream.resource<constant>{%_params.weight__size} -> !stream.resource<*>{%_params.weight__size}
    %_params.bias = util.global.load @_params.bias : !stream.resource<constant>
    %_params.bias__size = util.global.load @_params.bias__size : index
    %1 = stream.async.transfer %_params.bias : !stream.resource<constant>{%_params.bias__size} -> !stream.resource<*>{%_params.bias__size}
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c4 = arith.constant 4 : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = stream.tensor.sizeof tensor<4xf32> : index
    %3 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%2}
    %4 = stream.async.transfer %3 : !stream.resource<external>{%2} -> !stream.resource<*>{%2}
    %5 = stream.tensor.sizeof tensor<1x4xf32> : index
    %6 = stream.tensor.clone %4 : tensor<4xf32> in !stream.resource<*>{%2} -> tensor<1x4xf32> in !stream.resource<*>{%5}
    %7 = stream.tensor.sizeof tensor<1x3xf32> : index
    %8 = stream.tensor.clone %1 : tensor<3xf32> in !stream.resource<*>{%_params.bias__size} -> tensor<1x3xf32> in !stream.resource<*>{%7}
    %c0 = arith.constant 0 : index
    %9 = stream.tensor.sizeof tensor<1x3xf32> : index
    %10 = stream.async.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32(%6[%c0 to %5 for %5], %0[%c0 to %_params.weight__size for %_params.weight__size], %8[%c0 to %7 for %7]) : (!stream.resource<*>{%5}, !stream.resource<*>{%_params.weight__size}, !stream.resource<*>{%7}) -> !stream.resource<*>{%9}
    %11 = stream.tensor.sizeof tensor<3xf32> : index
    %12 = stream.tensor.clone %10 : tensor<1x3xf32> in !stream.resource<*>{%9} -> tensor<3xf32> in !stream.resource<*>{%11}
    %13 = stream.async.transfer %12 : !stream.resource<*>{%11} -> !stream.resource<external>{%11}
    %14 = stream.tensor.export %13 : tensor<3xf32> in !stream.resource<external>{%11} -> !hal.buffer_view
    return %14 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.initializer {
  %cst = stream.tensor.constant : tensor<4x3xf32> in !stream.resource<constant> = dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>
  %0 = stream.resource.size %cst : !stream.resource<constant>
  util.global.store %cst, @_params.weight : !stream.resource<constant>
  util.global.store %0, @_params.weight__size : index
  util.initializer.return
}

// -----// IR Dump After CSE (cse) //----- //
util.initializer {
  %cst = stream.tensor.constant : tensor<4x3xf32> in !stream.resource<constant> = dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>
  %0 = stream.resource.size %cst : !stream.resource<constant>
  util.global.store %cst, @_params.weight : !stream.resource<constant>
  util.global.store %0, @_params.weight__size : index
  util.initializer.return
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.initializer {
  %cst = stream.tensor.constant : tensor<4x3xf32> in !stream.resource<constant> = dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>
  %0 = stream.resource.size %cst : !stream.resource<constant>
  util.global.store %cst, @_params.weight : !stream.resource<constant>
  util.global.store %0, @_params.weight__size : index
  util.initializer.return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.initializer {
  %cst = stream.tensor.constant : tensor<3xf32> in !stream.resource<constant> = dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>
  %0 = stream.resource.size %cst : !stream.resource<constant>
  util.global.store %cst, @_params.bias : !stream.resource<constant>
  util.global.store %0, @_params.bias__size : index
  util.initializer.return
}

// -----// IR Dump After CSE (cse) //----- //
util.initializer {
  %cst = stream.tensor.constant : tensor<3xf32> in !stream.resource<constant> = dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>
  %0 = stream.resource.size %cst : !stream.resource<constant>
  util.global.store %cst, @_params.bias : !stream.resource<constant>
  util.global.store %0, @_params.bias__size : index
  util.initializer.return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c0 = arith.constant 0 : index
  %c4 = arith.constant 4 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
  %_params.weight__size = util.global.load @_params.weight__size : index
  %0 = stream.async.transfer %_params.weight : !stream.resource<constant>{%_params.weight__size} -> !stream.resource<*>{%_params.weight__size}
  %_params.bias = util.global.load @_params.bias : !stream.resource<constant>
  %_params.bias__size = util.global.load @_params.bias__size : index
  %1 = stream.async.transfer %_params.bias : !stream.resource<constant>{%_params.bias__size} -> !stream.resource<*>{%_params.bias__size}
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = stream.tensor.sizeof tensor<4xf32> : index
  %3 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%2}
  %4 = stream.async.transfer %3 : !stream.resource<external>{%2} -> !stream.resource<*>{%2}
  %5 = stream.tensor.sizeof tensor<1x4xf32> : index
  %6 = stream.tensor.sizeof tensor<1x3xf32> : index
  %7 = stream.tensor.sizeof tensor<1x3xf32> : index
  %8 = stream.async.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32(%4[%c0 to %5 for %5], %0[%c0 to %_params.weight__size for %_params.weight__size], %1[%c0 to %6 for %6]) : (!stream.resource<*>{%5}, !stream.resource<*>{%_params.weight__size}, !stream.resource<*>{%6}) -> !stream.resource<*>{%7}
  %9 = stream.tensor.sizeof tensor<3xf32> : index
  %10 = stream.async.transfer %8 : !stream.resource<*>{%9} -> !stream.resource<external>{%9}
  %11 = stream.tensor.export %10 : tensor<3xf32> in !stream.resource<external>{%9} -> !hal.buffer_view
  return %11 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.initializer {
  %cst = stream.tensor.constant : tensor<3xf32> in !stream.resource<constant> = dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>
  %0 = stream.resource.size %cst : !stream.resource<constant>
  util.global.store %cst, @_params.bias : !stream.resource<constant>
  util.global.store %0, @_params.bias__size : index
  util.initializer.return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c0 = arith.constant 0 : index
  %c4 = arith.constant 4 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
  %_params.weight__size = util.global.load @_params.weight__size : index
  %0 = stream.async.transfer %_params.weight : !stream.resource<constant>{%_params.weight__size} -> !stream.resource<*>{%_params.weight__size}
  %_params.bias = util.global.load @_params.bias : !stream.resource<constant>
  %_params.bias__size = util.global.load @_params.bias__size : index
  %1 = stream.async.transfer %_params.bias : !stream.resource<constant>{%_params.bias__size} -> !stream.resource<*>{%_params.bias__size}
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = stream.tensor.sizeof tensor<4xf32> : index
  %3 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%2}
  %4 = stream.async.transfer %3 : !stream.resource<external>{%2} -> !stream.resource<*>{%2}
  %5 = stream.tensor.sizeof tensor<1x4xf32> : index
  %6 = stream.tensor.sizeof tensor<1x3xf32> : index
  %7 = stream.async.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32(%4[%c0 to %5 for %5], %0[%c0 to %_params.weight__size for %_params.weight__size], %1[%c0 to %6 for %6]) : (!stream.resource<*>{%5}, !stream.resource<*>{%_params.weight__size}, !stream.resource<*>{%6}) -> !stream.resource<*>{%6}
  %8 = stream.tensor.sizeof tensor<3xf32> : index
  %9 = stream.async.transfer %7 : !stream.resource<*>{%8} -> !stream.resource<external>{%8}
  %10 = stream.tensor.export %9 : tensor<3xf32> in !stream.resource<external>{%8} -> !hal.buffer_view
  return %10 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
  %_params.weight__size = util.global.load @_params.weight__size : index
  %_params.bias = util.global.load @_params.bias : !stream.resource<constant>
  %_params.bias__size = util.global.load @_params.bias__size : index
  %c0 = arith.constant 0 : index
  %c4 = arith.constant 4 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %0 = stream.async.transfer %_params.weight : !stream.resource<constant>{%_params.weight__size} -> !stream.resource<*>{%_params.weight__size}
  %1 = stream.async.transfer %_params.bias : !stream.resource<constant>{%_params.bias__size} -> !stream.resource<*>{%_params.bias__size}
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = stream.tensor.sizeof tensor<4xf32> : index
  %3 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%2}
  %4 = stream.async.transfer %3 : !stream.resource<external>{%2} -> !stream.resource<*>{%2}
  %5 = stream.tensor.sizeof tensor<1x4xf32> : index
  %6 = stream.tensor.sizeof tensor<1x3xf32> : index
  %7 = stream.async.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32(%4[%c0 to %5 for %5], %0[%c0 to %_params.weight__size for %_params.weight__size], %1[%c0 to %6 for %6]) : (!stream.resource<*>{%5}, !stream.resource<*>{%_params.weight__size}, !stream.resource<*>{%6}) -> !stream.resource<*>{%6}
  %8 = stream.tensor.sizeof tensor<3xf32> : index
  %9 = stream.async.transfer %7 : !stream.resource<*>{%8} -> !stream.resource<external>{%8}
  %10 = stream.tensor.export %9 : tensor<3xf32> in !stream.resource<external>{%8} -> !hal.buffer_view
  return %10 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private @_params.weight : !stream.resource<constant>
  util.global private @_params.weight__size : index
  util.initializer {
    %cst = stream.tensor.constant : tensor<4x3xf32> in !stream.resource<constant> = dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>
    %0 = stream.resource.size %cst : !stream.resource<constant>
    util.global.store %cst, @_params.weight : !stream.resource<constant>
    util.global.store %0, @_params.weight__size : index
    util.initializer.return
  }
  util.global private @_params.bias : !stream.resource<constant>
  util.global private @_params.bias__size : index
  util.initializer {
    %cst = stream.tensor.constant : tensor<3xf32> in !stream.resource<constant> = dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>
    %0 = stream.resource.size %cst : !stream.resource<constant>
    util.global.store %cst, @_params.bias : !stream.resource<constant>
    util.global.store %0, @_params.bias__size : index
    util.initializer.return
  }
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_1x3x4_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        %4 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
        %5 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
        %6 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
        %7 = tensor.empty() : tensor<1x3xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%7 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %9 = linalg.matmul ins(%4, %5 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%8 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %10 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%9, %6 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%7 : tensor<1x3xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %11 = arith.addf %in, %in_0 : f32
          linalg.yield %11 : f32
        } -> tensor<1x3xf32>
        flow.dispatch.tensor.store %10, %3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
    %_params.weight__size = util.global.load @_params.weight__size : index
    %_params.bias = util.global.load @_params.bias : !stream.resource<constant>
    %_params.bias__size = util.global.load @_params.bias__size : index
    %0 = stream.async.transfer %_params.weight : !stream.resource<constant>{%_params.weight__size} -> !stream.resource<*>{%_params.weight__size}
    %1 = stream.async.transfer %_params.bias : !stream.resource<constant>{%_params.bias__size} -> !stream.resource<*>{%_params.bias__size}
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = stream.tensor.sizeof tensor<4xf32> : index
    %3 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%2}
    %4 = stream.async.transfer %3 : !stream.resource<external>{%2} -> !stream.resource<*>{%2}
    %5 = stream.tensor.sizeof tensor<1x4xf32> : index
    %6 = stream.tensor.sizeof tensor<1x3xf32> : index
    %7 = stream.async.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32(%4[%c0 to %5 for %5], %0[%c0 to %_params.weight__size for %_params.weight__size], %1[%c0 to %6 for %6]) : (!stream.resource<*>{%5}, !stream.resource<*>{%_params.weight__size}, !stream.resource<*>{%6}) -> !stream.resource<*>{%6}
    %8 = stream.tensor.sizeof tensor<3xf32> : index
    %9 = stream.async.transfer %7 : !stream.resource<*>{%8} -> !stream.resource<external>{%8}
    %10 = stream.tensor.export %9 : tensor<3xf32> in !stream.resource<external>{%8} -> !hal.buffer_view
    return %10 : !hal.buffer_view
  }
}


// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private @_params.weight : !stream.resource<constant>
  util.global private @_params.weight__size : index
  util.initializer {
    %cst = stream.tensor.constant : tensor<4x3xf32> in !stream.resource<constant> = dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>
    %0 = stream.resource.size %cst : !stream.resource<constant>
    util.global.store %cst, @_params.weight : !stream.resource<constant>
    util.global.store %0, @_params.weight__size : index
    util.initializer.return
  }
  util.global private @_params.bias : !stream.resource<constant>
  util.global private @_params.bias__size : index
  util.initializer {
    %cst = stream.tensor.constant : tensor<3xf32> in !stream.resource<constant> = dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>
    %0 = stream.resource.size %cst : !stream.resource<constant>
    util.global.store %cst, @_params.bias : !stream.resource<constant>
    util.global.store %0, @_params.bias__size : index
    util.initializer.return
  }
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_1x3x4_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        %4 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
        %5 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
        %6 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
        %7 = tensor.empty() : tensor<1x3xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%7 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %9 = linalg.matmul ins(%4, %5 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%8 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %10 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%9, %6 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%7 : tensor<1x3xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %11 = arith.addf %in, %in_0 : f32
          linalg.yield %11 : f32
        } -> tensor<1x3xf32>
        flow.dispatch.tensor.store %10, %3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
    %_params.weight__size = util.global.load @_params.weight__size : index
    %_params.bias = util.global.load @_params.bias : !stream.resource<constant>
    %_params.bias__size = util.global.load @_params.bias__size : index
    %0 = stream.async.transfer %_params.weight : !stream.resource<constant>{%_params.weight__size} -> !stream.resource<*>{%_params.weight__size}
    %1 = stream.async.transfer %_params.bias : !stream.resource<constant>{%_params.bias__size} -> !stream.resource<*>{%_params.bias__size}
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = stream.tensor.sizeof tensor<4xf32> : index
    %3 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%2}
    %4 = stream.async.transfer %3 : !stream.resource<external>{%2} -> !stream.resource<*>{%2}
    %5 = stream.tensor.sizeof tensor<1x4xf32> : index
    %6 = stream.tensor.sizeof tensor<1x3xf32> : index
    %7 = stream.async.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32(%4[%c0 to %5 for %5], %0[%c0 to %_params.weight__size for %_params.weight__size], %1[%c0 to %6 for %6]) : (!stream.resource<*>{%5}, !stream.resource<*>{%_params.weight__size}, !stream.resource<*>{%6}) -> !stream.resource<*>{%6}
    %8 = stream.tensor.sizeof tensor<3xf32> : index
    %9 = stream.async.transfer %7 : !stream.resource<*>{%8} -> !stream.resource<external>{%8}
    %10 = stream.tensor.export %9 : tensor<3xf32> in !stream.resource<external>{%8} -> !hal.buffer_view
    return %10 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private @_params.weight : !stream.resource<constant>
  util.global private @_params.weight__size : index
  util.initializer {
    %cst = stream.tensor.constant : tensor<4x3xf32> in !stream.resource<constant> = dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>
    %0 = stream.resource.size %cst : !stream.resource<constant>
    util.global.store %cst, @_params.weight : !stream.resource<constant>
    util.global.store %0, @_params.weight__size : index
    util.initializer.return
  }
  util.global private @_params.bias : !stream.resource<constant>
  util.global private @_params.bias__size : index
  util.initializer {
    %cst = stream.tensor.constant : tensor<3xf32> in !stream.resource<constant> = dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>
    %0 = stream.resource.size %cst : !stream.resource<constant>
    util.global.store %cst, @_params.bias : !stream.resource<constant>
    util.global.store %0, @_params.bias__size : index
    util.initializer.return
  }
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_1x3x4_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        %4 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
        %5 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
        %6 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
        %7 = tensor.empty() : tensor<1x3xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%7 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %9 = linalg.matmul ins(%4, %5 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%8 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %10 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%9, %6 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%7 : tensor<1x3xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %11 = arith.addf %in, %in_0 : f32
          linalg.yield %11 : f32
        } -> tensor<1x3xf32>
        flow.dispatch.tensor.store %10, %3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
    %_params.weight__size = util.global.load @_params.weight__size : index
    %_params.bias = util.global.load @_params.bias : !stream.resource<constant>
    %_params.bias__size = util.global.load @_params.bias__size : index
    %0 = stream.async.transfer %_params.weight : !stream.resource<constant>{%_params.weight__size} -> !stream.resource<*>{%_params.weight__size}
    %1 = stream.async.transfer %_params.bias : !stream.resource<constant>{%_params.bias__size} -> !stream.resource<*>{%_params.bias__size}
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = stream.tensor.sizeof tensor<4xf32> : index
    %3 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%2}
    %4 = stream.async.transfer %3 : !stream.resource<external>{%2} -> !stream.resource<*>{%2}
    %5 = stream.tensor.sizeof tensor<1x4xf32> : index
    %6 = stream.tensor.sizeof tensor<1x3xf32> : index
    %7 = stream.async.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32(%4[%c0 to %5 for %5], %0[%c0 to %_params.weight__size for %_params.weight__size], %1[%c0 to %6 for %6]) : (!stream.resource<*>{%5}, !stream.resource<*>{%_params.weight__size}, !stream.resource<*>{%6}) -> !stream.resource<*>{%6}
    %8 = stream.tensor.sizeof tensor<3xf32> : index
    %9 = stream.async.transfer %7 : !stream.resource<*>{%8} -> !stream.resource<external>{%8}
    %10 = stream.tensor.export %9 : tensor<3xf32> in !stream.resource<external>{%8} -> !hal.buffer_view
    return %10 : !hal.buffer_view
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private @_params.weight : !stream.resource<constant>
  util.global private @_params.weight__size : index
  util.initializer {
    %cst = stream.tensor.constant : tensor<4x3xf32> in !stream.resource<constant> = dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>
    %0 = stream.resource.size %cst : !stream.resource<constant>
    util.global.store %cst, @_params.weight : !stream.resource<constant>
    util.global.store %0, @_params.weight__size : index
    util.initializer.return
  }
  util.global private @_params.bias : !stream.resource<constant>
  util.global private @_params.bias__size : index
  util.initializer {
    %cst = stream.tensor.constant : tensor<3xf32> in !stream.resource<constant> = dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>
    %0 = stream.resource.size %cst : !stream.resource<constant>
    util.global.store %cst, @_params.bias : !stream.resource<constant>
    util.global.store %0, @_params.bias__size : index
    util.initializer.return
  }
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_1x3x4_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        %4 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
        %5 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
        %6 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
        %7 = tensor.empty() : tensor<1x3xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%7 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %9 = linalg.matmul ins(%4, %5 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%8 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %10 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%9, %6 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%7 : tensor<1x3xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %11 = arith.addf %in, %in_0 : f32
          linalg.yield %11 : f32
        } -> tensor<1x3xf32>
        flow.dispatch.tensor.store %10, %3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
    %_params.weight__size = util.global.load @_params.weight__size : index
    %_params.bias = util.global.load @_params.bias : !stream.resource<constant>
    %_params.bias__size = util.global.load @_params.bias__size : index
    %0 = stream.async.transfer %_params.weight : !stream.resource<constant>{%_params.weight__size} -> !stream.resource<*>{%_params.weight__size}
    %1 = stream.async.transfer %_params.bias : !stream.resource<constant>{%_params.bias__size} -> !stream.resource<*>{%_params.bias__size}
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = stream.tensor.sizeof tensor<4xf32> : index
    %3 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%2}
    %4 = stream.async.transfer %3 : !stream.resource<external>{%2} -> !stream.resource<*>{%2}
    %5 = stream.tensor.sizeof tensor<1x4xf32> : index
    %6 = stream.tensor.sizeof tensor<1x3xf32> : index
    %7 = stream.async.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32(%4[%c0 to %5 for %5], %0[%c0 to %_params.weight__size for %_params.weight__size], %1[%c0 to %6 for %6]) : (!stream.resource<*>{%5}, !stream.resource<*>{%_params.weight__size}, !stream.resource<*>{%6}) -> !stream.resource<*>{%6}
    %8 = stream.tensor.sizeof tensor<3xf32> : index
    %9 = stream.async.transfer %7 : !stream.resource<*>{%8} -> !stream.resource<external>{%8}
    %10 = stream.tensor.export %9 : tensor<3xf32> in !stream.resource<external>{%8} -> !hal.buffer_view
    return %10 : !hal.buffer_view
  }
}


// -----// IR Dump After CombineInitializers (iree-util-combine-initializers) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private @_params.weight : !stream.resource<constant>
  util.global private @_params.weight__size : index
  util.global private @_params.bias : !stream.resource<constant>
  util.global private @_params.bias__size : index
  util.initializer {
    %cst = stream.tensor.constant : tensor<4x3xf32> in !stream.resource<constant> = dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>
    %0 = stream.resource.size %cst : !stream.resource<constant>
    util.global.store %cst, @_params.weight : !stream.resource<constant>
    util.global.store %0, @_params.weight__size : index
    %cst_0 = stream.tensor.constant : tensor<3xf32> in !stream.resource<constant> = dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>
    %1 = stream.resource.size %cst_0 : !stream.resource<constant>
    util.global.store %cst_0, @_params.bias : !stream.resource<constant>
    util.global.store %1, @_params.bias__size : index
    util.initializer.return
  }
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_1x3x4_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        %4 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
        %5 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
        %6 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
        %7 = tensor.empty() : tensor<1x3xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%7 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %9 = linalg.matmul ins(%4, %5 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%8 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %10 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%9, %6 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%7 : tensor<1x3xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %11 = arith.addf %in, %in_0 : f32
          linalg.yield %11 : f32
        } -> tensor<1x3xf32>
        flow.dispatch.tensor.store %10, %3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
    %_params.weight__size = util.global.load @_params.weight__size : index
    %_params.bias = util.global.load @_params.bias : !stream.resource<constant>
    %_params.bias__size = util.global.load @_params.bias__size : index
    %0 = stream.async.transfer %_params.weight : !stream.resource<constant>{%_params.weight__size} -> !stream.resource<*>{%_params.weight__size}
    %1 = stream.async.transfer %_params.bias : !stream.resource<constant>{%_params.bias__size} -> !stream.resource<*>{%_params.bias__size}
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = stream.tensor.sizeof tensor<4xf32> : index
    %3 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%2}
    %4 = stream.async.transfer %3 : !stream.resource<external>{%2} -> !stream.resource<*>{%2}
    %5 = stream.tensor.sizeof tensor<1x4xf32> : index
    %6 = stream.tensor.sizeof tensor<1x3xf32> : index
    %7 = stream.async.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32(%4[%c0 to %5 for %5], %0[%c0 to %_params.weight__size for %_params.weight__size], %1[%c0 to %6 for %6]) : (!stream.resource<*>{%5}, !stream.resource<*>{%_params.weight__size}, !stream.resource<*>{%6}) -> !stream.resource<*>{%6}
    %8 = stream.tensor.sizeof tensor<3xf32> : index
    %9 = stream.async.transfer %7 : !stream.resource<*>{%8} -> !stream.resource<external>{%8}
    %10 = stream.tensor.export %9 : tensor<3xf32> in !stream.resource<external>{%8} -> !hal.buffer_view
    return %10 : !hal.buffer_view
  }
}


// -----// IR Dump After EncodeHostTensors (iree-stream-encode-host-tensors) //----- //
util.initializer {
  %c48 = arith.constant 48 : index
  %c12 = arith.constant 12 : index
  %cst = stream.async.constant : !stream.resource<constant>{%c48} = dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>
  util.global.store %cst, @_params.weight : !stream.resource<constant>
  util.global.store %c48, @_params.weight__size : index
  %cst_0 = stream.async.constant : !stream.resource<constant>{%c12} = dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>
  util.global.store %cst_0, @_params.bias : !stream.resource<constant>
  util.global.store %c12, @_params.bias__size : index
  util.initializer.return
}

// -----// IR Dump After EncodeHostTensors (iree-stream-encode-host-tensors) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c16 = arith.constant 16 : index
  %c12 = arith.constant 12 : index
  %c553648160_i32 = arith.constant 553648160 : i32
  %c1_i32 = arith.constant 1 : i32
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
  %_params.weight__size = util.global.load @_params.weight__size : index
  %_params.bias = util.global.load @_params.bias : !stream.resource<constant>
  %_params.bias__size = util.global.load @_params.bias__size : index
  %0 = stream.async.transfer %_params.weight : !stream.resource<constant>{%_params.weight__size} -> !stream.resource<*>{%_params.weight__size}
  %1 = stream.async.transfer %_params.bias : !stream.resource<constant>{%_params.bias__size} -> !stream.resource<*>{%_params.bias__size}
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
  %3 = stream.async.transfer %2 : !stream.resource<external>{%c16} -> !stream.resource<*>{%c16}
  %4 = stream.async.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32(%3[%c0 to %c16 for %c16], %0[%c0 to %_params.weight__size for %_params.weight__size], %1[%c0 to %c12 for %c12]) : (!stream.resource<*>{%c16}, !stream.resource<*>{%_params.weight__size}, !stream.resource<*>{%c12}) -> !stream.resource<*>{%c12}
  %5 = stream.async.transfer %4 : !stream.resource<*>{%c12} -> !stream.resource<external>{%c12}
  %6 = stream.tensor.export %5 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
  return %6 : !hal.buffer_view
}

// -----// IR Dump After EncodeDeviceTensors (iree-stream-encode-device-tensors) //----- //
stream.executable private @main_dispatch_0 {
  stream.executable.export public @main_dispatch_0_matmul_1x3x4_f32 workgroups() -> (index, index, index) {
    %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
    stream.return %x, %y, %z : index, index, index
  }
  builtin.module {
    func.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
      %cst = arith.constant 0.000000e+00 : f32
      %c0 = arith.constant 0 : index
      %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
      %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
      %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
      %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
      %4 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
      %5 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
      %6 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
      %7 = tensor.empty() : tensor<1x3xf32>
      %8 = linalg.fill ins(%cst : f32) outs(%7 : tensor<1x3xf32>) -> tensor<1x3xf32>
      %9 = linalg.matmul ins(%4, %5 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%8 : tensor<1x3xf32>) -> tensor<1x3xf32>
      %10 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%9, %6 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%7 : tensor<1x3xf32>) {
      ^bb0(%in: f32, %in_0: f32, %out: f32):
        %11 = arith.addf %in, %in_0 : f32
        linalg.yield %11 : f32
      } -> tensor<1x3xf32>
      flow.dispatch.tensor.store %10, %3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
      return
    }
  }
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.initializer {
  %c48 = arith.constant 48 : index
  %c12 = arith.constant 12 : index
  %cst = stream.async.constant : !stream.resource<constant>{%c48} = dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>
  util.global.store %cst, @_params.weight : !stream.resource<constant>
  util.global.store %c48, @_params.weight__size : index
  %cst_0 = stream.async.constant : !stream.resource<constant>{%c12} = dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>
  util.global.store %cst_0, @_params.bias : !stream.resource<constant>
  util.global.store %c12, @_params.bias__size : index
  util.initializer.return
}

// -----// IR Dump After CSE (cse) //----- //
util.initializer {
  %c48 = arith.constant 48 : index
  %c12 = arith.constant 12 : index
  %cst = stream.async.constant : !stream.resource<constant>{%c48} = dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>
  util.global.store %cst, @_params.weight : !stream.resource<constant>
  util.global.store %c48, @_params.weight__size : index
  %cst_0 = stream.async.constant : !stream.resource<constant>{%c12} = dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>
  util.global.store %cst_0, @_params.bias : !stream.resource<constant>
  util.global.store %c12, @_params.bias__size : index
  util.initializer.return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c16 = arith.constant 16 : index
  %c12 = arith.constant 12 : index
  %c553648160_i32 = arith.constant 553648160 : i32
  %c1_i32 = arith.constant 1 : i32
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
  %_params.weight__size = util.global.load @_params.weight__size : index
  %_params.bias = util.global.load @_params.bias : !stream.resource<constant>
  %_params.bias__size = util.global.load @_params.bias__size : index
  %0 = stream.async.transfer %_params.weight : !stream.resource<constant>{%_params.weight__size} -> !stream.resource<*>{%_params.weight__size}
  %1 = stream.async.transfer %_params.bias : !stream.resource<constant>{%_params.bias__size} -> !stream.resource<*>{%_params.bias__size}
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
  %3 = stream.async.transfer %2 : !stream.resource<external>{%c16} -> !stream.resource<*>{%c16}
  %4 = stream.async.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32(%3[%c0 to %c16 for %c16], %0[%c0 to %_params.weight__size for %_params.weight__size], %1[%c0 to %c12 for %c12]) : (!stream.resource<*>{%c16}, !stream.resource<*>{%_params.weight__size}, !stream.resource<*>{%c12}) -> !stream.resource<*>{%c12}
  %5 = stream.async.transfer %4 : !stream.resource<*>{%c12} -> !stream.resource<external>{%c12}
  %6 = stream.tensor.export %5 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
  return %6 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.initializer {
  %c48 = arith.constant 48 : index
  %c12 = arith.constant 12 : index
  %cst = stream.async.constant : !stream.resource<constant>{%c48} = dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>
  %cst_0 = stream.async.constant : !stream.resource<constant>{%c12} = dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>
  util.global.store %cst_0, @_params.bias : !stream.resource<constant>
  util.global.store %c12, @_params.bias__size : index
  util.global.store %cst, @_params.weight : !stream.resource<constant>
  util.global.store %c48, @_params.weight__size : index
  util.initializer.return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c16 = arith.constant 16 : index
  %c12 = arith.constant 12 : index
  %c553648160_i32 = arith.constant 553648160 : i32
  %c1_i32 = arith.constant 1 : i32
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
  %_params.weight__size = util.global.load @_params.weight__size : index
  %_params.bias = util.global.load @_params.bias : !stream.resource<constant>
  %_params.bias__size = util.global.load @_params.bias__size : index
  %0 = stream.async.transfer %_params.weight : !stream.resource<constant>{%_params.weight__size} -> !stream.resource<*>{%_params.weight__size}
  %1 = stream.async.transfer %_params.bias : !stream.resource<constant>{%_params.bias__size} -> !stream.resource<*>{%_params.bias__size}
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
  %3 = stream.async.transfer %2 : !stream.resource<external>{%c16} -> !stream.resource<*>{%c16}
  %4 = stream.async.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32(%3[%c0 to %c16 for %c16], %0[%c0 to %_params.weight__size for %_params.weight__size], %1[%c0 to %c12 for %c12]) : (!stream.resource<*>{%c16}, !stream.resource<*>{%_params.weight__size}, !stream.resource<*>{%c12}) -> !stream.resource<*>{%c12}
  %5 = stream.async.transfer %4 : !stream.resource<*>{%c12} -> !stream.resource<external>{%c12}
  %6 = stream.tensor.export %5 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
  return %6 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
  %_params.weight__size = util.global.load @_params.weight__size : index
  %_params.bias = util.global.load @_params.bias : !stream.resource<constant>
  %_params.bias__size = util.global.load @_params.bias__size : index
  %c16 = arith.constant 16 : index
  %c12 = arith.constant 12 : index
  %c553648160_i32 = arith.constant 553648160 : i32
  %c1_i32 = arith.constant 1 : i32
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %0 = stream.async.transfer %_params.weight : !stream.resource<constant>{%_params.weight__size} -> !stream.resource<*>{%_params.weight__size}
  %1 = stream.async.transfer %_params.bias : !stream.resource<constant>{%_params.bias__size} -> !stream.resource<*>{%_params.bias__size}
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
  %3 = stream.async.transfer %2 : !stream.resource<external>{%c16} -> !stream.resource<*>{%c16}
  %4 = stream.async.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32(%3[%c0 to %c16 for %c16], %0[%c0 to %_params.weight__size for %_params.weight__size], %1[%c0 to %c12 for %c12]) : (!stream.resource<*>{%c16}, !stream.resource<*>{%_params.weight__size}, !stream.resource<*>{%c12}) -> !stream.resource<*>{%c12}
  %5 = stream.async.transfer %4 : !stream.resource<*>{%c12} -> !stream.resource<external>{%c12}
  %6 = stream.tensor.export %5 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
  return %6 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private @_params.weight : !stream.resource<constant>
  util.global private @_params.weight__size = 48 : index
  util.global private @_params.bias : !stream.resource<constant>
  util.global private @_params.bias__size = 12 : index
  util.initializer {
    %c48 = arith.constant 48 : index
    %c12 = arith.constant 12 : index
    %cst = stream.async.constant : !stream.resource<constant>{%c48} = dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>
    %cst_0 = stream.async.constant : !stream.resource<constant>{%c12} = dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>
    util.global.store %cst_0, @_params.bias : !stream.resource<constant>
    util.global.store %cst, @_params.weight : !stream.resource<constant>
    util.initializer.return
  }
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_1x3x4_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        %4 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
        %5 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
        %6 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
        %7 = tensor.empty() : tensor<1x3xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%7 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %9 = linalg.matmul ins(%4, %5 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%8 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %10 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%9, %6 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%7 : tensor<1x3xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %11 = arith.addf %in, %in_0 : f32
          linalg.yield %11 : f32
        } -> tensor<1x3xf32>
        flow.dispatch.tensor.store %10, %3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %c12 = arith.constant 12 : index
    %c16 = arith.constant 16 : index
    %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
    %_params.weight__size = util.global.load @_params.weight__size : index
    %_params.bias = util.global.load @_params.bias : !stream.resource<constant>
    %_params.bias__size = util.global.load @_params.bias__size : index
    %0 = stream.async.transfer %_params.weight : !stream.resource<constant>{%_params.weight__size} -> !stream.resource<*>{%_params.weight__size}
    %1 = stream.async.transfer %_params.bias : !stream.resource<constant>{%_params.bias__size} -> !stream.resource<*>{%_params.bias__size}
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
    %3 = stream.async.transfer %2 : !stream.resource<external>{%c16} -> !stream.resource<*>{%c16}
    %4 = stream.async.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32(%3[%c0 to %c16 for %c16], %0[%c0 to %_params.weight__size for %_params.weight__size], %1[%c0 to %c12 for %c12]) : (!stream.resource<*>{%c16}, !stream.resource<*>{%_params.weight__size}, !stream.resource<*>{%c12}) -> !stream.resource<*>{%c12}
    %5 = stream.async.transfer %4 : !stream.resource<*>{%c12} -> !stream.resource<external>{%c12}
    %6 = stream.tensor.export %5 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
    return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private @_params.weight : !stream.resource<constant>
  util.global private @_params.bias : !stream.resource<constant>
  util.initializer {
    %c48 = arith.constant 48 : index
    %c12 = arith.constant 12 : index
    %cst = stream.async.constant : !stream.resource<constant>{%c48} = dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>
    %cst_0 = stream.async.constant : !stream.resource<constant>{%c12} = dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>
    util.global.store %cst_0, @_params.bias : !stream.resource<constant>
    util.global.store %cst, @_params.weight : !stream.resource<constant>
    util.initializer.return
  }
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_1x3x4_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        %4 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
        %5 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
        %6 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
        %7 = tensor.empty() : tensor<1x3xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%7 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %9 = linalg.matmul ins(%4, %5 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%8 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %10 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%9, %6 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%7 : tensor<1x3xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %11 = arith.addf %in, %in_0 : f32
          linalg.yield %11 : f32
        } -> tensor<1x3xf32>
        flow.dispatch.tensor.store %10, %3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c48 = arith.constant 48 : index
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %c12 = arith.constant 12 : index
    %c16 = arith.constant 16 : index
    %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
    %_params.bias = util.global.load @_params.bias : !stream.resource<constant>
    %0 = stream.async.transfer %_params.weight : !stream.resource<constant>{%c48} -> !stream.resource<*>{%c48}
    %1 = stream.async.transfer %_params.bias : !stream.resource<constant>{%c12} -> !stream.resource<*>{%c12}
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
    %3 = stream.async.transfer %2 : !stream.resource<external>{%c16} -> !stream.resource<*>{%c16}
    %4 = stream.async.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32(%3[%c0 to %c16 for %c16], %0[%c0 to %c48 for %c48], %1[%c0 to %c12 for %c12]) : (!stream.resource<*>{%c16}, !stream.resource<*>{%c48}, !stream.resource<*>{%c12}) -> !stream.resource<*>{%c12}
    %5 = stream.async.transfer %4 : !stream.resource<*>{%c12} -> !stream.resource<external>{%c12}
    %6 = stream.tensor.export %5 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
    return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private @_params.weight : !stream.resource<constant>
  util.global private @_params.bias : !stream.resource<constant>
  util.initializer {
    %c48 = arith.constant 48 : index
    %c12 = arith.constant 12 : index
    %cst = stream.async.constant : !stream.resource<constant>{%c48} = dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>
    %cst_0 = stream.async.constant : !stream.resource<constant>{%c12} = dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>
    util.global.store %cst_0, @_params.bias : !stream.resource<constant>
    util.global.store %cst, @_params.weight : !stream.resource<constant>
    util.initializer.return
  }
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_1x3x4_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        %4 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
        %5 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
        %6 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
        %7 = tensor.empty() : tensor<1x3xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%7 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %9 = linalg.matmul ins(%4, %5 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%8 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %10 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%9, %6 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%7 : tensor<1x3xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %11 = arith.addf %in, %in_0 : f32
          linalg.yield %11 : f32
        } -> tensor<1x3xf32>
        flow.dispatch.tensor.store %10, %3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c48 = arith.constant 48 : index
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %c12 = arith.constant 12 : index
    %c16 = arith.constant 16 : index
    %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
    %_params.bias = util.global.load @_params.bias : !stream.resource<constant>
    %0 = stream.async.transfer %_params.weight : !stream.resource<constant>{%c48} -> !stream.resource<*>{%c48}
    %1 = stream.async.transfer %_params.bias : !stream.resource<constant>{%c12} -> !stream.resource<*>{%c12}
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
    %3 = stream.async.transfer %2 : !stream.resource<external>{%c16} -> !stream.resource<*>{%c16}
    %4 = stream.async.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32(%3[%c0 to %c16 for %c16], %0[%c0 to %c48 for %c48], %1[%c0 to %c12 for %c12]) : (!stream.resource<*>{%c16}, !stream.resource<*>{%c48}, !stream.resource<*>{%c12}) -> !stream.resource<*>{%c12}
    %5 = stream.async.transfer %4 : !stream.resource<*>{%c12} -> !stream.resource<external>{%c12}
    %6 = stream.tensor.export %5 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
    return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private @_params.weight : !stream.resource<constant>
  util.global private @_params.bias : !stream.resource<constant>
  util.initializer {
    %c48 = arith.constant 48 : index
    %c12 = arith.constant 12 : index
    %cst = stream.async.constant : !stream.resource<constant>{%c48} = dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>
    %cst_0 = stream.async.constant : !stream.resource<constant>{%c12} = dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>
    util.global.store %cst_0, @_params.bias : !stream.resource<constant>
    util.global.store %cst, @_params.weight : !stream.resource<constant>
    util.initializer.return
  }
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_1x3x4_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        %4 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
        %5 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
        %6 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
        %7 = tensor.empty() : tensor<1x3xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%7 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %9 = linalg.matmul ins(%4, %5 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%8 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %10 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%9, %6 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%7 : tensor<1x3xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %11 = arith.addf %in, %in_0 : f32
          linalg.yield %11 : f32
        } -> tensor<1x3xf32>
        flow.dispatch.tensor.store %10, %3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c48 = arith.constant 48 : index
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %c12 = arith.constant 12 : index
    %c16 = arith.constant 16 : index
    %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
    %_params.bias = util.global.load @_params.bias : !stream.resource<constant>
    %0 = stream.async.transfer %_params.weight : !stream.resource<constant>{%c48} -> !stream.resource<*>{%c48}
    %1 = stream.async.transfer %_params.bias : !stream.resource<constant>{%c12} -> !stream.resource<*>{%c12}
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
    %3 = stream.async.transfer %2 : !stream.resource<external>{%c16} -> !stream.resource<*>{%c16}
    %4 = stream.async.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32(%3[%c0 to %c16 for %c16], %0[%c0 to %c48 for %c48], %1[%c0 to %c12 for %c12]) : (!stream.resource<*>{%c16}, !stream.resource<*>{%c48}, !stream.resource<*>{%c12}) -> !stream.resource<*>{%c12}
    %5 = stream.async.transfer %4 : !stream.resource<*>{%c12} -> !stream.resource<external>{%c12}
    %6 = stream.tensor.export %5 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
    return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After MaterializeCopyOnWrite (iree-stream-materialize-copy-on-write) //----- //
util.initializer {
  %c48 = arith.constant 48 : index
  %c12 = arith.constant 12 : index
  %cst = stream.async.constant : !stream.resource<constant>{%c48} = dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>
  %cst_0 = stream.async.constant : !stream.resource<constant>{%c12} = dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>
  util.global.store %cst_0, @_params.bias : !stream.resource<constant>
  util.global.store %cst, @_params.weight : !stream.resource<constant>
  util.initializer.return
}

// -----// IR Dump After MaterializeCopyOnWrite (iree-stream-materialize-copy-on-write) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c48 = arith.constant 48 : index
  %c0 = arith.constant 0 : index
  %c4 = arith.constant 4 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %c12 = arith.constant 12 : index
  %c16 = arith.constant 16 : index
  %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
  %_params.bias = util.global.load @_params.bias : !stream.resource<constant>
  %0 = stream.async.transfer %_params.weight : !stream.resource<constant>{%c48} -> !stream.resource<*>{%c48}
  %1 = stream.async.transfer %_params.bias : !stream.resource<constant>{%c12} -> !stream.resource<*>{%c12}
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
  %3 = stream.async.transfer %2 : !stream.resource<external>{%c16} -> !stream.resource<*>{%c16}
  %4 = stream.async.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32(%3[%c0 to %c16 for %c16], %0[%c0 to %c48 for %c48], %1[%c0 to %c12 for %c12]) : (!stream.resource<*>{%c16}, !stream.resource<*>{%c48}, !stream.resource<*>{%c12}) -> !stream.resource<*>{%c12}
  %5 = stream.async.transfer %4 : !stream.resource<*>{%c12} -> !stream.resource<external>{%c12}
  %6 = stream.tensor.export %5 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
  return %6 : !hal.buffer_view
}

// -----// IR Dump After ElideAsyncCopies (iree-stream-elide-async-copies) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private @_params.weight : !stream.resource<constant>
  util.global private @_params.bias : !stream.resource<constant>
  util.initializer {
    %c48 = arith.constant 48 : index
    %c12 = arith.constant 12 : index
    %cst = stream.async.constant : !stream.resource<constant>{%c48} = dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>
    %cst_0 = stream.async.constant : !stream.resource<constant>{%c12} = dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>
    util.global.store %cst_0, @_params.bias : !stream.resource<constant>
    util.global.store %cst, @_params.weight : !stream.resource<constant>
    util.initializer.return
  }
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_1x3x4_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        %4 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
        %5 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
        %6 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
        %7 = tensor.empty() : tensor<1x3xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%7 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %9 = linalg.matmul ins(%4, %5 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%8 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %10 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%9, %6 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%7 : tensor<1x3xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %11 = arith.addf %in, %in_0 : f32
          linalg.yield %11 : f32
        } -> tensor<1x3xf32>
        flow.dispatch.tensor.store %10, %3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c48 = arith.constant 48 : index
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %c12 = arith.constant 12 : index
    %c16 = arith.constant 16 : index
    %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
    %_params.bias = util.global.load @_params.bias : !stream.resource<constant>
    %0 = stream.async.transfer %_params.weight : !stream.resource<constant>{%c48} -> !stream.resource<*>{%c48}
    %1 = stream.async.transfer %_params.bias : !stream.resource<constant>{%c12} -> !stream.resource<*>{%c12}
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
    %3 = stream.async.transfer %2 : !stream.resource<external>{%c16} -> !stream.resource<*>{%c16}
    %4 = stream.async.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32(%3[%c0 to %c16 for %c16], %0[%c0 to %c48 for %c48], %1[%c0 to %c12 for %c12]) : (!stream.resource<*>{%c16}, !stream.resource<*>{%c48}, !stream.resource<*>{%c12}) -> !stream.resource<*>{%c12}
    %5 = stream.async.transfer %4 : !stream.resource<*>{%c12} -> !stream.resource<external>{%c12}
    %6 = stream.tensor.export %5 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
    return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.initializer {
  %c48 = arith.constant 48 : index
  %c12 = arith.constant 12 : index
  %cst = stream.async.constant : !stream.resource<constant>{%c48} = dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>
  %cst_0 = stream.async.constant : !stream.resource<constant>{%c12} = dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>
  util.global.store %cst_0, @_params.bias : !stream.resource<constant>
  util.global.store %cst, @_params.weight : !stream.resource<constant>
  util.initializer.return
}

// -----// IR Dump After EmplaceAllocations (iree-stream-emplace-allocations) //----- //
util.initializer {
  %c48 = arith.constant 48 : index
  %c12 = arith.constant 12 : index
  %cst = stream.async.constant : !stream.resource<constant>{%c48} = dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>
  %cst_0 = stream.async.constant : !stream.resource<constant>{%c12} = dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>
  util.global.store %cst_0, @_params.bias : !stream.resource<constant>
  util.global.store %cst, @_params.weight : !stream.resource<constant>
  util.initializer.return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c48 = arith.constant 48 : index
  %c0 = arith.constant 0 : index
  %c4 = arith.constant 4 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %c12 = arith.constant 12 : index
  %c16 = arith.constant 16 : index
  %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
  %_params.bias = util.global.load @_params.bias : !stream.resource<constant>
  %0 = stream.async.transfer %_params.weight : !stream.resource<constant>{%c48} -> !stream.resource<*>{%c48}
  %1 = stream.async.transfer %_params.bias : !stream.resource<constant>{%c12} -> !stream.resource<*>{%c12}
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
  %3 = stream.async.transfer %2 : !stream.resource<external>{%c16} -> !stream.resource<*>{%c16}
  %4 = stream.async.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32(%3[%c0 to %c16 for %c16], %0[%c0 to %c48 for %c48], %1[%c0 to %c12 for %c12]) : (!stream.resource<*>{%c16}, !stream.resource<*>{%c48}, !stream.resource<*>{%c12}) -> !stream.resource<*>{%c12}
  %5 = stream.async.transfer %4 : !stream.resource<*>{%c12} -> !stream.resource<external>{%c12}
  %6 = stream.tensor.export %5 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
  return %6 : !hal.buffer_view
}

// -----// IR Dump After EmplaceAllocations (iree-stream-emplace-allocations) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c48 = arith.constant 48 : index
  %c0 = arith.constant 0 : index
  %c4 = arith.constant 4 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %c12 = arith.constant 12 : index
  %c16 = arith.constant 16 : index
  %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
  %_params.bias = util.global.load @_params.bias : !stream.resource<constant>
  %0 = stream.async.transfer %_params.weight : !stream.resource<constant>{%c48} -> !stream.resource<*>{%c48}
  %1 = stream.async.transfer %_params.bias : !stream.resource<constant>{%c12} -> !stream.resource<*>{%c12}
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
  %3 = stream.async.transfer %2 : !stream.resource<external>{%c16} -> !stream.resource<*>{%c16}
  %4 = stream.async.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32(%3[%c0 to %c16 for %c16], %0[%c0 to %c48 for %c48], %1[%c0 to %c12 for %c12]) : (!stream.resource<*>{%c16}, !stream.resource<*>{%c48}, !stream.resource<*>{%c12}) -> !stream.resource<*>{%c12}
  %5 = stream.async.transfer %4 : !stream.resource<*>{%c12} -> !stream.resource<external>{%c12}
  %6 = stream.tensor.export %5 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
  return %6 : !hal.buffer_view
}

// -----// IR Dump After RefineUsage (iree-stream-refine-usage) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private @_params.weight : !stream.resource<constant>
  util.global private @_params.bias : !stream.resource<constant>
  util.initializer {
    %c48 = arith.constant 48 : index
    %c12 = arith.constant 12 : index
    %cst = stream.async.constant : !stream.resource<constant>{%c48} = dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>
    %cst_0 = stream.async.constant : !stream.resource<constant>{%c12} = dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>
    util.global.store %cst_0, @_params.bias : !stream.resource<constant>
    util.global.store %cst, @_params.weight : !stream.resource<constant>
    util.initializer.return
  }
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_1x3x4_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        %4 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
        %5 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
        %6 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
        %7 = tensor.empty() : tensor<1x3xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%7 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %9 = linalg.matmul ins(%4, %5 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%8 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %10 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%9, %6 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%7 : tensor<1x3xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %11 = arith.addf %in, %in_0 : f32
          linalg.yield %11 : f32
        } -> tensor<1x3xf32>
        flow.dispatch.tensor.store %10, %3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c48 = arith.constant 48 : index
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %c12 = arith.constant 12 : index
    %c16 = arith.constant 16 : index
    %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
    %_params.bias = util.global.load @_params.bias : !stream.resource<constant>
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
    %1 = stream.async.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32(%0[%c0 to %c16 for %c16], %_params.weight[%c0 to %c48 for %c48], %_params.bias[%c0 to %c12 for %c12]) : (!stream.resource<external>{%c16}, !stream.resource<constant>{%c48}, !stream.resource<constant>{%c12}) -> !stream.resource<external>{%c12}
    %2 = stream.tensor.export %1 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
    return %2 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.initializer {
  %c48 = arith.constant 48 : index
  %c12 = arith.constant 12 : index
  %cst = stream.async.constant : !stream.resource<constant>{%c48} = dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>
  %cst_0 = stream.async.constant : !stream.resource<constant>{%c12} = dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>
  util.global.store %cst_0, @_params.bias : !stream.resource<constant>
  util.global.store %cst, @_params.weight : !stream.resource<constant>
  util.initializer.return
}

// -----// IR Dump After CSE (cse) //----- //
util.initializer {
  %c48 = arith.constant 48 : index
  %c12 = arith.constant 12 : index
  %cst = stream.async.constant : !stream.resource<constant>{%c48} = dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>
  %cst_0 = stream.async.constant : !stream.resource<constant>{%c12} = dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>
  util.global.store %cst_0, @_params.bias : !stream.resource<constant>
  util.global.store %cst, @_params.weight : !stream.resource<constant>
  util.initializer.return
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.initializer {
  %c48 = arith.constant 48 : index
  %c12 = arith.constant 12 : index
  %cst = stream.async.constant : !stream.resource<constant>{%c48} = dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>
  %cst_0 = stream.async.constant : !stream.resource<constant>{%c12} = dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>
  util.global.store %cst_0, @_params.bias : !stream.resource<constant>
  util.global.store %cst, @_params.weight : !stream.resource<constant>
  util.initializer.return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c48 = arith.constant 48 : index
  %c0 = arith.constant 0 : index
  %c4 = arith.constant 4 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %c12 = arith.constant 12 : index
  %c16 = arith.constant 16 : index
  %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
  %_params.bias = util.global.load @_params.bias : !stream.resource<constant>
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
  %1 = stream.async.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32(%0[%c0 to %c16 for %c16], %_params.weight[%c0 to %c48 for %c48], %_params.bias[%c0 to %c12 for %c12]) : (!stream.resource<external>{%c16}, !stream.resource<constant>{%c48}, !stream.resource<constant>{%c12}) -> !stream.resource<external>{%c12}
  %2 = stream.tensor.export %1 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
  return %2 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c48 = arith.constant 48 : index
  %c0 = arith.constant 0 : index
  %c4 = arith.constant 4 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %c12 = arith.constant 12 : index
  %c16 = arith.constant 16 : index
  %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
  %_params.bias = util.global.load @_params.bias : !stream.resource<constant>
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
  %1 = stream.async.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32(%0[%c0 to %c16 for %c16], %_params.weight[%c0 to %c48 for %c48], %_params.bias[%c0 to %c12 for %c12]) : (!stream.resource<external>{%c16}, !stream.resource<constant>{%c48}, !stream.resource<constant>{%c12}) -> !stream.resource<external>{%c12}
  %2 = stream.tensor.export %1 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
  return %2 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
  %_params.bias = util.global.load @_params.bias : !stream.resource<constant>
  %c48 = arith.constant 48 : index
  %c0 = arith.constant 0 : index
  %c4 = arith.constant 4 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %c12 = arith.constant 12 : index
  %c16 = arith.constant 16 : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
  %1 = stream.async.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32(%0[%c0 to %c16 for %c16], %_params.weight[%c0 to %c48 for %c48], %_params.bias[%c0 to %c12 for %c12]) : (!stream.resource<external>{%c16}, !stream.resource<constant>{%c48}, !stream.resource<constant>{%c12}) -> !stream.resource<external>{%c12}
  %2 = stream.tensor.export %1 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
  return %2 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private @_params.weight : !stream.resource<constant>
  util.global private @_params.bias : !stream.resource<constant>
  util.initializer {
    %c48 = arith.constant 48 : index
    %c12 = arith.constant 12 : index
    %cst = stream.async.constant : !stream.resource<constant>{%c48} = dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>
    %cst_0 = stream.async.constant : !stream.resource<constant>{%c12} = dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>
    util.global.store %cst_0, @_params.bias : !stream.resource<constant>
    util.global.store %cst, @_params.weight : !stream.resource<constant>
    util.initializer.return
  }
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_1x3x4_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        %4 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
        %5 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
        %6 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
        %7 = tensor.empty() : tensor<1x3xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%7 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %9 = linalg.matmul ins(%4, %5 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%8 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %10 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%9, %6 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%7 : tensor<1x3xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %11 = arith.addf %in, %in_0 : f32
          linalg.yield %11 : f32
        } -> tensor<1x3xf32>
        flow.dispatch.tensor.store %10, %3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c16 = arith.constant 16 : index
    %c12 = arith.constant 12 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c48 = arith.constant 48 : index
    %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
    %_params.bias = util.global.load @_params.bias : !stream.resource<constant>
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
    %1 = stream.async.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32(%0[%c0 to %c16 for %c16], %_params.weight[%c0 to %c48 for %c48], %_params.bias[%c0 to %c12 for %c12]) : (!stream.resource<external>{%c16}, !stream.resource<constant>{%c48}, !stream.resource<constant>{%c12}) -> !stream.resource<external>{%c12}
    %2 = stream.tensor.export %1 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
    return %2 : !hal.buffer_view
  }
}


// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private @_params.weight : !stream.resource<constant>
  util.global private @_params.bias : !stream.resource<constant>
  util.initializer {
    %c48 = arith.constant 48 : index
    %c12 = arith.constant 12 : index
    %cst = stream.async.constant : !stream.resource<constant>{%c48} = dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>
    %cst_0 = stream.async.constant : !stream.resource<constant>{%c12} = dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>
    util.global.store %cst_0, @_params.bias : !stream.resource<constant>
    util.global.store %cst, @_params.weight : !stream.resource<constant>
    util.initializer.return
  }
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_1x3x4_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        %4 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
        %5 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
        %6 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
        %7 = tensor.empty() : tensor<1x3xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%7 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %9 = linalg.matmul ins(%4, %5 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%8 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %10 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%9, %6 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%7 : tensor<1x3xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %11 = arith.addf %in, %in_0 : f32
          linalg.yield %11 : f32
        } -> tensor<1x3xf32>
        flow.dispatch.tensor.store %10, %3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c16 = arith.constant 16 : index
    %c12 = arith.constant 12 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c48 = arith.constant 48 : index
    %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
    %_params.bias = util.global.load @_params.bias : !stream.resource<constant>
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
    %1 = stream.async.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32(%0[%c0 to %c16 for %c16], %_params.weight[%c0 to %c48 for %c48], %_params.bias[%c0 to %c12 for %c12]) : (!stream.resource<external>{%c16}, !stream.resource<constant>{%c48}, !stream.resource<constant>{%c12}) -> !stream.resource<external>{%c12}
    %2 = stream.tensor.export %1 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
    return %2 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private @_params.weight : !stream.resource<constant>
  util.global private @_params.bias : !stream.resource<constant>
  util.initializer {
    %c48 = arith.constant 48 : index
    %c12 = arith.constant 12 : index
    %cst = stream.async.constant : !stream.resource<constant>{%c48} = dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>
    %cst_0 = stream.async.constant : !stream.resource<constant>{%c12} = dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>
    util.global.store %cst_0, @_params.bias : !stream.resource<constant>
    util.global.store %cst, @_params.weight : !stream.resource<constant>
    util.initializer.return
  }
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_1x3x4_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        %4 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
        %5 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
        %6 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
        %7 = tensor.empty() : tensor<1x3xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%7 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %9 = linalg.matmul ins(%4, %5 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%8 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %10 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%9, %6 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%7 : tensor<1x3xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %11 = arith.addf %in, %in_0 : f32
          linalg.yield %11 : f32
        } -> tensor<1x3xf32>
        flow.dispatch.tensor.store %10, %3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c16 = arith.constant 16 : index
    %c12 = arith.constant 12 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c48 = arith.constant 48 : index
    %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
    %_params.bias = util.global.load @_params.bias : !stream.resource<constant>
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
    %1 = stream.async.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32(%0[%c0 to %c16 for %c16], %_params.weight[%c0 to %c48 for %c48], %_params.bias[%c0 to %c12 for %c12]) : (!stream.resource<external>{%c16}, !stream.resource<constant>{%c48}, !stream.resource<constant>{%c12}) -> !stream.resource<external>{%c12}
    %2 = stream.tensor.export %1 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
    return %2 : !hal.buffer_view
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private @_params.weight : !stream.resource<constant>
  util.global private @_params.bias : !stream.resource<constant>
  util.initializer {
    %c48 = arith.constant 48 : index
    %c12 = arith.constant 12 : index
    %cst = stream.async.constant : !stream.resource<constant>{%c48} = dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>
    %cst_0 = stream.async.constant : !stream.resource<constant>{%c12} = dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>
    util.global.store %cst_0, @_params.bias : !stream.resource<constant>
    util.global.store %cst, @_params.weight : !stream.resource<constant>
    util.initializer.return
  }
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_1x3x4_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        %4 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
        %5 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
        %6 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
        %7 = tensor.empty() : tensor<1x3xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%7 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %9 = linalg.matmul ins(%4, %5 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%8 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %10 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%9, %6 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%7 : tensor<1x3xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %11 = arith.addf %in, %in_0 : f32
          linalg.yield %11 : f32
        } -> tensor<1x3xf32>
        flow.dispatch.tensor.store %10, %3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c16 = arith.constant 16 : index
    %c12 = arith.constant 12 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c48 = arith.constant 48 : index
    %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
    %_params.bias = util.global.load @_params.bias : !stream.resource<constant>
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
    %1 = stream.async.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32(%0[%c0 to %c16 for %c16], %_params.weight[%c0 to %c48 for %c48], %_params.bias[%c0 to %c12 for %c12]) : (!stream.resource<external>{%c16}, !stream.resource<constant>{%c48}, !stream.resource<constant>{%c12}) -> !stream.resource<external>{%c12}
    %2 = stream.tensor.export %1 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
    return %2 : !hal.buffer_view
  }
}


// -----// IR Dump After VerifyAsyncAccessRanges (iree-stream-verify-async-access-ranges) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private @_params.weight : !stream.resource<constant>
  util.global private @_params.bias : !stream.resource<constant>
  util.initializer {
    %c48 = arith.constant 48 : index
    %c12 = arith.constant 12 : index
    %cst = stream.async.constant : !stream.resource<constant>{%c48} = dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>
    %cst_0 = stream.async.constant : !stream.resource<constant>{%c12} = dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>
    util.global.store %cst_0, @_params.bias : !stream.resource<constant>
    util.global.store %cst, @_params.weight : !stream.resource<constant>
    util.initializer.return
  }
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_1x3x4_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        %4 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
        %5 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
        %6 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
        %7 = tensor.empty() : tensor<1x3xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%7 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %9 = linalg.matmul ins(%4, %5 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%8 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %10 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%9, %6 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%7 : tensor<1x3xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %11 = arith.addf %in, %in_0 : f32
          linalg.yield %11 : f32
        } -> tensor<1x3xf32>
        flow.dispatch.tensor.store %10, %3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c16 = arith.constant 16 : index
    %c12 = arith.constant 12 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c48 = arith.constant 48 : index
    %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
    %_params.bias = util.global.load @_params.bias : !stream.resource<constant>
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
    %1 = stream.async.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32(%0[%c0 to %c16 for %c16], %_params.weight[%c0 to %c48 for %c48], %_params.bias[%c0 to %c12 for %c12]) : (!stream.resource<external>{%c16}, !stream.resource<constant>{%c48}, !stream.resource<constant>{%c12}) -> !stream.resource<external>{%c12}
    %2 = stream.tensor.export %1 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
    return %2 : !hal.buffer_view
  }
}


// -----// IR Dump After ScheduleExecution (iree-stream-schedule-execution) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c16 = arith.constant 16 : index
  %c12 = arith.constant 12 : index
  %c553648160_i32 = arith.constant 553648160 : i32
  %c1_i32 = arith.constant 1 : i32
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %c48 = arith.constant 48 : index
  %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
  %_params.bias = util.global.load @_params.bias : !stream.resource<constant>
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
  %results, %result_timepoint = stream.async.execute with(%0 as %arg1: !stream.resource<external>{%c16}, %_params.weight as %arg2: !stream.resource<constant>{%c48}, %_params.bias as %arg3: !stream.resource<constant>{%c12}) -> !stream.resource<external>{%c12} {
    %3 = stream.async.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32(%arg1[%c0 to %c16 for %c16], %arg2[%c0 to %c48 for %c48], %arg3[%c0 to %c12 for %c12]) : (!stream.resource<external>{%c16}, !stream.resource<constant>{%c48}, !stream.resource<constant>{%c12}) -> !stream.resource<external>{%c12}
    stream.yield %3 : !stream.resource<external>{%c12}
  } => !stream.timepoint
  %1 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%c12}
  %2 = stream.tensor.export %1 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
  return %2 : !hal.buffer_view
}

// -----// IR Dump After ScheduleExecution (iree-stream-schedule-execution) //----- //
util.initializer {
  %c48 = arith.constant 48 : index
  %c12 = arith.constant 12 : index
  %results:2, %result_timepoint = stream.async.execute with() -> (!stream.resource<constant>{%c48}, !stream.resource<constant>{%c12}) {
    %cst = stream.async.constant : !stream.resource<constant>{%c48} = dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>
    %cst_0 = stream.async.constant : !stream.resource<constant>{%c12} = dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>
    stream.yield %cst, %cst_0 : !stream.resource<constant>{%c48}, !stream.resource<constant>{%c12}
  } => !stream.timepoint
  %0:2 = stream.timepoint.await %result_timepoint => %results#1, %results#0 : !stream.resource<constant>{%c12}, !stream.resource<constant>{%c48}
  util.global.store %0#0, @_params.bias : !stream.resource<constant>
  util.global.store %0#1, @_params.weight : !stream.resource<constant>
  util.initializer.return
}

// -----// IR Dump After ScheduleConcurrency (iree-stream-schedule-concurrency) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c16 = arith.constant 16 : index
  %c12 = arith.constant 12 : index
  %c553648160_i32 = arith.constant 553648160 : i32
  %c1_i32 = arith.constant 1 : i32
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %c48 = arith.constant 48 : index
  %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
  %_params.bias = util.global.load @_params.bias : !stream.resource<constant>
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
  %results, %result_timepoint = stream.async.execute with(%0 as %arg1: !stream.resource<external>{%c16}, %_params.weight as %arg2: !stream.resource<constant>{%c48}, %_params.bias as %arg3: !stream.resource<constant>{%c12}) -> !stream.resource<external>{%c12} {
    %3 = stream.async.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32(%arg1[%c0 to %c16 for %c16], %arg2[%c0 to %c48 for %c48], %arg3[%c0 to %c12 for %c12]) : (!stream.resource<external>{%c16}, !stream.resource<constant>{%c48}, !stream.resource<constant>{%c12}) -> !stream.resource<external>{%c12}
    stream.yield %3 : !stream.resource<external>{%c12}
  } => !stream.timepoint
  %1 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%c12}
  %2 = stream.tensor.export %1 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
  return %2 : !hal.buffer_view
}

// -----// IR Dump After ScheduleConcurrency (iree-stream-schedule-concurrency) //----- //
util.initializer {
  %c48 = arith.constant 48 : index
  %c12 = arith.constant 12 : index
  %results:2, %result_timepoint = stream.async.execute with() -> (!stream.resource<constant>{%c48}, !stream.resource<constant>{%c12}) {
    %cst = stream.async.constant : !stream.resource<constant>{%c48} = dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>
    %cst_0 = stream.async.constant : !stream.resource<constant>{%c12} = dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>
    stream.yield %cst, %cst_0 : !stream.resource<constant>{%c48}, !stream.resource<constant>{%c12}
  } => !stream.timepoint
  %0:2 = stream.timepoint.await %result_timepoint => %results#1, %results#0 : !stream.resource<constant>{%c12}, !stream.resource<constant>{%c48}
  util.global.store %0#0, @_params.bias : !stream.resource<constant>
  util.global.store %0#1, @_params.weight : !stream.resource<constant>
  util.initializer.return
}

// -----// IR Dump After PropagateTimepoints (iree-stream-propagate-timepoints) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private mutable @_params.weight__timepoint = #stream.timepoint<immediate> : !stream.timepoint
  util.global private @_params.weight : !stream.resource<constant>
  util.global private mutable @_params.bias__timepoint = #stream.timepoint<immediate> : !stream.timepoint
  util.global private @_params.bias : !stream.resource<constant>
  util.initializer {
    %c48 = arith.constant 48 : index
    %c12 = arith.constant 12 : index
    %results:2, %result_timepoint = stream.async.execute with() -> (!stream.resource<constant>{%c48}, !stream.resource<constant>{%c12}) {
      %cst = stream.async.constant : !stream.resource<constant>{%c48} = dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>
      %cst_0 = stream.async.constant : !stream.resource<constant>{%c12} = dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>
      stream.yield %cst, %cst_0 : !stream.resource<constant>{%c48}, !stream.resource<constant>{%c12}
    } => !stream.timepoint
    %0:2 = stream.timepoint.await %result_timepoint => %results#1, %results#0 : !stream.resource<constant>{%c12}, !stream.resource<constant>{%c48}
    util.global.store %result_timepoint, @_params.bias__timepoint : !stream.timepoint
    util.global.store %results#1, @_params.bias : !stream.resource<constant>
    util.global.store %result_timepoint, @_params.weight__timepoint : !stream.timepoint
    util.global.store %results#0, @_params.weight : !stream.resource<constant>
    util.initializer.return
  }
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_1x3x4_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        %4 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
        %5 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
        %6 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
        %7 = tensor.empty() : tensor<1x3xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%7 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %9 = linalg.matmul ins(%4, %5 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%8 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %10 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%9, %6 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%7 : tensor<1x3xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %11 = arith.addf %in, %in_0 : f32
          linalg.yield %11 : f32
        } -> tensor<1x3xf32>
        flow.dispatch.tensor.store %10, %3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c16 = arith.constant 16 : index
    %c12 = arith.constant 12 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c48 = arith.constant 48 : index
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !stream.timepoint
    %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
    %0 = stream.timepoint.await %_params.weight__timepoint => %_params.weight : !stream.resource<constant>{%c48}
    %_params.bias__timepoint = util.global.load @_params.bias__timepoint : !stream.timepoint
    %_params.bias = util.global.load @_params.bias : !stream.resource<constant>
    %1 = stream.timepoint.await %_params.bias__timepoint => %_params.bias : !stream.resource<constant>{%c12}
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
    %3 = stream.timepoint.immediate => !stream.timepoint
    %4 = stream.timepoint.join max(%3, %_params.weight__timepoint, %_params.bias__timepoint) => !stream.timepoint
    %results, %result_timepoint = stream.async.execute await(%4) => with(%2 as %arg1: !stream.resource<external>{%c16}, %_params.weight as %arg2: !stream.resource<constant>{%c48}, %_params.bias as %arg3: !stream.resource<constant>{%c12}) -> !stream.resource<external>{%c12} {
      %7 = stream.async.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32(%arg1[%c0 to %c16 for %c16], %arg2[%c0 to %c48 for %c48], %arg3[%c0 to %c12 for %c12]) : (!stream.resource<external>{%c16}, !stream.resource<constant>{%c48}, !stream.resource<constant>{%c12}) -> !stream.resource<external>{%c12}
      stream.yield %7 : !stream.resource<external>{%c12}
    } => !stream.timepoint
    %5 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%c12}
    %6 = stream.tensor.export %5 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
    return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After MaterializeBuiltins (iree-stream-materialize-builtins) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private mutable @_params.weight__timepoint = #stream.timepoint<immediate> : !stream.timepoint
  util.global private @_params.weight : !stream.resource<constant>
  util.global private mutable @_params.bias__timepoint = #stream.timepoint<immediate> : !stream.timepoint
  util.global private @_params.bias : !stream.resource<constant>
  util.initializer {
    %c48 = arith.constant 48 : index
    %c12 = arith.constant 12 : index
    %results:2, %result_timepoint = stream.async.execute with() -> (!stream.resource<constant>{%c48}, !stream.resource<constant>{%c12}) {
      %cst = stream.async.constant : !stream.resource<constant>{%c48} = dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>
      %cst_0 = stream.async.constant : !stream.resource<constant>{%c12} = dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>
      stream.yield %cst, %cst_0 : !stream.resource<constant>{%c48}, !stream.resource<constant>{%c12}
    } => !stream.timepoint
    %0:2 = stream.timepoint.await %result_timepoint => %results#1, %results#0 : !stream.resource<constant>{%c12}, !stream.resource<constant>{%c48}
    util.global.store %result_timepoint, @_params.bias__timepoint : !stream.timepoint
    util.global.store %results#1, @_params.bias : !stream.resource<constant>
    util.global.store %result_timepoint, @_params.weight__timepoint : !stream.timepoint
    util.global.store %results#0, @_params.weight : !stream.resource<constant>
    util.initializer.return
  }
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_1x3x4_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        %4 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
        %5 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
        %6 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
        %7 = tensor.empty() : tensor<1x3xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%7 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %9 = linalg.matmul ins(%4, %5 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%8 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %10 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%9, %6 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%7 : tensor<1x3xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %11 = arith.addf %in, %in_0 : f32
          linalg.yield %11 : f32
        } -> tensor<1x3xf32>
        flow.dispatch.tensor.store %10, %3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c16 = arith.constant 16 : index
    %c12 = arith.constant 12 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c48 = arith.constant 48 : index
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !stream.timepoint
    %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
    %0 = stream.timepoint.await %_params.weight__timepoint => %_params.weight : !stream.resource<constant>{%c48}
    %_params.bias__timepoint = util.global.load @_params.bias__timepoint : !stream.timepoint
    %_params.bias = util.global.load @_params.bias : !stream.resource<constant>
    %1 = stream.timepoint.await %_params.bias__timepoint => %_params.bias : !stream.resource<constant>{%c12}
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
    %3 = stream.timepoint.immediate => !stream.timepoint
    %4 = stream.timepoint.join max(%3, %_params.weight__timepoint, %_params.bias__timepoint) => !stream.timepoint
    %results, %result_timepoint = stream.async.execute await(%4) => with(%2 as %arg1: !stream.resource<external>{%c16}, %_params.weight as %arg2: !stream.resource<constant>{%c48}, %_params.bias as %arg3: !stream.resource<constant>{%c12}) -> !stream.resource<external>{%c12} {
      %7 = stream.async.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32(%arg1[%c0 to %c16 for %c16], %arg2[%c0 to %c48 for %c48], %arg3[%c0 to %c12 for %c12]) : (!stream.resource<external>{%c16}, !stream.resource<constant>{%c48}, !stream.resource<constant>{%c12}) -> !stream.resource<external>{%c12}
      stream.yield %7 : !stream.resource<external>{%c12}
    } => !stream.timepoint
    %5 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%c12}
    %6 = stream.tensor.export %5 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
    return %6 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.initializer {
  %c48 = arith.constant 48 : index
  %c12 = arith.constant 12 : index
  %results:2, %result_timepoint = stream.async.execute with() -> (!stream.resource<constant>{%c48}, !stream.resource<constant>{%c12}) {
    %cst = stream.async.constant : !stream.resource<constant>{%c48} = dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>
    %cst_0 = stream.async.constant : !stream.resource<constant>{%c12} = dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>
    stream.yield %cst, %cst_0 : !stream.resource<constant>{%c48}, !stream.resource<constant>{%c12}
  } => !stream.timepoint
  util.global.store %result_timepoint, @_params.bias__timepoint : !stream.timepoint
  util.global.store %results#1, @_params.bias : !stream.resource<constant>
  util.global.store %result_timepoint, @_params.weight__timepoint : !stream.timepoint
  util.global.store %results#0, @_params.weight : !stream.resource<constant>
  util.initializer.return
}

// -----// IR Dump After CSE (cse) //----- //
util.initializer {
  %c48 = arith.constant 48 : index
  %c12 = arith.constant 12 : index
  %results:2, %result_timepoint = stream.async.execute with() -> (!stream.resource<constant>{%c48}, !stream.resource<constant>{%c12}) {
    %cst = stream.async.constant : !stream.resource<constant>{%c48} = dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>
    %cst_0 = stream.async.constant : !stream.resource<constant>{%c12} = dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>
    stream.yield %cst, %cst_0 : !stream.resource<constant>{%c48}, !stream.resource<constant>{%c12}
  } => !stream.timepoint
  util.global.store %result_timepoint, @_params.bias__timepoint : !stream.timepoint
  util.global.store %results#1, @_params.bias : !stream.resource<constant>
  util.global.store %result_timepoint, @_params.weight__timepoint : !stream.timepoint
  util.global.store %results#0, @_params.weight : !stream.resource<constant>
  util.initializer.return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c16 = arith.constant 16 : index
  %c12 = arith.constant 12 : index
  %c553648160_i32 = arith.constant 553648160 : i32
  %c1_i32 = arith.constant 1 : i32
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %c48 = arith.constant 48 : index
  %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !stream.timepoint
  %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
  %_params.bias__timepoint = util.global.load @_params.bias__timepoint : !stream.timepoint
  %_params.bias = util.global.load @_params.bias : !stream.resource<constant>
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
  %1 = stream.timepoint.join max(%_params.weight__timepoint, %_params.bias__timepoint) => !stream.timepoint
  %results, %result_timepoint = stream.async.execute await(%1) => with(%0 as %arg1: !stream.resource<external>{%c16}, %_params.weight as %arg2: !stream.resource<constant>{%c48}, %_params.bias as %arg3: !stream.resource<constant>{%c12}) -> !stream.resource<external>{%c12} {
    %4 = stream.async.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32(%arg1[%c0 to %c16 for %c16], %arg2[%c0 to %c48 for %c48], %arg3[%c0 to %c12 for %c12]) : (!stream.resource<external>{%c16}, !stream.resource<constant>{%c48}, !stream.resource<constant>{%c12}) -> !stream.resource<external>{%c12}
    stream.yield %4 : !stream.resource<external>{%c12}
  } => !stream.timepoint
  %2 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%c12}
  %3 = stream.tensor.export %2 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
  return %3 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.initializer {
  %c48 = arith.constant 48 : index
  %c12 = arith.constant 12 : index
  %results:2, %result_timepoint = stream.async.execute with() -> (!stream.resource<constant>{%c48}, !stream.resource<constant>{%c12}) {
    %cst = stream.async.constant : !stream.resource<constant>{%c48} = dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>
    %cst_0 = stream.async.constant : !stream.resource<constant>{%c12} = dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>
    stream.yield %cst, %cst_0 : !stream.resource<constant>{%c48}, !stream.resource<constant>{%c12}
  } => !stream.timepoint
  util.global.store %results#1, @_params.bias : !stream.resource<constant>
  util.global.store %result_timepoint, @_params.bias__timepoint : !stream.timepoint
  util.global.store %results#0, @_params.weight : !stream.resource<constant>
  util.global.store %result_timepoint, @_params.weight__timepoint : !stream.timepoint
  util.initializer.return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c16 = arith.constant 16 : index
  %c12 = arith.constant 12 : index
  %c553648160_i32 = arith.constant 553648160 : i32
  %c1_i32 = arith.constant 1 : i32
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %c48 = arith.constant 48 : index
  %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !stream.timepoint
  %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
  %_params.bias__timepoint = util.global.load @_params.bias__timepoint : !stream.timepoint
  %_params.bias = util.global.load @_params.bias : !stream.resource<constant>
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
  %1 = stream.timepoint.join max(%_params.weight__timepoint, %_params.bias__timepoint) => !stream.timepoint
  %results, %result_timepoint = stream.async.execute await(%1) => with(%0 as %arg1: !stream.resource<external>{%c16}, %_params.weight as %arg2: !stream.resource<constant>{%c48}, %_params.bias as %arg3: !stream.resource<constant>{%c12}) -> !stream.resource<external>{%c12} {
    %4 = stream.async.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32(%arg1[%c0 to %c16 for %c16], %arg2[%c0 to %c48 for %c48], %arg3[%c0 to %c12 for %c12]) : (!stream.resource<external>{%c16}, !stream.resource<constant>{%c48}, !stream.resource<constant>{%c12}) -> !stream.resource<external>{%c12}
    stream.yield %4 : !stream.resource<external>{%c12}
  } => !stream.timepoint
  %2 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%c12}
  %3 = stream.tensor.export %2 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
  return %3 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !stream.timepoint
  %_params.bias__timepoint = util.global.load @_params.bias__timepoint : !stream.timepoint
  %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
  %_params.bias = util.global.load @_params.bias : !stream.resource<constant>
  %c16 = arith.constant 16 : index
  %c12 = arith.constant 12 : index
  %c553648160_i32 = arith.constant 553648160 : i32
  %c1_i32 = arith.constant 1 : i32
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %c48 = arith.constant 48 : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
  %1 = stream.timepoint.join max(%_params.weight__timepoint, %_params.bias__timepoint) => !stream.timepoint
  %results, %result_timepoint = stream.async.execute await(%1) => with(%0 as %arg1: !stream.resource<external>{%c16}, %_params.weight as %arg2: !stream.resource<constant>{%c48}, %_params.bias as %arg3: !stream.resource<constant>{%c12}) -> !stream.resource<external>{%c12} {
    %4 = stream.async.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32(%arg1[%c0 to %c16 for %c16], %arg2[%c0 to %c48 for %c48], %arg3[%c0 to %c12 for %c12]) : (!stream.resource<external>{%c16}, !stream.resource<constant>{%c48}, !stream.resource<constant>{%c12}) -> !stream.resource<external>{%c12}
    stream.yield %4 : !stream.resource<external>{%c12}
  } => !stream.timepoint
  %2 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%c12}
  %3 = stream.tensor.export %2 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
  return %3 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private mutable @_params.weight__timepoint = #stream.timepoint<immediate> : !stream.timepoint
  util.global private @_params.weight : !stream.resource<constant>
  util.global private mutable @_params.bias__timepoint = #stream.timepoint<immediate> : !stream.timepoint
  util.global private @_params.bias : !stream.resource<constant>
  util.initializer {
    %c48 = arith.constant 48 : index
    %c12 = arith.constant 12 : index
    %results:2, %result_timepoint = stream.async.execute with() -> (!stream.resource<constant>{%c48}, !stream.resource<constant>{%c12}) {
      %cst = stream.async.constant : !stream.resource<constant>{%c48} = dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>
      %cst_0 = stream.async.constant : !stream.resource<constant>{%c12} = dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>
      stream.yield %cst, %cst_0 : !stream.resource<constant>{%c48}, !stream.resource<constant>{%c12}
    } => !stream.timepoint
    util.global.store %results#1, @_params.bias : !stream.resource<constant>
    util.global.store %result_timepoint, @_params.bias__timepoint : !stream.timepoint
    util.global.store %results#0, @_params.weight : !stream.resource<constant>
    util.global.store %result_timepoint, @_params.weight__timepoint : !stream.timepoint
    util.initializer.return
  }
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_1x3x4_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        %4 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
        %5 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
        %6 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
        %7 = tensor.empty() : tensor<1x3xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%7 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %9 = linalg.matmul ins(%4, %5 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%8 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %10 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%9, %6 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%7 : tensor<1x3xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %11 = arith.addf %in, %in_0 : f32
          linalg.yield %11 : f32
        } -> tensor<1x3xf32>
        flow.dispatch.tensor.store %10, %3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c48 = arith.constant 48 : index
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %c12 = arith.constant 12 : index
    %c16 = arith.constant 16 : index
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !stream.timepoint
    %_params.bias__timepoint = util.global.load @_params.bias__timepoint : !stream.timepoint
    %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
    %_params.bias = util.global.load @_params.bias : !stream.resource<constant>
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
    %1 = stream.timepoint.join max(%_params.weight__timepoint, %_params.bias__timepoint) => !stream.timepoint
    %results, %result_timepoint = stream.async.execute await(%1) => with(%0 as %arg1: !stream.resource<external>{%c16}, %_params.weight as %arg2: !stream.resource<constant>{%c48}, %_params.bias as %arg3: !stream.resource<constant>{%c12}) -> !stream.resource<external>{%c12} {
      %4 = stream.async.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32(%arg1[%c0 to %c16 for %c16], %arg2[%c0 to %c48 for %c48], %arg3[%c0 to %c12 for %c12]) : (!stream.resource<external>{%c16}, !stream.resource<constant>{%c48}, !stream.resource<constant>{%c12}) -> !stream.resource<external>{%c12}
      stream.yield %4 : !stream.resource<external>{%c12}
    } => !stream.timepoint
    %2 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%c12}
    %3 = stream.tensor.export %2 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
    return %3 : !hal.buffer_view
  }
}


// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private mutable @_params.weight__timepoint = #stream.timepoint<immediate> : !stream.timepoint
  util.global private @_params.weight : !stream.resource<constant>
  util.global private mutable @_params.bias__timepoint = #stream.timepoint<immediate> : !stream.timepoint
  util.global private @_params.bias : !stream.resource<constant>
  util.initializer {
    %c48 = arith.constant 48 : index
    %c12 = arith.constant 12 : index
    %results:2, %result_timepoint = stream.async.execute with() -> (!stream.resource<constant>{%c48}, !stream.resource<constant>{%c12}) {
      %cst = stream.async.constant : !stream.resource<constant>{%c48} = dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>
      %cst_0 = stream.async.constant : !stream.resource<constant>{%c12} = dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>
      stream.yield %cst, %cst_0 : !stream.resource<constant>{%c48}, !stream.resource<constant>{%c12}
    } => !stream.timepoint
    util.global.store %results#1, @_params.bias : !stream.resource<constant>
    util.global.store %result_timepoint, @_params.bias__timepoint : !stream.timepoint
    util.global.store %results#0, @_params.weight : !stream.resource<constant>
    util.global.store %result_timepoint, @_params.weight__timepoint : !stream.timepoint
    util.initializer.return
  }
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_1x3x4_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        %4 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
        %5 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
        %6 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
        %7 = tensor.empty() : tensor<1x3xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%7 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %9 = linalg.matmul ins(%4, %5 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%8 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %10 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%9, %6 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%7 : tensor<1x3xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %11 = arith.addf %in, %in_0 : f32
          linalg.yield %11 : f32
        } -> tensor<1x3xf32>
        flow.dispatch.tensor.store %10, %3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c48 = arith.constant 48 : index
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %c12 = arith.constant 12 : index
    %c16 = arith.constant 16 : index
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !stream.timepoint
    %_params.bias__timepoint = util.global.load @_params.bias__timepoint : !stream.timepoint
    %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
    %_params.bias = util.global.load @_params.bias : !stream.resource<constant>
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
    %1 = stream.timepoint.join max(%_params.weight__timepoint, %_params.bias__timepoint) => !stream.timepoint
    %results, %result_timepoint = stream.async.execute await(%1) => with(%0 as %arg1: !stream.resource<external>{%c16}, %_params.weight as %arg2: !stream.resource<constant>{%c48}, %_params.bias as %arg3: !stream.resource<constant>{%c12}) -> !stream.resource<external>{%c12} {
      %4 = stream.async.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32(%arg1[%c0 to %c16 for %c16], %arg2[%c0 to %c48 for %c48], %arg3[%c0 to %c12 for %c12]) : (!stream.resource<external>{%c16}, !stream.resource<constant>{%c48}, !stream.resource<constant>{%c12}) -> !stream.resource<external>{%c12}
      stream.yield %4 : !stream.resource<external>{%c12}
    } => !stream.timepoint
    %2 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%c12}
    %3 = stream.tensor.export %2 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
    return %3 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private mutable @_params.weight__timepoint = #stream.timepoint<immediate> : !stream.timepoint
  util.global private @_params.weight : !stream.resource<constant>
  util.global private @_params.bias : !stream.resource<constant>
  util.initializer {
    %c48 = arith.constant 48 : index
    %c12 = arith.constant 12 : index
    %results:2, %result_timepoint = stream.async.execute with() -> (!stream.resource<constant>{%c48}, !stream.resource<constant>{%c12}) {
      %cst = stream.async.constant : !stream.resource<constant>{%c48} = dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>
      %cst_0 = stream.async.constant : !stream.resource<constant>{%c12} = dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>
      stream.yield %cst, %cst_0 : !stream.resource<constant>{%c48}, !stream.resource<constant>{%c12}
    } => !stream.timepoint
    util.global.store %results#1, @_params.bias : !stream.resource<constant>
    util.global.store %results#0, @_params.weight : !stream.resource<constant>
    util.global.store %result_timepoint, @_params.weight__timepoint : !stream.timepoint
    util.initializer.return
  }
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_1x3x4_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        %4 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
        %5 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
        %6 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
        %7 = tensor.empty() : tensor<1x3xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%7 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %9 = linalg.matmul ins(%4, %5 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%8 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %10 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%9, %6 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%7 : tensor<1x3xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %11 = arith.addf %in, %in_0 : f32
          linalg.yield %11 : f32
        } -> tensor<1x3xf32>
        flow.dispatch.tensor.store %10, %3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c48 = arith.constant 48 : index
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %c12 = arith.constant 12 : index
    %c16 = arith.constant 16 : index
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !stream.timepoint
    %_params.weight__timepoint_0 = util.global.load @_params.weight__timepoint : !stream.timepoint
    %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
    %_params.bias = util.global.load @_params.bias : !stream.resource<constant>
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
    %1 = stream.timepoint.join max(%_params.weight__timepoint, %_params.weight__timepoint_0) => !stream.timepoint
    %results, %result_timepoint = stream.async.execute await(%1) => with(%0 as %arg1: !stream.resource<external>{%c16}, %_params.weight as %arg2: !stream.resource<constant>{%c48}, %_params.bias as %arg3: !stream.resource<constant>{%c12}) -> !stream.resource<external>{%c12} {
      %4 = stream.async.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32(%arg1[%c0 to %c16 for %c16], %arg2[%c0 to %c48 for %c48], %arg3[%c0 to %c12 for %c12]) : (!stream.resource<external>{%c16}, !stream.resource<constant>{%c48}, !stream.resource<constant>{%c12}) -> !stream.resource<external>{%c12}
      stream.yield %4 : !stream.resource<external>{%c12}
    } => !stream.timepoint
    %2 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%c12}
    %3 = stream.tensor.export %2 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
    return %3 : !hal.buffer_view
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private mutable @_params.weight__timepoint = #stream.timepoint<immediate> : !stream.timepoint
  util.global private @_params.weight : !stream.resource<constant>
  util.global private @_params.bias : !stream.resource<constant>
  util.initializer {
    %c48 = arith.constant 48 : index
    %c12 = arith.constant 12 : index
    %results:2, %result_timepoint = stream.async.execute with() -> (!stream.resource<constant>{%c48}, !stream.resource<constant>{%c12}) {
      %cst = stream.async.constant : !stream.resource<constant>{%c48} = dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>
      %cst_0 = stream.async.constant : !stream.resource<constant>{%c12} = dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>
      stream.yield %cst, %cst_0 : !stream.resource<constant>{%c48}, !stream.resource<constant>{%c12}
    } => !stream.timepoint
    util.global.store %results#1, @_params.bias : !stream.resource<constant>
    util.global.store %results#0, @_params.weight : !stream.resource<constant>
    util.global.store %result_timepoint, @_params.weight__timepoint : !stream.timepoint
    util.initializer.return
  }
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_1x3x4_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        %4 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
        %5 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
        %6 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
        %7 = tensor.empty() : tensor<1x3xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%7 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %9 = linalg.matmul ins(%4, %5 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%8 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %10 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%9, %6 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%7 : tensor<1x3xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %11 = arith.addf %in, %in_0 : f32
          linalg.yield %11 : f32
        } -> tensor<1x3xf32>
        flow.dispatch.tensor.store %10, %3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c48 = arith.constant 48 : index
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %c12 = arith.constant 12 : index
    %c16 = arith.constant 16 : index
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !stream.timepoint
    %_params.weight__timepoint_0 = util.global.load @_params.weight__timepoint : !stream.timepoint
    %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
    %_params.bias = util.global.load @_params.bias : !stream.resource<constant>
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
    %1 = stream.timepoint.join max(%_params.weight__timepoint, %_params.weight__timepoint_0) => !stream.timepoint
    %results, %result_timepoint = stream.async.execute await(%1) => with(%0 as %arg1: !stream.resource<external>{%c16}, %_params.weight as %arg2: !stream.resource<constant>{%c48}, %_params.bias as %arg3: !stream.resource<constant>{%c12}) -> !stream.resource<external>{%c12} {
      %4 = stream.async.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32(%arg1[%c0 to %c16 for %c16], %arg2[%c0 to %c48 for %c48], %arg3[%c0 to %c12 for %c12]) : (!stream.resource<external>{%c16}, !stream.resource<constant>{%c48}, !stream.resource<constant>{%c12}) -> !stream.resource<external>{%c12}
      stream.yield %4 : !stream.resource<external>{%c12}
    } => !stream.timepoint
    %2 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%c12}
    %3 = stream.tensor.export %2 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
    return %3 : !hal.buffer_view
  }
}


// -----// IR Dump After VerifyLoweringToAsync (iree-stream-verify-lowering-to-async) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private mutable @_params.weight__timepoint = #stream.timepoint<immediate> : !stream.timepoint
  util.global private @_params.weight : !stream.resource<constant>
  util.global private @_params.bias : !stream.resource<constant>
  util.initializer {
    %c48 = arith.constant 48 : index
    %c12 = arith.constant 12 : index
    %results:2, %result_timepoint = stream.async.execute with() -> (!stream.resource<constant>{%c48}, !stream.resource<constant>{%c12}) {
      %cst = stream.async.constant : !stream.resource<constant>{%c48} = dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>
      %cst_0 = stream.async.constant : !stream.resource<constant>{%c12} = dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>
      stream.yield %cst, %cst_0 : !stream.resource<constant>{%c48}, !stream.resource<constant>{%c12}
    } => !stream.timepoint
    util.global.store %results#1, @_params.bias : !stream.resource<constant>
    util.global.store %results#0, @_params.weight : !stream.resource<constant>
    util.global.store %result_timepoint, @_params.weight__timepoint : !stream.timepoint
    util.initializer.return
  }
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_1x3x4_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        %4 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
        %5 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
        %6 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
        %7 = tensor.empty() : tensor<1x3xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%7 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %9 = linalg.matmul ins(%4, %5 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%8 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %10 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%9, %6 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%7 : tensor<1x3xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %11 = arith.addf %in, %in_0 : f32
          linalg.yield %11 : f32
        } -> tensor<1x3xf32>
        flow.dispatch.tensor.store %10, %3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c48 = arith.constant 48 : index
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %c12 = arith.constant 12 : index
    %c16 = arith.constant 16 : index
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !stream.timepoint
    %_params.weight__timepoint_0 = util.global.load @_params.weight__timepoint : !stream.timepoint
    %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
    %_params.bias = util.global.load @_params.bias : !stream.resource<constant>
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
    %1 = stream.timepoint.join max(%_params.weight__timepoint, %_params.weight__timepoint_0) => !stream.timepoint
    %results, %result_timepoint = stream.async.execute await(%1) => with(%0 as %arg1: !stream.resource<external>{%c16}, %_params.weight as %arg2: !stream.resource<constant>{%c48}, %_params.bias as %arg3: !stream.resource<constant>{%c12}) -> !stream.resource<external>{%c12} {
      %4 = stream.async.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32(%arg1[%c0 to %c16 for %c16], %arg2[%c0 to %c48 for %c48], %arg3[%c0 to %c12 for %c12]) : (!stream.resource<external>{%c16}, !stream.resource<constant>{%c48}, !stream.resource<constant>{%c12}) -> !stream.resource<external>{%c12}
      stream.yield %4 : !stream.resource<external>{%c12}
    } => !stream.timepoint
    %2 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%c12}
    %3 = stream.tensor.export %2 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
    return %3 : !hal.buffer_view
  }
}


// -----// IR Dump After ScheduleAllocation (iree-stream-schedule-allocation) //----- //
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private mutable @_params.weight__timepoint = #stream.timepoint<immediate> : !stream.timepoint
  util.global private @_params.weight : !stream.resource<constant>
  util.global private @_params.bias : !stream.resource<constant>
  util.initializer {
    %c48 = arith.constant 48 : index
    %c12 = arith.constant 12 : index
    %results:2, %result_timepoint = stream.resource.constants : 
      !stream.resource<constant>{%c48} = dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
      !stream.resource<constant>{%c12} = dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>
      => !stream.timepoint
    %0 = stream.cmd.execute with() {
    } => !stream.timepoint
    %1 = stream.timepoint.join max(%result_timepoint, %0) => !stream.timepoint
    util.global.store %results#1, @_params.bias : !stream.resource<constant>
    util.global.store %results#0, @_params.weight : !stream.resource<constant>
    util.global.store %1, @_params.weight__timepoint : !stream.timepoint
    util.initializer.return
  }
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_1x3x4_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        %4 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
        %5 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
        %6 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
        %7 = tensor.empty() : tensor<1x3xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%7 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %9 = linalg.matmul ins(%4, %5 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%8 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %10 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%9, %6 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%7 : tensor<1x3xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %11 = arith.addf %in, %in_0 : f32
          linalg.yield %11 : f32
        } -> tensor<1x3xf32>
        flow.dispatch.tensor.store %10, %3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c48 = arith.constant 48 : index
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %c12 = arith.constant 12 : index
    %c16 = arith.constant 16 : index
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !stream.timepoint
    %_params.weight__timepoint_0 = util.global.load @_params.weight__timepoint : !stream.timepoint
    %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
    %_params.bias = util.global.load @_params.bias : !stream.resource<constant>
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
    %1 = stream.timepoint.join max(%_params.weight__timepoint, %_params.weight__timepoint_0) => !stream.timepoint
    %c0_1 = arith.constant 0 : index
    %result, %result_timepoint = stream.resource.alloca uninitialized await(%1) => !stream.resource<external>{%c12} => !stream.timepoint
    %2 = stream.timepoint.join max(%1, %result_timepoint) => !stream.timepoint
    %3 = stream.cmd.execute await(%2) => with(%0 as %arg1: !stream.resource<external>{%c16}, %_params.weight as %arg2: !stream.resource<constant>{%c48}, %_params.bias as %arg3: !stream.resource<constant>{%c12}, %result as %arg4: !stream.resource<external>{%c12}) {
      stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32 {
        ro %arg1[%c0 for %c16] : !stream.resource<external>{%c16},
        ro %arg2[%c0 for %c48] : !stream.resource<constant>{%c48},
        ro %arg3[%c0 for %c12] : !stream.resource<constant>{%c12},
        wo %arg4[%c0_1 for %c12] : !stream.resource<external>{%c12}
      }
    } => !stream.timepoint
    %4 = stream.timepoint.await %3 => %result : !stream.resource<external>{%c12}
    %5 = stream.tensor.export %4 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
    return %5 : !hal.buffer_view
  }
}


// -----// IR Dump After PackConstants (iree-stream-pack-constants) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c48 = arith.constant 48 : index
  %c0 = arith.constant 0 : index
  %c4 = arith.constant 4 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %c12 = arith.constant 12 : index
  %c16 = arith.constant 16 : index
  %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !stream.timepoint
  %_params.weight__timepoint_0 = util.global.load @_params.weight__timepoint : !stream.timepoint
  %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
  %_params.bias = util.global.load @_params.bias : !stream.resource<constant>
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
  %1 = stream.timepoint.join max(%_params.weight__timepoint, %_params.weight__timepoint_0) => !stream.timepoint
  %c0_1 = arith.constant 0 : index
  %result, %result_timepoint = stream.resource.alloca uninitialized await(%1) => !stream.resource<external>{%c12} => !stream.timepoint
  %2 = stream.timepoint.join max(%1, %result_timepoint) => !stream.timepoint
  %3 = stream.cmd.execute await(%2) => with(%0 as %arg1: !stream.resource<external>{%c16}, %_params.weight as %arg2: !stream.resource<constant>{%c48}, %_params.bias as %arg3: !stream.resource<constant>{%c12}, %result as %arg4: !stream.resource<external>{%c12}) {
    stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32 {
      ro %arg1[%c0 for %c16] : !stream.resource<external>{%c16},
      ro %arg2[%c0 for %c48] : !stream.resource<constant>{%c48},
      ro %arg3[%c0 for %c12] : !stream.resource<constant>{%c12},
      wo %arg4[%c0_1 for %c12] : !stream.resource<external>{%c12}
    }
  } => !stream.timepoint
  %4 = stream.timepoint.await %3 => %result : !stream.resource<external>{%c12}
  %5 = stream.tensor.export %4 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
  return %5 : !hal.buffer_view
}

// -----// IR Dump After PackConstants (iree-stream-pack-constants) //----- //
util.initializer {
  %c48 = arith.constant 48 : index
  %c12 = arith.constant 12 : index
  %0 = stream.timepoint.immediate => !stream.timepoint
  %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
  %c128 = arith.constant 128 : index
  %c0 = arith.constant 0 : index
  %did_map, %result = stream.resource.try_map %buffer_cst[%c0] : !util.buffer -> i1, !stream.resource<constant>{%c128}
  %1:2 = scf.if %did_map -> (!stream.timepoint, !stream.resource<constant>) {
    scf.yield %0, %result : !stream.timepoint, !stream.resource<constant>
  } else {
    %6 = stream.resource.alloc uninitialized : !stream.resource<constant>{%c128}
    %file = stream.file.constant %buffer_cst[%c0 for %c128] : !util.buffer{%c128} -> !stream.file
    %c0_i64 = arith.constant 0 : i64
    %7 = stream.file.read await(%0) => %file[%c0_i64], %6[%c0], %c128 : !stream.file -> !stream.resource<constant>{%c128} => !stream.timepoint
    scf.yield %7, %6 : !stream.timepoint, !stream.resource<constant>
  }
  %2 = stream.resource.subview %1#1[%c0] : !stream.resource<constant>{%c128} -> !stream.resource<constant>{%c48}
  %c64 = arith.constant 64 : index
  %3 = stream.resource.subview %1#1[%c64] : !stream.resource<constant>{%c128} -> !stream.resource<constant>{%c12}
  %4 = stream.cmd.execute with() {
  } => !stream.timepoint
  %5 = stream.timepoint.join max(%1#0, %4) => !stream.timepoint
  util.global.store %3, @_params.bias : !stream.resource<constant>
  util.global.store %2, @_params.weight : !stream.resource<constant>
  util.global.store %5, @_params.weight__timepoint : !stream.timepoint
  util.initializer.return
}

// -----// IR Dump After LayoutSlices (iree-stream-layout-slices) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c48 = arith.constant 48 : index
  %c0 = arith.constant 0 : index
  %c4 = arith.constant 4 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %c12 = arith.constant 12 : index
  %c16 = arith.constant 16 : index
  %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !stream.timepoint
  %_params.weight__timepoint_0 = util.global.load @_params.weight__timepoint : !stream.timepoint
  %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
  %_params.bias = util.global.load @_params.bias : !stream.resource<constant>
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
  %1 = stream.timepoint.join max(%_params.weight__timepoint, %_params.weight__timepoint_0) => !stream.timepoint
  %c0_1 = arith.constant 0 : index
  %result, %result_timepoint = stream.resource.alloca uninitialized await(%1) => !stream.resource<external>{%c12} => !stream.timepoint
  %2 = stream.timepoint.join max(%1, %result_timepoint) => !stream.timepoint
  %3 = stream.cmd.execute await(%2) => with(%0 as %arg1: !stream.resource<external>{%c16}, %_params.weight as %arg2: !stream.resource<constant>{%c48}, %_params.bias as %arg3: !stream.resource<constant>{%c12}, %result as %arg4: !stream.resource<external>{%c12}) {
    stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32 {
      ro %arg1[%c0 for %c16] : !stream.resource<external>{%c16},
      ro %arg2[%c0 for %c48] : !stream.resource<constant>{%c48},
      ro %arg3[%c0 for %c12] : !stream.resource<constant>{%c12},
      wo %arg4[%c0_1 for %c12] : !stream.resource<external>{%c12}
    }
  } => !stream.timepoint
  %4 = stream.timepoint.await %3 => %result : !stream.resource<external>{%c12}
  %5 = stream.tensor.export %4 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
  return %5 : !hal.buffer_view
}

// -----// IR Dump After LayoutSlices (iree-stream-layout-slices) //----- //
util.initializer {
  %c48 = arith.constant 48 : index
  %c12 = arith.constant 12 : index
  %0 = stream.timepoint.immediate => !stream.timepoint
  %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
  %c128 = arith.constant 128 : index
  %c0 = arith.constant 0 : index
  %did_map, %result = stream.resource.try_map %buffer_cst[%c0] : !util.buffer -> i1, !stream.resource<constant>{%c128}
  %1:2 = scf.if %did_map -> (!stream.timepoint, !stream.resource<constant>) {
    scf.yield %0, %result : !stream.timepoint, !stream.resource<constant>
  } else {
    %6 = stream.resource.alloc uninitialized : !stream.resource<constant>{%c128}
    %file = stream.file.constant %buffer_cst[%c0 for %c128] : !util.buffer{%c128} -> !stream.file
    %c0_i64 = arith.constant 0 : i64
    %7 = stream.file.read await(%0) => %file[%c0_i64], %6[%c0], %c128 : !stream.file -> !stream.resource<constant>{%c128} => !stream.timepoint
    scf.yield %7, %6 : !stream.timepoint, !stream.resource<constant>
  }
  %2 = stream.resource.subview %1#1[%c0] : !stream.resource<constant>{%c128} -> !stream.resource<constant>{%c48}
  %c64 = arith.constant 64 : index
  %3 = stream.resource.subview %1#1[%c64] : !stream.resource<constant>{%c128} -> !stream.resource<constant>{%c12}
  %4 = stream.cmd.execute with() {
  } => !stream.timepoint
  %5 = stream.timepoint.join max(%1#0, %4) => !stream.timepoint
  util.global.store %3, @_params.bias : !stream.resource<constant>
  util.global.store %2, @_params.weight : !stream.resource<constant>
  util.global.store %5, @_params.weight__timepoint : !stream.timepoint
  util.initializer.return
}

// -----// IR Dump After PropagateSubranges (iree-util-propagate-subranges) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private mutable @_params.weight__timepoint = #stream.timepoint<immediate> : !stream.timepoint
  util.global private @_params.weight : !stream.resource<constant>
  util.global private mutable @_params.weight__storage_size : index
  util.global private mutable @_params.weight__offset : index
  util.global private mutable @_params.weight__length : index
  util.global private @_params.bias : !stream.resource<constant>
  util.global private mutable @_params.bias__storage_size : index
  util.global private mutable @_params.bias__offset : index
  util.global private mutable @_params.bias__length : index
  util.initializer {
    %c0 = arith.constant 0 : index
    %c48 = arith.constant 48 : index
    %c12 = arith.constant 12 : index
    %0 = stream.timepoint.immediate => !stream.timepoint
    %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #composite_of_128b
    %c128 = arith.constant 128 : index
    %c0_0 = arith.constant 0 : index
    %did_map, %result = stream.resource.try_map %buffer_cst[%c0_0] : !util.buffer -> i1, !stream.resource<constant>{%c128}
    %1:2 = scf.if %did_map -> (!stream.timepoint, !stream.resource<constant>) {
      scf.yield %0, %result : !stream.timepoint, !stream.resource<constant>
    } else {
      %6 = stream.resource.alloc uninitialized : !stream.resource<constant>{%c128}
      %file = stream.file.constant %buffer_cst[%c0_0 for %c128] : !util.buffer{%c128} -> !stream.file
      %c0_i64 = arith.constant 0 : i64
      %7 = stream.file.read await(%0) => %file[%c0_i64], %6[%c0_0], %c128 : !stream.file -> !stream.resource<constant>{%c128} => !stream.timepoint
      scf.yield %7, %6 : !stream.timepoint, !stream.resource<constant>
    }
    %2 = stream.resource.subview %1#1[%c0_0] : !stream.resource<constant>{%c128} -> !stream.resource<constant>{%c48}
    %c64 = arith.constant 64 : index
    %3 = stream.resource.subview %1#1[%c64] : !stream.resource<constant>{%c128} -> !stream.resource<constant>{%c12}
    %4 = stream.cmd.execute with() {
    } => !stream.timepoint
    %5 = stream.timepoint.join max(%1#0, %4) => !stream.timepoint
    util.global.store %1#1, @_params.bias : !stream.resource<constant>
    util.global.store %c128, @_params.bias__storage_size : index
    util.global.store %c64, @_params.bias__offset : index
    util.global.store %c12, @_params.bias__length : index
    util.global.store %1#1, @_params.weight : !stream.resource<constant>
    util.global.store %c128, @_params.weight__storage_size : index
    util.global.store %c0_0, @_params.weight__offset : index
    util.global.store %c48, @_params.weight__length : index
    util.global.store %5, @_params.weight__timepoint : !stream.timepoint
    util.initializer.return
  }
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_1x3x4_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        %4 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
        %5 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
        %6 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
        %7 = tensor.empty() : tensor<1x3xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%7 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %9 = linalg.matmul ins(%4, %5 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%8 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %10 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%9, %6 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%7 : tensor<1x3xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %11 = arith.addf %in, %in_0 : f32
          linalg.yield %11 : f32
        } -> tensor<1x3xf32>
        flow.dispatch.tensor.store %10, %3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c48 = arith.constant 48 : index
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %c12 = arith.constant 12 : index
    %c16 = arith.constant 16 : index
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !stream.timepoint
    %_params.weight__timepoint_0 = util.global.load @_params.weight__timepoint : !stream.timepoint
    %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
    %_params.weight__storage_size = util.global.load @_params.weight__storage_size : index
    %_params.weight__offset = util.global.load @_params.weight__offset : index
    %_params.weight__length = util.global.load @_params.weight__length : index
    %0 = stream.resource.subview %_params.weight[%_params.weight__offset] : !stream.resource<constant>{%_params.weight__storage_size} -> !stream.resource<constant>{%_params.weight__length}
    %_params.bias = util.global.load @_params.bias : !stream.resource<constant>
    %_params.bias__storage_size = util.global.load @_params.bias__storage_size : index
    %_params.bias__offset = util.global.load @_params.bias__offset : index
    %_params.bias__length = util.global.load @_params.bias__length : index
    %1 = stream.resource.subview %_params.bias[%_params.bias__offset] : !stream.resource<constant>{%_params.bias__storage_size} -> !stream.resource<constant>{%_params.bias__length}
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
    %3 = stream.timepoint.join max(%_params.weight__timepoint, %_params.weight__timepoint_0) => !stream.timepoint
    %c0_1 = arith.constant 0 : index
    %result, %result_timepoint = stream.resource.alloca uninitialized await(%3) => !stream.resource<external>{%c12} => !stream.timepoint
    %4 = stream.timepoint.join max(%3, %result_timepoint) => !stream.timepoint
    %5 = stream.cmd.execute await(%4) => with(%2 as %arg1: !stream.resource<external>{%c16}, %0 as %arg2: !stream.resource<constant>{%c48}, %1 as %arg3: !stream.resource<constant>{%c12}, %result as %arg4: !stream.resource<external>{%c12}) {
      stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32 {
        ro %arg1[%c0 for %c16] : !stream.resource<external>{%c16},
        ro %arg2[%c0 for %c48] : !stream.resource<constant>{%c48},
        ro %arg3[%c0 for %c12] : !stream.resource<constant>{%c12},
        wo %arg4[%c0_1 for %c12] : !stream.resource<external>{%c12}
      }
    } => !stream.timepoint
    %6 = stream.timepoint.await %5 => %result : !stream.resource<external>{%c12}
    %7 = stream.tensor.export %6 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
    return %7 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.initializer {
  %0 = stream.timepoint.immediate => !stream.timepoint
  %c64 = arith.constant 64 : index
  %c0_i64 = arith.constant 0 : i64
  %c128 = arith.constant 128 : index
  %c0 = arith.constant 0 : index
  %c48 = arith.constant 48 : index
  %c12 = arith.constant 12 : index
  %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
  %did_map, %result = stream.resource.try_map %buffer_cst[%c0] : !util.buffer -> i1, !stream.resource<constant>{%c128}
  %1:2 = scf.if %did_map -> (!stream.timepoint, !stream.resource<constant>) {
    scf.yield %0, %result : !stream.timepoint, !stream.resource<constant>
  } else {
    %2 = stream.resource.alloc uninitialized : !stream.resource<constant>{%c128}
    %file = stream.file.constant %buffer_cst[%c0 for %c128] : !util.buffer{%c128} -> !stream.file
    %3 = stream.file.read await(%0) => %file[%c0_i64], %2[%c0], %c128 : !stream.file -> !stream.resource<constant>{%c128} => !stream.timepoint
    scf.yield %3, %2 : !stream.timepoint, !stream.resource<constant>
  }
  util.global.store %1#1, @_params.bias : !stream.resource<constant>
  util.global.store %c128, @_params.bias__storage_size : index
  util.global.store %c64, @_params.bias__offset : index
  util.global.store %c12, @_params.bias__length : index
  util.global.store %1#1, @_params.weight : !stream.resource<constant>
  util.global.store %c128, @_params.weight__storage_size : index
  util.global.store %c0, @_params.weight__offset : index
  util.global.store %c48, @_params.weight__length : index
  util.global.store %1#0, @_params.weight__timepoint : !stream.timepoint
  util.initializer.return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c48 = arith.constant 48 : index
  %c0 = arith.constant 0 : index
  %c4 = arith.constant 4 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %c12 = arith.constant 12 : index
  %c16 = arith.constant 16 : index
  %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !stream.timepoint
  %_params.weight__timepoint_0 = util.global.load @_params.weight__timepoint : !stream.timepoint
  %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
  %_params.weight__storage_size = util.global.load @_params.weight__storage_size : index
  %_params.weight__offset = util.global.load @_params.weight__offset : index
  %_params.bias = util.global.load @_params.bias : !stream.resource<constant>
  %_params.bias__storage_size = util.global.load @_params.bias__storage_size : index
  %_params.bias__offset = util.global.load @_params.bias__offset : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
  %1 = stream.timepoint.join max(%_params.weight__timepoint, %_params.weight__timepoint_0) => !stream.timepoint
  %result, %result_timepoint = stream.resource.alloca uninitialized await(%1) => !stream.resource<external>{%c12} => !stream.timepoint
  %2 = stream.timepoint.join max(%_params.weight__timepoint, %_params.weight__timepoint_0, %result_timepoint) => !stream.timepoint
  %3 = stream.cmd.execute await(%2) => with(%0 as %arg1: !stream.resource<external>{%c16}, %_params.weight as %arg2: !stream.resource<constant>{%_params.weight__storage_size}, %_params.bias as %arg3: !stream.resource<constant>{%_params.bias__storage_size}, %result as %arg4: !stream.resource<external>{%c12}) {
    stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32 {
      ro %arg1[%c0 for %c16] : !stream.resource<external>{%c16},
      ro %arg2[%_params.weight__offset for %c48] : !stream.resource<constant>{%_params.weight__storage_size},
      ro %arg3[%_params.bias__offset for %c12] : !stream.resource<constant>{%_params.bias__storage_size},
      wo %arg4[%c0 for %c12] : !stream.resource<external>{%c12}
    }
  } => !stream.timepoint
  %4 = stream.timepoint.await %3 => %result : !stream.resource<external>{%c12}
  %5 = stream.tensor.export %4 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
  return %5 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.initializer {
  %0 = stream.timepoint.immediate => !stream.timepoint
  %c64 = arith.constant 64 : index
  %c0_i64 = arith.constant 0 : i64
  %c128 = arith.constant 128 : index
  %c0 = arith.constant 0 : index
  %c48 = arith.constant 48 : index
  %c12 = arith.constant 12 : index
  %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
  %did_map, %result = stream.resource.try_map %buffer_cst[%c0] : !util.buffer -> i1, !stream.resource<constant>{%c128}
  %1:2 = scf.if %did_map -> (!stream.timepoint, !stream.resource<constant>) {
    scf.yield %0, %result : !stream.timepoint, !stream.resource<constant>
  } else {
    %2 = stream.resource.alloc uninitialized : !stream.resource<constant>{%c128}
    %file = stream.file.constant %buffer_cst[%c0 for %c128] : !util.buffer{%c128} -> !stream.file
    %3 = stream.file.read await(%0) => %file[%c0_i64], %2[%c0], %c128 : !stream.file -> !stream.resource<constant>{%c128} => !stream.timepoint
    scf.yield %3, %2 : !stream.timepoint, !stream.resource<constant>
  }
  util.global.store %1#1, @_params.bias : !stream.resource<constant>
  util.global.store %c128, @_params.bias__storage_size : index
  util.global.store %c64, @_params.bias__offset : index
  util.global.store %c12, @_params.bias__length : index
  util.global.store %1#1, @_params.weight : !stream.resource<constant>
  util.global.store %c128, @_params.weight__storage_size : index
  util.global.store %c0, @_params.weight__offset : index
  util.global.store %c48, @_params.weight__length : index
  util.global.store %1#0, @_params.weight__timepoint : !stream.timepoint
  util.initializer.return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c48 = arith.constant 48 : index
  %c0 = arith.constant 0 : index
  %c4 = arith.constant 4 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %c12 = arith.constant 12 : index
  %c16 = arith.constant 16 : index
  %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !stream.timepoint
  %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
  %_params.weight__storage_size = util.global.load @_params.weight__storage_size : index
  %_params.weight__offset = util.global.load @_params.weight__offset : index
  %_params.bias = util.global.load @_params.bias : !stream.resource<constant>
  %_params.bias__storage_size = util.global.load @_params.bias__storage_size : index
  %_params.bias__offset = util.global.load @_params.bias__offset : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
  %1 = stream.timepoint.join max(%_params.weight__timepoint, %_params.weight__timepoint) => !stream.timepoint
  %result, %result_timepoint = stream.resource.alloca uninitialized await(%1) => !stream.resource<external>{%c12} => !stream.timepoint
  %2 = stream.timepoint.join max(%_params.weight__timepoint, %_params.weight__timepoint, %result_timepoint) => !stream.timepoint
  %3 = stream.cmd.execute await(%2) => with(%0 as %arg1: !stream.resource<external>{%c16}, %_params.weight as %arg2: !stream.resource<constant>{%_params.weight__storage_size}, %_params.bias as %arg3: !stream.resource<constant>{%_params.bias__storage_size}, %result as %arg4: !stream.resource<external>{%c12}) {
    stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32 {
      ro %arg1[%c0 for %c16] : !stream.resource<external>{%c16},
      ro %arg2[%_params.weight__offset for %c48] : !stream.resource<constant>{%_params.weight__storage_size},
      ro %arg3[%_params.bias__offset for %c12] : !stream.resource<constant>{%_params.bias__storage_size},
      wo %arg4[%c0 for %c12] : !stream.resource<external>{%c12}
    }
  } => !stream.timepoint
  %4 = stream.timepoint.await %3 => %result : !stream.resource<external>{%c12}
  %5 = stream.tensor.export %4 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
  return %5 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.initializer {
  %0 = stream.timepoint.immediate => !stream.timepoint
  %c64 = arith.constant 64 : index
  %c0_i64 = arith.constant 0 : i64
  %c128 = arith.constant 128 : index
  %c0 = arith.constant 0 : index
  %c48 = arith.constant 48 : index
  %c12 = arith.constant 12 : index
  %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
  %did_map, %result = stream.resource.try_map %buffer_cst[%c0] : !util.buffer -> i1, !stream.resource<constant>{%c128}
  %1:2 = scf.if %did_map -> (!stream.timepoint, !stream.resource<constant>) {
    scf.yield %0, %result : !stream.timepoint, !stream.resource<constant>
  } else {
    %2 = stream.resource.alloc uninitialized : !stream.resource<constant>{%c128}
    %file = stream.file.constant %buffer_cst[%c0 for %c128] : !util.buffer{%c128} -> !stream.file
    %3 = stream.file.read await(%0) => %file[%c0_i64], %2[%c0], %c128 : !stream.file -> !stream.resource<constant>{%c128} => !stream.timepoint
    scf.yield %3, %2 : !stream.timepoint, !stream.resource<constant>
  }
  util.global.store %1#1, @_params.bias : !stream.resource<constant>
  util.global.store %c12, @_params.bias__length : index
  util.global.store %c64, @_params.bias__offset : index
  util.global.store %c128, @_params.bias__storage_size : index
  util.global.store %1#1, @_params.weight : !stream.resource<constant>
  util.global.store %c48, @_params.weight__length : index
  util.global.store %c0, @_params.weight__offset : index
  util.global.store %c128, @_params.weight__storage_size : index
  util.global.store %1#0, @_params.weight__timepoint : !stream.timepoint
  util.initializer.return
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !stream.timepoint
  %_params.weight__storage_size = util.global.load @_params.weight__storage_size : index
  %_params.weight__offset = util.global.load @_params.weight__offset : index
  %_params.bias__storage_size = util.global.load @_params.bias__storage_size : index
  %_params.bias__offset = util.global.load @_params.bias__offset : index
  %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
  %_params.bias = util.global.load @_params.bias : !stream.resource<constant>
  %c48 = arith.constant 48 : index
  %c0 = arith.constant 0 : index
  %c4 = arith.constant 4 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %c12 = arith.constant 12 : index
  %c16 = arith.constant 16 : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
  %1 = stream.timepoint.join max(%_params.weight__timepoint, %_params.weight__timepoint) => !stream.timepoint
  %result, %result_timepoint = stream.resource.alloca uninitialized await(%1) => !stream.resource<external>{%c12} => !stream.timepoint
  %2 = stream.timepoint.join max(%_params.weight__timepoint, %_params.weight__timepoint, %result_timepoint) => !stream.timepoint
  %3 = stream.cmd.execute await(%2) => with(%0 as %arg1: !stream.resource<external>{%c16}, %_params.weight as %arg2: !stream.resource<constant>{%_params.weight__storage_size}, %_params.bias as %arg3: !stream.resource<constant>{%_params.bias__storage_size}, %result as %arg4: !stream.resource<external>{%c12}) {
    stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32 {
      ro %arg1[%c0 for %c16] : !stream.resource<external>{%c16},
      ro %arg2[%_params.weight__offset for %c48] : !stream.resource<constant>{%_params.weight__storage_size},
      ro %arg3[%_params.bias__offset for %c12] : !stream.resource<constant>{%_params.bias__storage_size},
      wo %arg4[%c0 for %c12] : !stream.resource<external>{%c12}
    }
  } => !stream.timepoint
  %4 = stream.timepoint.await %3 => %result : !stream.resource<external>{%c12}
  %5 = stream.tensor.export %4 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
  return %5 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private mutable @_params.weight__timepoint = #stream.timepoint<immediate> : !stream.timepoint
  util.global private @_params.weight : !stream.resource<constant>
  util.global private mutable @_params.weight__storage_size = 128 : index
  util.global private mutable @_params.weight__offset = 0 : index
  util.global private mutable @_params.weight__length = 48 : index
  util.global private @_params.bias : !stream.resource<constant>
  util.global private mutable @_params.bias__storage_size = 128 : index
  util.global private mutable @_params.bias__offset = 64 : index
  util.global private mutable @_params.bias__length = 12 : index
  util.initializer {
    %0 = stream.timepoint.immediate => !stream.timepoint
    %c0_i64 = arith.constant 0 : i64
    %c128 = arith.constant 128 : index
    %c0 = arith.constant 0 : index
    %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #composite_of_128b
    %did_map, %result = stream.resource.try_map %buffer_cst[%c0] : !util.buffer -> i1, !stream.resource<constant>{%c128}
    %1:2 = scf.if %did_map -> (!stream.timepoint, !stream.resource<constant>) {
      scf.yield %0, %result : !stream.timepoint, !stream.resource<constant>
    } else {
      %2 = stream.resource.alloc uninitialized : !stream.resource<constant>{%c128}
      %file = stream.file.constant %buffer_cst[%c0 for %c128] : !util.buffer{%c128} -> !stream.file
      %3 = stream.file.read await(%0) => %file[%c0_i64], %2[%c0], %c128 : !stream.file -> !stream.resource<constant>{%c128} => !stream.timepoint
      scf.yield %3, %2 : !stream.timepoint, !stream.resource<constant>
    }
    util.global.store %1#1, @_params.bias : !stream.resource<constant>
    util.global.store %1#1, @_params.weight : !stream.resource<constant>
    util.global.store %1#0, @_params.weight__timepoint : !stream.timepoint
    util.initializer.return
  }
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_1x3x4_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        %4 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
        %5 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
        %6 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
        %7 = tensor.empty() : tensor<1x3xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%7 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %9 = linalg.matmul ins(%4, %5 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%8 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %10 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%9, %6 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%7 : tensor<1x3xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %11 = arith.addf %in, %in_0 : f32
          linalg.yield %11 : f32
        } -> tensor<1x3xf32>
        flow.dispatch.tensor.store %10, %3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c16 = arith.constant 16 : index
    %c12 = arith.constant 12 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c48 = arith.constant 48 : index
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !stream.timepoint
    %_params.weight__storage_size = util.global.load @_params.weight__storage_size : index
    %_params.weight__offset = util.global.load @_params.weight__offset : index
    %_params.bias__storage_size = util.global.load @_params.bias__storage_size : index
    %_params.bias__offset = util.global.load @_params.bias__offset : index
    %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
    %_params.bias = util.global.load @_params.bias : !stream.resource<constant>
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
    %result, %result_timepoint = stream.resource.alloca uninitialized await(%_params.weight__timepoint) => !stream.resource<external>{%c12} => !stream.timepoint
    %1 = stream.timepoint.join max(%_params.weight__timepoint, %result_timepoint) => !stream.timepoint
    %2 = stream.cmd.execute await(%1) => with(%0 as %arg1: !stream.resource<external>{%c16}, %_params.weight as %arg2: !stream.resource<constant>{%_params.weight__storage_size}, %_params.bias as %arg3: !stream.resource<constant>{%_params.bias__storage_size}, %result as %arg4: !stream.resource<external>{%c12}) {
      stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32 {
        ro %arg1[%c0 for %c16] : !stream.resource<external>{%c16},
        ro %arg2[%_params.weight__offset for %c48] : !stream.resource<constant>{%_params.weight__storage_size},
        ro %arg3[%_params.bias__offset for %c12] : !stream.resource<constant>{%_params.bias__storage_size},
        wo %arg4[%c0 for %c12] : !stream.resource<external>{%c12}
      }
    } => !stream.timepoint
    %3 = stream.timepoint.await %2 => %result : !stream.resource<external>{%c12}
    %4 = stream.tensor.export %3 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
    return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private mutable @_params.weight__timepoint = #stream.timepoint<immediate> : !stream.timepoint
  util.global private @_params.weight : !stream.resource<constant>
  util.global private @_params.bias : !stream.resource<constant>
  util.initializer {
    %0 = stream.timepoint.immediate => !stream.timepoint
    %c0_i64 = arith.constant 0 : i64
    %c128 = arith.constant 128 : index
    %c0 = arith.constant 0 : index
    %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #composite_of_128b
    %did_map, %result = stream.resource.try_map %buffer_cst[%c0] : !util.buffer -> i1, !stream.resource<constant>{%c128}
    %1:2 = scf.if %did_map -> (!stream.timepoint, !stream.resource<constant>) {
      scf.yield %0, %result : !stream.timepoint, !stream.resource<constant>
    } else {
      %2 = stream.resource.alloc uninitialized : !stream.resource<constant>{%c128}
      %file = stream.file.constant %buffer_cst[%c0 for %c128] : !util.buffer{%c128} -> !stream.file
      %3 = stream.file.read await(%0) => %file[%c0_i64], %2[%c0], %c128 : !stream.file -> !stream.resource<constant>{%c128} => !stream.timepoint
      scf.yield %3, %2 : !stream.timepoint, !stream.resource<constant>
    }
    util.global.store %1#1, @_params.bias : !stream.resource<constant>
    util.global.store %1#1, @_params.weight : !stream.resource<constant>
    util.global.store %1#0, @_params.weight__timepoint : !stream.timepoint
    util.initializer.return
  }
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_1x3x4_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        %4 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
        %5 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
        %6 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
        %7 = tensor.empty() : tensor<1x3xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%7 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %9 = linalg.matmul ins(%4, %5 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%8 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %10 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%9, %6 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%7 : tensor<1x3xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %11 = arith.addf %in, %in_0 : f32
          linalg.yield %11 : f32
        } -> tensor<1x3xf32>
        flow.dispatch.tensor.store %10, %3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c64 = arith.constant 64 : index
    %c128 = arith.constant 128 : index
    %c16 = arith.constant 16 : index
    %c12 = arith.constant 12 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c48 = arith.constant 48 : index
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !stream.timepoint
    %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
    %_params.bias = util.global.load @_params.bias : !stream.resource<constant>
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
    %result, %result_timepoint = stream.resource.alloca uninitialized await(%_params.weight__timepoint) => !stream.resource<external>{%c12} => !stream.timepoint
    %1 = stream.timepoint.join max(%_params.weight__timepoint, %result_timepoint) => !stream.timepoint
    %2 = stream.cmd.execute await(%1) => with(%0 as %arg1: !stream.resource<external>{%c16}, %_params.weight as %arg2: !stream.resource<constant>{%c128}, %_params.bias as %arg3: !stream.resource<constant>{%c128}, %result as %arg4: !stream.resource<external>{%c12}) {
      stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32 {
        ro %arg1[%c0 for %c16] : !stream.resource<external>{%c16},
        ro %arg2[%c0 for %c48] : !stream.resource<constant>{%c128},
        ro %arg3[%c64 for %c12] : !stream.resource<constant>{%c128},
        wo %arg4[%c0 for %c12] : !stream.resource<external>{%c12}
      }
    } => !stream.timepoint
    %3 = stream.timepoint.await %2 => %result : !stream.resource<external>{%c12}
    %4 = stream.tensor.export %3 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
    return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private mutable @_params.weight__timepoint = #stream.timepoint<immediate> : !stream.timepoint
  util.global private @_params.weight : !stream.resource<constant>
  util.initializer {
    %0 = stream.timepoint.immediate => !stream.timepoint
    %c0_i64 = arith.constant 0 : i64
    %c128 = arith.constant 128 : index
    %c0 = arith.constant 0 : index
    %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #composite_of_128b
    %did_map, %result = stream.resource.try_map %buffer_cst[%c0] : !util.buffer -> i1, !stream.resource<constant>{%c128}
    %1:2 = scf.if %did_map -> (!stream.timepoint, !stream.resource<constant>) {
      scf.yield %0, %result : !stream.timepoint, !stream.resource<constant>
    } else {
      %2 = stream.resource.alloc uninitialized : !stream.resource<constant>{%c128}
      %file = stream.file.constant %buffer_cst[%c0 for %c128] : !util.buffer{%c128} -> !stream.file
      %3 = stream.file.read await(%0) => %file[%c0_i64], %2[%c0], %c128 : !stream.file -> !stream.resource<constant>{%c128} => !stream.timepoint
      scf.yield %3, %2 : !stream.timepoint, !stream.resource<constant>
    }
    util.global.store %1#1, @_params.weight : !stream.resource<constant>
    util.global.store %1#0, @_params.weight__timepoint : !stream.timepoint
    util.initializer.return
  }
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_1x3x4_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        %4 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
        %5 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
        %6 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
        %7 = tensor.empty() : tensor<1x3xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%7 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %9 = linalg.matmul ins(%4, %5 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%8 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %10 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%9, %6 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%7 : tensor<1x3xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %11 = arith.addf %in, %in_0 : f32
          linalg.yield %11 : f32
        } -> tensor<1x3xf32>
        flow.dispatch.tensor.store %10, %3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c64 = arith.constant 64 : index
    %c128 = arith.constant 128 : index
    %c16 = arith.constant 16 : index
    %c12 = arith.constant 12 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c48 = arith.constant 48 : index
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !stream.timepoint
    %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
    %_params.weight_0 = util.global.load @_params.weight : !stream.resource<constant>
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
    %result, %result_timepoint = stream.resource.alloca uninitialized await(%_params.weight__timepoint) => !stream.resource<external>{%c12} => !stream.timepoint
    %1 = stream.timepoint.join max(%_params.weight__timepoint, %result_timepoint) => !stream.timepoint
    %2 = stream.cmd.execute await(%1) => with(%0 as %arg1: !stream.resource<external>{%c16}, %_params.weight as %arg2: !stream.resource<constant>{%c128}, %_params.weight_0 as %arg3: !stream.resource<constant>{%c128}, %result as %arg4: !stream.resource<external>{%c12}) {
      stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32 {
        ro %arg1[%c0 for %c16] : !stream.resource<external>{%c16},
        ro %arg2[%c0 for %c48] : !stream.resource<constant>{%c128},
        ro %arg3[%c64 for %c12] : !stream.resource<constant>{%c128},
        wo %arg4[%c0 for %c12] : !stream.resource<external>{%c12}
      }
    } => !stream.timepoint
    %3 = stream.timepoint.await %2 => %result : !stream.resource<external>{%c12}
    %4 = stream.tensor.export %3 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
    return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private mutable @_params.weight__timepoint = #stream.timepoint<immediate> : !stream.timepoint
  util.global private @_params.weight : !stream.resource<constant>
  util.initializer {
    %0 = stream.timepoint.immediate => !stream.timepoint
    %c0_i64 = arith.constant 0 : i64
    %c128 = arith.constant 128 : index
    %c0 = arith.constant 0 : index
    %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #composite_of_128b
    %did_map, %result = stream.resource.try_map %buffer_cst[%c0] : !util.buffer -> i1, !stream.resource<constant>{%c128}
    %1:2 = scf.if %did_map -> (!stream.timepoint, !stream.resource<constant>) {
      scf.yield %0, %result : !stream.timepoint, !stream.resource<constant>
    } else {
      %2 = stream.resource.alloc uninitialized : !stream.resource<constant>{%c128}
      %file = stream.file.constant %buffer_cst[%c0 for %c128] : !util.buffer{%c128} -> !stream.file
      %3 = stream.file.read await(%0) => %file[%c0_i64], %2[%c0], %c128 : !stream.file -> !stream.resource<constant>{%c128} => !stream.timepoint
      scf.yield %3, %2 : !stream.timepoint, !stream.resource<constant>
    }
    util.global.store %1#1, @_params.weight : !stream.resource<constant>
    util.global.store %1#0, @_params.weight__timepoint : !stream.timepoint
    util.initializer.return
  }
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_1x3x4_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        %4 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
        %5 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
        %6 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
        %7 = tensor.empty() : tensor<1x3xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%7 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %9 = linalg.matmul ins(%4, %5 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%8 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %10 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%9, %6 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%7 : tensor<1x3xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %11 = arith.addf %in, %in_0 : f32
          linalg.yield %11 : f32
        } -> tensor<1x3xf32>
        flow.dispatch.tensor.store %10, %3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c64 = arith.constant 64 : index
    %c128 = arith.constant 128 : index
    %c16 = arith.constant 16 : index
    %c12 = arith.constant 12 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c48 = arith.constant 48 : index
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !stream.timepoint
    %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
    %_params.weight_0 = util.global.load @_params.weight : !stream.resource<constant>
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
    %result, %result_timepoint = stream.resource.alloca uninitialized await(%_params.weight__timepoint) => !stream.resource<external>{%c12} => !stream.timepoint
    %1 = stream.timepoint.join max(%_params.weight__timepoint, %result_timepoint) => !stream.timepoint
    %2 = stream.cmd.execute await(%1) => with(%0 as %arg1: !stream.resource<external>{%c16}, %_params.weight as %arg2: !stream.resource<constant>{%c128}, %_params.weight_0 as %arg3: !stream.resource<constant>{%c128}, %result as %arg4: !stream.resource<external>{%c12}) {
      stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32 {
        ro %arg1[%c0 for %c16] : !stream.resource<external>{%c16},
        ro %arg2[%c0 for %c48] : !stream.resource<constant>{%c128},
        ro %arg3[%c64 for %c12] : !stream.resource<constant>{%c128},
        wo %arg4[%c0 for %c12] : !stream.resource<external>{%c12}
      }
    } => !stream.timepoint
    %3 = stream.timepoint.await %2 => %result : !stream.resource<external>{%c12}
    %4 = stream.tensor.export %3 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
    return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After VerifyLoweringToCmd (iree-stream-verify-lowering-to-cmd) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private mutable @_params.weight__timepoint = #stream.timepoint<immediate> : !stream.timepoint
  util.global private @_params.weight : !stream.resource<constant>
  util.initializer {
    %0 = stream.timepoint.immediate => !stream.timepoint
    %c0_i64 = arith.constant 0 : i64
    %c128 = arith.constant 128 : index
    %c0 = arith.constant 0 : index
    %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #composite_of_128b
    %did_map, %result = stream.resource.try_map %buffer_cst[%c0] : !util.buffer -> i1, !stream.resource<constant>{%c128}
    %1:2 = scf.if %did_map -> (!stream.timepoint, !stream.resource<constant>) {
      scf.yield %0, %result : !stream.timepoint, !stream.resource<constant>
    } else {
      %2 = stream.resource.alloc uninitialized : !stream.resource<constant>{%c128}
      %file = stream.file.constant %buffer_cst[%c0 for %c128] : !util.buffer{%c128} -> !stream.file
      %3 = stream.file.read await(%0) => %file[%c0_i64], %2[%c0], %c128 : !stream.file -> !stream.resource<constant>{%c128} => !stream.timepoint
      scf.yield %3, %2 : !stream.timepoint, !stream.resource<constant>
    }
    util.global.store %1#1, @_params.weight : !stream.resource<constant>
    util.global.store %1#0, @_params.weight__timepoint : !stream.timepoint
    util.initializer.return
  }
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_1x3x4_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        %4 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
        %5 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
        %6 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
        %7 = tensor.empty() : tensor<1x3xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%7 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %9 = linalg.matmul ins(%4, %5 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%8 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %10 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%9, %6 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%7 : tensor<1x3xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %11 = arith.addf %in, %in_0 : f32
          linalg.yield %11 : f32
        } -> tensor<1x3xf32>
        flow.dispatch.tensor.store %10, %3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c64 = arith.constant 64 : index
    %c128 = arith.constant 128 : index
    %c16 = arith.constant 16 : index
    %c12 = arith.constant 12 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c48 = arith.constant 48 : index
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !stream.timepoint
    %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
    %_params.weight_0 = util.global.load @_params.weight : !stream.resource<constant>
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
    %result, %result_timepoint = stream.resource.alloca uninitialized await(%_params.weight__timepoint) => !stream.resource<external>{%c12} => !stream.timepoint
    %1 = stream.timepoint.join max(%_params.weight__timepoint, %result_timepoint) => !stream.timepoint
    %2 = stream.cmd.execute await(%1) => with(%0 as %arg1: !stream.resource<external>{%c16}, %_params.weight as %arg2: !stream.resource<constant>{%c128}, %_params.weight_0 as %arg3: !stream.resource<constant>{%c128}, %result as %arg4: !stream.resource<external>{%c12}) {
      stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32 {
        ro %arg1[%c0 for %c16] : !stream.resource<external>{%c16},
        ro %arg2[%c0 for %c48] : !stream.resource<constant>{%c128},
        ro %arg3[%c64 for %c12] : !stream.resource<constant>{%c128},
        wo %arg4[%c0 for %c12] : !stream.resource<external>{%c12}
      }
    } => !stream.timepoint
    %3 = stream.timepoint.await %2 => %result : !stream.resource<external>{%c12}
    %4 = stream.tensor.export %3 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
    return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.initializer {
  %0 = stream.timepoint.immediate => !stream.timepoint
  %c0_i64 = arith.constant 0 : i64
  %c128 = arith.constant 128 : index
  %c0 = arith.constant 0 : index
  %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
  %did_map, %result = stream.resource.try_map %buffer_cst[%c0] : !util.buffer -> i1, !stream.resource<constant>{%c128}
  %1:2 = scf.if %did_map -> (!stream.timepoint, !stream.resource<constant>) {
    scf.yield %0, %result : !stream.timepoint, !stream.resource<constant>
  } else {
    %2 = stream.resource.alloc uninitialized : !stream.resource<constant>{%c128}
    %file = stream.file.constant %buffer_cst[%c0 for %c128] : !util.buffer{%c128} -> !stream.file
    %3 = stream.file.read await(%0) => %file[%c0_i64], %2[%c0], %c128 : !stream.file -> !stream.resource<constant>{%c128} => !stream.timepoint
    scf.yield %3, %2 : !stream.timepoint, !stream.resource<constant>
  }
  util.global.store %1#1, @_params.weight : !stream.resource<constant>
  util.global.store %1#0, @_params.weight__timepoint : !stream.timepoint
  util.initializer.return
}

// -----// IR Dump After CSE (cse) //----- //
util.initializer {
  %0 = stream.timepoint.immediate => !stream.timepoint
  %c0_i64 = arith.constant 0 : i64
  %c128 = arith.constant 128 : index
  %c0 = arith.constant 0 : index
  %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
  %did_map, %result = stream.resource.try_map %buffer_cst[%c0] : !util.buffer -> i1, !stream.resource<constant>{%c128}
  %1:2 = scf.if %did_map -> (!stream.timepoint, !stream.resource<constant>) {
    scf.yield %0, %result : !stream.timepoint, !stream.resource<constant>
  } else {
    %2 = stream.resource.alloc uninitialized : !stream.resource<constant>{%c128}
    %file = stream.file.constant %buffer_cst[%c0 for %c128] : !util.buffer{%c128} -> !stream.file
    %3 = stream.file.read await(%0) => %file[%c0_i64], %2[%c0], %c128 : !stream.file -> !stream.resource<constant>{%c128} => !stream.timepoint
    scf.yield %3, %2 : !stream.timepoint, !stream.resource<constant>
  }
  util.global.store %1#1, @_params.weight : !stream.resource<constant>
  util.global.store %1#0, @_params.weight__timepoint : !stream.timepoint
  util.initializer.return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c64 = arith.constant 64 : index
  %c128 = arith.constant 128 : index
  %c16 = arith.constant 16 : index
  %c12 = arith.constant 12 : index
  %c553648160_i32 = arith.constant 553648160 : i32
  %c1_i32 = arith.constant 1 : i32
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %c48 = arith.constant 48 : index
  %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !stream.timepoint
  %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
  %_params.weight_0 = util.global.load @_params.weight : !stream.resource<constant>
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
  %result, %result_timepoint = stream.resource.alloca uninitialized await(%_params.weight__timepoint) => !stream.resource<external>{%c12} => !stream.timepoint
  %1 = stream.timepoint.join max(%_params.weight__timepoint, %result_timepoint) => !stream.timepoint
  %2 = stream.cmd.execute await(%1) => with(%0 as %arg1: !stream.resource<external>{%c16}, %_params.weight as %arg2: !stream.resource<constant>{%c128}, %_params.weight_0 as %arg3: !stream.resource<constant>{%c128}, %result as %arg4: !stream.resource<external>{%c12}) {
    stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32 {
      ro %arg1[%c0 for %c16] : !stream.resource<external>{%c16},
      ro %arg2[%c0 for %c48] : !stream.resource<constant>{%c128},
      ro %arg3[%c64 for %c12] : !stream.resource<constant>{%c128},
      wo %arg4[%c0 for %c12] : !stream.resource<external>{%c12}
    }
  } => !stream.timepoint
  %3 = stream.timepoint.await %2 => %result : !stream.resource<external>{%c12}
  %4 = stream.tensor.export %3 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
  return %4 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.initializer {
  %0 = stream.timepoint.immediate => !stream.timepoint
  %c0_i64 = arith.constant 0 : i64
  %c128 = arith.constant 128 : index
  %c0 = arith.constant 0 : index
  %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
  %did_map, %result = stream.resource.try_map %buffer_cst[%c0] : !util.buffer -> i1, !stream.resource<constant>{%c128}
  %1:2 = scf.if %did_map -> (!stream.timepoint, !stream.resource<constant>) {
    scf.yield %0, %result : !stream.timepoint, !stream.resource<constant>
  } else {
    %2 = stream.resource.alloc uninitialized : !stream.resource<constant>{%c128}
    %file = stream.file.constant %buffer_cst[%c0 for %c128] : !util.buffer{%c128} -> !stream.file
    %3 = stream.file.read await(%0) => %file[%c0_i64], %2[%c0], %c128 : !stream.file -> !stream.resource<constant>{%c128} => !stream.timepoint
    scf.yield %3, %2 : !stream.timepoint, !stream.resource<constant>
  }
  util.global.store %1#1, @_params.weight : !stream.resource<constant>
  util.global.store %1#0, @_params.weight__timepoint : !stream.timepoint
  util.initializer.return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c64 = arith.constant 64 : index
  %c128 = arith.constant 128 : index
  %c16 = arith.constant 16 : index
  %c12 = arith.constant 12 : index
  %c553648160_i32 = arith.constant 553648160 : i32
  %c1_i32 = arith.constant 1 : i32
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %c48 = arith.constant 48 : index
  %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !stream.timepoint
  %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
  %result, %result_timepoint = stream.resource.alloca uninitialized await(%_params.weight__timepoint) => !stream.resource<external>{%c12} => !stream.timepoint
  %1 = stream.timepoint.join max(%_params.weight__timepoint, %result_timepoint) => !stream.timepoint
  %2 = stream.cmd.execute await(%1) => with(%0 as %arg1: !stream.resource<external>{%c16}, %_params.weight as %arg2: !stream.resource<constant>{%c128}, %_params.weight as %arg3: !stream.resource<constant>{%c128}, %result as %arg4: !stream.resource<external>{%c12}) {
    stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32 {
      ro %arg1[%c0 for %c16] : !stream.resource<external>{%c16},
      ro %arg2[%c0 for %c48] : !stream.resource<constant>{%c128},
      ro %arg3[%c64 for %c12] : !stream.resource<constant>{%c128},
      wo %arg4[%c0 for %c12] : !stream.resource<external>{%c12}
    }
  } => !stream.timepoint
  %3 = stream.timepoint.await %2 => %result : !stream.resource<external>{%c12}
  %4 = stream.tensor.export %3 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
  return %4 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !stream.timepoint
  %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
  %c64 = arith.constant 64 : index
  %c128 = arith.constant 128 : index
  %c16 = arith.constant 16 : index
  %c12 = arith.constant 12 : index
  %c553648160_i32 = arith.constant 553648160 : i32
  %c1_i32 = arith.constant 1 : i32
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %c48 = arith.constant 48 : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
  %result, %result_timepoint = stream.resource.alloca uninitialized await(%_params.weight__timepoint) => !stream.resource<external>{%c12} => !stream.timepoint
  %1 = stream.timepoint.join max(%_params.weight__timepoint, %result_timepoint) => !stream.timepoint
  %2 = stream.cmd.execute await(%1) => with(%0 as %arg1: !stream.resource<external>{%c16}, %_params.weight as %arg2: !stream.resource<constant>{%c128}, %_params.weight as %arg3: !stream.resource<constant>{%c128}, %result as %arg4: !stream.resource<external>{%c12}) {
    stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32 {
      ro %arg1[%c0 for %c16] : !stream.resource<external>{%c16},
      ro %arg2[%c0 for %c48] : !stream.resource<constant>{%c128},
      ro %arg3[%c64 for %c12] : !stream.resource<constant>{%c128},
      wo %arg4[%c0 for %c12] : !stream.resource<external>{%c12}
    }
  } => !stream.timepoint
  %3 = stream.timepoint.await %2 => %result : !stream.resource<external>{%c12}
  %4 = stream.tensor.export %3 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
  return %4 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private mutable @_params.weight__timepoint = #stream.timepoint<immediate> : !stream.timepoint
  util.global private @_params.weight : !stream.resource<constant>
  util.initializer {
    %0 = stream.timepoint.immediate => !stream.timepoint
    %c0_i64 = arith.constant 0 : i64
    %c128 = arith.constant 128 : index
    %c0 = arith.constant 0 : index
    %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #composite_of_128b
    %did_map, %result = stream.resource.try_map %buffer_cst[%c0] : !util.buffer -> i1, !stream.resource<constant>{%c128}
    %1:2 = scf.if %did_map -> (!stream.timepoint, !stream.resource<constant>) {
      scf.yield %0, %result : !stream.timepoint, !stream.resource<constant>
    } else {
      %2 = stream.resource.alloc uninitialized : !stream.resource<constant>{%c128}
      %file = stream.file.constant %buffer_cst[%c0 for %c128] : !util.buffer{%c128} -> !stream.file
      %3 = stream.file.read await(%0) => %file[%c0_i64], %2[%c0], %c128 : !stream.file -> !stream.resource<constant>{%c128} => !stream.timepoint
      scf.yield %3, %2 : !stream.timepoint, !stream.resource<constant>
    }
    util.global.store %1#1, @_params.weight : !stream.resource<constant>
    util.global.store %1#0, @_params.weight__timepoint : !stream.timepoint
    util.initializer.return
  }
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_1x3x4_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        %4 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
        %5 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
        %6 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
        %7 = tensor.empty() : tensor<1x3xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%7 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %9 = linalg.matmul ins(%4, %5 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%8 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %10 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%9, %6 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%7 : tensor<1x3xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %11 = arith.addf %in, %in_0 : f32
          linalg.yield %11 : f32
        } -> tensor<1x3xf32>
        flow.dispatch.tensor.store %10, %3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c48 = arith.constant 48 : index
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %c12 = arith.constant 12 : index
    %c16 = arith.constant 16 : index
    %c128 = arith.constant 128 : index
    %c64 = arith.constant 64 : index
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !stream.timepoint
    %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
    %result, %result_timepoint = stream.resource.alloca uninitialized await(%_params.weight__timepoint) => !stream.resource<external>{%c12} => !stream.timepoint
    %1 = stream.timepoint.join max(%_params.weight__timepoint, %result_timepoint) => !stream.timepoint
    %2 = stream.cmd.execute await(%1) => with(%0 as %arg1: !stream.resource<external>{%c16}, %_params.weight as %arg2: !stream.resource<constant>{%c128}, %result as %arg3: !stream.resource<external>{%c12}) {
      stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32 {
        ro %arg1[%c0 for %c16] : !stream.resource<external>{%c16},
        ro %arg2[%c0 for %c48] : !stream.resource<constant>{%c128},
        ro %arg2[%c64 for %c12] : !stream.resource<constant>{%c128},
        wo %arg3[%c0 for %c12] : !stream.resource<external>{%c12}
      }
    } => !stream.timepoint
    %3 = stream.timepoint.await %2 => %result : !stream.resource<external>{%c12}
    %4 = stream.tensor.export %3 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
    return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private mutable @_params.weight__timepoint = #stream.timepoint<immediate> : !stream.timepoint
  util.global private @_params.weight : !stream.resource<constant>
  util.initializer {
    %0 = stream.timepoint.immediate => !stream.timepoint
    %c0_i64 = arith.constant 0 : i64
    %c128 = arith.constant 128 : index
    %c0 = arith.constant 0 : index
    %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #composite_of_128b
    %did_map, %result = stream.resource.try_map %buffer_cst[%c0] : !util.buffer -> i1, !stream.resource<constant>{%c128}
    %1:2 = scf.if %did_map -> (!stream.timepoint, !stream.resource<constant>) {
      scf.yield %0, %result : !stream.timepoint, !stream.resource<constant>
    } else {
      %2 = stream.resource.alloc uninitialized : !stream.resource<constant>{%c128}
      %file = stream.file.constant %buffer_cst[%c0 for %c128] : !util.buffer{%c128} -> !stream.file
      %3 = stream.file.read await(%0) => %file[%c0_i64], %2[%c0], %c128 : !stream.file -> !stream.resource<constant>{%c128} => !stream.timepoint
      scf.yield %3, %2 : !stream.timepoint, !stream.resource<constant>
    }
    util.global.store %1#1, @_params.weight : !stream.resource<constant>
    util.global.store %1#0, @_params.weight__timepoint : !stream.timepoint
    util.initializer.return
  }
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_1x3x4_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        %4 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
        %5 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
        %6 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
        %7 = tensor.empty() : tensor<1x3xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%7 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %9 = linalg.matmul ins(%4, %5 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%8 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %10 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%9, %6 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%7 : tensor<1x3xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %11 = arith.addf %in, %in_0 : f32
          linalg.yield %11 : f32
        } -> tensor<1x3xf32>
        flow.dispatch.tensor.store %10, %3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c48 = arith.constant 48 : index
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %c12 = arith.constant 12 : index
    %c16 = arith.constant 16 : index
    %c128 = arith.constant 128 : index
    %c64 = arith.constant 64 : index
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !stream.timepoint
    %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
    %result, %result_timepoint = stream.resource.alloca uninitialized await(%_params.weight__timepoint) => !stream.resource<external>{%c12} => !stream.timepoint
    %1 = stream.timepoint.join max(%_params.weight__timepoint, %result_timepoint) => !stream.timepoint
    %2 = stream.cmd.execute await(%1) => with(%0 as %arg1: !stream.resource<external>{%c16}, %_params.weight as %arg2: !stream.resource<constant>{%c128}, %result as %arg3: !stream.resource<external>{%c12}) {
      stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32 {
        ro %arg1[%c0 for %c16] : !stream.resource<external>{%c16},
        ro %arg2[%c0 for %c48] : !stream.resource<constant>{%c128},
        ro %arg2[%c64 for %c12] : !stream.resource<constant>{%c128},
        wo %arg3[%c0 for %c12] : !stream.resource<external>{%c12}
      }
    } => !stream.timepoint
    %3 = stream.timepoint.await %2 => %result : !stream.resource<external>{%c12}
    %4 = stream.tensor.export %3 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
    return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private mutable @_params.weight__timepoint = #stream.timepoint<immediate> : !stream.timepoint
  util.global private @_params.weight : !stream.resource<constant>
  util.initializer {
    %0 = stream.timepoint.immediate => !stream.timepoint
    %c0_i64 = arith.constant 0 : i64
    %c128 = arith.constant 128 : index
    %c0 = arith.constant 0 : index
    %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #composite_of_128b
    %did_map, %result = stream.resource.try_map %buffer_cst[%c0] : !util.buffer -> i1, !stream.resource<constant>{%c128}
    %1:2 = scf.if %did_map -> (!stream.timepoint, !stream.resource<constant>) {
      scf.yield %0, %result : !stream.timepoint, !stream.resource<constant>
    } else {
      %2 = stream.resource.alloc uninitialized : !stream.resource<constant>{%c128}
      %file = stream.file.constant %buffer_cst[%c0 for %c128] : !util.buffer{%c128} -> !stream.file
      %3 = stream.file.read await(%0) => %file[%c0_i64], %2[%c0], %c128 : !stream.file -> !stream.resource<constant>{%c128} => !stream.timepoint
      scf.yield %3, %2 : !stream.timepoint, !stream.resource<constant>
    }
    util.global.store %1#1, @_params.weight : !stream.resource<constant>
    util.global.store %1#0, @_params.weight__timepoint : !stream.timepoint
    util.initializer.return
  }
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_1x3x4_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        %4 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
        %5 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
        %6 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
        %7 = tensor.empty() : tensor<1x3xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%7 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %9 = linalg.matmul ins(%4, %5 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%8 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %10 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%9, %6 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%7 : tensor<1x3xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %11 = arith.addf %in, %in_0 : f32
          linalg.yield %11 : f32
        } -> tensor<1x3xf32>
        flow.dispatch.tensor.store %10, %3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c48 = arith.constant 48 : index
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %c12 = arith.constant 12 : index
    %c16 = arith.constant 16 : index
    %c128 = arith.constant 128 : index
    %c64 = arith.constant 64 : index
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !stream.timepoint
    %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
    %result, %result_timepoint = stream.resource.alloca uninitialized await(%_params.weight__timepoint) => !stream.resource<external>{%c12} => !stream.timepoint
    %1 = stream.timepoint.join max(%_params.weight__timepoint, %result_timepoint) => !stream.timepoint
    %2 = stream.cmd.execute await(%1) => with(%0 as %arg1: !stream.resource<external>{%c16}, %_params.weight as %arg2: !stream.resource<constant>{%c128}, %result as %arg3: !stream.resource<external>{%c12}) {
      stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32 {
        ro %arg1[%c0 for %c16] : !stream.resource<external>{%c16},
        ro %arg2[%c0 for %c48] : !stream.resource<constant>{%c128},
        ro %arg2[%c64 for %c12] : !stream.resource<constant>{%c128},
        wo %arg3[%c0 for %c12] : !stream.resource<external>{%c12}
      }
    } => !stream.timepoint
    %3 = stream.timepoint.await %2 => %result : !stream.resource<external>{%c12}
    %4 = stream.tensor.export %3 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
    return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private mutable @_params.weight__timepoint = #stream.timepoint<immediate> : !stream.timepoint
  util.global private @_params.weight : !stream.resource<constant>
  util.initializer {
    %0 = stream.timepoint.immediate => !stream.timepoint
    %c0_i64 = arith.constant 0 : i64
    %c128 = arith.constant 128 : index
    %c0 = arith.constant 0 : index
    %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #composite_of_128b
    %did_map, %result = stream.resource.try_map %buffer_cst[%c0] : !util.buffer -> i1, !stream.resource<constant>{%c128}
    %1:2 = scf.if %did_map -> (!stream.timepoint, !stream.resource<constant>) {
      scf.yield %0, %result : !stream.timepoint, !stream.resource<constant>
    } else {
      %2 = stream.resource.alloc uninitialized : !stream.resource<constant>{%c128}
      %file = stream.file.constant %buffer_cst[%c0 for %c128] : !util.buffer{%c128} -> !stream.file
      %3 = stream.file.read await(%0) => %file[%c0_i64], %2[%c0], %c128 : !stream.file -> !stream.resource<constant>{%c128} => !stream.timepoint
      scf.yield %3, %2 : !stream.timepoint, !stream.resource<constant>
    }
    util.global.store %1#1, @_params.weight : !stream.resource<constant>
    util.global.store %1#0, @_params.weight__timepoint : !stream.timepoint
    util.initializer.return
  }
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_1x3x4_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        %4 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
        %5 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
        %6 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
        %7 = tensor.empty() : tensor<1x3xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%7 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %9 = linalg.matmul ins(%4, %5 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%8 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %10 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%9, %6 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%7 : tensor<1x3xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %11 = arith.addf %in, %in_0 : f32
          linalg.yield %11 : f32
        } -> tensor<1x3xf32>
        flow.dispatch.tensor.store %10, %3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c48 = arith.constant 48 : index
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %c12 = arith.constant 12 : index
    %c16 = arith.constant 16 : index
    %c128 = arith.constant 128 : index
    %c64 = arith.constant 64 : index
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !stream.timepoint
    %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
    %result, %result_timepoint = stream.resource.alloca uninitialized await(%_params.weight__timepoint) => !stream.resource<external>{%c12} => !stream.timepoint
    %1 = stream.timepoint.join max(%_params.weight__timepoint, %result_timepoint) => !stream.timepoint
    %2 = stream.cmd.execute await(%1) => with(%0 as %arg1: !stream.resource<external>{%c16}, %_params.weight as %arg2: !stream.resource<constant>{%c128}, %result as %arg3: !stream.resource<external>{%c12}) {
      stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32 {
        ro %arg1[%c0 for %c16] : !stream.resource<external>{%c16},
        ro %arg2[%c0 for %c48] : !stream.resource<constant>{%c128},
        ro %arg2[%c64 for %c12] : !stream.resource<constant>{%c128},
        wo %arg3[%c0 for %c12] : !stream.resource<external>{%c12}
      }
    } => !stream.timepoint
    %3 = stream.timepoint.await %2 => %result : !stream.resource<external>{%c12}
    %4 = stream.tensor.export %3 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
    return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After SCFToControlFlow (convert-scf-to-cf) //----- //
util.initializer {
  %0 = stream.timepoint.immediate => !stream.timepoint
  %c0_i64 = arith.constant 0 : i64
  %c128 = arith.constant 128 : index
  %c0 = arith.constant 0 : index
  %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
  %did_map, %result = stream.resource.try_map %buffer_cst[%c0] : !util.buffer -> i1, !stream.resource<constant>{%c128}
  cf.cond_br %did_map, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  cf.br ^bb3(%0, %result : !stream.timepoint, !stream.resource<constant>)
^bb2:  // pred: ^bb0
  %1 = stream.resource.alloc uninitialized : !stream.resource<constant>{%c128}
  %file = stream.file.constant %buffer_cst[%c0 for %c128] : !util.buffer{%c128} -> !stream.file
  %2 = stream.file.read await(%0) => %file[%c0_i64], %1[%c0], %c128 : !stream.file -> !stream.resource<constant>{%c128} => !stream.timepoint
  cf.br ^bb3(%2, %1 : !stream.timepoint, !stream.resource<constant>)
^bb3(%3: !stream.timepoint, %4: !stream.resource<constant>):  // 2 preds: ^bb1, ^bb2
  cf.br ^bb4
^bb4:  // pred: ^bb3
  util.global.store %4, @_params.weight : !stream.resource<constant>
  util.global.store %3, @_params.weight__timepoint : !stream.timepoint
  util.initializer.return
}

// -----// IR Dump After SCFToControlFlow (convert-scf-to-cf) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c48 = arith.constant 48 : index
  %c0 = arith.constant 0 : index
  %c4 = arith.constant 4 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %c12 = arith.constant 12 : index
  %c16 = arith.constant 16 : index
  %c128 = arith.constant 128 : index
  %c64 = arith.constant 64 : index
  %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !stream.timepoint
  %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
  %result, %result_timepoint = stream.resource.alloca uninitialized await(%_params.weight__timepoint) => !stream.resource<external>{%c12} => !stream.timepoint
  %1 = stream.timepoint.join max(%_params.weight__timepoint, %result_timepoint) => !stream.timepoint
  %2 = stream.cmd.execute await(%1) => with(%0 as %arg1: !stream.resource<external>{%c16}, %_params.weight as %arg2: !stream.resource<constant>{%c128}, %result as %arg3: !stream.resource<external>{%c12}) {
    stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32 {
      ro %arg1[%c0 for %c16] : !stream.resource<external>{%c16},
      ro %arg2[%c0 for %c48] : !stream.resource<constant>{%c128},
      ro %arg2[%c64 for %c12] : !stream.resource<constant>{%c128},
      wo %arg3[%c0 for %c12] : !stream.resource<external>{%c12}
    }
  } => !stream.timepoint
  %3 = stream.timepoint.await %2 => %result : !stream.resource<external>{%c12}
  %4 = stream.tensor.export %3 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
  return %4 : !hal.buffer_view
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c48 = arith.constant 48 : index
  %c0 = arith.constant 0 : index
  %c4 = arith.constant 4 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %c12 = arith.constant 12 : index
  %c16 = arith.constant 16 : index
  %c128 = arith.constant 128 : index
  %c64 = arith.constant 64 : index
  %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !stream.timepoint
  %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
  %result, %result_timepoint = stream.resource.alloca uninitialized await(%_params.weight__timepoint) => !stream.resource<external>{%c12} => !stream.timepoint
  %1 = stream.timepoint.join max(%_params.weight__timepoint, %result_timepoint) => !stream.timepoint
  %2 = stream.cmd.execute await(%1) => with(%0 as %arg1: !stream.resource<external>{%c16}, %_params.weight as %arg2: !stream.resource<constant>{%c128}, %result as %arg3: !stream.resource<external>{%c12}) {
    stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32 {
      ro %arg1[%c0 for %c16] : !stream.resource<external>{%c16},
      ro %arg2[%c0 for %c48] : !stream.resource<constant>{%c128},
      ro %arg2[%c64 for %c12] : !stream.resource<constant>{%c128},
      wo %arg3[%c0 for %c12] : !stream.resource<external>{%c12}
    }
  } => !stream.timepoint
  %3 = stream.timepoint.await %2 => %result : !stream.resource<external>{%c12}
  %4 = stream.tensor.export %3 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
  return %4 : !hal.buffer_view
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.initializer {
  %0 = stream.timepoint.immediate => !stream.timepoint
  %c0_i64 = arith.constant 0 : i64
  %c128 = arith.constant 128 : index
  %c0 = arith.constant 0 : index
  %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
  %did_map, %result = stream.resource.try_map %buffer_cst[%c0] : !util.buffer -> i1, !stream.resource<constant>{%c128}
  cf.cond_br %did_map, ^bb2(%0, %result : !stream.timepoint, !stream.resource<constant>), ^bb1
^bb1:  // pred: ^bb0
  %1 = stream.resource.alloc uninitialized : !stream.resource<constant>{%c128}
  %file = stream.file.constant %buffer_cst[%c0 for %c128] : !util.buffer{%c128} -> !stream.file
  %2 = stream.file.read await(%0) => %file[%c0_i64], %1[%c0], %c128 : !stream.file -> !stream.resource<constant>{%c128} => !stream.timepoint
  cf.br ^bb2(%2, %1 : !stream.timepoint, !stream.resource<constant>)
^bb2(%3: !stream.timepoint, %4: !stream.resource<constant>):  // 2 preds: ^bb0, ^bb1
  util.global.store %4, @_params.weight : !stream.resource<constant>
  util.global.store %3, @_params.weight__timepoint : !stream.timepoint
  util.initializer.return
}

// -----// IR Dump After CSE (cse) //----- //
util.initializer {
  %0 = stream.timepoint.immediate => !stream.timepoint
  %c0_i64 = arith.constant 0 : i64
  %c128 = arith.constant 128 : index
  %c0 = arith.constant 0 : index
  %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
  %did_map, %result = stream.resource.try_map %buffer_cst[%c0] : !util.buffer -> i1, !stream.resource<constant>{%c128}
  cf.cond_br %did_map, ^bb2(%0, %result : !stream.timepoint, !stream.resource<constant>), ^bb1
^bb1:  // pred: ^bb0
  %1 = stream.resource.alloc uninitialized : !stream.resource<constant>{%c128}
  %file = stream.file.constant %buffer_cst[%c0 for %c128] : !util.buffer{%c128} -> !stream.file
  %2 = stream.file.read await(%0) => %file[%c0_i64], %1[%c0], %c128 : !stream.file -> !stream.resource<constant>{%c128} => !stream.timepoint
  cf.br ^bb2(%2, %1 : !stream.timepoint, !stream.resource<constant>)
^bb2(%3: !stream.timepoint, %4: !stream.resource<constant>):  // 2 preds: ^bb0, ^bb1
  util.global.store %4, @_params.weight : !stream.resource<constant>
  util.global.store %3, @_params.weight__timepoint : !stream.timepoint
  util.initializer.return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c48 = arith.constant 48 : index
  %c0 = arith.constant 0 : index
  %c4 = arith.constant 4 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %c12 = arith.constant 12 : index
  %c16 = arith.constant 16 : index
  %c128 = arith.constant 128 : index
  %c64 = arith.constant 64 : index
  %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !stream.timepoint
  %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
  %result, %result_timepoint = stream.resource.alloca uninitialized await(%_params.weight__timepoint) => !stream.resource<external>{%c12} => !stream.timepoint
  %1 = stream.timepoint.join max(%_params.weight__timepoint, %result_timepoint) => !stream.timepoint
  %2 = stream.cmd.execute await(%1) => with(%0 as %arg1: !stream.resource<external>{%c16}, %_params.weight as %arg2: !stream.resource<constant>{%c128}, %result as %arg3: !stream.resource<external>{%c12}) {
    stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32 {
      ro %arg1[%c0 for %c16] : !stream.resource<external>{%c16},
      ro %arg2[%c0 for %c48] : !stream.resource<constant>{%c128},
      ro %arg2[%c64 for %c12] : !stream.resource<constant>{%c128},
      wo %arg3[%c0 for %c12] : !stream.resource<external>{%c12}
    }
  } => !stream.timepoint
  %3 = stream.timepoint.await %2 => %result : !stream.resource<external>{%c12}
  %4 = stream.tensor.export %3 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
  return %4 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.initializer {
  %0 = stream.timepoint.immediate => !stream.timepoint
  %c0_i64 = arith.constant 0 : i64
  %c128 = arith.constant 128 : index
  %c0 = arith.constant 0 : index
  %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
  %did_map, %result = stream.resource.try_map %buffer_cst[%c0] : !util.buffer -> i1, !stream.resource<constant>{%c128}
  cf.cond_br %did_map, ^bb2(%0, %result : !stream.timepoint, !stream.resource<constant>), ^bb1
^bb1:  // pred: ^bb0
  %1 = stream.resource.alloc uninitialized : !stream.resource<constant>{%c128}
  %file = stream.file.constant %buffer_cst[%c0 for %c128] : !util.buffer{%c128} -> !stream.file
  %2 = stream.file.read await(%0) => %file[%c0_i64], %1[%c0], %c128 : !stream.file -> !stream.resource<constant>{%c128} => !stream.timepoint
  cf.br ^bb2(%2, %1 : !stream.timepoint, !stream.resource<constant>)
^bb2(%3: !stream.timepoint, %4: !stream.resource<constant>):  // 2 preds: ^bb0, ^bb1
  util.global.store %4, @_params.weight : !stream.resource<constant>
  util.global.store %3, @_params.weight__timepoint : !stream.timepoint
  util.initializer.return
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !stream.timepoint
  %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
  %c48 = arith.constant 48 : index
  %c0 = arith.constant 0 : index
  %c4 = arith.constant 4 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %c12 = arith.constant 12 : index
  %c16 = arith.constant 16 : index
  %c128 = arith.constant 128 : index
  %c64 = arith.constant 64 : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
  %result, %result_timepoint = stream.resource.alloca uninitialized await(%_params.weight__timepoint) => !stream.resource<external>{%c12} => !stream.timepoint
  %1 = stream.timepoint.join max(%_params.weight__timepoint, %result_timepoint) => !stream.timepoint
  %2 = stream.cmd.execute await(%1) => with(%0 as %arg1: !stream.resource<external>{%c16}, %_params.weight as %arg2: !stream.resource<constant>{%c128}, %result as %arg3: !stream.resource<external>{%c12}) {
    stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32 {
      ro %arg1[%c0 for %c16] : !stream.resource<external>{%c16},
      ro %arg2[%c0 for %c48] : !stream.resource<constant>{%c128},
      ro %arg2[%c64 for %c12] : !stream.resource<constant>{%c128},
      wo %arg3[%c0 for %c12] : !stream.resource<external>{%c12}
    }
  } => !stream.timepoint
  %3 = stream.timepoint.await %2 => %result : !stream.resource<external>{%c12}
  %4 = stream.tensor.export %3 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
  return %4 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda], iree.fixedpoint.iteration = 0 : index} {
  util.global private mutable @_params.weight__timepoint = #stream.timepoint<immediate> : !stream.timepoint
  util.global private @_params.weight : !stream.resource<constant>
  util.initializer {
    %0 = stream.timepoint.immediate => !stream.timepoint
    %c0_i64 = arith.constant 0 : i64
    %c128 = arith.constant 128 : index
    %c0 = arith.constant 0 : index
    %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #composite_of_128b
    %did_map, %result = stream.resource.try_map %buffer_cst[%c0] : !util.buffer -> i1, !stream.resource<constant>{%c128}
    cf.cond_br %did_map, ^bb2(%0, %result : !stream.timepoint, !stream.resource<constant>), ^bb1
  ^bb1:  // pred: ^bb0
    %1 = stream.resource.alloc uninitialized : !stream.resource<constant>{%c128}
    %file = stream.file.constant %buffer_cst[%c0 for %c128] : !util.buffer{%c128} -> !stream.file
    %2 = stream.file.read await(%0) => %file[%c0_i64], %1[%c0], %c128 : !stream.file -> !stream.resource<constant>{%c128} => !stream.timepoint
    cf.br ^bb2(%2, %1 : !stream.timepoint, !stream.resource<constant>)
  ^bb2(%3: !stream.timepoint, %4: !stream.resource<constant>):  // 2 preds: ^bb0, ^bb1
    util.global.store %4, @_params.weight : !stream.resource<constant>
    util.global.store %3, @_params.weight__timepoint : !stream.timepoint
    util.initializer.return
  }
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_1x3x4_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        %4 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
        %5 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
        %6 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
        %7 = tensor.empty() : tensor<1x3xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%7 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %9 = linalg.matmul ins(%4, %5 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%8 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %10 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%9, %6 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%7 : tensor<1x3xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %11 = arith.addf %in, %in_0 : f32
          linalg.yield %11 : f32
        } -> tensor<1x3xf32>
        flow.dispatch.tensor.store %10, %3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c64 = arith.constant 64 : index
    %c128 = arith.constant 128 : index
    %c16 = arith.constant 16 : index
    %c12 = arith.constant 12 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c48 = arith.constant 48 : index
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !stream.timepoint
    %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
    %result, %result_timepoint = stream.resource.alloca uninitialized await(%_params.weight__timepoint) => !stream.resource<external>{%c12} => !stream.timepoint
    %1 = stream.timepoint.join max(%_params.weight__timepoint, %result_timepoint) => !stream.timepoint
    %2 = stream.cmd.execute await(%1) => with(%0 as %arg1: !stream.resource<external>{%c16}, %_params.weight as %arg2: !stream.resource<constant>{%c128}, %result as %arg3: !stream.resource<external>{%c12}) {
      stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32 {
        ro %arg1[%c0 for %c16] : !stream.resource<external>{%c16},
        ro %arg2[%c0 for %c48] : !stream.resource<constant>{%c128},
        ro %arg2[%c64 for %c12] : !stream.resource<constant>{%c128},
        wo %arg3[%c0 for %c12] : !stream.resource<external>{%c12}
      }
    } => !stream.timepoint
    %3 = stream.timepoint.await %2 => %result : !stream.resource<external>{%c12}
    %4 = stream.tensor.export %3 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
    return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda], iree.fixedpoint.iteration = 0 : index} {
  util.global private mutable @_params.weight__timepoint = #stream.timepoint<immediate> : !stream.timepoint
  util.global private @_params.weight : !stream.resource<constant>
  util.initializer {
    %0 = stream.timepoint.immediate => !stream.timepoint
    %c0_i64 = arith.constant 0 : i64
    %c128 = arith.constant 128 : index
    %c0 = arith.constant 0 : index
    %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #composite_of_128b
    %did_map, %result = stream.resource.try_map %buffer_cst[%c0] : !util.buffer -> i1, !stream.resource<constant>{%c128}
    cf.cond_br %did_map, ^bb2(%0, %result : !stream.timepoint, !stream.resource<constant>), ^bb1
  ^bb1:  // pred: ^bb0
    %1 = stream.resource.alloc uninitialized : !stream.resource<constant>{%c128}
    %file = stream.file.constant %buffer_cst[%c0 for %c128] : !util.buffer{%c128} -> !stream.file
    %2 = stream.file.read await(%0) => %file[%c0_i64], %1[%c0], %c128 : !stream.file -> !stream.resource<constant>{%c128} => !stream.timepoint
    cf.br ^bb2(%2, %1 : !stream.timepoint, !stream.resource<constant>)
  ^bb2(%3: !stream.timepoint, %4: !stream.resource<constant>):  // 2 preds: ^bb0, ^bb1
    util.global.store %4, @_params.weight : !stream.resource<constant>
    util.global.store %3, @_params.weight__timepoint : !stream.timepoint
    util.initializer.return
  }
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_1x3x4_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        %4 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
        %5 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
        %6 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
        %7 = tensor.empty() : tensor<1x3xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%7 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %9 = linalg.matmul ins(%4, %5 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%8 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %10 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%9, %6 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%7 : tensor<1x3xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %11 = arith.addf %in, %in_0 : f32
          linalg.yield %11 : f32
        } -> tensor<1x3xf32>
        flow.dispatch.tensor.store %10, %3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c64 = arith.constant 64 : index
    %c128 = arith.constant 128 : index
    %c16 = arith.constant 16 : index
    %c12 = arith.constant 12 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c48 = arith.constant 48 : index
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !stream.timepoint
    %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
    %result, %result_timepoint = stream.resource.alloca uninitialized await(%_params.weight__timepoint) => !stream.resource<external>{%c12} => !stream.timepoint
    %1 = stream.timepoint.join max(%_params.weight__timepoint, %result_timepoint) => !stream.timepoint
    %2 = stream.cmd.execute await(%1) => with(%0 as %arg1: !stream.resource<external>{%c16}, %_params.weight as %arg2: !stream.resource<constant>{%c128}, %result as %arg3: !stream.resource<external>{%c12}) {
      stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32 {
        ro %arg1[%c0 for %c16] : !stream.resource<external>{%c16},
        ro %arg2[%c0 for %c48] : !stream.resource<constant>{%c128},
        ro %arg2[%c64 for %c12] : !stream.resource<constant>{%c128},
        wo %arg3[%c0 for %c12] : !stream.resource<external>{%c12}
      }
    } => !stream.timepoint
    %3 = stream.timepoint.await %2 => %result : !stream.resource<external>{%c12}
    %4 = stream.tensor.export %3 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
    return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda], iree.fixedpoint.iteration = 0 : index} {
  util.global private mutable @_params.weight__timepoint = #stream.timepoint<immediate> : !stream.timepoint
  util.global private @_params.weight : !stream.resource<constant>
  util.initializer {
    %0 = stream.timepoint.immediate => !stream.timepoint
    %c0_i64 = arith.constant 0 : i64
    %c128 = arith.constant 128 : index
    %c0 = arith.constant 0 : index
    %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #composite_of_128b
    %did_map, %result = stream.resource.try_map %buffer_cst[%c0] : !util.buffer -> i1, !stream.resource<constant>{%c128}
    cf.cond_br %did_map, ^bb2(%0, %result : !stream.timepoint, !stream.resource<constant>), ^bb1
  ^bb1:  // pred: ^bb0
    %1 = stream.resource.alloc uninitialized : !stream.resource<constant>{%c128}
    %file = stream.file.constant %buffer_cst[%c0 for %c128] : !util.buffer{%c128} -> !stream.file
    %2 = stream.file.read await(%0) => %file[%c0_i64], %1[%c0], %c128 : !stream.file -> !stream.resource<constant>{%c128} => !stream.timepoint
    cf.br ^bb2(%2, %1 : !stream.timepoint, !stream.resource<constant>)
  ^bb2(%3: !stream.timepoint, %4: !stream.resource<constant>):  // 2 preds: ^bb0, ^bb1
    util.global.store %4, @_params.weight : !stream.resource<constant>
    util.global.store %3, @_params.weight__timepoint : !stream.timepoint
    util.initializer.return
  }
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_1x3x4_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        %4 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
        %5 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
        %6 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
        %7 = tensor.empty() : tensor<1x3xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%7 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %9 = linalg.matmul ins(%4, %5 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%8 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %10 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%9, %6 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%7 : tensor<1x3xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %11 = arith.addf %in, %in_0 : f32
          linalg.yield %11 : f32
        } -> tensor<1x3xf32>
        flow.dispatch.tensor.store %10, %3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c64 = arith.constant 64 : index
    %c128 = arith.constant 128 : index
    %c16 = arith.constant 16 : index
    %c12 = arith.constant 12 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c48 = arith.constant 48 : index
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !stream.timepoint
    %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
    %result, %result_timepoint = stream.resource.alloca uninitialized await(%_params.weight__timepoint) => !stream.resource<external>{%c12} => !stream.timepoint
    %1 = stream.timepoint.join max(%_params.weight__timepoint, %result_timepoint) => !stream.timepoint
    %2 = stream.cmd.execute await(%1) => with(%0 as %arg1: !stream.resource<external>{%c16}, %_params.weight as %arg2: !stream.resource<constant>{%c128}, %result as %arg3: !stream.resource<external>{%c12}) {
      stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32 {
        ro %arg1[%c0 for %c16] : !stream.resource<external>{%c16},
        ro %arg2[%c0 for %c48] : !stream.resource<constant>{%c128},
        ro %arg2[%c64 for %c12] : !stream.resource<constant>{%c128},
        wo %arg3[%c0 for %c12] : !stream.resource<external>{%c12}
      }
    } => !stream.timepoint
    %3 = stream.timepoint.await %2 => %result : !stream.resource<external>{%c12}
    %4 = stream.tensor.export %3 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
    return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda], iree.fixedpoint.iteration = 0 : index} {
  util.global private mutable @_params.weight__timepoint = #stream.timepoint<immediate> : !stream.timepoint
  util.global private @_params.weight : !stream.resource<constant>
  util.initializer {
    %0 = stream.timepoint.immediate => !stream.timepoint
    %c0_i64 = arith.constant 0 : i64
    %c128 = arith.constant 128 : index
    %c0 = arith.constant 0 : index
    %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #composite_of_128b
    %did_map, %result = stream.resource.try_map %buffer_cst[%c0] : !util.buffer -> i1, !stream.resource<constant>{%c128}
    cf.cond_br %did_map, ^bb2(%0, %result : !stream.timepoint, !stream.resource<constant>), ^bb1
  ^bb1:  // pred: ^bb0
    %1 = stream.resource.alloc uninitialized : !stream.resource<constant>{%c128}
    %file = stream.file.constant %buffer_cst[%c0 for %c128] : !util.buffer{%c128} -> !stream.file
    %2 = stream.file.read await(%0) => %file[%c0_i64], %1[%c0], %c128 : !stream.file -> !stream.resource<constant>{%c128} => !stream.timepoint
    cf.br ^bb2(%2, %1 : !stream.timepoint, !stream.resource<constant>)
  ^bb2(%3: !stream.timepoint, %4: !stream.resource<constant>):  // 2 preds: ^bb0, ^bb1
    util.global.store %4, @_params.weight : !stream.resource<constant>
    util.global.store %3, @_params.weight__timepoint : !stream.timepoint
    util.initializer.return
  }
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_1x3x4_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        %4 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
        %5 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
        %6 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
        %7 = tensor.empty() : tensor<1x3xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%7 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %9 = linalg.matmul ins(%4, %5 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%8 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %10 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%9, %6 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%7 : tensor<1x3xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %11 = arith.addf %in, %in_0 : f32
          linalg.yield %11 : f32
        } -> tensor<1x3xf32>
        flow.dispatch.tensor.store %10, %3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c64 = arith.constant 64 : index
    %c128 = arith.constant 128 : index
    %c16 = arith.constant 16 : index
    %c12 = arith.constant 12 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c48 = arith.constant 48 : index
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !stream.timepoint
    %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
    %result, %result_timepoint = stream.resource.alloca uninitialized await(%_params.weight__timepoint) => !stream.resource<external>{%c12} => !stream.timepoint
    %1 = stream.timepoint.join max(%_params.weight__timepoint, %result_timepoint) => !stream.timepoint
    %2 = stream.cmd.execute await(%1) => with(%0 as %arg1: !stream.resource<external>{%c16}, %_params.weight as %arg2: !stream.resource<constant>{%c128}, %result as %arg3: !stream.resource<external>{%c12}) {
      stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32 {
        ro %arg1[%c0 for %c16] : !stream.resource<external>{%c16},
        ro %arg2[%c0 for %c48] : !stream.resource<constant>{%c128},
        ro %arg2[%c64 for %c12] : !stream.resource<constant>{%c128},
        wo %arg3[%c0 for %c12] : !stream.resource<external>{%c12}
      }
    } => !stream.timepoint
    %3 = stream.timepoint.await %2 => %result : !stream.resource<external>{%c12}
    %4 = stream.tensor.export %3 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
    return %4 : !hal.buffer_view
  }
}


// -----// IR Dump After ElideTimepoints (iree-stream-elide-timepoints) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda], iree.fixedpoint.iteration = 0 : index, iree.fixedpoint.modified} {
  util.global private mutable @_params.weight__timepoint = #stream.timepoint<immediate> : !stream.timepoint
  util.global private @_params.weight : !stream.resource<constant>
  util.initializer {
    %0 = stream.timepoint.immediate => !stream.timepoint
    %c0_i64 = arith.constant 0 : i64
    %c128 = arith.constant 128 : index
    %c0 = arith.constant 0 : index
    %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #composite_of_128b
    %did_map, %result = stream.resource.try_map %buffer_cst[%c0] : !util.buffer -> i1, !stream.resource<constant>{%c128}
    cf.cond_br %did_map, ^bb2(%0, %result : !stream.timepoint, !stream.resource<constant>), ^bb1
  ^bb1:  // pred: ^bb0
    %1 = stream.resource.alloc uninitialized : !stream.resource<constant>{%c128}
    %file = stream.file.constant %buffer_cst[%c0 for %c128] : !util.buffer{%c128} -> !stream.file
    %2 = stream.file.read await(%0) => %file[%c0_i64], %1[%c0], %c128 : !stream.file -> !stream.resource<constant>{%c128} => !stream.timepoint
    cf.br ^bb2(%2, %1 : !stream.timepoint, !stream.resource<constant>)
  ^bb2(%3: !stream.timepoint, %4: !stream.resource<constant>):  // 2 preds: ^bb0, ^bb1
    util.global.store %4, @_params.weight : !stream.resource<constant>
    util.global.store %3, @_params.weight__timepoint : !stream.timepoint
    util.initializer.return
  }
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_1x3x4_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        %4 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
        %5 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
        %6 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
        %7 = tensor.empty() : tensor<1x3xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%7 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %9 = linalg.matmul ins(%4, %5 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%8 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %10 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%9, %6 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%7 : tensor<1x3xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %11 = arith.addf %in, %in_0 : f32
          linalg.yield %11 : f32
        } -> tensor<1x3xf32>
        flow.dispatch.tensor.store %10, %3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c64 = arith.constant 64 : index
    %c128 = arith.constant 128 : index
    %c16 = arith.constant 16 : index
    %c12 = arith.constant 12 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c48 = arith.constant 48 : index
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !stream.timepoint
    %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
    %result, %result_timepoint = stream.resource.alloca uninitialized await(%_params.weight__timepoint) => !stream.resource<external>{%c12} => !stream.timepoint
    %1 = stream.timepoint.immediate => !stream.timepoint
    %2 = stream.timepoint.join max(%1, %result_timepoint) => !stream.timepoint
    %3 = stream.cmd.execute await(%2) => with(%0 as %arg1: !stream.resource<external>{%c16}, %_params.weight as %arg2: !stream.resource<constant>{%c128}, %result as %arg3: !stream.resource<external>{%c12}) {
      stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32 {
        ro %arg1[%c0 for %c16] : !stream.resource<external>{%c16},
        ro %arg2[%c0 for %c48] : !stream.resource<constant>{%c128},
        ro %arg2[%c64 for %c12] : !stream.resource<constant>{%c128},
        wo %arg3[%c0 for %c12] : !stream.resource<external>{%c12}
      }
    } => !stream.timepoint
    %4 = stream.timepoint.await %3 => %result : !stream.resource<external>{%c12}
    %5 = stream.tensor.export %4 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
    return %5 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.initializer {
  %0 = stream.timepoint.immediate => !stream.timepoint
  %c0_i64 = arith.constant 0 : i64
  %c128 = arith.constant 128 : index
  %c0 = arith.constant 0 : index
  %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
  %did_map, %result = stream.resource.try_map %buffer_cst[%c0] : !util.buffer -> i1, !stream.resource<constant>{%c128}
  cf.cond_br %did_map, ^bb2(%0, %result : !stream.timepoint, !stream.resource<constant>), ^bb1
^bb1:  // pred: ^bb0
  %1 = stream.resource.alloc uninitialized : !stream.resource<constant>{%c128}
  %file = stream.file.constant %buffer_cst[%c0 for %c128] : !util.buffer{%c128} -> !stream.file
  %2 = stream.file.read await(%0) => %file[%c0_i64], %1[%c0], %c128 : !stream.file -> !stream.resource<constant>{%c128} => !stream.timepoint
  cf.br ^bb2(%2, %1 : !stream.timepoint, !stream.resource<constant>)
^bb2(%3: !stream.timepoint, %4: !stream.resource<constant>):  // 2 preds: ^bb0, ^bb1
  util.global.store %4, @_params.weight : !stream.resource<constant>
  util.global.store %3, @_params.weight__timepoint : !stream.timepoint
  util.initializer.return
}

// -----// IR Dump After CSE (cse) //----- //
util.initializer {
  %0 = stream.timepoint.immediate => !stream.timepoint
  %c0_i64 = arith.constant 0 : i64
  %c128 = arith.constant 128 : index
  %c0 = arith.constant 0 : index
  %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
  %did_map, %result = stream.resource.try_map %buffer_cst[%c0] : !util.buffer -> i1, !stream.resource<constant>{%c128}
  cf.cond_br %did_map, ^bb2(%0, %result : !stream.timepoint, !stream.resource<constant>), ^bb1
^bb1:  // pred: ^bb0
  %1 = stream.resource.alloc uninitialized : !stream.resource<constant>{%c128}
  %file = stream.file.constant %buffer_cst[%c0 for %c128] : !util.buffer{%c128} -> !stream.file
  %2 = stream.file.read await(%0) => %file[%c0_i64], %1[%c0], %c128 : !stream.file -> !stream.resource<constant>{%c128} => !stream.timepoint
  cf.br ^bb2(%2, %1 : !stream.timepoint, !stream.resource<constant>)
^bb2(%3: !stream.timepoint, %4: !stream.resource<constant>):  // 2 preds: ^bb0, ^bb1
  util.global.store %4, @_params.weight : !stream.resource<constant>
  util.global.store %3, @_params.weight__timepoint : !stream.timepoint
  util.initializer.return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c64 = arith.constant 64 : index
  %c128 = arith.constant 128 : index
  %c16 = arith.constant 16 : index
  %c12 = arith.constant 12 : index
  %c553648160_i32 = arith.constant 553648160 : i32
  %c1_i32 = arith.constant 1 : i32
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %c48 = arith.constant 48 : index
  %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !stream.timepoint
  %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
  %result, %result_timepoint = stream.resource.alloca uninitialized await(%_params.weight__timepoint) => !stream.resource<external>{%c12} => !stream.timepoint
  %1 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c16}, %_params.weight as %arg2: !stream.resource<constant>{%c128}, %result as %arg3: !stream.resource<external>{%c12}) {
    stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32 {
      ro %arg1[%c0 for %c16] : !stream.resource<external>{%c16},
      ro %arg2[%c0 for %c48] : !stream.resource<constant>{%c128},
      ro %arg2[%c64 for %c12] : !stream.resource<constant>{%c128},
      wo %arg3[%c0 for %c12] : !stream.resource<external>{%c12}
    }
  } => !stream.timepoint
  %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c12}
  %3 = stream.tensor.export %2 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
  return %3 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.initializer {
  %0 = stream.timepoint.immediate => !stream.timepoint
  %c0_i64 = arith.constant 0 : i64
  %c128 = arith.constant 128 : index
  %c0 = arith.constant 0 : index
  %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
  %did_map, %result = stream.resource.try_map %buffer_cst[%c0] : !util.buffer -> i1, !stream.resource<constant>{%c128}
  cf.cond_br %did_map, ^bb2(%0, %result : !stream.timepoint, !stream.resource<constant>), ^bb1
^bb1:  // pred: ^bb0
  %1 = stream.resource.alloc uninitialized : !stream.resource<constant>{%c128}
  %file = stream.file.constant %buffer_cst[%c0 for %c128] : !util.buffer{%c128} -> !stream.file
  %2 = stream.file.read await(%0) => %file[%c0_i64], %1[%c0], %c128 : !stream.file -> !stream.resource<constant>{%c128} => !stream.timepoint
  cf.br ^bb2(%2, %1 : !stream.timepoint, !stream.resource<constant>)
^bb2(%3: !stream.timepoint, %4: !stream.resource<constant>):  // 2 preds: ^bb0, ^bb1
  util.global.store %4, @_params.weight : !stream.resource<constant>
  util.global.store %3, @_params.weight__timepoint : !stream.timepoint
  util.initializer.return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c64 = arith.constant 64 : index
  %c128 = arith.constant 128 : index
  %c16 = arith.constant 16 : index
  %c12 = arith.constant 12 : index
  %c553648160_i32 = arith.constant 553648160 : i32
  %c1_i32 = arith.constant 1 : i32
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %c48 = arith.constant 48 : index
  %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !stream.timepoint
  %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
  %result, %result_timepoint = stream.resource.alloca uninitialized await(%_params.weight__timepoint) => !stream.resource<external>{%c12} => !stream.timepoint
  %1 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c16}, %_params.weight as %arg2: !stream.resource<constant>{%c128}, %result as %arg3: !stream.resource<external>{%c12}) {
    stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32 {
      ro %arg1[%c0 for %c16] : !stream.resource<external>{%c16},
      ro %arg2[%c0 for %c48] : !stream.resource<constant>{%c128},
      ro %arg2[%c64 for %c12] : !stream.resource<constant>{%c128},
      wo %arg3[%c0 for %c12] : !stream.resource<external>{%c12}
    }
  } => !stream.timepoint
  %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c12}
  %3 = stream.tensor.export %2 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
  return %3 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !stream.timepoint
  %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
  %c64 = arith.constant 64 : index
  %c128 = arith.constant 128 : index
  %c16 = arith.constant 16 : index
  %c12 = arith.constant 12 : index
  %c553648160_i32 = arith.constant 553648160 : i32
  %c1_i32 = arith.constant 1 : i32
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %c48 = arith.constant 48 : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
  %result, %result_timepoint = stream.resource.alloca uninitialized await(%_params.weight__timepoint) => !stream.resource<external>{%c12} => !stream.timepoint
  %1 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c16}, %_params.weight as %arg2: !stream.resource<constant>{%c128}, %result as %arg3: !stream.resource<external>{%c12}) {
    stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32 {
      ro %arg1[%c0 for %c16] : !stream.resource<external>{%c16},
      ro %arg2[%c0 for %c48] : !stream.resource<constant>{%c128},
      ro %arg2[%c64 for %c12] : !stream.resource<constant>{%c128},
      wo %arg3[%c0 for %c12] : !stream.resource<external>{%c12}
    }
  } => !stream.timepoint
  %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c12}
  %3 = stream.tensor.export %2 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
  return %3 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda], iree.fixedpoint.iteration = 1 : index} {
  util.global private mutable @_params.weight__timepoint = #stream.timepoint<immediate> : !stream.timepoint
  util.global private @_params.weight : !stream.resource<constant>
  util.initializer {
    %0 = stream.timepoint.immediate => !stream.timepoint
    %c0_i64 = arith.constant 0 : i64
    %c128 = arith.constant 128 : index
    %c0 = arith.constant 0 : index
    %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #composite_of_128b
    %did_map, %result = stream.resource.try_map %buffer_cst[%c0] : !util.buffer -> i1, !stream.resource<constant>{%c128}
    cf.cond_br %did_map, ^bb2(%0, %result : !stream.timepoint, !stream.resource<constant>), ^bb1
  ^bb1:  // pred: ^bb0
    %1 = stream.resource.alloc uninitialized : !stream.resource<constant>{%c128}
    %file = stream.file.constant %buffer_cst[%c0 for %c128] : !util.buffer{%c128} -> !stream.file
    %2 = stream.file.read await(%0) => %file[%c0_i64], %1[%c0], %c128 : !stream.file -> !stream.resource<constant>{%c128} => !stream.timepoint
    cf.br ^bb2(%2, %1 : !stream.timepoint, !stream.resource<constant>)
  ^bb2(%3: !stream.timepoint, %4: !stream.resource<constant>):  // 2 preds: ^bb0, ^bb1
    util.global.store %4, @_params.weight : !stream.resource<constant>
    util.global.store %3, @_params.weight__timepoint : !stream.timepoint
    util.initializer.return
  }
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_1x3x4_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        %4 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
        %5 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
        %6 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
        %7 = tensor.empty() : tensor<1x3xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%7 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %9 = linalg.matmul ins(%4, %5 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%8 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %10 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%9, %6 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%7 : tensor<1x3xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %11 = arith.addf %in, %in_0 : f32
          linalg.yield %11 : f32
        } -> tensor<1x3xf32>
        flow.dispatch.tensor.store %10, %3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c48 = arith.constant 48 : index
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %c12 = arith.constant 12 : index
    %c16 = arith.constant 16 : index
    %c128 = arith.constant 128 : index
    %c64 = arith.constant 64 : index
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !stream.timepoint
    %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
    %result, %result_timepoint = stream.resource.alloca uninitialized await(%_params.weight__timepoint) => !stream.resource<external>{%c12} => !stream.timepoint
    %1 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c16}, %_params.weight as %arg2: !stream.resource<constant>{%c128}, %result as %arg3: !stream.resource<external>{%c12}) {
      stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32 {
        ro %arg1[%c0 for %c16] : !stream.resource<external>{%c16},
        ro %arg2[%c0 for %c48] : !stream.resource<constant>{%c128},
        ro %arg2[%c64 for %c12] : !stream.resource<constant>{%c128},
        wo %arg3[%c0 for %c12] : !stream.resource<external>{%c12}
      }
    } => !stream.timepoint
    %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c12}
    %3 = stream.tensor.export %2 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
    return %3 : !hal.buffer_view
  }
}


// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda], iree.fixedpoint.iteration = 1 : index} {
  util.global private mutable @_params.weight__timepoint = #stream.timepoint<immediate> : !stream.timepoint
  util.global private @_params.weight : !stream.resource<constant>
  util.initializer {
    %0 = stream.timepoint.immediate => !stream.timepoint
    %c0_i64 = arith.constant 0 : i64
    %c128 = arith.constant 128 : index
    %c0 = arith.constant 0 : index
    %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #composite_of_128b
    %did_map, %result = stream.resource.try_map %buffer_cst[%c0] : !util.buffer -> i1, !stream.resource<constant>{%c128}
    cf.cond_br %did_map, ^bb2(%0, %result : !stream.timepoint, !stream.resource<constant>), ^bb1
  ^bb1:  // pred: ^bb0
    %1 = stream.resource.alloc uninitialized : !stream.resource<constant>{%c128}
    %file = stream.file.constant %buffer_cst[%c0 for %c128] : !util.buffer{%c128} -> !stream.file
    %2 = stream.file.read await(%0) => %file[%c0_i64], %1[%c0], %c128 : !stream.file -> !stream.resource<constant>{%c128} => !stream.timepoint
    cf.br ^bb2(%2, %1 : !stream.timepoint, !stream.resource<constant>)
  ^bb2(%3: !stream.timepoint, %4: !stream.resource<constant>):  // 2 preds: ^bb0, ^bb1
    util.global.store %4, @_params.weight : !stream.resource<constant>
    util.global.store %3, @_params.weight__timepoint : !stream.timepoint
    util.initializer.return
  }
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_1x3x4_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        %4 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
        %5 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
        %6 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
        %7 = tensor.empty() : tensor<1x3xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%7 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %9 = linalg.matmul ins(%4, %5 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%8 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %10 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%9, %6 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%7 : tensor<1x3xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %11 = arith.addf %in, %in_0 : f32
          linalg.yield %11 : f32
        } -> tensor<1x3xf32>
        flow.dispatch.tensor.store %10, %3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c48 = arith.constant 48 : index
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %c12 = arith.constant 12 : index
    %c16 = arith.constant 16 : index
    %c128 = arith.constant 128 : index
    %c64 = arith.constant 64 : index
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !stream.timepoint
    %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
    %result, %result_timepoint = stream.resource.alloca uninitialized await(%_params.weight__timepoint) => !stream.resource<external>{%c12} => !stream.timepoint
    %1 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c16}, %_params.weight as %arg2: !stream.resource<constant>{%c128}, %result as %arg3: !stream.resource<external>{%c12}) {
      stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32 {
        ro %arg1[%c0 for %c16] : !stream.resource<external>{%c16},
        ro %arg2[%c0 for %c48] : !stream.resource<constant>{%c128},
        ro %arg2[%c64 for %c12] : !stream.resource<constant>{%c128},
        wo %arg3[%c0 for %c12] : !stream.resource<external>{%c12}
      }
    } => !stream.timepoint
    %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c12}
    %3 = stream.tensor.export %2 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
    return %3 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda], iree.fixedpoint.iteration = 1 : index} {
  util.global private mutable @_params.weight__timepoint = #stream.timepoint<immediate> : !stream.timepoint
  util.global private @_params.weight : !stream.resource<constant>
  util.initializer {
    %0 = stream.timepoint.immediate => !stream.timepoint
    %c0_i64 = arith.constant 0 : i64
    %c128 = arith.constant 128 : index
    %c0 = arith.constant 0 : index
    %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #composite_of_128b
    %did_map, %result = stream.resource.try_map %buffer_cst[%c0] : !util.buffer -> i1, !stream.resource<constant>{%c128}
    cf.cond_br %did_map, ^bb2(%0, %result : !stream.timepoint, !stream.resource<constant>), ^bb1
  ^bb1:  // pred: ^bb0
    %1 = stream.resource.alloc uninitialized : !stream.resource<constant>{%c128}
    %file = stream.file.constant %buffer_cst[%c0 for %c128] : !util.buffer{%c128} -> !stream.file
    %2 = stream.file.read await(%0) => %file[%c0_i64], %1[%c0], %c128 : !stream.file -> !stream.resource<constant>{%c128} => !stream.timepoint
    cf.br ^bb2(%2, %1 : !stream.timepoint, !stream.resource<constant>)
  ^bb2(%3: !stream.timepoint, %4: !stream.resource<constant>):  // 2 preds: ^bb0, ^bb1
    util.global.store %4, @_params.weight : !stream.resource<constant>
    util.global.store %3, @_params.weight__timepoint : !stream.timepoint
    util.initializer.return
  }
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_1x3x4_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        %4 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
        %5 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
        %6 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
        %7 = tensor.empty() : tensor<1x3xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%7 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %9 = linalg.matmul ins(%4, %5 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%8 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %10 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%9, %6 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%7 : tensor<1x3xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %11 = arith.addf %in, %in_0 : f32
          linalg.yield %11 : f32
        } -> tensor<1x3xf32>
        flow.dispatch.tensor.store %10, %3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c48 = arith.constant 48 : index
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %c12 = arith.constant 12 : index
    %c16 = arith.constant 16 : index
    %c128 = arith.constant 128 : index
    %c64 = arith.constant 64 : index
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !stream.timepoint
    %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
    %result, %result_timepoint = stream.resource.alloca uninitialized await(%_params.weight__timepoint) => !stream.resource<external>{%c12} => !stream.timepoint
    %1 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c16}, %_params.weight as %arg2: !stream.resource<constant>{%c128}, %result as %arg3: !stream.resource<external>{%c12}) {
      stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32 {
        ro %arg1[%c0 for %c16] : !stream.resource<external>{%c16},
        ro %arg2[%c0 for %c48] : !stream.resource<constant>{%c128},
        ro %arg2[%c64 for %c12] : !stream.resource<constant>{%c128},
        wo %arg3[%c0 for %c12] : !stream.resource<external>{%c12}
      }
    } => !stream.timepoint
    %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c12}
    %3 = stream.tensor.export %2 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
    return %3 : !hal.buffer_view
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda], iree.fixedpoint.iteration = 1 : index} {
  util.global private mutable @_params.weight__timepoint = #stream.timepoint<immediate> : !stream.timepoint
  util.global private @_params.weight : !stream.resource<constant>
  util.initializer {
    %0 = stream.timepoint.immediate => !stream.timepoint
    %c0_i64 = arith.constant 0 : i64
    %c128 = arith.constant 128 : index
    %c0 = arith.constant 0 : index
    %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #composite_of_128b
    %did_map, %result = stream.resource.try_map %buffer_cst[%c0] : !util.buffer -> i1, !stream.resource<constant>{%c128}
    cf.cond_br %did_map, ^bb2(%0, %result : !stream.timepoint, !stream.resource<constant>), ^bb1
  ^bb1:  // pred: ^bb0
    %1 = stream.resource.alloc uninitialized : !stream.resource<constant>{%c128}
    %file = stream.file.constant %buffer_cst[%c0 for %c128] : !util.buffer{%c128} -> !stream.file
    %2 = stream.file.read await(%0) => %file[%c0_i64], %1[%c0], %c128 : !stream.file -> !stream.resource<constant>{%c128} => !stream.timepoint
    cf.br ^bb2(%2, %1 : !stream.timepoint, !stream.resource<constant>)
  ^bb2(%3: !stream.timepoint, %4: !stream.resource<constant>):  // 2 preds: ^bb0, ^bb1
    util.global.store %4, @_params.weight : !stream.resource<constant>
    util.global.store %3, @_params.weight__timepoint : !stream.timepoint
    util.initializer.return
  }
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_1x3x4_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        %4 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
        %5 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
        %6 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
        %7 = tensor.empty() : tensor<1x3xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%7 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %9 = linalg.matmul ins(%4, %5 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%8 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %10 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%9, %6 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%7 : tensor<1x3xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %11 = arith.addf %in, %in_0 : f32
          linalg.yield %11 : f32
        } -> tensor<1x3xf32>
        flow.dispatch.tensor.store %10, %3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c48 = arith.constant 48 : index
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %c12 = arith.constant 12 : index
    %c16 = arith.constant 16 : index
    %c128 = arith.constant 128 : index
    %c64 = arith.constant 64 : index
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !stream.timepoint
    %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
    %result, %result_timepoint = stream.resource.alloca uninitialized await(%_params.weight__timepoint) => !stream.resource<external>{%c12} => !stream.timepoint
    %1 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c16}, %_params.weight as %arg2: !stream.resource<constant>{%c128}, %result as %arg3: !stream.resource<external>{%c12}) {
      stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32 {
        ro %arg1[%c0 for %c16] : !stream.resource<external>{%c16},
        ro %arg2[%c0 for %c48] : !stream.resource<constant>{%c128},
        ro %arg2[%c64 for %c12] : !stream.resource<constant>{%c128},
        wo %arg3[%c0 for %c12] : !stream.resource<external>{%c12}
      }
    } => !stream.timepoint
    %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c12}
    %3 = stream.tensor.export %2 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
    return %3 : !hal.buffer_view
  }
}


// -----// IR Dump After ElideTimepoints (iree-stream-elide-timepoints) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda], iree.fixedpoint.iteration = 1 : index} {
  util.global private mutable @_params.weight__timepoint = #stream.timepoint<immediate> : !stream.timepoint
  util.global private @_params.weight : !stream.resource<constant>
  util.initializer {
    %0 = stream.timepoint.immediate => !stream.timepoint
    %c0_i64 = arith.constant 0 : i64
    %c128 = arith.constant 128 : index
    %c0 = arith.constant 0 : index
    %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #composite_of_128b
    %did_map, %result = stream.resource.try_map %buffer_cst[%c0] : !util.buffer -> i1, !stream.resource<constant>{%c128}
    cf.cond_br %did_map, ^bb2(%0, %result : !stream.timepoint, !stream.resource<constant>), ^bb1
  ^bb1:  // pred: ^bb0
    %1 = stream.resource.alloc uninitialized : !stream.resource<constant>{%c128}
    %file = stream.file.constant %buffer_cst[%c0 for %c128] : !util.buffer{%c128} -> !stream.file
    %2 = stream.file.read await(%0) => %file[%c0_i64], %1[%c0], %c128 : !stream.file -> !stream.resource<constant>{%c128} => !stream.timepoint
    cf.br ^bb2(%2, %1 : !stream.timepoint, !stream.resource<constant>)
  ^bb2(%3: !stream.timepoint, %4: !stream.resource<constant>):  // 2 preds: ^bb0, ^bb1
    util.global.store %4, @_params.weight : !stream.resource<constant>
    util.global.store %3, @_params.weight__timepoint : !stream.timepoint
    util.initializer.return
  }
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_1x3x4_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        %4 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
        %5 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
        %6 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
        %7 = tensor.empty() : tensor<1x3xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%7 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %9 = linalg.matmul ins(%4, %5 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%8 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %10 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%9, %6 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%7 : tensor<1x3xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %11 = arith.addf %in, %in_0 : f32
          linalg.yield %11 : f32
        } -> tensor<1x3xf32>
        flow.dispatch.tensor.store %10, %3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c48 = arith.constant 48 : index
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %c12 = arith.constant 12 : index
    %c16 = arith.constant 16 : index
    %c128 = arith.constant 128 : index
    %c64 = arith.constant 64 : index
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !stream.timepoint
    %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
    %result, %result_timepoint = stream.resource.alloca uninitialized await(%_params.weight__timepoint) => !stream.resource<external>{%c12} => !stream.timepoint
    %1 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c16}, %_params.weight as %arg2: !stream.resource<constant>{%c128}, %result as %arg3: !stream.resource<external>{%c12}) {
      stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32 {
        ro %arg1[%c0 for %c16] : !stream.resource<external>{%c16},
        ro %arg2[%c0 for %c48] : !stream.resource<constant>{%c128},
        ro %arg2[%c64 for %c12] : !stream.resource<constant>{%c128},
        wo %arg3[%c0 for %c12] : !stream.resource<external>{%c12}
      }
    } => !stream.timepoint
    %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c12}
    %3 = stream.tensor.export %2 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
    return %3 : !hal.buffer_view
  }
}


// -----// IR Dump After FixedPointIterator (iree-util-fixed-point-iterator) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private mutable @_params.weight__timepoint = #stream.timepoint<immediate> : !stream.timepoint
  util.global private @_params.weight : !stream.resource<constant>
  util.initializer {
    %0 = stream.timepoint.immediate => !stream.timepoint
    %c0_i64 = arith.constant 0 : i64
    %c128 = arith.constant 128 : index
    %c0 = arith.constant 0 : index
    %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #composite_of_128b
    %did_map, %result = stream.resource.try_map %buffer_cst[%c0] : !util.buffer -> i1, !stream.resource<constant>{%c128}
    cf.cond_br %did_map, ^bb2(%0, %result : !stream.timepoint, !stream.resource<constant>), ^bb1
  ^bb1:  // pred: ^bb0
    %1 = stream.resource.alloc uninitialized : !stream.resource<constant>{%c128}
    %file = stream.file.constant %buffer_cst[%c0 for %c128] : !util.buffer{%c128} -> !stream.file
    %2 = stream.file.read await(%0) => %file[%c0_i64], %1[%c0], %c128 : !stream.file -> !stream.resource<constant>{%c128} => !stream.timepoint
    cf.br ^bb2(%2, %1 : !stream.timepoint, !stream.resource<constant>)
  ^bb2(%3: !stream.timepoint, %4: !stream.resource<constant>):  // 2 preds: ^bb0, ^bb1
    util.global.store %4, @_params.weight : !stream.resource<constant>
    util.global.store %3, @_params.weight__timepoint : !stream.timepoint
    util.initializer.return
  }
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_1x3x4_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding) {
        %cst = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
        %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        %4 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
        %5 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
        %6 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
        %7 = tensor.empty() : tensor<1x3xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%7 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %9 = linalg.matmul ins(%4, %5 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%8 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %10 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%9, %6 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%7 : tensor<1x3xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %11 = arith.addf %in, %in_0 : f32
          linalg.yield %11 : f32
        } -> tensor<1x3xf32>
        flow.dispatch.tensor.store %10, %3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c48 = arith.constant 48 : index
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %c12 = arith.constant 12 : index
    %c16 = arith.constant 16 : index
    %c128 = arith.constant 128 : index
    %c64 = arith.constant 64 : index
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !stream.timepoint
    %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
    %result, %result_timepoint = stream.resource.alloca uninitialized await(%_params.weight__timepoint) => !stream.resource<external>{%c12} => !stream.timepoint
    %1 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c16}, %_params.weight as %arg2: !stream.resource<constant>{%c128}, %result as %arg3: !stream.resource<external>{%c12}) {
      stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32 {
        ro %arg1[%c0 for %c16] : !stream.resource<external>{%c16},
        ro %arg2[%c0 for %c48] : !stream.resource<constant>{%c128},
        ro %arg2[%c64 for %c12] : !stream.resource<constant>{%c128},
        wo %arg3[%c0 for %c12] : !stream.resource<external>{%c12}
      }
    } => !stream.timepoint
    %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c12}
    %3 = stream.tensor.export %2 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
    return %3 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseDispatchBindings (iree-stream-fuse-dispatch-bindings) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private mutable @_params.weight__timepoint = #stream.timepoint<immediate> : !stream.timepoint
  util.global private @_params.weight : !stream.resource<constant>
  util.initializer {
    %0 = stream.timepoint.immediate => !stream.timepoint
    %c0_i64 = arith.constant 0 : i64
    %c128 = arith.constant 128 : index
    %c0 = arith.constant 0 : index
    %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #composite_of_128b
    %did_map, %result = stream.resource.try_map %buffer_cst[%c0] : !util.buffer -> i1, !stream.resource<constant>{%c128}
    cf.cond_br %did_map, ^bb2(%0, %result : !stream.timepoint, !stream.resource<constant>), ^bb1
  ^bb1:  // pred: ^bb0
    %1 = stream.resource.alloc uninitialized : !stream.resource<constant>{%c128}
    %file = stream.file.constant %buffer_cst[%c0 for %c128] : !util.buffer{%c128} -> !stream.file
    %2 = stream.file.read await(%0) => %file[%c0_i64], %1[%c0], %c128 : !stream.file -> !stream.resource<constant>{%c128} => !stream.timepoint
    cf.br ^bb2(%2, %1 : !stream.timepoint, !stream.resource<constant>)
  ^bb2(%3: !stream.timepoint, %4: !stream.resource<constant>):  // 2 preds: ^bb0, ^bb1
    util.global.store %4, @_params.weight : !stream.resource<constant>
    util.global.store %3, @_params.weight__timepoint : !stream.timepoint
    util.initializer.return
  }
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_1x3x4_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: index, %arg4: index, %arg5: index, %arg6: index) {
        %cst = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%arg3] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
        %1 = stream.binding.subspan %arg1[%arg4] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
        %2 = stream.binding.subspan %arg1[%arg5] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
        %3 = stream.binding.subspan %arg2[%arg6] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        %4 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
        %5 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
        %6 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
        %7 = tensor.empty() : tensor<1x3xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%7 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %9 = linalg.matmul ins(%4, %5 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%8 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %10 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%9, %6 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%7 : tensor<1x3xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %11 = arith.addf %in, %in_0 : f32
          linalg.yield %11 : f32
        } -> tensor<1x3xf32>
        flow.dispatch.tensor.store %10, %3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c48 = arith.constant 48 : index
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %c12 = arith.constant 12 : index
    %c16 = arith.constant 16 : index
    %c128 = arith.constant 128 : index
    %c64 = arith.constant 64 : index
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !stream.timepoint
    %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
    %result, %result_timepoint = stream.resource.alloca uninitialized await(%_params.weight__timepoint) => !stream.resource<external>{%c12} => !stream.timepoint
    %c0_0 = arith.constant 0 : index
    %1 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c16}, %_params.weight as %arg2: !stream.resource<constant>{%c128}, %result as %arg3: !stream.resource<external>{%c12}) {
      stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32(%c0, %c0, %c64, %c0 : index, index, index, index) {
        ro %arg1[%c0_0 for %c16] : !stream.resource<external>{%c16},
        ro %arg2[%c0_0 for %c128] : !stream.resource<constant>{%c128},
        wo %arg3[%c0_0 for %c12] : !stream.resource<external>{%c12}
      }
    } => !stream.timepoint
    %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c12}
    %3 = stream.tensor.export %2 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
    return %3 : !hal.buffer_view
  }
}


// -----// IR Dump After AnnotateDispatchArguments (iree-stream-annotate-dispatch-arguments) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private mutable @_params.weight__timepoint = #stream.timepoint<immediate> : !stream.timepoint
  util.global private @_params.weight : !stream.resource<constant>
  util.initializer {
    %0 = stream.timepoint.immediate => !stream.timepoint
    %c0_i64 = arith.constant 0 : i64
    %c128 = arith.constant 128 : index
    %c0 = arith.constant 0 : index
    %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #composite_of_128b
    %did_map, %result = stream.resource.try_map %buffer_cst[%c0] : !util.buffer -> i1, !stream.resource<constant>{%c128}
    cf.cond_br %did_map, ^bb2(%0, %result : !stream.timepoint, !stream.resource<constant>), ^bb1
  ^bb1:  // pred: ^bb0
    %1 = stream.resource.alloc uninitialized : !stream.resource<constant>{%c128}
    %file = stream.file.constant %buffer_cst[%c0 for %c128] : !util.buffer{%c128} -> !stream.file
    %2 = stream.file.read await(%0) => %file[%c0_i64], %1[%c0], %c128 : !stream.file -> !stream.resource<constant>{%c128} => !stream.timepoint
    cf.br ^bb2(%2, %1 : !stream.timepoint, !stream.resource<constant>)
  ^bb2(%3: !stream.timepoint, %4: !stream.resource<constant>):  // 2 preds: ^bb0, ^bb1
    util.global.store %4, @_params.weight : !stream.resource<constant>
    util.global.store %3, @_params.weight__timepoint : !stream.timepoint
    util.initializer.return
  }
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_1x3x4_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}, %arg3: index {stream.values = [0 : index]}, %arg4: index {stream.values = [0 : index]}, %arg5: index {stream.alignment = 64 : index, stream.values = [64 : index]}, %arg6: index {stream.values = [0 : index]}) {
        %cst = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%arg3] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
        %1 = stream.binding.subspan %arg1[%arg4] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
        %2 = stream.binding.subspan %arg1[%arg5] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
        %3 = stream.binding.subspan %arg2[%arg6] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        %4 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
        %5 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
        %6 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
        %7 = tensor.empty() : tensor<1x3xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%7 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %9 = linalg.matmul ins(%4, %5 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%8 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %10 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%9, %6 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%7 : tensor<1x3xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %11 = arith.addf %in, %in_0 : f32
          linalg.yield %11 : f32
        } -> tensor<1x3xf32>
        flow.dispatch.tensor.store %10, %3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c48 = arith.constant 48 : index
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %c12 = arith.constant 12 : index
    %c16 = arith.constant 16 : index
    %c128 = arith.constant 128 : index
    %c64 = arith.constant 64 : index
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !stream.timepoint
    %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
    %result, %result_timepoint = stream.resource.alloca uninitialized await(%_params.weight__timepoint) => !stream.resource<external>{%c12} => !stream.timepoint
    %c0_0 = arith.constant 0 : index
    %1 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c16}, %_params.weight as %arg2: !stream.resource<constant>{%c128}, %result as %arg3: !stream.resource<external>{%c12}) {
      stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32(%c0, %c0, %c64, %c0 : index, index, index, index) {
        ro %arg1[%c0_0 for %c16] : !stream.resource<external>{%c16},
        ro %arg2[%c0_0 for %c128] : !stream.resource<constant>{%c128},
        wo %arg3[%c0_0 for %c12] : !stream.resource<external>{%c12}
      }
    } => !stream.timepoint
    %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c12}
    %3 = stream.tensor.export %2 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
    return %3 : !hal.buffer_view
  }
}


// -----// IR Dump After PackDispatchOperands (iree-stream-pack-dispatch-operands) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private mutable @_params.weight__timepoint = #stream.timepoint<immediate> : !stream.timepoint
  util.global private @_params.weight : !stream.resource<constant>
  util.initializer {
    %0 = stream.timepoint.immediate => !stream.timepoint
    %c0_i64 = arith.constant 0 : i64
    %c128 = arith.constant 128 : index
    %c0 = arith.constant 0 : index
    %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #composite_of_128b
    %did_map, %result = stream.resource.try_map %buffer_cst[%c0] : !util.buffer -> i1, !stream.resource<constant>{%c128}
    cf.cond_br %did_map, ^bb2(%0, %result : !stream.timepoint, !stream.resource<constant>), ^bb1
  ^bb1:  // pred: ^bb0
    %1 = stream.resource.alloc uninitialized : !stream.resource<constant>{%c128}
    %file = stream.file.constant %buffer_cst[%c0 for %c128] : !util.buffer{%c128} -> !stream.file
    %2 = stream.file.read await(%0) => %file[%c0_i64], %1[%c0], %c128 : !stream.file -> !stream.resource<constant>{%c128} => !stream.timepoint
    cf.br ^bb2(%2, %1 : !stream.timepoint, !stream.resource<constant>)
  ^bb2(%3: !stream.timepoint, %4: !stream.resource<constant>):  // 2 preds: ^bb0, ^bb1
    util.global.store %4, @_params.weight : !stream.resource<constant>
    util.global.store %3, @_params.weight__timepoint : !stream.timepoint
    util.initializer.return
  }
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_1x3x4_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32) {
        %0 = arith.extui %arg3 : i32 to i64
        %1 = arith.extui %arg4 : i32 to i64
        %c32_i64 = arith.constant 32 : i64
        %2 = arith.shli %1, %c32_i64 : i64
        %3 = arith.ori %0, %2 : i64
        %4 = arith.index_castui %3 {stream.values = [0 : index]} : i64 to index
        %5 = arith.extui %arg5 : i32 to i64
        %6 = arith.extui %arg6 : i32 to i64
        %c32_i64_0 = arith.constant 32 : i64
        %7 = arith.shli %6, %c32_i64_0 : i64
        %8 = arith.ori %5, %7 : i64
        %9 = arith.index_castui %8 {stream.values = [0 : index]} : i64 to index
        %10 = arith.extui %arg7 : i32 to i64
        %11 = arith.extui %arg8 : i32 to i64
        %c32_i64_1 = arith.constant 32 : i64
        %12 = arith.shli %11, %c32_i64_1 : i64
        %13 = arith.ori %10, %12 : i64
        %14 = arith.index_castui %13 {stream.alignment = 64 : index, stream.values = [64 : index]} : i64 to index
        %15 = arith.extui %arg9 : i32 to i64
        %16 = arith.extui %arg10 : i32 to i64
        %c32_i64_2 = arith.constant 32 : i64
        %17 = arith.shli %16, %c32_i64_2 : i64
        %18 = arith.ori %15, %17 : i64
        %19 = arith.index_castui %18 {stream.values = [0 : index]} : i64 to index
        %cst = arith.constant 0.000000e+00 : f32
        %c0 = arith.constant 0 : index
        %20 = stream.binding.subspan %arg0[%4] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
        %21 = stream.binding.subspan %arg1[%9] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
        %22 = stream.binding.subspan %arg1[%14] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
        %23 = stream.binding.subspan %arg2[%19] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        %24 = flow.dispatch.tensor.load %20, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
        %25 = flow.dispatch.tensor.load %21, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
        %26 = flow.dispatch.tensor.load %22, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
        %27 = tensor.empty() : tensor<1x3xf32>
        %28 = linalg.fill ins(%cst : f32) outs(%27 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %29 = linalg.matmul ins(%24, %25 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%28 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %30 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%29, %26 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%27 : tensor<1x3xf32>) {
        ^bb0(%in: f32, %in_3: f32, %out: f32):
          %31 = arith.addf %in, %in_3 : f32
          linalg.yield %31 : f32
        } -> tensor<1x3xf32>
        flow.dispatch.tensor.store %30, %23, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c48 = arith.constant 48 : index
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %c12 = arith.constant 12 : index
    %c16 = arith.constant 16 : index
    %c128 = arith.constant 128 : index
    %c64 = arith.constant 64 : index
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !stream.timepoint
    %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
    %result, %result_timepoint = stream.resource.alloca uninitialized await(%_params.weight__timepoint) => !stream.resource<external>{%c12} => !stream.timepoint
    %c0_0 = arith.constant 0 : index
    %c0_i64 = arith.constant 0 : i64
    %c0_i32 = arith.constant 0 : i32
    %c32_i64 = arith.constant 32 : i64
    %c0_i64_1 = arith.constant 0 : i64
    %c0_i32_2 = arith.constant 0 : i32
    %c0_i64_3 = arith.constant 0 : i64
    %c0_i32_4 = arith.constant 0 : i32
    %c32_i64_5 = arith.constant 32 : i64
    %c0_i64_6 = arith.constant 0 : i64
    %c0_i32_7 = arith.constant 0 : i32
    %c64_i64 = arith.constant 64 : i64
    %c64_i32 = arith.constant 64 : i32
    %c32_i64_8 = arith.constant 32 : i64
    %c0_i64_9 = arith.constant 0 : i64
    %c0_i32_10 = arith.constant 0 : i32
    %c0_i64_11 = arith.constant 0 : i64
    %c0_i32_12 = arith.constant 0 : i32
    %c32_i64_13 = arith.constant 32 : i64
    %c0_i64_14 = arith.constant 0 : i64
    %c0_i32_15 = arith.constant 0 : i32
    %1 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c16}, %_params.weight as %arg2: !stream.resource<constant>{%c128}, %result as %arg3: !stream.resource<external>{%c12}) {
      stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32(%c0_i32, %c0_i32_2, %c0_i32_4, %c0_i32_7, %c64_i32, %c0_i32_10, %c0_i32_12, %c0_i32_15 : i32, i32, i32, i32, i32, i32, i32, i32) {
        ro %arg1[%c0_0 for %c16] : !stream.resource<external>{%c16},
        ro %arg2[%c0_0 for %c128] : !stream.resource<constant>{%c128},
        wo %arg3[%c0_0 for %c12] : !stream.resource<external>{%c12}
      }
    } => !stream.timepoint
    %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c12}
    %3 = stream.tensor.export %2 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
    return %3 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.initializer {
  %0 = stream.timepoint.immediate => !stream.timepoint
  %c0_i64 = arith.constant 0 : i64
  %c128 = arith.constant 128 : index
  %c0 = arith.constant 0 : index
  %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
  %did_map, %result = stream.resource.try_map %buffer_cst[%c0] : !util.buffer -> i1, !stream.resource<constant>{%c128}
  cf.cond_br %did_map, ^bb2(%0, %result : !stream.timepoint, !stream.resource<constant>), ^bb1
^bb1:  // pred: ^bb0
  %1 = stream.resource.alloc uninitialized : !stream.resource<constant>{%c128}
  %file = stream.file.constant %buffer_cst[%c0 for %c128] : !util.buffer{%c128} -> !stream.file
  %2 = stream.file.read await(%0) => %file[%c0_i64], %1[%c0], %c128 : !stream.file -> !stream.resource<constant>{%c128} => !stream.timepoint
  cf.br ^bb2(%2, %1 : !stream.timepoint, !stream.resource<constant>)
^bb2(%3: !stream.timepoint, %4: !stream.resource<constant>):  // 2 preds: ^bb0, ^bb1
  util.global.store %4, @_params.weight : !stream.resource<constant>
  util.global.store %3, @_params.weight__timepoint : !stream.timepoint
  util.initializer.return
}

// -----// IR Dump After CSE (cse) //----- //
util.initializer {
  %0 = stream.timepoint.immediate => !stream.timepoint
  %c0_i64 = arith.constant 0 : i64
  %c128 = arith.constant 128 : index
  %c0 = arith.constant 0 : index
  %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
  %did_map, %result = stream.resource.try_map %buffer_cst[%c0] : !util.buffer -> i1, !stream.resource<constant>{%c128}
  cf.cond_br %did_map, ^bb2(%0, %result : !stream.timepoint, !stream.resource<constant>), ^bb1
^bb1:  // pred: ^bb0
  %1 = stream.resource.alloc uninitialized : !stream.resource<constant>{%c128}
  %file = stream.file.constant %buffer_cst[%c0 for %c128] : !util.buffer{%c128} -> !stream.file
  %2 = stream.file.read await(%0) => %file[%c0_i64], %1[%c0], %c128 : !stream.file -> !stream.resource<constant>{%c128} => !stream.timepoint
  cf.br ^bb2(%2, %1 : !stream.timepoint, !stream.resource<constant>)
^bb2(%3: !stream.timepoint, %4: !stream.resource<constant>):  // 2 preds: ^bb0, ^bb1
  util.global.store %4, @_params.weight : !stream.resource<constant>
  util.global.store %3, @_params.weight__timepoint : !stream.timepoint
  util.initializer.return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c64_i32 = arith.constant 64 : i32
  %c0_i32 = arith.constant 0 : i32
  %c0 = arith.constant 0 : index
  %c4 = arith.constant 4 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %c12 = arith.constant 12 : index
  %c16 = arith.constant 16 : index
  %c128 = arith.constant 128 : index
  %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !stream.timepoint
  %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
  %result, %result_timepoint = stream.resource.alloca uninitialized await(%_params.weight__timepoint) => !stream.resource<external>{%c12} => !stream.timepoint
  %1 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c16}, %_params.weight as %arg2: !stream.resource<constant>{%c128}, %result as %arg3: !stream.resource<external>{%c12}) {
    stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32(%c0_i32, %c0_i32, %c0_i32, %c0_i32, %c64_i32, %c0_i32, %c0_i32, %c0_i32 : i32, i32, i32, i32, i32, i32, i32, i32) {
      ro %arg1[%c0 for %c16] : !stream.resource<external>{%c16},
      ro %arg2[%c0 for %c128] : !stream.resource<constant>{%c128},
      wo %arg3[%c0 for %c12] : !stream.resource<external>{%c12}
    }
  } => !stream.timepoint
  %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c12}
  %3 = stream.tensor.export %2 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
  return %3 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.initializer {
  %0 = stream.timepoint.immediate => !stream.timepoint
  %c0_i64 = arith.constant 0 : i64
  %c128 = arith.constant 128 : index
  %c0 = arith.constant 0 : index
  %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
  %did_map, %result = stream.resource.try_map %buffer_cst[%c0] : !util.buffer -> i1, !stream.resource<constant>{%c128}
  cf.cond_br %did_map, ^bb2(%0, %result : !stream.timepoint, !stream.resource<constant>), ^bb1
^bb1:  // pred: ^bb0
  %1 = stream.resource.alloc uninitialized : !stream.resource<constant>{%c128}
  %file = stream.file.constant %buffer_cst[%c0 for %c128] : !util.buffer{%c128} -> !stream.file
  %2 = stream.file.read await(%0) => %file[%c0_i64], %1[%c0], %c128 : !stream.file -> !stream.resource<constant>{%c128} => !stream.timepoint
  cf.br ^bb2(%2, %1 : !stream.timepoint, !stream.resource<constant>)
^bb2(%3: !stream.timepoint, %4: !stream.resource<constant>):  // 2 preds: ^bb0, ^bb1
  util.global.store %4, @_params.weight : !stream.resource<constant>
  util.global.store %3, @_params.weight__timepoint : !stream.timepoint
  util.initializer.return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c64_i32 = arith.constant 64 : i32
  %c0_i32 = arith.constant 0 : i32
  %c0 = arith.constant 0 : index
  %c4 = arith.constant 4 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %c12 = arith.constant 12 : index
  %c16 = arith.constant 16 : index
  %c128 = arith.constant 128 : index
  %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !stream.timepoint
  %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
  %result, %result_timepoint = stream.resource.alloca uninitialized await(%_params.weight__timepoint) => !stream.resource<external>{%c12} => !stream.timepoint
  %1 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c16}, %_params.weight as %arg2: !stream.resource<constant>{%c128}, %result as %arg3: !stream.resource<external>{%c12}) {
    stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32(%c0_i32, %c0_i32, %c0_i32, %c0_i32, %c64_i32, %c0_i32, %c0_i32, %c0_i32 : i32, i32, i32, i32, i32, i32, i32, i32) {
      ro %arg1[%c0 for %c16] : !stream.resource<external>{%c16},
      ro %arg2[%c0 for %c128] : !stream.resource<constant>{%c128},
      wo %arg3[%c0 for %c12] : !stream.resource<external>{%c12}
    }
  } => !stream.timepoint
  %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c12}
  %3 = stream.tensor.export %2 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
  return %3 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !stream.timepoint
  %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
  %c64_i32 = arith.constant 64 : i32
  %c0_i32 = arith.constant 0 : i32
  %c0 = arith.constant 0 : index
  %c4 = arith.constant 4 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %c12 = arith.constant 12 : index
  %c16 = arith.constant 16 : index
  %c128 = arith.constant 128 : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
  %result, %result_timepoint = stream.resource.alloca uninitialized await(%_params.weight__timepoint) => !stream.resource<external>{%c12} => !stream.timepoint
  %1 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c16}, %_params.weight as %arg2: !stream.resource<constant>{%c128}, %result as %arg3: !stream.resource<external>{%c12}) {
    stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32(%c0_i32, %c0_i32, %c0_i32, %c0_i32, %c64_i32, %c0_i32, %c0_i32, %c0_i32 : i32, i32, i32, i32, i32, i32, i32, i32) {
      ro %arg1[%c0 for %c16] : !stream.resource<external>{%c16},
      ro %arg2[%c0 for %c128] : !stream.resource<constant>{%c128},
      wo %arg3[%c0 for %c12] : !stream.resource<external>{%c12}
    }
  } => !stream.timepoint
  %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c12}
  %3 = stream.tensor.export %2 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
  return %3 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private mutable @_params.weight__timepoint = #stream.timepoint<immediate> : !stream.timepoint
  util.global private @_params.weight : !stream.resource<constant>
  util.initializer {
    %0 = stream.timepoint.immediate => !stream.timepoint
    %c0_i64 = arith.constant 0 : i64
    %c128 = arith.constant 128 : index
    %c0 = arith.constant 0 : index
    %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #composite_of_128b
    %did_map, %result = stream.resource.try_map %buffer_cst[%c0] : !util.buffer -> i1, !stream.resource<constant>{%c128}
    cf.cond_br %did_map, ^bb2(%0, %result : !stream.timepoint, !stream.resource<constant>), ^bb1
  ^bb1:  // pred: ^bb0
    %1 = stream.resource.alloc uninitialized : !stream.resource<constant>{%c128}
    %file = stream.file.constant %buffer_cst[%c0 for %c128] : !util.buffer{%c128} -> !stream.file
    %2 = stream.file.read await(%0) => %file[%c0_i64], %1[%c0], %c128 : !stream.file -> !stream.resource<constant>{%c128} => !stream.timepoint
    cf.br ^bb2(%2, %1 : !stream.timepoint, !stream.resource<constant>)
  ^bb2(%3: !stream.timepoint, %4: !stream.resource<constant>):  // 2 preds: ^bb0, ^bb1
    util.global.store %4, @_params.weight : !stream.resource<constant>
    util.global.store %3, @_params.weight__timepoint : !stream.timepoint
    util.initializer.return
  }
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_1x3x4_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32) {
        %cst = arith.constant 0.000000e+00 : f32
        %c32_i64 = arith.constant 32 : i64
        %0 = arith.extui %arg3 : i32 to i64
        %1 = arith.extui %arg4 : i32 to i64
        %2 = arith.shli %1, %c32_i64 : i64
        %3 = arith.ori %0, %2 : i64
        %4 = arith.index_castui %3 {stream.values = [0 : index]} : i64 to index
        %5 = arith.extui %arg5 : i32 to i64
        %6 = arith.extui %arg6 : i32 to i64
        %7 = arith.shli %6, %c32_i64 : i64
        %8 = arith.ori %5, %7 : i64
        %9 = arith.index_castui %8 {stream.values = [0 : index]} : i64 to index
        %10 = arith.extui %arg7 : i32 to i64
        %11 = arith.extui %arg8 : i32 to i64
        %12 = arith.shli %11, %c32_i64 : i64
        %13 = arith.ori %10, %12 : i64
        %14 = arith.index_castui %13 {stream.alignment = 64 : index, stream.values = [64 : index]} : i64 to index
        %15 = arith.extui %arg9 : i32 to i64
        %16 = arith.extui %arg10 : i32 to i64
        %17 = arith.shli %16, %c32_i64 : i64
        %18 = arith.ori %15, %17 : i64
        %19 = arith.index_castui %18 {stream.values = [0 : index]} : i64 to index
        %20 = stream.binding.subspan %arg0[%4] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
        %21 = stream.binding.subspan %arg1[%9] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
        %22 = stream.binding.subspan %arg1[%14] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
        %23 = stream.binding.subspan %arg2[%19] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        %24 = flow.dispatch.tensor.load %20, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
        %25 = flow.dispatch.tensor.load %21, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
        %26 = flow.dispatch.tensor.load %22, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
        %27 = tensor.empty() : tensor<1x3xf32>
        %28 = linalg.fill ins(%cst : f32) outs(%27 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %29 = linalg.matmul ins(%24, %25 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%28 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %30 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%29, %26 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%27 : tensor<1x3xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %31 = arith.addf %in, %in_0 : f32
          linalg.yield %31 : f32
        } -> tensor<1x3xf32>
        flow.dispatch.tensor.store %30, %23, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c128 = arith.constant 128 : index
    %c16 = arith.constant 16 : index
    %c12 = arith.constant 12 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c0_i32 = arith.constant 0 : i32
    %c64_i32 = arith.constant 64 : i32
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !stream.timepoint
    %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
    %result, %result_timepoint = stream.resource.alloca uninitialized await(%_params.weight__timepoint) => !stream.resource<external>{%c12} => !stream.timepoint
    %1 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c16}, %_params.weight as %arg2: !stream.resource<constant>{%c128}, %result as %arg3: !stream.resource<external>{%c12}) {
      stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32(%c0_i32, %c0_i32, %c0_i32, %c0_i32, %c64_i32, %c0_i32, %c0_i32, %c0_i32 : i32, i32, i32, i32, i32, i32, i32, i32) {
        ro %arg1[%c0 for %c16] : !stream.resource<external>{%c16},
        ro %arg2[%c0 for %c128] : !stream.resource<constant>{%c128},
        wo %arg3[%c0 for %c12] : !stream.resource<external>{%c12}
      }
    } => !stream.timepoint
    %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c12}
    %3 = stream.tensor.export %2 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
    return %3 : !hal.buffer_view
  }
}


// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private mutable @_params.weight__timepoint = #stream.timepoint<immediate> : !stream.timepoint
  util.global private @_params.weight : !stream.resource<constant>
  util.initializer {
    %0 = stream.timepoint.immediate => !stream.timepoint
    %c0_i64 = arith.constant 0 : i64
    %c128 = arith.constant 128 : index
    %c0 = arith.constant 0 : index
    %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #composite_of_128b
    %did_map, %result = stream.resource.try_map %buffer_cst[%c0] : !util.buffer -> i1, !stream.resource<constant>{%c128}
    cf.cond_br %did_map, ^bb2(%0, %result : !stream.timepoint, !stream.resource<constant>), ^bb1
  ^bb1:  // pred: ^bb0
    %1 = stream.resource.alloc uninitialized : !stream.resource<constant>{%c128}
    %file = stream.file.constant %buffer_cst[%c0 for %c128] : !util.buffer{%c128} -> !stream.file
    %2 = stream.file.read await(%0) => %file[%c0_i64], %1[%c0], %c128 : !stream.file -> !stream.resource<constant>{%c128} => !stream.timepoint
    cf.br ^bb2(%2, %1 : !stream.timepoint, !stream.resource<constant>)
  ^bb2(%3: !stream.timepoint, %4: !stream.resource<constant>):  // 2 preds: ^bb0, ^bb1
    util.global.store %4, @_params.weight : !stream.resource<constant>
    util.global.store %3, @_params.weight__timepoint : !stream.timepoint
    util.initializer.return
  }
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_1x3x4_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32) {
        %cst = arith.constant 0.000000e+00 : f32
        %c32_i64 = arith.constant 32 : i64
        %0 = arith.extui %arg3 : i32 to i64
        %1 = arith.extui %arg4 : i32 to i64
        %2 = arith.shli %1, %c32_i64 : i64
        %3 = arith.ori %0, %2 : i64
        %4 = arith.index_castui %3 {stream.values = [0 : index]} : i64 to index
        %5 = arith.extui %arg5 : i32 to i64
        %6 = arith.extui %arg6 : i32 to i64
        %7 = arith.shli %6, %c32_i64 : i64
        %8 = arith.ori %5, %7 : i64
        %9 = arith.index_castui %8 {stream.values = [0 : index]} : i64 to index
        %10 = arith.extui %arg7 : i32 to i64
        %11 = arith.extui %arg8 : i32 to i64
        %12 = arith.shli %11, %c32_i64 : i64
        %13 = arith.ori %10, %12 : i64
        %14 = arith.index_castui %13 {stream.alignment = 64 : index, stream.values = [64 : index]} : i64 to index
        %15 = arith.extui %arg9 : i32 to i64
        %16 = arith.extui %arg10 : i32 to i64
        %17 = arith.shli %16, %c32_i64 : i64
        %18 = arith.ori %15, %17 : i64
        %19 = arith.index_castui %18 {stream.values = [0 : index]} : i64 to index
        %20 = stream.binding.subspan %arg0[%4] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
        %21 = stream.binding.subspan %arg1[%9] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
        %22 = stream.binding.subspan %arg1[%14] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
        %23 = stream.binding.subspan %arg2[%19] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        %24 = flow.dispatch.tensor.load %20, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
        %25 = flow.dispatch.tensor.load %21, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
        %26 = flow.dispatch.tensor.load %22, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
        %27 = tensor.empty() : tensor<1x3xf32>
        %28 = linalg.fill ins(%cst : f32) outs(%27 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %29 = linalg.matmul ins(%24, %25 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%28 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %30 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%29, %26 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%27 : tensor<1x3xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %31 = arith.addf %in, %in_0 : f32
          linalg.yield %31 : f32
        } -> tensor<1x3xf32>
        flow.dispatch.tensor.store %30, %23, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c128 = arith.constant 128 : index
    %c16 = arith.constant 16 : index
    %c12 = arith.constant 12 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c0_i32 = arith.constant 0 : i32
    %c64_i32 = arith.constant 64 : i32
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !stream.timepoint
    %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
    %result, %result_timepoint = stream.resource.alloca uninitialized await(%_params.weight__timepoint) => !stream.resource<external>{%c12} => !stream.timepoint
    %1 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c16}, %_params.weight as %arg2: !stream.resource<constant>{%c128}, %result as %arg3: !stream.resource<external>{%c12}) {
      stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32(%c0_i32, %c0_i32, %c0_i32, %c0_i32, %c64_i32, %c0_i32, %c0_i32, %c0_i32 : i32, i32, i32, i32, i32, i32, i32, i32) {
        ro %arg1[%c0 for %c16] : !stream.resource<external>{%c16},
        ro %arg2[%c0 for %c128] : !stream.resource<constant>{%c128},
        wo %arg3[%c0 for %c12] : !stream.resource<external>{%c12}
      }
    } => !stream.timepoint
    %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c12}
    %3 = stream.tensor.export %2 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
    return %3 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private mutable @_params.weight__timepoint = #stream.timepoint<immediate> : !stream.timepoint
  util.global private @_params.weight : !stream.resource<constant>
  util.initializer {
    %0 = stream.timepoint.immediate => !stream.timepoint
    %c0_i64 = arith.constant 0 : i64
    %c128 = arith.constant 128 : index
    %c0 = arith.constant 0 : index
    %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #composite_of_128b
    %did_map, %result = stream.resource.try_map %buffer_cst[%c0] : !util.buffer -> i1, !stream.resource<constant>{%c128}
    cf.cond_br %did_map, ^bb2(%0, %result : !stream.timepoint, !stream.resource<constant>), ^bb1
  ^bb1:  // pred: ^bb0
    %1 = stream.resource.alloc uninitialized : !stream.resource<constant>{%c128}
    %file = stream.file.constant %buffer_cst[%c0 for %c128] : !util.buffer{%c128} -> !stream.file
    %2 = stream.file.read await(%0) => %file[%c0_i64], %1[%c0], %c128 : !stream.file -> !stream.resource<constant>{%c128} => !stream.timepoint
    cf.br ^bb2(%2, %1 : !stream.timepoint, !stream.resource<constant>)
  ^bb2(%3: !stream.timepoint, %4: !stream.resource<constant>):  // 2 preds: ^bb0, ^bb1
    util.global.store %4, @_params.weight : !stream.resource<constant>
    util.global.store %3, @_params.weight__timepoint : !stream.timepoint
    util.initializer.return
  }
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_1x3x4_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32) {
        %cst = arith.constant 0.000000e+00 : f32
        %c32_i64 = arith.constant 32 : i64
        %0 = arith.extui %arg3 : i32 to i64
        %1 = arith.extui %arg4 : i32 to i64
        %2 = arith.shli %1, %c32_i64 : i64
        %3 = arith.ori %0, %2 : i64
        %4 = arith.index_castui %3 {stream.values = [0 : index]} : i64 to index
        %5 = arith.extui %arg5 : i32 to i64
        %6 = arith.extui %arg6 : i32 to i64
        %7 = arith.shli %6, %c32_i64 : i64
        %8 = arith.ori %5, %7 : i64
        %9 = arith.index_castui %8 {stream.values = [0 : index]} : i64 to index
        %10 = arith.extui %arg7 : i32 to i64
        %11 = arith.extui %arg8 : i32 to i64
        %12 = arith.shli %11, %c32_i64 : i64
        %13 = arith.ori %10, %12 : i64
        %14 = arith.index_castui %13 {stream.alignment = 64 : index, stream.values = [64 : index]} : i64 to index
        %15 = arith.extui %arg9 : i32 to i64
        %16 = arith.extui %arg10 : i32 to i64
        %17 = arith.shli %16, %c32_i64 : i64
        %18 = arith.ori %15, %17 : i64
        %19 = arith.index_castui %18 {stream.values = [0 : index]} : i64 to index
        %20 = stream.binding.subspan %arg0[%4] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
        %21 = stream.binding.subspan %arg1[%9] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
        %22 = stream.binding.subspan %arg1[%14] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
        %23 = stream.binding.subspan %arg2[%19] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        %24 = flow.dispatch.tensor.load %20, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
        %25 = flow.dispatch.tensor.load %21, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
        %26 = flow.dispatch.tensor.load %22, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
        %27 = tensor.empty() : tensor<1x3xf32>
        %28 = linalg.fill ins(%cst : f32) outs(%27 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %29 = linalg.matmul ins(%24, %25 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%28 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %30 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%29, %26 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%27 : tensor<1x3xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %31 = arith.addf %in, %in_0 : f32
          linalg.yield %31 : f32
        } -> tensor<1x3xf32>
        flow.dispatch.tensor.store %30, %23, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c128 = arith.constant 128 : index
    %c16 = arith.constant 16 : index
    %c12 = arith.constant 12 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c0_i32 = arith.constant 0 : i32
    %c64_i32 = arith.constant 64 : i32
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !stream.timepoint
    %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
    %result, %result_timepoint = stream.resource.alloca uninitialized await(%_params.weight__timepoint) => !stream.resource<external>{%c12} => !stream.timepoint
    %1 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c16}, %_params.weight as %arg2: !stream.resource<constant>{%c128}, %result as %arg3: !stream.resource<external>{%c12}) {
      stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32(%c0_i32, %c0_i32, %c0_i32, %c0_i32, %c64_i32, %c0_i32, %c0_i32, %c0_i32 : i32, i32, i32, i32, i32, i32, i32, i32) {
        ro %arg1[%c0 for %c16] : !stream.resource<external>{%c16},
        ro %arg2[%c0 for %c128] : !stream.resource<constant>{%c128},
        wo %arg3[%c0 for %c12] : !stream.resource<external>{%c12}
      }
    } => !stream.timepoint
    %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c12}
    %3 = stream.tensor.export %2 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
    return %3 : !hal.buffer_view
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private mutable @_params.weight__timepoint = #stream.timepoint<immediate> : !stream.timepoint
  util.global private @_params.weight : !stream.resource<constant>
  util.initializer {
    %0 = stream.timepoint.immediate => !stream.timepoint
    %c0_i64 = arith.constant 0 : i64
    %c128 = arith.constant 128 : index
    %c0 = arith.constant 0 : index
    %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #composite_of_128b
    %did_map, %result = stream.resource.try_map %buffer_cst[%c0] : !util.buffer -> i1, !stream.resource<constant>{%c128}
    cf.cond_br %did_map, ^bb2(%0, %result : !stream.timepoint, !stream.resource<constant>), ^bb1
  ^bb1:  // pred: ^bb0
    %1 = stream.resource.alloc uninitialized : !stream.resource<constant>{%c128}
    %file = stream.file.constant %buffer_cst[%c0 for %c128] : !util.buffer{%c128} -> !stream.file
    %2 = stream.file.read await(%0) => %file[%c0_i64], %1[%c0], %c128 : !stream.file -> !stream.resource<constant>{%c128} => !stream.timepoint
    cf.br ^bb2(%2, %1 : !stream.timepoint, !stream.resource<constant>)
  ^bb2(%3: !stream.timepoint, %4: !stream.resource<constant>):  // 2 preds: ^bb0, ^bb1
    util.global.store %4, @_params.weight : !stream.resource<constant>
    util.global.store %3, @_params.weight__timepoint : !stream.timepoint
    util.initializer.return
  }
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_1x3x4_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32) {
        %cst = arith.constant 0.000000e+00 : f32
        %c32_i64 = arith.constant 32 : i64
        %0 = arith.extui %arg3 : i32 to i64
        %1 = arith.extui %arg4 : i32 to i64
        %2 = arith.shli %1, %c32_i64 : i64
        %3 = arith.ori %0, %2 : i64
        %4 = arith.index_castui %3 {stream.values = [0 : index]} : i64 to index
        %5 = arith.extui %arg5 : i32 to i64
        %6 = arith.extui %arg6 : i32 to i64
        %7 = arith.shli %6, %c32_i64 : i64
        %8 = arith.ori %5, %7 : i64
        %9 = arith.index_castui %8 {stream.values = [0 : index]} : i64 to index
        %10 = arith.extui %arg7 : i32 to i64
        %11 = arith.extui %arg8 : i32 to i64
        %12 = arith.shli %11, %c32_i64 : i64
        %13 = arith.ori %10, %12 : i64
        %14 = arith.index_castui %13 {stream.alignment = 64 : index, stream.values = [64 : index]} : i64 to index
        %15 = arith.extui %arg9 : i32 to i64
        %16 = arith.extui %arg10 : i32 to i64
        %17 = arith.shli %16, %c32_i64 : i64
        %18 = arith.ori %15, %17 : i64
        %19 = arith.index_castui %18 {stream.values = [0 : index]} : i64 to index
        %20 = stream.binding.subspan %arg0[%4] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
        %21 = stream.binding.subspan %arg1[%9] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
        %22 = stream.binding.subspan %arg1[%14] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
        %23 = stream.binding.subspan %arg2[%19] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        %24 = flow.dispatch.tensor.load %20, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
        %25 = flow.dispatch.tensor.load %21, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
        %26 = flow.dispatch.tensor.load %22, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
        %27 = tensor.empty() : tensor<1x3xf32>
        %28 = linalg.fill ins(%cst : f32) outs(%27 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %29 = linalg.matmul ins(%24, %25 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%28 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %30 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%29, %26 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%27 : tensor<1x3xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %31 = arith.addf %in, %in_0 : f32
          linalg.yield %31 : f32
        } -> tensor<1x3xf32>
        flow.dispatch.tensor.store %30, %23, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c128 = arith.constant 128 : index
    %c16 = arith.constant 16 : index
    %c12 = arith.constant 12 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c0_i32 = arith.constant 0 : i32
    %c64_i32 = arith.constant 64 : i32
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !stream.timepoint
    %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
    %result, %result_timepoint = stream.resource.alloca uninitialized await(%_params.weight__timepoint) => !stream.resource<external>{%c12} => !stream.timepoint
    %1 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c16}, %_params.weight as %arg2: !stream.resource<constant>{%c128}, %result as %arg3: !stream.resource<external>{%c12}) {
      stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32(%c0_i32, %c0_i32, %c0_i32, %c0_i32, %c64_i32, %c0_i32, %c0_i32, %c0_i32 : i32, i32, i32, i32, i32, i32, i32, i32) {
        ro %arg1[%c0 for %c16] : !stream.resource<external>{%c16},
        ro %arg2[%c0 for %c128] : !stream.resource<constant>{%c128},
        wo %arg3[%c0 for %c12] : !stream.resource<external>{%c12}
      }
    } => !stream.timepoint
    %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c12}
    %3 = stream.tensor.export %2 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
    return %3 : !hal.buffer_view
  }
}


// -----// IR Dump After FoldUniformOperands (iree-stream-fold-uniform-operands) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private mutable @_params.weight__timepoint = #stream.timepoint<immediate> : !stream.timepoint
  util.global private @_params.weight : !stream.resource<constant>
  util.initializer {
    %0 = stream.timepoint.immediate => !stream.timepoint
    %c0_i64 = arith.constant 0 : i64
    %c128 = arith.constant 128 : index
    %c0 = arith.constant 0 : index
    %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #composite_of_128b
    %did_map, %result = stream.resource.try_map %buffer_cst[%c0] : !util.buffer -> i1, !stream.resource<constant>{%c128}
    cf.cond_br %did_map, ^bb2(%0, %result : !stream.timepoint, !stream.resource<constant>), ^bb1
  ^bb1:  // pred: ^bb0
    %1 = stream.resource.alloc uninitialized : !stream.resource<constant>{%c128}
    %file = stream.file.constant %buffer_cst[%c0 for %c128] : !util.buffer{%c128} -> !stream.file
    %2 = stream.file.read await(%0) => %file[%c0_i64], %1[%c0], %c128 : !stream.file -> !stream.resource<constant>{%c128} => !stream.timepoint
    cf.br ^bb2(%2, %1 : !stream.timepoint, !stream.resource<constant>)
  ^bb2(%3: !stream.timepoint, %4: !stream.resource<constant>):  // 2 preds: ^bb0, ^bb1
    util.global.store %4, @_params.weight : !stream.resource<constant>
    util.global.store %3, @_params.weight__timepoint : !stream.timepoint
    util.initializer.return
  }
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_1x3x4_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}) {
        %c0_i32 = arith.constant 0 : i32
        %c64_i32 = arith.constant 64 : i32
        %cst = arith.constant 0.000000e+00 : f32
        %c32_i64 = arith.constant 32 : i64
        %0 = arith.extui %c0_i32 : i32 to i64
        %1 = arith.extui %c0_i32 : i32 to i64
        %2 = arith.shli %1, %c32_i64 : i64
        %3 = arith.ori %0, %2 : i64
        %4 = arith.index_castui %3 {stream.values = [0 : index]} : i64 to index
        %5 = arith.extui %c0_i32 : i32 to i64
        %6 = arith.extui %c0_i32 : i32 to i64
        %7 = arith.shli %6, %c32_i64 : i64
        %8 = arith.ori %5, %7 : i64
        %9 = arith.index_castui %8 {stream.values = [0 : index]} : i64 to index
        %10 = arith.extui %c64_i32 : i32 to i64
        %11 = arith.extui %c0_i32 : i32 to i64
        %12 = arith.shli %11, %c32_i64 : i64
        %13 = arith.ori %10, %12 : i64
        %14 = arith.index_castui %13 {stream.alignment = 64 : index, stream.values = [64 : index]} : i64 to index
        %15 = arith.extui %c0_i32 : i32 to i64
        %16 = arith.extui %c0_i32 : i32 to i64
        %17 = arith.shli %16, %c32_i64 : i64
        %18 = arith.ori %15, %17 : i64
        %19 = arith.index_castui %18 {stream.values = [0 : index]} : i64 to index
        %20 = stream.binding.subspan %arg0[%4] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
        %21 = stream.binding.subspan %arg1[%9] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
        %22 = stream.binding.subspan %arg1[%14] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
        %23 = stream.binding.subspan %arg2[%19] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        %24 = flow.dispatch.tensor.load %20, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
        %25 = flow.dispatch.tensor.load %21, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
        %26 = flow.dispatch.tensor.load %22, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
        %27 = tensor.empty() : tensor<1x3xf32>
        %28 = linalg.fill ins(%cst : f32) outs(%27 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %29 = linalg.matmul ins(%24, %25 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%28 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %30 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%29, %26 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%27 : tensor<1x3xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %31 = arith.addf %in, %in_0 : f32
          linalg.yield %31 : f32
        } -> tensor<1x3xf32>
        flow.dispatch.tensor.store %30, %23, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c128 = arith.constant 128 : index
    %c16 = arith.constant 16 : index
    %c12 = arith.constant 12 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c0_i32 = arith.constant 0 : i32
    %c64_i32 = arith.constant 64 : i32
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !stream.timepoint
    %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
    %result, %result_timepoint = stream.resource.alloca uninitialized await(%_params.weight__timepoint) => !stream.resource<external>{%c12} => !stream.timepoint
    %1 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c16}, %_params.weight as %arg2: !stream.resource<constant>{%c128}, %result as %arg3: !stream.resource<external>{%c12}) {
      stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32 {
        ro %arg1[%c0 for %c16] : !stream.resource<external>{%c16},
        ro %arg2[%c0 for %c128] : !stream.resource<constant>{%c128},
        wo %arg3[%c0 for %c12] : !stream.resource<external>{%c12}
      }
    } => !stream.timepoint
    %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c12}
    %3 = stream.tensor.export %2 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
    return %3 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.initializer {
  %0 = stream.timepoint.immediate => !stream.timepoint
  %c0_i64 = arith.constant 0 : i64
  %c128 = arith.constant 128 : index
  %c0 = arith.constant 0 : index
  %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
  %did_map, %result = stream.resource.try_map %buffer_cst[%c0] : !util.buffer -> i1, !stream.resource<constant>{%c128}
  cf.cond_br %did_map, ^bb2(%0, %result : !stream.timepoint, !stream.resource<constant>), ^bb1
^bb1:  // pred: ^bb0
  %1 = stream.resource.alloc uninitialized : !stream.resource<constant>{%c128}
  %file = stream.file.constant %buffer_cst[%c0 for %c128] : !util.buffer{%c128} -> !stream.file
  %2 = stream.file.read await(%0) => %file[%c0_i64], %1[%c0], %c128 : !stream.file -> !stream.resource<constant>{%c128} => !stream.timepoint
  cf.br ^bb2(%2, %1 : !stream.timepoint, !stream.resource<constant>)
^bb2(%3: !stream.timepoint, %4: !stream.resource<constant>):  // 2 preds: ^bb0, ^bb1
  util.global.store %4, @_params.weight : !stream.resource<constant>
  util.global.store %3, @_params.weight__timepoint : !stream.timepoint
  util.initializer.return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c128 = arith.constant 128 : index
  %c16 = arith.constant 16 : index
  %c12 = arith.constant 12 : index
  %c553648160_i32 = arith.constant 553648160 : i32
  %c1_i32 = arith.constant 1 : i32
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !stream.timepoint
  %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
  %result, %result_timepoint = stream.resource.alloca uninitialized await(%_params.weight__timepoint) => !stream.resource<external>{%c12} => !stream.timepoint
  %1 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c16}, %_params.weight as %arg2: !stream.resource<constant>{%c128}, %result as %arg3: !stream.resource<external>{%c12}) {
    stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32 {
      ro %arg1[%c0 for %c16] : !stream.resource<external>{%c16},
      ro %arg2[%c0 for %c128] : !stream.resource<constant>{%c128},
      wo %arg3[%c0 for %c12] : !stream.resource<external>{%c12}
    }
  } => !stream.timepoint
  %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c12}
  %3 = stream.tensor.export %2 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
  return %3 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c128 = arith.constant 128 : index
  %c16 = arith.constant 16 : index
  %c12 = arith.constant 12 : index
  %c553648160_i32 = arith.constant 553648160 : i32
  %c1_i32 = arith.constant 1 : i32
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !stream.timepoint
  %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
  %result, %result_timepoint = stream.resource.alloca uninitialized await(%_params.weight__timepoint) => !stream.resource<external>{%c12} => !stream.timepoint
  %1 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c16}, %_params.weight as %arg2: !stream.resource<constant>{%c128}, %result as %arg3: !stream.resource<external>{%c12}) {
    stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32 {
      ro %arg1[%c0 for %c16] : !stream.resource<external>{%c16},
      ro %arg2[%c0 for %c128] : !stream.resource<constant>{%c128},
      wo %arg3[%c0 for %c12] : !stream.resource<external>{%c12}
    }
  } => !stream.timepoint
  %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c12}
  %3 = stream.tensor.export %2 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
  return %3 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
util.initializer {
  %0 = stream.timepoint.immediate => !stream.timepoint
  %c0_i64 = arith.constant 0 : i64
  %c128 = arith.constant 128 : index
  %c0 = arith.constant 0 : index
  %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
  %did_map, %result = stream.resource.try_map %buffer_cst[%c0] : !util.buffer -> i1, !stream.resource<constant>{%c128}
  cf.cond_br %did_map, ^bb2(%0, %result : !stream.timepoint, !stream.resource<constant>), ^bb1
^bb1:  // pred: ^bb0
  %1 = stream.resource.alloc uninitialized : !stream.resource<constant>{%c128}
  %file = stream.file.constant %buffer_cst[%c0 for %c128] : !util.buffer{%c128} -> !stream.file
  %2 = stream.file.read await(%0) => %file[%c0_i64], %1[%c0], %c128 : !stream.file -> !stream.resource<constant>{%c128} => !stream.timepoint
  cf.br ^bb2(%2, %1 : !stream.timepoint, !stream.resource<constant>)
^bb2(%3: !stream.timepoint, %4: !stream.resource<constant>):  // 2 preds: ^bb0, ^bb1
  util.global.store %4, @_params.weight : !stream.resource<constant>
  util.global.store %3, @_params.weight__timepoint : !stream.timepoint
  util.initializer.return
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !stream.timepoint
  %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
  %c128 = arith.constant 128 : index
  %c16 = arith.constant 16 : index
  %c12 = arith.constant 12 : index
  %c553648160_i32 = arith.constant 553648160 : i32
  %c1_i32 = arith.constant 1 : i32
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
  %result, %result_timepoint = stream.resource.alloca uninitialized await(%_params.weight__timepoint) => !stream.resource<external>{%c12} => !stream.timepoint
  %1 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c16}, %_params.weight as %arg2: !stream.resource<constant>{%c128}, %result as %arg3: !stream.resource<external>{%c12}) {
    stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32 {
      ro %arg1[%c0 for %c16] : !stream.resource<external>{%c16},
      ro %arg2[%c0 for %c128] : !stream.resource<constant>{%c128},
      wo %arg3[%c0 for %c12] : !stream.resource<external>{%c12}
    }
  } => !stream.timepoint
  %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c12}
  %3 = stream.tensor.export %2 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
  return %3 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.initializer {
  %0 = stream.timepoint.immediate => !stream.timepoint
  %c0_i64 = arith.constant 0 : i64
  %c128 = arith.constant 128 : index
  %c0 = arith.constant 0 : index
  %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
  %did_map, %result = stream.resource.try_map %buffer_cst[%c0] : !util.buffer -> i1, !stream.resource<constant>{%c128}
  cf.cond_br %did_map, ^bb2(%0, %result : !stream.timepoint, !stream.resource<constant>), ^bb1
^bb1:  // pred: ^bb0
  %1 = stream.resource.alloc uninitialized : !stream.resource<constant>{%c128}
  %file = stream.file.constant %buffer_cst[%c0 for %c128] : !util.buffer{%c128} -> !stream.file
  %2 = stream.file.read await(%0) => %file[%c0_i64], %1[%c0], %c128 : !stream.file -> !stream.resource<constant>{%c128} => !stream.timepoint
  cf.br ^bb2(%2, %1 : !stream.timepoint, !stream.resource<constant>)
^bb2(%3: !stream.timepoint, %4: !stream.resource<constant>):  // 2 preds: ^bb0, ^bb1
  util.global.store %4, @_params.weight : !stream.resource<constant>
  util.global.store %3, @_params.weight__timepoint : !stream.timepoint
  util.initializer.return
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private mutable @_params.weight__timepoint = #stream.timepoint<immediate> : !stream.timepoint
  util.global private @_params.weight : !stream.resource<constant>
  util.initializer {
    %0 = stream.timepoint.immediate => !stream.timepoint
    %c0_i64 = arith.constant 0 : i64
    %c128 = arith.constant 128 : index
    %c0 = arith.constant 0 : index
    %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #composite_of_128b
    %did_map, %result = stream.resource.try_map %buffer_cst[%c0] : !util.buffer -> i1, !stream.resource<constant>{%c128}
    cf.cond_br %did_map, ^bb2(%0, %result : !stream.timepoint, !stream.resource<constant>), ^bb1
  ^bb1:  // pred: ^bb0
    %1 = stream.resource.alloc uninitialized : !stream.resource<constant>{%c128}
    %file = stream.file.constant %buffer_cst[%c0 for %c128] : !util.buffer{%c128} -> !stream.file
    %2 = stream.file.read await(%0) => %file[%c0_i64], %1[%c0], %c128 : !stream.file -> !stream.resource<constant>{%c128} => !stream.timepoint
    cf.br ^bb2(%2, %1 : !stream.timepoint, !stream.resource<constant>)
  ^bb2(%3: !stream.timepoint, %4: !stream.resource<constant>):  // 2 preds: ^bb0, ^bb1
    util.global.store %4, @_params.weight : !stream.resource<constant>
    util.global.store %3, @_params.weight__timepoint : !stream.timepoint
    util.initializer.return
  }
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_1x3x4_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}) {
        %c0 = arith.constant 0 : index
        %c64 = arith.constant 64 : index
        %cst = arith.constant 0.000000e+00 : f32
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
        %2 = stream.binding.subspan %arg1[%c64] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
        %3 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        %4 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
        %5 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
        %6 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
        %7 = tensor.empty() : tensor<1x3xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%7 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %9 = linalg.matmul ins(%4, %5 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%8 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %10 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%9, %6 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%7 : tensor<1x3xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %11 = arith.addf %in, %in_0 : f32
          linalg.yield %11 : f32
        } -> tensor<1x3xf32>
        flow.dispatch.tensor.store %10, %3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %c12 = arith.constant 12 : index
    %c16 = arith.constant 16 : index
    %c128 = arith.constant 128 : index
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !stream.timepoint
    %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
    %result, %result_timepoint = stream.resource.alloca uninitialized await(%_params.weight__timepoint) => !stream.resource<external>{%c12} => !stream.timepoint
    %1 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c16}, %_params.weight as %arg2: !stream.resource<constant>{%c128}, %result as %arg3: !stream.resource<external>{%c12}) {
      stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32 {
        ro %arg1[%c0 for %c16] : !stream.resource<external>{%c16},
        ro %arg2[%c0 for %c128] : !stream.resource<constant>{%c128},
        wo %arg3[%c0 for %c12] : !stream.resource<external>{%c12}
      }
    } => !stream.timepoint
    %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c12}
    %3 = stream.tensor.export %2 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
    return %3 : !hal.buffer_view
  }
}


// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private mutable @_params.weight__timepoint = #stream.timepoint<immediate> : !stream.timepoint
  util.global private @_params.weight : !stream.resource<constant>
  util.initializer {
    %0 = stream.timepoint.immediate => !stream.timepoint
    %c0_i64 = arith.constant 0 : i64
    %c128 = arith.constant 128 : index
    %c0 = arith.constant 0 : index
    %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #composite_of_128b
    %did_map, %result = stream.resource.try_map %buffer_cst[%c0] : !util.buffer -> i1, !stream.resource<constant>{%c128}
    cf.cond_br %did_map, ^bb2(%0, %result : !stream.timepoint, !stream.resource<constant>), ^bb1
  ^bb1:  // pred: ^bb0
    %1 = stream.resource.alloc uninitialized : !stream.resource<constant>{%c128}
    %file = stream.file.constant %buffer_cst[%c0 for %c128] : !util.buffer{%c128} -> !stream.file
    %2 = stream.file.read await(%0) => %file[%c0_i64], %1[%c0], %c128 : !stream.file -> !stream.resource<constant>{%c128} => !stream.timepoint
    cf.br ^bb2(%2, %1 : !stream.timepoint, !stream.resource<constant>)
  ^bb2(%3: !stream.timepoint, %4: !stream.resource<constant>):  // 2 preds: ^bb0, ^bb1
    util.global.store %4, @_params.weight : !stream.resource<constant>
    util.global.store %3, @_params.weight__timepoint : !stream.timepoint
    util.initializer.return
  }
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_1x3x4_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}) {
        %c0 = arith.constant 0 : index
        %c64 = arith.constant 64 : index
        %cst = arith.constant 0.000000e+00 : f32
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
        %2 = stream.binding.subspan %arg1[%c64] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
        %3 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        %4 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
        %5 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
        %6 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
        %7 = tensor.empty() : tensor<1x3xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%7 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %9 = linalg.matmul ins(%4, %5 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%8 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %10 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%9, %6 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%7 : tensor<1x3xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %11 = arith.addf %in, %in_0 : f32
          linalg.yield %11 : f32
        } -> tensor<1x3xf32>
        flow.dispatch.tensor.store %10, %3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %c12 = arith.constant 12 : index
    %c16 = arith.constant 16 : index
    %c128 = arith.constant 128 : index
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !stream.timepoint
    %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
    %result, %result_timepoint = stream.resource.alloca uninitialized await(%_params.weight__timepoint) => !stream.resource<external>{%c12} => !stream.timepoint
    %1 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c16}, %_params.weight as %arg2: !stream.resource<constant>{%c128}, %result as %arg3: !stream.resource<external>{%c12}) {
      stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32 {
        ro %arg1[%c0 for %c16] : !stream.resource<external>{%c16},
        ro %arg2[%c0 for %c128] : !stream.resource<constant>{%c128},
        wo %arg3[%c0 for %c12] : !stream.resource<external>{%c12}
      }
    } => !stream.timepoint
    %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c12}
    %3 = stream.tensor.export %2 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
    return %3 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private mutable @_params.weight__timepoint = #stream.timepoint<immediate> : !stream.timepoint
  util.global private @_params.weight : !stream.resource<constant>
  util.initializer {
    %0 = stream.timepoint.immediate => !stream.timepoint
    %c0_i64 = arith.constant 0 : i64
    %c128 = arith.constant 128 : index
    %c0 = arith.constant 0 : index
    %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #composite_of_128b
    %did_map, %result = stream.resource.try_map %buffer_cst[%c0] : !util.buffer -> i1, !stream.resource<constant>{%c128}
    cf.cond_br %did_map, ^bb2(%0, %result : !stream.timepoint, !stream.resource<constant>), ^bb1
  ^bb1:  // pred: ^bb0
    %1 = stream.resource.alloc uninitialized : !stream.resource<constant>{%c128}
    %file = stream.file.constant %buffer_cst[%c0 for %c128] : !util.buffer{%c128} -> !stream.file
    %2 = stream.file.read await(%0) => %file[%c0_i64], %1[%c0], %c128 : !stream.file -> !stream.resource<constant>{%c128} => !stream.timepoint
    cf.br ^bb2(%2, %1 : !stream.timepoint, !stream.resource<constant>)
  ^bb2(%3: !stream.timepoint, %4: !stream.resource<constant>):  // 2 preds: ^bb0, ^bb1
    util.global.store %4, @_params.weight : !stream.resource<constant>
    util.global.store %3, @_params.weight__timepoint : !stream.timepoint
    util.initializer.return
  }
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_1x3x4_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}) {
        %c0 = arith.constant 0 : index
        %c64 = arith.constant 64 : index
        %cst = arith.constant 0.000000e+00 : f32
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
        %2 = stream.binding.subspan %arg1[%c64] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
        %3 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        %4 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
        %5 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
        %6 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
        %7 = tensor.empty() : tensor<1x3xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%7 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %9 = linalg.matmul ins(%4, %5 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%8 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %10 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%9, %6 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%7 : tensor<1x3xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %11 = arith.addf %in, %in_0 : f32
          linalg.yield %11 : f32
        } -> tensor<1x3xf32>
        flow.dispatch.tensor.store %10, %3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %c12 = arith.constant 12 : index
    %c16 = arith.constant 16 : index
    %c128 = arith.constant 128 : index
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !stream.timepoint
    %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
    %result, %result_timepoint = stream.resource.alloca uninitialized await(%_params.weight__timepoint) => !stream.resource<external>{%c12} => !stream.timepoint
    %1 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c16}, %_params.weight as %arg2: !stream.resource<constant>{%c128}, %result as %arg3: !stream.resource<external>{%c12}) {
      stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32 {
        ro %arg1[%c0 for %c16] : !stream.resource<external>{%c16},
        ro %arg2[%c0 for %c128] : !stream.resource<constant>{%c128},
        wo %arg3[%c0 for %c12] : !stream.resource<external>{%c12}
      }
    } => !stream.timepoint
    %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c12}
    %3 = stream.tensor.export %2 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
    return %3 : !hal.buffer_view
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private mutable @_params.weight__timepoint = #stream.timepoint<immediate> : !stream.timepoint
  util.global private @_params.weight : !stream.resource<constant>
  util.initializer {
    %0 = stream.timepoint.immediate => !stream.timepoint
    %c0_i64 = arith.constant 0 : i64
    %c128 = arith.constant 128 : index
    %c0 = arith.constant 0 : index
    %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #composite_of_128b
    %did_map, %result = stream.resource.try_map %buffer_cst[%c0] : !util.buffer -> i1, !stream.resource<constant>{%c128}
    cf.cond_br %did_map, ^bb2(%0, %result : !stream.timepoint, !stream.resource<constant>), ^bb1
  ^bb1:  // pred: ^bb0
    %1 = stream.resource.alloc uninitialized : !stream.resource<constant>{%c128}
    %file = stream.file.constant %buffer_cst[%c0 for %c128] : !util.buffer{%c128} -> !stream.file
    %2 = stream.file.read await(%0) => %file[%c0_i64], %1[%c0], %c128 : !stream.file -> !stream.resource<constant>{%c128} => !stream.timepoint
    cf.br ^bb2(%2, %1 : !stream.timepoint, !stream.resource<constant>)
  ^bb2(%3: !stream.timepoint, %4: !stream.resource<constant>):  // 2 preds: ^bb0, ^bb1
    util.global.store %4, @_params.weight : !stream.resource<constant>
    util.global.store %3, @_params.weight__timepoint : !stream.timepoint
    util.initializer.return
  }
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_1x3x4_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}) {
        %c0 = arith.constant 0 : index
        %c64 = arith.constant 64 : index
        %cst = arith.constant 0.000000e+00 : f32
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
        %2 = stream.binding.subspan %arg1[%c64] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
        %3 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        %4 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
        %5 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
        %6 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
        %7 = tensor.empty() : tensor<1x3xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%7 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %9 = linalg.matmul ins(%4, %5 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%8 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %10 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%9, %6 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%7 : tensor<1x3xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %11 = arith.addf %in, %in_0 : f32
          linalg.yield %11 : f32
        } -> tensor<1x3xf32>
        flow.dispatch.tensor.store %10, %3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %c12 = arith.constant 12 : index
    %c16 = arith.constant 16 : index
    %c128 = arith.constant 128 : index
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !stream.timepoint
    %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
    %result, %result_timepoint = stream.resource.alloca uninitialized await(%_params.weight__timepoint) => !stream.resource<external>{%c12} => !stream.timepoint
    %1 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c16}, %_params.weight as %arg2: !stream.resource<constant>{%c128}, %result as %arg3: !stream.resource<external>{%c12}) {
      stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32 {
        ro %arg1[%c0 for %c16] : !stream.resource<external>{%c16},
        ro %arg2[%c0 for %c128] : !stream.resource<constant>{%c128},
        wo %arg3[%c0 for %c12] : !stream.resource<external>{%c12}
      }
    } => !stream.timepoint
    %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c12}
    %3 = stream.tensor.export %2 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
    return %3 : !hal.buffer_view
  }
}


// -----// IR Dump After SymbolDCE (symbol-dce) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private mutable @_params.weight__timepoint = #stream.timepoint<immediate> : !stream.timepoint
  util.global private @_params.weight : !stream.resource<constant>
  util.initializer {
    %0 = stream.timepoint.immediate => !stream.timepoint
    %c0_i64 = arith.constant 0 : i64
    %c128 = arith.constant 128 : index
    %c0 = arith.constant 0 : index
    %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #composite_of_128b
    %did_map, %result = stream.resource.try_map %buffer_cst[%c0] : !util.buffer -> i1, !stream.resource<constant>{%c128}
    cf.cond_br %did_map, ^bb2(%0, %result : !stream.timepoint, !stream.resource<constant>), ^bb1
  ^bb1:  // pred: ^bb0
    %1 = stream.resource.alloc uninitialized : !stream.resource<constant>{%c128}
    %file = stream.file.constant %buffer_cst[%c0 for %c128] : !util.buffer{%c128} -> !stream.file
    %2 = stream.file.read await(%0) => %file[%c0_i64], %1[%c0], %c128 : !stream.file -> !stream.resource<constant>{%c128} => !stream.timepoint
    cf.br ^bb2(%2, %1 : !stream.timepoint, !stream.resource<constant>)
  ^bb2(%3: !stream.timepoint, %4: !stream.resource<constant>):  // 2 preds: ^bb0, ^bb1
    util.global.store %4, @_params.weight : !stream.resource<constant>
    util.global.store %3, @_params.weight__timepoint : !stream.timepoint
    util.initializer.return
  }
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_1x3x4_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}) {
        %c0 = arith.constant 0 : index
        %c64 = arith.constant 64 : index
        %cst = arith.constant 0.000000e+00 : f32
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
        %2 = stream.binding.subspan %arg1[%c64] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
        %3 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        %4 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
        %5 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
        %6 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
        %7 = tensor.empty() : tensor<1x3xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%7 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %9 = linalg.matmul ins(%4, %5 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%8 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %10 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%9, %6 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%7 : tensor<1x3xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %11 = arith.addf %in, %in_0 : f32
          linalg.yield %11 : f32
        } -> tensor<1x3xf32>
        flow.dispatch.tensor.store %10, %3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %c12 = arith.constant 12 : index
    %c16 = arith.constant 16 : index
    %c128 = arith.constant 128 : index
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !stream.timepoint
    %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
    %result, %result_timepoint = stream.resource.alloca uninitialized await(%_params.weight__timepoint) => !stream.resource<external>{%c12} => !stream.timepoint
    %1 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c16}, %_params.weight as %arg2: !stream.resource<constant>{%c128}, %result as %arg3: !stream.resource<external>{%c12}) {
      stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32 {
        ro %arg1[%c0 for %c16] : !stream.resource<external>{%c16},
        ro %arg2[%c0 for %c128] : !stream.resource<constant>{%c128},
        wo %arg3[%c0 for %c12] : !stream.resource<external>{%c12}
      }
    } => !stream.timepoint
    %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c12}
    %3 = stream.tensor.export %2 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
    return %3 : !hal.buffer_view
  }
}


// -----// IR Dump After CSE (cse) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private mutable @_params.weight__timepoint = #stream.timepoint<immediate> : !stream.timepoint
  util.global private @_params.weight : !stream.resource<constant>
  util.initializer {
    %0 = stream.timepoint.immediate => !stream.timepoint
    %c0_i64 = arith.constant 0 : i64
    %c128 = arith.constant 128 : index
    %c0 = arith.constant 0 : index
    %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #composite_of_128b
    %did_map, %result = stream.resource.try_map %buffer_cst[%c0] : !util.buffer -> i1, !stream.resource<constant>{%c128}
    cf.cond_br %did_map, ^bb2(%0, %result : !stream.timepoint, !stream.resource<constant>), ^bb1
  ^bb1:  // pred: ^bb0
    %1 = stream.resource.alloc uninitialized : !stream.resource<constant>{%c128}
    %file = stream.file.constant %buffer_cst[%c0 for %c128] : !util.buffer{%c128} -> !stream.file
    %2 = stream.file.read await(%0) => %file[%c0_i64], %1[%c0], %c128 : !stream.file -> !stream.resource<constant>{%c128} => !stream.timepoint
    cf.br ^bb2(%2, %1 : !stream.timepoint, !stream.resource<constant>)
  ^bb2(%3: !stream.timepoint, %4: !stream.resource<constant>):  // 2 preds: ^bb0, ^bb1
    util.global.store %4, @_params.weight : !stream.resource<constant>
    util.global.store %3, @_params.weight__timepoint : !stream.timepoint
    util.initializer.return
  }
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_1x3x4_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}) {
        %c0 = arith.constant 0 : index
        %c64 = arith.constant 64 : index
        %cst = arith.constant 0.000000e+00 : f32
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
        %2 = stream.binding.subspan %arg1[%c64] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
        %3 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        %4 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
        %5 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
        %6 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
        %7 = tensor.empty() : tensor<1x3xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%7 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %9 = linalg.matmul ins(%4, %5 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%8 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %10 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%9, %6 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%7 : tensor<1x3xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %11 = arith.addf %in, %in_0 : f32
          linalg.yield %11 : f32
        } -> tensor<1x3xf32>
        flow.dispatch.tensor.store %10, %3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %c12 = arith.constant 12 : index
    %c16 = arith.constant 16 : index
    %c128 = arith.constant 128 : index
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !stream.timepoint
    %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
    %result, %result_timepoint = stream.resource.alloca uninitialized await(%_params.weight__timepoint) => !stream.resource<external>{%c12} => !stream.timepoint
    %1 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c16}, %_params.weight as %arg2: !stream.resource<constant>{%c128}, %result as %arg3: !stream.resource<external>{%c12}) {
      stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32 {
        ro %arg1[%c0 for %c16] : !stream.resource<external>{%c16},
        ro %arg2[%c0 for %c128] : !stream.resource<constant>{%c128},
        wo %arg3[%c0 for %c12] : !stream.resource<external>{%c12}
      }
    } => !stream.timepoint
    %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c12}
    %3 = stream.tensor.export %2 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
    return %3 : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private mutable @_params.weight__timepoint = #stream.timepoint<immediate> : !stream.timepoint
  util.global private @_params.weight : !stream.resource<constant>
  util.initializer {
    %0 = stream.timepoint.immediate => !stream.timepoint
    %c0_i64 = arith.constant 0 : i64
    %c128 = arith.constant 128 : index
    %c0 = arith.constant 0 : index
    %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #composite_of_128b
    %did_map, %result = stream.resource.try_map %buffer_cst[%c0] : !util.buffer -> i1, !stream.resource<constant>{%c128}
    cf.cond_br %did_map, ^bb2(%0, %result : !stream.timepoint, !stream.resource<constant>), ^bb1
  ^bb1:  // pred: ^bb0
    %1 = stream.resource.alloc uninitialized : !stream.resource<constant>{%c128}
    %file = stream.file.constant %buffer_cst[%c0 for %c128] : !util.buffer{%c128} -> !stream.file
    %2 = stream.file.read await(%0) => %file[%c0_i64], %1[%c0], %c128 : !stream.file -> !stream.resource<constant>{%c128} => !stream.timepoint
    cf.br ^bb2(%2, %1 : !stream.timepoint, !stream.resource<constant>)
  ^bb2(%3: !stream.timepoint, %4: !stream.resource<constant>):  // 2 preds: ^bb0, ^bb1
    util.global.store %4, @_params.weight : !stream.resource<constant>
    util.global.store %3, @_params.weight__timepoint : !stream.timepoint
    util.initializer.return
  }
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_1x3x4_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}) {
        %c0 = arith.constant 0 : index
        %c64 = arith.constant 64 : index
        %cst = arith.constant 0.000000e+00 : f32
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
        %2 = stream.binding.subspan %arg1[%c64] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
        %3 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        %4 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
        %5 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
        %6 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
        %7 = tensor.empty() : tensor<1x3xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%7 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %9 = linalg.matmul ins(%4, %5 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%8 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %10 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%9, %6 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%7 : tensor<1x3xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %11 = arith.addf %in, %in_0 : f32
          linalg.yield %11 : f32
        } -> tensor<1x3xf32>
        flow.dispatch.tensor.store %10, %3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %c12 = arith.constant 12 : index
    %c16 = arith.constant 16 : index
    %c128 = arith.constant 128 : index
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !stream.timepoint
    %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
    %result, %result_timepoint = stream.resource.alloca uninitialized await(%_params.weight__timepoint) => !stream.resource<external>{%c12} => !stream.timepoint
    %1 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c16}, %_params.weight as %arg2: !stream.resource<constant>{%c128}, %result as %arg3: !stream.resource<external>{%c12}) {
      stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32 {
        ro %arg1[%c0 for %c16] : !stream.resource<external>{%c16},
        ro %arg2[%c0 for %c128] : !stream.resource<constant>{%c128},
        wo %arg3[%c0 for %c12] : !stream.resource<external>{%c12}
      }
    } => !stream.timepoint
    %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c12}
    %3 = stream.tensor.export %2 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
    return %3 : !hal.buffer_view
  }
}


// -----// IR Dump After CSE (cse) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private mutable @_params.weight__timepoint = #stream.timepoint<immediate> : !stream.timepoint
  util.global private @_params.weight : !stream.resource<constant>
  util.initializer {
    %0 = stream.timepoint.immediate => !stream.timepoint
    %c0_i64 = arith.constant 0 : i64
    %c128 = arith.constant 128 : index
    %c0 = arith.constant 0 : index
    %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #composite_of_128b
    %did_map, %result = stream.resource.try_map %buffer_cst[%c0] : !util.buffer -> i1, !stream.resource<constant>{%c128}
    cf.cond_br %did_map, ^bb2(%0, %result : !stream.timepoint, !stream.resource<constant>), ^bb1
  ^bb1:  // pred: ^bb0
    %1 = stream.resource.alloc uninitialized : !stream.resource<constant>{%c128}
    %file = stream.file.constant %buffer_cst[%c0 for %c128] : !util.buffer{%c128} -> !stream.file
    %2 = stream.file.read await(%0) => %file[%c0_i64], %1[%c0], %c128 : !stream.file -> !stream.resource<constant>{%c128} => !stream.timepoint
    cf.br ^bb2(%2, %1 : !stream.timepoint, !stream.resource<constant>)
  ^bb2(%3: !stream.timepoint, %4: !stream.resource<constant>):  // 2 preds: ^bb0, ^bb1
    util.global.store %4, @_params.weight : !stream.resource<constant>
    util.global.store %3, @_params.weight__timepoint : !stream.timepoint
    util.initializer.return
  }
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_1x3x4_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}) {
        %c0 = arith.constant 0 : index
        %c64 = arith.constant 64 : index
        %cst = arith.constant 0.000000e+00 : f32
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
        %2 = stream.binding.subspan %arg1[%c64] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
        %3 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        %4 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
        %5 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
        %6 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
        %7 = tensor.empty() : tensor<1x3xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%7 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %9 = linalg.matmul ins(%4, %5 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%8 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %10 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%9, %6 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%7 : tensor<1x3xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %11 = arith.addf %in, %in_0 : f32
          linalg.yield %11 : f32
        } -> tensor<1x3xf32>
        flow.dispatch.tensor.store %10, %3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %c12 = arith.constant 12 : index
    %c16 = arith.constant 16 : index
    %c128 = arith.constant 128 : index
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !stream.timepoint
    %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
    %result, %result_timepoint = stream.resource.alloca uninitialized await(%_params.weight__timepoint) => !stream.resource<external>{%c12} => !stream.timepoint
    %1 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c16}, %_params.weight as %arg2: !stream.resource<constant>{%c128}, %result as %arg3: !stream.resource<external>{%c12}) {
      stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32 {
        ro %arg1[%c0 for %c16] : !stream.resource<external>{%c16},
        ro %arg2[%c0 for %c128] : !stream.resource<constant>{%c128},
        wo %arg3[%c0 for %c12] : !stream.resource<external>{%c12}
      }
    } => !stream.timepoint
    %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c12}
    %3 = stream.tensor.export %2 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
    return %3 : !hal.buffer_view
  }
}


// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.initializer {
  %0 = stream.timepoint.immediate => !stream.timepoint
  %c0_i64 = arith.constant 0 : i64
  %c128 = arith.constant 128 : index
  %c0 = arith.constant 0 : index
  %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
  %did_map, %result = stream.resource.try_map %buffer_cst[%c0] : !util.buffer -> i1, !stream.resource<constant>{%c128}
  cf.cond_br %did_map, ^bb2(%0, %result : !stream.timepoint, !stream.resource<constant>), ^bb1
^bb1:  // pred: ^bb0
  %1 = stream.resource.alloc uninitialized : !stream.resource<constant>{%c128}
  %file = stream.file.constant %buffer_cst[%c0 for %c128] : !util.buffer{%c128} -> !stream.file
  %2 = stream.file.read await(%0) => %file[%c0_i64], %1[%c0], %c128 : !stream.file -> !stream.resource<constant>{%c128} => !stream.timepoint
  cf.br ^bb2(%2, %1 : !stream.timepoint, !stream.resource<constant>)
^bb2(%3: !stream.timepoint, %4: !stream.resource<constant>):  // 2 preds: ^bb0, ^bb1
  util.global.store %4, @_params.weight : !stream.resource<constant>
  util.global.store %3, @_params.weight__timepoint : !stream.timepoint
  util.initializer.return
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !stream.timepoint
  %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
  %c0 = arith.constant 0 : index
  %c4 = arith.constant 4 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %c12 = arith.constant 12 : index
  %c16 = arith.constant 16 : index
  %c128 = arith.constant 128 : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
  %result, %result_timepoint = stream.resource.alloca uninitialized await(%_params.weight__timepoint) => !stream.resource<external>{%c12} => !stream.timepoint
  %1 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c16}, %_params.weight as %arg2: !stream.resource<constant>{%c128}, %result as %arg3: !stream.resource<external>{%c12}) {
    stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32 {
      ro %arg1[%c0 for %c16] : !stream.resource<external>{%c16},
      ro %arg2[%c0 for %c128] : !stream.resource<constant>{%c128},
      wo %arg3[%c0 for %c12] : !stream.resource<external>{%c12}
    }
  } => !stream.timepoint
  %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c12}
  %3 = stream.tensor.export %2 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
  return %3 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private mutable @_params.weight__timepoint = #stream.timepoint<immediate> : !stream.timepoint
  util.global private @_params.weight : !stream.resource<constant>
  util.initializer {
    %0 = stream.timepoint.immediate => !stream.timepoint
    %c0_i64 = arith.constant 0 : i64
    %c128 = arith.constant 128 : index
    %c0 = arith.constant 0 : index
    %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #composite_of_128b
    %did_map, %result = stream.resource.try_map %buffer_cst[%c0] : !util.buffer -> i1, !stream.resource<constant>{%c128}
    cf.cond_br %did_map, ^bb2(%0, %result : !stream.timepoint, !stream.resource<constant>), ^bb1
  ^bb1:  // pred: ^bb0
    %1 = stream.resource.alloc uninitialized : !stream.resource<constant>{%c128}
    %file = stream.file.constant %buffer_cst[%c0 for %c128] : !util.buffer{%c128} -> !stream.file
    %2 = stream.file.read await(%0) => %file[%c0_i64], %1[%c0], %c128 : !stream.file -> !stream.resource<constant>{%c128} => !stream.timepoint
    cf.br ^bb2(%2, %1 : !stream.timepoint, !stream.resource<constant>)
  ^bb2(%3: !stream.timepoint, %4: !stream.resource<constant>):  // 2 preds: ^bb0, ^bb1
    util.global.store %4, @_params.weight : !stream.resource<constant>
    util.global.store %3, @_params.weight__timepoint : !stream.timepoint
    util.initializer.return
  }
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_1x3x4_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}) {
        %c0 = arith.constant 0 : index
        %c64 = arith.constant 64 : index
        %cst = arith.constant 0.000000e+00 : f32
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
        %2 = stream.binding.subspan %arg1[%c64] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
        %3 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        %4 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
        %5 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
        %6 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
        %7 = tensor.empty() : tensor<1x3xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%7 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %9 = linalg.matmul ins(%4, %5 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%8 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %10 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%9, %6 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%7 : tensor<1x3xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %11 = arith.addf %in, %in_0 : f32
          linalg.yield %11 : f32
        } -> tensor<1x3xf32>
        flow.dispatch.tensor.store %10, %3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c128 = arith.constant 128 : index
    %c16 = arith.constant 16 : index
    %c12 = arith.constant 12 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !stream.timepoint
    %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
    %result, %result_timepoint = stream.resource.alloca uninitialized await(%_params.weight__timepoint) => !stream.resource<external>{%c12} => !stream.timepoint
    %1 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c16}, %_params.weight as %arg2: !stream.resource<constant>{%c128}, %result as %arg3: !stream.resource<external>{%c12}) {
      stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32 {
        ro %arg1[%c0 for %c16] : !stream.resource<external>{%c16},
        ro %arg2[%c0 for %c128] : !stream.resource<constant>{%c128},
        wo %arg3[%c0 for %c12] : !stream.resource<external>{%c12}
      }
    } => !stream.timepoint
    %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c12}
    %3 = stream.tensor.export %2 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
    return %3 : !hal.buffer_view
  }
}


// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private mutable @_params.weight__timepoint = #stream.timepoint<immediate> : !stream.timepoint
  util.global private @_params.weight : !stream.resource<constant>
  util.initializer {
    %0 = stream.timepoint.immediate => !stream.timepoint
    %c0_i64 = arith.constant 0 : i64
    %c128 = arith.constant 128 : index
    %c0 = arith.constant 0 : index
    %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #composite_of_128b
    %did_map, %result = stream.resource.try_map %buffer_cst[%c0] : !util.buffer -> i1, !stream.resource<constant>{%c128}
    cf.cond_br %did_map, ^bb2(%0, %result : !stream.timepoint, !stream.resource<constant>), ^bb1
  ^bb1:  // pred: ^bb0
    %1 = stream.resource.alloc uninitialized : !stream.resource<constant>{%c128}
    %file = stream.file.constant %buffer_cst[%c0 for %c128] : !util.buffer{%c128} -> !stream.file
    %2 = stream.file.read await(%0) => %file[%c0_i64], %1[%c0], %c128 : !stream.file -> !stream.resource<constant>{%c128} => !stream.timepoint
    cf.br ^bb2(%2, %1 : !stream.timepoint, !stream.resource<constant>)
  ^bb2(%3: !stream.timepoint, %4: !stream.resource<constant>):  // 2 preds: ^bb0, ^bb1
    util.global.store %4, @_params.weight : !stream.resource<constant>
    util.global.store %3, @_params.weight__timepoint : !stream.timepoint
    util.initializer.return
  }
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_1x3x4_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}) {
        %c0 = arith.constant 0 : index
        %c64 = arith.constant 64 : index
        %cst = arith.constant 0.000000e+00 : f32
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
        %2 = stream.binding.subspan %arg1[%c64] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
        %3 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        %4 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
        %5 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
        %6 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
        %7 = tensor.empty() : tensor<1x3xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%7 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %9 = linalg.matmul ins(%4, %5 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%8 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %10 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%9, %6 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%7 : tensor<1x3xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %11 = arith.addf %in, %in_0 : f32
          linalg.yield %11 : f32
        } -> tensor<1x3xf32>
        flow.dispatch.tensor.store %10, %3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c128 = arith.constant 128 : index
    %c16 = arith.constant 16 : index
    %c12 = arith.constant 12 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !stream.timepoint
    %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
    %result, %result_timepoint = stream.resource.alloca uninitialized await(%_params.weight__timepoint) => !stream.resource<external>{%c12} => !stream.timepoint
    %1 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c16}, %_params.weight as %arg2: !stream.resource<constant>{%c128}, %result as %arg3: !stream.resource<external>{%c12}) {
      stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32 {
        ro %arg1[%c0 for %c16] : !stream.resource<external>{%c16},
        ro %arg2[%c0 for %c128] : !stream.resource<constant>{%c128},
        wo %arg3[%c0 for %c12] : !stream.resource<external>{%c12}
      }
    } => !stream.timepoint
    %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c12}
    %3 = stream.tensor.export %2 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
    return %3 : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private mutable @_params.weight__timepoint = #stream.timepoint<immediate> : !stream.timepoint
  util.global private @_params.weight : !stream.resource<constant>
  util.initializer {
    %0 = stream.timepoint.immediate => !stream.timepoint
    %c0_i64 = arith.constant 0 : i64
    %c128 = arith.constant 128 : index
    %c0 = arith.constant 0 : index
    %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #composite_of_128b
    %did_map, %result = stream.resource.try_map %buffer_cst[%c0] : !util.buffer -> i1, !stream.resource<constant>{%c128}
    cf.cond_br %did_map, ^bb2(%0, %result : !stream.timepoint, !stream.resource<constant>), ^bb1
  ^bb1:  // pred: ^bb0
    %1 = stream.resource.alloc uninitialized : !stream.resource<constant>{%c128}
    %file = stream.file.constant %buffer_cst[%c0 for %c128] : !util.buffer{%c128} -> !stream.file
    %2 = stream.file.read await(%0) => %file[%c0_i64], %1[%c0], %c128 : !stream.file -> !stream.resource<constant>{%c128} => !stream.timepoint
    cf.br ^bb2(%2, %1 : !stream.timepoint, !stream.resource<constant>)
  ^bb2(%3: !stream.timepoint, %4: !stream.resource<constant>):  // 2 preds: ^bb0, ^bb1
    util.global.store %4, @_params.weight : !stream.resource<constant>
    util.global.store %3, @_params.weight__timepoint : !stream.timepoint
    util.initializer.return
  }
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_1x3x4_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}) {
        %c0 = arith.constant 0 : index
        %c64 = arith.constant 64 : index
        %cst = arith.constant 0.000000e+00 : f32
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
        %2 = stream.binding.subspan %arg1[%c64] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
        %3 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        %4 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
        %5 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
        %6 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
        %7 = tensor.empty() : tensor<1x3xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%7 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %9 = linalg.matmul ins(%4, %5 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%8 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %10 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%9, %6 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%7 : tensor<1x3xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %11 = arith.addf %in, %in_0 : f32
          linalg.yield %11 : f32
        } -> tensor<1x3xf32>
        flow.dispatch.tensor.store %10, %3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c128 = arith.constant 128 : index
    %c16 = arith.constant 16 : index
    %c12 = arith.constant 12 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !stream.timepoint
    %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
    %result, %result_timepoint = stream.resource.alloca uninitialized await(%_params.weight__timepoint) => !stream.resource<external>{%c12} => !stream.timepoint
    %1 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c16}, %_params.weight as %arg2: !stream.resource<constant>{%c128}, %result as %arg3: !stream.resource<external>{%c12}) {
      stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32 {
        ro %arg1[%c0 for %c16] : !stream.resource<external>{%c16},
        ro %arg2[%c0 for %c128] : !stream.resource<constant>{%c128},
        wo %arg3[%c0 for %c12] : !stream.resource<external>{%c12}
      }
    } => !stream.timepoint
    %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c12}
    %3 = stream.tensor.export %2 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
    return %3 : !hal.buffer_view
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::HAL::AssignTargetDevicesPass (iree-hal-assign-target-devices) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private mutable @_params.weight__timepoint = #stream.timepoint<immediate> : !stream.timepoint
  util.global private @_params.weight : !stream.resource<constant>
  util.initializer {
    %0 = stream.timepoint.immediate => !stream.timepoint
    %c0_i64 = arith.constant 0 : i64
    %c128 = arith.constant 128 : index
    %c0 = arith.constant 0 : index
    %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #composite_of_128b
    %did_map, %result = stream.resource.try_map %buffer_cst[%c0] : !util.buffer -> i1, !stream.resource<constant>{%c128}
    cf.cond_br %did_map, ^bb2(%0, %result : !stream.timepoint, !stream.resource<constant>), ^bb1
  ^bb1:  // pred: ^bb0
    %1 = stream.resource.alloc uninitialized : !stream.resource<constant>{%c128}
    %file = stream.file.constant %buffer_cst[%c0 for %c128] : !util.buffer{%c128} -> !stream.file
    %2 = stream.file.read await(%0) => %file[%c0_i64], %1[%c0], %c128 : !stream.file -> !stream.resource<constant>{%c128} => !stream.timepoint
    cf.br ^bb2(%2, %1 : !stream.timepoint, !stream.resource<constant>)
  ^bb2(%3: !stream.timepoint, %4: !stream.resource<constant>):  // 2 preds: ^bb0, ^bb1
    util.global.store %4, @_params.weight : !stream.resource<constant>
    util.global.store %3, @_params.weight__timepoint : !stream.timepoint
    util.initializer.return
  }
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_1x3x4_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}) {
        %c0 = arith.constant 0 : index
        %c64 = arith.constant 64 : index
        %cst = arith.constant 0.000000e+00 : f32
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
        %2 = stream.binding.subspan %arg1[%c64] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
        %3 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        %4 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
        %5 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
        %6 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
        %7 = tensor.empty() : tensor<1x3xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%7 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %9 = linalg.matmul ins(%4, %5 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%8 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %10 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%9, %6 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%7 : tensor<1x3xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %11 = arith.addf %in, %in_0 : f32
          linalg.yield %11 : f32
        } -> tensor<1x3xf32>
        flow.dispatch.tensor.store %10, %3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c128 = arith.constant 128 : index
    %c16 = arith.constant 16 : index
    %c12 = arith.constant 12 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !stream.timepoint
    %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
    %result, %result_timepoint = stream.resource.alloca uninitialized await(%_params.weight__timepoint) => !stream.resource<external>{%c12} => !stream.timepoint
    %1 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c16}, %_params.weight as %arg2: !stream.resource<constant>{%c128}, %result as %arg3: !stream.resource<external>{%c12}) {
      stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32 {
        ro %arg1[%c0 for %c16] : !stream.resource<external>{%c16},
        ro %arg2[%c0 for %c128] : !stream.resource<constant>{%c128},
        wo %arg3[%c0 for %c12] : !stream.resource<external>{%c12}
      }
    } => !stream.timepoint
    %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c12}
    %3 = stream.tensor.export %2 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
    return %3 : !hal.buffer_view
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::HAL::VerifyTargetEnvironmentPass (iree-hal-verify-target-environment) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private mutable @_params.weight__timepoint = #stream.timepoint<immediate> : !stream.timepoint
  util.global private @_params.weight : !stream.resource<constant>
  util.initializer {
    %0 = stream.timepoint.immediate => !stream.timepoint
    %c0_i64 = arith.constant 0 : i64
    %c128 = arith.constant 128 : index
    %c0 = arith.constant 0 : index
    %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #composite_of_128b
    %did_map, %result = stream.resource.try_map %buffer_cst[%c0] : !util.buffer -> i1, !stream.resource<constant>{%c128}
    cf.cond_br %did_map, ^bb2(%0, %result : !stream.timepoint, !stream.resource<constant>), ^bb1
  ^bb1:  // pred: ^bb0
    %1 = stream.resource.alloc uninitialized : !stream.resource<constant>{%c128}
    %file = stream.file.constant %buffer_cst[%c0 for %c128] : !util.buffer{%c128} -> !stream.file
    %2 = stream.file.read await(%0) => %file[%c0_i64], %1[%c0], %c128 : !stream.file -> !stream.resource<constant>{%c128} => !stream.timepoint
    cf.br ^bb2(%2, %1 : !stream.timepoint, !stream.resource<constant>)
  ^bb2(%3: !stream.timepoint, %4: !stream.resource<constant>):  // 2 preds: ^bb0, ^bb1
    util.global.store %4, @_params.weight : !stream.resource<constant>
    util.global.store %3, @_params.weight__timepoint : !stream.timepoint
    util.initializer.return
  }
  stream.executable private @main_dispatch_0 {
    stream.executable.export public @main_dispatch_0_matmul_1x3x4_f32 workgroups() -> (index, index, index) {
      %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}) {
        %c0 = arith.constant 0 : index
        %c64 = arith.constant 64 : index
        %cst = arith.constant 0.000000e+00 : f32
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
        %2 = stream.binding.subspan %arg1[%c64] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
        %3 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        %4 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
        %5 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
        %6 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
        %7 = tensor.empty() : tensor<1x3xf32>
        %8 = linalg.fill ins(%cst : f32) outs(%7 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %9 = linalg.matmul ins(%4, %5 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%8 : tensor<1x3xf32>) -> tensor<1x3xf32>
        %10 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%9, %6 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%7 : tensor<1x3xf32>) {
        ^bb0(%in: f32, %in_0: f32, %out: f32):
          %11 = arith.addf %in, %in_0 : f32
          linalg.yield %11 : f32
        } -> tensor<1x3xf32>
        flow.dispatch.tensor.store %10, %3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
        return
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c128 = arith.constant 128 : index
    %c16 = arith.constant 16 : index
    %c12 = arith.constant 12 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !stream.timepoint
    %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
    %result, %result_timepoint = stream.resource.alloca uninitialized await(%_params.weight__timepoint) => !stream.resource<external>{%c12} => !stream.timepoint
    %1 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c16}, %_params.weight as %arg2: !stream.resource<constant>{%c128}, %result as %arg3: !stream.resource<external>{%c12}) {
      stream.cmd.dispatch @main_dispatch_0::@main_dispatch_0_matmul_1x3x4_f32 {
        ro %arg1[%c0 for %c16] : !stream.resource<external>{%c16},
        ro %arg2[%c0 for %c128] : !stream.resource<constant>{%c128},
        wo %arg3[%c0 for %c12] : !stream.resource<external>{%c12}
      }
    } => !stream.timepoint
    %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c12}
    %3 = stream.tensor.export %2 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
    return %3 : !hal.buffer_view
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::HAL::(anonymous namespace)::MaterializeInterfacesPass (iree-hal-materialize-interfaces) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#map = affine_map<(d0, d1) -> (d0, d1)>
#pipeline_layout = #hal.pipeline.layout<push_constants = 0, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private mutable @_params.weight__timepoint = #stream.timepoint<immediate> : !stream.timepoint
  util.global private @_params.weight : !stream.resource<constant>
  util.initializer {
    %0 = stream.timepoint.immediate => !stream.timepoint
    %c0_i64 = arith.constant 0 : i64
    %c128 = arith.constant 128 : index
    %c0 = arith.constant 0 : index
    %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #composite_of_128b
    %did_map, %result = stream.resource.try_map %buffer_cst[%c0] : !util.buffer -> i1, !stream.resource<constant>{%c128}
    cf.cond_br %did_map, ^bb2(%0, %result : !stream.timepoint, !stream.resource<constant>), ^bb1
  ^bb1:  // pred: ^bb0
    %1 = stream.resource.alloc uninitialized : !stream.resource<constant>{%c128}
    %file = stream.file.constant %buffer_cst[%c0 for %c128] : !util.buffer{%c128} -> !stream.file
    %2 = stream.file.read await(%0) => %file[%c0_i64], %1[%c0], %c128 : !stream.file -> !stream.resource<constant>{%c128} => !stream.timepoint
    cf.br ^bb2(%2, %1 : !stream.timepoint, !stream.resource<constant>)
  ^bb2(%3: !stream.timepoint, %4: !stream.resource<constant>):  // 2 preds: ^bb0, ^bb1
    util.global.store %4, @_params.weight : !stream.resource<constant>
    util.global.store %3, @_params.weight__timepoint : !stream.timepoint
    util.initializer.return
  }
  hal.executable private @main_dispatch_0 {
    hal.executable.variant public @cuda_nvptx_fb target(#executable_target_cuda_nvptx_fb) {
      hal.executable.export public @main_dispatch_0_matmul_1x3x4_f32 ordinal(0) layout(#pipeline_layout) {
      ^bb0(%arg0: !hal.device):
        %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
        hal.return %x, %y, %z : index, index, index
      }
      builtin.module {
        func.func @main_dispatch_0_matmul_1x3x4_f32() {
          %c0 = arith.constant 0 : index
          %c64 = arith.constant 64 : index
          %cst = arith.constant 0.000000e+00 : f32
          %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
          %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
          %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
          %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
          %4 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
          %5 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
          %6 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
          %7 = tensor.empty() : tensor<1x3xf32>
          %8 = linalg.fill ins(%cst : f32) outs(%7 : tensor<1x3xf32>) -> tensor<1x3xf32>
          %9 = linalg.matmul ins(%4, %5 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%8 : tensor<1x3xf32>) -> tensor<1x3xf32>
          %10 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = ["parallel", "parallel"]} ins(%9, %6 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%7 : tensor<1x3xf32>) {
          ^bb0(%in: f32, %in_0: f32, %out: f32):
            %11 = arith.addf %in, %in_0 : f32
            linalg.yield %11 : f32
          } -> tensor<1x3xf32>
          flow.dispatch.tensor.store %10, %3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
          return
        }
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c128 = arith.constant 128 : index
    %c16 = arith.constant 16 : index
    %c12 = arith.constant 12 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !stream.timepoint
    %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
    %result, %result_timepoint = stream.resource.alloca uninitialized await(%_params.weight__timepoint) => !stream.resource<external>{%c12} => !stream.timepoint
    %1 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c16}, %_params.weight as %arg2: !stream.resource<constant>{%c128}, %result as %arg3: !stream.resource<external>{%c12}) {
      stream.cmd.dispatch @main_dispatch_0::@cuda_nvptx_fb::@main_dispatch_0_matmul_1x3x4_f32 {
        ro %arg1[%c0 for %c16] : !stream.resource<external>{%c16},
        ro %arg2[%c0 for %c128] : !stream.resource<constant>{%c128},
        wo %arg3[%c0 for %c12] : !stream.resource<external>{%c12}
      } attributes {hal.interface.bindings = [#hal.interface.binding<0, 0>, #hal.interface.binding<0, 1>, #hal.interface.binding<0, 2>]}
    } => !stream.timepoint
    %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c12}
    %3 = stream.tensor.export %2 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
    return %3 : !hal.buffer_view
  }
}


// -----// IR Dump After CPUMaterializeUpperBoundTileSize (iree-codegen-cpu-materialize-upper-bound-tile-size) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c128 = arith.constant 128 : index
  %c16 = arith.constant 16 : index
  %c12 = arith.constant 12 : index
  %c553648160_i32 = arith.constant 553648160 : i32
  %c1_i32 = arith.constant 1 : i32
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !stream.timepoint
  %_params.weight = util.global.load @_params.weight : !stream.resource<constant>
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
  %0 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<4xf32> in !stream.resource<external>{%c16}
  %result, %result_timepoint = stream.resource.alloca uninitialized await(%_params.weight__timepoint) => !stream.resource<external>{%c12} => !stream.timepoint
  %1 = stream.cmd.execute await(%result_timepoint) => with(%0 as %arg1: !stream.resource<external>{%c16}, %_params.weight as %arg2: !stream.resource<constant>{%c128}, %result as %arg3: !stream.resource<external>{%c12}) {
    stream.cmd.dispatch @main_dispatch_0::@cuda_nvptx_fb::@main_dispatch_0_matmul_1x3x4_f32 {
      ro %arg1[%c0 for %c16] : !stream.resource<external>{%c16},
      ro %arg2[%c0 for %c128] : !stream.resource<constant>{%c128},
      wo %arg3[%c0 for %c12] : !stream.resource<external>{%c12}
    } attributes {hal.interface.bindings = [#hal.interface.binding<0, 0>, #hal.interface.binding<0, 1>, #hal.interface.binding<0, 2>]}
  } => !stream.timepoint
  %2 = stream.timepoint.await %1 => %result : !stream.resource<external>{%c12}
  %3 = stream.tensor.export %2 : tensor<3xf32> in !stream.resource<external>{%c12} -> !hal.buffer_view
  return %3 : !hal.buffer_view
}

// -----// IR Dump After CPUMaterializeUpperBoundTileSize (iree-codegen-cpu-materialize-upper-bound-tile-size) //----- //
util.initializer {
  %0 = stream.timepoint.immediate => !stream.timepoint
  %c0_i64 = arith.constant 0 : i64
  %c128 = arith.constant 128 : index
  %c0 = arith.constant 0 : index
  %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
  %did_map, %result = stream.resource.try_map %buffer_cst[%c0] : !util.buffer -> i1, !stream.resource<constant>{%c128}
  cf.cond_br %did_map, ^bb2(%0, %result : !stream.timepoint, !stream.resource<constant>), ^bb1
^bb1:  // pred: ^bb0
  %1 = stream.resource.alloc uninitialized : !stream.resource<constant>{%c128}
  %file = stream.file.constant %buffer_cst[%c0 for %c128] : !util.buffer{%c128} -> !stream.file
  %2 = stream.file.read await(%0) => %file[%c0_i64], %1[%c0], %c128 : !stream.file -> !stream.resource<constant>{%c128} => !stream.timepoint
  cf.br ^bb2(%2, %1 : !stream.timepoint, !stream.resource<constant>)
^bb2(%3: !stream.timepoint, %4: !stream.resource<constant>):  // 2 preds: ^bb0, ^bb1
  util.global.store %4, @_params.weight : !stream.resource<constant>
  util.global.store %3, @_params.weight__timepoint : !stream.timepoint
  util.initializer.return
}

// -----// IR Dump After TypePropagation (iree-codegen-type-propagation) //----- //
func.func @main_dispatch_0_matmul_1x3x4_f32() {
  %c0 = arith.constant 0 : index
  %c64 = arith.constant 64 : index
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
  %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
  %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
  %4 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
  %5 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
  %6 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
  %7 = tensor.empty() : tensor<1x3xf32>
  %8 = linalg.fill ins(%cst : f32) outs(%7 : tensor<1x3xf32>) -> tensor<1x3xf32>
  %9 = linalg.matmul ins(%4, %5 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%8 : tensor<1x3xf32>) -> tensor<1x3xf32>
  %10 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%9, %6 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%7 : tensor<1x3xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %11 = arith.addf %in, %in_0 : f32
    linalg.yield %11 : f32
  } -> tensor<1x3xf32>
  flow.dispatch.tensor.store %10, %3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
  return
}

// -----// IR Dump After BubbleUpOrdinalOps (iree-codegen-bubble-up-ordinal-ops) //----- //
module {
  func.func @main_dispatch_0_matmul_1x3x4_f32() {
    %c0 = arith.constant 0 : index
    %c64 = arith.constant 64 : index
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
    %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
    %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
    %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
    %4 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
    %5 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
    %6 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
    %7 = tensor.empty() : tensor<1x3xf32>
    %8 = linalg.fill ins(%cst : f32) outs(%7 : tensor<1x3xf32>) -> tensor<1x3xf32>
    %9 = linalg.matmul ins(%4, %5 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%8 : tensor<1x3xf32>) -> tensor<1x3xf32>
    %10 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%9, %6 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%7 : tensor<1x3xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %11 = arith.addf %in, %in_0 : f32
      linalg.yield %11 : f32
    } -> tensor<1x3xf32>
    flow.dispatch.tensor.store %10, %3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
    return
  }
}

// -----// IR Dump After BufferizeCopyOnlyDispatches (iree-codegen-bufferize-copy-only-dispatches) //----- //
module {
  func.func @main_dispatch_0_matmul_1x3x4_f32() {
    %c0 = arith.constant 0 : index
    %c64 = arith.constant 64 : index
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
    %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
    %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
    %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
    %4 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
    %5 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
    %6 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
    %7 = tensor.empty() : tensor<1x3xf32>
    %8 = linalg.fill ins(%cst : f32) outs(%7 : tensor<1x3xf32>) -> tensor<1x3xf32>
    %9 = linalg.matmul ins(%4, %5 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%8 : tensor<1x3xf32>) -> tensor<1x3xf32>
    %10 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%9, %6 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%7 : tensor<1x3xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %11 = arith.addf %in, %in_0 : f32
      linalg.yield %11 : f32
    } -> tensor<1x3xf32>
    flow.dispatch.tensor.store %10, %3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
    return
  }
}

// -----// IR Dump After DecomposeSoftmax (iree-linalg-ext-decompose-softmax) //----- //
func.func @main_dispatch_0_matmul_1x3x4_f32() {
  %c0 = arith.constant 0 : index
  %c64 = arith.constant 64 : index
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
  %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
  %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
  %4 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
  %5 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
  %6 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
  %7 = tensor.empty() : tensor<1x3xf32>
  %8 = linalg.fill ins(%cst : f32) outs(%7 : tensor<1x3xf32>) -> tensor<1x3xf32>
  %9 = linalg.matmul ins(%4, %5 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%8 : tensor<1x3xf32>) -> tensor<1x3xf32>
  %10 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%9, %6 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%7 : tensor<1x3xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %11 = arith.addf %in, %in_0 : f32
    linalg.yield %11 : f32
  } -> tensor<1x3xf32>
  flow.dispatch.tensor.store %10, %3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
  return
}

// -----// IR Dump After MaterializeUserConfigs (iree-codegen-materialize-user-configs) //----- //
hal.executable.variant public @cuda_nvptx_fb target(<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>) {
  hal.executable.export public @main_dispatch_0_matmul_1x3x4_f32 ordinal(0) layout(#hal.pipeline.layout<push_constants = 0, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>) {
  ^bb0(%arg0: !hal.device):
    %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
    hal.return %x, %y, %z : index, index, index
  }
  builtin.module {
    func.func @main_dispatch_0_matmul_1x3x4_f32() {
      %c0 = arith.constant 0 : index
      %c64 = arith.constant 64 : index
      %cst = arith.constant 0.000000e+00 : f32
      %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
      %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
      %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
      %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
      %4 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
      %5 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
      %6 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
      %7 = tensor.empty() : tensor<1x3xf32>
      %8 = linalg.fill ins(%cst : f32) outs(%7 : tensor<1x3xf32>) -> tensor<1x3xf32>
      %9 = linalg.matmul ins(%4, %5 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%8 : tensor<1x3xf32>) -> tensor<1x3xf32>
      %10 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%9, %6 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%7 : tensor<1x3xf32>) {
      ^bb0(%in: f32, %in_0: f32, %out: f32):
        %11 = arith.addf %in, %in_0 : f32
        linalg.yield %11 : f32
      } -> tensor<1x3xf32>
      flow.dispatch.tensor.store %10, %3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
      return
    }
  }
}

// -----// IR Dump After LLVMGPUSelectLoweringStrategy (iree-llvmgpu-select-lowering-strategy) //----- //
hal.executable.variant public @cuda_nvptx_fb target(<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>) {
  hal.executable.export public @main_dispatch_0_matmul_1x3x4_f32 ordinal(0) layout(#hal.pipeline.layout<push_constants = 0, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>) attributes {translation_info = #iree_codegen.translation_info<LLVMGPUMatmulSimt>, workgroup_size = [1 : index, 3 : index, 1 : index]} {
  ^bb0(%arg0: !hal.device):
    %x, %y, %z = flow.dispatch.workgroup_count_from_slice 
    hal.return %x, %y, %z : index, index, index
  }
  builtin.module {
    func.func @main_dispatch_0_matmul_1x3x4_f32() {
      %c0 = arith.constant 0 : index
      %c64 = arith.constant 64 : index
      %cst = arith.constant 0.000000e+00 : f32
      %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
      %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
      %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
      %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
      %4 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
      %5 = flow.dispatch.tensor.load %1, offsets = [0, 0], sizes = [4, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x3xf32>
      %6 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x3xf32>
      %7 = tensor.empty() : tensor<1x3xf32>
      %8 = linalg.fill {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[0, 1, 4]]>} ins(%cst : f32) outs(%7 : tensor<1x3xf32>) -> tensor<1x3xf32>
      %9 = linalg.matmul {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[0, 1, 4]]>} ins(%4, %5 : tensor<1x4xf32>, tensor<4x3xf32>) outs(%8 : tensor<1x3xf32>) -> tensor<1x3xf32>
      %10 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%9, %6 : tensor<1x3xf32>, tensor<1x3xf32>) outs(%7 : tensor<1x3xf32>) attrs =  {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[0, 1, 4]]>} {
      ^bb0(%in: f32, %in_0: f32, %out: f32):
        %11 = arith.addf %in, %in_0 : f32
        linalg.yield %11 : f32
      } -> tensor<1x3xf32>
      flow.dispatch.tensor.store %10, %3, offsets = [0, 0], sizes = [1, 3], strides = [1, 1] : tensor<1x3xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
      return
    }
  }
}

// -----// IR Dump After TileAndDistributeToWorkgroups (iree-codegen-tile-and-distribute-to-workgroups) //----- //
hal.executable.variant public @cuda_nvptx_fb target(<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>) {
  hal.executable.export public @main_dispatch_0_matmul_1x3x4_f32 ordinal(0) layout(#hal.pipeline.layout<push_constants = 0, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>) attributes {translation_info = #iree_codegen.translation_info<LLVMGPUMatmulSimt>, workgroup_size = [1 : index, 3 : index, 1 : index]} {
  ^bb0(%arg0: !hal.device):
    %c3 = arith.constant 3 : index
    %c1 = arith.constant 1 : index
    hal.return %c3, %c1, %c1 : index, index, index
  }
  builtin.module {
    func.func @main_dispatch_0_matmul_1x3x4_f32() {
      %c0 = arith.constant 0 : index
      %c64 = arith.constant 64 : index
      %cst = arith.constant 0.000000e+00 : f32
      %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
      %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
      %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
      %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
      %4 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
      %workgroup_id_x = hal.interface.workgroup.id[0] : index
      %5 = flow.dispatch.tensor.load %1, offsets = [0, %workgroup_id_x], sizes = [4, 1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x1xf32>
      %6 = tensor.empty() : tensor<1x1xf32>
      %7 = linalg.fill {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[0, 1, 4]]>} ins(%cst : f32) outs(%6 : tensor<1x1xf32>) -> tensor<1x1xf32>
      %8 = linalg.matmul {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[0, 1, 4]]>} ins(%4, %5 : tensor<1x4xf32>, tensor<4x1xf32>) outs(%7 : tensor<1x1xf32>) -> tensor<1x1xf32>
      %9 = flow.dispatch.tensor.load %2, offsets = [0, %workgroup_id_x], sizes = [1, 1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x1xf32>
      %10 = tensor.empty() : tensor<1x1xf32>
      %11 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%8, %9 : tensor<1x1xf32>, tensor<1x1xf32>) outs(%10 : tensor<1x1xf32>) attrs =  {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[0, 1, 4]]>} {
      ^bb0(%in: f32, %in_0: f32, %out: f32):
        %12 = arith.addf %in, %in_0 : f32
        linalg.yield %12 : f32
      } -> tensor<1x1xf32>
      flow.dispatch.tensor.store %11, %3, offsets = [0, %workgroup_id_x], sizes = [1, 1], strides = [1, 1] : tensor<1x1xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
      return
    }
  }
}

// -----// IR Dump After ConvertToDestinationPassingStyle (iree-codegen-convert-to-destination-passing-style) //----- //
func.func @main_dispatch_0_matmul_1x3x4_f32() {
  %c0 = arith.constant 0 : index
  %c64 = arith.constant 64 : index
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
  %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
  %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %4 = flow.dispatch.tensor.load %3, offsets = [0, %workgroup_id_x], sizes = [1, 1], strides = [1, 1] : !flow.dispatch.tensor<writeonly:tensor<1x3xf32>> -> tensor<1x1xf32>
  %5 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
  %workgroup_id_x_0 = hal.interface.workgroup.id[0] : index
  %6 = flow.dispatch.tensor.load %1, offsets = [0, %workgroup_id_x_0], sizes = [4, 1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x1xf32>
  %7 = tensor.empty() : tensor<1x1xf32>
  %8 = linalg.fill {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[0, 1, 4]]>} ins(%cst : f32) outs(%7 : tensor<1x1xf32>) -> tensor<1x1xf32>
  %9 = linalg.matmul {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[0, 1, 4]]>} ins(%5, %6 : tensor<1x4xf32>, tensor<4x1xf32>) outs(%8 : tensor<1x1xf32>) -> tensor<1x1xf32>
  %10 = flow.dispatch.tensor.load %2, offsets = [0, %workgroup_id_x_0], sizes = [1, 1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x1xf32>
  %11 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%9, %10 : tensor<1x1xf32>, tensor<1x1xf32>) outs(%4 : tensor<1x1xf32>) attrs =  {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[0, 1, 4]]>} {
  ^bb0(%in: f32, %in_1: f32, %out: f32):
    %12 = arith.addf %in, %in_1 : f32
    linalg.yield %12 : f32
  } -> tensor<1x1xf32>
  flow.dispatch.tensor.store %11, %3, offsets = [0, %workgroup_id_x_0], sizes = [1, 1], strides = [1, 1] : tensor<1x1xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
  return
}

// -----// IR Dump After TileAndDecomposeAttention (iree-linalg-ext-tile-and-decompose-attention) //----- //
func.func @main_dispatch_0_matmul_1x3x4_f32() {
  %c0 = arith.constant 0 : index
  %c64 = arith.constant 64 : index
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
  %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
  %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %4 = flow.dispatch.tensor.load %3, offsets = [0, %workgroup_id_x], sizes = [1, 1], strides = [1, 1] : !flow.dispatch.tensor<writeonly:tensor<1x3xf32>> -> tensor<1x1xf32>
  %5 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
  %workgroup_id_x_0 = hal.interface.workgroup.id[0] : index
  %6 = flow.dispatch.tensor.load %1, offsets = [0, %workgroup_id_x_0], sizes = [4, 1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x1xf32>
  %7 = tensor.empty() : tensor<1x1xf32>
  %8 = linalg.fill {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[0, 1, 4]]>} ins(%cst : f32) outs(%7 : tensor<1x1xf32>) -> tensor<1x1xf32>
  %9 = linalg.matmul {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[0, 1, 4]]>} ins(%5, %6 : tensor<1x4xf32>, tensor<4x1xf32>) outs(%8 : tensor<1x1xf32>) -> tensor<1x1xf32>
  %10 = flow.dispatch.tensor.load %2, offsets = [0, %workgroup_id_x_0], sizes = [1, 1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x1xf32>
  %11 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%9, %10 : tensor<1x1xf32>, tensor<1x1xf32>) outs(%4 : tensor<1x1xf32>) attrs =  {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[0, 1, 4]]>} {
  ^bb0(%in: f32, %in_1: f32, %out: f32):
    %12 = arith.addf %in, %in_1 : f32
    linalg.yield %12 : f32
  } -> tensor<1x1xf32>
  flow.dispatch.tensor.store %11, %3, offsets = [0, %workgroup_id_x_0], sizes = [1, 1], strides = [1, 1] : tensor<1x1xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
  return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
module {
  func.func @main_dispatch_0_matmul_1x3x4_f32() {
    %c0 = arith.constant 0 : index
    %c64 = arith.constant 64 : index
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
    %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
    %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
    %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %4 = flow.dispatch.tensor.load %3, offsets = [0, %workgroup_id_x], sizes = [1, 1], strides = [1, 1] : !flow.dispatch.tensor<writeonly:tensor<1x3xf32>> -> tensor<1x1xf32>
    %5 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
    %workgroup_id_x_0 = hal.interface.workgroup.id[0] : index
    %6 = flow.dispatch.tensor.load %1, offsets = [0, %workgroup_id_x_0], sizes = [4, 1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x1xf32>
    %7 = tensor.empty() : tensor<1x1xf32>
    %8 = linalg.fill {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[0, 1, 4]]>} ins(%cst : f32) outs(%7 : tensor<1x1xf32>) -> tensor<1x1xf32>
    %9 = linalg.matmul {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[0, 1, 4]]>} ins(%5, %6 : tensor<1x4xf32>, tensor<4x1xf32>) outs(%8 : tensor<1x1xf32>) -> tensor<1x1xf32>
    %10 = flow.dispatch.tensor.load %2, offsets = [0, %workgroup_id_x_0], sizes = [1, 1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x1xf32>
    %11 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%9, %10 : tensor<1x1xf32>, tensor<1x1xf32>) outs(%4 : tensor<1x1xf32>) attrs =  {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[0, 1, 4]]>} {
    ^bb0(%in: f32, %in_1: f32, %out: f32):
      %12 = arith.addf %in, %in_1 : f32
      linalg.yield %12 : f32
    } -> tensor<1x1xf32>
    flow.dispatch.tensor.store %11, %3, offsets = [0, %workgroup_id_x_0], sizes = [1, 1], strides = [1, 1] : tensor<1x1xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
    return
  }
}

// -----// IR Dump After CSE (cse) //----- //
module {
  func.func @main_dispatch_0_matmul_1x3x4_f32() {
    %c0 = arith.constant 0 : index
    %c64 = arith.constant 64 : index
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
    %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
    %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
    %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %4 = flow.dispatch.tensor.load %3, offsets = [0, %workgroup_id_x], sizes = [1, 1], strides = [1, 1] : !flow.dispatch.tensor<writeonly:tensor<1x3xf32>> -> tensor<1x1xf32>
    %5 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
    %6 = flow.dispatch.tensor.load %1, offsets = [0, %workgroup_id_x], sizes = [4, 1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x1xf32>
    %7 = tensor.empty() : tensor<1x1xf32>
    %8 = linalg.fill {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[0, 1, 4]]>} ins(%cst : f32) outs(%7 : tensor<1x1xf32>) -> tensor<1x1xf32>
    %9 = linalg.matmul {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[0, 1, 4]]>} ins(%5, %6 : tensor<1x4xf32>, tensor<4x1xf32>) outs(%8 : tensor<1x1xf32>) -> tensor<1x1xf32>
    %10 = flow.dispatch.tensor.load %2, offsets = [0, %workgroup_id_x], sizes = [1, 1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x1xf32>
    %11 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%9, %10 : tensor<1x1xf32>, tensor<1x1xf32>) outs(%4 : tensor<1x1xf32>) attrs =  {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[0, 1, 4]]>} {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %12 = arith.addf %in, %in_0 : f32
      linalg.yield %12 : f32
    } -> tensor<1x1xf32>
    flow.dispatch.tensor.store %11, %3, offsets = [0, %workgroup_id_x], sizes = [1, 1], strides = [1, 1] : tensor<1x1xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
    return
  }
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
module {
  func.func @main_dispatch_0_matmul_1x3x4_f32() {
    %c0 = arith.constant 0 : index
    %c64 = arith.constant 64 : index
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
    %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
    %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
    %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %4 = flow.dispatch.tensor.load %3, offsets = [0, %workgroup_id_x], sizes = [1, 1], strides = [1, 1] : !flow.dispatch.tensor<writeonly:tensor<1x3xf32>> -> tensor<1x1xf32>
    %5 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
    %6 = flow.dispatch.tensor.load %1, offsets = [0, %workgroup_id_x], sizes = [4, 1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x1xf32>
    %7 = tensor.empty() : tensor<1x1xf32>
    %8 = linalg.fill {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[0, 1, 4]]>} ins(%cst : f32) outs(%7 : tensor<1x1xf32>) -> tensor<1x1xf32>
    %9 = linalg.matmul {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[0, 1, 4]]>} ins(%5, %6 : tensor<1x4xf32>, tensor<4x1xf32>) outs(%8 : tensor<1x1xf32>) -> tensor<1x1xf32>
    %10 = flow.dispatch.tensor.load %2, offsets = [0, %workgroup_id_x], sizes = [1, 1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x1xf32>
    %11 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%9, %10 : tensor<1x1xf32>, tensor<1x1xf32>) outs(%4 : tensor<1x1xf32>) attrs =  {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[0, 1, 4]]>} {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %12 = arith.addf %in, %in_0 : f32
      linalg.yield %12 : f32
    } -> tensor<1x1xf32>
    flow.dispatch.tensor.store %11, %3, offsets = [0, %workgroup_id_x], sizes = [1, 1], strides = [1, 1] : tensor<1x1xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
    return
  }
}

// -----// IR Dump After WorkgroupSpecialization (iree-codegen-workgroup-specialization) //----- //
func.func @main_dispatch_0_matmul_1x3x4_f32() {
  %c0 = arith.constant 0 : index
  %c64 = arith.constant 64 : index
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
  %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
  %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %4 = flow.dispatch.tensor.load %3, offsets = [0, %workgroup_id_x], sizes = [1, 1], strides = [1, 1] : !flow.dispatch.tensor<writeonly:tensor<1x3xf32>> -> tensor<1x1xf32>
  %5 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
  %6 = flow.dispatch.tensor.load %1, offsets = [0, %workgroup_id_x], sizes = [4, 1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x1xf32>
  %7 = tensor.empty() : tensor<1x1xf32>
  %8 = linalg.fill {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[0, 1, 4]]>} ins(%cst : f32) outs(%7 : tensor<1x1xf32>) -> tensor<1x1xf32>
  %9 = linalg.matmul {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[0, 1, 4]]>} ins(%5, %6 : tensor<1x4xf32>, tensor<4x1xf32>) outs(%8 : tensor<1x1xf32>) -> tensor<1x1xf32>
  %10 = flow.dispatch.tensor.load %2, offsets = [0, %workgroup_id_x], sizes = [1, 1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x1xf32>
  %11 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%9, %10 : tensor<1x1xf32>, tensor<1x1xf32>) outs(%4 : tensor<1x1xf32>) attrs =  {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[0, 1, 4]]>} {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %12 = arith.addf %in, %in_0 : f32
    linalg.yield %12 : f32
  } -> tensor<1x1xf32>
  flow.dispatch.tensor.store %11, %3, offsets = [0, %workgroup_id_x], sizes = [1, 1], strides = [1, 1] : tensor<1x1xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
  return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
module {
  func.func @main_dispatch_0_matmul_1x3x4_f32() {
    %c0 = arith.constant 0 : index
    %c64 = arith.constant 64 : index
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
    %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
    %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
    %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %4 = flow.dispatch.tensor.load %3, offsets = [0, %workgroup_id_x], sizes = [1, 1], strides = [1, 1] : !flow.dispatch.tensor<writeonly:tensor<1x3xf32>> -> tensor<1x1xf32>
    %5 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
    %6 = flow.dispatch.tensor.load %1, offsets = [0, %workgroup_id_x], sizes = [4, 1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x1xf32>
    %7 = tensor.empty() : tensor<1x1xf32>
    %8 = linalg.fill {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[0, 1, 4]]>} ins(%cst : f32) outs(%7 : tensor<1x1xf32>) -> tensor<1x1xf32>
    %9 = linalg.matmul {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[0, 1, 4]]>} ins(%5, %6 : tensor<1x4xf32>, tensor<4x1xf32>) outs(%8 : tensor<1x1xf32>) -> tensor<1x1xf32>
    %10 = flow.dispatch.tensor.load %2, offsets = [0, %workgroup_id_x], sizes = [1, 1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x1xf32>
    %11 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%9, %10 : tensor<1x1xf32>, tensor<1x1xf32>) outs(%4 : tensor<1x1xf32>) attrs =  {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[0, 1, 4]]>} {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %12 = arith.addf %in, %in_0 : f32
      linalg.yield %12 : f32
    } -> tensor<1x1xf32>
    flow.dispatch.tensor.store %11, %3, offsets = [0, %workgroup_id_x], sizes = [1, 1], strides = [1, 1] : tensor<1x1xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
    return
  }
}

// -----// IR Dump After CSE (cse) //----- //
module {
  func.func @main_dispatch_0_matmul_1x3x4_f32() {
    %c0 = arith.constant 0 : index
    %c64 = arith.constant 64 : index
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
    %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
    %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
    %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %4 = flow.dispatch.tensor.load %3, offsets = [0, %workgroup_id_x], sizes = [1, 1], strides = [1, 1] : !flow.dispatch.tensor<writeonly:tensor<1x3xf32>> -> tensor<1x1xf32>
    %5 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
    %6 = flow.dispatch.tensor.load %1, offsets = [0, %workgroup_id_x], sizes = [4, 1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x1xf32>
    %7 = tensor.empty() : tensor<1x1xf32>
    %8 = linalg.fill {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[0, 1, 4]]>} ins(%cst : f32) outs(%7 : tensor<1x1xf32>) -> tensor<1x1xf32>
    %9 = linalg.matmul {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[0, 1, 4]]>} ins(%5, %6 : tensor<1x4xf32>, tensor<4x1xf32>) outs(%8 : tensor<1x1xf32>) -> tensor<1x1xf32>
    %10 = flow.dispatch.tensor.load %2, offsets = [0, %workgroup_id_x], sizes = [1, 1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x1xf32>
    %11 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%9, %10 : tensor<1x1xf32>, tensor<1x1xf32>) outs(%4 : tensor<1x1xf32>) attrs =  {lowering_config = #iree_codegen.lowering_config<tile_sizes = [[0, 1, 4]]>} {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %12 = arith.addf %in, %in_0 : f32
      linalg.yield %12 : f32
    } -> tensor<1x1xf32>
    flow.dispatch.tensor.store %11, %3, offsets = [0, %workgroup_id_x], sizes = [1, 1], strides = [1, 1] : tensor<1x1xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
    return
  }
}

// -----// IR Dump After GPUTensorAlloc (iree-codegen-gpu-tensor-alloc) //----- //
func.func @main_dispatch_0_matmul_1x3x4_f32() {
  %c0 = arith.constant 0 : index
  %c64 = arith.constant 64 : index
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
  %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
  %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %4 = flow.dispatch.tensor.load %3, offsets = [0, %workgroup_id_x], sizes = [1, 1], strides = [1, 1] : !flow.dispatch.tensor<writeonly:tensor<1x3xf32>> -> tensor<1x1xf32>
  %5 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
  %6 = flow.dispatch.tensor.load %1, offsets = [0, %workgroup_id_x], sizes = [4, 1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x1xf32>
  %7 = tensor.empty() : tensor<1x1xf32>
  %8 = linalg.fill {__internal_linalg_transform__ = "workgroup_k_tiled", lowering_config = #iree_codegen.lowering_config<tile_sizes = [[0, 1, 4]]>} ins(%cst : f32) outs(%7 : tensor<1x1xf32>) -> tensor<1x1xf32>
  %9 = linalg.matmul {__internal_linalg_transform__ = "workgroup_k_tiled", lowering_config = #iree_codegen.lowering_config<tile_sizes = [[0, 1, 4]]>} ins(%5, %6 : tensor<1x4xf32>, tensor<4x1xf32>) outs(%8 : tensor<1x1xf32>) -> tensor<1x1xf32>
  %10 = flow.dispatch.tensor.load %2, offsets = [0, %workgroup_id_x], sizes = [1, 1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x1xf32>
  %11 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%9, %10 : tensor<1x1xf32>, tensor<1x1xf32>) outs(%4 : tensor<1x1xf32>) attrs =  {__internal_linalg_transform__ = "workgroup_k_tiled", lowering_config = #iree_codegen.lowering_config<tile_sizes = [[0, 1, 4]]>} {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %12 = arith.addf %in, %in_0 : f32
    linalg.yield %12 : f32
  } -> tensor<1x1xf32>
  flow.dispatch.tensor.store %11, %3, offsets = [0, %workgroup_id_x], sizes = [1, 1], strides = [1, 1] : tensor<1x1xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
  return
}

// -----// IR Dump After GPUTensorTile (iree-codegen-gpu-tensor-tile) //----- //
func.func @main_dispatch_0_matmul_1x3x4_f32() {
  %c0 = arith.constant 0 : index
  %c64 = arith.constant 64 : index
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
  %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
  %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %4 = flow.dispatch.tensor.load %3, offsets = [0, %workgroup_id_x], sizes = [1, 1], strides = [1, 1] : !flow.dispatch.tensor<writeonly:tensor<1x3xf32>> -> tensor<1x1xf32>
  %5 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
  %6 = flow.dispatch.tensor.load %1, offsets = [0, %workgroup_id_x], sizes = [4, 1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x1xf32>
  %7 = tensor.empty() : tensor<1x1xf32>
  %8 = linalg.fill {__internal_linalg_transform__ = "workgroup_k_tiled", lowering_config = #iree_codegen.lowering_config<tile_sizes = [[0, 1, 4]]>} ins(%cst : f32) outs(%7 : tensor<1x1xf32>) -> tensor<1x1xf32>
  %9 = linalg.matmul {__internal_linalg_transform__ = "workgroup_k_tiled", lowering_config = #iree_codegen.lowering_config<tile_sizes = [[0, 1, 4]]>} ins(%5, %6 : tensor<1x4xf32>, tensor<4x1xf32>) outs(%8 : tensor<1x1xf32>) -> tensor<1x1xf32>
  %10 = flow.dispatch.tensor.load %2, offsets = [0, %workgroup_id_x], sizes = [1, 1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x1xf32>
  %11 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%9, %10 : tensor<1x1xf32>, tensor<1x1xf32>) outs(%4 : tensor<1x1xf32>) attrs =  {__internal_linalg_transform__ = "workgroup_k_tiled", lowering_config = #iree_codegen.lowering_config<tile_sizes = [[0, 1, 4]]>} {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %12 = arith.addf %in, %in_0 : f32
    linalg.yield %12 : f32
  } -> tensor<1x1xf32>
  flow.dispatch.tensor.store %11, %3, offsets = [0, %workgroup_id_x], sizes = [1, 1], strides = [1, 1] : tensor<1x1xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
  return
}

// -----// IR Dump After DecomposeConvolutionToLowerDimOps (iree-codegen-decompose-convolution-to-lower-dim-ops) //----- //
func.func @main_dispatch_0_matmul_1x3x4_f32() {
  %c0 = arith.constant 0 : index
  %c64 = arith.constant 64 : index
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
  %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
  %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %4 = flow.dispatch.tensor.load %3, offsets = [0, %workgroup_id_x], sizes = [1, 1], strides = [1, 1] : !flow.dispatch.tensor<writeonly:tensor<1x3xf32>> -> tensor<1x1xf32>
  %5 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
  %6 = flow.dispatch.tensor.load %1, offsets = [0, %workgroup_id_x], sizes = [4, 1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x1xf32>
  %7 = tensor.empty() : tensor<1x1xf32>
  %8 = linalg.fill {__internal_linalg_transform__ = "workgroup_k_tiled", lowering_config = #iree_codegen.lowering_config<tile_sizes = [[0, 1, 4]]>} ins(%cst : f32) outs(%7 : tensor<1x1xf32>) -> tensor<1x1xf32>
  %9 = linalg.matmul {__internal_linalg_transform__ = "workgroup_k_tiled", lowering_config = #iree_codegen.lowering_config<tile_sizes = [[0, 1, 4]]>} ins(%5, %6 : tensor<1x4xf32>, tensor<4x1xf32>) outs(%8 : tensor<1x1xf32>) -> tensor<1x1xf32>
  %10 = flow.dispatch.tensor.load %2, offsets = [0, %workgroup_id_x], sizes = [1, 1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x1xf32>
  %11 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%9, %10 : tensor<1x1xf32>, tensor<1x1xf32>) outs(%4 : tensor<1x1xf32>) attrs =  {__internal_linalg_transform__ = "workgroup_k_tiled", lowering_config = #iree_codegen.lowering_config<tile_sizes = [[0, 1, 4]]>} {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %12 = arith.addf %in, %in_0 : f32
    linalg.yield %12 : f32
  } -> tensor<1x1xf32>
  flow.dispatch.tensor.store %11, %3, offsets = [0, %workgroup_id_x], sizes = [1, 1], strides = [1, 1] : tensor<1x1xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
  return
}

// -----// IR Dump After GenericVectorization (iree-codegen-generic-vectorization) //----- //
func.func @main_dispatch_0_matmul_1x3x4_f32() {
  %cst = arith.constant dense<0.000000e+00> : vector<1x1xf32>
  %c0 = arith.constant 0 : index
  %c64 = arith.constant 64 : index
  %cst_0 = arith.constant 0.000000e+00 : f32
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
  %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
  %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %4 = flow.dispatch.tensor.load %3, offsets = [0, %workgroup_id_x], sizes = [1, 1], strides = [1, 1] : !flow.dispatch.tensor<writeonly:tensor<1x3xf32>> -> tensor<1x1xf32>
  %5 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
  %6 = flow.dispatch.tensor.load %1, offsets = [0, %workgroup_id_x], sizes = [4, 1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x1xf32>
  %7 = vector.transfer_read %5[%c0, %c0], %cst_0 {in_bounds = [true, true]} : tensor<1x4xf32>, vector<1x4xf32>
  %8 = vector.transfer_read %6[%c0, %c0], %cst_0 {in_bounds = [true, true]} : tensor<4x1xf32>, vector<4x1xf32>
  %9 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"], kind = #vector.kind<add>} %7, %8, %cst : vector<1x4xf32>, vector<4x1xf32> into vector<1x1xf32>
  %10 = flow.dispatch.tensor.load %2, offsets = [0, %workgroup_id_x], sizes = [1, 1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x1xf32>
  %11 = vector.transfer_read %10[%c0, %c0], %cst_0 {in_bounds = [true, true]} : tensor<1x1xf32>, vector<1x1xf32>
  %12 = arith.addf %9, %11 : vector<1x1xf32>
  %13 = vector.transfer_write %12, %4[%c0, %c0] {in_bounds = [true, true]} : vector<1x1xf32>, tensor<1x1xf32>
  flow.dispatch.tensor.store %13, %3, offsets = [0, %workgroup_id_x], sizes = [1, 1], strides = [1, 1] : tensor<1x1xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
  return
}

// -----// IR Dump After HoistRedundantVectorTransfers (iree-codegen-hoist-redundant-vector-transfers) //----- //
func.func @main_dispatch_0_matmul_1x3x4_f32() {
  %cst = arith.constant dense<0.000000e+00> : vector<1x1xf32>
  %c0 = arith.constant 0 : index
  %c64 = arith.constant 64 : index
  %cst_0 = arith.constant 0.000000e+00 : f32
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
  %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
  %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %4 = flow.dispatch.tensor.load %3, offsets = [0, %workgroup_id_x], sizes = [1, 1], strides = [1, 1] : !flow.dispatch.tensor<writeonly:tensor<1x3xf32>> -> tensor<1x1xf32>
  %5 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
  %6 = flow.dispatch.tensor.load %1, offsets = [0, %workgroup_id_x], sizes = [4, 1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x1xf32>
  %7 = vector.transfer_read %5[%c0, %c0], %cst_0 {in_bounds = [true, true]} : tensor<1x4xf32>, vector<1x4xf32>
  %8 = vector.transfer_read %6[%c0, %c0], %cst_0 {in_bounds = [true, true]} : tensor<4x1xf32>, vector<4x1xf32>
  %9 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"], kind = #vector.kind<add>} %7, %8, %cst : vector<1x4xf32>, vector<4x1xf32> into vector<1x1xf32>
  %10 = flow.dispatch.tensor.load %2, offsets = [0, %workgroup_id_x], sizes = [1, 1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x1xf32>
  %11 = vector.transfer_read %10[%c0, %c0], %cst_0 {in_bounds = [true, true]} : tensor<1x1xf32>, vector<1x1xf32>
  %12 = arith.addf %9, %11 : vector<1x1xf32>
  %13 = vector.transfer_write %12, %4[%c0, %c0] {in_bounds = [true, true]} : vector<1x1xf32>, tensor<1x1xf32>
  flow.dispatch.tensor.store %13, %3, offsets = [0, %workgroup_id_x], sizes = [1, 1], strides = [1, 1] : tensor<1x1xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
  return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main_dispatch_0_matmul_1x3x4_f32() {
  %c0 = arith.constant 0 : index
  %c64 = arith.constant 64 : index
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
  %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
  %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %4 = flow.dispatch.tensor.load %3, offsets = [0, %workgroup_id_x], sizes = [1, 1], strides = [1, 1] : !flow.dispatch.tensor<writeonly:tensor<1x3xf32>> -> tensor<1x1xf32>
  %5 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
  %6 = flow.dispatch.tensor.load %1, offsets = [0, %workgroup_id_x], sizes = [4, 1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x1xf32>
  %7 = vector.transfer_read %5[%c0, %c0], %cst {in_bounds = [true, true]} : tensor<1x4xf32>, vector<1x4xf32>
  %8 = vector.transfer_read %6[%c0, %c0], %cst {in_bounds = [true, true]} : tensor<4x1xf32>, vector<4x1xf32>
  %9 = flow.dispatch.tensor.load %2, offsets = [0, %workgroup_id_x], sizes = [1, 1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x1xf32>
  %10 = vector.transfer_read %9[%c0, %c0], %cst {in_bounds = [true, true]} : tensor<1x1xf32>, vector<1x1xf32>
  %11 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"], kind = #vector.kind<add>} %7, %8, %10 : vector<1x4xf32>, vector<4x1xf32> into vector<1x1xf32>
  %12 = vector.transfer_write %11, %4[%c0, %c0] {in_bounds = [true, true]} : vector<1x1xf32>, tensor<1x1xf32>
  flow.dispatch.tensor.store %12, %3, offsets = [0, %workgroup_id_x], sizes = [1, 1], strides = [1, 1] : tensor<1x1xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @main_dispatch_0_matmul_1x3x4_f32() {
  %c0 = arith.constant 0 : index
  %c64 = arith.constant 64 : index
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
  %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
  %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %4 = flow.dispatch.tensor.load %3, offsets = [0, %workgroup_id_x], sizes = [1, 1], strides = [1, 1] : !flow.dispatch.tensor<writeonly:tensor<1x3xf32>> -> tensor<1x1xf32>
  %5 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
  %6 = flow.dispatch.tensor.load %1, offsets = [0, %workgroup_id_x], sizes = [4, 1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x1xf32>
  %7 = vector.transfer_read %5[%c0, %c0], %cst {in_bounds = [true, true]} : tensor<1x4xf32>, vector<1x4xf32>
  %8 = vector.transfer_read %6[%c0, %c0], %cst {in_bounds = [true, true]} : tensor<4x1xf32>, vector<4x1xf32>
  %9 = flow.dispatch.tensor.load %2, offsets = [0, %workgroup_id_x], sizes = [1, 1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x1xf32>
  %10 = vector.transfer_read %9[%c0, %c0], %cst {in_bounds = [true, true]} : tensor<1x1xf32>, vector<1x1xf32>
  %11 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"], kind = #vector.kind<add>} %7, %8, %10 : vector<1x4xf32>, vector<4x1xf32> into vector<1x1xf32>
  %12 = vector.transfer_write %11, %4[%c0, %c0] {in_bounds = [true, true]} : vector<1x1xf32>, tensor<1x1xf32>
  flow.dispatch.tensor.store %12, %3, offsets = [0, %workgroup_id_x], sizes = [1, 1], strides = [1, 1] : tensor<1x1xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
  return
}

// -----// IR Dump After EliminateEmptyTensors (iree-eliminate-empty-tensors) //----- //
module {
  func.func @main_dispatch_0_matmul_1x3x4_f32() {
    %c0 = arith.constant 0 : index
    %c64 = arith.constant 64 : index
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
    %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
    %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
    %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %4 = flow.dispatch.tensor.load %3, offsets = [0, %workgroup_id_x], sizes = [1, 1], strides = [1, 1] : !flow.dispatch.tensor<writeonly:tensor<1x3xf32>> -> tensor<1x1xf32>
    %5 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
    %6 = flow.dispatch.tensor.load %1, offsets = [0, %workgroup_id_x], sizes = [4, 1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x1xf32>
    %7 = vector.transfer_read %5[%c0, %c0], %cst {in_bounds = [true, true]} : tensor<1x4xf32>, vector<1x4xf32>
    %8 = vector.transfer_read %6[%c0, %c0], %cst {in_bounds = [true, true]} : tensor<4x1xf32>, vector<4x1xf32>
    %9 = flow.dispatch.tensor.load %2, offsets = [0, %workgroup_id_x], sizes = [1, 1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x1xf32>
    %10 = vector.transfer_read %9[%c0, %c0], %cst {in_bounds = [true, true]} : tensor<1x1xf32>, vector<1x1xf32>
    %11 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"], kind = #vector.kind<add>} %7, %8, %10 : vector<1x4xf32>, vector<4x1xf32> into vector<1x1xf32>
    %12 = vector.transfer_write %11, %4[%c0, %c0] {in_bounds = [true, true]} : vector<1x1xf32>, tensor<1x1xf32>
    flow.dispatch.tensor.store %12, %3, offsets = [0, %workgroup_id_x], sizes = [1, 1], strides = [1, 1] : tensor<1x1xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
    return
  }
}

// -----// IR Dump After EmptyTensorToAllocTensor (empty-tensor-to-alloc-tensor) //----- //
module {
  func.func @main_dispatch_0_matmul_1x3x4_f32() {
    %c0 = arith.constant 0 : index
    %c64 = arith.constant 64 : index
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<1x4xf32>>
    %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<4x3xf32>>
    %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<1x3xf32>>
    %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %4 = flow.dispatch.tensor.load %3, offsets = [0, %workgroup_id_x], sizes = [1, 1], strides = [1, 1] : !flow.dispatch.tensor<writeonly:tensor<1x3xf32>> -> tensor<1x1xf32>
    %5 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [1, 4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x4xf32>> -> tensor<1x4xf32>
    %6 = flow.dispatch.tensor.load %1, offsets = [0, %workgroup_id_x], sizes = [4, 1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<4x3xf32>> -> tensor<4x1xf32>
    %7 = vector.transfer_read %5[%c0, %c0], %cst {in_bounds = [true, true]} : tensor<1x4xf32>, vector<1x4xf32>
    %8 = vector.transfer_read %6[%c0, %c0], %cst {in_bounds = [true, true]} : tensor<4x1xf32>, vector<4x1xf32>
    %9 = flow.dispatch.tensor.load %2, offsets = [0, %workgroup_id_x], sizes = [1, 1], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<1x3xf32>> -> tensor<1x1xf32>
    %10 = vector.transfer_read %9[%c0, %c0], %cst {in_bounds = [true, true]} : tensor<1x1xf32>, vector<1x1xf32>
    %11 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"], kind = #vector.kind<add>} %7, %8, %10 : vector<1x4xf32>, vector<4x1xf32> into vector<1x1xf32>
    %12 = vector.transfer_write %11, %4[%c0, %c0] {in_bounds = [true, true]} : vector<1x1xf32>, tensor<1x1xf32>
    flow.dispatch.tensor.store %12, %3, offsets = [0, %workgroup_id_x], sizes = [1, 1], strides = [1, 1] : tensor<1x1xf32> -> !flow.dispatch.tensor<writeonly:tensor<1x3xf32>>
    return
  }
}

// -----// IR Dump After IREEComprehensiveBufferize (iree-codegen-iree-comprehensive-bufferize) //----- //
module {
  func.func @main_dispatch_0_matmul_1x3x4_f32() {
    %c0 = arith.constant 0 : index
    %c64 = arith.constant 64 : index
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<1x4xf32, #hal.descriptor_type<storage_buffer>>
    memref.assume_alignment %0, 64 : memref<1x4xf32, #hal.descriptor_type<storage_buffer>>
    %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<4x3xf32, #hal.descriptor_type<storage_buffer>>
    memref.assume_alignment %1, 64 : memref<4x3xf32, #hal.descriptor_type<storage_buffer>>
    %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : memref<1x3xf32, strided<[3, 1], offset: 16>, #hal.descriptor_type<storage_buffer>>
    memref.assume_alignment %2, 64 : memref<1x3xf32, strided<[3, 1], offset: 16>, #hal.descriptor_type<storage_buffer>>
    %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<1x3xf32, #hal.descriptor_type<storage_buffer>>
    memref.assume_alignment %3, 64 : memref<1x3xf32, #hal.descriptor_type<storage_buffer>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %subview = memref.subview %3[0, %workgroup_id_x] [1, 1] [1, 1] : memref<1x3xf32, #hal.descriptor_type<storage_buffer>> to memref<1x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %subview_0 = memref.subview %1[0, %workgroup_id_x] [4, 1] [1, 1] : memref<4x3xf32, #hal.descriptor_type<storage_buffer>> to memref<4x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %4 = vector.transfer_read %0[%c0, %c0], %cst {in_bounds = [true, true]} : memref<1x4xf32, #hal.descriptor_type<storage_buffer>>, vector<1x4xf32>
    %5 = vector.transfer_read %subview_0[%c0, %c0], %cst {in_bounds = [true, true]} : memref<4x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<4x1xf32>
    %subview_1 = memref.subview %2[0, %workgroup_id_x] [1, 1] [1, 1] : memref<1x3xf32, strided<[3, 1], offset: 16>, #hal.descriptor_type<storage_buffer>> to memref<1x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %6 = vector.transfer_read %subview_1[%c0, %c0], %cst {in_bounds = [true, true]} : memref<1x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<1x1xf32>
    %7 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"], kind = #vector.kind<add>} %4, %5, %6 : vector<1x4xf32>, vector<4x1xf32> into vector<1x1xf32>
    vector.transfer_write %7, %subview[%c0, %c0] {in_bounds = [true, true]} : vector<1x1xf32>, memref<1x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %subview_2 = memref.subview %3[0, %workgroup_id_x] [1, 1] [1, 1] : memref<1x3xf32, #hal.descriptor_type<storage_buffer>> to memref<1x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    memref.copy %subview, %subview_2 : memref<1x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<1x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    return
  }
}

// -----// IR Dump After ResolveShapedTypeResultDims (resolve-shaped-type-result-dims) //----- //
module {
  func.func @main_dispatch_0_matmul_1x3x4_f32() {
    %c0 = arith.constant 0 : index
    %c64 = arith.constant 64 : index
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<1x4xf32, #hal.descriptor_type<storage_buffer>>
    memref.assume_alignment %0, 64 : memref<1x4xf32, #hal.descriptor_type<storage_buffer>>
    %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<4x3xf32, #hal.descriptor_type<storage_buffer>>
    memref.assume_alignment %1, 64 : memref<4x3xf32, #hal.descriptor_type<storage_buffer>>
    %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : memref<1x3xf32, strided<[3, 1], offset: 16>, #hal.descriptor_type<storage_buffer>>
    memref.assume_alignment %2, 64 : memref<1x3xf32, strided<[3, 1], offset: 16>, #hal.descriptor_type<storage_buffer>>
    %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<1x3xf32, #hal.descriptor_type<storage_buffer>>
    memref.assume_alignment %3, 64 : memref<1x3xf32, #hal.descriptor_type<storage_buffer>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %subview = memref.subview %3[0, %workgroup_id_x] [1, 1] [1, 1] : memref<1x3xf32, #hal.descriptor_type<storage_buffer>> to memref<1x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %subview_0 = memref.subview %1[0, %workgroup_id_x] [4, 1] [1, 1] : memref<4x3xf32, #hal.descriptor_type<storage_buffer>> to memref<4x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %4 = vector.transfer_read %0[%c0, %c0], %cst {in_bounds = [true, true]} : memref<1x4xf32, #hal.descriptor_type<storage_buffer>>, vector<1x4xf32>
    %5 = vector.transfer_read %subview_0[%c0, %c0], %cst {in_bounds = [true, true]} : memref<4x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<4x1xf32>
    %subview_1 = memref.subview %2[0, %workgroup_id_x] [1, 1] [1, 1] : memref<1x3xf32, strided<[3, 1], offset: 16>, #hal.descriptor_type<storage_buffer>> to memref<1x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %6 = vector.transfer_read %subview_1[%c0, %c0], %cst {in_bounds = [true, true]} : memref<1x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<1x1xf32>
    %7 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"], kind = #vector.kind<add>} %4, %5, %6 : vector<1x4xf32>, vector<4x1xf32> into vector<1x1xf32>
    vector.transfer_write %7, %subview[%c0, %c0] {in_bounds = [true, true]} : vector<1x1xf32>, memref<1x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %subview_2 = memref.subview %3[0, %workgroup_id_x] [1, 1] [1, 1] : memref<1x3xf32, #hal.descriptor_type<storage_buffer>> to memref<1x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    memref.copy %subview, %subview_2 : memref<1x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<1x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    return
  }
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main_dispatch_0_matmul_1x3x4_f32() {
  %c0 = arith.constant 0 : index
  %c64 = arith.constant 64 : index
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<1x4xf32, #hal.descriptor_type<storage_buffer>>
  memref.assume_alignment %0, 64 : memref<1x4xf32, #hal.descriptor_type<storage_buffer>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<4x3xf32, #hal.descriptor_type<storage_buffer>>
  memref.assume_alignment %1, 64 : memref<4x3xf32, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : memref<1x3xf32, strided<[3, 1], offset: 16>, #hal.descriptor_type<storage_buffer>>
  memref.assume_alignment %2, 64 : memref<1x3xf32, strided<[3, 1], offset: 16>, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<1x3xf32, #hal.descriptor_type<storage_buffer>>
  memref.assume_alignment %3, 64 : memref<1x3xf32, #hal.descriptor_type<storage_buffer>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %subview = memref.subview %3[0, %workgroup_id_x] [1, 1] [1, 1] : memref<1x3xf32, #hal.descriptor_type<storage_buffer>> to memref<1x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %subview_0 = memref.subview %1[0, %workgroup_id_x] [4, 1] [1, 1] : memref<4x3xf32, #hal.descriptor_type<storage_buffer>> to memref<4x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %4 = vector.transfer_read %0[%c0, %c0], %cst {in_bounds = [true, true]} : memref<1x4xf32, #hal.descriptor_type<storage_buffer>>, vector<1x4xf32>
  %5 = vector.transfer_read %subview_0[%c0, %c0], %cst {in_bounds = [true, true]} : memref<4x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<4x1xf32>
  %subview_1 = memref.subview %2[0, %workgroup_id_x] [1, 1] [1, 1] : memref<1x3xf32, strided<[3, 1], offset: 16>, #hal.descriptor_type<storage_buffer>> to memref<1x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %6 = vector.transfer_read %subview_1[%c0, %c0], %cst {in_bounds = [true, true]} : memref<1x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<1x1xf32>
  %7 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"], kind = #vector.kind<add>} %4, %5, %6 : vector<1x4xf32>, vector<4x1xf32> into vector<1x1xf32>
  vector.transfer_write %7, %subview[%c0, %c0] {in_bounds = [true, true]} : vector<1x1xf32>, memref<1x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %subview_2 = memref.subview %3[0, %workgroup_id_x] [1, 1] [1, 1] : memref<1x3xf32, #hal.descriptor_type<storage_buffer>> to memref<1x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  memref.copy %subview, %subview_2 : memref<1x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<1x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @main_dispatch_0_matmul_1x3x4_f32() {
  %c0 = arith.constant 0 : index
  %c64 = arith.constant 64 : index
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<1x4xf32, #hal.descriptor_type<storage_buffer>>
  memref.assume_alignment %0, 64 : memref<1x4xf32, #hal.descriptor_type<storage_buffer>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<4x3xf32, #hal.descriptor_type<storage_buffer>>
  memref.assume_alignment %1, 64 : memref<4x3xf32, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : memref<1x3xf32, strided<[3, 1], offset: 16>, #hal.descriptor_type<storage_buffer>>
  memref.assume_alignment %2, 64 : memref<1x3xf32, strided<[3, 1], offset: 16>, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<1x3xf32, #hal.descriptor_type<storage_buffer>>
  memref.assume_alignment %3, 64 : memref<1x3xf32, #hal.descriptor_type<storage_buffer>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %subview = memref.subview %3[0, %workgroup_id_x] [1, 1] [1, 1] : memref<1x3xf32, #hal.descriptor_type<storage_buffer>> to memref<1x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %subview_0 = memref.subview %1[0, %workgroup_id_x] [4, 1] [1, 1] : memref<4x3xf32, #hal.descriptor_type<storage_buffer>> to memref<4x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %4 = vector.transfer_read %0[%c0, %c0], %cst {in_bounds = [true, true]} : memref<1x4xf32, #hal.descriptor_type<storage_buffer>>, vector<1x4xf32>
  %5 = vector.transfer_read %subview_0[%c0, %c0], %cst {in_bounds = [true, true]} : memref<4x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<4x1xf32>
  %subview_1 = memref.subview %2[0, %workgroup_id_x] [1, 1] [1, 1] : memref<1x3xf32, strided<[3, 1], offset: 16>, #hal.descriptor_type<storage_buffer>> to memref<1x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %6 = vector.transfer_read %subview_1[%c0, %c0], %cst {in_bounds = [true, true]} : memref<1x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<1x1xf32>
  %7 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"], kind = #vector.kind<add>} %4, %5, %6 : vector<1x4xf32>, vector<4x1xf32> into vector<1x1xf32>
  vector.transfer_write %7, %subview[%c0, %c0] {in_bounds = [true, true]} : vector<1x1xf32>, memref<1x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  memref.copy %subview, %subview : memref<1x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>> to memref<1x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main_dispatch_0_matmul_1x3x4_f32() {
  %c0 = arith.constant 0 : index
  %c64 = arith.constant 64 : index
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<1x4xf32, #hal.descriptor_type<storage_buffer>>
  memref.assume_alignment %0, 64 : memref<1x4xf32, #hal.descriptor_type<storage_buffer>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<4x3xf32, #hal.descriptor_type<storage_buffer>>
  memref.assume_alignment %1, 64 : memref<4x3xf32, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : memref<1x3xf32, strided<[3, 1], offset: 16>, #hal.descriptor_type<storage_buffer>>
  memref.assume_alignment %2, 64 : memref<1x3xf32, strided<[3, 1], offset: 16>, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<1x3xf32, #hal.descriptor_type<storage_buffer>>
  memref.assume_alignment %3, 64 : memref<1x3xf32, #hal.descriptor_type<storage_buffer>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %subview = memref.subview %3[0, %workgroup_id_x] [1, 1] [1, 1] : memref<1x3xf32, #hal.descriptor_type<storage_buffer>> to memref<1x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %subview_0 = memref.subview %1[0, %workgroup_id_x] [4, 1] [1, 1] : memref<4x3xf32, #hal.descriptor_type<storage_buffer>> to memref<4x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %4 = vector.transfer_read %0[%c0, %c0], %cst {in_bounds = [true, true]} : memref<1x4xf32, #hal.descriptor_type<storage_buffer>>, vector<1x4xf32>
  %5 = vector.transfer_read %subview_0[%c0, %c0], %cst {in_bounds = [true, true]} : memref<4x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<4x1xf32>
  %subview_1 = memref.subview %2[0, %workgroup_id_x] [1, 1] [1, 1] : memref<1x3xf32, strided<[3, 1], offset: 16>, #hal.descriptor_type<storage_buffer>> to memref<1x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %6 = vector.transfer_read %subview_1[%c0, %c0], %cst {in_bounds = [true, true]} : memref<1x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<1x1xf32>
  %7 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"], kind = #vector.kind<add>} %4, %5, %6 : vector<1x4xf32>, vector<4x1xf32> into vector<1x1xf32>
  vector.transfer_write %7, %subview[%c0, %c0] {in_bounds = [true, true]} : vector<1x1xf32>, memref<1x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After CleanupBufferAllocView (iree-codegen-cleanup-buffer-alloc-view) //----- //
func.func @main_dispatch_0_matmul_1x3x4_f32() {
  %c0 = arith.constant 0 : index
  %c64 = arith.constant 64 : index
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<1x4xf32, #hal.descriptor_type<storage_buffer>>
  memref.assume_alignment %0, 64 : memref<1x4xf32, #hal.descriptor_type<storage_buffer>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<4x3xf32, #hal.descriptor_type<storage_buffer>>
  memref.assume_alignment %1, 64 : memref<4x3xf32, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : memref<1x3xf32, strided<[3, 1], offset: 16>, #hal.descriptor_type<storage_buffer>>
  memref.assume_alignment %2, 64 : memref<1x3xf32, strided<[3, 1], offset: 16>, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<1x3xf32, #hal.descriptor_type<storage_buffer>>
  memref.assume_alignment %3, 64 : memref<1x3xf32, #hal.descriptor_type<storage_buffer>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %subview = memref.subview %3[0, %workgroup_id_x] [1, 1] [1, 1] : memref<1x3xf32, #hal.descriptor_type<storage_buffer>> to memref<1x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %subview_0 = memref.subview %1[0, %workgroup_id_x] [4, 1] [1, 1] : memref<4x3xf32, #hal.descriptor_type<storage_buffer>> to memref<4x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %4 = vector.transfer_read %0[%c0, %c0], %cst {in_bounds = [true, true]} : memref<1x4xf32, #hal.descriptor_type<storage_buffer>>, vector<1x4xf32>
  %5 = vector.transfer_read %subview_0[%c0, %c0], %cst {in_bounds = [true, true]} : memref<4x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<4x1xf32>
  %subview_1 = memref.subview %2[0, %workgroup_id_x] [1, 1] [1, 1] : memref<1x3xf32, strided<[3, 1], offset: 16>, #hal.descriptor_type<storage_buffer>> to memref<1x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %6 = vector.transfer_read %subview_1[%c0, %c0], %cst {in_bounds = [true, true]} : memref<1x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<1x1xf32>
  %7 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"], kind = #vector.kind<add>} %4, %5, %6 : vector<1x4xf32>, vector<4x1xf32> into vector<1x1xf32>
  vector.transfer_write %7, %subview[%c0, %c0] {in_bounds = [true, true]} : vector<1x1xf32>, memref<1x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
module {
  func.func @main_dispatch_0_matmul_1x3x4_f32() {
    %c0 = arith.constant 0 : index
    %c64 = arith.constant 64 : index
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<1x4xf32, #hal.descriptor_type<storage_buffer>>
    memref.assume_alignment %0, 64 : memref<1x4xf32, #hal.descriptor_type<storage_buffer>>
    %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<4x3xf32, #hal.descriptor_type<storage_buffer>>
    memref.assume_alignment %1, 64 : memref<4x3xf32, #hal.descriptor_type<storage_buffer>>
    %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : memref<1x3xf32, strided<[3, 1], offset: 16>, #hal.descriptor_type<storage_buffer>>
    memref.assume_alignment %2, 64 : memref<1x3xf32, strided<[3, 1], offset: 16>, #hal.descriptor_type<storage_buffer>>
    %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<1x3xf32, #hal.descriptor_type<storage_buffer>>
    memref.assume_alignment %3, 64 : memref<1x3xf32, #hal.descriptor_type<storage_buffer>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %subview = memref.subview %3[0, %workgroup_id_x] [1, 1] [1, 1] : memref<1x3xf32, #hal.descriptor_type<storage_buffer>> to memref<1x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %subview_0 = memref.subview %1[0, %workgroup_id_x] [4, 1] [1, 1] : memref<4x3xf32, #hal.descriptor_type<storage_buffer>> to memref<4x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %4 = vector.transfer_read %0[%c0, %c0], %cst {in_bounds = [true, true]} : memref<1x4xf32, #hal.descriptor_type<storage_buffer>>, vector<1x4xf32>
    %5 = vector.transfer_read %subview_0[%c0, %c0], %cst {in_bounds = [true, true]} : memref<4x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<4x1xf32>
    %subview_1 = memref.subview %2[0, %workgroup_id_x] [1, 1] [1, 1] : memref<1x3xf32, strided<[3, 1], offset: 16>, #hal.descriptor_type<storage_buffer>> to memref<1x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %6 = vector.transfer_read %subview_1[%c0, %c0], %cst {in_bounds = [true, true]} : memref<1x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<1x1xf32>
    %7 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"], kind = #vector.kind<add>} %4, %5, %6 : vector<1x4xf32>, vector<4x1xf32> into vector<1x1xf32>
    vector.transfer_write %7, %subview[%c0, %c0] {in_bounds = [true, true]} : vector<1x1xf32>, memref<1x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    return
  }
}

// -----// IR Dump After CSE (cse) //----- //
module {
  func.func @main_dispatch_0_matmul_1x3x4_f32() {
    %c0 = arith.constant 0 : index
    %c64 = arith.constant 64 : index
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<1x4xf32, #hal.descriptor_type<storage_buffer>>
    memref.assume_alignment %0, 64 : memref<1x4xf32, #hal.descriptor_type<storage_buffer>>
    %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<4x3xf32, #hal.descriptor_type<storage_buffer>>
    memref.assume_alignment %1, 64 : memref<4x3xf32, #hal.descriptor_type<storage_buffer>>
    %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : memref<1x3xf32, strided<[3, 1], offset: 16>, #hal.descriptor_type<storage_buffer>>
    memref.assume_alignment %2, 64 : memref<1x3xf32, strided<[3, 1], offset: 16>, #hal.descriptor_type<storage_buffer>>
    %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<1x3xf32, #hal.descriptor_type<storage_buffer>>
    memref.assume_alignment %3, 64 : memref<1x3xf32, #hal.descriptor_type<storage_buffer>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %subview = memref.subview %3[0, %workgroup_id_x] [1, 1] [1, 1] : memref<1x3xf32, #hal.descriptor_type<storage_buffer>> to memref<1x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %subview_0 = memref.subview %1[0, %workgroup_id_x] [4, 1] [1, 1] : memref<4x3xf32, #hal.descriptor_type<storage_buffer>> to memref<4x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %4 = vector.transfer_read %0[%c0, %c0], %cst {in_bounds = [true, true]} : memref<1x4xf32, #hal.descriptor_type<storage_buffer>>, vector<1x4xf32>
    %5 = vector.transfer_read %subview_0[%c0, %c0], %cst {in_bounds = [true, true]} : memref<4x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<4x1xf32>
    %subview_1 = memref.subview %2[0, %workgroup_id_x] [1, 1] [1, 1] : memref<1x3xf32, strided<[3, 1], offset: 16>, #hal.descriptor_type<storage_buffer>> to memref<1x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %6 = vector.transfer_read %subview_1[%c0, %c0], %cst {in_bounds = [true, true]} : memref<1x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<1x1xf32>
    %7 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"], kind = #vector.kind<add>} %4, %5, %6 : vector<1x4xf32>, vector<4x1xf32> into vector<1x1xf32>
    vector.transfer_write %7, %subview[%c0, %c0] {in_bounds = [true, true]} : vector<1x1xf32>, memref<1x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    return
  }
}

// -----// IR Dump After GPUDistribute (iree-codegen-gpu-distribute) //----- //
func.func @main_dispatch_0_matmul_1x3x4_f32() {
  %c0 = arith.constant 0 : index
  %c0_0 = arith.constant 0 : index
  %c64 = arith.constant 64 : index
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0_0) flags(ReadOnly) : memref<1x4xf32, #hal.descriptor_type<storage_buffer>>
  memref.assume_alignment %0, 64 : memref<1x4xf32, #hal.descriptor_type<storage_buffer>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0_0) flags(ReadOnly) : memref<4x3xf32, #hal.descriptor_type<storage_buffer>>
  memref.assume_alignment %1, 64 : memref<4x3xf32, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : memref<1x3xf32, strided<[3, 1], offset: 16>, #hal.descriptor_type<storage_buffer>>
  memref.assume_alignment %2, 64 : memref<1x3xf32, strided<[3, 1], offset: 16>, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0_0) : memref<1x3xf32, #hal.descriptor_type<storage_buffer>>
  memref.assume_alignment %3, 64 : memref<1x3xf32, #hal.descriptor_type<storage_buffer>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %subview = memref.subview %3[0, %workgroup_id_x] [1, 1] [1, 1] : memref<1x3xf32, #hal.descriptor_type<storage_buffer>> to memref<1x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %subview_1 = memref.subview %1[0, %workgroup_id_x] [4, 1] [1, 1] : memref<4x3xf32, #hal.descriptor_type<storage_buffer>> to memref<4x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %4 = vector.transfer_read %0[%c0_0, %c0_0], %cst {in_bounds = [true, true]} : memref<1x4xf32, #hal.descriptor_type<storage_buffer>>, vector<1x4xf32>
  %5 = vector.transfer_read %subview_1[%c0_0, %c0_0], %cst {in_bounds = [true, true]} : memref<4x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<4x1xf32>
  %subview_2 = memref.subview %2[0, %workgroup_id_x] [1, 1] [1, 1] : memref<1x3xf32, strided<[3, 1], offset: 16>, #hal.descriptor_type<storage_buffer>> to memref<1x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %6 = vector.transfer_read %subview_2[%c0_0, %c0_0], %cst {in_bounds = [true, true]} : memref<1x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<1x1xf32>
  %7 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"], kind = #vector.kind<add>} %4, %5, %6 : vector<1x4xf32>, vector<4x1xf32> into vector<1x1xf32>
  vector.transfer_write %7, %subview[%c0_0, %c0_0] {in_bounds = [true, true]} : vector<1x1xf32>, memref<1x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After MemrefCopyToLinalgPass (iree-codegen-memrefcopy-to-linalg) //----- //
func.func @main_dispatch_0_matmul_1x3x4_f32() {
  %c0 = arith.constant 0 : index
  %c64 = arith.constant 64 : index
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<1x4xf32, #hal.descriptor_type<storage_buffer>>
  memref.assume_alignment %0, 64 : memref<1x4xf32, #hal.descriptor_type<storage_buffer>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<4x3xf32, #hal.descriptor_type<storage_buffer>>
  memref.assume_alignment %1, 64 : memref<4x3xf32, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : memref<1x3xf32, strided<[3, 1], offset: 16>, #hal.descriptor_type<storage_buffer>>
  memref.assume_alignment %2, 64 : memref<1x3xf32, strided<[3, 1], offset: 16>, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<1x3xf32, #hal.descriptor_type<storage_buffer>>
  memref.assume_alignment %3, 64 : memref<1x3xf32, #hal.descriptor_type<storage_buffer>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %subview = memref.subview %3[0, %workgroup_id_x] [1, 1] [1, 1] : memref<1x3xf32, #hal.descriptor_type<storage_buffer>> to memref<1x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %subview_0 = memref.subview %1[0, %workgroup_id_x] [4, 1] [1, 1] : memref<4x3xf32, #hal.descriptor_type<storage_buffer>> to memref<4x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %4 = vector.transfer_read %0[%c0, %c0], %cst {in_bounds = [true, true]} : memref<1x4xf32, #hal.descriptor_type<storage_buffer>>, vector<1x4xf32>
  %5 = vector.transfer_read %subview_0[%c0, %c0], %cst {in_bounds = [true, true]} : memref<4x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<4x1xf32>
  %subview_1 = memref.subview %2[0, %workgroup_id_x] [1, 1] [1, 1] : memref<1x3xf32, strided<[3, 1], offset: 16>, #hal.descriptor_type<storage_buffer>> to memref<1x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %6 = vector.transfer_read %subview_1[%c0, %c0], %cst {in_bounds = [true, true]} : memref<1x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<1x1xf32>
  %7 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"], kind = #vector.kind<add>} %4, %5, %6 : vector<1x4xf32>, vector<4x1xf32> into vector<1x1xf32>
  vector.transfer_write %7, %subview[%c0, %c0] {in_bounds = [true, true]} : vector<1x1xf32>, memref<1x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After GPUDistributeSharedMemoryCopy (iree-codegen-gpu-distribute-shared-memory-copy) //----- //
func.func @main_dispatch_0_matmul_1x3x4_f32() {
  %c0 = arith.constant 0 : index
  %c64 = arith.constant 64 : index
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<1x4xf32, #hal.descriptor_type<storage_buffer>>
  memref.assume_alignment %0, 64 : memref<1x4xf32, #hal.descriptor_type<storage_buffer>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<4x3xf32, #hal.descriptor_type<storage_buffer>>
  memref.assume_alignment %1, 64 : memref<4x3xf32, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : memref<1x3xf32, strided<[3, 1], offset: 16>, #hal.descriptor_type<storage_buffer>>
  memref.assume_alignment %2, 64 : memref<1x3xf32, strided<[3, 1], offset: 16>, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<1x3xf32, #hal.descriptor_type<storage_buffer>>
  memref.assume_alignment %3, 64 : memref<1x3xf32, #hal.descriptor_type<storage_buffer>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %subview = memref.subview %3[0, %workgroup_id_x] [1, 1] [1, 1] : memref<1x3xf32, #hal.descriptor_type<storage_buffer>> to memref<1x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %subview_0 = memref.subview %1[0, %workgroup_id_x] [4, 1] [1, 1] : memref<4x3xf32, #hal.descriptor_type<storage_buffer>> to memref<4x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %4 = vector.transfer_read %0[%c0, %c0], %cst {in_bounds = [true, true]} : memref<1x4xf32, #hal.descriptor_type<storage_buffer>>, vector<1x4xf32>
  %5 = vector.transfer_read %subview_0[%c0, %c0], %cst {in_bounds = [true, true]} : memref<4x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<4x1xf32>
  %subview_1 = memref.subview %2[0, %workgroup_id_x] [1, 1] [1, 1] : memref<1x3xf32, strided<[3, 1], offset: 16>, #hal.descriptor_type<storage_buffer>> to memref<1x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %6 = vector.transfer_read %subview_1[%c0, %c0], %cst {in_bounds = [true, true]} : memref<1x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<1x1xf32>
  %7 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"], kind = #vector.kind<add>} %4, %5, %6 : vector<1x4xf32>, vector<4x1xf32> into vector<1x1xf32>
  vector.transfer_write %7, %subview[%c0, %c0] {in_bounds = [true, true]} : vector<1x1xf32>, memref<1x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
module {
  func.func @main_dispatch_0_matmul_1x3x4_f32() {
    %c0 = arith.constant 0 : index
    %c64 = arith.constant 64 : index
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<1x4xf32, #hal.descriptor_type<storage_buffer>>
    memref.assume_alignment %0, 64 : memref<1x4xf32, #hal.descriptor_type<storage_buffer>>
    %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<4x3xf32, #hal.descriptor_type<storage_buffer>>
    memref.assume_alignment %1, 64 : memref<4x3xf32, #hal.descriptor_type<storage_buffer>>
    %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : memref<1x3xf32, strided<[3, 1], offset: 16>, #hal.descriptor_type<storage_buffer>>
    memref.assume_alignment %2, 64 : memref<1x3xf32, strided<[3, 1], offset: 16>, #hal.descriptor_type<storage_buffer>>
    %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<1x3xf32, #hal.descriptor_type<storage_buffer>>
    memref.assume_alignment %3, 64 : memref<1x3xf32, #hal.descriptor_type<storage_buffer>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %subview = memref.subview %3[0, %workgroup_id_x] [1, 1] [1, 1] : memref<1x3xf32, #hal.descriptor_type<storage_buffer>> to memref<1x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %subview_0 = memref.subview %1[0, %workgroup_id_x] [4, 1] [1, 1] : memref<4x3xf32, #hal.descriptor_type<storage_buffer>> to memref<4x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %4 = vector.transfer_read %0[%c0, %c0], %cst {in_bounds = [true, true]} : memref<1x4xf32, #hal.descriptor_type<storage_buffer>>, vector<1x4xf32>
    %5 = vector.transfer_read %subview_0[%c0, %c0], %cst {in_bounds = [true, true]} : memref<4x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<4x1xf32>
    %subview_1 = memref.subview %2[0, %workgroup_id_x] [1, 1] [1, 1] : memref<1x3xf32, strided<[3, 1], offset: 16>, #hal.descriptor_type<storage_buffer>> to memref<1x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %6 = vector.transfer_read %subview_1[%c0, %c0], %cst {in_bounds = [true, true]} : memref<1x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<1x1xf32>
    %7 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"], kind = #vector.kind<add>} %4, %5, %6 : vector<1x4xf32>, vector<4x1xf32> into vector<1x1xf32>
    vector.transfer_write %7, %subview[%c0, %c0] {in_bounds = [true, true]} : vector<1x1xf32>, memref<1x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    return
  }
}

// -----// IR Dump After CSE (cse) //----- //
module {
  func.func @main_dispatch_0_matmul_1x3x4_f32() {
    %c0 = arith.constant 0 : index
    %c64 = arith.constant 64 : index
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<1x4xf32, #hal.descriptor_type<storage_buffer>>
    memref.assume_alignment %0, 64 : memref<1x4xf32, #hal.descriptor_type<storage_buffer>>
    %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<4x3xf32, #hal.descriptor_type<storage_buffer>>
    memref.assume_alignment %1, 64 : memref<4x3xf32, #hal.descriptor_type<storage_buffer>>
    %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : memref<1x3xf32, strided<[3, 1], offset: 16>, #hal.descriptor_type<storage_buffer>>
    memref.assume_alignment %2, 64 : memref<1x3xf32, strided<[3, 1], offset: 16>, #hal.descriptor_type<storage_buffer>>
    %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<1x3xf32, #hal.descriptor_type<storage_buffer>>
    memref.assume_alignment %3, 64 : memref<1x3xf32, #hal.descriptor_type<storage_buffer>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %subview = memref.subview %3[0, %workgroup_id_x] [1, 1] [1, 1] : memref<1x3xf32, #hal.descriptor_type<storage_buffer>> to memref<1x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %subview_0 = memref.subview %1[0, %workgroup_id_x] [4, 1] [1, 1] : memref<4x3xf32, #hal.descriptor_type<storage_buffer>> to memref<4x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %4 = vector.transfer_read %0[%c0, %c0], %cst {in_bounds = [true, true]} : memref<1x4xf32, #hal.descriptor_type<storage_buffer>>, vector<1x4xf32>
    %5 = vector.transfer_read %subview_0[%c0, %c0], %cst {in_bounds = [true, true]} : memref<4x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<4x1xf32>
    %subview_1 = memref.subview %2[0, %workgroup_id_x] [1, 1] [1, 1] : memref<1x3xf32, strided<[3, 1], offset: 16>, #hal.descriptor_type<storage_buffer>> to memref<1x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %6 = vector.transfer_read %subview_1[%c0, %c0], %cst {in_bounds = [true, true]} : memref<1x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<1x1xf32>
    %7 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"], kind = #vector.kind<add>} %4, %5, %6 : vector<1x4xf32>, vector<4x1xf32> into vector<1x1xf32>
    vector.transfer_write %7, %subview[%c0, %c0] {in_bounds = [true, true]} : vector<1x1xf32>, memref<1x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    return
  }
}

// -----// IR Dump After GPUReduceBankConflicts (iree-codegen-gpu-reduce-bank-conflicts) //----- //
func.func @main_dispatch_0_matmul_1x3x4_f32() {
  %c0 = arith.constant 0 : index
  %c64 = arith.constant 64 : index
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<1x4xf32, #hal.descriptor_type<storage_buffer>>
  memref.assume_alignment %0, 64 : memref<1x4xf32, #hal.descriptor_type<storage_buffer>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<4x3xf32, #hal.descriptor_type<storage_buffer>>
  memref.assume_alignment %1, 64 : memref<4x3xf32, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : memref<1x3xf32, strided<[3, 1], offset: 16>, #hal.descriptor_type<storage_buffer>>
  memref.assume_alignment %2, 64 : memref<1x3xf32, strided<[3, 1], offset: 16>, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<1x3xf32, #hal.descriptor_type<storage_buffer>>
  memref.assume_alignment %3, 64 : memref<1x3xf32, #hal.descriptor_type<storage_buffer>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %subview = memref.subview %3[0, %workgroup_id_x] [1, 1] [1, 1] : memref<1x3xf32, #hal.descriptor_type<storage_buffer>> to memref<1x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %subview_0 = memref.subview %1[0, %workgroup_id_x] [4, 1] [1, 1] : memref<4x3xf32, #hal.descriptor_type<storage_buffer>> to memref<4x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %4 = vector.transfer_read %0[%c0, %c0], %cst {in_bounds = [true, true]} : memref<1x4xf32, #hal.descriptor_type<storage_buffer>>, vector<1x4xf32>
  %5 = vector.transfer_read %subview_0[%c0, %c0], %cst {in_bounds = [true, true]} : memref<4x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<4x1xf32>
  %subview_1 = memref.subview %2[0, %workgroup_id_x] [1, 1] [1, 1] : memref<1x3xf32, strided<[3, 1], offset: 16>, #hal.descriptor_type<storage_buffer>> to memref<1x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %6 = vector.transfer_read %subview_1[%c0, %c0], %cst {in_bounds = [true, true]} : memref<1x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<1x1xf32>
  %7 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"], kind = #vector.kind<add>} %4, %5, %6 : vector<1x4xf32>, vector<4x1xf32> into vector<1x1xf32>
  vector.transfer_write %7, %subview[%c0, %c0] {in_bounds = [true, true]} : vector<1x1xf32>, memref<1x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After WorkGroupSwizzle (iree-workgroup-swizzle) //----- //
func.func @main_dispatch_0_matmul_1x3x4_f32() {
  %c0 = arith.constant 0 : index
  %c64 = arith.constant 64 : index
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<1x4xf32, #hal.descriptor_type<storage_buffer>>
  memref.assume_alignment %0, 64 : memref<1x4xf32, #hal.descriptor_type<storage_buffer>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<4x3xf32, #hal.descriptor_type<storage_buffer>>
  memref.assume_alignment %1, 64 : memref<4x3xf32, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : memref<1x3xf32, strided<[3, 1], offset: 16>, #hal.descriptor_type<storage_buffer>>
  memref.assume_alignment %2, 64 : memref<1x3xf32, strided<[3, 1], offset: 16>, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<1x3xf32, #hal.descriptor_type<storage_buffer>>
  memref.assume_alignment %3, 64 : memref<1x3xf32, #hal.descriptor_type<storage_buffer>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %subview = memref.subview %3[0, %workgroup_id_x] [1, 1] [1, 1] : memref<1x3xf32, #hal.descriptor_type<storage_buffer>> to memref<1x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %subview_0 = memref.subview %1[0, %workgroup_id_x] [4, 1] [1, 1] : memref<4x3xf32, #hal.descriptor_type<storage_buffer>> to memref<4x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %4 = vector.transfer_read %0[%c0, %c0], %cst {in_bounds = [true, true]} : memref<1x4xf32, #hal.descriptor_type<storage_buffer>>, vector<1x4xf32>
  %5 = vector.transfer_read %subview_0[%c0, %c0], %cst {in_bounds = [true, true]} : memref<4x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<4x1xf32>
  %subview_1 = memref.subview %2[0, %workgroup_id_x] [1, 1] [1, 1] : memref<1x3xf32, strided<[3, 1], offset: 16>, #hal.descriptor_type<storage_buffer>> to memref<1x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %6 = vector.transfer_read %subview_1[%c0, %c0], %cst {in_bounds = [true, true]} : memref<1x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<1x1xf32>
  %7 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"], kind = #vector.kind<add>} %4, %5, %6 : vector<1x4xf32>, vector<4x1xf32> into vector<1x1xf32>
  vector.transfer_write %7, %subview[%c0, %c0] {in_bounds = [true, true]} : vector<1x1xf32>, memref<1x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
module {
  func.func @main_dispatch_0_matmul_1x3x4_f32() {
    %c0 = arith.constant 0 : index
    %c64 = arith.constant 64 : index
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<1x4xf32, #hal.descriptor_type<storage_buffer>>
    memref.assume_alignment %0, 64 : memref<1x4xf32, #hal.descriptor_type<storage_buffer>>
    %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<4x3xf32, #hal.descriptor_type<storage_buffer>>
    memref.assume_alignment %1, 64 : memref<4x3xf32, #hal.descriptor_type<storage_buffer>>
    %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : memref<1x3xf32, strided<[3, 1], offset: 16>, #hal.descriptor_type<storage_buffer>>
    memref.assume_alignment %2, 64 : memref<1x3xf32, strided<[3, 1], offset: 16>, #hal.descriptor_type<storage_buffer>>
    %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<1x3xf32, #hal.descriptor_type<storage_buffer>>
    memref.assume_alignment %3, 64 : memref<1x3xf32, #hal.descriptor_type<storage_buffer>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %subview = memref.subview %3[0, %workgroup_id_x] [1, 1] [1, 1] : memref<1x3xf32, #hal.descriptor_type<storage_buffer>> to memref<1x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %subview_0 = memref.subview %1[0, %workgroup_id_x] [4, 1] [1, 1] : memref<4x3xf32, #hal.descriptor_type<storage_buffer>> to memref<4x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %4 = vector.transfer_read %0[%c0, %c0], %cst {in_bounds = [true, true]} : memref<1x4xf32, #hal.descriptor_type<storage_buffer>>, vector<1x4xf32>
    %5 = vector.transfer_read %subview_0[%c0, %c0], %cst {in_bounds = [true, true]} : memref<4x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<4x1xf32>
    %subview_1 = memref.subview %2[0, %workgroup_id_x] [1, 1] [1, 1] : memref<1x3xf32, strided<[3, 1], offset: 16>, #hal.descriptor_type<storage_buffer>> to memref<1x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %6 = vector.transfer_read %subview_1[%c0, %c0], %cst {in_bounds = [true, true]} : memref<1x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<1x1xf32>
    %7 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"], kind = #vector.kind<add>} %4, %5, %6 : vector<1x4xf32>, vector<4x1xf32> into vector<1x1xf32>
    vector.transfer_write %7, %subview[%c0, %c0] {in_bounds = [true, true]} : vector<1x1xf32>, memref<1x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    return
  }
}

// -----// IR Dump After CSE (cse) //----- //
module {
  func.func @main_dispatch_0_matmul_1x3x4_f32() {
    %c0 = arith.constant 0 : index
    %c64 = arith.constant 64 : index
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<1x4xf32, #hal.descriptor_type<storage_buffer>>
    memref.assume_alignment %0, 64 : memref<1x4xf32, #hal.descriptor_type<storage_buffer>>
    %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<4x3xf32, #hal.descriptor_type<storage_buffer>>
    memref.assume_alignment %1, 64 : memref<4x3xf32, #hal.descriptor_type<storage_buffer>>
    %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : memref<1x3xf32, strided<[3, 1], offset: 16>, #hal.descriptor_type<storage_buffer>>
    memref.assume_alignment %2, 64 : memref<1x3xf32, strided<[3, 1], offset: 16>, #hal.descriptor_type<storage_buffer>>
    %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<1x3xf32, #hal.descriptor_type<storage_buffer>>
    memref.assume_alignment %3, 64 : memref<1x3xf32, #hal.descriptor_type<storage_buffer>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %subview = memref.subview %3[0, %workgroup_id_x] [1, 1] [1, 1] : memref<1x3xf32, #hal.descriptor_type<storage_buffer>> to memref<1x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %subview_0 = memref.subview %1[0, %workgroup_id_x] [4, 1] [1, 1] : memref<4x3xf32, #hal.descriptor_type<storage_buffer>> to memref<4x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %4 = vector.transfer_read %0[%c0, %c0], %cst {in_bounds = [true, true]} : memref<1x4xf32, #hal.descriptor_type<storage_buffer>>, vector<1x4xf32>
    %5 = vector.transfer_read %subview_0[%c0, %c0], %cst {in_bounds = [true, true]} : memref<4x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<4x1xf32>
    %subview_1 = memref.subview %2[0, %workgroup_id_x] [1, 1] [1, 1] : memref<1x3xf32, strided<[3, 1], offset: 16>, #hal.descriptor_type<storage_buffer>> to memref<1x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %6 = vector.transfer_read %subview_1[%c0, %c0], %cst {in_bounds = [true, true]} : memref<1x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, vector<1x1xf32>
    %7 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"], kind = #vector.kind<add>} %4, %5, %6 : vector<1x4xf32>, vector<4x1xf32> into vector<1x1xf32>
    vector.transfer_write %7, %subview[%c0, %c0] {in_bounds = [true, true]} : vector<1x1xf32>, memref<1x1xf32, strided<[3, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    return
  }
}

// -----// IR Dump After FoldMemRefAliasOps (fold-memref-alias-ops) //----- //
func.func @main_dispatch_0_matmul_1x3x4_f32() {
  %c0 = arith.constant 0 : index
  %c64 = arith.constant 64 : index
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<1x4xf32, #hal.descriptor_type<storage_buffer>>
  memref.assume_alignment %0, 64 : memref<1x4xf32, #hal.descriptor_type<storage_buffer>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<4x3xf32, #hal.descriptor_type<storage_buffer>>
  memref.assume_alignment %1, 64 : memref<4x3xf32, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : memref<1x3xf32, strided<[3, 1], offset: 16>, #hal.descriptor_type<storage_buffer>>
  memref.assume_alignment %2, 64 : memref<1x3xf32, strided<[3, 1], offset: 16>, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<1x3xf32, #hal.descriptor_type<storage_buffer>>
  memref.assume_alignment %3, 64 : memref<1x3xf32, #hal.descriptor_type<storage_buffer>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %4 = vector.transfer_read %0[%c0, %c0], %cst {in_bounds = [true, true]} : memref<1x4xf32, #hal.descriptor_type<storage_buffer>>, vector<1x4xf32>
  %5 = vector.transfer_read %1[%c0, %workgroup_id_x], %cst {in_bounds = [true, true]} : memref<4x3xf32, #hal.descriptor_type<storage_buffer>>, vector<4x1xf32>
  %6 = vector.transfer_read %2[%c0, %workgroup_id_x], %cst {in_bounds = [true, true]} : memref<1x3xf32, strided<[3, 1], offset: 16>, #hal.descriptor_type<storage_buffer>>, vector<1x1xf32>
  %7 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"], kind = #vector.kind<add>} %4, %5, %6 : vector<1x4xf32>, vector<4x1xf32> into vector<1x1xf32>
  vector.transfer_write %7, %3[%c0, %workgroup_id_x] {in_bounds = [true, true]} : vector<1x1xf32>, memref<1x3xf32, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After CSE (cse) //----- //
module {
  func.func @main_dispatch_0_matmul_1x3x4_f32() {
    %c0 = arith.constant 0 : index
    %c64 = arith.constant 64 : index
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<1x4xf32, #hal.descriptor_type<storage_buffer>>
    memref.assume_alignment %0, 64 : memref<1x4xf32, #hal.descriptor_type<storage_buffer>>
    %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<4x3xf32, #hal.descriptor_type<storage_buffer>>
    memref.assume_alignment %1, 64 : memref<4x3xf32, #hal.descriptor_type<storage_buffer>>
    %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : memref<1x3xf32, strided<[3, 1], offset: 16>, #hal.descriptor_type<storage_buffer>>
    memref.assume_alignment %2, 64 : memref<1x3xf32, strided<[3, 1], offset: 16>, #hal.descriptor_type<storage_buffer>>
    %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<1x3xf32, #hal.descriptor_type<storage_buffer>>
    memref.assume_alignment %3, 64 : memref<1x3xf32, #hal.descriptor_type<storage_buffer>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %4 = vector.transfer_read %0[%c0, %c0], %cst {in_bounds = [true, true]} : memref<1x4xf32, #hal.descriptor_type<storage_buffer>>, vector<1x4xf32>
    %5 = vector.transfer_read %1[%c0, %workgroup_id_x], %cst {in_bounds = [true, true]} : memref<4x3xf32, #hal.descriptor_type<storage_buffer>>, vector<4x1xf32>
    %6 = vector.transfer_read %2[%c0, %workgroup_id_x], %cst {in_bounds = [true, true]} : memref<1x3xf32, strided<[3, 1], offset: 16>, #hal.descriptor_type<storage_buffer>>, vector<1x1xf32>
    %7 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"], kind = #vector.kind<add>} %4, %5, %6 : vector<1x4xf32>, vector<4x1xf32> into vector<1x1xf32>
    vector.transfer_write %7, %3[%c0, %workgroup_id_x] {in_bounds = [true, true]} : vector<1x1xf32>, memref<1x3xf32, #hal.descriptor_type<storage_buffer>>
    return
  }
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
module {
  func.func @main_dispatch_0_matmul_1x3x4_f32() {
    %c0 = arith.constant 0 : index
    %c64 = arith.constant 64 : index
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<1x4xf32, #hal.descriptor_type<storage_buffer>>
    memref.assume_alignment %0, 64 : memref<1x4xf32, #hal.descriptor_type<storage_buffer>>
    %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<4x3xf32, #hal.descriptor_type<storage_buffer>>
    memref.assume_alignment %1, 64 : memref<4x3xf32, #hal.descriptor_type<storage_buffer>>
    %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : memref<1x3xf32, strided<[3, 1], offset: 16>, #hal.descriptor_type<storage_buffer>>
    memref.assume_alignment %2, 64 : memref<1x3xf32, strided<[3, 1], offset: 16>, #hal.descriptor_type<storage_buffer>>
    %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<1x3xf32, #hal.descriptor_type<storage_buffer>>
    memref.assume_alignment %3, 64 : memref<1x3xf32, #hal.descriptor_type<storage_buffer>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %4 = vector.transfer_read %0[%c0, %c0], %cst {in_bounds = [true, true]} : memref<1x4xf32, #hal.descriptor_type<storage_buffer>>, vector<1x4xf32>
    %5 = vector.transfer_read %1[%c0, %workgroup_id_x], %cst {in_bounds = [true, true]} : memref<4x3xf32, #hal.descriptor_type<storage_buffer>>, vector<4x1xf32>
    %6 = vector.transfer_read %2[%c0, %workgroup_id_x], %cst {in_bounds = [true, true]} : memref<1x3xf32, strided<[3, 1], offset: 16>, #hal.descriptor_type<storage_buffer>>, vector<1x1xf32>
    %7 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"], kind = #vector.kind<add>} %4, %5, %6 : vector<1x4xf32>, vector<4x1xf32> into vector<1x1xf32>
    vector.transfer_write %7, %3[%c0, %workgroup_id_x] {in_bounds = [true, true]} : vector<1x1xf32>, memref<1x3xf32, #hal.descriptor_type<storage_buffer>>
    return
  }
}

// -----// IR Dump After CSE (cse) //----- //
module {
  func.func @main_dispatch_0_matmul_1x3x4_f32() {
    %c0 = arith.constant 0 : index
    %c64 = arith.constant 64 : index
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<1x4xf32, #hal.descriptor_type<storage_buffer>>
    memref.assume_alignment %0, 64 : memref<1x4xf32, #hal.descriptor_type<storage_buffer>>
    %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<4x3xf32, #hal.descriptor_type<storage_buffer>>
    memref.assume_alignment %1, 64 : memref<4x3xf32, #hal.descriptor_type<storage_buffer>>
    %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : memref<1x3xf32, strided<[3, 1], offset: 16>, #hal.descriptor_type<storage_buffer>>
    memref.assume_alignment %2, 64 : memref<1x3xf32, strided<[3, 1], offset: 16>, #hal.descriptor_type<storage_buffer>>
    %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<1x3xf32, #hal.descriptor_type<storage_buffer>>
    memref.assume_alignment %3, 64 : memref<1x3xf32, #hal.descriptor_type<storage_buffer>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %4 = vector.transfer_read %0[%c0, %c0], %cst {in_bounds = [true, true]} : memref<1x4xf32, #hal.descriptor_type<storage_buffer>>, vector<1x4xf32>
    %5 = vector.transfer_read %1[%c0, %workgroup_id_x], %cst {in_bounds = [true, true]} : memref<4x3xf32, #hal.descriptor_type<storage_buffer>>, vector<4x1xf32>
    %6 = vector.transfer_read %2[%c0, %workgroup_id_x], %cst {in_bounds = [true, true]} : memref<1x3xf32, strided<[3, 1], offset: 16>, #hal.descriptor_type<storage_buffer>>, vector<1x1xf32>
    %7 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"], kind = #vector.kind<add>} %4, %5, %6 : vector<1x4xf32>, vector<4x1xf32> into vector<1x1xf32>
    vector.transfer_write %7, %3[%c0, %workgroup_id_x] {in_bounds = [true, true]} : vector<1x1xf32>, memref<1x3xf32, #hal.descriptor_type<storage_buffer>>
    return
  }
}

// -----// IR Dump After HoistRedundantVectorTransfers (iree-codegen-hoist-redundant-vector-transfers) //----- //
func.func @main_dispatch_0_matmul_1x3x4_f32() {
  %c0 = arith.constant 0 : index
  %c64 = arith.constant 64 : index
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<1x4xf32, #hal.descriptor_type<storage_buffer>>
  memref.assume_alignment %0, 64 : memref<1x4xf32, #hal.descriptor_type<storage_buffer>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<4x3xf32, #hal.descriptor_type<storage_buffer>>
  memref.assume_alignment %1, 64 : memref<4x3xf32, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : memref<1x3xf32, strided<[3, 1], offset: 16>, #hal.descriptor_type<storage_buffer>>
  memref.assume_alignment %2, 64 : memref<1x3xf32, strided<[3, 1], offset: 16>, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<1x3xf32, #hal.descriptor_type<storage_buffer>>
  memref.assume_alignment %3, 64 : memref<1x3xf32, #hal.descriptor_type<storage_buffer>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %4 = vector.transfer_read %0[%c0, %c0], %cst {in_bounds = [true, true]} : memref<1x4xf32, #hal.descriptor_type<storage_buffer>>, vector<1x4xf32>
  %5 = vector.transfer_read %1[%c0, %workgroup_id_x], %cst {in_bounds = [true, true]} : memref<4x3xf32, #hal.descriptor_type<storage_buffer>>, vector<4x1xf32>
  %6 = vector.transfer_read %2[%c0, %workgroup_id_x], %cst {in_bounds = [true, true]} : memref<1x3xf32, strided<[3, 1], offset: 16>, #hal.descriptor_type<storage_buffer>>, vector<1x1xf32>
  %7 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"], kind = #vector.kind<add>} %4, %5, %6 : vector<1x4xf32>, vector<4x1xf32> into vector<1x1xf32>
  vector.transfer_write %7, %3[%c0, %workgroup_id_x] {in_bounds = [true, true]} : vector<1x1xf32>, memref<1x3xf32, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After LoopInvariantCodeMotion (loop-invariant-code-motion) //----- //
func.func @main_dispatch_0_matmul_1x3x4_f32() {
  %c0 = arith.constant 0 : index
  %c64 = arith.constant 64 : index
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<1x4xf32, #hal.descriptor_type<storage_buffer>>
  memref.assume_alignment %0, 64 : memref<1x4xf32, #hal.descriptor_type<storage_buffer>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<4x3xf32, #hal.descriptor_type<storage_buffer>>
  memref.assume_alignment %1, 64 : memref<4x3xf32, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : memref<1x3xf32, strided<[3, 1], offset: 16>, #hal.descriptor_type<storage_buffer>>
  memref.assume_alignment %2, 64 : memref<1x3xf32, strided<[3, 1], offset: 16>, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<1x3xf32, #hal.descriptor_type<storage_buffer>>
  memref.assume_alignment %3, 64 : memref<1x3xf32, #hal.descriptor_type<storage_buffer>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %4 = vector.transfer_read %0[%c0, %c0], %cst {in_bounds = [true, true]} : memref<1x4xf32, #hal.descriptor_type<storage_buffer>>, vector<1x4xf32>
  %5 = vector.transfer_read %1[%c0, %workgroup_id_x], %cst {in_bounds = [true, true]} : memref<4x3xf32, #hal.descriptor_type<storage_buffer>>, vector<4x1xf32>
  %6 = vector.transfer_read %2[%c0, %workgroup_id_x], %cst {in_bounds = [true, true]} : memref<1x3xf32, strided<[3, 1], offset: 16>, #hal.descriptor_type<storage_buffer>>, vector<1x1xf32>
  %7 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"], kind = #vector.kind<add>} %4, %5, %6 : vector<1x4xf32>, vector<4x1xf32> into vector<1x1xf32>
  vector.transfer_write %7, %3[%c0, %workgroup_id_x] {in_bounds = [true, true]} : vector<1x1xf32>, memref<1x3xf32, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After GPUPipelining (iree-codegen-gpu-pipelining) //----- //
func.func @main_dispatch_0_matmul_1x3x4_f32() {
  %c0 = arith.constant 0 : index
  %c64 = arith.constant 64 : index
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<1x4xf32, #hal.descriptor_type<storage_buffer>>
  memref.assume_alignment %0, 64 : memref<1x4xf32, #hal.descriptor_type<storage_buffer>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<4x3xf32, #hal.descriptor_type<storage_buffer>>
  memref.assume_alignment %1, 64 : memref<4x3xf32, #hal.descriptor_type<storage_buffer>>
  %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : memref<1x3xf32, strided<[3, 1], offset: 16>, #hal.descriptor_type<storage_buffer>>
  memref.assume_alignment %2, 64 : memref<1x3xf32, strided<[3, 1], offset: 16>, #hal.descriptor_type<storage_buffer>>
  %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<1x3xf32, #hal.descriptor_type<storage_buffer>>
  memref.assume_alignment %3, 64 : memref<1x3xf32, #hal.descriptor_type<storage_buffer>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %4 = vector.transfer_read %0[%c0, %c0], %cst {in_bounds = [true, true]} : memref<1x4xf32, #hal.descriptor_type<storage_buffer>>, vector<1x4xf32>
  %5 = vector.transfer_read %1[%c0, %workgroup_id_x], %cst {in_bounds = [true, true]} : memref<4x3xf32, #hal.descriptor_type<storage_buffer>>, vector<4x1xf32>
  %6 = vector.transfer_read %2[%c0, %workgroup_id_x], %cst {in_bounds = [true, true]} : memref<1x3xf32, strided<[3, 1], offset: 16>, #hal.descriptor_type<storage_buffer>>, vector<1x1xf32>
  %7 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"], kind = #vector.kind<add>} %4, %5, %6 : vector<1x4xf32>, vector<4x1xf32> into vector<1x1xf32>
  vector.transfer_write %7, %3[%c0, %workgroup_id_x] {in_bounds = [true, true]} : vector<1x1xf32>, memref<1x3xf32, #hal.descriptor_type<storage_buffer>>
  return
}

// -----// IR Dump After LLVMGPULowerExecutableTarget (iree-llvmgpu-lower-executable-target) //----- //
hal.executable.variant public @cuda_nvptx_fb target(<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>) {
  hal.executable.export public @main_dispatch_0_matmul_1x3x4_f32 ordinal(0) layout(#hal.pipeline.layout<push_constants = 0, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>) attributes {translation_info = #iree_codegen.translation_info<LLVMGPUMatmulSimt>, workgroup_size = [1 : index, 3 : index, 1 : index]} {
  ^bb0(%arg0: !hal.device):
    %c3 = arith.constant 3 : index
    %c1 = arith.constant 1 : index
    hal.return %c3, %c1, %c1 : index, index, index
  }
  builtin.module {
    func.func @main_dispatch_0_matmul_1x3x4_f32() {
      %c0 = arith.constant 0 : index
      %c64 = arith.constant 64 : index
      %cst = arith.constant 0.000000e+00 : f32
      %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<1x4xf32, #hal.descriptor_type<storage_buffer>>
      memref.assume_alignment %0, 64 : memref<1x4xf32, #hal.descriptor_type<storage_buffer>>
      %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<4x3xf32, #hal.descriptor_type<storage_buffer>>
      memref.assume_alignment %1, 64 : memref<4x3xf32, #hal.descriptor_type<storage_buffer>>
      %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : memref<1x3xf32, strided<[3, 1], offset: 16>, #hal.descriptor_type<storage_buffer>>
      memref.assume_alignment %2, 64 : memref<1x3xf32, strided<[3, 1], offset: 16>, #hal.descriptor_type<storage_buffer>>
      %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<1x3xf32, #hal.descriptor_type<storage_buffer>>
      memref.assume_alignment %3, 64 : memref<1x3xf32, #hal.descriptor_type<storage_buffer>>
      %workgroup_id_x = hal.interface.workgroup.id[0] : index
      %4 = vector.transfer_read %0[%c0, %c0], %cst {in_bounds = [true, true]} : memref<1x4xf32, #hal.descriptor_type<storage_buffer>>, vector<1x4xf32>
      %5 = vector.transfer_read %1[%c0, %workgroup_id_x], %cst {in_bounds = [true, true]} : memref<4x3xf32, #hal.descriptor_type<storage_buffer>>, vector<4x1xf32>
      %6 = vector.transfer_read %2[%c0, %workgroup_id_x], %cst {in_bounds = [true, true]} : memref<1x3xf32, strided<[3, 1], offset: 16>, #hal.descriptor_type<storage_buffer>>, vector<1x1xf32>
      %7 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"], kind = #vector.kind<add>} %4, %5, %6 : vector<1x4xf32>, vector<4x1xf32> into vector<1x1xf32>
      vector.transfer_write %7, %3[%c0, %workgroup_id_x] {in_bounds = [true, true]} : vector<1x1xf32>, memref<1x3xf32, #hal.descriptor_type<storage_buffer>>
      return
    }
  }
}

// -----// IR Dump After ConvertHALDescriptorTypeToGPUAddressSpace (iree-codegen-convert-hal-descriptor-type-to-gpu-address-space) //----- //
module {
  func.func @main_dispatch_0_matmul_1x3x4_f32() {
    %c0 = arith.constant 0 : index
    %c64 = arith.constant 64 : index
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<1x4xf32, #gpu.address_space<global>>
    memref.assume_alignment %0, 64 : memref<1x4xf32, #gpu.address_space<global>>
    %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<4x3xf32, #gpu.address_space<global>>
    memref.assume_alignment %1, 64 : memref<4x3xf32, #gpu.address_space<global>>
    %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
    memref.assume_alignment %2, 64 : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
    %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<1x3xf32, #gpu.address_space<global>>
    memref.assume_alignment %3, 64 : memref<1x3xf32, #gpu.address_space<global>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %4 = vector.transfer_read %0[%c0, %c0], %cst {in_bounds = [true, true]} : memref<1x4xf32, #gpu.address_space<global>>, vector<1x4xf32>
    %5 = vector.transfer_read %1[%c0, %workgroup_id_x], %cst {in_bounds = [true, true]} : memref<4x3xf32, #gpu.address_space<global>>, vector<4x1xf32>
    %6 = vector.transfer_read %2[%c0, %workgroup_id_x], %cst {in_bounds = [true, true]} : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>, vector<1x1xf32>
    %7 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"], kind = #vector.kind<add>} %4, %5, %6 : vector<1x4xf32>, vector<4x1xf32> into vector<1x1xf32>
    vector.transfer_write %7, %3[%c0, %workgroup_id_x] {in_bounds = [true, true]} : vector<1x1xf32>, memref<1x3xf32, #gpu.address_space<global>>
    return
  }
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
module {
  func.func @main_dispatch_0_matmul_1x3x4_f32() {
    %c0 = arith.constant 0 : index
    %c64 = arith.constant 64 : index
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<1x4xf32, #gpu.address_space<global>>
    memref.assume_alignment %0, 64 : memref<1x4xf32, #gpu.address_space<global>>
    %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<4x3xf32, #gpu.address_space<global>>
    memref.assume_alignment %1, 64 : memref<4x3xf32, #gpu.address_space<global>>
    %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
    memref.assume_alignment %2, 64 : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
    %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<1x3xf32, #gpu.address_space<global>>
    memref.assume_alignment %3, 64 : memref<1x3xf32, #gpu.address_space<global>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %4 = vector.transfer_read %0[%c0, %c0], %cst {in_bounds = [true, true]} : memref<1x4xf32, #gpu.address_space<global>>, vector<1x4xf32>
    %5 = vector.transfer_read %1[%c0, %workgroup_id_x], %cst {in_bounds = [true, true]} : memref<4x3xf32, #gpu.address_space<global>>, vector<4x1xf32>
    %6 = vector.transfer_read %2[%c0, %workgroup_id_x], %cst {in_bounds = [true, true]} : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>, vector<1x1xf32>
    %7 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"], kind = #vector.kind<add>} %4, %5, %6 : vector<1x4xf32>, vector<4x1xf32> into vector<1x1xf32>
    vector.transfer_write %7, %3[%c0, %workgroup_id_x] {in_bounds = [true, true]} : vector<1x1xf32>, memref<1x3xf32, #gpu.address_space<global>>
    return
  }
}

// -----// IR Dump After CSE (cse) //----- //
module {
  func.func @main_dispatch_0_matmul_1x3x4_f32() {
    %c0 = arith.constant 0 : index
    %c64 = arith.constant 64 : index
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<1x4xf32, #gpu.address_space<global>>
    memref.assume_alignment %0, 64 : memref<1x4xf32, #gpu.address_space<global>>
    %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<4x3xf32, #gpu.address_space<global>>
    memref.assume_alignment %1, 64 : memref<4x3xf32, #gpu.address_space<global>>
    %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
    memref.assume_alignment %2, 64 : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
    %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<1x3xf32, #gpu.address_space<global>>
    memref.assume_alignment %3, 64 : memref<1x3xf32, #gpu.address_space<global>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %4 = vector.transfer_read %0[%c0, %c0], %cst {in_bounds = [true, true]} : memref<1x4xf32, #gpu.address_space<global>>, vector<1x4xf32>
    %5 = vector.transfer_read %1[%c0, %workgroup_id_x], %cst {in_bounds = [true, true]} : memref<4x3xf32, #gpu.address_space<global>>, vector<4x1xf32>
    %6 = vector.transfer_read %2[%c0, %workgroup_id_x], %cst {in_bounds = [true, true]} : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>, vector<1x1xf32>
    %7 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"], kind = #vector.kind<add>} %4, %5, %6 : vector<1x4xf32>, vector<4x1xf32> into vector<1x1xf32>
    vector.transfer_write %7, %3[%c0, %workgroup_id_x] {in_bounds = [true, true]} : vector<1x1xf32>, memref<1x3xf32, #gpu.address_space<global>>
    return
  }
}

// -----// IR Dump After LowerUKernelOpsToCalls (iree-codegen-lower-ukernel-ops-to-calls) //----- //
module {
  func.func @main_dispatch_0_matmul_1x3x4_f32() {
    %c0 = arith.constant 0 : index
    %c64 = arith.constant 64 : index
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<1x4xf32, #gpu.address_space<global>>
    memref.assume_alignment %0, 64 : memref<1x4xf32, #gpu.address_space<global>>
    %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<4x3xf32, #gpu.address_space<global>>
    memref.assume_alignment %1, 64 : memref<4x3xf32, #gpu.address_space<global>>
    %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
    memref.assume_alignment %2, 64 : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
    %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<1x3xf32, #gpu.address_space<global>>
    memref.assume_alignment %3, 64 : memref<1x3xf32, #gpu.address_space<global>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %4 = vector.transfer_read %0[%c0, %c0], %cst {in_bounds = [true, true]} : memref<1x4xf32, #gpu.address_space<global>>, vector<1x4xf32>
    %5 = vector.transfer_read %1[%c0, %workgroup_id_x], %cst {in_bounds = [true, true]} : memref<4x3xf32, #gpu.address_space<global>>, vector<4x1xf32>
    %6 = vector.transfer_read %2[%c0, %workgroup_id_x], %cst {in_bounds = [true, true]} : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>, vector<1x1xf32>
    %7 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"], kind = #vector.kind<add>} %4, %5, %6 : vector<1x4xf32>, vector<4x1xf32> into vector<1x1xf32>
    vector.transfer_write %7, %3[%c0, %workgroup_id_x] {in_bounds = [true, true]} : vector<1x1xf32>, memref<1x3xf32, #gpu.address_space<global>>
    return
  }
}

// -----// IR Dump After LinalgExtToLoops (iree-linalg-ext-to-loops) //----- //
func.func @main_dispatch_0_matmul_1x3x4_f32() {
  %c0 = arith.constant 0 : index
  %c64 = arith.constant 64 : index
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<1x4xf32, #gpu.address_space<global>>
  memref.assume_alignment %0, 64 : memref<1x4xf32, #gpu.address_space<global>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<4x3xf32, #gpu.address_space<global>>
  memref.assume_alignment %1, 64 : memref<4x3xf32, #gpu.address_space<global>>
  %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
  memref.assume_alignment %2, 64 : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
  %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<1x3xf32, #gpu.address_space<global>>
  memref.assume_alignment %3, 64 : memref<1x3xf32, #gpu.address_space<global>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %4 = vector.transfer_read %0[%c0, %c0], %cst {in_bounds = [true, true]} : memref<1x4xf32, #gpu.address_space<global>>, vector<1x4xf32>
  %5 = vector.transfer_read %1[%c0, %workgroup_id_x], %cst {in_bounds = [true, true]} : memref<4x3xf32, #gpu.address_space<global>>, vector<4x1xf32>
  %6 = vector.transfer_read %2[%c0, %workgroup_id_x], %cst {in_bounds = [true, true]} : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>, vector<1x1xf32>
  %7 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"], kind = #vector.kind<add>} %4, %5, %6 : vector<1x4xf32>, vector<4x1xf32> into vector<1x1xf32>
  vector.transfer_write %7, %3[%c0, %workgroup_id_x] {in_bounds = [true, true]} : vector<1x1xf32>, memref<1x3xf32, #gpu.address_space<global>>
  return
}

// -----// IR Dump After MemrefCopyToLinalgPass (iree-codegen-memrefcopy-to-linalg) //----- //
func.func @main_dispatch_0_matmul_1x3x4_f32() {
  %c0 = arith.constant 0 : index
  %c64 = arith.constant 64 : index
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<1x4xf32, #gpu.address_space<global>>
  memref.assume_alignment %0, 64 : memref<1x4xf32, #gpu.address_space<global>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<4x3xf32, #gpu.address_space<global>>
  memref.assume_alignment %1, 64 : memref<4x3xf32, #gpu.address_space<global>>
  %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
  memref.assume_alignment %2, 64 : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
  %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<1x3xf32, #gpu.address_space<global>>
  memref.assume_alignment %3, 64 : memref<1x3xf32, #gpu.address_space<global>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %4 = vector.transfer_read %0[%c0, %c0], %cst {in_bounds = [true, true]} : memref<1x4xf32, #gpu.address_space<global>>, vector<1x4xf32>
  %5 = vector.transfer_read %1[%c0, %workgroup_id_x], %cst {in_bounds = [true, true]} : memref<4x3xf32, #gpu.address_space<global>>, vector<4x1xf32>
  %6 = vector.transfer_read %2[%c0, %workgroup_id_x], %cst {in_bounds = [true, true]} : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>, vector<1x1xf32>
  %7 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"], kind = #vector.kind<add>} %4, %5, %6 : vector<1x4xf32>, vector<4x1xf32> into vector<1x1xf32>
  vector.transfer_write %7, %3[%c0, %workgroup_id_x] {in_bounds = [true, true]} : vector<1x1xf32>, memref<1x3xf32, #gpu.address_space<global>>
  return
}

// -----// IR Dump After LinalgLowerToLoops (convert-linalg-to-loops) //----- //
func.func @main_dispatch_0_matmul_1x3x4_f32() {
  %c0 = arith.constant 0 : index
  %c64 = arith.constant 64 : index
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<1x4xf32, #gpu.address_space<global>>
  memref.assume_alignment %0, 64 : memref<1x4xf32, #gpu.address_space<global>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<4x3xf32, #gpu.address_space<global>>
  memref.assume_alignment %1, 64 : memref<4x3xf32, #gpu.address_space<global>>
  %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
  memref.assume_alignment %2, 64 : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
  %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<1x3xf32, #gpu.address_space<global>>
  memref.assume_alignment %3, 64 : memref<1x3xf32, #gpu.address_space<global>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %4 = vector.transfer_read %0[%c0, %c0], %cst {in_bounds = [true, true]} : memref<1x4xf32, #gpu.address_space<global>>, vector<1x4xf32>
  %5 = vector.transfer_read %1[%c0, %workgroup_id_x], %cst {in_bounds = [true, true]} : memref<4x3xf32, #gpu.address_space<global>>, vector<4x1xf32>
  %6 = vector.transfer_read %2[%c0, %workgroup_id_x], %cst {in_bounds = [true, true]} : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>, vector<1x1xf32>
  %7 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"], kind = #vector.kind<add>} %4, %5, %6 : vector<1x4xf32>, vector<4x1xf32> into vector<1x1xf32>
  vector.transfer_write %7, %3[%c0, %workgroup_id_x] {in_bounds = [true, true]} : vector<1x1xf32>, memref<1x3xf32, #gpu.address_space<global>>
  return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main_dispatch_0_matmul_1x3x4_f32() {
  %c0 = arith.constant 0 : index
  %c64 = arith.constant 64 : index
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<1x4xf32, #gpu.address_space<global>>
  memref.assume_alignment %0, 64 : memref<1x4xf32, #gpu.address_space<global>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<4x3xf32, #gpu.address_space<global>>
  memref.assume_alignment %1, 64 : memref<4x3xf32, #gpu.address_space<global>>
  %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
  memref.assume_alignment %2, 64 : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
  %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<1x3xf32, #gpu.address_space<global>>
  memref.assume_alignment %3, 64 : memref<1x3xf32, #gpu.address_space<global>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %4 = vector.transfer_read %0[%c0, %c0], %cst {in_bounds = [true, true]} : memref<1x4xf32, #gpu.address_space<global>>, vector<1x4xf32>
  %5 = vector.transfer_read %1[%c0, %workgroup_id_x], %cst {in_bounds = [true, true]} : memref<4x3xf32, #gpu.address_space<global>>, vector<4x1xf32>
  %6 = vector.transfer_read %2[%c0, %workgroup_id_x], %cst {in_bounds = [true, true]} : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>, vector<1x1xf32>
  %7 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"], kind = #vector.kind<add>} %4, %5, %6 : vector<1x4xf32>, vector<4x1xf32> into vector<1x1xf32>
  vector.transfer_write %7, %3[%c0, %workgroup_id_x] {in_bounds = [true, true]} : vector<1x1xf32>, memref<1x3xf32, #gpu.address_space<global>>
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @main_dispatch_0_matmul_1x3x4_f32() {
  %c0 = arith.constant 0 : index
  %c64 = arith.constant 64 : index
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<1x4xf32, #gpu.address_space<global>>
  memref.assume_alignment %0, 64 : memref<1x4xf32, #gpu.address_space<global>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<4x3xf32, #gpu.address_space<global>>
  memref.assume_alignment %1, 64 : memref<4x3xf32, #gpu.address_space<global>>
  %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
  memref.assume_alignment %2, 64 : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
  %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<1x3xf32, #gpu.address_space<global>>
  memref.assume_alignment %3, 64 : memref<1x3xf32, #gpu.address_space<global>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %4 = vector.transfer_read %0[%c0, %c0], %cst {in_bounds = [true, true]} : memref<1x4xf32, #gpu.address_space<global>>, vector<1x4xf32>
  %5 = vector.transfer_read %1[%c0, %workgroup_id_x], %cst {in_bounds = [true, true]} : memref<4x3xf32, #gpu.address_space<global>>, vector<4x1xf32>
  %6 = vector.transfer_read %2[%c0, %workgroup_id_x], %cst {in_bounds = [true, true]} : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>, vector<1x1xf32>
  %7 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"], kind = #vector.kind<add>} %4, %5, %6 : vector<1x4xf32>, vector<4x1xf32> into vector<1x1xf32>
  vector.transfer_write %7, %3[%c0, %workgroup_id_x] {in_bounds = [true, true]} : vector<1x1xf32>, memref<1x3xf32, #gpu.address_space<global>>
  return
}

// -----// IR Dump After PadDynamicAlloc (iree-codegen-pad-dynamic-alloc) //----- //
func.func @main_dispatch_0_matmul_1x3x4_f32() {
  %c0 = arith.constant 0 : index
  %c64 = arith.constant 64 : index
  %cst = arith.constant 0.000000e+00 : f32
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<1x4xf32, #gpu.address_space<global>>
  memref.assume_alignment %0, 64 : memref<1x4xf32, #gpu.address_space<global>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<4x3xf32, #gpu.address_space<global>>
  memref.assume_alignment %1, 64 : memref<4x3xf32, #gpu.address_space<global>>
  %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
  memref.assume_alignment %2, 64 : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
  %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<1x3xf32, #gpu.address_space<global>>
  memref.assume_alignment %3, 64 : memref<1x3xf32, #gpu.address_space<global>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %4 = vector.transfer_read %0[%c0, %c0], %cst {in_bounds = [true, true]} : memref<1x4xf32, #gpu.address_space<global>>, vector<1x4xf32>
  %5 = vector.transfer_read %1[%c0, %workgroup_id_x], %cst {in_bounds = [true, true]} : memref<4x3xf32, #gpu.address_space<global>>, vector<4x1xf32>
  %6 = vector.transfer_read %2[%c0, %workgroup_id_x], %cst {in_bounds = [true, true]} : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>, vector<1x1xf32>
  %7 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"], kind = #vector.kind<add>} %4, %5, %6 : vector<1x4xf32>, vector<4x1xf32> into vector<1x1xf32>
  vector.transfer_write %7, %3[%c0, %workgroup_id_x] {in_bounds = [true, true]} : vector<1x1xf32>, memref<1x3xf32, #gpu.address_space<global>>
  return
}

// -----// IR Dump After ConvertAffineToStandard (lower-affine) //----- //
module {
  func.func @main_dispatch_0_matmul_1x3x4_f32() {
    %c0 = arith.constant 0 : index
    %c64 = arith.constant 64 : index
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<1x4xf32, #gpu.address_space<global>>
    memref.assume_alignment %0, 64 : memref<1x4xf32, #gpu.address_space<global>>
    %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<4x3xf32, #gpu.address_space<global>>
    memref.assume_alignment %1, 64 : memref<4x3xf32, #gpu.address_space<global>>
    %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
    memref.assume_alignment %2, 64 : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
    %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<1x3xf32, #gpu.address_space<global>>
    memref.assume_alignment %3, 64 : memref<1x3xf32, #gpu.address_space<global>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %4 = vector.transfer_read %0[%c0, %c0], %cst {in_bounds = [true, true]} : memref<1x4xf32, #gpu.address_space<global>>, vector<1x4xf32>
    %5 = vector.transfer_read %1[%c0, %workgroup_id_x], %cst {in_bounds = [true, true]} : memref<4x3xf32, #gpu.address_space<global>>, vector<4x1xf32>
    %6 = vector.transfer_read %2[%c0, %workgroup_id_x], %cst {in_bounds = [true, true]} : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>, vector<1x1xf32>
    %7 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"], kind = #vector.kind<add>} %4, %5, %6 : vector<1x4xf32>, vector<4x1xf32> into vector<1x1xf32>
    vector.transfer_write %7, %3[%c0, %workgroup_id_x] {in_bounds = [true, true]} : vector<1x1xf32>, memref<1x3xf32, #gpu.address_space<global>>
    return
  }
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
module {
  func.func @main_dispatch_0_matmul_1x3x4_f32() {
    %c0 = arith.constant 0 : index
    %c64 = arith.constant 64 : index
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<1x4xf32, #gpu.address_space<global>>
    memref.assume_alignment %0, 64 : memref<1x4xf32, #gpu.address_space<global>>
    %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<4x3xf32, #gpu.address_space<global>>
    memref.assume_alignment %1, 64 : memref<4x3xf32, #gpu.address_space<global>>
    %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
    memref.assume_alignment %2, 64 : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
    %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<1x3xf32, #gpu.address_space<global>>
    memref.assume_alignment %3, 64 : memref<1x3xf32, #gpu.address_space<global>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %4 = vector.transfer_read %0[%c0, %c0], %cst {in_bounds = [true, true]} : memref<1x4xf32, #gpu.address_space<global>>, vector<1x4xf32>
    %5 = vector.transfer_read %1[%c0, %workgroup_id_x], %cst {in_bounds = [true, true]} : memref<4x3xf32, #gpu.address_space<global>>, vector<4x1xf32>
    %6 = vector.transfer_read %2[%c0, %workgroup_id_x], %cst {in_bounds = [true, true]} : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>, vector<1x1xf32>
    %7 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"], kind = #vector.kind<add>} %4, %5, %6 : vector<1x4xf32>, vector<4x1xf32> into vector<1x1xf32>
    vector.transfer_write %7, %3[%c0, %workgroup_id_x] {in_bounds = [true, true]} : vector<1x1xf32>, memref<1x3xf32, #gpu.address_space<global>>
    return
  }
}

// -----// IR Dump After CSE (cse) //----- //
module {
  func.func @main_dispatch_0_matmul_1x3x4_f32() {
    %c0 = arith.constant 0 : index
    %c64 = arith.constant 64 : index
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<1x4xf32, #gpu.address_space<global>>
    memref.assume_alignment %0, 64 : memref<1x4xf32, #gpu.address_space<global>>
    %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<4x3xf32, #gpu.address_space<global>>
    memref.assume_alignment %1, 64 : memref<4x3xf32, #gpu.address_space<global>>
    %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
    memref.assume_alignment %2, 64 : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
    %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<1x3xf32, #gpu.address_space<global>>
    memref.assume_alignment %3, 64 : memref<1x3xf32, #gpu.address_space<global>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %4 = vector.transfer_read %0[%c0, %c0], %cst {in_bounds = [true, true]} : memref<1x4xf32, #gpu.address_space<global>>, vector<1x4xf32>
    %5 = vector.transfer_read %1[%c0, %workgroup_id_x], %cst {in_bounds = [true, true]} : memref<4x3xf32, #gpu.address_space<global>>, vector<4x1xf32>
    %6 = vector.transfer_read %2[%c0, %workgroup_id_x], %cst {in_bounds = [true, true]} : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>, vector<1x1xf32>
    %7 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"], kind = #vector.kind<add>} %4, %5, %6 : vector<1x4xf32>, vector<4x1xf32> into vector<1x1xf32>
    vector.transfer_write %7, %3[%c0, %workgroup_id_x] {in_bounds = [true, true]} : vector<1x1xf32>, memref<1x3xf32, #gpu.address_space<global>>
    return
  }
}

// -----// IR Dump After ArithBufferizePass (arith-bufferize) //----- //
module {
  func.func @main_dispatch_0_matmul_1x3x4_f32() {
    %c0 = arith.constant 0 : index
    %c64 = arith.constant 64 : index
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<1x4xf32, #gpu.address_space<global>>
    memref.assume_alignment %0, 64 : memref<1x4xf32, #gpu.address_space<global>>
    %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<4x3xf32, #gpu.address_space<global>>
    memref.assume_alignment %1, 64 : memref<4x3xf32, #gpu.address_space<global>>
    %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
    memref.assume_alignment %2, 64 : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
    %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<1x3xf32, #gpu.address_space<global>>
    memref.assume_alignment %3, 64 : memref<1x3xf32, #gpu.address_space<global>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %4 = vector.transfer_read %0[%c0, %c0], %cst {in_bounds = [true, true]} : memref<1x4xf32, #gpu.address_space<global>>, vector<1x4xf32>
    %5 = vector.transfer_read %1[%c0, %workgroup_id_x], %cst {in_bounds = [true, true]} : memref<4x3xf32, #gpu.address_space<global>>, vector<4x1xf32>
    %6 = vector.transfer_read %2[%c0, %workgroup_id_x], %cst {in_bounds = [true, true]} : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>, vector<1x1xf32>
    %7 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"], kind = #vector.kind<add>} %4, %5, %6 : vector<1x4xf32>, vector<4x1xf32> into vector<1x1xf32>
    vector.transfer_write %7, %3[%c0, %workgroup_id_x] {in_bounds = [true, true]} : vector<1x1xf32>, memref<1x3xf32, #gpu.address_space<global>>
    return
  }
}

// -----// IR Dump After FoldTensorExtractOp (iree-codegen-fold-tensor-extract-op) //----- //
module {
  func.func @main_dispatch_0_matmul_1x3x4_f32() {
    %c0 = arith.constant 0 : index
    %c64 = arith.constant 64 : index
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<1x4xf32, #gpu.address_space<global>>
    memref.assume_alignment %0, 64 : memref<1x4xf32, #gpu.address_space<global>>
    %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<4x3xf32, #gpu.address_space<global>>
    memref.assume_alignment %1, 64 : memref<4x3xf32, #gpu.address_space<global>>
    %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
    memref.assume_alignment %2, 64 : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
    %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<1x3xf32, #gpu.address_space<global>>
    memref.assume_alignment %3, 64 : memref<1x3xf32, #gpu.address_space<global>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %4 = vector.transfer_read %0[%c0, %c0], %cst {in_bounds = [true, true]} : memref<1x4xf32, #gpu.address_space<global>>, vector<1x4xf32>
    %5 = vector.transfer_read %1[%c0, %workgroup_id_x], %cst {in_bounds = [true, true]} : memref<4x3xf32, #gpu.address_space<global>>, vector<4x1xf32>
    %6 = vector.transfer_read %2[%c0, %workgroup_id_x], %cst {in_bounds = [true, true]} : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>, vector<1x1xf32>
    %7 = vector.contract {indexing_maps = [affine_map<(d0, d1, d2) -> (d0, d2)>, affine_map<(d0, d1, d2) -> (d2, d1)>, affine_map<(d0, d1, d2) -> (d0, d1)>], iterator_types = ["parallel", "parallel", "reduction"], kind = #vector.kind<add>} %4, %5, %6 : vector<1x4xf32>, vector<4x1xf32> into vector<1x1xf32>
    vector.transfer_write %7, %3[%c0, %workgroup_id_x] {in_bounds = [true, true]} : vector<1x1xf32>, memref<1x3xf32, #gpu.address_space<global>>
    return
  }
}

// -----// IR Dump After LLVMGPUVectorLowering (iree-llvmgpu-vector-lowering) //----- //
func.func @main_dispatch_0_matmul_1x3x4_f32() {
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c2 = arith.constant 2 : index
  %c3 = arith.constant 3 : index
  %c64 = arith.constant 64 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<1x4xf32, #gpu.address_space<global>>
  memref.assume_alignment %0, 64 : memref<1x4xf32, #gpu.address_space<global>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<4x3xf32, #gpu.address_space<global>>
  memref.assume_alignment %1, 64 : memref<4x3xf32, #gpu.address_space<global>>
  %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
  memref.assume_alignment %2, 64 : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
  %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<1x3xf32, #gpu.address_space<global>>
  memref.assume_alignment %3, 64 : memref<1x3xf32, #gpu.address_space<global>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %4 = vector.load %0[%c0, %c0] : memref<1x4xf32, #gpu.address_space<global>>, vector<4xf32>
  %5 = memref.load %1[%c0, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
  %6 = vector.broadcast %5 : f32 to vector<1xf32>
  %7 = memref.load %1[%c1, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
  %8 = vector.broadcast %7 : f32 to vector<1xf32>
  %9 = memref.load %1[%c2, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
  %10 = vector.broadcast %9 : f32 to vector<1xf32>
  %11 = memref.load %1[%c3, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
  %12 = vector.broadcast %11 : f32 to vector<1xf32>
  %13 = memref.load %2[%c0, %workgroup_id_x] : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
  %14 = vector.broadcast %13 : f32 to vector<1xf32>
  %15 = vector.extract %4[0] : f32 from vector<4xf32>
  %16 = vector.splat %15 : vector<1xf32>
  %17 = vector.fma %16, %6, %14 : vector<1xf32>
  %18 = vector.extract %4[1] : f32 from vector<4xf32>
  %19 = vector.splat %18 : vector<1xf32>
  %20 = vector.fma %19, %8, %17 : vector<1xf32>
  %21 = vector.extract %4[2] : f32 from vector<4xf32>
  %22 = vector.splat %21 : vector<1xf32>
  %23 = vector.fma %22, %10, %20 : vector<1xf32>
  %24 = vector.extract %4[3] : f32 from vector<4xf32>
  %25 = vector.splat %24 : vector<1xf32>
  %26 = vector.fma %25, %12, %23 : vector<1xf32>
  %27 = vector.extract %26[0] : f32 from vector<1xf32>
  memref.store %27, %3[%c0, %workgroup_id_x] : memref<1x3xf32, #gpu.address_space<global>>
  return
}

// -----// IR Dump After ExtractAddressComputationGPU (extract-address-computation-gpu) //----- //
module {
  func.func @main_dispatch_0_matmul_1x3x4_f32() {
    %c0 = arith.constant 0 : index
    %c64 = arith.constant 64 : index
    %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<1x4xf32, #gpu.address_space<global>>
    memref.assume_alignment %0, 64 : memref<1x4xf32, #gpu.address_space<global>>
    %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<4x3xf32, #gpu.address_space<global>>
    memref.assume_alignment %1, 64 : memref<4x3xf32, #gpu.address_space<global>>
    %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
    memref.assume_alignment %2, 64 : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
    %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<1x3xf32, #gpu.address_space<global>>
    memref.assume_alignment %3, 64 : memref<1x3xf32, #gpu.address_space<global>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %4 = vector.load %0[%c0, %c0] : memref<1x4xf32, #gpu.address_space<global>>, vector<4xf32>
    %subview = memref.subview %1[0, %workgroup_id_x] [1, 1] [1, 1] : memref<4x3xf32, #gpu.address_space<global>> to memref<1x1xf32, strided<[3, 1], offset: ?>, #gpu.address_space<global>>
    %5 = memref.load %subview[%c0, %c0] : memref<1x1xf32, strided<[3, 1], offset: ?>, #gpu.address_space<global>>
    %6 = vector.broadcast %5 : f32 to vector<1xf32>
    %subview_0 = memref.subview %1[1, %workgroup_id_x] [1, 1] [1, 1] : memref<4x3xf32, #gpu.address_space<global>> to memref<1x1xf32, strided<[3, 1], offset: ?>, #gpu.address_space<global>>
    %7 = memref.load %subview_0[%c0, %c0] : memref<1x1xf32, strided<[3, 1], offset: ?>, #gpu.address_space<global>>
    %8 = vector.broadcast %7 : f32 to vector<1xf32>
    %subview_1 = memref.subview %1[2, %workgroup_id_x] [1, 1] [1, 1] : memref<4x3xf32, #gpu.address_space<global>> to memref<1x1xf32, strided<[3, 1], offset: ?>, #gpu.address_space<global>>
    %9 = memref.load %subview_1[%c0, %c0] : memref<1x1xf32, strided<[3, 1], offset: ?>, #gpu.address_space<global>>
    %10 = vector.broadcast %9 : f32 to vector<1xf32>
    %subview_2 = memref.subview %1[3, %workgroup_id_x] [1, 1] [1, 1] : memref<4x3xf32, #gpu.address_space<global>> to memref<1x1xf32, strided<[3, 1], offset: ?>, #gpu.address_space<global>>
    %11 = memref.load %subview_2[%c0, %c0] : memref<1x1xf32, strided<[3, 1], offset: ?>, #gpu.address_space<global>>
    %12 = vector.broadcast %11 : f32 to vector<1xf32>
    %subview_3 = memref.subview %2[0, %workgroup_id_x] [1, 1] [1, 1] : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>> to memref<1x1xf32, strided<[3, 1], offset: ?>, #gpu.address_space<global>>
    %13 = memref.load %subview_3[%c0, %c0] : memref<1x1xf32, strided<[3, 1], offset: ?>, #gpu.address_space<global>>
    %14 = vector.broadcast %13 : f32 to vector<1xf32>
    %15 = vector.extract %4[0] : f32 from vector<4xf32>
    %16 = vector.splat %15 : vector<1xf32>
    %17 = vector.fma %16, %6, %14 : vector<1xf32>
    %18 = vector.extract %4[1] : f32 from vector<4xf32>
    %19 = vector.splat %18 : vector<1xf32>
    %20 = vector.fma %19, %8, %17 : vector<1xf32>
    %21 = vector.extract %4[2] : f32 from vector<4xf32>
    %22 = vector.splat %21 : vector<1xf32>
    %23 = vector.fma %22, %10, %20 : vector<1xf32>
    %24 = vector.extract %4[3] : f32 from vector<4xf32>
    %25 = vector.splat %24 : vector<1xf32>
    %26 = vector.fma %25, %12, %23 : vector<1xf32>
    %27 = vector.extract %26[0] : f32 from vector<1xf32>
    %subview_4 = memref.subview %3[0, %workgroup_id_x] [1, 1] [1, 1] : memref<1x3xf32, #gpu.address_space<global>> to memref<1x1xf32, strided<[3, 1], offset: ?>, #gpu.address_space<global>>
    memref.store %27, %subview_4[%c0, %c0] : memref<1x1xf32, strided<[3, 1], offset: ?>, #gpu.address_space<global>>
    return
  }
}

// -----// IR Dump After ExpandOps (memref-expand) //----- //
func.func @main_dispatch_0_matmul_1x3x4_f32() {
  %c0 = arith.constant 0 : index
  %c64 = arith.constant 64 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<1x4xf32, #gpu.address_space<global>>
  memref.assume_alignment %0, 64 : memref<1x4xf32, #gpu.address_space<global>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<4x3xf32, #gpu.address_space<global>>
  memref.assume_alignment %1, 64 : memref<4x3xf32, #gpu.address_space<global>>
  %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
  memref.assume_alignment %2, 64 : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
  %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<1x3xf32, #gpu.address_space<global>>
  memref.assume_alignment %3, 64 : memref<1x3xf32, #gpu.address_space<global>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %4 = vector.load %0[%c0, %c0] : memref<1x4xf32, #gpu.address_space<global>>, vector<4xf32>
  %subview = memref.subview %1[0, %workgroup_id_x] [1, 1] [1, 1] : memref<4x3xf32, #gpu.address_space<global>> to memref<1x1xf32, strided<[3, 1], offset: ?>, #gpu.address_space<global>>
  %5 = memref.load %subview[%c0, %c0] : memref<1x1xf32, strided<[3, 1], offset: ?>, #gpu.address_space<global>>
  %6 = vector.broadcast %5 : f32 to vector<1xf32>
  %subview_0 = memref.subview %1[1, %workgroup_id_x] [1, 1] [1, 1] : memref<4x3xf32, #gpu.address_space<global>> to memref<1x1xf32, strided<[3, 1], offset: ?>, #gpu.address_space<global>>
  %7 = memref.load %subview_0[%c0, %c0] : memref<1x1xf32, strided<[3, 1], offset: ?>, #gpu.address_space<global>>
  %8 = vector.broadcast %7 : f32 to vector<1xf32>
  %subview_1 = memref.subview %1[2, %workgroup_id_x] [1, 1] [1, 1] : memref<4x3xf32, #gpu.address_space<global>> to memref<1x1xf32, strided<[3, 1], offset: ?>, #gpu.address_space<global>>
  %9 = memref.load %subview_1[%c0, %c0] : memref<1x1xf32, strided<[3, 1], offset: ?>, #gpu.address_space<global>>
  %10 = vector.broadcast %9 : f32 to vector<1xf32>
  %subview_2 = memref.subview %1[3, %workgroup_id_x] [1, 1] [1, 1] : memref<4x3xf32, #gpu.address_space<global>> to memref<1x1xf32, strided<[3, 1], offset: ?>, #gpu.address_space<global>>
  %11 = memref.load %subview_2[%c0, %c0] : memref<1x1xf32, strided<[3, 1], offset: ?>, #gpu.address_space<global>>
  %12 = vector.broadcast %11 : f32 to vector<1xf32>
  %subview_3 = memref.subview %2[0, %workgroup_id_x] [1, 1] [1, 1] : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>> to memref<1x1xf32, strided<[3, 1], offset: ?>, #gpu.address_space<global>>
  %13 = memref.load %subview_3[%c0, %c0] : memref<1x1xf32, strided<[3, 1], offset: ?>, #gpu.address_space<global>>
  %14 = vector.broadcast %13 : f32 to vector<1xf32>
  %15 = vector.extract %4[0] : f32 from vector<4xf32>
  %16 = vector.splat %15 : vector<1xf32>
  %17 = vector.fma %16, %6, %14 : vector<1xf32>
  %18 = vector.extract %4[1] : f32 from vector<4xf32>
  %19 = vector.splat %18 : vector<1xf32>
  %20 = vector.fma %19, %8, %17 : vector<1xf32>
  %21 = vector.extract %4[2] : f32 from vector<4xf32>
  %22 = vector.splat %21 : vector<1xf32>
  %23 = vector.fma %22, %10, %20 : vector<1xf32>
  %24 = vector.extract %4[3] : f32 from vector<4xf32>
  %25 = vector.splat %24 : vector<1xf32>
  %26 = vector.fma %25, %12, %23 : vector<1xf32>
  %27 = vector.extract %26[0] : f32 from vector<1xf32>
  %subview_4 = memref.subview %3[0, %workgroup_id_x] [1, 1] [1, 1] : memref<1x3xf32, #gpu.address_space<global>> to memref<1x1xf32, strided<[3, 1], offset: ?>, #gpu.address_space<global>>
  memref.store %27, %subview_4[%c0, %c0] : memref<1x1xf32, strided<[3, 1], offset: ?>, #gpu.address_space<global>>
  return
}

// -----// IR Dump After FoldMemRefAliasOps (fold-memref-alias-ops) //----- //
module {
  func.func @main_dispatch_0_matmul_1x3x4_f32() {
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c2 = arith.constant 2 : index
    %c3 = arith.constant 3 : index
    %c64 = arith.constant 64 : index
    %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<1x4xf32, #gpu.address_space<global>>
    memref.assume_alignment %0, 64 : memref<1x4xf32, #gpu.address_space<global>>
    %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<4x3xf32, #gpu.address_space<global>>
    memref.assume_alignment %1, 64 : memref<4x3xf32, #gpu.address_space<global>>
    %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
    memref.assume_alignment %2, 64 : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
    %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<1x3xf32, #gpu.address_space<global>>
    memref.assume_alignment %3, 64 : memref<1x3xf32, #gpu.address_space<global>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %4 = vector.load %0[%c0, %c0] : memref<1x4xf32, #gpu.address_space<global>>, vector<4xf32>
    %5 = memref.load %1[%c0, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
    %6 = vector.broadcast %5 : f32 to vector<1xf32>
    %7 = memref.load %1[%c1, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
    %8 = vector.broadcast %7 : f32 to vector<1xf32>
    %9 = memref.load %1[%c2, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
    %10 = vector.broadcast %9 : f32 to vector<1xf32>
    %11 = memref.load %1[%c3, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
    %12 = vector.broadcast %11 : f32 to vector<1xf32>
    %13 = memref.load %2[%c0, %workgroup_id_x] : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
    %14 = vector.broadcast %13 : f32 to vector<1xf32>
    %15 = vector.extract %4[0] : f32 from vector<4xf32>
    %16 = vector.splat %15 : vector<1xf32>
    %17 = vector.fma %16, %6, %14 : vector<1xf32>
    %18 = vector.extract %4[1] : f32 from vector<4xf32>
    %19 = vector.splat %18 : vector<1xf32>
    %20 = vector.fma %19, %8, %17 : vector<1xf32>
    %21 = vector.extract %4[2] : f32 from vector<4xf32>
    %22 = vector.splat %21 : vector<1xf32>
    %23 = vector.fma %22, %10, %20 : vector<1xf32>
    %24 = vector.extract %4[3] : f32 from vector<4xf32>
    %25 = vector.splat %24 : vector<1xf32>
    %26 = vector.fma %25, %12, %23 : vector<1xf32>
    %27 = vector.extract %26[0] : f32 from vector<1xf32>
    memref.store %27, %3[%c0, %workgroup_id_x] : memref<1x3xf32, #gpu.address_space<global>>
    return
  }
}

// -----// IR Dump After ExpandStridedMetadata (expand-strided-metadata) //----- //
module {
  func.func @main_dispatch_0_matmul_1x3x4_f32() {
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c2 = arith.constant 2 : index
    %c3 = arith.constant 3 : index
    %c64 = arith.constant 64 : index
    %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<1x4xf32, #gpu.address_space<global>>
    memref.assume_alignment %0, 64 : memref<1x4xf32, #gpu.address_space<global>>
    %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<4x3xf32, #gpu.address_space<global>>
    memref.assume_alignment %1, 64 : memref<4x3xf32, #gpu.address_space<global>>
    %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
    memref.assume_alignment %2, 64 : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
    %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<1x3xf32, #gpu.address_space<global>>
    memref.assume_alignment %3, 64 : memref<1x3xf32, #gpu.address_space<global>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %4 = vector.load %0[%c0, %c0] : memref<1x4xf32, #gpu.address_space<global>>, vector<4xf32>
    %5 = memref.load %1[%c0, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
    %6 = vector.broadcast %5 : f32 to vector<1xf32>
    %7 = memref.load %1[%c1, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
    %8 = vector.broadcast %7 : f32 to vector<1xf32>
    %9 = memref.load %1[%c2, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
    %10 = vector.broadcast %9 : f32 to vector<1xf32>
    %11 = memref.load %1[%c3, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
    %12 = vector.broadcast %11 : f32 to vector<1xf32>
    %13 = memref.load %2[%c0, %workgroup_id_x] : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
    %14 = vector.broadcast %13 : f32 to vector<1xf32>
    %15 = vector.extract %4[0] : f32 from vector<4xf32>
    %16 = vector.splat %15 : vector<1xf32>
    %17 = vector.fma %16, %6, %14 : vector<1xf32>
    %18 = vector.extract %4[1] : f32 from vector<4xf32>
    %19 = vector.splat %18 : vector<1xf32>
    %20 = vector.fma %19, %8, %17 : vector<1xf32>
    %21 = vector.extract %4[2] : f32 from vector<4xf32>
    %22 = vector.splat %21 : vector<1xf32>
    %23 = vector.fma %22, %10, %20 : vector<1xf32>
    %24 = vector.extract %4[3] : f32 from vector<4xf32>
    %25 = vector.splat %24 : vector<1xf32>
    %26 = vector.fma %25, %12, %23 : vector<1xf32>
    %27 = vector.extract %26[0] : f32 from vector<1xf32>
    memref.store %27, %3[%c0, %workgroup_id_x] : memref<1x3xf32, #gpu.address_space<global>>
    return
  }
}

// -----// IR Dump After LoopInvariantCodeMotion (loop-invariant-code-motion) //----- //
module {
  func.func @main_dispatch_0_matmul_1x3x4_f32() {
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c2 = arith.constant 2 : index
    %c3 = arith.constant 3 : index
    %c64 = arith.constant 64 : index
    %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<1x4xf32, #gpu.address_space<global>>
    memref.assume_alignment %0, 64 : memref<1x4xf32, #gpu.address_space<global>>
    %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<4x3xf32, #gpu.address_space<global>>
    memref.assume_alignment %1, 64 : memref<4x3xf32, #gpu.address_space<global>>
    %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
    memref.assume_alignment %2, 64 : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
    %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<1x3xf32, #gpu.address_space<global>>
    memref.assume_alignment %3, 64 : memref<1x3xf32, #gpu.address_space<global>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %4 = vector.load %0[%c0, %c0] : memref<1x4xf32, #gpu.address_space<global>>, vector<4xf32>
    %5 = memref.load %1[%c0, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
    %6 = vector.broadcast %5 : f32 to vector<1xf32>
    %7 = memref.load %1[%c1, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
    %8 = vector.broadcast %7 : f32 to vector<1xf32>
    %9 = memref.load %1[%c2, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
    %10 = vector.broadcast %9 : f32 to vector<1xf32>
    %11 = memref.load %1[%c3, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
    %12 = vector.broadcast %11 : f32 to vector<1xf32>
    %13 = memref.load %2[%c0, %workgroup_id_x] : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
    %14 = vector.broadcast %13 : f32 to vector<1xf32>
    %15 = vector.extract %4[0] : f32 from vector<4xf32>
    %16 = vector.splat %15 : vector<1xf32>
    %17 = vector.fma %16, %6, %14 : vector<1xf32>
    %18 = vector.extract %4[1] : f32 from vector<4xf32>
    %19 = vector.splat %18 : vector<1xf32>
    %20 = vector.fma %19, %8, %17 : vector<1xf32>
    %21 = vector.extract %4[2] : f32 from vector<4xf32>
    %22 = vector.splat %21 : vector<1xf32>
    %23 = vector.fma %22, %10, %20 : vector<1xf32>
    %24 = vector.extract %4[3] : f32 from vector<4xf32>
    %25 = vector.splat %24 : vector<1xf32>
    %26 = vector.fma %25, %12, %23 : vector<1xf32>
    %27 = vector.extract %26[0] : f32 from vector<1xf32>
    memref.store %27, %3[%c0, %workgroup_id_x] : memref<1x3xf32, #gpu.address_space<global>>
    return
  }
}

// -----// IR Dump After DecomposeAffineOps (decompose-affine-ops) //----- //
module {
  func.func @main_dispatch_0_matmul_1x3x4_f32() {
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c2 = arith.constant 2 : index
    %c3 = arith.constant 3 : index
    %c64 = arith.constant 64 : index
    %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<1x4xf32, #gpu.address_space<global>>
    memref.assume_alignment %0, 64 : memref<1x4xf32, #gpu.address_space<global>>
    %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<4x3xf32, #gpu.address_space<global>>
    memref.assume_alignment %1, 64 : memref<4x3xf32, #gpu.address_space<global>>
    %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
    memref.assume_alignment %2, 64 : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
    %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<1x3xf32, #gpu.address_space<global>>
    memref.assume_alignment %3, 64 : memref<1x3xf32, #gpu.address_space<global>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %4 = vector.load %0[%c0, %c0] : memref<1x4xf32, #gpu.address_space<global>>, vector<4xf32>
    %5 = memref.load %1[%c0, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
    %6 = vector.broadcast %5 : f32 to vector<1xf32>
    %7 = memref.load %1[%c1, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
    %8 = vector.broadcast %7 : f32 to vector<1xf32>
    %9 = memref.load %1[%c2, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
    %10 = vector.broadcast %9 : f32 to vector<1xf32>
    %11 = memref.load %1[%c3, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
    %12 = vector.broadcast %11 : f32 to vector<1xf32>
    %13 = memref.load %2[%c0, %workgroup_id_x] : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
    %14 = vector.broadcast %13 : f32 to vector<1xf32>
    %15 = vector.extract %4[0] : f32 from vector<4xf32>
    %16 = vector.splat %15 : vector<1xf32>
    %17 = vector.fma %16, %6, %14 : vector<1xf32>
    %18 = vector.extract %4[1] : f32 from vector<4xf32>
    %19 = vector.splat %18 : vector<1xf32>
    %20 = vector.fma %19, %8, %17 : vector<1xf32>
    %21 = vector.extract %4[2] : f32 from vector<4xf32>
    %22 = vector.splat %21 : vector<1xf32>
    %23 = vector.fma %22, %10, %20 : vector<1xf32>
    %24 = vector.extract %4[3] : f32 from vector<4xf32>
    %25 = vector.splat %24 : vector<1xf32>
    %26 = vector.fma %25, %12, %23 : vector<1xf32>
    %27 = vector.extract %26[0] : f32 from vector<1xf32>
    memref.store %27, %3[%c0, %workgroup_id_x] : memref<1x3xf32, #gpu.address_space<global>>
    return
  }
}

// -----// IR Dump After CSE (cse) //----- //
module {
  func.func @main_dispatch_0_matmul_1x3x4_f32() {
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c2 = arith.constant 2 : index
    %c3 = arith.constant 3 : index
    %c64 = arith.constant 64 : index
    %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<1x4xf32, #gpu.address_space<global>>
    memref.assume_alignment %0, 64 : memref<1x4xf32, #gpu.address_space<global>>
    %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<4x3xf32, #gpu.address_space<global>>
    memref.assume_alignment %1, 64 : memref<4x3xf32, #gpu.address_space<global>>
    %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
    memref.assume_alignment %2, 64 : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
    %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<1x3xf32, #gpu.address_space<global>>
    memref.assume_alignment %3, 64 : memref<1x3xf32, #gpu.address_space<global>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %4 = vector.load %0[%c0, %c0] : memref<1x4xf32, #gpu.address_space<global>>, vector<4xf32>
    %5 = memref.load %1[%c0, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
    %6 = vector.broadcast %5 : f32 to vector<1xf32>
    %7 = memref.load %1[%c1, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
    %8 = vector.broadcast %7 : f32 to vector<1xf32>
    %9 = memref.load %1[%c2, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
    %10 = vector.broadcast %9 : f32 to vector<1xf32>
    %11 = memref.load %1[%c3, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
    %12 = vector.broadcast %11 : f32 to vector<1xf32>
    %13 = memref.load %2[%c0, %workgroup_id_x] : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
    %14 = vector.broadcast %13 : f32 to vector<1xf32>
    %15 = vector.extract %4[0] : f32 from vector<4xf32>
    %16 = vector.splat %15 : vector<1xf32>
    %17 = vector.fma %16, %6, %14 : vector<1xf32>
    %18 = vector.extract %4[1] : f32 from vector<4xf32>
    %19 = vector.splat %18 : vector<1xf32>
    %20 = vector.fma %19, %8, %17 : vector<1xf32>
    %21 = vector.extract %4[2] : f32 from vector<4xf32>
    %22 = vector.splat %21 : vector<1xf32>
    %23 = vector.fma %22, %10, %20 : vector<1xf32>
    %24 = vector.extract %4[3] : f32 from vector<4xf32>
    %25 = vector.splat %24 : vector<1xf32>
    %26 = vector.fma %25, %12, %23 : vector<1xf32>
    %27 = vector.extract %26[0] : f32 from vector<1xf32>
    memref.store %27, %3[%c0, %workgroup_id_x] : memref<1x3xf32, #gpu.address_space<global>>
    return
  }
}

// -----// IR Dump After LoopInvariantCodeMotion (loop-invariant-code-motion) //----- //
module {
  func.func @main_dispatch_0_matmul_1x3x4_f32() {
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c2 = arith.constant 2 : index
    %c3 = arith.constant 3 : index
    %c64 = arith.constant 64 : index
    %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<1x4xf32, #gpu.address_space<global>>
    memref.assume_alignment %0, 64 : memref<1x4xf32, #gpu.address_space<global>>
    %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<4x3xf32, #gpu.address_space<global>>
    memref.assume_alignment %1, 64 : memref<4x3xf32, #gpu.address_space<global>>
    %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
    memref.assume_alignment %2, 64 : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
    %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<1x3xf32, #gpu.address_space<global>>
    memref.assume_alignment %3, 64 : memref<1x3xf32, #gpu.address_space<global>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %4 = vector.load %0[%c0, %c0] : memref<1x4xf32, #gpu.address_space<global>>, vector<4xf32>
    %5 = memref.load %1[%c0, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
    %6 = vector.broadcast %5 : f32 to vector<1xf32>
    %7 = memref.load %1[%c1, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
    %8 = vector.broadcast %7 : f32 to vector<1xf32>
    %9 = memref.load %1[%c2, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
    %10 = vector.broadcast %9 : f32 to vector<1xf32>
    %11 = memref.load %1[%c3, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
    %12 = vector.broadcast %11 : f32 to vector<1xf32>
    %13 = memref.load %2[%c0, %workgroup_id_x] : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
    %14 = vector.broadcast %13 : f32 to vector<1xf32>
    %15 = vector.extract %4[0] : f32 from vector<4xf32>
    %16 = vector.splat %15 : vector<1xf32>
    %17 = vector.fma %16, %6, %14 : vector<1xf32>
    %18 = vector.extract %4[1] : f32 from vector<4xf32>
    %19 = vector.splat %18 : vector<1xf32>
    %20 = vector.fma %19, %8, %17 : vector<1xf32>
    %21 = vector.extract %4[2] : f32 from vector<4xf32>
    %22 = vector.splat %21 : vector<1xf32>
    %23 = vector.fma %22, %10, %20 : vector<1xf32>
    %24 = vector.extract %4[3] : f32 from vector<4xf32>
    %25 = vector.splat %24 : vector<1xf32>
    %26 = vector.fma %25, %12, %23 : vector<1xf32>
    %27 = vector.extract %26[0] : f32 from vector<1xf32>
    memref.store %27, %3[%c0, %workgroup_id_x] : memref<1x3xf32, #gpu.address_space<global>>
    return
  }
}

// -----// IR Dump After ConvertAffineToStandard (lower-affine) //----- //
module {
  func.func @main_dispatch_0_matmul_1x3x4_f32() {
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c2 = arith.constant 2 : index
    %c3 = arith.constant 3 : index
    %c64 = arith.constant 64 : index
    %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<1x4xf32, #gpu.address_space<global>>
    memref.assume_alignment %0, 64 : memref<1x4xf32, #gpu.address_space<global>>
    %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<4x3xf32, #gpu.address_space<global>>
    memref.assume_alignment %1, 64 : memref<4x3xf32, #gpu.address_space<global>>
    %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
    memref.assume_alignment %2, 64 : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
    %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<1x3xf32, #gpu.address_space<global>>
    memref.assume_alignment %3, 64 : memref<1x3xf32, #gpu.address_space<global>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %4 = vector.load %0[%c0, %c0] : memref<1x4xf32, #gpu.address_space<global>>, vector<4xf32>
    %5 = memref.load %1[%c0, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
    %6 = vector.broadcast %5 : f32 to vector<1xf32>
    %7 = memref.load %1[%c1, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
    %8 = vector.broadcast %7 : f32 to vector<1xf32>
    %9 = memref.load %1[%c2, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
    %10 = vector.broadcast %9 : f32 to vector<1xf32>
    %11 = memref.load %1[%c3, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
    %12 = vector.broadcast %11 : f32 to vector<1xf32>
    %13 = memref.load %2[%c0, %workgroup_id_x] : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
    %14 = vector.broadcast %13 : f32 to vector<1xf32>
    %15 = vector.extract %4[0] : f32 from vector<4xf32>
    %16 = vector.splat %15 : vector<1xf32>
    %17 = vector.fma %16, %6, %14 : vector<1xf32>
    %18 = vector.extract %4[1] : f32 from vector<4xf32>
    %19 = vector.splat %18 : vector<1xf32>
    %20 = vector.fma %19, %8, %17 : vector<1xf32>
    %21 = vector.extract %4[2] : f32 from vector<4xf32>
    %22 = vector.splat %21 : vector<1xf32>
    %23 = vector.fma %22, %10, %20 : vector<1xf32>
    %24 = vector.extract %4[3] : f32 from vector<4xf32>
    %25 = vector.splat %24 : vector<1xf32>
    %26 = vector.fma %25, %12, %23 : vector<1xf32>
    %27 = vector.extract %26[0] : f32 from vector<1xf32>
    memref.store %27, %3[%c0, %workgroup_id_x] : memref<1x3xf32, #gpu.address_space<global>>
    return
  }
}

// -----// IR Dump After GPUCheckResourceUsage (iree-codegen-gpu-check-resource-usage) //----- //
module {
  func.func @main_dispatch_0_matmul_1x3x4_f32() {
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c2 = arith.constant 2 : index
    %c3 = arith.constant 3 : index
    %c64 = arith.constant 64 : index
    %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<1x4xf32, #gpu.address_space<global>>
    memref.assume_alignment %0, 64 : memref<1x4xf32, #gpu.address_space<global>>
    %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<4x3xf32, #gpu.address_space<global>>
    memref.assume_alignment %1, 64 : memref<4x3xf32, #gpu.address_space<global>>
    %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
    memref.assume_alignment %2, 64 : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
    %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<1x3xf32, #gpu.address_space<global>>
    memref.assume_alignment %3, 64 : memref<1x3xf32, #gpu.address_space<global>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %4 = vector.load %0[%c0, %c0] : memref<1x4xf32, #gpu.address_space<global>>, vector<4xf32>
    %5 = memref.load %1[%c0, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
    %6 = vector.broadcast %5 : f32 to vector<1xf32>
    %7 = memref.load %1[%c1, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
    %8 = vector.broadcast %7 : f32 to vector<1xf32>
    %9 = memref.load %1[%c2, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
    %10 = vector.broadcast %9 : f32 to vector<1xf32>
    %11 = memref.load %1[%c3, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
    %12 = vector.broadcast %11 : f32 to vector<1xf32>
    %13 = memref.load %2[%c0, %workgroup_id_x] : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
    %14 = vector.broadcast %13 : f32 to vector<1xf32>
    %15 = vector.extract %4[0] : f32 from vector<4xf32>
    %16 = vector.splat %15 : vector<1xf32>
    %17 = vector.fma %16, %6, %14 : vector<1xf32>
    %18 = vector.extract %4[1] : f32 from vector<4xf32>
    %19 = vector.splat %18 : vector<1xf32>
    %20 = vector.fma %19, %8, %17 : vector<1xf32>
    %21 = vector.extract %4[2] : f32 from vector<4xf32>
    %22 = vector.splat %21 : vector<1xf32>
    %23 = vector.fma %22, %10, %20 : vector<1xf32>
    %24 = vector.extract %4[3] : f32 from vector<4xf32>
    %25 = vector.splat %24 : vector<1xf32>
    %26 = vector.fma %25, %12, %23 : vector<1xf32>
    %27 = vector.extract %26[0] : f32 from vector<1xf32>
    memref.store %27, %3[%c0, %workgroup_id_x] : memref<1x3xf32, #gpu.address_space<global>>
    return
  }
}

// -----// IR Dump After SCFToControlFlow (convert-scf-to-cf) //----- //
func.func @main_dispatch_0_matmul_1x3x4_f32() {
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c2 = arith.constant 2 : index
  %c3 = arith.constant 3 : index
  %c64 = arith.constant 64 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<1x4xf32, #gpu.address_space<global>>
  memref.assume_alignment %0, 64 : memref<1x4xf32, #gpu.address_space<global>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<4x3xf32, #gpu.address_space<global>>
  memref.assume_alignment %1, 64 : memref<4x3xf32, #gpu.address_space<global>>
  %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
  memref.assume_alignment %2, 64 : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
  %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<1x3xf32, #gpu.address_space<global>>
  memref.assume_alignment %3, 64 : memref<1x3xf32, #gpu.address_space<global>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %4 = vector.load %0[%c0, %c0] : memref<1x4xf32, #gpu.address_space<global>>, vector<4xf32>
  %5 = memref.load %1[%c0, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
  %6 = vector.broadcast %5 : f32 to vector<1xf32>
  %7 = memref.load %1[%c1, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
  %8 = vector.broadcast %7 : f32 to vector<1xf32>
  %9 = memref.load %1[%c2, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
  %10 = vector.broadcast %9 : f32 to vector<1xf32>
  %11 = memref.load %1[%c3, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
  %12 = vector.broadcast %11 : f32 to vector<1xf32>
  %13 = memref.load %2[%c0, %workgroup_id_x] : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
  %14 = vector.broadcast %13 : f32 to vector<1xf32>
  %15 = vector.extract %4[0] : f32 from vector<4xf32>
  %16 = vector.splat %15 : vector<1xf32>
  %17 = vector.fma %16, %6, %14 : vector<1xf32>
  %18 = vector.extract %4[1] : f32 from vector<4xf32>
  %19 = vector.splat %18 : vector<1xf32>
  %20 = vector.fma %19, %8, %17 : vector<1xf32>
  %21 = vector.extract %4[2] : f32 from vector<4xf32>
  %22 = vector.splat %21 : vector<1xf32>
  %23 = vector.fma %22, %10, %20 : vector<1xf32>
  %24 = vector.extract %4[3] : f32 from vector<4xf32>
  %25 = vector.splat %24 : vector<1xf32>
  %26 = vector.fma %25, %12, %23 : vector<1xf32>
  %27 = vector.extract %26[0] : f32 from vector<1xf32>
  memref.store %27, %3[%c0, %workgroup_id_x] : memref<1x3xf32, #gpu.address_space<global>>
  return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main_dispatch_0_matmul_1x3x4_f32() {
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c2 = arith.constant 2 : index
  %c3 = arith.constant 3 : index
  %c64 = arith.constant 64 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<1x4xf32, #gpu.address_space<global>>
  memref.assume_alignment %0, 64 : memref<1x4xf32, #gpu.address_space<global>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<4x3xf32, #gpu.address_space<global>>
  memref.assume_alignment %1, 64 : memref<4x3xf32, #gpu.address_space<global>>
  %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
  memref.assume_alignment %2, 64 : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
  %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<1x3xf32, #gpu.address_space<global>>
  memref.assume_alignment %3, 64 : memref<1x3xf32, #gpu.address_space<global>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %4 = vector.load %0[%c0, %c0] : memref<1x4xf32, #gpu.address_space<global>>, vector<4xf32>
  %5 = memref.load %1[%c0, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
  %6 = vector.broadcast %5 : f32 to vector<1xf32>
  %7 = memref.load %1[%c1, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
  %8 = vector.broadcast %7 : f32 to vector<1xf32>
  %9 = memref.load %1[%c2, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
  %10 = vector.broadcast %9 : f32 to vector<1xf32>
  %11 = memref.load %1[%c3, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
  %12 = vector.broadcast %11 : f32 to vector<1xf32>
  %13 = memref.load %2[%c0, %workgroup_id_x] : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
  %14 = vector.broadcast %13 : f32 to vector<1xf32>
  %15 = vector.extract %4[0] : f32 from vector<4xf32>
  %16 = vector.splat %15 : vector<1xf32>
  %17 = vector.fma %16, %6, %14 : vector<1xf32>
  %18 = vector.extract %4[1] : f32 from vector<4xf32>
  %19 = vector.splat %18 : vector<1xf32>
  %20 = vector.fma %19, %8, %17 : vector<1xf32>
  %21 = vector.extract %4[2] : f32 from vector<4xf32>
  %22 = vector.splat %21 : vector<1xf32>
  %23 = vector.fma %22, %10, %20 : vector<1xf32>
  %24 = vector.extract %4[3] : f32 from vector<4xf32>
  %25 = vector.splat %24 : vector<1xf32>
  %26 = vector.fma %25, %12, %23 : vector<1xf32>
  %27 = vector.extract %26[0] : f32 from vector<1xf32>
  memref.store %27, %3[%c0, %workgroup_id_x] : memref<1x3xf32, #gpu.address_space<global>>
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @main_dispatch_0_matmul_1x3x4_f32() {
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c2 = arith.constant 2 : index
  %c3 = arith.constant 3 : index
  %c64 = arith.constant 64 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<1x4xf32, #gpu.address_space<global>>
  memref.assume_alignment %0, 64 : memref<1x4xf32, #gpu.address_space<global>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<4x3xf32, #gpu.address_space<global>>
  memref.assume_alignment %1, 64 : memref<4x3xf32, #gpu.address_space<global>>
  %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
  memref.assume_alignment %2, 64 : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
  %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<1x3xf32, #gpu.address_space<global>>
  memref.assume_alignment %3, 64 : memref<1x3xf32, #gpu.address_space<global>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %4 = vector.load %0[%c0, %c0] : memref<1x4xf32, #gpu.address_space<global>>, vector<4xf32>
  %5 = memref.load %1[%c0, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
  %6 = vector.broadcast %5 : f32 to vector<1xf32>
  %7 = memref.load %1[%c1, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
  %8 = vector.broadcast %7 : f32 to vector<1xf32>
  %9 = memref.load %1[%c2, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
  %10 = vector.broadcast %9 : f32 to vector<1xf32>
  %11 = memref.load %1[%c3, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
  %12 = vector.broadcast %11 : f32 to vector<1xf32>
  %13 = memref.load %2[%c0, %workgroup_id_x] : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
  %14 = vector.broadcast %13 : f32 to vector<1xf32>
  %15 = vector.extract %4[0] : f32 from vector<4xf32>
  %16 = vector.splat %15 : vector<1xf32>
  %17 = vector.fma %16, %6, %14 : vector<1xf32>
  %18 = vector.extract %4[1] : f32 from vector<4xf32>
  %19 = vector.splat %18 : vector<1xf32>
  %20 = vector.fma %19, %8, %17 : vector<1xf32>
  %21 = vector.extract %4[2] : f32 from vector<4xf32>
  %22 = vector.splat %21 : vector<1xf32>
  %23 = vector.fma %22, %10, %20 : vector<1xf32>
  %24 = vector.extract %4[3] : f32 from vector<4xf32>
  %25 = vector.splat %24 : vector<1xf32>
  %26 = vector.fma %25, %12, %23 : vector<1xf32>
  %27 = vector.extract %26[0] : f32 from vector<1xf32>
  memref.store %27, %3[%c0, %workgroup_id_x] : memref<1x3xf32, #gpu.address_space<global>>
  return
}

// -----// IR Dump After ConvertComplexToStandard (convert-complex-to-standard) //----- //
module {
  func.func @main_dispatch_0_matmul_1x3x4_f32() {
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c2 = arith.constant 2 : index
    %c3 = arith.constant 3 : index
    %c64 = arith.constant 64 : index
    %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<1x4xf32, #gpu.address_space<global>>
    memref.assume_alignment %0, 64 : memref<1x4xf32, #gpu.address_space<global>>
    %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<4x3xf32, #gpu.address_space<global>>
    memref.assume_alignment %1, 64 : memref<4x3xf32, #gpu.address_space<global>>
    %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
    memref.assume_alignment %2, 64 : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
    %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<1x3xf32, #gpu.address_space<global>>
    memref.assume_alignment %3, 64 : memref<1x3xf32, #gpu.address_space<global>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %4 = vector.load %0[%c0, %c0] : memref<1x4xf32, #gpu.address_space<global>>, vector<4xf32>
    %5 = memref.load %1[%c0, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
    %6 = vector.broadcast %5 : f32 to vector<1xf32>
    %7 = memref.load %1[%c1, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
    %8 = vector.broadcast %7 : f32 to vector<1xf32>
    %9 = memref.load %1[%c2, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
    %10 = vector.broadcast %9 : f32 to vector<1xf32>
    %11 = memref.load %1[%c3, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
    %12 = vector.broadcast %11 : f32 to vector<1xf32>
    %13 = memref.load %2[%c0, %workgroup_id_x] : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
    %14 = vector.broadcast %13 : f32 to vector<1xf32>
    %15 = vector.extract %4[0] : f32 from vector<4xf32>
    %16 = vector.splat %15 : vector<1xf32>
    %17 = vector.fma %16, %6, %14 : vector<1xf32>
    %18 = vector.extract %4[1] : f32 from vector<4xf32>
    %19 = vector.splat %18 : vector<1xf32>
    %20 = vector.fma %19, %8, %17 : vector<1xf32>
    %21 = vector.extract %4[2] : f32 from vector<4xf32>
    %22 = vector.splat %21 : vector<1xf32>
    %23 = vector.fma %22, %10, %20 : vector<1xf32>
    %24 = vector.extract %4[3] : f32 from vector<4xf32>
    %25 = vector.splat %24 : vector<1xf32>
    %26 = vector.fma %25, %12, %23 : vector<1xf32>
    %27 = vector.extract %26[0] : f32 from vector<1xf32>
    memref.store %27, %3[%c0, %workgroup_id_x] : memref<1x3xf32, #gpu.address_space<global>>
    return
  }
}

// -----// IR Dump After ConvertBf16ArithToF32 (iree-convert-bf16-arith-to-f32) //----- //
module {
  func.func @main_dispatch_0_matmul_1x3x4_f32() {
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c2 = arith.constant 2 : index
    %c3 = arith.constant 3 : index
    %c64 = arith.constant 64 : index
    %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<1x4xf32, #gpu.address_space<global>>
    memref.assume_alignment %0, 64 : memref<1x4xf32, #gpu.address_space<global>>
    %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<4x3xf32, #gpu.address_space<global>>
    memref.assume_alignment %1, 64 : memref<4x3xf32, #gpu.address_space<global>>
    %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
    memref.assume_alignment %2, 64 : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
    %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<1x3xf32, #gpu.address_space<global>>
    memref.assume_alignment %3, 64 : memref<1x3xf32, #gpu.address_space<global>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %4 = vector.load %0[%c0, %c0] : memref<1x4xf32, #gpu.address_space<global>>, vector<4xf32>
    %5 = memref.load %1[%c0, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
    %6 = vector.broadcast %5 : f32 to vector<1xf32>
    %7 = memref.load %1[%c1, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
    %8 = vector.broadcast %7 : f32 to vector<1xf32>
    %9 = memref.load %1[%c2, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
    %10 = vector.broadcast %9 : f32 to vector<1xf32>
    %11 = memref.load %1[%c3, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
    %12 = vector.broadcast %11 : f32 to vector<1xf32>
    %13 = memref.load %2[%c0, %workgroup_id_x] : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
    %14 = vector.broadcast %13 : f32 to vector<1xf32>
    %15 = vector.extract %4[0] : f32 from vector<4xf32>
    %16 = vector.splat %15 : vector<1xf32>
    %17 = vector.fma %16, %6, %14 : vector<1xf32>
    %18 = vector.extract %4[1] : f32 from vector<4xf32>
    %19 = vector.splat %18 : vector<1xf32>
    %20 = vector.fma %19, %8, %17 : vector<1xf32>
    %21 = vector.extract %4[2] : f32 from vector<4xf32>
    %22 = vector.splat %21 : vector<1xf32>
    %23 = vector.fma %22, %10, %20 : vector<1xf32>
    %24 = vector.extract %4[3] : f32 from vector<4xf32>
    %25 = vector.splat %24 : vector<1xf32>
    %26 = vector.fma %25, %12, %23 : vector<1xf32>
    %27 = vector.extract %26[0] : f32 from vector<1xf32>
    memref.store %27, %3[%c0, %workgroup_id_x] : memref<1x3xf32, #gpu.address_space<global>>
    return
  }
}

// -----// IR Dump After ConvertBf16ToUInt16Buffers (iree-convert-bf16-to-uint16-buffers) //----- //
module {
  func.func @main_dispatch_0_matmul_1x3x4_f32() {
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c2 = arith.constant 2 : index
    %c3 = arith.constant 3 : index
    %c64 = arith.constant 64 : index
    %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<1x4xf32, #gpu.address_space<global>>
    memref.assume_alignment %0, 64 : memref<1x4xf32, #gpu.address_space<global>>
    %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<4x3xf32, #gpu.address_space<global>>
    memref.assume_alignment %1, 64 : memref<4x3xf32, #gpu.address_space<global>>
    %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
    memref.assume_alignment %2, 64 : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
    %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<1x3xf32, #gpu.address_space<global>>
    memref.assume_alignment %3, 64 : memref<1x3xf32, #gpu.address_space<global>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %4 = vector.load %0[%c0, %c0] : memref<1x4xf32, #gpu.address_space<global>>, vector<4xf32>
    %5 = memref.load %1[%c0, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
    %6 = vector.broadcast %5 : f32 to vector<1xf32>
    %7 = memref.load %1[%c1, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
    %8 = vector.broadcast %7 : f32 to vector<1xf32>
    %9 = memref.load %1[%c2, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
    %10 = vector.broadcast %9 : f32 to vector<1xf32>
    %11 = memref.load %1[%c3, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
    %12 = vector.broadcast %11 : f32 to vector<1xf32>
    %13 = memref.load %2[%c0, %workgroup_id_x] : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
    %14 = vector.broadcast %13 : f32 to vector<1xf32>
    %15 = vector.extract %4[0] : f32 from vector<4xf32>
    %16 = vector.splat %15 : vector<1xf32>
    %17 = vector.fma %16, %6, %14 : vector<1xf32>
    %18 = vector.extract %4[1] : f32 from vector<4xf32>
    %19 = vector.splat %18 : vector<1xf32>
    %20 = vector.fma %19, %8, %17 : vector<1xf32>
    %21 = vector.extract %4[2] : f32 from vector<4xf32>
    %22 = vector.splat %21 : vector<1xf32>
    %23 = vector.fma %22, %10, %20 : vector<1xf32>
    %24 = vector.extract %4[3] : f32 from vector<4xf32>
    %25 = vector.splat %24 : vector<1xf32>
    %26 = vector.fma %25, %12, %23 : vector<1xf32>
    %27 = vector.extract %26[0] : f32 from vector<1xf32>
    memref.store %27, %3[%c0, %workgroup_id_x] : memref<1x3xf32, #gpu.address_space<global>>
    return
  }
}

// -----// IR Dump After ArithExpandOpsPass (arith-expand) //----- //
func.func @main_dispatch_0_matmul_1x3x4_f32() {
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c2 = arith.constant 2 : index
  %c3 = arith.constant 3 : index
  %c64 = arith.constant 64 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<1x4xf32, #gpu.address_space<global>>
  memref.assume_alignment %0, 64 : memref<1x4xf32, #gpu.address_space<global>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<4x3xf32, #gpu.address_space<global>>
  memref.assume_alignment %1, 64 : memref<4x3xf32, #gpu.address_space<global>>
  %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
  memref.assume_alignment %2, 64 : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
  %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<1x3xf32, #gpu.address_space<global>>
  memref.assume_alignment %3, 64 : memref<1x3xf32, #gpu.address_space<global>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %4 = vector.load %0[%c0, %c0] : memref<1x4xf32, #gpu.address_space<global>>, vector<4xf32>
  %5 = memref.load %1[%c0, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
  %6 = vector.broadcast %5 : f32 to vector<1xf32>
  %7 = memref.load %1[%c1, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
  %8 = vector.broadcast %7 : f32 to vector<1xf32>
  %9 = memref.load %1[%c2, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
  %10 = vector.broadcast %9 : f32 to vector<1xf32>
  %11 = memref.load %1[%c3, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
  %12 = vector.broadcast %11 : f32 to vector<1xf32>
  %13 = memref.load %2[%c0, %workgroup_id_x] : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
  %14 = vector.broadcast %13 : f32 to vector<1xf32>
  %15 = vector.extract %4[0] : f32 from vector<4xf32>
  %16 = vector.splat %15 : vector<1xf32>
  %17 = vector.fma %16, %6, %14 : vector<1xf32>
  %18 = vector.extract %4[1] : f32 from vector<4xf32>
  %19 = vector.splat %18 : vector<1xf32>
  %20 = vector.fma %19, %8, %17 : vector<1xf32>
  %21 = vector.extract %4[2] : f32 from vector<4xf32>
  %22 = vector.splat %21 : vector<1xf32>
  %23 = vector.fma %22, %10, %20 : vector<1xf32>
  %24 = vector.extract %4[3] : f32 from vector<4xf32>
  %25 = vector.splat %24 : vector<1xf32>
  %26 = vector.fma %25, %12, %23 : vector<1xf32>
  %27 = vector.extract %26[0] : f32 from vector<1xf32>
  memref.store %27, %3[%c0, %workgroup_id_x] : memref<1x3xf32, #gpu.address_space<global>>
  return
}

// -----// IR Dump After PolynomialApproximationPass (iree-codegen-polynomial-approximation) //----- //
func.func @main_dispatch_0_matmul_1x3x4_f32() {
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c2 = arith.constant 2 : index
  %c3 = arith.constant 3 : index
  %c64 = arith.constant 64 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<1x4xf32, #gpu.address_space<global>>
  memref.assume_alignment %0, 64 : memref<1x4xf32, #gpu.address_space<global>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<4x3xf32, #gpu.address_space<global>>
  memref.assume_alignment %1, 64 : memref<4x3xf32, #gpu.address_space<global>>
  %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
  memref.assume_alignment %2, 64 : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
  %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<1x3xf32, #gpu.address_space<global>>
  memref.assume_alignment %3, 64 : memref<1x3xf32, #gpu.address_space<global>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %4 = vector.load %0[%c0, %c0] : memref<1x4xf32, #gpu.address_space<global>>, vector<4xf32>
  %5 = memref.load %1[%c0, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
  %6 = vector.broadcast %5 : f32 to vector<1xf32>
  %7 = memref.load %1[%c1, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
  %8 = vector.broadcast %7 : f32 to vector<1xf32>
  %9 = memref.load %1[%c2, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
  %10 = vector.broadcast %9 : f32 to vector<1xf32>
  %11 = memref.load %1[%c3, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
  %12 = vector.broadcast %11 : f32 to vector<1xf32>
  %13 = memref.load %2[%c0, %workgroup_id_x] : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
  %14 = vector.broadcast %13 : f32 to vector<1xf32>
  %15 = vector.extract %4[0] : f32 from vector<4xf32>
  %16 = vector.splat %15 : vector<1xf32>
  %17 = vector.fma %16, %6, %14 : vector<1xf32>
  %18 = vector.extract %4[1] : f32 from vector<4xf32>
  %19 = vector.splat %18 : vector<1xf32>
  %20 = vector.fma %19, %8, %17 : vector<1xf32>
  %21 = vector.extract %4[2] : f32 from vector<4xf32>
  %22 = vector.splat %21 : vector<1xf32>
  %23 = vector.fma %22, %10, %20 : vector<1xf32>
  %24 = vector.extract %4[3] : f32 from vector<4xf32>
  %25 = vector.splat %24 : vector<1xf32>
  %26 = vector.fma %25, %12, %23 : vector<1xf32>
  %27 = vector.extract %26[0] : f32 from vector<1xf32>
  memref.store %27, %3[%c0, %workgroup_id_x] : memref<1x3xf32, #gpu.address_space<global>>
  return
}

// -----// IR Dump After ExpandOps (memref-expand) //----- //
func.func @main_dispatch_0_matmul_1x3x4_f32() {
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c2 = arith.constant 2 : index
  %c3 = arith.constant 3 : index
  %c64 = arith.constant 64 : index
  %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<1x4xf32, #gpu.address_space<global>>
  memref.assume_alignment %0, 64 : memref<1x4xf32, #gpu.address_space<global>>
  %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<4x3xf32, #gpu.address_space<global>>
  memref.assume_alignment %1, 64 : memref<4x3xf32, #gpu.address_space<global>>
  %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
  memref.assume_alignment %2, 64 : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
  %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<1x3xf32, #gpu.address_space<global>>
  memref.assume_alignment %3, 64 : memref<1x3xf32, #gpu.address_space<global>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %4 = vector.load %0[%c0, %c0] : memref<1x4xf32, #gpu.address_space<global>>, vector<4xf32>
  %5 = memref.load %1[%c0, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
  %6 = vector.broadcast %5 : f32 to vector<1xf32>
  %7 = memref.load %1[%c1, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
  %8 = vector.broadcast %7 : f32 to vector<1xf32>
  %9 = memref.load %1[%c2, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
  %10 = vector.broadcast %9 : f32 to vector<1xf32>
  %11 = memref.load %1[%c3, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
  %12 = vector.broadcast %11 : f32 to vector<1xf32>
  %13 = memref.load %2[%c0, %workgroup_id_x] : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
  %14 = vector.broadcast %13 : f32 to vector<1xf32>
  %15 = vector.extract %4[0] : f32 from vector<4xf32>
  %16 = vector.splat %15 : vector<1xf32>
  %17 = vector.fma %16, %6, %14 : vector<1xf32>
  %18 = vector.extract %4[1] : f32 from vector<4xf32>
  %19 = vector.splat %18 : vector<1xf32>
  %20 = vector.fma %19, %8, %17 : vector<1xf32>
  %21 = vector.extract %4[2] : f32 from vector<4xf32>
  %22 = vector.splat %21 : vector<1xf32>
  %23 = vector.fma %22, %10, %20 : vector<1xf32>
  %24 = vector.extract %4[3] : f32 from vector<4xf32>
  %25 = vector.splat %24 : vector<1xf32>
  %26 = vector.fma %25, %12, %23 : vector<1xf32>
  %27 = vector.extract %26[0] : f32 from vector<1xf32>
  memref.store %27, %3[%c0, %workgroup_id_x] : memref<1x3xf32, #gpu.address_space<global>>
  return
}

// -----// IR Dump After FoldMemRefAliasOps (fold-memref-alias-ops) //----- //
module {
  func.func @main_dispatch_0_matmul_1x3x4_f32() {
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c2 = arith.constant 2 : index
    %c3 = arith.constant 3 : index
    %c64 = arith.constant 64 : index
    %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<1x4xf32, #gpu.address_space<global>>
    memref.assume_alignment %0, 64 : memref<1x4xf32, #gpu.address_space<global>>
    %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<4x3xf32, #gpu.address_space<global>>
    memref.assume_alignment %1, 64 : memref<4x3xf32, #gpu.address_space<global>>
    %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
    memref.assume_alignment %2, 64 : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
    %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<1x3xf32, #gpu.address_space<global>>
    memref.assume_alignment %3, 64 : memref<1x3xf32, #gpu.address_space<global>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %4 = vector.load %0[%c0, %c0] : memref<1x4xf32, #gpu.address_space<global>>, vector<4xf32>
    %5 = memref.load %1[%c0, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
    %6 = vector.broadcast %5 : f32 to vector<1xf32>
    %7 = memref.load %1[%c1, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
    %8 = vector.broadcast %7 : f32 to vector<1xf32>
    %9 = memref.load %1[%c2, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
    %10 = vector.broadcast %9 : f32 to vector<1xf32>
    %11 = memref.load %1[%c3, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
    %12 = vector.broadcast %11 : f32 to vector<1xf32>
    %13 = memref.load %2[%c0, %workgroup_id_x] : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
    %14 = vector.broadcast %13 : f32 to vector<1xf32>
    %15 = vector.extract %4[0] : f32 from vector<4xf32>
    %16 = vector.splat %15 : vector<1xf32>
    %17 = vector.fma %16, %6, %14 : vector<1xf32>
    %18 = vector.extract %4[1] : f32 from vector<4xf32>
    %19 = vector.splat %18 : vector<1xf32>
    %20 = vector.fma %19, %8, %17 : vector<1xf32>
    %21 = vector.extract %4[2] : f32 from vector<4xf32>
    %22 = vector.splat %21 : vector<1xf32>
    %23 = vector.fma %22, %10, %20 : vector<1xf32>
    %24 = vector.extract %4[3] : f32 from vector<4xf32>
    %25 = vector.splat %24 : vector<1xf32>
    %26 = vector.fma %25, %12, %23 : vector<1xf32>
    %27 = vector.extract %26[0] : f32 from vector<1xf32>
    memref.store %27, %3[%c0, %workgroup_id_x] : memref<1x3xf32, #gpu.address_space<global>>
    return
  }
}

// -----// IR Dump After ExpandStridedMetadata (expand-strided-metadata) //----- //
module {
  func.func @main_dispatch_0_matmul_1x3x4_f32() {
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c2 = arith.constant 2 : index
    %c3 = arith.constant 3 : index
    %c64 = arith.constant 64 : index
    %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<1x4xf32, #gpu.address_space<global>>
    memref.assume_alignment %0, 64 : memref<1x4xf32, #gpu.address_space<global>>
    %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<4x3xf32, #gpu.address_space<global>>
    memref.assume_alignment %1, 64 : memref<4x3xf32, #gpu.address_space<global>>
    %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
    memref.assume_alignment %2, 64 : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
    %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<1x3xf32, #gpu.address_space<global>>
    memref.assume_alignment %3, 64 : memref<1x3xf32, #gpu.address_space<global>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %4 = vector.load %0[%c0, %c0] : memref<1x4xf32, #gpu.address_space<global>>, vector<4xf32>
    %5 = memref.load %1[%c0, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
    %6 = vector.broadcast %5 : f32 to vector<1xf32>
    %7 = memref.load %1[%c1, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
    %8 = vector.broadcast %7 : f32 to vector<1xf32>
    %9 = memref.load %1[%c2, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
    %10 = vector.broadcast %9 : f32 to vector<1xf32>
    %11 = memref.load %1[%c3, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
    %12 = vector.broadcast %11 : f32 to vector<1xf32>
    %13 = memref.load %2[%c0, %workgroup_id_x] : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
    %14 = vector.broadcast %13 : f32 to vector<1xf32>
    %15 = vector.extract %4[0] : f32 from vector<4xf32>
    %16 = vector.splat %15 : vector<1xf32>
    %17 = vector.fma %16, %6, %14 : vector<1xf32>
    %18 = vector.extract %4[1] : f32 from vector<4xf32>
    %19 = vector.splat %18 : vector<1xf32>
    %20 = vector.fma %19, %8, %17 : vector<1xf32>
    %21 = vector.extract %4[2] : f32 from vector<4xf32>
    %22 = vector.splat %21 : vector<1xf32>
    %23 = vector.fma %22, %10, %20 : vector<1xf32>
    %24 = vector.extract %4[3] : f32 from vector<4xf32>
    %25 = vector.splat %24 : vector<1xf32>
    %26 = vector.fma %25, %12, %23 : vector<1xf32>
    %27 = vector.extract %26[0] : f32 from vector<1xf32>
    memref.store %27, %3[%c0, %workgroup_id_x] : memref<1x3xf32, #gpu.address_space<global>>
    return
  }
}

// -----// IR Dump After EmulateNarrowType (iree-codegen-emulate-narrow-type) //----- //
module {
  func.func @main_dispatch_0_matmul_1x3x4_f32() {
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c2 = arith.constant 2 : index
    %c3 = arith.constant 3 : index
    %c64 = arith.constant 64 : index
    %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<1x4xf32, #gpu.address_space<global>>
    memref.assume_alignment %0, 64 : memref<1x4xf32, #gpu.address_space<global>>
    %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<4x3xf32, #gpu.address_space<global>>
    memref.assume_alignment %1, 64 : memref<4x3xf32, #gpu.address_space<global>>
    %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
    memref.assume_alignment %2, 64 : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
    %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<1x3xf32, #gpu.address_space<global>>
    memref.assume_alignment %3, 64 : memref<1x3xf32, #gpu.address_space<global>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %4 = vector.load %0[%c0, %c0] : memref<1x4xf32, #gpu.address_space<global>>, vector<4xf32>
    %5 = memref.load %1[%c0, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
    %6 = vector.broadcast %5 : f32 to vector<1xf32>
    %7 = memref.load %1[%c1, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
    %8 = vector.broadcast %7 : f32 to vector<1xf32>
    %9 = memref.load %1[%c2, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
    %10 = vector.broadcast %9 : f32 to vector<1xf32>
    %11 = memref.load %1[%c3, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
    %12 = vector.broadcast %11 : f32 to vector<1xf32>
    %13 = memref.load %2[%c0, %workgroup_id_x] : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
    %14 = vector.broadcast %13 : f32 to vector<1xf32>
    %15 = vector.extract %4[0] : f32 from vector<4xf32>
    %16 = vector.splat %15 : vector<1xf32>
    %17 = vector.fma %16, %6, %14 : vector<1xf32>
    %18 = vector.extract %4[1] : f32 from vector<4xf32>
    %19 = vector.splat %18 : vector<1xf32>
    %20 = vector.fma %19, %8, %17 : vector<1xf32>
    %21 = vector.extract %4[2] : f32 from vector<4xf32>
    %22 = vector.splat %21 : vector<1xf32>
    %23 = vector.fma %22, %10, %20 : vector<1xf32>
    %24 = vector.extract %4[3] : f32 from vector<4xf32>
    %25 = vector.splat %24 : vector<1xf32>
    %26 = vector.fma %25, %12, %23 : vector<1xf32>
    %27 = vector.extract %26[0] : f32 from vector<1xf32>
    memref.store %27, %3[%c0, %workgroup_id_x] : memref<1x3xf32, #gpu.address_space<global>>
    return
  }
}

// -----// IR Dump After ConvertAffineToStandard (lower-affine) //----- //
module {
  func.func @main_dispatch_0_matmul_1x3x4_f32() {
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c2 = arith.constant 2 : index
    %c3 = arith.constant 3 : index
    %c64 = arith.constant 64 : index
    %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<1x4xf32, #gpu.address_space<global>>
    memref.assume_alignment %0, 64 : memref<1x4xf32, #gpu.address_space<global>>
    %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<4x3xf32, #gpu.address_space<global>>
    memref.assume_alignment %1, 64 : memref<4x3xf32, #gpu.address_space<global>>
    %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
    memref.assume_alignment %2, 64 : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
    %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<1x3xf32, #gpu.address_space<global>>
    memref.assume_alignment %3, 64 : memref<1x3xf32, #gpu.address_space<global>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %4 = vector.load %0[%c0, %c0] : memref<1x4xf32, #gpu.address_space<global>>, vector<4xf32>
    %5 = memref.load %1[%c0, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
    %6 = vector.broadcast %5 : f32 to vector<1xf32>
    %7 = memref.load %1[%c1, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
    %8 = vector.broadcast %7 : f32 to vector<1xf32>
    %9 = memref.load %1[%c2, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
    %10 = vector.broadcast %9 : f32 to vector<1xf32>
    %11 = memref.load %1[%c3, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
    %12 = vector.broadcast %11 : f32 to vector<1xf32>
    %13 = memref.load %2[%c0, %workgroup_id_x] : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
    %14 = vector.broadcast %13 : f32 to vector<1xf32>
    %15 = vector.extract %4[0] : f32 from vector<4xf32>
    %16 = vector.splat %15 : vector<1xf32>
    %17 = vector.fma %16, %6, %14 : vector<1xf32>
    %18 = vector.extract %4[1] : f32 from vector<4xf32>
    %19 = vector.splat %18 : vector<1xf32>
    %20 = vector.fma %19, %8, %17 : vector<1xf32>
    %21 = vector.extract %4[2] : f32 from vector<4xf32>
    %22 = vector.splat %21 : vector<1xf32>
    %23 = vector.fma %22, %10, %20 : vector<1xf32>
    %24 = vector.extract %4[3] : f32 from vector<4xf32>
    %25 = vector.splat %24 : vector<1xf32>
    %26 = vector.fma %25, %12, %23 : vector<1xf32>
    %27 = vector.extract %26[0] : f32 from vector<1xf32>
    memref.store %27, %3[%c0, %workgroup_id_x] : memref<1x3xf32, #gpu.address_space<global>>
    return
  }
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
module {
  func.func @main_dispatch_0_matmul_1x3x4_f32() {
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c2 = arith.constant 2 : index
    %c3 = arith.constant 3 : index
    %c64 = arith.constant 64 : index
    %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<1x4xf32, #gpu.address_space<global>>
    memref.assume_alignment %0, 64 : memref<1x4xf32, #gpu.address_space<global>>
    %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<4x3xf32, #gpu.address_space<global>>
    memref.assume_alignment %1, 64 : memref<4x3xf32, #gpu.address_space<global>>
    %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
    memref.assume_alignment %2, 64 : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
    %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<1x3xf32, #gpu.address_space<global>>
    memref.assume_alignment %3, 64 : memref<1x3xf32, #gpu.address_space<global>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %4 = vector.load %0[%c0, %c0] : memref<1x4xf32, #gpu.address_space<global>>, vector<4xf32>
    %5 = memref.load %1[%c0, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
    %6 = vector.broadcast %5 : f32 to vector<1xf32>
    %7 = memref.load %1[%c1, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
    %8 = vector.broadcast %7 : f32 to vector<1xf32>
    %9 = memref.load %1[%c2, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
    %10 = vector.broadcast %9 : f32 to vector<1xf32>
    %11 = memref.load %1[%c3, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
    %12 = vector.broadcast %11 : f32 to vector<1xf32>
    %13 = memref.load %2[%c0, %workgroup_id_x] : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
    %14 = vector.broadcast %13 : f32 to vector<1xf32>
    %15 = vector.extract %4[0] : f32 from vector<4xf32>
    %16 = vector.splat %15 : vector<1xf32>
    %17 = vector.fma %16, %6, %14 : vector<1xf32>
    %18 = vector.extract %4[1] : f32 from vector<4xf32>
    %19 = vector.splat %18 : vector<1xf32>
    %20 = vector.fma %19, %8, %17 : vector<1xf32>
    %21 = vector.extract %4[2] : f32 from vector<4xf32>
    %22 = vector.splat %21 : vector<1xf32>
    %23 = vector.fma %22, %10, %20 : vector<1xf32>
    %24 = vector.extract %4[3] : f32 from vector<4xf32>
    %25 = vector.splat %24 : vector<1xf32>
    %26 = vector.fma %25, %12, %23 : vector<1xf32>
    %27 = vector.extract %26[0] : f32 from vector<1xf32>
    memref.store %27, %3[%c0, %workgroup_id_x] : memref<1x3xf32, #gpu.address_space<global>>
    return
  }
}

// -----// IR Dump After CSE (cse) //----- //
module {
  func.func @main_dispatch_0_matmul_1x3x4_f32() {
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c2 = arith.constant 2 : index
    %c3 = arith.constant 3 : index
    %c64 = arith.constant 64 : index
    %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<1x4xf32, #gpu.address_space<global>>
    memref.assume_alignment %0, 64 : memref<1x4xf32, #gpu.address_space<global>>
    %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<4x3xf32, #gpu.address_space<global>>
    memref.assume_alignment %1, 64 : memref<4x3xf32, #gpu.address_space<global>>
    %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
    memref.assume_alignment %2, 64 : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
    %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<1x3xf32, #gpu.address_space<global>>
    memref.assume_alignment %3, 64 : memref<1x3xf32, #gpu.address_space<global>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %4 = vector.load %0[%c0, %c0] : memref<1x4xf32, #gpu.address_space<global>>, vector<4xf32>
    %5 = memref.load %1[%c0, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
    %6 = vector.broadcast %5 : f32 to vector<1xf32>
    %7 = memref.load %1[%c1, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
    %8 = vector.broadcast %7 : f32 to vector<1xf32>
    %9 = memref.load %1[%c2, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
    %10 = vector.broadcast %9 : f32 to vector<1xf32>
    %11 = memref.load %1[%c3, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
    %12 = vector.broadcast %11 : f32 to vector<1xf32>
    %13 = memref.load %2[%c0, %workgroup_id_x] : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
    %14 = vector.broadcast %13 : f32 to vector<1xf32>
    %15 = vector.extract %4[0] : f32 from vector<4xf32>
    %16 = vector.splat %15 : vector<1xf32>
    %17 = vector.fma %16, %6, %14 : vector<1xf32>
    %18 = vector.extract %4[1] : f32 from vector<4xf32>
    %19 = vector.splat %18 : vector<1xf32>
    %20 = vector.fma %19, %8, %17 : vector<1xf32>
    %21 = vector.extract %4[2] : f32 from vector<4xf32>
    %22 = vector.splat %21 : vector<1xf32>
    %23 = vector.fma %22, %10, %20 : vector<1xf32>
    %24 = vector.extract %4[3] : f32 from vector<4xf32>
    %25 = vector.splat %24 : vector<1xf32>
    %26 = vector.fma %25, %12, %23 : vector<1xf32>
    %27 = vector.extract %26[0] : f32 from vector<1xf32>
    memref.store %27, %3[%c0, %workgroup_id_x] : memref<1x3xf32, #gpu.address_space<global>>
    return
  }
}

// -----// IR Dump After StripDebugInfo (strip-debuginfo) //----- //
module {
  func.func @main_dispatch_0_matmul_1x3x4_f32() {
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c2 = arith.constant 2 : index
    %c3 = arith.constant 3 : index
    %c64 = arith.constant 64 : index
    %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<1x4xf32, #gpu.address_space<global>>
    memref.assume_alignment %0, 64 : memref<1x4xf32, #gpu.address_space<global>>
    %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<4x3xf32, #gpu.address_space<global>>
    memref.assume_alignment %1, 64 : memref<4x3xf32, #gpu.address_space<global>>
    %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
    memref.assume_alignment %2, 64 : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
    %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<1x3xf32, #gpu.address_space<global>>
    memref.assume_alignment %3, 64 : memref<1x3xf32, #gpu.address_space<global>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %4 = vector.load %0[%c0, %c0] : memref<1x4xf32, #gpu.address_space<global>>, vector<4xf32>
    %5 = memref.load %1[%c0, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
    %6 = vector.broadcast %5 : f32 to vector<1xf32>
    %7 = memref.load %1[%c1, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
    %8 = vector.broadcast %7 : f32 to vector<1xf32>
    %9 = memref.load %1[%c2, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
    %10 = vector.broadcast %9 : f32 to vector<1xf32>
    %11 = memref.load %1[%c3, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
    %12 = vector.broadcast %11 : f32 to vector<1xf32>
    %13 = memref.load %2[%c0, %workgroup_id_x] : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
    %14 = vector.broadcast %13 : f32 to vector<1xf32>
    %15 = vector.extract %4[0] : f32 from vector<4xf32>
    %16 = vector.splat %15 : vector<1xf32>
    %17 = vector.fma %16, %6, %14 : vector<1xf32>
    %18 = vector.extract %4[1] : f32 from vector<4xf32>
    %19 = vector.splat %18 : vector<1xf32>
    %20 = vector.fma %19, %8, %17 : vector<1xf32>
    %21 = vector.extract %4[2] : f32 from vector<4xf32>
    %22 = vector.splat %21 : vector<1xf32>
    %23 = vector.fma %22, %10, %20 : vector<1xf32>
    %24 = vector.extract %4[3] : f32 from vector<4xf32>
    %25 = vector.splat %24 : vector<1xf32>
    %26 = vector.fma %25, %12, %23 : vector<1xf32>
    %27 = vector.extract %26[0] : f32 from vector<1xf32>
    memref.store %27, %3[%c0, %workgroup_id_x] : memref<1x3xf32, #gpu.address_space<global>>
    return
  }
}

// -----// IR Dump After LLVMGPUCastAddressSpaceFunction (iree-llvmgpu-cast-address-space-function) //----- //
module {
  func.func @main_dispatch_0_matmul_1x3x4_f32() {
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c2 = arith.constant 2 : index
    %c3 = arith.constant 3 : index
    %c64 = arith.constant 64 : index
    %0 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<1x4xf32, #gpu.address_space<global>>
    memref.assume_alignment %0, 64 : memref<1x4xf32, #gpu.address_space<global>>
    %1 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<4x3xf32, #gpu.address_space<global>>
    memref.assume_alignment %1, 64 : memref<4x3xf32, #gpu.address_space<global>>
    %2 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c64) flags(ReadOnly) : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
    memref.assume_alignment %2, 64 : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
    %3 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<1x3xf32, #gpu.address_space<global>>
    memref.assume_alignment %3, 64 : memref<1x3xf32, #gpu.address_space<global>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %4 = vector.load %0[%c0, %c0] : memref<1x4xf32, #gpu.address_space<global>>, vector<4xf32>
    %5 = memref.load %1[%c0, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
    %6 = vector.broadcast %5 : f32 to vector<1xf32>
    %7 = memref.load %1[%c1, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
    %8 = vector.broadcast %7 : f32 to vector<1xf32>
    %9 = memref.load %1[%c2, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
    %10 = vector.broadcast %9 : f32 to vector<1xf32>
    %11 = memref.load %1[%c3, %workgroup_id_x] : memref<4x3xf32, #gpu.address_space<global>>
    %12 = vector.broadcast %11 : f32 to vector<1xf32>
    %13 = memref.load %2[%c0, %workgroup_id_x] : memref<1x3xf32, strided<[3, 1], offset: 16>, #gpu.address_space<global>>
    %14 = vector.broadcast %13 : f32 to vector<1xf32>
    %15 = vector.extract %4[0] : f32 from vector<4xf32>
    %16 = vector.splat %15 : vector<1xf32>
    %17 = vector.fma %16, %6, %14 : vector<1xf32>
    %18 = vector.extract %4[1] : f32 from vector<4xf32>
    %19 = vector.splat %18 : vector<1xf32>
    %20 = vector.fma %19, %8, %17 : vector<1xf32>
    %21 = vector.extract %4[2] : f32 from vector<4xf32>
    %22 = vector.splat %21 : vector<1xf32>
    %23 = vector.fma %22, %10, %20 : vector<1xf32>
    %24 = vector.extract %4[3] : f32 from vector<4xf32>
    %25 = vector.splat %24 : vector<1xf32>
    %26 = vector.fma %25, %12, %23 : vector<1xf32>
    %27 = vector.extract %26[0] : f32 from vector<1xf32>
    memref.store %27, %3[%c0, %workgroup_id_x] : memref<1x3xf32, #gpu.address_space<global>>
    return
  }
}

// -----// IR Dump After ConvertToNVVM (iree-convert-to-nvvm) //----- //
module {
  llvm.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg2: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias}) {
    %0 = llvm.mlir.constant(3 : i64) : i64
    %1 = llvm.mlir.constant(2 : i64) : i64
    %2 = llvm.mlir.constant(1 : i64) : i64
    %3 = llvm.mlir.constant(0 : i64) : i64
    %4 = llvm.mlir.constant(0 : i32) : i32
    %5 = llvm.mlir.constant(63 : index) : i64
    %6 = llvm.mlir.constant(4 : index) : i64
    %7 = llvm.mlir.constant(0 : index) : i64
    %8 = llvm.mlir.constant(1 : index) : i64
    %9 = llvm.mlir.constant(2 : index) : i64
    %10 = llvm.mlir.constant(3 : index) : i64
    %11 = llvm.ptrtoint %arg0 : !llvm.ptr<1> to i64
    %12 = llvm.and %11, %5  : i64
    %13 = llvm.icmp "eq" %12, %7 : i64
    "llvm.intr.assume"(%13) : (i1) -> ()
    %14 = llvm.ptrtoint %arg1 : !llvm.ptr<1> to i64
    %15 = llvm.and %14, %5  : i64
    %16 = llvm.icmp "eq" %15, %7 : i64
    "llvm.intr.assume"(%16) : (i1) -> ()
    %17 = llvm.getelementptr %arg1[16] : (!llvm.ptr<1>) -> !llvm.ptr<1>, f32
    %18 = llvm.ptrtoint %17 : !llvm.ptr<1> to i64
    %19 = llvm.and %18, %5  : i64
    %20 = llvm.icmp "eq" %19, %7 : i64
    "llvm.intr.assume"(%20) : (i1) -> ()
    %21 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
    %22 = llvm.and %21, %5  : i64
    %23 = llvm.icmp "eq" %22, %7 : i64
    "llvm.intr.assume"(%23) : (i1) -> ()
    %24 = nvvm.read.ptx.sreg.ctaid.x : i32
    %25 = llvm.sext %24 : i32 to i64
    %26 = llvm.mul %7, %6  : i64
    %27 = llvm.add %26, %7  : i64
    %28 = llvm.getelementptr %arg0[%27] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
    %29 = llvm.load %28 {alignment = 4 : i64} : !llvm.ptr<1> -> vector<4xf32>
    %30 = llvm.mul %7, %10  : i64
    %31 = llvm.add %30, %25  : i64
    %32 = llvm.getelementptr %arg1[%31] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
    %33 = llvm.load %32 : !llvm.ptr<1> -> f32
    %34 = llvm.mlir.undef : vector<1xf32>
    %35 = llvm.insertelement %33, %34[%4 : i32] : vector<1xf32>
    %36 = llvm.shufflevector %35, %34 [0] : vector<1xf32> 
    %37 = llvm.mul %8, %10  : i64
    %38 = llvm.add %37, %25  : i64
    %39 = llvm.getelementptr %arg1[%38] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
    %40 = llvm.load %39 : !llvm.ptr<1> -> f32
    %41 = llvm.mlir.undef : vector<1xf32>
    %42 = llvm.insertelement %40, %41[%4 : i32] : vector<1xf32>
    %43 = llvm.shufflevector %42, %41 [0] : vector<1xf32> 
    %44 = llvm.mul %9, %10  : i64
    %45 = llvm.add %44, %25  : i64
    %46 = llvm.getelementptr %arg1[%45] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
    %47 = llvm.load %46 : !llvm.ptr<1> -> f32
    %48 = llvm.mlir.undef : vector<1xf32>
    %49 = llvm.insertelement %47, %48[%4 : i32] : vector<1xf32>
    %50 = llvm.shufflevector %49, %48 [0] : vector<1xf32> 
    %51 = llvm.mul %10, %10  : i64
    %52 = llvm.add %51, %25  : i64
    %53 = llvm.getelementptr %arg1[%52] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
    %54 = llvm.load %53 : !llvm.ptr<1> -> f32
    %55 = llvm.mlir.undef : vector<1xf32>
    %56 = llvm.insertelement %54, %55[%4 : i32] : vector<1xf32>
    %57 = llvm.shufflevector %56, %55 [0] : vector<1xf32> 
    %58 = llvm.getelementptr %arg1[16] : (!llvm.ptr<1>) -> !llvm.ptr<1>, f32
    %59 = llvm.mul %7, %10  : i64
    %60 = llvm.add %59, %25  : i64
    %61 = llvm.getelementptr %58[%60] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
    %62 = llvm.load %61 : !llvm.ptr<1> -> f32
    %63 = llvm.mlir.undef : vector<1xf32>
    %64 = llvm.insertelement %62, %63[%4 : i32] : vector<1xf32>
    %65 = llvm.shufflevector %64, %63 [0] : vector<1xf32> 
    %66 = llvm.extractelement %29[%3 : i64] : vector<4xf32>
    %67 = llvm.mlir.undef : vector<1xf32>
    %68 = llvm.insertelement %66, %67[%4 : i32] : vector<1xf32>
    %69 = llvm.shufflevector %68, %67 [0] : vector<1xf32> 
    %70 = llvm.intr.fmuladd(%69, %36, %65)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
    %71 = llvm.extractelement %29[%2 : i64] : vector<4xf32>
    %72 = llvm.mlir.undef : vector<1xf32>
    %73 = llvm.insertelement %71, %72[%4 : i32] : vector<1xf32>
    %74 = llvm.shufflevector %73, %72 [0] : vector<1xf32> 
    %75 = llvm.intr.fmuladd(%74, %43, %70)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
    %76 = llvm.extractelement %29[%1 : i64] : vector<4xf32>
    %77 = llvm.mlir.undef : vector<1xf32>
    %78 = llvm.insertelement %76, %77[%4 : i32] : vector<1xf32>
    %79 = llvm.shufflevector %78, %77 [0] : vector<1xf32> 
    %80 = llvm.intr.fmuladd(%79, %50, %75)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
    %81 = llvm.extractelement %29[%0 : i64] : vector<4xf32>
    %82 = llvm.mlir.undef : vector<1xf32>
    %83 = llvm.insertelement %81, %82[%4 : i32] : vector<1xf32>
    %84 = llvm.shufflevector %83, %82 [0] : vector<1xf32> 
    %85 = llvm.intr.fmuladd(%84, %57, %80)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
    %86 = llvm.extractelement %85[%3 : i64] : vector<1xf32>
    %87 = llvm.mul %7, %10  : i64
    %88 = llvm.add %87, %25  : i64
    %89 = llvm.getelementptr %arg2[%88] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
    llvm.store %86, %89 : f32, !llvm.ptr<1>
    llvm.return
  }
}

// -----// IR Dump After mlir::iree_compiler::IREE::HAL::TranslateTargetExecutableVariantsPass (iree-hal-translate-target-executable-variants) //----- //
hal.executable.variant public @cuda_nvptx_fb target(<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>) {
  hal.executable.export public @main_dispatch_0_matmul_1x3x4_f32 ordinal(0) layout(#hal.pipeline.layout<push_constants = 0, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>) attributes {translation_info = #iree_codegen.translation_info<LLVMGPUMatmulSimt>, workgroup_size = [1 : index, 3 : index, 1 : index]} {
  ^bb0(%arg0: !hal.device):
    %c3 = arith.constant 3 : index
    %c1 = arith.constant 1 : index
    hal.return %c3, %c1, %c1 : index, index, index
  }
  builtin.module {
    llvm.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg2: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias}) {
      %0 = llvm.mlir.constant(3 : i64) : i64
      %1 = llvm.mlir.constant(2 : i64) : i64
      %2 = llvm.mlir.constant(1 : i64) : i64
      %3 = llvm.mlir.constant(0 : i64) : i64
      %4 = llvm.mlir.constant(0 : i32) : i32
      %5 = llvm.mlir.constant(63 : index) : i64
      %6 = llvm.mlir.constant(4 : index) : i64
      %7 = llvm.mlir.constant(0 : index) : i64
      %8 = llvm.mlir.constant(1 : index) : i64
      %9 = llvm.mlir.constant(2 : index) : i64
      %10 = llvm.mlir.constant(3 : index) : i64
      %11 = llvm.ptrtoint %arg0 : !llvm.ptr<1> to i64
      %12 = llvm.and %11, %5  : i64
      %13 = llvm.icmp "eq" %12, %7 : i64
      "llvm.intr.assume"(%13) : (i1) -> ()
      %14 = llvm.ptrtoint %arg1 : !llvm.ptr<1> to i64
      %15 = llvm.and %14, %5  : i64
      %16 = llvm.icmp "eq" %15, %7 : i64
      "llvm.intr.assume"(%16) : (i1) -> ()
      %17 = llvm.getelementptr %arg1[16] : (!llvm.ptr<1>) -> !llvm.ptr<1>, f32
      %18 = llvm.ptrtoint %17 : !llvm.ptr<1> to i64
      %19 = llvm.and %18, %5  : i64
      %20 = llvm.icmp "eq" %19, %7 : i64
      "llvm.intr.assume"(%20) : (i1) -> ()
      %21 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
      %22 = llvm.and %21, %5  : i64
      %23 = llvm.icmp "eq" %22, %7 : i64
      "llvm.intr.assume"(%23) : (i1) -> ()
      %24 = nvvm.read.ptx.sreg.ctaid.x : i32
      %25 = llvm.sext %24 : i32 to i64
      %26 = llvm.mul %7, %6  : i64
      %27 = llvm.add %26, %7  : i64
      %28 = llvm.getelementptr %arg0[%27] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
      %29 = llvm.load %28 {alignment = 4 : i64} : !llvm.ptr<1> -> vector<4xf32>
      %30 = llvm.mul %7, %10  : i64
      %31 = llvm.add %30, %25  : i64
      %32 = llvm.getelementptr %arg1[%31] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
      %33 = llvm.load %32 : !llvm.ptr<1> -> f32
      %34 = llvm.mlir.undef : vector<1xf32>
      %35 = llvm.insertelement %33, %34[%4 : i32] : vector<1xf32>
      %36 = llvm.shufflevector %35, %34 [0] : vector<1xf32> 
      %37 = llvm.mul %8, %10  : i64
      %38 = llvm.add %37, %25  : i64
      %39 = llvm.getelementptr %arg1[%38] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
      %40 = llvm.load %39 : !llvm.ptr<1> -> f32
      %41 = llvm.mlir.undef : vector<1xf32>
      %42 = llvm.insertelement %40, %41[%4 : i32] : vector<1xf32>
      %43 = llvm.shufflevector %42, %41 [0] : vector<1xf32> 
      %44 = llvm.mul %9, %10  : i64
      %45 = llvm.add %44, %25  : i64
      %46 = llvm.getelementptr %arg1[%45] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
      %47 = llvm.load %46 : !llvm.ptr<1> -> f32
      %48 = llvm.mlir.undef : vector<1xf32>
      %49 = llvm.insertelement %47, %48[%4 : i32] : vector<1xf32>
      %50 = llvm.shufflevector %49, %48 [0] : vector<1xf32> 
      %51 = llvm.mul %10, %10  : i64
      %52 = llvm.add %51, %25  : i64
      %53 = llvm.getelementptr %arg1[%52] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
      %54 = llvm.load %53 : !llvm.ptr<1> -> f32
      %55 = llvm.mlir.undef : vector<1xf32>
      %56 = llvm.insertelement %54, %55[%4 : i32] : vector<1xf32>
      %57 = llvm.shufflevector %56, %55 [0] : vector<1xf32> 
      %58 = llvm.getelementptr %arg1[16] : (!llvm.ptr<1>) -> !llvm.ptr<1>, f32
      %59 = llvm.mul %7, %10  : i64
      %60 = llvm.add %59, %25  : i64
      %61 = llvm.getelementptr %58[%60] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
      %62 = llvm.load %61 : !llvm.ptr<1> -> f32
      %63 = llvm.mlir.undef : vector<1xf32>
      %64 = llvm.insertelement %62, %63[%4 : i32] : vector<1xf32>
      %65 = llvm.shufflevector %64, %63 [0] : vector<1xf32> 
      %66 = llvm.extractelement %29[%3 : i64] : vector<4xf32>
      %67 = llvm.mlir.undef : vector<1xf32>
      %68 = llvm.insertelement %66, %67[%4 : i32] : vector<1xf32>
      %69 = llvm.shufflevector %68, %67 [0] : vector<1xf32> 
      %70 = llvm.intr.fmuladd(%69, %36, %65)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
      %71 = llvm.extractelement %29[%2 : i64] : vector<4xf32>
      %72 = llvm.mlir.undef : vector<1xf32>
      %73 = llvm.insertelement %71, %72[%4 : i32] : vector<1xf32>
      %74 = llvm.shufflevector %73, %72 [0] : vector<1xf32> 
      %75 = llvm.intr.fmuladd(%74, %43, %70)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
      %76 = llvm.extractelement %29[%1 : i64] : vector<4xf32>
      %77 = llvm.mlir.undef : vector<1xf32>
      %78 = llvm.insertelement %76, %77[%4 : i32] : vector<1xf32>
      %79 = llvm.shufflevector %78, %77 [0] : vector<1xf32> 
      %80 = llvm.intr.fmuladd(%79, %50, %75)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
      %81 = llvm.extractelement %29[%0 : i64] : vector<4xf32>
      %82 = llvm.mlir.undef : vector<1xf32>
      %83 = llvm.insertelement %81, %82[%4 : i32] : vector<1xf32>
      %84 = llvm.shufflevector %83, %82 [0] : vector<1xf32> 
      %85 = llvm.intr.fmuladd(%84, %57, %80)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
      %86 = llvm.extractelement %85[%3 : i64] : vector<1xf32>
      %87 = llvm.mul %7, %10  : i64
      %88 = llvm.add %87, %25  : i64
      %89 = llvm.getelementptr %arg2[%88] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
      llvm.store %86, %89 : f32, !llvm.ptr<1>
      llvm.return
    }
  }
}

// -----// IR Dump After mlir::iree_compiler::IREE::HAL::TranslateExecutablesPass (iree-hal-translate-executables) //----- //
hal.executable private @main_dispatch_0 {
  hal.executable.variant public @cuda_nvptx_fb target(<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>) {
    hal.executable.export public @main_dispatch_0_matmul_1x3x4_f32 ordinal(0) layout(#hal.pipeline.layout<push_constants = 0, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>) attributes {translation_info = #iree_codegen.translation_info<LLVMGPUMatmulSimt>, workgroup_size = [1 : index, 3 : index, 1 : index]} {
    ^bb0(%arg0: !hal.device):
      %c3 = arith.constant 3 : index
      %c1 = arith.constant 1 : index
      hal.return %c3, %c1, %c1 : index, index, index
    }
    builtin.module {
      llvm.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg2: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias}) {
        %0 = llvm.mlir.constant(3 : i64) : i64
        %1 = llvm.mlir.constant(2 : i64) : i64
        %2 = llvm.mlir.constant(1 : i64) : i64
        %3 = llvm.mlir.constant(0 : i64) : i64
        %4 = llvm.mlir.constant(0 : i32) : i32
        %5 = llvm.mlir.constant(63 : index) : i64
        %6 = llvm.mlir.constant(4 : index) : i64
        %7 = llvm.mlir.constant(0 : index) : i64
        %8 = llvm.mlir.constant(1 : index) : i64
        %9 = llvm.mlir.constant(2 : index) : i64
        %10 = llvm.mlir.constant(3 : index) : i64
        %11 = llvm.ptrtoint %arg0 : !llvm.ptr<1> to i64
        %12 = llvm.and %11, %5  : i64
        %13 = llvm.icmp "eq" %12, %7 : i64
        "llvm.intr.assume"(%13) : (i1) -> ()
        %14 = llvm.ptrtoint %arg1 : !llvm.ptr<1> to i64
        %15 = llvm.and %14, %5  : i64
        %16 = llvm.icmp "eq" %15, %7 : i64
        "llvm.intr.assume"(%16) : (i1) -> ()
        %17 = llvm.getelementptr %arg1[16] : (!llvm.ptr<1>) -> !llvm.ptr<1>, f32
        %18 = llvm.ptrtoint %17 : !llvm.ptr<1> to i64
        %19 = llvm.and %18, %5  : i64
        %20 = llvm.icmp "eq" %19, %7 : i64
        "llvm.intr.assume"(%20) : (i1) -> ()
        %21 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
        %22 = llvm.and %21, %5  : i64
        %23 = llvm.icmp "eq" %22, %7 : i64
        "llvm.intr.assume"(%23) : (i1) -> ()
        %24 = nvvm.read.ptx.sreg.ctaid.x : i32
        %25 = llvm.sext %24 : i32 to i64
        %26 = llvm.mul %7, %6  : i64
        %27 = llvm.add %26, %7  : i64
        %28 = llvm.getelementptr %arg0[%27] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
        %29 = llvm.load %28 {alignment = 4 : i64} : !llvm.ptr<1> -> vector<4xf32>
        %30 = llvm.mul %7, %10  : i64
        %31 = llvm.add %30, %25  : i64
        %32 = llvm.getelementptr %arg1[%31] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
        %33 = llvm.load %32 : !llvm.ptr<1> -> f32
        %34 = llvm.mlir.undef : vector<1xf32>
        %35 = llvm.insertelement %33, %34[%4 : i32] : vector<1xf32>
        %36 = llvm.shufflevector %35, %34 [0] : vector<1xf32> 
        %37 = llvm.mul %8, %10  : i64
        %38 = llvm.add %37, %25  : i64
        %39 = llvm.getelementptr %arg1[%38] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
        %40 = llvm.load %39 : !llvm.ptr<1> -> f32
        %41 = llvm.mlir.undef : vector<1xf32>
        %42 = llvm.insertelement %40, %41[%4 : i32] : vector<1xf32>
        %43 = llvm.shufflevector %42, %41 [0] : vector<1xf32> 
        %44 = llvm.mul %9, %10  : i64
        %45 = llvm.add %44, %25  : i64
        %46 = llvm.getelementptr %arg1[%45] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
        %47 = llvm.load %46 : !llvm.ptr<1> -> f32
        %48 = llvm.mlir.undef : vector<1xf32>
        %49 = llvm.insertelement %47, %48[%4 : i32] : vector<1xf32>
        %50 = llvm.shufflevector %49, %48 [0] : vector<1xf32> 
        %51 = llvm.mul %10, %10  : i64
        %52 = llvm.add %51, %25  : i64
        %53 = llvm.getelementptr %arg1[%52] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
        %54 = llvm.load %53 : !llvm.ptr<1> -> f32
        %55 = llvm.mlir.undef : vector<1xf32>
        %56 = llvm.insertelement %54, %55[%4 : i32] : vector<1xf32>
        %57 = llvm.shufflevector %56, %55 [0] : vector<1xf32> 
        %58 = llvm.getelementptr %arg1[16] : (!llvm.ptr<1>) -> !llvm.ptr<1>, f32
        %59 = llvm.mul %7, %10  : i64
        %60 = llvm.add %59, %25  : i64
        %61 = llvm.getelementptr %58[%60] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
        %62 = llvm.load %61 : !llvm.ptr<1> -> f32
        %63 = llvm.mlir.undef : vector<1xf32>
        %64 = llvm.insertelement %62, %63[%4 : i32] : vector<1xf32>
        %65 = llvm.shufflevector %64, %63 [0] : vector<1xf32> 
        %66 = llvm.extractelement %29[%3 : i64] : vector<4xf32>
        %67 = llvm.mlir.undef : vector<1xf32>
        %68 = llvm.insertelement %66, %67[%4 : i32] : vector<1xf32>
        %69 = llvm.shufflevector %68, %67 [0] : vector<1xf32> 
        %70 = llvm.intr.fmuladd(%69, %36, %65)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
        %71 = llvm.extractelement %29[%2 : i64] : vector<4xf32>
        %72 = llvm.mlir.undef : vector<1xf32>
        %73 = llvm.insertelement %71, %72[%4 : i32] : vector<1xf32>
        %74 = llvm.shufflevector %73, %72 [0] : vector<1xf32> 
        %75 = llvm.intr.fmuladd(%74, %43, %70)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
        %76 = llvm.extractelement %29[%1 : i64] : vector<4xf32>
        %77 = llvm.mlir.undef : vector<1xf32>
        %78 = llvm.insertelement %76, %77[%4 : i32] : vector<1xf32>
        %79 = llvm.shufflevector %78, %77 [0] : vector<1xf32> 
        %80 = llvm.intr.fmuladd(%79, %50, %75)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
        %81 = llvm.extractelement %29[%0 : i64] : vector<4xf32>
        %82 = llvm.mlir.undef : vector<1xf32>
        %83 = llvm.insertelement %81, %82[%4 : i32] : vector<1xf32>
        %84 = llvm.shufflevector %83, %82 [0] : vector<1xf32> 
        %85 = llvm.intr.fmuladd(%84, %57, %80)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
        %86 = llvm.extractelement %85[%3 : i64] : vector<1xf32>
        %87 = llvm.mul %7, %10  : i64
        %88 = llvm.add %87, %25  : i64
        %89 = llvm.getelementptr %arg2[%88] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
        llvm.store %86, %89 : f32, !llvm.ptr<1>
        llvm.return
      }
    }
  }
}

// -----// IR Dump After mlir::iree_compiler::IREE::HAL::(anonymous namespace)::ConvertToHALPass (iree-hal-conversion) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#pipeline_layout = #hal.pipeline.layout<push_constants = 0, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>
#translation = #iree_codegen.translation_info<LLVMGPUMatmulSimt>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private mutable @_params.weight__timepoint : !hal.fence
  util.global private @_params.weight : !hal.buffer
  util.initializer {
    %0 = util.null : !hal.fence
    %c0_i64 = arith.constant 0 : i64
    %c128 = arith.constant 128 : index
    %c0 = arith.constant 0 : index
    %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #composite_of_128b
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    %c-1_i64 = arith.constant -1 : i64
    %did_import, %mapped = hal.allocator.import<%allocator : !hal.allocator> source(%buffer_cst : !util.buffer)[%c0, %c128] affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : i1, !hal.buffer
    cf.cond_br %did_import, ^bb2(%0, %mapped : !hal.fence, !hal.buffer), ^bb1
  ^bb1:  // pred: ^bb0
    %device_0 = hal.ex.shared_device : !hal.device
    %allocator_1 = hal.device.allocator<%device_0 : !hal.device> : !hal.allocator
    %c-1_i64_2 = arith.constant -1 : i64
    %buffer = hal.allocator.allocate<%allocator_1 : !hal.allocator> affinity(%c-1_i64_2) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : !hal.buffer{%c128}
    %device_3 = hal.ex.shared_device : !hal.device
    %c-1_i64_4 = arith.constant -1 : i64
    %c0_i32 = arith.constant 0 : i32
    %memory_file = hal.ex.file.from_memory device(%device_3 : !hal.device) affinity(%c-1_i64_4) access(Read) buffer(%buffer_cst : !util.buffer)[%c0 for %c128] flags(%c0_i32) : !hal.file
    %device_5 = hal.ex.shared_device : !hal.device
    %c-1_i64_6 = arith.constant -1 : i64
    %fence = hal.fence.create device(%device_5 : !hal.device) flags("None") : !hal.fence
    hal.device.queue.read<%device_5 : !hal.device> affinity(%c-1_i64_6) wait(%0) signal(%fence) source(%memory_file : !hal.file)[%c0_i64] target(%buffer : !hal.buffer)[%c0] length(%c128) flags(0)
    cf.br ^bb2(%fence, %buffer : !hal.fence, !hal.buffer)
  ^bb2(%1: !hal.fence, %2: !hal.buffer):  // 2 preds: ^bb0, ^bb1
    util.global.store %2, @_params.weight : !hal.buffer
    util.global.store %1, @_params.weight__timepoint : !hal.fence
    util.initializer.return
  }
  hal.executable private @main_dispatch_0 {
    hal.executable.variant public @cuda_nvptx_fb target(#executable_target_cuda_nvptx_fb) {
      hal.executable.export public @main_dispatch_0_matmul_1x3x4_f32 ordinal(0) layout(#pipeline_layout) attributes {translation_info = #translation, workgroup_size = [1 : index, 3 : index, 1 : index]} {
      ^bb0(%arg0: !hal.device):
        %c3 = arith.constant 3 : index
        %c1 = arith.constant 1 : index
        hal.return %c3, %c1, %c1 : index, index, index
      }
      builtin.module {
        llvm.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg2: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias}) {
          %0 = llvm.mlir.constant(3 : i64) : i64
          %1 = llvm.mlir.constant(2 : i64) : i64
          %2 = llvm.mlir.constant(1 : i64) : i64
          %3 = llvm.mlir.constant(0 : i64) : i64
          %4 = llvm.mlir.constant(0 : i32) : i32
          %5 = llvm.mlir.constant(63 : index) : i64
          %6 = llvm.mlir.constant(4 : index) : i64
          %7 = llvm.mlir.constant(0 : index) : i64
          %8 = llvm.mlir.constant(1 : index) : i64
          %9 = llvm.mlir.constant(2 : index) : i64
          %10 = llvm.mlir.constant(3 : index) : i64
          %11 = llvm.ptrtoint %arg0 : !llvm.ptr<1> to i64
          %12 = llvm.and %11, %5  : i64
          %13 = llvm.icmp "eq" %12, %7 : i64
          "llvm.intr.assume"(%13) : (i1) -> ()
          %14 = llvm.ptrtoint %arg1 : !llvm.ptr<1> to i64
          %15 = llvm.and %14, %5  : i64
          %16 = llvm.icmp "eq" %15, %7 : i64
          "llvm.intr.assume"(%16) : (i1) -> ()
          %17 = llvm.getelementptr %arg1[16] : (!llvm.ptr<1>) -> !llvm.ptr<1>, f32
          %18 = llvm.ptrtoint %17 : !llvm.ptr<1> to i64
          %19 = llvm.and %18, %5  : i64
          %20 = llvm.icmp "eq" %19, %7 : i64
          "llvm.intr.assume"(%20) : (i1) -> ()
          %21 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
          %22 = llvm.and %21, %5  : i64
          %23 = llvm.icmp "eq" %22, %7 : i64
          "llvm.intr.assume"(%23) : (i1) -> ()
          %24 = nvvm.read.ptx.sreg.ctaid.x : i32
          %25 = llvm.sext %24 : i32 to i64
          %26 = llvm.mul %7, %6  : i64
          %27 = llvm.add %26, %7  : i64
          %28 = llvm.getelementptr %arg0[%27] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %29 = llvm.load %28 {alignment = 4 : i64} : !llvm.ptr<1> -> vector<4xf32>
          %30 = llvm.mul %7, %10  : i64
          %31 = llvm.add %30, %25  : i64
          %32 = llvm.getelementptr %arg1[%31] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %33 = llvm.load %32 : !llvm.ptr<1> -> f32
          %34 = llvm.mlir.undef : vector<1xf32>
          %35 = llvm.insertelement %33, %34[%4 : i32] : vector<1xf32>
          %36 = llvm.shufflevector %35, %34 [0] : vector<1xf32> 
          %37 = llvm.mul %8, %10  : i64
          %38 = llvm.add %37, %25  : i64
          %39 = llvm.getelementptr %arg1[%38] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %40 = llvm.load %39 : !llvm.ptr<1> -> f32
          %41 = llvm.mlir.undef : vector<1xf32>
          %42 = llvm.insertelement %40, %41[%4 : i32] : vector<1xf32>
          %43 = llvm.shufflevector %42, %41 [0] : vector<1xf32> 
          %44 = llvm.mul %9, %10  : i64
          %45 = llvm.add %44, %25  : i64
          %46 = llvm.getelementptr %arg1[%45] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %47 = llvm.load %46 : !llvm.ptr<1> -> f32
          %48 = llvm.mlir.undef : vector<1xf32>
          %49 = llvm.insertelement %47, %48[%4 : i32] : vector<1xf32>
          %50 = llvm.shufflevector %49, %48 [0] : vector<1xf32> 
          %51 = llvm.mul %10, %10  : i64
          %52 = llvm.add %51, %25  : i64
          %53 = llvm.getelementptr %arg1[%52] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %54 = llvm.load %53 : !llvm.ptr<1> -> f32
          %55 = llvm.mlir.undef : vector<1xf32>
          %56 = llvm.insertelement %54, %55[%4 : i32] : vector<1xf32>
          %57 = llvm.shufflevector %56, %55 [0] : vector<1xf32> 
          %58 = llvm.getelementptr %arg1[16] : (!llvm.ptr<1>) -> !llvm.ptr<1>, f32
          %59 = llvm.mul %7, %10  : i64
          %60 = llvm.add %59, %25  : i64
          %61 = llvm.getelementptr %58[%60] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %62 = llvm.load %61 : !llvm.ptr<1> -> f32
          %63 = llvm.mlir.undef : vector<1xf32>
          %64 = llvm.insertelement %62, %63[%4 : i32] : vector<1xf32>
          %65 = llvm.shufflevector %64, %63 [0] : vector<1xf32> 
          %66 = llvm.extractelement %29[%3 : i64] : vector<4xf32>
          %67 = llvm.mlir.undef : vector<1xf32>
          %68 = llvm.insertelement %66, %67[%4 : i32] : vector<1xf32>
          %69 = llvm.shufflevector %68, %67 [0] : vector<1xf32> 
          %70 = llvm.intr.fmuladd(%69, %36, %65)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
          %71 = llvm.extractelement %29[%2 : i64] : vector<4xf32>
          %72 = llvm.mlir.undef : vector<1xf32>
          %73 = llvm.insertelement %71, %72[%4 : i32] : vector<1xf32>
          %74 = llvm.shufflevector %73, %72 [0] : vector<1xf32> 
          %75 = llvm.intr.fmuladd(%74, %43, %70)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
          %76 = llvm.extractelement %29[%1 : i64] : vector<4xf32>
          %77 = llvm.mlir.undef : vector<1xf32>
          %78 = llvm.insertelement %76, %77[%4 : i32] : vector<1xf32>
          %79 = llvm.shufflevector %78, %77 [0] : vector<1xf32> 
          %80 = llvm.intr.fmuladd(%79, %50, %75)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
          %81 = llvm.extractelement %29[%0 : i64] : vector<4xf32>
          %82 = llvm.mlir.undef : vector<1xf32>
          %83 = llvm.insertelement %81, %82[%4 : i32] : vector<1xf32>
          %84 = llvm.shufflevector %83, %82 [0] : vector<1xf32> 
          %85 = llvm.intr.fmuladd(%84, %57, %80)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
          %86 = llvm.extractelement %85[%3 : i64] : vector<1xf32>
          %87 = llvm.mul %7, %10  : i64
          %88 = llvm.add %87, %25  : i64
          %89 = llvm.getelementptr %arg2[%88] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          llvm.store %86, %89 : f32, !llvm.ptr<1>
          llvm.return
        }
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c128 = arith.constant 128 : index
    %c16 = arith.constant 16 : index
    %c12 = arith.constant 12 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !hal.fence
    %_params.weight = util.global.load @_params.weight : !hal.buffer
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c16) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %device_0 = hal.ex.shared_device : !hal.device
    %c-1_i64 = arith.constant -1 : i64
    %fence = hal.fence.create device(%device_0 : !hal.device) flags("None") : !hal.fence
    %c0_i64 = arith.constant 0 : i64
    %transient_buffer = hal.device.queue.alloca<%device_0 : !hal.device> affinity(%c-1_i64) wait(%_params.weight__timepoint) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%c12}
    %device_1 = hal.ex.shared_device : !hal.device
    %c-1_i64_2 = arith.constant -1 : i64
    %cmd = hal.command_buffer.create device(%device_1 : !hal.device) mode(OneShot) categories("Transfer|Dispatch") : !hal.command_buffer
    %0 = hal.command_buffer.device<%cmd : !hal.command_buffer> : !hal.device
    %ok, %value = hal.device.query<%0 : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    %c-1 = arith.constant -1 : index
    %c0_3 = arith.constant 0 : index
    %1 = arith.select %value, %c0_3, %c-1 : index
    scf.index_switch %1 
    case 0 {
      %pipeline_layout = hal.pipeline_layout.lookup device(%0 : !hal.device) layout(#pipeline_layout) : !hal.pipeline_layout
      %c0_8 = arith.constant 0 : index
      %c1 = arith.constant 1 : index
      %c2 = arith.constant 2 : index
      %c0_9 = arith.constant 0 : index
      hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%pipeline_layout : !hal.pipeline_layout)[%c0_9] bindings([
        %c0_8 = (%buffer : !hal.buffer)[%c0, %c16], 
        %c1 = (%_params.weight : !hal.buffer)[%c0, %c128], 
        %c2 = (%transient_buffer : !hal.buffer)[%c0, %c12]
      ])
      %c3_10 = arith.constant 3 : index
      %c1_11 = arith.constant 1 : index
      hal.command_buffer.dispatch.symbol<%cmd : !hal.command_buffer> target(@main_dispatch_0::@cuda_nvptx_fb::@main_dispatch_0_matmul_1x3x4_f32) workgroups([%c3_10, %c1_11, %c1_11])
      scf.yield
    }
    default {
    }
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_4 = hal.fence.create device(%device_1 : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%device_1 : !hal.device> affinity(%c-1_i64_2) wait(%fence) signal(%fence_4) commands([%cmd])
    %c-1_i32 = arith.constant -1 : i32
    %status = hal.fence.await until([%fence_4]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %c3 = arith.constant 3 : index
    %c0_5 = arith.constant 0 : index
    %c553648160_i32_6 = arith.constant 553648160 : i32
    %c1_i32_7 = arith.constant 1 : i32
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0_5, %c12] shape([%c3]) type(%c553648160_i32_6) encoding(%c1_i32_7) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::HAL::FixupLegacySyncPass (iree-hal-fixup-legacy-sync) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#pipeline_layout = #hal.pipeline.layout<push_constants = 0, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>
#translation = #iree_codegen.translation_info<LLVMGPUMatmulSimt>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private mutable @_params.weight__timepoint : !hal.fence
  util.global private @_params.weight : !hal.buffer
  util.initializer {
    %0 = util.null : !hal.fence
    %c0_i64 = arith.constant 0 : i64
    %c128 = arith.constant 128 : index
    %c0 = arith.constant 0 : index
    %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #composite_of_128b
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    %c-1_i64 = arith.constant -1 : i64
    %did_import, %mapped = hal.allocator.import<%allocator : !hal.allocator> source(%buffer_cst : !util.buffer)[%c0, %c128] affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : i1, !hal.buffer
    cf.cond_br %did_import, ^bb2(%0, %mapped : !hal.fence, !hal.buffer), ^bb1
  ^bb1:  // pred: ^bb0
    %device_0 = hal.ex.shared_device : !hal.device
    %allocator_1 = hal.device.allocator<%device_0 : !hal.device> : !hal.allocator
    %c-1_i64_2 = arith.constant -1 : i64
    %buffer = hal.allocator.allocate<%allocator_1 : !hal.allocator> affinity(%c-1_i64_2) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : !hal.buffer{%c128}
    %device_3 = hal.ex.shared_device : !hal.device
    %c-1_i64_4 = arith.constant -1 : i64
    %c0_i32 = arith.constant 0 : i32
    %memory_file = hal.ex.file.from_memory device(%device_3 : !hal.device) affinity(%c-1_i64_4) access(Read) buffer(%buffer_cst : !util.buffer)[%c0 for %c128] flags(%c0_i32) : !hal.file
    %device_5 = hal.ex.shared_device : !hal.device
    %c-1_i64_6 = arith.constant -1 : i64
    %fence = hal.fence.create device(%device_5 : !hal.device) flags("None") : !hal.fence
    hal.device.queue.read<%device_5 : !hal.device> affinity(%c-1_i64_6) wait(%0) signal(%fence) source(%memory_file : !hal.file)[%c0_i64] target(%buffer : !hal.buffer)[%c0] length(%c128) flags(0)
    cf.br ^bb2(%fence, %buffer : !hal.fence, !hal.buffer)
  ^bb2(%1: !hal.fence, %2: !hal.buffer):  // 2 preds: ^bb0, ^bb1
    util.global.store %2, @_params.weight : !hal.buffer
    util.global.store %1, @_params.weight__timepoint : !hal.fence
    util.initializer.return
  }
  hal.executable private @main_dispatch_0 {
    hal.executable.variant public @cuda_nvptx_fb target(#executable_target_cuda_nvptx_fb) {
      hal.executable.export public @main_dispatch_0_matmul_1x3x4_f32 ordinal(0) layout(#pipeline_layout) attributes {translation_info = #translation, workgroup_size = [1 : index, 3 : index, 1 : index]} {
      ^bb0(%arg0: !hal.device):
        %c3 = arith.constant 3 : index
        %c1 = arith.constant 1 : index
        hal.return %c3, %c1, %c1 : index, index, index
      }
      builtin.module {
        llvm.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg2: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias}) {
          %0 = llvm.mlir.constant(3 : i64) : i64
          %1 = llvm.mlir.constant(2 : i64) : i64
          %2 = llvm.mlir.constant(1 : i64) : i64
          %3 = llvm.mlir.constant(0 : i64) : i64
          %4 = llvm.mlir.constant(0 : i32) : i32
          %5 = llvm.mlir.constant(63 : index) : i64
          %6 = llvm.mlir.constant(4 : index) : i64
          %7 = llvm.mlir.constant(0 : index) : i64
          %8 = llvm.mlir.constant(1 : index) : i64
          %9 = llvm.mlir.constant(2 : index) : i64
          %10 = llvm.mlir.constant(3 : index) : i64
          %11 = llvm.ptrtoint %arg0 : !llvm.ptr<1> to i64
          %12 = llvm.and %11, %5  : i64
          %13 = llvm.icmp "eq" %12, %7 : i64
          "llvm.intr.assume"(%13) : (i1) -> ()
          %14 = llvm.ptrtoint %arg1 : !llvm.ptr<1> to i64
          %15 = llvm.and %14, %5  : i64
          %16 = llvm.icmp "eq" %15, %7 : i64
          "llvm.intr.assume"(%16) : (i1) -> ()
          %17 = llvm.getelementptr %arg1[16] : (!llvm.ptr<1>) -> !llvm.ptr<1>, f32
          %18 = llvm.ptrtoint %17 : !llvm.ptr<1> to i64
          %19 = llvm.and %18, %5  : i64
          %20 = llvm.icmp "eq" %19, %7 : i64
          "llvm.intr.assume"(%20) : (i1) -> ()
          %21 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
          %22 = llvm.and %21, %5  : i64
          %23 = llvm.icmp "eq" %22, %7 : i64
          "llvm.intr.assume"(%23) : (i1) -> ()
          %24 = nvvm.read.ptx.sreg.ctaid.x : i32
          %25 = llvm.sext %24 : i32 to i64
          %26 = llvm.mul %7, %6  : i64
          %27 = llvm.add %26, %7  : i64
          %28 = llvm.getelementptr %arg0[%27] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %29 = llvm.load %28 {alignment = 4 : i64} : !llvm.ptr<1> -> vector<4xf32>
          %30 = llvm.mul %7, %10  : i64
          %31 = llvm.add %30, %25  : i64
          %32 = llvm.getelementptr %arg1[%31] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %33 = llvm.load %32 : !llvm.ptr<1> -> f32
          %34 = llvm.mlir.undef : vector<1xf32>
          %35 = llvm.insertelement %33, %34[%4 : i32] : vector<1xf32>
          %36 = llvm.shufflevector %35, %34 [0] : vector<1xf32> 
          %37 = llvm.mul %8, %10  : i64
          %38 = llvm.add %37, %25  : i64
          %39 = llvm.getelementptr %arg1[%38] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %40 = llvm.load %39 : !llvm.ptr<1> -> f32
          %41 = llvm.mlir.undef : vector<1xf32>
          %42 = llvm.insertelement %40, %41[%4 : i32] : vector<1xf32>
          %43 = llvm.shufflevector %42, %41 [0] : vector<1xf32> 
          %44 = llvm.mul %9, %10  : i64
          %45 = llvm.add %44, %25  : i64
          %46 = llvm.getelementptr %arg1[%45] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %47 = llvm.load %46 : !llvm.ptr<1> -> f32
          %48 = llvm.mlir.undef : vector<1xf32>
          %49 = llvm.insertelement %47, %48[%4 : i32] : vector<1xf32>
          %50 = llvm.shufflevector %49, %48 [0] : vector<1xf32> 
          %51 = llvm.mul %10, %10  : i64
          %52 = llvm.add %51, %25  : i64
          %53 = llvm.getelementptr %arg1[%52] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %54 = llvm.load %53 : !llvm.ptr<1> -> f32
          %55 = llvm.mlir.undef : vector<1xf32>
          %56 = llvm.insertelement %54, %55[%4 : i32] : vector<1xf32>
          %57 = llvm.shufflevector %56, %55 [0] : vector<1xf32> 
          %58 = llvm.getelementptr %arg1[16] : (!llvm.ptr<1>) -> !llvm.ptr<1>, f32
          %59 = llvm.mul %7, %10  : i64
          %60 = llvm.add %59, %25  : i64
          %61 = llvm.getelementptr %58[%60] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %62 = llvm.load %61 : !llvm.ptr<1> -> f32
          %63 = llvm.mlir.undef : vector<1xf32>
          %64 = llvm.insertelement %62, %63[%4 : i32] : vector<1xf32>
          %65 = llvm.shufflevector %64, %63 [0] : vector<1xf32> 
          %66 = llvm.extractelement %29[%3 : i64] : vector<4xf32>
          %67 = llvm.mlir.undef : vector<1xf32>
          %68 = llvm.insertelement %66, %67[%4 : i32] : vector<1xf32>
          %69 = llvm.shufflevector %68, %67 [0] : vector<1xf32> 
          %70 = llvm.intr.fmuladd(%69, %36, %65)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
          %71 = llvm.extractelement %29[%2 : i64] : vector<4xf32>
          %72 = llvm.mlir.undef : vector<1xf32>
          %73 = llvm.insertelement %71, %72[%4 : i32] : vector<1xf32>
          %74 = llvm.shufflevector %73, %72 [0] : vector<1xf32> 
          %75 = llvm.intr.fmuladd(%74, %43, %70)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
          %76 = llvm.extractelement %29[%1 : i64] : vector<4xf32>
          %77 = llvm.mlir.undef : vector<1xf32>
          %78 = llvm.insertelement %76, %77[%4 : i32] : vector<1xf32>
          %79 = llvm.shufflevector %78, %77 [0] : vector<1xf32> 
          %80 = llvm.intr.fmuladd(%79, %50, %75)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
          %81 = llvm.extractelement %29[%0 : i64] : vector<4xf32>
          %82 = llvm.mlir.undef : vector<1xf32>
          %83 = llvm.insertelement %81, %82[%4 : i32] : vector<1xf32>
          %84 = llvm.shufflevector %83, %82 [0] : vector<1xf32> 
          %85 = llvm.intr.fmuladd(%84, %57, %80)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
          %86 = llvm.extractelement %85[%3 : i64] : vector<1xf32>
          %87 = llvm.mul %7, %10  : i64
          %88 = llvm.add %87, %25  : i64
          %89 = llvm.getelementptr %arg2[%88] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          llvm.store %86, %89 : f32, !llvm.ptr<1>
          llvm.return
        }
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c128 = arith.constant 128 : index
    %c16 = arith.constant 16 : index
    %c12 = arith.constant 12 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !hal.fence
    %_params.weight = util.global.load @_params.weight : !hal.buffer
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c16) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %device_0 = hal.ex.shared_device : !hal.device
    %c-1_i64 = arith.constant -1 : i64
    %fence = hal.fence.create device(%device_0 : !hal.device) flags("None") : !hal.fence
    %c0_i64 = arith.constant 0 : i64
    %c-1_i32 = arith.constant -1 : i32
    %status = hal.fence.await until([%_params.weight__timepoint]) timeout_millis(%c-1_i32) : i32
    %0 = util.null : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%device_0 : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%c12}
    %status_1 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    %device_2 = hal.ex.shared_device : !hal.device
    %c-1_i64_3 = arith.constant -1 : i64
    %cmd = hal.command_buffer.create device(%device_2 : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    %1 = hal.command_buffer.device<%cmd : !hal.command_buffer> : !hal.device
    %ok, %value = hal.device.query<%1 : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    %c-1 = arith.constant -1 : index
    %c0_4 = arith.constant 0 : index
    %2 = arith.select %value, %c0_4, %c-1 : index
    scf.index_switch %2 
    case 0 {
      %pipeline_layout = hal.pipeline_layout.lookup device(%1 : !hal.device) layout(#pipeline_layout) : !hal.pipeline_layout
      %c0_13 = arith.constant 0 : index
      %c1 = arith.constant 1 : index
      %c2 = arith.constant 2 : index
      %c0_14 = arith.constant 0 : index
      hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%pipeline_layout : !hal.pipeline_layout)[%c0_14] bindings([
        %c0_13 = (%buffer : !hal.buffer)[%c0, %c16], 
        %c1 = (%_params.weight : !hal.buffer)[%c0, %c128], 
        %c2 = (%transient_buffer : !hal.buffer)[%c0, %c12]
      ])
      %c3_15 = arith.constant 3 : index
      %c1_16 = arith.constant 1 : index
      hal.command_buffer.dispatch.symbol<%cmd : !hal.command_buffer> target(@main_dispatch_0::@cuda_nvptx_fb::@main_dispatch_0_matmul_1x3x4_f32) workgroups([%c3_15, %c1_16, %c1_16])
      scf.yield
    }
    default {
    }
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_5 = hal.fence.create device(%device_2 : !hal.device) flags("None") : !hal.fence
    %c-1_i32_6 = arith.constant -1 : i32
    %status_7 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32_6) : i32
    %3 = util.null : !hal.fence
    hal.device.queue.execute<%device_2 : !hal.device> affinity(%c-1_i64_3) wait(%3) signal(%fence_5) commands([%cmd])
    %c-1_i32_8 = arith.constant -1 : i32
    %status_9 = hal.fence.await until([%fence_5]) timeout_millis(%c-1_i32_8) : i32
    util.status.check_ok %status_9, "failed to wait on timepoint"
    %c3 = arith.constant 3 : index
    %c0_10 = arith.constant 0 : index
    %c553648160_i32_11 = arith.constant 553648160 : i32
    %c1_i32_12 = arith.constant 1 : i32
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0_10, %c12] shape([%c3]) type(%c553648160_i32_11) encoding(%c1_i32_12) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After CSE (cse) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#pipeline_layout = #hal.pipeline.layout<push_constants = 0, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>
#translation = #iree_codegen.translation_info<LLVMGPUMatmulSimt>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private mutable @_params.weight__timepoint : !hal.fence
  util.global private @_params.weight : !hal.buffer
  util.initializer {
    %0 = util.null : !hal.fence
    %c0_i64 = arith.constant 0 : i64
    %c128 = arith.constant 128 : index
    %c0 = arith.constant 0 : index
    %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #composite_of_128b
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    %c-1_i64 = arith.constant -1 : i64
    %did_import, %mapped = hal.allocator.import<%allocator : !hal.allocator> source(%buffer_cst : !util.buffer)[%c0, %c128] affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : i1, !hal.buffer
    cf.cond_br %did_import, ^bb2(%0, %mapped : !hal.fence, !hal.buffer), ^bb1
  ^bb1:  // pred: ^bb0
    %buffer = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : !hal.buffer{%c128}
    %c0_i32 = arith.constant 0 : i32
    %memory_file = hal.ex.file.from_memory device(%device : !hal.device) affinity(%c-1_i64) access(Read) buffer(%buffer_cst : !util.buffer)[%c0 for %c128] flags(%c0_i32) : !hal.file
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.read<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) source(%memory_file : !hal.file)[%c0_i64] target(%buffer : !hal.buffer)[%c0] length(%c128) flags(0)
    cf.br ^bb2(%fence, %buffer : !hal.fence, !hal.buffer)
  ^bb2(%1: !hal.fence, %2: !hal.buffer):  // 2 preds: ^bb0, ^bb1
    util.global.store %2, @_params.weight : !hal.buffer
    util.global.store %1, @_params.weight__timepoint : !hal.fence
    util.initializer.return
  }
  hal.executable private @main_dispatch_0 {
    hal.executable.variant public @cuda_nvptx_fb target(#executable_target_cuda_nvptx_fb) {
      hal.executable.export public @main_dispatch_0_matmul_1x3x4_f32 ordinal(0) layout(#pipeline_layout) attributes {translation_info = #translation, workgroup_size = [1 : index, 3 : index, 1 : index]} {
      ^bb0(%arg0: !hal.device):
        %c3 = arith.constant 3 : index
        %c1 = arith.constant 1 : index
        hal.return %c3, %c1, %c1 : index, index, index
      }
      builtin.module {
        llvm.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg2: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias}) {
          %0 = llvm.mlir.constant(3 : i64) : i64
          %1 = llvm.mlir.constant(2 : i64) : i64
          %2 = llvm.mlir.constant(1 : i64) : i64
          %3 = llvm.mlir.constant(0 : i64) : i64
          %4 = llvm.mlir.constant(0 : i32) : i32
          %5 = llvm.mlir.constant(63 : index) : i64
          %6 = llvm.mlir.constant(4 : index) : i64
          %7 = llvm.mlir.constant(0 : index) : i64
          %8 = llvm.mlir.constant(1 : index) : i64
          %9 = llvm.mlir.constant(2 : index) : i64
          %10 = llvm.mlir.constant(3 : index) : i64
          %11 = llvm.ptrtoint %arg0 : !llvm.ptr<1> to i64
          %12 = llvm.and %11, %5  : i64
          %13 = llvm.icmp "eq" %12, %7 : i64
          "llvm.intr.assume"(%13) : (i1) -> ()
          %14 = llvm.ptrtoint %arg1 : !llvm.ptr<1> to i64
          %15 = llvm.and %14, %5  : i64
          %16 = llvm.icmp "eq" %15, %7 : i64
          "llvm.intr.assume"(%16) : (i1) -> ()
          %17 = llvm.getelementptr %arg1[16] : (!llvm.ptr<1>) -> !llvm.ptr<1>, f32
          %18 = llvm.ptrtoint %17 : !llvm.ptr<1> to i64
          %19 = llvm.and %18, %5  : i64
          %20 = llvm.icmp "eq" %19, %7 : i64
          "llvm.intr.assume"(%20) : (i1) -> ()
          %21 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
          %22 = llvm.and %21, %5  : i64
          %23 = llvm.icmp "eq" %22, %7 : i64
          "llvm.intr.assume"(%23) : (i1) -> ()
          %24 = nvvm.read.ptx.sreg.ctaid.x : i32
          %25 = llvm.sext %24 : i32 to i64
          %26 = llvm.mul %7, %6  : i64
          %27 = llvm.add %26, %7  : i64
          %28 = llvm.getelementptr %arg0[%27] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %29 = llvm.load %28 {alignment = 4 : i64} : !llvm.ptr<1> -> vector<4xf32>
          %30 = llvm.mul %7, %10  : i64
          %31 = llvm.add %30, %25  : i64
          %32 = llvm.getelementptr %arg1[%31] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %33 = llvm.load %32 : !llvm.ptr<1> -> f32
          %34 = llvm.mlir.undef : vector<1xf32>
          %35 = llvm.insertelement %33, %34[%4 : i32] : vector<1xf32>
          %36 = llvm.shufflevector %35, %34 [0] : vector<1xf32> 
          %37 = llvm.mul %8, %10  : i64
          %38 = llvm.add %37, %25  : i64
          %39 = llvm.getelementptr %arg1[%38] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %40 = llvm.load %39 : !llvm.ptr<1> -> f32
          %41 = llvm.insertelement %40, %34[%4 : i32] : vector<1xf32>
          %42 = llvm.shufflevector %41, %34 [0] : vector<1xf32> 
          %43 = llvm.mul %9, %10  : i64
          %44 = llvm.add %43, %25  : i64
          %45 = llvm.getelementptr %arg1[%44] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %46 = llvm.load %45 : !llvm.ptr<1> -> f32
          %47 = llvm.insertelement %46, %34[%4 : i32] : vector<1xf32>
          %48 = llvm.shufflevector %47, %34 [0] : vector<1xf32> 
          %49 = llvm.mul %10, %10  : i64
          %50 = llvm.add %49, %25  : i64
          %51 = llvm.getelementptr %arg1[%50] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %52 = llvm.load %51 : !llvm.ptr<1> -> f32
          %53 = llvm.insertelement %52, %34[%4 : i32] : vector<1xf32>
          %54 = llvm.shufflevector %53, %34 [0] : vector<1xf32> 
          %55 = llvm.getelementptr %17[%31] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %56 = llvm.load %55 : !llvm.ptr<1> -> f32
          %57 = llvm.insertelement %56, %34[%4 : i32] : vector<1xf32>
          %58 = llvm.shufflevector %57, %34 [0] : vector<1xf32> 
          %59 = llvm.extractelement %29[%3 : i64] : vector<4xf32>
          %60 = llvm.insertelement %59, %34[%4 : i32] : vector<1xf32>
          %61 = llvm.shufflevector %60, %34 [0] : vector<1xf32> 
          %62 = llvm.intr.fmuladd(%61, %36, %58)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
          %63 = llvm.extractelement %29[%2 : i64] : vector<4xf32>
          %64 = llvm.insertelement %63, %34[%4 : i32] : vector<1xf32>
          %65 = llvm.shufflevector %64, %34 [0] : vector<1xf32> 
          %66 = llvm.intr.fmuladd(%65, %42, %62)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
          %67 = llvm.extractelement %29[%1 : i64] : vector<4xf32>
          %68 = llvm.insertelement %67, %34[%4 : i32] : vector<1xf32>
          %69 = llvm.shufflevector %68, %34 [0] : vector<1xf32> 
          %70 = llvm.intr.fmuladd(%69, %48, %66)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
          %71 = llvm.extractelement %29[%0 : i64] : vector<4xf32>
          %72 = llvm.insertelement %71, %34[%4 : i32] : vector<1xf32>
          %73 = llvm.shufflevector %72, %34 [0] : vector<1xf32> 
          %74 = llvm.intr.fmuladd(%73, %54, %70)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
          %75 = llvm.extractelement %74[%3 : i64] : vector<1xf32>
          %76 = llvm.getelementptr %arg2[%31] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          llvm.store %75, %76 : f32, !llvm.ptr<1>
          llvm.return
        }
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c128 = arith.constant 128 : index
    %c16 = arith.constant 16 : index
    %c12 = arith.constant 12 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !hal.fence
    %_params.weight = util.global.load @_params.weight : !hal.buffer
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c16) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %c-1_i64 = arith.constant -1 : i64
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %c0_i64 = arith.constant 0 : i64
    %c-1_i32 = arith.constant -1 : i32
    %status = hal.fence.await until([%_params.weight__timepoint]) timeout_millis(%c-1_i32) : i32
    %0 = util.null : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%c12}
    %status_0 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    %1 = hal.command_buffer.device<%cmd : !hal.command_buffer> : !hal.device
    %ok, %value = hal.device.query<%1 : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    %c-1 = arith.constant -1 : index
    %2 = arith.select %value, %c0, %c-1 : index
    scf.index_switch %2 
    case 0 {
      %pipeline_layout = hal.pipeline_layout.lookup device(%1 : !hal.device) layout(#pipeline_layout) : !hal.pipeline_layout
      %c1 = arith.constant 1 : index
      %c2 = arith.constant 2 : index
      hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%pipeline_layout : !hal.pipeline_layout)[%c0] bindings([
        %c0 = (%buffer : !hal.buffer)[%c0, %c16], 
        %c1 = (%_params.weight : !hal.buffer)[%c0, %c128], 
        %c2 = (%transient_buffer : !hal.buffer)[%c0, %c12]
      ])
      %c3_4 = arith.constant 3 : index
      hal.command_buffer.dispatch.symbol<%cmd : !hal.command_buffer> target(@main_dispatch_0::@cuda_nvptx_fb::@main_dispatch_0_matmul_1x3x4_f32) workgroups([%c3_4, %c1, %c1])
      scf.yield
    }
    default {
    }
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_1 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status_2 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence_1) commands([%cmd])
    %status_3 = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status_3, "failed to wait on timepoint"
    %c3 = arith.constant 3 : index
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c12] shape([%c3]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#pipeline_layout = #hal.pipeline.layout<push_constants = 0, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>
#translation = #iree_codegen.translation_info<LLVMGPUMatmulSimt>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private mutable @_params.weight__timepoint : !hal.fence
  util.global private @_params.weight : !hal.buffer
  util.initializer {
    %c0_i32 = arith.constant 0 : i32
    %c-1_i64 = arith.constant -1 : i64
    %c0 = arith.constant 0 : index
    %c128 = arith.constant 128 : index
    %c0_i64 = arith.constant 0 : i64
    %0 = util.null : !hal.fence
    %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #composite_of_128b
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    %did_import, %mapped = hal.allocator.import<%allocator : !hal.allocator> source(%buffer_cst : !util.buffer)[%c0, %c128] affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : i1, !hal.buffer
    cf.cond_br %did_import, ^bb2(%0, %mapped : !hal.fence, !hal.buffer), ^bb1
  ^bb1:  // pred: ^bb0
    %buffer = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : !hal.buffer{%c128}
    %memory_file = hal.ex.file.from_memory device(%device : !hal.device) affinity(%c-1_i64) access(Read) buffer(%buffer_cst : !util.buffer)[%c0 for %c128] flags(%c0_i32) : !hal.file
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.read<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) source(%memory_file : !hal.file)[%c0_i64] target(%buffer : !hal.buffer)[%c0] length(%c128) flags(0)
    cf.br ^bb2(%fence, %buffer : !hal.fence, !hal.buffer)
  ^bb2(%1: !hal.fence, %2: !hal.buffer):  // 2 preds: ^bb0, ^bb1
    util.global.store %2, @_params.weight : !hal.buffer
    util.global.store %1, @_params.weight__timepoint : !hal.fence
    util.initializer.return
  }
  hal.executable private @main_dispatch_0 {
    hal.executable.variant public @cuda_nvptx_fb target(#executable_target_cuda_nvptx_fb) {
      hal.executable.export public @main_dispatch_0_matmul_1x3x4_f32 ordinal(0) layout(#pipeline_layout) attributes {translation_info = #translation, workgroup_size = [1 : index, 3 : index, 1 : index]} {
      ^bb0(%arg0: !hal.device):
        %c3 = arith.constant 3 : index
        %c1 = arith.constant 1 : index
        hal.return %c3, %c1, %c1 : index, index, index
      }
      builtin.module {
        llvm.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg2: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias}) {
          %0 = llvm.mlir.constant(3 : i64) : i64
          %1 = llvm.mlir.constant(2 : i64) : i64
          %2 = llvm.mlir.constant(1 : i64) : i64
          %3 = llvm.mlir.constant(0 : i64) : i64
          %4 = llvm.mlir.constant(0 : i32) : i32
          %5 = llvm.mlir.constant(63 : index) : i64
          %6 = llvm.mlir.constant(4 : index) : i64
          %7 = llvm.mlir.constant(0 : index) : i64
          %8 = llvm.mlir.constant(1 : index) : i64
          %9 = llvm.mlir.constant(2 : index) : i64
          %10 = llvm.mlir.constant(3 : index) : i64
          %11 = llvm.ptrtoint %arg0 : !llvm.ptr<1> to i64
          %12 = llvm.and %11, %5  : i64
          %13 = llvm.icmp "eq" %12, %7 : i64
          "llvm.intr.assume"(%13) : (i1) -> ()
          %14 = llvm.ptrtoint %arg1 : !llvm.ptr<1> to i64
          %15 = llvm.and %14, %5  : i64
          %16 = llvm.icmp "eq" %15, %7 : i64
          "llvm.intr.assume"(%16) : (i1) -> ()
          %17 = llvm.getelementptr %arg1[16] : (!llvm.ptr<1>) -> !llvm.ptr<1>, f32
          %18 = llvm.ptrtoint %17 : !llvm.ptr<1> to i64
          %19 = llvm.and %18, %5  : i64
          %20 = llvm.icmp "eq" %19, %7 : i64
          "llvm.intr.assume"(%20) : (i1) -> ()
          %21 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
          %22 = llvm.and %21, %5  : i64
          %23 = llvm.icmp "eq" %22, %7 : i64
          "llvm.intr.assume"(%23) : (i1) -> ()
          %24 = nvvm.read.ptx.sreg.ctaid.x : i32
          %25 = llvm.sext %24 : i32 to i64
          %26 = llvm.mul %7, %6  : i64
          %27 = llvm.add %26, %7  : i64
          %28 = llvm.getelementptr %arg0[%27] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %29 = llvm.load %28 {alignment = 4 : i64} : !llvm.ptr<1> -> vector<4xf32>
          %30 = llvm.mul %7, %10  : i64
          %31 = llvm.add %30, %25  : i64
          %32 = llvm.getelementptr %arg1[%31] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %33 = llvm.load %32 : !llvm.ptr<1> -> f32
          %34 = llvm.mlir.undef : vector<1xf32>
          %35 = llvm.insertelement %33, %34[%4 : i32] : vector<1xf32>
          %36 = llvm.shufflevector %35, %34 [0] : vector<1xf32> 
          %37 = llvm.mul %8, %10  : i64
          %38 = llvm.add %37, %25  : i64
          %39 = llvm.getelementptr %arg1[%38] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %40 = llvm.load %39 : !llvm.ptr<1> -> f32
          %41 = llvm.insertelement %40, %34[%4 : i32] : vector<1xf32>
          %42 = llvm.shufflevector %41, %34 [0] : vector<1xf32> 
          %43 = llvm.mul %9, %10  : i64
          %44 = llvm.add %43, %25  : i64
          %45 = llvm.getelementptr %arg1[%44] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %46 = llvm.load %45 : !llvm.ptr<1> -> f32
          %47 = llvm.insertelement %46, %34[%4 : i32] : vector<1xf32>
          %48 = llvm.shufflevector %47, %34 [0] : vector<1xf32> 
          %49 = llvm.mul %10, %10  : i64
          %50 = llvm.add %49, %25  : i64
          %51 = llvm.getelementptr %arg1[%50] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %52 = llvm.load %51 : !llvm.ptr<1> -> f32
          %53 = llvm.insertelement %52, %34[%4 : i32] : vector<1xf32>
          %54 = llvm.shufflevector %53, %34 [0] : vector<1xf32> 
          %55 = llvm.getelementptr %17[%31] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %56 = llvm.load %55 : !llvm.ptr<1> -> f32
          %57 = llvm.insertelement %56, %34[%4 : i32] : vector<1xf32>
          %58 = llvm.shufflevector %57, %34 [0] : vector<1xf32> 
          %59 = llvm.extractelement %29[%3 : i64] : vector<4xf32>
          %60 = llvm.insertelement %59, %34[%4 : i32] : vector<1xf32>
          %61 = llvm.shufflevector %60, %34 [0] : vector<1xf32> 
          %62 = llvm.intr.fmuladd(%61, %36, %58)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
          %63 = llvm.extractelement %29[%2 : i64] : vector<4xf32>
          %64 = llvm.insertelement %63, %34[%4 : i32] : vector<1xf32>
          %65 = llvm.shufflevector %64, %34 [0] : vector<1xf32> 
          %66 = llvm.intr.fmuladd(%65, %42, %62)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
          %67 = llvm.extractelement %29[%1 : i64] : vector<4xf32>
          %68 = llvm.insertelement %67, %34[%4 : i32] : vector<1xf32>
          %69 = llvm.shufflevector %68, %34 [0] : vector<1xf32> 
          %70 = llvm.intr.fmuladd(%69, %48, %66)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
          %71 = llvm.extractelement %29[%0 : i64] : vector<4xf32>
          %72 = llvm.insertelement %71, %34[%4 : i32] : vector<1xf32>
          %73 = llvm.shufflevector %72, %34 [0] : vector<1xf32> 
          %74 = llvm.intr.fmuladd(%73, %54, %70)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
          %75 = llvm.extractelement %74[%3 : i64] : vector<1xf32>
          %76 = llvm.getelementptr %arg2[%31] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          llvm.store %75, %76 : f32, !llvm.ptr<1>
          llvm.return
        }
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c3 = arith.constant 3 : index
    %c2 = arith.constant 2 : index
    %c1 = arith.constant 1 : index
    %c-1 = arith.constant -1 : index
    %c-1_i32 = arith.constant -1 : i32
    %c0_i64 = arith.constant 0 : i64
    %c-1_i64 = arith.constant -1 : i64
    %c128 = arith.constant 128 : index
    %c16 = arith.constant 16 : index
    %c12 = arith.constant 12 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !hal.fence
    %_params.weight = util.global.load @_params.weight : !hal.buffer
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c16) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status = hal.fence.await until([%_params.weight__timepoint]) timeout_millis(%c-1_i32) : i32
    %0 = util.null : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%c12}
    %status_0 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    %1 = arith.select %value, %c0, %c-1 : index
    scf.index_switch %1 
    case 0 {
      %pipeline_layout = hal.pipeline_layout.lookup device(%device : !hal.device) layout(#pipeline_layout) : !hal.pipeline_layout
      hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%pipeline_layout : !hal.pipeline_layout)[%c0] bindings([
        %c0 = (%buffer : !hal.buffer)[%c0, %c16], 
        %c1 = (%_params.weight : !hal.buffer)[%c0, %c128], 
        %c2 = (%transient_buffer : !hal.buffer)[%c0, %c12]
      ])
      hal.command_buffer.dispatch.symbol<%cmd : !hal.command_buffer> target(@main_dispatch_0::@cuda_nvptx_fb::@main_dispatch_0_matmul_1x3x4_f32) workgroups([%c3, %c1, %c1])
      scf.yield
    }
    default {
    }
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_1 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status_2 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence_1) commands([%cmd])
    %status_3 = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status_3, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c12] shape([%c3]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After CSE (cse) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#pipeline_layout = #hal.pipeline.layout<push_constants = 0, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>
#translation = #iree_codegen.translation_info<LLVMGPUMatmulSimt>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private mutable @_params.weight__timepoint : !hal.fence
  util.global private @_params.weight : !hal.buffer
  util.initializer {
    %c0_i32 = arith.constant 0 : i32
    %c-1_i64 = arith.constant -1 : i64
    %c0 = arith.constant 0 : index
    %c128 = arith.constant 128 : index
    %c0_i64 = arith.constant 0 : i64
    %0 = util.null : !hal.fence
    %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #composite_of_128b
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    %did_import, %mapped = hal.allocator.import<%allocator : !hal.allocator> source(%buffer_cst : !util.buffer)[%c0, %c128] affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : i1, !hal.buffer
    cf.cond_br %did_import, ^bb2(%0, %mapped : !hal.fence, !hal.buffer), ^bb1
  ^bb1:  // pred: ^bb0
    %buffer = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : !hal.buffer{%c128}
    %memory_file = hal.ex.file.from_memory device(%device : !hal.device) affinity(%c-1_i64) access(Read) buffer(%buffer_cst : !util.buffer)[%c0 for %c128] flags(%c0_i32) : !hal.file
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.read<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) source(%memory_file : !hal.file)[%c0_i64] target(%buffer : !hal.buffer)[%c0] length(%c128) flags(0)
    cf.br ^bb2(%fence, %buffer : !hal.fence, !hal.buffer)
  ^bb2(%1: !hal.fence, %2: !hal.buffer):  // 2 preds: ^bb0, ^bb1
    util.global.store %2, @_params.weight : !hal.buffer
    util.global.store %1, @_params.weight__timepoint : !hal.fence
    util.initializer.return
  }
  hal.executable private @main_dispatch_0 {
    hal.executable.variant public @cuda_nvptx_fb target(#executable_target_cuda_nvptx_fb) {
      hal.executable.export public @main_dispatch_0_matmul_1x3x4_f32 ordinal(0) layout(#pipeline_layout) attributes {translation_info = #translation, workgroup_size = [1 : index, 3 : index, 1 : index]} {
      ^bb0(%arg0: !hal.device):
        %c3 = arith.constant 3 : index
        %c1 = arith.constant 1 : index
        hal.return %c3, %c1, %c1 : index, index, index
      }
      builtin.module {
        llvm.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg2: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias}) {
          %0 = llvm.mlir.constant(3 : i64) : i64
          %1 = llvm.mlir.constant(2 : i64) : i64
          %2 = llvm.mlir.constant(1 : i64) : i64
          %3 = llvm.mlir.constant(0 : i64) : i64
          %4 = llvm.mlir.constant(0 : i32) : i32
          %5 = llvm.mlir.constant(63 : index) : i64
          %6 = llvm.mlir.constant(4 : index) : i64
          %7 = llvm.mlir.constant(0 : index) : i64
          %8 = llvm.mlir.constant(1 : index) : i64
          %9 = llvm.mlir.constant(2 : index) : i64
          %10 = llvm.mlir.constant(3 : index) : i64
          %11 = llvm.ptrtoint %arg0 : !llvm.ptr<1> to i64
          %12 = llvm.and %11, %5  : i64
          %13 = llvm.icmp "eq" %12, %7 : i64
          "llvm.intr.assume"(%13) : (i1) -> ()
          %14 = llvm.ptrtoint %arg1 : !llvm.ptr<1> to i64
          %15 = llvm.and %14, %5  : i64
          %16 = llvm.icmp "eq" %15, %7 : i64
          "llvm.intr.assume"(%16) : (i1) -> ()
          %17 = llvm.getelementptr %arg1[16] : (!llvm.ptr<1>) -> !llvm.ptr<1>, f32
          %18 = llvm.ptrtoint %17 : !llvm.ptr<1> to i64
          %19 = llvm.and %18, %5  : i64
          %20 = llvm.icmp "eq" %19, %7 : i64
          "llvm.intr.assume"(%20) : (i1) -> ()
          %21 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
          %22 = llvm.and %21, %5  : i64
          %23 = llvm.icmp "eq" %22, %7 : i64
          "llvm.intr.assume"(%23) : (i1) -> ()
          %24 = nvvm.read.ptx.sreg.ctaid.x : i32
          %25 = llvm.sext %24 : i32 to i64
          %26 = llvm.mul %7, %6  : i64
          %27 = llvm.add %26, %7  : i64
          %28 = llvm.getelementptr %arg0[%27] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %29 = llvm.load %28 {alignment = 4 : i64} : !llvm.ptr<1> -> vector<4xf32>
          %30 = llvm.mul %7, %10  : i64
          %31 = llvm.add %30, %25  : i64
          %32 = llvm.getelementptr %arg1[%31] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %33 = llvm.load %32 : !llvm.ptr<1> -> f32
          %34 = llvm.mlir.undef : vector<1xf32>
          %35 = llvm.insertelement %33, %34[%4 : i32] : vector<1xf32>
          %36 = llvm.shufflevector %35, %34 [0] : vector<1xf32> 
          %37 = llvm.mul %8, %10  : i64
          %38 = llvm.add %37, %25  : i64
          %39 = llvm.getelementptr %arg1[%38] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %40 = llvm.load %39 : !llvm.ptr<1> -> f32
          %41 = llvm.insertelement %40, %34[%4 : i32] : vector<1xf32>
          %42 = llvm.shufflevector %41, %34 [0] : vector<1xf32> 
          %43 = llvm.mul %9, %10  : i64
          %44 = llvm.add %43, %25  : i64
          %45 = llvm.getelementptr %arg1[%44] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %46 = llvm.load %45 : !llvm.ptr<1> -> f32
          %47 = llvm.insertelement %46, %34[%4 : i32] : vector<1xf32>
          %48 = llvm.shufflevector %47, %34 [0] : vector<1xf32> 
          %49 = llvm.mul %10, %10  : i64
          %50 = llvm.add %49, %25  : i64
          %51 = llvm.getelementptr %arg1[%50] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %52 = llvm.load %51 : !llvm.ptr<1> -> f32
          %53 = llvm.insertelement %52, %34[%4 : i32] : vector<1xf32>
          %54 = llvm.shufflevector %53, %34 [0] : vector<1xf32> 
          %55 = llvm.getelementptr %17[%31] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %56 = llvm.load %55 : !llvm.ptr<1> -> f32
          %57 = llvm.insertelement %56, %34[%4 : i32] : vector<1xf32>
          %58 = llvm.shufflevector %57, %34 [0] : vector<1xf32> 
          %59 = llvm.extractelement %29[%3 : i64] : vector<4xf32>
          %60 = llvm.insertelement %59, %34[%4 : i32] : vector<1xf32>
          %61 = llvm.shufflevector %60, %34 [0] : vector<1xf32> 
          %62 = llvm.intr.fmuladd(%61, %36, %58)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
          %63 = llvm.extractelement %29[%2 : i64] : vector<4xf32>
          %64 = llvm.insertelement %63, %34[%4 : i32] : vector<1xf32>
          %65 = llvm.shufflevector %64, %34 [0] : vector<1xf32> 
          %66 = llvm.intr.fmuladd(%65, %42, %62)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
          %67 = llvm.extractelement %29[%1 : i64] : vector<4xf32>
          %68 = llvm.insertelement %67, %34[%4 : i32] : vector<1xf32>
          %69 = llvm.shufflevector %68, %34 [0] : vector<1xf32> 
          %70 = llvm.intr.fmuladd(%69, %48, %66)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
          %71 = llvm.extractelement %29[%0 : i64] : vector<4xf32>
          %72 = llvm.insertelement %71, %34[%4 : i32] : vector<1xf32>
          %73 = llvm.shufflevector %72, %34 [0] : vector<1xf32> 
          %74 = llvm.intr.fmuladd(%73, %54, %70)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
          %75 = llvm.extractelement %74[%3 : i64] : vector<1xf32>
          %76 = llvm.getelementptr %arg2[%31] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          llvm.store %75, %76 : f32, !llvm.ptr<1>
          llvm.return
        }
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c3 = arith.constant 3 : index
    %c2 = arith.constant 2 : index
    %c1 = arith.constant 1 : index
    %c-1 = arith.constant -1 : index
    %c-1_i32 = arith.constant -1 : i32
    %c0_i64 = arith.constant 0 : i64
    %c-1_i64 = arith.constant -1 : i64
    %c128 = arith.constant 128 : index
    %c16 = arith.constant 16 : index
    %c12 = arith.constant 12 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !hal.fence
    %_params.weight = util.global.load @_params.weight : !hal.buffer
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c16) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status = hal.fence.await until([%_params.weight__timepoint]) timeout_millis(%c-1_i32) : i32
    %0 = util.null : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%c12}
    %status_0 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    %1 = arith.select %value, %c0, %c-1 : index
    scf.index_switch %1 
    case 0 {
      %pipeline_layout = hal.pipeline_layout.lookup device(%device : !hal.device) layout(#pipeline_layout) : !hal.pipeline_layout
      hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%pipeline_layout : !hal.pipeline_layout)[%c0] bindings([
        %c0 = (%buffer : !hal.buffer)[%c0, %c16], 
        %c1 = (%_params.weight : !hal.buffer)[%c0, %c128], 
        %c2 = (%transient_buffer : !hal.buffer)[%c0, %c12]
      ])
      hal.command_buffer.dispatch.symbol<%cmd : !hal.command_buffer> target(@main_dispatch_0::@cuda_nvptx_fb::@main_dispatch_0_matmul_1x3x4_f32) workgroups([%c3, %c1, %c1])
      scf.yield
    }
    default {
    }
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_1 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status_2 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence_1) commands([%cmd])
    %status_3 = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status_3, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c12] shape([%c3]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.initializer {
  %c0_i32 = arith.constant 0 : i32
  %c-1_i64 = arith.constant -1 : i64
  %c0 = arith.constant 0 : index
  %c128 = arith.constant 128 : index
  %c0_i64 = arith.constant 0 : i64
  %0 = util.null : !hal.fence
  %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
  %device = hal.ex.shared_device : !hal.device
  %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
  %did_import, %mapped = hal.allocator.import<%allocator : !hal.allocator> source(%buffer_cst : !util.buffer)[%c0, %c128] affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : i1, !hal.buffer
  cf.cond_br %did_import, ^bb2(%0, %mapped : !hal.fence, !hal.buffer), ^bb1
^bb1:  // pred: ^bb0
  %buffer = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : !hal.buffer{%c128}
  %memory_file = hal.ex.file.from_memory device(%device : !hal.device) affinity(%c-1_i64) access(Read) buffer(%buffer_cst : !util.buffer)[%c0 for %c128] flags(%c0_i32) : !hal.file
  %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
  hal.device.queue.read<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) source(%memory_file : !hal.file)[%c0_i64] target(%buffer : !hal.buffer)[%c0] length(%c128) flags(0)
  cf.br ^bb2(%fence, %buffer : !hal.fence, !hal.buffer)
^bb2(%1: !hal.fence, %2: !hal.buffer):  // 2 preds: ^bb0, ^bb1
  util.global.store %2, @_params.weight : !hal.buffer
  util.global.store %1, @_params.weight__timepoint : !hal.fence
  util.initializer.return
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !hal.fence
  %_params.weight = util.global.load @_params.weight : !hal.buffer
  %c3 = arith.constant 3 : index
  %c2 = arith.constant 2 : index
  %c1 = arith.constant 1 : index
  %c-1 = arith.constant -1 : index
  %c-1_i32 = arith.constant -1 : i32
  %c0_i64 = arith.constant 0 : i64
  %c-1_i64 = arith.constant -1 : i64
  %c128 = arith.constant 128 : index
  %c16 = arith.constant 16 : index
  %c12 = arith.constant 12 : index
  %c553648160_i32 = arith.constant 553648160 : i32
  %c1_i32 = arith.constant 1 : i32
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %device = hal.ex.shared_device : !hal.device
  %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c16) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
  %status = hal.fence.await until([%_params.weight__timepoint]) timeout_millis(%c-1_i32) : i32
  %0 = util.null : !hal.fence
  %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%c12}
  %status_0 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
  %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
  %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
  %1 = arith.select %value, %c0, %c-1 : index
  scf.index_switch %1 
  case 0 {
    %pipeline_layout = hal.pipeline_layout.lookup device(%device : !hal.device) layout(<push_constants = 0, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>) : !hal.pipeline_layout
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%pipeline_layout : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%buffer : !hal.buffer)[%c0, %c16], 
      %c1 = (%_params.weight : !hal.buffer)[%c0, %c128], 
      %c2 = (%transient_buffer : !hal.buffer)[%c0, %c12]
    ])
    hal.command_buffer.dispatch.symbol<%cmd : !hal.command_buffer> target(@main_dispatch_0::@cuda_nvptx_fb::@main_dispatch_0_matmul_1x3x4_f32) workgroups([%c3, %c1, %c1])
    scf.yield
  }
  default {
  }
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  %fence_1 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
  %status_2 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
  hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence_1) commands([%cmd])
  %status_3 = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
  util.status.check_ok %status_3, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c12] shape([%c3]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
  return %view : !hal.buffer_view
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#pipeline_layout = #hal.pipeline.layout<push_constants = 0, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>
#translation = #iree_codegen.translation_info<LLVMGPUMatmulSimt>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private mutable @_params.weight__timepoint : !hal.fence
  util.global private @_params.weight : !hal.buffer
  util.initializer {
    %c0_i32 = arith.constant 0 : i32
    %c-1_i64 = arith.constant -1 : i64
    %c0 = arith.constant 0 : index
    %c128 = arith.constant 128 : index
    %c0_i64 = arith.constant 0 : i64
    %0 = util.null : !hal.fence
    %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #composite_of_128b
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    %did_import, %mapped = hal.allocator.import<%allocator : !hal.allocator> source(%buffer_cst : !util.buffer)[%c0, %c128] affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : i1, !hal.buffer
    cf.cond_br %did_import, ^bb2(%0, %mapped : !hal.fence, !hal.buffer), ^bb1
  ^bb1:  // pred: ^bb0
    %buffer = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : !hal.buffer{%c128}
    %memory_file = hal.ex.file.from_memory device(%device : !hal.device) affinity(%c-1_i64) access(Read) buffer(%buffer_cst : !util.buffer)[%c0 for %c128] flags(%c0_i32) : !hal.file
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.read<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) source(%memory_file : !hal.file)[%c0_i64] target(%buffer : !hal.buffer)[%c0] length(%c128) flags(0)
    cf.br ^bb2(%fence, %buffer : !hal.fence, !hal.buffer)
  ^bb2(%1: !hal.fence, %2: !hal.buffer):  // 2 preds: ^bb0, ^bb1
    util.global.store %2, @_params.weight : !hal.buffer
    util.global.store %1, @_params.weight__timepoint : !hal.fence
    util.initializer.return
  }
  hal.executable private @main_dispatch_0 {
    hal.executable.variant public @cuda_nvptx_fb target(#executable_target_cuda_nvptx_fb) {
      hal.executable.export public @main_dispatch_0_matmul_1x3x4_f32 ordinal(0) layout(#pipeline_layout) attributes {translation_info = #translation, workgroup_size = [1 : index, 3 : index, 1 : index]} {
      ^bb0(%arg0: !hal.device):
        %c3 = arith.constant 3 : index
        %c1 = arith.constant 1 : index
        hal.return %c3, %c1, %c1 : index, index, index
      }
      builtin.module {
        llvm.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg2: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias}) {
          %0 = llvm.mlir.constant(3 : i64) : i64
          %1 = llvm.mlir.constant(2 : i64) : i64
          %2 = llvm.mlir.constant(1 : i64) : i64
          %3 = llvm.mlir.constant(0 : i64) : i64
          %4 = llvm.mlir.constant(0 : i32) : i32
          %5 = llvm.mlir.constant(63 : index) : i64
          %6 = llvm.mlir.constant(4 : index) : i64
          %7 = llvm.mlir.constant(0 : index) : i64
          %8 = llvm.mlir.constant(1 : index) : i64
          %9 = llvm.mlir.constant(2 : index) : i64
          %10 = llvm.mlir.constant(3 : index) : i64
          %11 = llvm.ptrtoint %arg0 : !llvm.ptr<1> to i64
          %12 = llvm.and %11, %5  : i64
          %13 = llvm.icmp "eq" %12, %7 : i64
          "llvm.intr.assume"(%13) : (i1) -> ()
          %14 = llvm.ptrtoint %arg1 : !llvm.ptr<1> to i64
          %15 = llvm.and %14, %5  : i64
          %16 = llvm.icmp "eq" %15, %7 : i64
          "llvm.intr.assume"(%16) : (i1) -> ()
          %17 = llvm.getelementptr %arg1[16] : (!llvm.ptr<1>) -> !llvm.ptr<1>, f32
          %18 = llvm.ptrtoint %17 : !llvm.ptr<1> to i64
          %19 = llvm.and %18, %5  : i64
          %20 = llvm.icmp "eq" %19, %7 : i64
          "llvm.intr.assume"(%20) : (i1) -> ()
          %21 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
          %22 = llvm.and %21, %5  : i64
          %23 = llvm.icmp "eq" %22, %7 : i64
          "llvm.intr.assume"(%23) : (i1) -> ()
          %24 = nvvm.read.ptx.sreg.ctaid.x : i32
          %25 = llvm.sext %24 : i32 to i64
          %26 = llvm.mul %7, %6  : i64
          %27 = llvm.add %26, %7  : i64
          %28 = llvm.getelementptr %arg0[%27] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %29 = llvm.load %28 {alignment = 4 : i64} : !llvm.ptr<1> -> vector<4xf32>
          %30 = llvm.mul %7, %10  : i64
          %31 = llvm.add %30, %25  : i64
          %32 = llvm.getelementptr %arg1[%31] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %33 = llvm.load %32 : !llvm.ptr<1> -> f32
          %34 = llvm.mlir.undef : vector<1xf32>
          %35 = llvm.insertelement %33, %34[%4 : i32] : vector<1xf32>
          %36 = llvm.shufflevector %35, %34 [0] : vector<1xf32> 
          %37 = llvm.mul %8, %10  : i64
          %38 = llvm.add %37, %25  : i64
          %39 = llvm.getelementptr %arg1[%38] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %40 = llvm.load %39 : !llvm.ptr<1> -> f32
          %41 = llvm.insertelement %40, %34[%4 : i32] : vector<1xf32>
          %42 = llvm.shufflevector %41, %34 [0] : vector<1xf32> 
          %43 = llvm.mul %9, %10  : i64
          %44 = llvm.add %43, %25  : i64
          %45 = llvm.getelementptr %arg1[%44] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %46 = llvm.load %45 : !llvm.ptr<1> -> f32
          %47 = llvm.insertelement %46, %34[%4 : i32] : vector<1xf32>
          %48 = llvm.shufflevector %47, %34 [0] : vector<1xf32> 
          %49 = llvm.mul %10, %10  : i64
          %50 = llvm.add %49, %25  : i64
          %51 = llvm.getelementptr %arg1[%50] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %52 = llvm.load %51 : !llvm.ptr<1> -> f32
          %53 = llvm.insertelement %52, %34[%4 : i32] : vector<1xf32>
          %54 = llvm.shufflevector %53, %34 [0] : vector<1xf32> 
          %55 = llvm.getelementptr %17[%31] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %56 = llvm.load %55 : !llvm.ptr<1> -> f32
          %57 = llvm.insertelement %56, %34[%4 : i32] : vector<1xf32>
          %58 = llvm.shufflevector %57, %34 [0] : vector<1xf32> 
          %59 = llvm.extractelement %29[%3 : i64] : vector<4xf32>
          %60 = llvm.insertelement %59, %34[%4 : i32] : vector<1xf32>
          %61 = llvm.shufflevector %60, %34 [0] : vector<1xf32> 
          %62 = llvm.intr.fmuladd(%61, %36, %58)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
          %63 = llvm.extractelement %29[%2 : i64] : vector<4xf32>
          %64 = llvm.insertelement %63, %34[%4 : i32] : vector<1xf32>
          %65 = llvm.shufflevector %64, %34 [0] : vector<1xf32> 
          %66 = llvm.intr.fmuladd(%65, %42, %62)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
          %67 = llvm.extractelement %29[%1 : i64] : vector<4xf32>
          %68 = llvm.insertelement %67, %34[%4 : i32] : vector<1xf32>
          %69 = llvm.shufflevector %68, %34 [0] : vector<1xf32> 
          %70 = llvm.intr.fmuladd(%69, %48, %66)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
          %71 = llvm.extractelement %29[%0 : i64] : vector<4xf32>
          %72 = llvm.insertelement %71, %34[%4 : i32] : vector<1xf32>
          %73 = llvm.shufflevector %72, %34 [0] : vector<1xf32> 
          %74 = llvm.intr.fmuladd(%73, %54, %70)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
          %75 = llvm.extractelement %74[%3 : i64] : vector<1xf32>
          %76 = llvm.getelementptr %arg2[%31] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          llvm.store %75, %76 : f32, !llvm.ptr<1>
          llvm.return
        }
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %c12 = arith.constant 12 : index
    %c16 = arith.constant 16 : index
    %c128 = arith.constant 128 : index
    %c-1_i64 = arith.constant -1 : i64
    %c0_i64 = arith.constant 0 : i64
    %c-1_i32 = arith.constant -1 : i32
    %c-1 = arith.constant -1 : index
    %c1 = arith.constant 1 : index
    %c2 = arith.constant 2 : index
    %c3 = arith.constant 3 : index
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !hal.fence
    %_params.weight = util.global.load @_params.weight : !hal.buffer
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c16) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status = hal.fence.await until([%_params.weight__timepoint]) timeout_millis(%c-1_i32) : i32
    %0 = util.null : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%c12}
    %status_0 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    %1 = arith.select %value, %c0, %c-1 : index
    scf.index_switch %1 
    case 0 {
      %pipeline_layout = hal.pipeline_layout.lookup device(%device : !hal.device) layout(#pipeline_layout) : !hal.pipeline_layout
      hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%pipeline_layout : !hal.pipeline_layout)[%c0] bindings([
        %c0 = (%buffer : !hal.buffer)[%c0, %c16], 
        %c1 = (%_params.weight : !hal.buffer)[%c0, %c128], 
        %c2 = (%transient_buffer : !hal.buffer)[%c0, %c12]
      ])
      hal.command_buffer.dispatch.symbol<%cmd : !hal.command_buffer> target(@main_dispatch_0::@cuda_nvptx_fb::@main_dispatch_0_matmul_1x3x4_f32) workgroups([%c3, %c1, %c1])
      scf.yield
    }
    default {
    }
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_1 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status_2 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence_1) commands([%cmd])
    %status_3 = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status_3, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c12] shape([%c3]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#pipeline_layout = #hal.pipeline.layout<push_constants = 0, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>
#translation = #iree_codegen.translation_info<LLVMGPUMatmulSimt>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private mutable @_params.weight__timepoint : !hal.fence
  util.global private @_params.weight : !hal.buffer
  util.initializer {
    %c0_i32 = arith.constant 0 : i32
    %c-1_i64 = arith.constant -1 : i64
    %c0 = arith.constant 0 : index
    %c128 = arith.constant 128 : index
    %c0_i64 = arith.constant 0 : i64
    %0 = util.null : !hal.fence
    %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #composite_of_128b
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    %did_import, %mapped = hal.allocator.import<%allocator : !hal.allocator> source(%buffer_cst : !util.buffer)[%c0, %c128] affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : i1, !hal.buffer
    cf.cond_br %did_import, ^bb2(%0, %mapped : !hal.fence, !hal.buffer), ^bb1
  ^bb1:  // pred: ^bb0
    %buffer = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : !hal.buffer{%c128}
    %memory_file = hal.ex.file.from_memory device(%device : !hal.device) affinity(%c-1_i64) access(Read) buffer(%buffer_cst : !util.buffer)[%c0 for %c128] flags(%c0_i32) : !hal.file
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.read<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) source(%memory_file : !hal.file)[%c0_i64] target(%buffer : !hal.buffer)[%c0] length(%c128) flags(0)
    cf.br ^bb2(%fence, %buffer : !hal.fence, !hal.buffer)
  ^bb2(%1: !hal.fence, %2: !hal.buffer):  // 2 preds: ^bb0, ^bb1
    util.global.store %2, @_params.weight : !hal.buffer
    util.global.store %1, @_params.weight__timepoint : !hal.fence
    util.initializer.return
  }
  hal.executable private @main_dispatch_0 {
    hal.executable.variant public @cuda_nvptx_fb target(#executable_target_cuda_nvptx_fb) {
      hal.executable.export public @main_dispatch_0_matmul_1x3x4_f32 ordinal(0) layout(#pipeline_layout) attributes {translation_info = #translation, workgroup_size = [1 : index, 3 : index, 1 : index]} {
      ^bb0(%arg0: !hal.device):
        %c3 = arith.constant 3 : index
        %c1 = arith.constant 1 : index
        hal.return %c3, %c1, %c1 : index, index, index
      }
      builtin.module {
        llvm.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg2: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias}) {
          %0 = llvm.mlir.constant(3 : i64) : i64
          %1 = llvm.mlir.constant(2 : i64) : i64
          %2 = llvm.mlir.constant(1 : i64) : i64
          %3 = llvm.mlir.constant(0 : i64) : i64
          %4 = llvm.mlir.constant(0 : i32) : i32
          %5 = llvm.mlir.constant(63 : index) : i64
          %6 = llvm.mlir.constant(4 : index) : i64
          %7 = llvm.mlir.constant(0 : index) : i64
          %8 = llvm.mlir.constant(1 : index) : i64
          %9 = llvm.mlir.constant(2 : index) : i64
          %10 = llvm.mlir.constant(3 : index) : i64
          %11 = llvm.ptrtoint %arg0 : !llvm.ptr<1> to i64
          %12 = llvm.and %11, %5  : i64
          %13 = llvm.icmp "eq" %12, %7 : i64
          "llvm.intr.assume"(%13) : (i1) -> ()
          %14 = llvm.ptrtoint %arg1 : !llvm.ptr<1> to i64
          %15 = llvm.and %14, %5  : i64
          %16 = llvm.icmp "eq" %15, %7 : i64
          "llvm.intr.assume"(%16) : (i1) -> ()
          %17 = llvm.getelementptr %arg1[16] : (!llvm.ptr<1>) -> !llvm.ptr<1>, f32
          %18 = llvm.ptrtoint %17 : !llvm.ptr<1> to i64
          %19 = llvm.and %18, %5  : i64
          %20 = llvm.icmp "eq" %19, %7 : i64
          "llvm.intr.assume"(%20) : (i1) -> ()
          %21 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
          %22 = llvm.and %21, %5  : i64
          %23 = llvm.icmp "eq" %22, %7 : i64
          "llvm.intr.assume"(%23) : (i1) -> ()
          %24 = nvvm.read.ptx.sreg.ctaid.x : i32
          %25 = llvm.sext %24 : i32 to i64
          %26 = llvm.mul %7, %6  : i64
          %27 = llvm.add %26, %7  : i64
          %28 = llvm.getelementptr %arg0[%27] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %29 = llvm.load %28 {alignment = 4 : i64} : !llvm.ptr<1> -> vector<4xf32>
          %30 = llvm.mul %7, %10  : i64
          %31 = llvm.add %30, %25  : i64
          %32 = llvm.getelementptr %arg1[%31] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %33 = llvm.load %32 : !llvm.ptr<1> -> f32
          %34 = llvm.mlir.undef : vector<1xf32>
          %35 = llvm.insertelement %33, %34[%4 : i32] : vector<1xf32>
          %36 = llvm.shufflevector %35, %34 [0] : vector<1xf32> 
          %37 = llvm.mul %8, %10  : i64
          %38 = llvm.add %37, %25  : i64
          %39 = llvm.getelementptr %arg1[%38] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %40 = llvm.load %39 : !llvm.ptr<1> -> f32
          %41 = llvm.insertelement %40, %34[%4 : i32] : vector<1xf32>
          %42 = llvm.shufflevector %41, %34 [0] : vector<1xf32> 
          %43 = llvm.mul %9, %10  : i64
          %44 = llvm.add %43, %25  : i64
          %45 = llvm.getelementptr %arg1[%44] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %46 = llvm.load %45 : !llvm.ptr<1> -> f32
          %47 = llvm.insertelement %46, %34[%4 : i32] : vector<1xf32>
          %48 = llvm.shufflevector %47, %34 [0] : vector<1xf32> 
          %49 = llvm.mul %10, %10  : i64
          %50 = llvm.add %49, %25  : i64
          %51 = llvm.getelementptr %arg1[%50] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %52 = llvm.load %51 : !llvm.ptr<1> -> f32
          %53 = llvm.insertelement %52, %34[%4 : i32] : vector<1xf32>
          %54 = llvm.shufflevector %53, %34 [0] : vector<1xf32> 
          %55 = llvm.getelementptr %17[%31] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %56 = llvm.load %55 : !llvm.ptr<1> -> f32
          %57 = llvm.insertelement %56, %34[%4 : i32] : vector<1xf32>
          %58 = llvm.shufflevector %57, %34 [0] : vector<1xf32> 
          %59 = llvm.extractelement %29[%3 : i64] : vector<4xf32>
          %60 = llvm.insertelement %59, %34[%4 : i32] : vector<1xf32>
          %61 = llvm.shufflevector %60, %34 [0] : vector<1xf32> 
          %62 = llvm.intr.fmuladd(%61, %36, %58)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
          %63 = llvm.extractelement %29[%2 : i64] : vector<4xf32>
          %64 = llvm.insertelement %63, %34[%4 : i32] : vector<1xf32>
          %65 = llvm.shufflevector %64, %34 [0] : vector<1xf32> 
          %66 = llvm.intr.fmuladd(%65, %42, %62)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
          %67 = llvm.extractelement %29[%1 : i64] : vector<4xf32>
          %68 = llvm.insertelement %67, %34[%4 : i32] : vector<1xf32>
          %69 = llvm.shufflevector %68, %34 [0] : vector<1xf32> 
          %70 = llvm.intr.fmuladd(%69, %48, %66)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
          %71 = llvm.extractelement %29[%0 : i64] : vector<4xf32>
          %72 = llvm.insertelement %71, %34[%4 : i32] : vector<1xf32>
          %73 = llvm.shufflevector %72, %34 [0] : vector<1xf32> 
          %74 = llvm.intr.fmuladd(%73, %54, %70)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
          %75 = llvm.extractelement %74[%3 : i64] : vector<1xf32>
          %76 = llvm.getelementptr %arg2[%31] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          llvm.store %75, %76 : f32, !llvm.ptr<1>
          llvm.return
        }
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %c12 = arith.constant 12 : index
    %c16 = arith.constant 16 : index
    %c128 = arith.constant 128 : index
    %c-1_i64 = arith.constant -1 : i64
    %c0_i64 = arith.constant 0 : i64
    %c-1_i32 = arith.constant -1 : i32
    %c-1 = arith.constant -1 : index
    %c1 = arith.constant 1 : index
    %c2 = arith.constant 2 : index
    %c3 = arith.constant 3 : index
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !hal.fence
    %_params.weight = util.global.load @_params.weight : !hal.buffer
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c16) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status = hal.fence.await until([%_params.weight__timepoint]) timeout_millis(%c-1_i32) : i32
    %0 = util.null : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%c12}
    %status_0 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    %1 = arith.select %value, %c0, %c-1 : index
    scf.index_switch %1 
    case 0 {
      %pipeline_layout = hal.pipeline_layout.lookup device(%device : !hal.device) layout(#pipeline_layout) : !hal.pipeline_layout
      hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%pipeline_layout : !hal.pipeline_layout)[%c0] bindings([
        %c0 = (%buffer : !hal.buffer)[%c0, %c16], 
        %c1 = (%_params.weight : !hal.buffer)[%c0, %c128], 
        %c2 = (%transient_buffer : !hal.buffer)[%c0, %c12]
      ])
      hal.command_buffer.dispatch.symbol<%cmd : !hal.command_buffer> target(@main_dispatch_0::@cuda_nvptx_fb::@main_dispatch_0_matmul_1x3x4_f32) workgroups([%c3, %c1, %c1])
      scf.yield
    }
    default {
    }
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_1 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status_2 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence_1) commands([%cmd])
    %status_3 = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status_3, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c12] shape([%c3]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#pipeline_layout = #hal.pipeline.layout<push_constants = 0, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>
#translation = #iree_codegen.translation_info<LLVMGPUMatmulSimt>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private mutable @_params.weight__timepoint : !hal.fence
  util.global private @_params.weight : !hal.buffer
  util.initializer {
    %c0_i32 = arith.constant 0 : i32
    %c-1_i64 = arith.constant -1 : i64
    %c0 = arith.constant 0 : index
    %c128 = arith.constant 128 : index
    %c0_i64 = arith.constant 0 : i64
    %0 = util.null : !hal.fence
    %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #composite_of_128b
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    %did_import, %mapped = hal.allocator.import<%allocator : !hal.allocator> source(%buffer_cst : !util.buffer)[%c0, %c128] affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : i1, !hal.buffer
    cf.cond_br %did_import, ^bb2(%0, %mapped : !hal.fence, !hal.buffer), ^bb1
  ^bb1:  // pred: ^bb0
    %buffer = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : !hal.buffer{%c128}
    %memory_file = hal.ex.file.from_memory device(%device : !hal.device) affinity(%c-1_i64) access(Read) buffer(%buffer_cst : !util.buffer)[%c0 for %c128] flags(%c0_i32) : !hal.file
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.read<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) source(%memory_file : !hal.file)[%c0_i64] target(%buffer : !hal.buffer)[%c0] length(%c128) flags(0)
    cf.br ^bb2(%fence, %buffer : !hal.fence, !hal.buffer)
  ^bb2(%1: !hal.fence, %2: !hal.buffer):  // 2 preds: ^bb0, ^bb1
    util.global.store %2, @_params.weight : !hal.buffer
    util.global.store %1, @_params.weight__timepoint : !hal.fence
    util.initializer.return
  }
  hal.executable private @main_dispatch_0 {
    hal.executable.variant public @cuda_nvptx_fb target(#executable_target_cuda_nvptx_fb) {
      hal.executable.export public @main_dispatch_0_matmul_1x3x4_f32 ordinal(0) layout(#pipeline_layout) attributes {translation_info = #translation, workgroup_size = [1 : index, 3 : index, 1 : index]} {
      ^bb0(%arg0: !hal.device):
        %c3 = arith.constant 3 : index
        %c1 = arith.constant 1 : index
        hal.return %c3, %c1, %c1 : index, index, index
      }
      builtin.module {
        llvm.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg2: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias}) {
          %0 = llvm.mlir.constant(3 : i64) : i64
          %1 = llvm.mlir.constant(2 : i64) : i64
          %2 = llvm.mlir.constant(1 : i64) : i64
          %3 = llvm.mlir.constant(0 : i64) : i64
          %4 = llvm.mlir.constant(0 : i32) : i32
          %5 = llvm.mlir.constant(63 : index) : i64
          %6 = llvm.mlir.constant(4 : index) : i64
          %7 = llvm.mlir.constant(0 : index) : i64
          %8 = llvm.mlir.constant(1 : index) : i64
          %9 = llvm.mlir.constant(2 : index) : i64
          %10 = llvm.mlir.constant(3 : index) : i64
          %11 = llvm.ptrtoint %arg0 : !llvm.ptr<1> to i64
          %12 = llvm.and %11, %5  : i64
          %13 = llvm.icmp "eq" %12, %7 : i64
          "llvm.intr.assume"(%13) : (i1) -> ()
          %14 = llvm.ptrtoint %arg1 : !llvm.ptr<1> to i64
          %15 = llvm.and %14, %5  : i64
          %16 = llvm.icmp "eq" %15, %7 : i64
          "llvm.intr.assume"(%16) : (i1) -> ()
          %17 = llvm.getelementptr %arg1[16] : (!llvm.ptr<1>) -> !llvm.ptr<1>, f32
          %18 = llvm.ptrtoint %17 : !llvm.ptr<1> to i64
          %19 = llvm.and %18, %5  : i64
          %20 = llvm.icmp "eq" %19, %7 : i64
          "llvm.intr.assume"(%20) : (i1) -> ()
          %21 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
          %22 = llvm.and %21, %5  : i64
          %23 = llvm.icmp "eq" %22, %7 : i64
          "llvm.intr.assume"(%23) : (i1) -> ()
          %24 = nvvm.read.ptx.sreg.ctaid.x : i32
          %25 = llvm.sext %24 : i32 to i64
          %26 = llvm.mul %7, %6  : i64
          %27 = llvm.add %26, %7  : i64
          %28 = llvm.getelementptr %arg0[%27] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %29 = llvm.load %28 {alignment = 4 : i64} : !llvm.ptr<1> -> vector<4xf32>
          %30 = llvm.mul %7, %10  : i64
          %31 = llvm.add %30, %25  : i64
          %32 = llvm.getelementptr %arg1[%31] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %33 = llvm.load %32 : !llvm.ptr<1> -> f32
          %34 = llvm.mlir.undef : vector<1xf32>
          %35 = llvm.insertelement %33, %34[%4 : i32] : vector<1xf32>
          %36 = llvm.shufflevector %35, %34 [0] : vector<1xf32> 
          %37 = llvm.mul %8, %10  : i64
          %38 = llvm.add %37, %25  : i64
          %39 = llvm.getelementptr %arg1[%38] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %40 = llvm.load %39 : !llvm.ptr<1> -> f32
          %41 = llvm.insertelement %40, %34[%4 : i32] : vector<1xf32>
          %42 = llvm.shufflevector %41, %34 [0] : vector<1xf32> 
          %43 = llvm.mul %9, %10  : i64
          %44 = llvm.add %43, %25  : i64
          %45 = llvm.getelementptr %arg1[%44] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %46 = llvm.load %45 : !llvm.ptr<1> -> f32
          %47 = llvm.insertelement %46, %34[%4 : i32] : vector<1xf32>
          %48 = llvm.shufflevector %47, %34 [0] : vector<1xf32> 
          %49 = llvm.mul %10, %10  : i64
          %50 = llvm.add %49, %25  : i64
          %51 = llvm.getelementptr %arg1[%50] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %52 = llvm.load %51 : !llvm.ptr<1> -> f32
          %53 = llvm.insertelement %52, %34[%4 : i32] : vector<1xf32>
          %54 = llvm.shufflevector %53, %34 [0] : vector<1xf32> 
          %55 = llvm.getelementptr %17[%31] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %56 = llvm.load %55 : !llvm.ptr<1> -> f32
          %57 = llvm.insertelement %56, %34[%4 : i32] : vector<1xf32>
          %58 = llvm.shufflevector %57, %34 [0] : vector<1xf32> 
          %59 = llvm.extractelement %29[%3 : i64] : vector<4xf32>
          %60 = llvm.insertelement %59, %34[%4 : i32] : vector<1xf32>
          %61 = llvm.shufflevector %60, %34 [0] : vector<1xf32> 
          %62 = llvm.intr.fmuladd(%61, %36, %58)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
          %63 = llvm.extractelement %29[%2 : i64] : vector<4xf32>
          %64 = llvm.insertelement %63, %34[%4 : i32] : vector<1xf32>
          %65 = llvm.shufflevector %64, %34 [0] : vector<1xf32> 
          %66 = llvm.intr.fmuladd(%65, %42, %62)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
          %67 = llvm.extractelement %29[%1 : i64] : vector<4xf32>
          %68 = llvm.insertelement %67, %34[%4 : i32] : vector<1xf32>
          %69 = llvm.shufflevector %68, %34 [0] : vector<1xf32> 
          %70 = llvm.intr.fmuladd(%69, %48, %66)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
          %71 = llvm.extractelement %29[%0 : i64] : vector<4xf32>
          %72 = llvm.insertelement %71, %34[%4 : i32] : vector<1xf32>
          %73 = llvm.shufflevector %72, %34 [0] : vector<1xf32> 
          %74 = llvm.intr.fmuladd(%73, %54, %70)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
          %75 = llvm.extractelement %74[%3 : i64] : vector<1xf32>
          %76 = llvm.getelementptr %arg2[%31] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          llvm.store %75, %76 : f32, !llvm.ptr<1>
          llvm.return
        }
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %c12 = arith.constant 12 : index
    %c16 = arith.constant 16 : index
    %c128 = arith.constant 128 : index
    %c-1_i64 = arith.constant -1 : i64
    %c0_i64 = arith.constant 0 : i64
    %c-1_i32 = arith.constant -1 : i32
    %c-1 = arith.constant -1 : index
    %c1 = arith.constant 1 : index
    %c2 = arith.constant 2 : index
    %c3 = arith.constant 3 : index
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !hal.fence
    %_params.weight = util.global.load @_params.weight : !hal.buffer
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c16) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status = hal.fence.await until([%_params.weight__timepoint]) timeout_millis(%c-1_i32) : i32
    %0 = util.null : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%c12}
    %status_0 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    %1 = arith.select %value, %c0, %c-1 : index
    scf.index_switch %1 
    case 0 {
      %pipeline_layout = hal.pipeline_layout.lookup device(%device : !hal.device) layout(#pipeline_layout) : !hal.pipeline_layout
      hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%pipeline_layout : !hal.pipeline_layout)[%c0] bindings([
        %c0 = (%buffer : !hal.buffer)[%c0, %c16], 
        %c1 = (%_params.weight : !hal.buffer)[%c0, %c128], 
        %c2 = (%transient_buffer : !hal.buffer)[%c0, %c12]
      ])
      hal.command_buffer.dispatch.symbol<%cmd : !hal.command_buffer> target(@main_dispatch_0::@cuda_nvptx_fb::@main_dispatch_0_matmul_1x3x4_f32) workgroups([%c3, %c1, %c1])
      scf.yield
    }
    default {
    }
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_1 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status_2 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence_1) commands([%cmd])
    %status_3 = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status_3, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c12] shape([%c3]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::HAL::LinkTargetExecutablesPass (iree-hal-link-target-executables) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#pipeline_layout = #hal.pipeline.layout<push_constants = 0, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>
#translation = #iree_codegen.translation_info<LLVMGPUMatmulSimt>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private mutable @_params.weight__timepoint : !hal.fence
  util.global private @_params.weight : !hal.buffer
  util.initializer {
    %c0_i32 = arith.constant 0 : i32
    %c-1_i64 = arith.constant -1 : i64
    %c0 = arith.constant 0 : index
    %c128 = arith.constant 128 : index
    %c0_i64 = arith.constant 0 : i64
    %0 = util.null : !hal.fence
    %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #composite_of_128b
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    %did_import, %mapped = hal.allocator.import<%allocator : !hal.allocator> source(%buffer_cst : !util.buffer)[%c0, %c128] affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : i1, !hal.buffer
    cf.cond_br %did_import, ^bb2(%0, %mapped : !hal.fence, !hal.buffer), ^bb1
  ^bb1:  // pred: ^bb0
    %buffer = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : !hal.buffer{%c128}
    %memory_file = hal.ex.file.from_memory device(%device : !hal.device) affinity(%c-1_i64) access(Read) buffer(%buffer_cst : !util.buffer)[%c0 for %c128] flags(%c0_i32) : !hal.file
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.read<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) source(%memory_file : !hal.file)[%c0_i64] target(%buffer : !hal.buffer)[%c0] length(%c128) flags(0)
    cf.br ^bb2(%fence, %buffer : !hal.fence, !hal.buffer)
  ^bb2(%1: !hal.fence, %2: !hal.buffer):  // 2 preds: ^bb0, ^bb1
    util.global.store %2, @_params.weight : !hal.buffer
    util.global.store %1, @_params.weight__timepoint : !hal.fence
    util.initializer.return
  }
  hal.executable private @main_dispatch_0 {
    hal.executable.variant public @cuda_nvptx_fb target(#executable_target_cuda_nvptx_fb) {
      hal.executable.export public @main_dispatch_0_matmul_1x3x4_f32 ordinal(0) layout(#pipeline_layout) attributes {translation_info = #translation, workgroup_size = [1 : index, 3 : index, 1 : index]} {
      ^bb0(%arg0: !hal.device):
        %c3 = arith.constant 3 : index
        %c1 = arith.constant 1 : index
        hal.return %c3, %c1, %c1 : index, index, index
      }
      builtin.module {
        llvm.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg2: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias}) {
          %0 = llvm.mlir.constant(3 : i64) : i64
          %1 = llvm.mlir.constant(2 : i64) : i64
          %2 = llvm.mlir.constant(1 : i64) : i64
          %3 = llvm.mlir.constant(0 : i64) : i64
          %4 = llvm.mlir.constant(0 : i32) : i32
          %5 = llvm.mlir.constant(63 : index) : i64
          %6 = llvm.mlir.constant(4 : index) : i64
          %7 = llvm.mlir.constant(0 : index) : i64
          %8 = llvm.mlir.constant(1 : index) : i64
          %9 = llvm.mlir.constant(2 : index) : i64
          %10 = llvm.mlir.constant(3 : index) : i64
          %11 = llvm.ptrtoint %arg0 : !llvm.ptr<1> to i64
          %12 = llvm.and %11, %5  : i64
          %13 = llvm.icmp "eq" %12, %7 : i64
          "llvm.intr.assume"(%13) : (i1) -> ()
          %14 = llvm.ptrtoint %arg1 : !llvm.ptr<1> to i64
          %15 = llvm.and %14, %5  : i64
          %16 = llvm.icmp "eq" %15, %7 : i64
          "llvm.intr.assume"(%16) : (i1) -> ()
          %17 = llvm.getelementptr %arg1[16] : (!llvm.ptr<1>) -> !llvm.ptr<1>, f32
          %18 = llvm.ptrtoint %17 : !llvm.ptr<1> to i64
          %19 = llvm.and %18, %5  : i64
          %20 = llvm.icmp "eq" %19, %7 : i64
          "llvm.intr.assume"(%20) : (i1) -> ()
          %21 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
          %22 = llvm.and %21, %5  : i64
          %23 = llvm.icmp "eq" %22, %7 : i64
          "llvm.intr.assume"(%23) : (i1) -> ()
          %24 = nvvm.read.ptx.sreg.ctaid.x : i32
          %25 = llvm.sext %24 : i32 to i64
          %26 = llvm.mul %7, %6  : i64
          %27 = llvm.add %26, %7  : i64
          %28 = llvm.getelementptr %arg0[%27] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %29 = llvm.load %28 {alignment = 4 : i64} : !llvm.ptr<1> -> vector<4xf32>
          %30 = llvm.mul %7, %10  : i64
          %31 = llvm.add %30, %25  : i64
          %32 = llvm.getelementptr %arg1[%31] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %33 = llvm.load %32 : !llvm.ptr<1> -> f32
          %34 = llvm.mlir.undef : vector<1xf32>
          %35 = llvm.insertelement %33, %34[%4 : i32] : vector<1xf32>
          %36 = llvm.shufflevector %35, %34 [0] : vector<1xf32> 
          %37 = llvm.mul %8, %10  : i64
          %38 = llvm.add %37, %25  : i64
          %39 = llvm.getelementptr %arg1[%38] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %40 = llvm.load %39 : !llvm.ptr<1> -> f32
          %41 = llvm.insertelement %40, %34[%4 : i32] : vector<1xf32>
          %42 = llvm.shufflevector %41, %34 [0] : vector<1xf32> 
          %43 = llvm.mul %9, %10  : i64
          %44 = llvm.add %43, %25  : i64
          %45 = llvm.getelementptr %arg1[%44] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %46 = llvm.load %45 : !llvm.ptr<1> -> f32
          %47 = llvm.insertelement %46, %34[%4 : i32] : vector<1xf32>
          %48 = llvm.shufflevector %47, %34 [0] : vector<1xf32> 
          %49 = llvm.mul %10, %10  : i64
          %50 = llvm.add %49, %25  : i64
          %51 = llvm.getelementptr %arg1[%50] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %52 = llvm.load %51 : !llvm.ptr<1> -> f32
          %53 = llvm.insertelement %52, %34[%4 : i32] : vector<1xf32>
          %54 = llvm.shufflevector %53, %34 [0] : vector<1xf32> 
          %55 = llvm.getelementptr %17[%31] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %56 = llvm.load %55 : !llvm.ptr<1> -> f32
          %57 = llvm.insertelement %56, %34[%4 : i32] : vector<1xf32>
          %58 = llvm.shufflevector %57, %34 [0] : vector<1xf32> 
          %59 = llvm.extractelement %29[%3 : i64] : vector<4xf32>
          %60 = llvm.insertelement %59, %34[%4 : i32] : vector<1xf32>
          %61 = llvm.shufflevector %60, %34 [0] : vector<1xf32> 
          %62 = llvm.intr.fmuladd(%61, %36, %58)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
          %63 = llvm.extractelement %29[%2 : i64] : vector<4xf32>
          %64 = llvm.insertelement %63, %34[%4 : i32] : vector<1xf32>
          %65 = llvm.shufflevector %64, %34 [0] : vector<1xf32> 
          %66 = llvm.intr.fmuladd(%65, %42, %62)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
          %67 = llvm.extractelement %29[%1 : i64] : vector<4xf32>
          %68 = llvm.insertelement %67, %34[%4 : i32] : vector<1xf32>
          %69 = llvm.shufflevector %68, %34 [0] : vector<1xf32> 
          %70 = llvm.intr.fmuladd(%69, %48, %66)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
          %71 = llvm.extractelement %29[%0 : i64] : vector<4xf32>
          %72 = llvm.insertelement %71, %34[%4 : i32] : vector<1xf32>
          %73 = llvm.shufflevector %72, %34 [0] : vector<1xf32> 
          %74 = llvm.intr.fmuladd(%73, %54, %70)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
          %75 = llvm.extractelement %74[%3 : i64] : vector<1xf32>
          %76 = llvm.getelementptr %arg2[%31] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          llvm.store %75, %76 : f32, !llvm.ptr<1>
          llvm.return
        }
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %c12 = arith.constant 12 : index
    %c16 = arith.constant 16 : index
    %c128 = arith.constant 128 : index
    %c-1_i64 = arith.constant -1 : i64
    %c0_i64 = arith.constant 0 : i64
    %c-1_i32 = arith.constant -1 : i32
    %c-1 = arith.constant -1 : index
    %c1 = arith.constant 1 : index
    %c2 = arith.constant 2 : index
    %c3 = arith.constant 3 : index
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !hal.fence
    %_params.weight = util.global.load @_params.weight : !hal.buffer
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c16) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status = hal.fence.await until([%_params.weight__timepoint]) timeout_millis(%c-1_i32) : i32
    %0 = util.null : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%c12}
    %status_0 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    %1 = arith.select %value, %c0, %c-1 : index
    scf.index_switch %1 
    case 0 {
      %pipeline_layout = hal.pipeline_layout.lookup device(%device : !hal.device) layout(#pipeline_layout) : !hal.pipeline_layout
      hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%pipeline_layout : !hal.pipeline_layout)[%c0] bindings([
        %c0 = (%buffer : !hal.buffer)[%c0, %c16], 
        %c1 = (%_params.weight : !hal.buffer)[%c0, %c128], 
        %c2 = (%transient_buffer : !hal.buffer)[%c0, %c12]
      ])
      hal.command_buffer.dispatch.symbol<%cmd : !hal.command_buffer> target(@main_dispatch_0::@cuda_nvptx_fb::@main_dispatch_0_matmul_1x3x4_f32) workgroups([%c3, %c1, %c1])
      scf.yield
    }
    default {
    }
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_1 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status_2 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence_1) commands([%cmd])
    %status_3 = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status_3, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c12] shape([%c3]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After SymbolDCE (symbol-dce) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#pipeline_layout = #hal.pipeline.layout<push_constants = 0, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>
#translation = #iree_codegen.translation_info<LLVMGPUMatmulSimt>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private mutable @_params.weight__timepoint : !hal.fence
  util.global private @_params.weight : !hal.buffer
  util.initializer {
    %c0_i32 = arith.constant 0 : i32
    %c-1_i64 = arith.constant -1 : i64
    %c0 = arith.constant 0 : index
    %c128 = arith.constant 128 : index
    %c0_i64 = arith.constant 0 : i64
    %0 = util.null : !hal.fence
    %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #composite_of_128b
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    %did_import, %mapped = hal.allocator.import<%allocator : !hal.allocator> source(%buffer_cst : !util.buffer)[%c0, %c128] affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : i1, !hal.buffer
    cf.cond_br %did_import, ^bb2(%0, %mapped : !hal.fence, !hal.buffer), ^bb1
  ^bb1:  // pred: ^bb0
    %buffer = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : !hal.buffer{%c128}
    %memory_file = hal.ex.file.from_memory device(%device : !hal.device) affinity(%c-1_i64) access(Read) buffer(%buffer_cst : !util.buffer)[%c0 for %c128] flags(%c0_i32) : !hal.file
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.read<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) source(%memory_file : !hal.file)[%c0_i64] target(%buffer : !hal.buffer)[%c0] length(%c128) flags(0)
    cf.br ^bb2(%fence, %buffer : !hal.fence, !hal.buffer)
  ^bb2(%1: !hal.fence, %2: !hal.buffer):  // 2 preds: ^bb0, ^bb1
    util.global.store %2, @_params.weight : !hal.buffer
    util.global.store %1, @_params.weight__timepoint : !hal.fence
    util.initializer.return
  }
  hal.executable private @main_dispatch_0 {
    hal.executable.variant public @cuda_nvptx_fb target(#executable_target_cuda_nvptx_fb) {
      hal.executable.export public @main_dispatch_0_matmul_1x3x4_f32 ordinal(0) layout(#pipeline_layout) attributes {translation_info = #translation, workgroup_size = [1 : index, 3 : index, 1 : index]} {
      ^bb0(%arg0: !hal.device):
        %c3 = arith.constant 3 : index
        %c1 = arith.constant 1 : index
        hal.return %c3, %c1, %c1 : index, index, index
      }
      builtin.module {
        llvm.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg2: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias}) {
          %0 = llvm.mlir.constant(3 : i64) : i64
          %1 = llvm.mlir.constant(2 : i64) : i64
          %2 = llvm.mlir.constant(1 : i64) : i64
          %3 = llvm.mlir.constant(0 : i64) : i64
          %4 = llvm.mlir.constant(0 : i32) : i32
          %5 = llvm.mlir.constant(63 : index) : i64
          %6 = llvm.mlir.constant(4 : index) : i64
          %7 = llvm.mlir.constant(0 : index) : i64
          %8 = llvm.mlir.constant(1 : index) : i64
          %9 = llvm.mlir.constant(2 : index) : i64
          %10 = llvm.mlir.constant(3 : index) : i64
          %11 = llvm.ptrtoint %arg0 : !llvm.ptr<1> to i64
          %12 = llvm.and %11, %5  : i64
          %13 = llvm.icmp "eq" %12, %7 : i64
          "llvm.intr.assume"(%13) : (i1) -> ()
          %14 = llvm.ptrtoint %arg1 : !llvm.ptr<1> to i64
          %15 = llvm.and %14, %5  : i64
          %16 = llvm.icmp "eq" %15, %7 : i64
          "llvm.intr.assume"(%16) : (i1) -> ()
          %17 = llvm.getelementptr %arg1[16] : (!llvm.ptr<1>) -> !llvm.ptr<1>, f32
          %18 = llvm.ptrtoint %17 : !llvm.ptr<1> to i64
          %19 = llvm.and %18, %5  : i64
          %20 = llvm.icmp "eq" %19, %7 : i64
          "llvm.intr.assume"(%20) : (i1) -> ()
          %21 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
          %22 = llvm.and %21, %5  : i64
          %23 = llvm.icmp "eq" %22, %7 : i64
          "llvm.intr.assume"(%23) : (i1) -> ()
          %24 = nvvm.read.ptx.sreg.ctaid.x : i32
          %25 = llvm.sext %24 : i32 to i64
          %26 = llvm.mul %7, %6  : i64
          %27 = llvm.add %26, %7  : i64
          %28 = llvm.getelementptr %arg0[%27] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %29 = llvm.load %28 {alignment = 4 : i64} : !llvm.ptr<1> -> vector<4xf32>
          %30 = llvm.mul %7, %10  : i64
          %31 = llvm.add %30, %25  : i64
          %32 = llvm.getelementptr %arg1[%31] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %33 = llvm.load %32 : !llvm.ptr<1> -> f32
          %34 = llvm.mlir.undef : vector<1xf32>
          %35 = llvm.insertelement %33, %34[%4 : i32] : vector<1xf32>
          %36 = llvm.shufflevector %35, %34 [0] : vector<1xf32> 
          %37 = llvm.mul %8, %10  : i64
          %38 = llvm.add %37, %25  : i64
          %39 = llvm.getelementptr %arg1[%38] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %40 = llvm.load %39 : !llvm.ptr<1> -> f32
          %41 = llvm.insertelement %40, %34[%4 : i32] : vector<1xf32>
          %42 = llvm.shufflevector %41, %34 [0] : vector<1xf32> 
          %43 = llvm.mul %9, %10  : i64
          %44 = llvm.add %43, %25  : i64
          %45 = llvm.getelementptr %arg1[%44] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %46 = llvm.load %45 : !llvm.ptr<1> -> f32
          %47 = llvm.insertelement %46, %34[%4 : i32] : vector<1xf32>
          %48 = llvm.shufflevector %47, %34 [0] : vector<1xf32> 
          %49 = llvm.mul %10, %10  : i64
          %50 = llvm.add %49, %25  : i64
          %51 = llvm.getelementptr %arg1[%50] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %52 = llvm.load %51 : !llvm.ptr<1> -> f32
          %53 = llvm.insertelement %52, %34[%4 : i32] : vector<1xf32>
          %54 = llvm.shufflevector %53, %34 [0] : vector<1xf32> 
          %55 = llvm.getelementptr %17[%31] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %56 = llvm.load %55 : !llvm.ptr<1> -> f32
          %57 = llvm.insertelement %56, %34[%4 : i32] : vector<1xf32>
          %58 = llvm.shufflevector %57, %34 [0] : vector<1xf32> 
          %59 = llvm.extractelement %29[%3 : i64] : vector<4xf32>
          %60 = llvm.insertelement %59, %34[%4 : i32] : vector<1xf32>
          %61 = llvm.shufflevector %60, %34 [0] : vector<1xf32> 
          %62 = llvm.intr.fmuladd(%61, %36, %58)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
          %63 = llvm.extractelement %29[%2 : i64] : vector<4xf32>
          %64 = llvm.insertelement %63, %34[%4 : i32] : vector<1xf32>
          %65 = llvm.shufflevector %64, %34 [0] : vector<1xf32> 
          %66 = llvm.intr.fmuladd(%65, %42, %62)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
          %67 = llvm.extractelement %29[%1 : i64] : vector<4xf32>
          %68 = llvm.insertelement %67, %34[%4 : i32] : vector<1xf32>
          %69 = llvm.shufflevector %68, %34 [0] : vector<1xf32> 
          %70 = llvm.intr.fmuladd(%69, %48, %66)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
          %71 = llvm.extractelement %29[%0 : i64] : vector<4xf32>
          %72 = llvm.insertelement %71, %34[%4 : i32] : vector<1xf32>
          %73 = llvm.shufflevector %72, %34 [0] : vector<1xf32> 
          %74 = llvm.intr.fmuladd(%73, %54, %70)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
          %75 = llvm.extractelement %74[%3 : i64] : vector<1xf32>
          %76 = llvm.getelementptr %arg2[%31] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          llvm.store %75, %76 : f32, !llvm.ptr<1>
          llvm.return
        }
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %c12 = arith.constant 12 : index
    %c16 = arith.constant 16 : index
    %c128 = arith.constant 128 : index
    %c-1_i64 = arith.constant -1 : i64
    %c0_i64 = arith.constant 0 : i64
    %c-1_i32 = arith.constant -1 : i32
    %c-1 = arith.constant -1 : index
    %c1 = arith.constant 1 : index
    %c2 = arith.constant 2 : index
    %c3 = arith.constant 3 : index
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !hal.fence
    %_params.weight = util.global.load @_params.weight : !hal.buffer
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c16) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status = hal.fence.await until([%_params.weight__timepoint]) timeout_millis(%c-1_i32) : i32
    %0 = util.null : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%c12}
    %status_0 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    %1 = arith.select %value, %c0, %c-1 : index
    scf.index_switch %1 
    case 0 {
      %pipeline_layout = hal.pipeline_layout.lookup device(%device : !hal.device) layout(#pipeline_layout) : !hal.pipeline_layout
      hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%pipeline_layout : !hal.pipeline_layout)[%c0] bindings([
        %c0 = (%buffer : !hal.buffer)[%c0, %c16], 
        %c1 = (%_params.weight : !hal.buffer)[%c0, %c128], 
        %c2 = (%transient_buffer : !hal.buffer)[%c0, %c12]
      ])
      hal.command_buffer.dispatch.symbol<%cmd : !hal.command_buffer> target(@main_dispatch_0::@cuda_nvptx_fb::@main_dispatch_0_matmul_1x3x4_f32) workgroups([%c3, %c1, %c1])
      scf.yield
    }
    default {
    }
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_1 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status_2 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence_1) commands([%cmd])
    %status_3 = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status_3, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c12] shape([%c3]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::HAL::LinkExecutablesPass (iree-hal-link-executables) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#pipeline_layout = #hal.pipeline.layout<push_constants = 0, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>
#translation = #iree_codegen.translation_info<LLVMGPUMatmulSimt>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private mutable @_params.weight__timepoint : !hal.fence
  util.global private @_params.weight : !hal.buffer
  util.initializer {
    %c0_i32 = arith.constant 0 : i32
    %c-1_i64 = arith.constant -1 : i64
    %c0 = arith.constant 0 : index
    %c128 = arith.constant 128 : index
    %c0_i64 = arith.constant 0 : i64
    %0 = util.null : !hal.fence
    %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #composite_of_128b
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    %did_import, %mapped = hal.allocator.import<%allocator : !hal.allocator> source(%buffer_cst : !util.buffer)[%c0, %c128] affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : i1, !hal.buffer
    cf.cond_br %did_import, ^bb2(%0, %mapped : !hal.fence, !hal.buffer), ^bb1
  ^bb1:  // pred: ^bb0
    %buffer = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : !hal.buffer{%c128}
    %memory_file = hal.ex.file.from_memory device(%device : !hal.device) affinity(%c-1_i64) access(Read) buffer(%buffer_cst : !util.buffer)[%c0 for %c128] flags(%c0_i32) : !hal.file
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.read<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) source(%memory_file : !hal.file)[%c0_i64] target(%buffer : !hal.buffer)[%c0] length(%c128) flags(0)
    cf.br ^bb2(%fence, %buffer : !hal.fence, !hal.buffer)
  ^bb2(%1: !hal.fence, %2: !hal.buffer):  // 2 preds: ^bb0, ^bb1
    util.global.store %2, @_params.weight : !hal.buffer
    util.global.store %1, @_params.weight__timepoint : !hal.fence
    util.initializer.return
  }
  hal.executable private @main_dispatch_0 {
    hal.executable.variant public @cuda_nvptx_fb target(#executable_target_cuda_nvptx_fb) {
      hal.executable.export public @main_dispatch_0_matmul_1x3x4_f32 ordinal(0) layout(#pipeline_layout) attributes {translation_info = #translation, workgroup_size = [1 : index, 3 : index, 1 : index]} {
      ^bb0(%arg0: !hal.device):
        %c3 = arith.constant 3 : index
        %c1 = arith.constant 1 : index
        hal.return %c3, %c1, %c1 : index, index, index
      }
      builtin.module {
        llvm.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg2: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias}) {
          %0 = llvm.mlir.constant(3 : i64) : i64
          %1 = llvm.mlir.constant(2 : i64) : i64
          %2 = llvm.mlir.constant(1 : i64) : i64
          %3 = llvm.mlir.constant(0 : i64) : i64
          %4 = llvm.mlir.constant(0 : i32) : i32
          %5 = llvm.mlir.constant(63 : index) : i64
          %6 = llvm.mlir.constant(4 : index) : i64
          %7 = llvm.mlir.constant(0 : index) : i64
          %8 = llvm.mlir.constant(1 : index) : i64
          %9 = llvm.mlir.constant(2 : index) : i64
          %10 = llvm.mlir.constant(3 : index) : i64
          %11 = llvm.ptrtoint %arg0 : !llvm.ptr<1> to i64
          %12 = llvm.and %11, %5  : i64
          %13 = llvm.icmp "eq" %12, %7 : i64
          "llvm.intr.assume"(%13) : (i1) -> ()
          %14 = llvm.ptrtoint %arg1 : !llvm.ptr<1> to i64
          %15 = llvm.and %14, %5  : i64
          %16 = llvm.icmp "eq" %15, %7 : i64
          "llvm.intr.assume"(%16) : (i1) -> ()
          %17 = llvm.getelementptr %arg1[16] : (!llvm.ptr<1>) -> !llvm.ptr<1>, f32
          %18 = llvm.ptrtoint %17 : !llvm.ptr<1> to i64
          %19 = llvm.and %18, %5  : i64
          %20 = llvm.icmp "eq" %19, %7 : i64
          "llvm.intr.assume"(%20) : (i1) -> ()
          %21 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
          %22 = llvm.and %21, %5  : i64
          %23 = llvm.icmp "eq" %22, %7 : i64
          "llvm.intr.assume"(%23) : (i1) -> ()
          %24 = nvvm.read.ptx.sreg.ctaid.x : i32
          %25 = llvm.sext %24 : i32 to i64
          %26 = llvm.mul %7, %6  : i64
          %27 = llvm.add %26, %7  : i64
          %28 = llvm.getelementptr %arg0[%27] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %29 = llvm.load %28 {alignment = 4 : i64} : !llvm.ptr<1> -> vector<4xf32>
          %30 = llvm.mul %7, %10  : i64
          %31 = llvm.add %30, %25  : i64
          %32 = llvm.getelementptr %arg1[%31] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %33 = llvm.load %32 : !llvm.ptr<1> -> f32
          %34 = llvm.mlir.undef : vector<1xf32>
          %35 = llvm.insertelement %33, %34[%4 : i32] : vector<1xf32>
          %36 = llvm.shufflevector %35, %34 [0] : vector<1xf32> 
          %37 = llvm.mul %8, %10  : i64
          %38 = llvm.add %37, %25  : i64
          %39 = llvm.getelementptr %arg1[%38] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %40 = llvm.load %39 : !llvm.ptr<1> -> f32
          %41 = llvm.insertelement %40, %34[%4 : i32] : vector<1xf32>
          %42 = llvm.shufflevector %41, %34 [0] : vector<1xf32> 
          %43 = llvm.mul %9, %10  : i64
          %44 = llvm.add %43, %25  : i64
          %45 = llvm.getelementptr %arg1[%44] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %46 = llvm.load %45 : !llvm.ptr<1> -> f32
          %47 = llvm.insertelement %46, %34[%4 : i32] : vector<1xf32>
          %48 = llvm.shufflevector %47, %34 [0] : vector<1xf32> 
          %49 = llvm.mul %10, %10  : i64
          %50 = llvm.add %49, %25  : i64
          %51 = llvm.getelementptr %arg1[%50] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %52 = llvm.load %51 : !llvm.ptr<1> -> f32
          %53 = llvm.insertelement %52, %34[%4 : i32] : vector<1xf32>
          %54 = llvm.shufflevector %53, %34 [0] : vector<1xf32> 
          %55 = llvm.getelementptr %17[%31] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %56 = llvm.load %55 : !llvm.ptr<1> -> f32
          %57 = llvm.insertelement %56, %34[%4 : i32] : vector<1xf32>
          %58 = llvm.shufflevector %57, %34 [0] : vector<1xf32> 
          %59 = llvm.extractelement %29[%3 : i64] : vector<4xf32>
          %60 = llvm.insertelement %59, %34[%4 : i32] : vector<1xf32>
          %61 = llvm.shufflevector %60, %34 [0] : vector<1xf32> 
          %62 = llvm.intr.fmuladd(%61, %36, %58)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
          %63 = llvm.extractelement %29[%2 : i64] : vector<4xf32>
          %64 = llvm.insertelement %63, %34[%4 : i32] : vector<1xf32>
          %65 = llvm.shufflevector %64, %34 [0] : vector<1xf32> 
          %66 = llvm.intr.fmuladd(%65, %42, %62)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
          %67 = llvm.extractelement %29[%1 : i64] : vector<4xf32>
          %68 = llvm.insertelement %67, %34[%4 : i32] : vector<1xf32>
          %69 = llvm.shufflevector %68, %34 [0] : vector<1xf32> 
          %70 = llvm.intr.fmuladd(%69, %48, %66)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
          %71 = llvm.extractelement %29[%0 : i64] : vector<4xf32>
          %72 = llvm.insertelement %71, %34[%4 : i32] : vector<1xf32>
          %73 = llvm.shufflevector %72, %34 [0] : vector<1xf32> 
          %74 = llvm.intr.fmuladd(%73, %54, %70)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
          %75 = llvm.extractelement %74[%3 : i64] : vector<1xf32>
          %76 = llvm.getelementptr %arg2[%31] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          llvm.store %75, %76 : f32, !llvm.ptr<1>
          llvm.return
        }
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %c12 = arith.constant 12 : index
    %c16 = arith.constant 16 : index
    %c128 = arith.constant 128 : index
    %c-1_i64 = arith.constant -1 : i64
    %c0_i64 = arith.constant 0 : i64
    %c-1_i32 = arith.constant -1 : i32
    %c-1 = arith.constant -1 : index
    %c1 = arith.constant 1 : index
    %c2 = arith.constant 2 : index
    %c3 = arith.constant 3 : index
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !hal.fence
    %_params.weight = util.global.load @_params.weight : !hal.buffer
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c16) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status = hal.fence.await until([%_params.weight__timepoint]) timeout_millis(%c-1_i32) : i32
    %0 = util.null : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%c12}
    %status_0 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    %1 = arith.select %value, %c0, %c-1 : index
    scf.index_switch %1 
    case 0 {
      %pipeline_layout = hal.pipeline_layout.lookup device(%device : !hal.device) layout(#pipeline_layout) : !hal.pipeline_layout
      hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%pipeline_layout : !hal.pipeline_layout)[%c0] bindings([
        %c0 = (%buffer : !hal.buffer)[%c0, %c16], 
        %c1 = (%_params.weight : !hal.buffer)[%c0, %c128], 
        %c2 = (%transient_buffer : !hal.buffer)[%c0, %c12]
      ])
      hal.command_buffer.dispatch.symbol<%cmd : !hal.command_buffer> target(@main_dispatch_0::@cuda_nvptx_fb::@main_dispatch_0_matmul_1x3x4_f32) workgroups([%c3, %c1, %c1])
      scf.yield
    }
    default {
    }
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_1 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status_2 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence_1) commands([%cmd])
    %status_3 = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status_3, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c12] shape([%c3]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::HAL::ResolveExportOrdinalsPass (iree-hal-resolve-export-ordinals) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#pipeline_layout = #hal.pipeline.layout<push_constants = 0, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>
#translation = #iree_codegen.translation_info<LLVMGPUMatmulSimt>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private mutable @_params.weight__timepoint : !hal.fence
  util.global private @_params.weight : !hal.buffer
  util.initializer {
    %c0_i32 = arith.constant 0 : i32
    %c-1_i64 = arith.constant -1 : i64
    %c0 = arith.constant 0 : index
    %c128 = arith.constant 128 : index
    %c0_i64 = arith.constant 0 : i64
    %0 = util.null : !hal.fence
    %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #composite_of_128b
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    %did_import, %mapped = hal.allocator.import<%allocator : !hal.allocator> source(%buffer_cst : !util.buffer)[%c0, %c128] affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : i1, !hal.buffer
    cf.cond_br %did_import, ^bb2(%0, %mapped : !hal.fence, !hal.buffer), ^bb1
  ^bb1:  // pred: ^bb0
    %buffer = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : !hal.buffer{%c128}
    %memory_file = hal.ex.file.from_memory device(%device : !hal.device) affinity(%c-1_i64) access(Read) buffer(%buffer_cst : !util.buffer)[%c0 for %c128] flags(%c0_i32) : !hal.file
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.read<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) source(%memory_file : !hal.file)[%c0_i64] target(%buffer : !hal.buffer)[%c0] length(%c128) flags(0)
    cf.br ^bb2(%fence, %buffer : !hal.fence, !hal.buffer)
  ^bb2(%1: !hal.fence, %2: !hal.buffer):  // 2 preds: ^bb0, ^bb1
    util.global.store %2, @_params.weight : !hal.buffer
    util.global.store %1, @_params.weight__timepoint : !hal.fence
    util.initializer.return
  }
  hal.executable private @main_dispatch_0 {
    hal.executable.variant public @cuda_nvptx_fb target(#executable_target_cuda_nvptx_fb) {
      hal.executable.export public @main_dispatch_0_matmul_1x3x4_f32 ordinal(0) layout(#pipeline_layout) attributes {translation_info = #translation, workgroup_size = [1 : index, 3 : index, 1 : index]} {
      ^bb0(%arg0: !hal.device):
        %c3 = arith.constant 3 : index
        %c1 = arith.constant 1 : index
        hal.return %c3, %c1, %c1 : index, index, index
      }
      builtin.module {
        llvm.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg2: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias}) {
          %0 = llvm.mlir.constant(3 : i64) : i64
          %1 = llvm.mlir.constant(2 : i64) : i64
          %2 = llvm.mlir.constant(1 : i64) : i64
          %3 = llvm.mlir.constant(0 : i64) : i64
          %4 = llvm.mlir.constant(0 : i32) : i32
          %5 = llvm.mlir.constant(63 : index) : i64
          %6 = llvm.mlir.constant(4 : index) : i64
          %7 = llvm.mlir.constant(0 : index) : i64
          %8 = llvm.mlir.constant(1 : index) : i64
          %9 = llvm.mlir.constant(2 : index) : i64
          %10 = llvm.mlir.constant(3 : index) : i64
          %11 = llvm.ptrtoint %arg0 : !llvm.ptr<1> to i64
          %12 = llvm.and %11, %5  : i64
          %13 = llvm.icmp "eq" %12, %7 : i64
          "llvm.intr.assume"(%13) : (i1) -> ()
          %14 = llvm.ptrtoint %arg1 : !llvm.ptr<1> to i64
          %15 = llvm.and %14, %5  : i64
          %16 = llvm.icmp "eq" %15, %7 : i64
          "llvm.intr.assume"(%16) : (i1) -> ()
          %17 = llvm.getelementptr %arg1[16] : (!llvm.ptr<1>) -> !llvm.ptr<1>, f32
          %18 = llvm.ptrtoint %17 : !llvm.ptr<1> to i64
          %19 = llvm.and %18, %5  : i64
          %20 = llvm.icmp "eq" %19, %7 : i64
          "llvm.intr.assume"(%20) : (i1) -> ()
          %21 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
          %22 = llvm.and %21, %5  : i64
          %23 = llvm.icmp "eq" %22, %7 : i64
          "llvm.intr.assume"(%23) : (i1) -> ()
          %24 = nvvm.read.ptx.sreg.ctaid.x : i32
          %25 = llvm.sext %24 : i32 to i64
          %26 = llvm.mul %7, %6  : i64
          %27 = llvm.add %26, %7  : i64
          %28 = llvm.getelementptr %arg0[%27] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %29 = llvm.load %28 {alignment = 4 : i64} : !llvm.ptr<1> -> vector<4xf32>
          %30 = llvm.mul %7, %10  : i64
          %31 = llvm.add %30, %25  : i64
          %32 = llvm.getelementptr %arg1[%31] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %33 = llvm.load %32 : !llvm.ptr<1> -> f32
          %34 = llvm.mlir.undef : vector<1xf32>
          %35 = llvm.insertelement %33, %34[%4 : i32] : vector<1xf32>
          %36 = llvm.shufflevector %35, %34 [0] : vector<1xf32> 
          %37 = llvm.mul %8, %10  : i64
          %38 = llvm.add %37, %25  : i64
          %39 = llvm.getelementptr %arg1[%38] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %40 = llvm.load %39 : !llvm.ptr<1> -> f32
          %41 = llvm.insertelement %40, %34[%4 : i32] : vector<1xf32>
          %42 = llvm.shufflevector %41, %34 [0] : vector<1xf32> 
          %43 = llvm.mul %9, %10  : i64
          %44 = llvm.add %43, %25  : i64
          %45 = llvm.getelementptr %arg1[%44] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %46 = llvm.load %45 : !llvm.ptr<1> -> f32
          %47 = llvm.insertelement %46, %34[%4 : i32] : vector<1xf32>
          %48 = llvm.shufflevector %47, %34 [0] : vector<1xf32> 
          %49 = llvm.mul %10, %10  : i64
          %50 = llvm.add %49, %25  : i64
          %51 = llvm.getelementptr %arg1[%50] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %52 = llvm.load %51 : !llvm.ptr<1> -> f32
          %53 = llvm.insertelement %52, %34[%4 : i32] : vector<1xf32>
          %54 = llvm.shufflevector %53, %34 [0] : vector<1xf32> 
          %55 = llvm.getelementptr %17[%31] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %56 = llvm.load %55 : !llvm.ptr<1> -> f32
          %57 = llvm.insertelement %56, %34[%4 : i32] : vector<1xf32>
          %58 = llvm.shufflevector %57, %34 [0] : vector<1xf32> 
          %59 = llvm.extractelement %29[%3 : i64] : vector<4xf32>
          %60 = llvm.insertelement %59, %34[%4 : i32] : vector<1xf32>
          %61 = llvm.shufflevector %60, %34 [0] : vector<1xf32> 
          %62 = llvm.intr.fmuladd(%61, %36, %58)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
          %63 = llvm.extractelement %29[%2 : i64] : vector<4xf32>
          %64 = llvm.insertelement %63, %34[%4 : i32] : vector<1xf32>
          %65 = llvm.shufflevector %64, %34 [0] : vector<1xf32> 
          %66 = llvm.intr.fmuladd(%65, %42, %62)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
          %67 = llvm.extractelement %29[%1 : i64] : vector<4xf32>
          %68 = llvm.insertelement %67, %34[%4 : i32] : vector<1xf32>
          %69 = llvm.shufflevector %68, %34 [0] : vector<1xf32> 
          %70 = llvm.intr.fmuladd(%69, %48, %66)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
          %71 = llvm.extractelement %29[%0 : i64] : vector<4xf32>
          %72 = llvm.insertelement %71, %34[%4 : i32] : vector<1xf32>
          %73 = llvm.shufflevector %72, %34 [0] : vector<1xf32> 
          %74 = llvm.intr.fmuladd(%73, %54, %70)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
          %75 = llvm.extractelement %74[%3 : i64] : vector<1xf32>
          %76 = llvm.getelementptr %arg2[%31] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          llvm.store %75, %76 : f32, !llvm.ptr<1>
          llvm.return
        }
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %c12 = arith.constant 12 : index
    %c16 = arith.constant 16 : index
    %c128 = arith.constant 128 : index
    %c-1_i64 = arith.constant -1 : i64
    %c0_i64 = arith.constant 0 : i64
    %c-1_i32 = arith.constant -1 : i32
    %c-1 = arith.constant -1 : index
    %c1 = arith.constant 1 : index
    %c2 = arith.constant 2 : index
    %c3 = arith.constant 3 : index
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !hal.fence
    %_params.weight = util.global.load @_params.weight : !hal.buffer
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c16) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status = hal.fence.await until([%_params.weight__timepoint]) timeout_millis(%c-1_i32) : i32
    %0 = util.null : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%c12}
    %status_0 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    %1 = arith.select %value, %c0, %c-1 : index
    scf.index_switch %1 
    case 0 {
      %pipeline_layout = hal.pipeline_layout.lookup device(%device : !hal.device) layout(#pipeline_layout) : !hal.pipeline_layout
      hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%pipeline_layout : !hal.pipeline_layout)[%c0] bindings([
        %c0 = (%buffer : !hal.buffer)[%c0, %c16], 
        %c1 = (%_params.weight : !hal.buffer)[%c0, %c128], 
        %c2 = (%transient_buffer : !hal.buffer)[%c0, %c12]
      ])
      %2 = hal.command_buffer.device<%cmd : !hal.command_buffer> : !hal.device
      %exe = hal.executable.lookup device(%2 : !hal.device) executable(@main_dispatch_0) : !hal.executable
      hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%exe : !hal.executable)[0] workgroups([%c3, %c1, %c1])
      scf.yield
    }
    default {
    }
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_1 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status_2 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence_1) commands([%cmd])
    %status_3 = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status_3, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c12] shape([%c3]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::HAL::MaterializeResourceCachesPass (iree-hal-materialize-resource-caches) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#pipeline_layout = #hal.pipeline.layout<push_constants = 0, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>
#translation = #iree_codegen.translation_info<LLVMGPUMatmulSimt>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
    util.global.store %descriptor_set_layout, @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    util.initializer.return
  }
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.initializer {
    %_descriptor_set_layout_0 = util.global.load @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    %device = hal.ex.shared_device : !hal.device
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(0) layouts([%_descriptor_set_layout_0]) : !hal.pipeline_layout
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    util.initializer.return
  }
  util.global private @_executable_main_dispatch_0 : !hal.executable
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    %c-1 = arith.constant -1 : index
    %c0 = arith.constant 0 : index
    %0 = arith.select %value, %c0, %c-1 : index
    %1 = scf.index_switch %0 -> !hal.executable 
    case 0 {
      %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
      %exe = hal.executable.create device(%device : !hal.device) target(@main_dispatch_0::@cuda_nvptx_fb) layouts([%_pipeline_layout_0]) : !hal.executable
      scf.yield %exe : !hal.executable
    }
    default {
      %2 = util.null : !hal.executable
      scf.yield %2 : !hal.executable
    }
    util.global.store %1, @_executable_main_dispatch_0 : !hal.executable
    util.initializer.return
  }
  util.global private mutable @_params.weight__timepoint : !hal.fence
  util.global private @_params.weight : !hal.buffer
  util.initializer {
    %c0_i32 = arith.constant 0 : i32
    %c-1_i64 = arith.constant -1 : i64
    %c0 = arith.constant 0 : index
    %c128 = arith.constant 128 : index
    %c0_i64 = arith.constant 0 : i64
    %0 = util.null : !hal.fence
    %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #composite_of_128b
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    %did_import, %mapped = hal.allocator.import<%allocator : !hal.allocator> source(%buffer_cst : !util.buffer)[%c0, %c128] affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : i1, !hal.buffer
    cf.cond_br %did_import, ^bb2(%0, %mapped : !hal.fence, !hal.buffer), ^bb1
  ^bb1:  // pred: ^bb0
    %buffer = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : !hal.buffer{%c128}
    %memory_file = hal.ex.file.from_memory device(%device : !hal.device) affinity(%c-1_i64) access(Read) buffer(%buffer_cst : !util.buffer)[%c0 for %c128] flags(%c0_i32) : !hal.file
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.read<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) source(%memory_file : !hal.file)[%c0_i64] target(%buffer : !hal.buffer)[%c0] length(%c128) flags(0)
    cf.br ^bb2(%fence, %buffer : !hal.fence, !hal.buffer)
  ^bb2(%1: !hal.fence, %2: !hal.buffer):  // 2 preds: ^bb0, ^bb1
    util.global.store %2, @_params.weight : !hal.buffer
    util.global.store %1, @_params.weight__timepoint : !hal.fence
    util.initializer.return
  }
  hal.executable private @main_dispatch_0 {
    hal.executable.variant public @cuda_nvptx_fb target(#executable_target_cuda_nvptx_fb) {
      hal.executable.export public @main_dispatch_0_matmul_1x3x4_f32 ordinal(0) layout(#pipeline_layout) attributes {translation_info = #translation, workgroup_size = [1 : index, 3 : index, 1 : index]} {
      ^bb0(%arg0: !hal.device):
        %c3 = arith.constant 3 : index
        %c1 = arith.constant 1 : index
        hal.return %c3, %c1, %c1 : index, index, index
      }
      builtin.module {
        llvm.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg2: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias}) {
          %0 = llvm.mlir.constant(3 : i64) : i64
          %1 = llvm.mlir.constant(2 : i64) : i64
          %2 = llvm.mlir.constant(1 : i64) : i64
          %3 = llvm.mlir.constant(0 : i64) : i64
          %4 = llvm.mlir.constant(0 : i32) : i32
          %5 = llvm.mlir.constant(63 : index) : i64
          %6 = llvm.mlir.constant(4 : index) : i64
          %7 = llvm.mlir.constant(0 : index) : i64
          %8 = llvm.mlir.constant(1 : index) : i64
          %9 = llvm.mlir.constant(2 : index) : i64
          %10 = llvm.mlir.constant(3 : index) : i64
          %11 = llvm.ptrtoint %arg0 : !llvm.ptr<1> to i64
          %12 = llvm.and %11, %5  : i64
          %13 = llvm.icmp "eq" %12, %7 : i64
          "llvm.intr.assume"(%13) : (i1) -> ()
          %14 = llvm.ptrtoint %arg1 : !llvm.ptr<1> to i64
          %15 = llvm.and %14, %5  : i64
          %16 = llvm.icmp "eq" %15, %7 : i64
          "llvm.intr.assume"(%16) : (i1) -> ()
          %17 = llvm.getelementptr %arg1[16] : (!llvm.ptr<1>) -> !llvm.ptr<1>, f32
          %18 = llvm.ptrtoint %17 : !llvm.ptr<1> to i64
          %19 = llvm.and %18, %5  : i64
          %20 = llvm.icmp "eq" %19, %7 : i64
          "llvm.intr.assume"(%20) : (i1) -> ()
          %21 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
          %22 = llvm.and %21, %5  : i64
          %23 = llvm.icmp "eq" %22, %7 : i64
          "llvm.intr.assume"(%23) : (i1) -> ()
          %24 = nvvm.read.ptx.sreg.ctaid.x : i32
          %25 = llvm.sext %24 : i32 to i64
          %26 = llvm.mul %7, %6  : i64
          %27 = llvm.add %26, %7  : i64
          %28 = llvm.getelementptr %arg0[%27] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %29 = llvm.load %28 {alignment = 4 : i64} : !llvm.ptr<1> -> vector<4xf32>
          %30 = llvm.mul %7, %10  : i64
          %31 = llvm.add %30, %25  : i64
          %32 = llvm.getelementptr %arg1[%31] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %33 = llvm.load %32 : !llvm.ptr<1> -> f32
          %34 = llvm.mlir.undef : vector<1xf32>
          %35 = llvm.insertelement %33, %34[%4 : i32] : vector<1xf32>
          %36 = llvm.shufflevector %35, %34 [0] : vector<1xf32> 
          %37 = llvm.mul %8, %10  : i64
          %38 = llvm.add %37, %25  : i64
          %39 = llvm.getelementptr %arg1[%38] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %40 = llvm.load %39 : !llvm.ptr<1> -> f32
          %41 = llvm.insertelement %40, %34[%4 : i32] : vector<1xf32>
          %42 = llvm.shufflevector %41, %34 [0] : vector<1xf32> 
          %43 = llvm.mul %9, %10  : i64
          %44 = llvm.add %43, %25  : i64
          %45 = llvm.getelementptr %arg1[%44] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %46 = llvm.load %45 : !llvm.ptr<1> -> f32
          %47 = llvm.insertelement %46, %34[%4 : i32] : vector<1xf32>
          %48 = llvm.shufflevector %47, %34 [0] : vector<1xf32> 
          %49 = llvm.mul %10, %10  : i64
          %50 = llvm.add %49, %25  : i64
          %51 = llvm.getelementptr %arg1[%50] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %52 = llvm.load %51 : !llvm.ptr<1> -> f32
          %53 = llvm.insertelement %52, %34[%4 : i32] : vector<1xf32>
          %54 = llvm.shufflevector %53, %34 [0] : vector<1xf32> 
          %55 = llvm.getelementptr %17[%31] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %56 = llvm.load %55 : !llvm.ptr<1> -> f32
          %57 = llvm.insertelement %56, %34[%4 : i32] : vector<1xf32>
          %58 = llvm.shufflevector %57, %34 [0] : vector<1xf32> 
          %59 = llvm.extractelement %29[%3 : i64] : vector<4xf32>
          %60 = llvm.insertelement %59, %34[%4 : i32] : vector<1xf32>
          %61 = llvm.shufflevector %60, %34 [0] : vector<1xf32> 
          %62 = llvm.intr.fmuladd(%61, %36, %58)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
          %63 = llvm.extractelement %29[%2 : i64] : vector<4xf32>
          %64 = llvm.insertelement %63, %34[%4 : i32] : vector<1xf32>
          %65 = llvm.shufflevector %64, %34 [0] : vector<1xf32> 
          %66 = llvm.intr.fmuladd(%65, %42, %62)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
          %67 = llvm.extractelement %29[%1 : i64] : vector<4xf32>
          %68 = llvm.insertelement %67, %34[%4 : i32] : vector<1xf32>
          %69 = llvm.shufflevector %68, %34 [0] : vector<1xf32> 
          %70 = llvm.intr.fmuladd(%69, %48, %66)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
          %71 = llvm.extractelement %29[%0 : i64] : vector<4xf32>
          %72 = llvm.insertelement %71, %34[%4 : i32] : vector<1xf32>
          %73 = llvm.shufflevector %72, %34 [0] : vector<1xf32> 
          %74 = llvm.intr.fmuladd(%73, %54, %70)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
          %75 = llvm.extractelement %74[%3 : i64] : vector<1xf32>
          %76 = llvm.getelementptr %arg2[%31] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          llvm.store %75, %76 : f32, !llvm.ptr<1>
          llvm.return
        }
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %c12 = arith.constant 12 : index
    %c16 = arith.constant 16 : index
    %c128 = arith.constant 128 : index
    %c-1_i64 = arith.constant -1 : i64
    %c0_i64 = arith.constant 0 : i64
    %c-1_i32 = arith.constant -1 : i32
    %c-1 = arith.constant -1 : index
    %c1 = arith.constant 1 : index
    %c2 = arith.constant 2 : index
    %c3 = arith.constant 3 : index
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !hal.fence
    %_params.weight = util.global.load @_params.weight : !hal.buffer
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c16) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status = hal.fence.await until([%_params.weight__timepoint]) timeout_millis(%c-1_i32) : i32
    %0 = util.null : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%c12}
    %status_0 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    %1 = arith.select %value, %c0, %c-1 : index
    scf.index_switch %1 
    case 0 {
      %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
      hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
        %c0 = (%buffer : !hal.buffer)[%c0, %c16], 
        %c1 = (%_params.weight : !hal.buffer)[%c0, %c128], 
        %c2 = (%transient_buffer : !hal.buffer)[%c0, %c12]
      ])
      %2 = hal.command_buffer.device<%cmd : !hal.command_buffer> : !hal.device
      %_executable_main_dispatch_0 = util.global.load @_executable_main_dispatch_0 : !hal.executable
      hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_main_dispatch_0 : !hal.executable)[0] workgroups([%c3, %c1, %c1])
      scf.yield
    }
    default {
    }
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_1 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status_2 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence_1) commands([%cmd])
    %status_3 = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status_3, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c12] shape([%c3]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::HAL::MemoizeDeviceQueriesPass (iree-hal-memoize-device-queries) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#pipeline_layout = #hal.pipeline.layout<push_constants = 0, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>
#translation = #iree_codegen.translation_info<LLVMGPUMatmulSimt>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private @_device_query_0 : i1
  util.global private @_device_query_0_ok : i1
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    util.global.store %ok, @_device_query_0_ok : i1
    util.global.store %value, @_device_query_0 : i1
    util.initializer.return
  }
  util.global private @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
    util.global.store %descriptor_set_layout, @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    util.initializer.return
  }
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.initializer {
    %_descriptor_set_layout_0 = util.global.load @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    %device = hal.ex.shared_device : !hal.device
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(0) layouts([%_descriptor_set_layout_0]) : !hal.pipeline_layout
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    util.initializer.return
  }
  util.global private @_executable_main_dispatch_0 : !hal.executable
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %_device_query_0_ok = util.global.load @_device_query_0_ok : i1
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %c-1 = arith.constant -1 : index
    %c0 = arith.constant 0 : index
    %0 = arith.select %_device_query_0, %c0, %c-1 : index
    %1 = scf.index_switch %0 -> !hal.executable 
    case 0 {
      %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
      %exe = hal.executable.create device(%device : !hal.device) target(@main_dispatch_0::@cuda_nvptx_fb) layouts([%_pipeline_layout_0]) : !hal.executable
      scf.yield %exe : !hal.executable
    }
    default {
      %2 = util.null : !hal.executable
      scf.yield %2 : !hal.executable
    }
    util.global.store %1, @_executable_main_dispatch_0 : !hal.executable
    util.initializer.return
  }
  util.global private mutable @_params.weight__timepoint : !hal.fence
  util.global private @_params.weight : !hal.buffer
  util.initializer {
    %c0_i32 = arith.constant 0 : i32
    %c-1_i64 = arith.constant -1 : i64
    %c0 = arith.constant 0 : index
    %c128 = arith.constant 128 : index
    %c0_i64 = arith.constant 0 : i64
    %0 = util.null : !hal.fence
    %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #composite_of_128b
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    %did_import, %mapped = hal.allocator.import<%allocator : !hal.allocator> source(%buffer_cst : !util.buffer)[%c0, %c128] affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : i1, !hal.buffer
    cf.cond_br %did_import, ^bb2(%0, %mapped : !hal.fence, !hal.buffer), ^bb1
  ^bb1:  // pred: ^bb0
    %buffer = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : !hal.buffer{%c128}
    %memory_file = hal.ex.file.from_memory device(%device : !hal.device) affinity(%c-1_i64) access(Read) buffer(%buffer_cst : !util.buffer)[%c0 for %c128] flags(%c0_i32) : !hal.file
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.read<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) source(%memory_file : !hal.file)[%c0_i64] target(%buffer : !hal.buffer)[%c0] length(%c128) flags(0)
    cf.br ^bb2(%fence, %buffer : !hal.fence, !hal.buffer)
  ^bb2(%1: !hal.fence, %2: !hal.buffer):  // 2 preds: ^bb0, ^bb1
    util.global.store %2, @_params.weight : !hal.buffer
    util.global.store %1, @_params.weight__timepoint : !hal.fence
    util.initializer.return
  }
  hal.executable private @main_dispatch_0 {
    hal.executable.variant public @cuda_nvptx_fb target(#executable_target_cuda_nvptx_fb) {
      hal.executable.export public @main_dispatch_0_matmul_1x3x4_f32 ordinal(0) layout(#pipeline_layout) attributes {translation_info = #translation, workgroup_size = [1 : index, 3 : index, 1 : index]} {
      ^bb0(%arg0: !hal.device):
        %c3 = arith.constant 3 : index
        %c1 = arith.constant 1 : index
        hal.return %c3, %c1, %c1 : index, index, index
      }
      builtin.module {
        llvm.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg2: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias}) {
          %0 = llvm.mlir.constant(3 : i64) : i64
          %1 = llvm.mlir.constant(2 : i64) : i64
          %2 = llvm.mlir.constant(1 : i64) : i64
          %3 = llvm.mlir.constant(0 : i64) : i64
          %4 = llvm.mlir.constant(0 : i32) : i32
          %5 = llvm.mlir.constant(63 : index) : i64
          %6 = llvm.mlir.constant(4 : index) : i64
          %7 = llvm.mlir.constant(0 : index) : i64
          %8 = llvm.mlir.constant(1 : index) : i64
          %9 = llvm.mlir.constant(2 : index) : i64
          %10 = llvm.mlir.constant(3 : index) : i64
          %11 = llvm.ptrtoint %arg0 : !llvm.ptr<1> to i64
          %12 = llvm.and %11, %5  : i64
          %13 = llvm.icmp "eq" %12, %7 : i64
          "llvm.intr.assume"(%13) : (i1) -> ()
          %14 = llvm.ptrtoint %arg1 : !llvm.ptr<1> to i64
          %15 = llvm.and %14, %5  : i64
          %16 = llvm.icmp "eq" %15, %7 : i64
          "llvm.intr.assume"(%16) : (i1) -> ()
          %17 = llvm.getelementptr %arg1[16] : (!llvm.ptr<1>) -> !llvm.ptr<1>, f32
          %18 = llvm.ptrtoint %17 : !llvm.ptr<1> to i64
          %19 = llvm.and %18, %5  : i64
          %20 = llvm.icmp "eq" %19, %7 : i64
          "llvm.intr.assume"(%20) : (i1) -> ()
          %21 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
          %22 = llvm.and %21, %5  : i64
          %23 = llvm.icmp "eq" %22, %7 : i64
          "llvm.intr.assume"(%23) : (i1) -> ()
          %24 = nvvm.read.ptx.sreg.ctaid.x : i32
          %25 = llvm.sext %24 : i32 to i64
          %26 = llvm.mul %7, %6  : i64
          %27 = llvm.add %26, %7  : i64
          %28 = llvm.getelementptr %arg0[%27] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %29 = llvm.load %28 {alignment = 4 : i64} : !llvm.ptr<1> -> vector<4xf32>
          %30 = llvm.mul %7, %10  : i64
          %31 = llvm.add %30, %25  : i64
          %32 = llvm.getelementptr %arg1[%31] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %33 = llvm.load %32 : !llvm.ptr<1> -> f32
          %34 = llvm.mlir.undef : vector<1xf32>
          %35 = llvm.insertelement %33, %34[%4 : i32] : vector<1xf32>
          %36 = llvm.shufflevector %35, %34 [0] : vector<1xf32> 
          %37 = llvm.mul %8, %10  : i64
          %38 = llvm.add %37, %25  : i64
          %39 = llvm.getelementptr %arg1[%38] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %40 = llvm.load %39 : !llvm.ptr<1> -> f32
          %41 = llvm.insertelement %40, %34[%4 : i32] : vector<1xf32>
          %42 = llvm.shufflevector %41, %34 [0] : vector<1xf32> 
          %43 = llvm.mul %9, %10  : i64
          %44 = llvm.add %43, %25  : i64
          %45 = llvm.getelementptr %arg1[%44] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %46 = llvm.load %45 : !llvm.ptr<1> -> f32
          %47 = llvm.insertelement %46, %34[%4 : i32] : vector<1xf32>
          %48 = llvm.shufflevector %47, %34 [0] : vector<1xf32> 
          %49 = llvm.mul %10, %10  : i64
          %50 = llvm.add %49, %25  : i64
          %51 = llvm.getelementptr %arg1[%50] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %52 = llvm.load %51 : !llvm.ptr<1> -> f32
          %53 = llvm.insertelement %52, %34[%4 : i32] : vector<1xf32>
          %54 = llvm.shufflevector %53, %34 [0] : vector<1xf32> 
          %55 = llvm.getelementptr %17[%31] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %56 = llvm.load %55 : !llvm.ptr<1> -> f32
          %57 = llvm.insertelement %56, %34[%4 : i32] : vector<1xf32>
          %58 = llvm.shufflevector %57, %34 [0] : vector<1xf32> 
          %59 = llvm.extractelement %29[%3 : i64] : vector<4xf32>
          %60 = llvm.insertelement %59, %34[%4 : i32] : vector<1xf32>
          %61 = llvm.shufflevector %60, %34 [0] : vector<1xf32> 
          %62 = llvm.intr.fmuladd(%61, %36, %58)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
          %63 = llvm.extractelement %29[%2 : i64] : vector<4xf32>
          %64 = llvm.insertelement %63, %34[%4 : i32] : vector<1xf32>
          %65 = llvm.shufflevector %64, %34 [0] : vector<1xf32> 
          %66 = llvm.intr.fmuladd(%65, %42, %62)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
          %67 = llvm.extractelement %29[%1 : i64] : vector<4xf32>
          %68 = llvm.insertelement %67, %34[%4 : i32] : vector<1xf32>
          %69 = llvm.shufflevector %68, %34 [0] : vector<1xf32> 
          %70 = llvm.intr.fmuladd(%69, %48, %66)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
          %71 = llvm.extractelement %29[%0 : i64] : vector<4xf32>
          %72 = llvm.insertelement %71, %34[%4 : i32] : vector<1xf32>
          %73 = llvm.shufflevector %72, %34 [0] : vector<1xf32> 
          %74 = llvm.intr.fmuladd(%73, %54, %70)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
          %75 = llvm.extractelement %74[%3 : i64] : vector<1xf32>
          %76 = llvm.getelementptr %arg2[%31] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          llvm.store %75, %76 : f32, !llvm.ptr<1>
          llvm.return
        }
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %c12 = arith.constant 12 : index
    %c16 = arith.constant 16 : index
    %c128 = arith.constant 128 : index
    %c-1_i64 = arith.constant -1 : i64
    %c0_i64 = arith.constant 0 : i64
    %c-1_i32 = arith.constant -1 : i32
    %c-1 = arith.constant -1 : index
    %c1 = arith.constant 1 : index
    %c2 = arith.constant 2 : index
    %c3 = arith.constant 3 : index
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !hal.fence
    %_params.weight = util.global.load @_params.weight : !hal.buffer
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c16) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status = hal.fence.await until([%_params.weight__timepoint]) timeout_millis(%c-1_i32) : i32
    %0 = util.null : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%c12}
    %status_0 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    %_device_query_0_ok = util.global.load @_device_query_0_ok : i1
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %1 = arith.select %_device_query_0, %c0, %c-1 : index
    scf.index_switch %1 
    case 0 {
      %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
      hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
        %c0 = (%buffer : !hal.buffer)[%c0, %c16], 
        %c1 = (%_params.weight : !hal.buffer)[%c0, %c128], 
        %c2 = (%transient_buffer : !hal.buffer)[%c0, %c12]
      ])
      %2 = hal.command_buffer.device<%cmd : !hal.command_buffer> : !hal.device
      %_executable_main_dispatch_0 = util.global.load @_executable_main_dispatch_0 : !hal.executable
      hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_main_dispatch_0 : !hal.executable)[0] workgroups([%c3, %c1, %c1])
      scf.yield
    }
    default {
    }
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_1 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status_2 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence_1) commands([%cmd])
    %status_3 = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status_3, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c12] shape([%c3]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After CSE (cse) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#pipeline_layout = #hal.pipeline.layout<push_constants = 0, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>
#translation = #iree_codegen.translation_info<LLVMGPUMatmulSimt>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private @_device_query_0 : i1
  util.global private @_device_query_0_ok : i1
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    util.global.store %ok, @_device_query_0_ok : i1
    util.global.store %value, @_device_query_0 : i1
    util.initializer.return
  }
  util.global private @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
    util.global.store %descriptor_set_layout, @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    util.initializer.return
  }
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.initializer {
    %_descriptor_set_layout_0 = util.global.load @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    %device = hal.ex.shared_device : !hal.device
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(0) layouts([%_descriptor_set_layout_0]) : !hal.pipeline_layout
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    util.initializer.return
  }
  util.global private @_executable_main_dispatch_0 : !hal.executable
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %c-1 = arith.constant -1 : index
    %c0 = arith.constant 0 : index
    %0 = arith.select %_device_query_0, %c0, %c-1 : index
    %1 = scf.index_switch %0 -> !hal.executable 
    case 0 {
      %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
      %exe = hal.executable.create device(%device : !hal.device) target(@main_dispatch_0::@cuda_nvptx_fb) layouts([%_pipeline_layout_0]) : !hal.executable
      scf.yield %exe : !hal.executable
    }
    default {
      %2 = util.null : !hal.executable
      scf.yield %2 : !hal.executable
    }
    util.global.store %1, @_executable_main_dispatch_0 : !hal.executable
    util.initializer.return
  }
  util.global private mutable @_params.weight__timepoint : !hal.fence
  util.global private @_params.weight : !hal.buffer
  util.initializer {
    %c0_i32 = arith.constant 0 : i32
    %c-1_i64 = arith.constant -1 : i64
    %c0 = arith.constant 0 : index
    %c128 = arith.constant 128 : index
    %c0_i64 = arith.constant 0 : i64
    %0 = util.null : !hal.fence
    %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #composite_of_128b
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    %did_import, %mapped = hal.allocator.import<%allocator : !hal.allocator> source(%buffer_cst : !util.buffer)[%c0, %c128] affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : i1, !hal.buffer
    cf.cond_br %did_import, ^bb2(%0, %mapped : !hal.fence, !hal.buffer), ^bb1
  ^bb1:  // pred: ^bb0
    %buffer = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : !hal.buffer{%c128}
    %memory_file = hal.ex.file.from_memory device(%device : !hal.device) affinity(%c-1_i64) access(Read) buffer(%buffer_cst : !util.buffer)[%c0 for %c128] flags(%c0_i32) : !hal.file
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.read<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) source(%memory_file : !hal.file)[%c0_i64] target(%buffer : !hal.buffer)[%c0] length(%c128) flags(0)
    cf.br ^bb2(%fence, %buffer : !hal.fence, !hal.buffer)
  ^bb2(%1: !hal.fence, %2: !hal.buffer):  // 2 preds: ^bb0, ^bb1
    util.global.store %2, @_params.weight : !hal.buffer
    util.global.store %1, @_params.weight__timepoint : !hal.fence
    util.initializer.return
  }
  hal.executable private @main_dispatch_0 {
    hal.executable.variant public @cuda_nvptx_fb target(#executable_target_cuda_nvptx_fb) {
      hal.executable.export public @main_dispatch_0_matmul_1x3x4_f32 ordinal(0) layout(#pipeline_layout) attributes {translation_info = #translation, workgroup_size = [1 : index, 3 : index, 1 : index]} {
      ^bb0(%arg0: !hal.device):
        %c3 = arith.constant 3 : index
        %c1 = arith.constant 1 : index
        hal.return %c3, %c1, %c1 : index, index, index
      }
      builtin.module {
        llvm.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg2: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias}) {
          %0 = llvm.mlir.constant(3 : i64) : i64
          %1 = llvm.mlir.constant(2 : i64) : i64
          %2 = llvm.mlir.constant(1 : i64) : i64
          %3 = llvm.mlir.constant(0 : i64) : i64
          %4 = llvm.mlir.constant(0 : i32) : i32
          %5 = llvm.mlir.constant(63 : index) : i64
          %6 = llvm.mlir.constant(4 : index) : i64
          %7 = llvm.mlir.constant(0 : index) : i64
          %8 = llvm.mlir.constant(1 : index) : i64
          %9 = llvm.mlir.constant(2 : index) : i64
          %10 = llvm.mlir.constant(3 : index) : i64
          %11 = llvm.ptrtoint %arg0 : !llvm.ptr<1> to i64
          %12 = llvm.and %11, %5  : i64
          %13 = llvm.icmp "eq" %12, %7 : i64
          "llvm.intr.assume"(%13) : (i1) -> ()
          %14 = llvm.ptrtoint %arg1 : !llvm.ptr<1> to i64
          %15 = llvm.and %14, %5  : i64
          %16 = llvm.icmp "eq" %15, %7 : i64
          "llvm.intr.assume"(%16) : (i1) -> ()
          %17 = llvm.getelementptr %arg1[16] : (!llvm.ptr<1>) -> !llvm.ptr<1>, f32
          %18 = llvm.ptrtoint %17 : !llvm.ptr<1> to i64
          %19 = llvm.and %18, %5  : i64
          %20 = llvm.icmp "eq" %19, %7 : i64
          "llvm.intr.assume"(%20) : (i1) -> ()
          %21 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
          %22 = llvm.and %21, %5  : i64
          %23 = llvm.icmp "eq" %22, %7 : i64
          "llvm.intr.assume"(%23) : (i1) -> ()
          %24 = nvvm.read.ptx.sreg.ctaid.x : i32
          %25 = llvm.sext %24 : i32 to i64
          %26 = llvm.mul %7, %6  : i64
          %27 = llvm.add %26, %7  : i64
          %28 = llvm.getelementptr %arg0[%27] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %29 = llvm.load %28 {alignment = 4 : i64} : !llvm.ptr<1> -> vector<4xf32>
          %30 = llvm.mul %7, %10  : i64
          %31 = llvm.add %30, %25  : i64
          %32 = llvm.getelementptr %arg1[%31] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %33 = llvm.load %32 : !llvm.ptr<1> -> f32
          %34 = llvm.mlir.undef : vector<1xf32>
          %35 = llvm.insertelement %33, %34[%4 : i32] : vector<1xf32>
          %36 = llvm.shufflevector %35, %34 [0] : vector<1xf32> 
          %37 = llvm.mul %8, %10  : i64
          %38 = llvm.add %37, %25  : i64
          %39 = llvm.getelementptr %arg1[%38] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %40 = llvm.load %39 : !llvm.ptr<1> -> f32
          %41 = llvm.insertelement %40, %34[%4 : i32] : vector<1xf32>
          %42 = llvm.shufflevector %41, %34 [0] : vector<1xf32> 
          %43 = llvm.mul %9, %10  : i64
          %44 = llvm.add %43, %25  : i64
          %45 = llvm.getelementptr %arg1[%44] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %46 = llvm.load %45 : !llvm.ptr<1> -> f32
          %47 = llvm.insertelement %46, %34[%4 : i32] : vector<1xf32>
          %48 = llvm.shufflevector %47, %34 [0] : vector<1xf32> 
          %49 = llvm.mul %10, %10  : i64
          %50 = llvm.add %49, %25  : i64
          %51 = llvm.getelementptr %arg1[%50] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %52 = llvm.load %51 : !llvm.ptr<1> -> f32
          %53 = llvm.insertelement %52, %34[%4 : i32] : vector<1xf32>
          %54 = llvm.shufflevector %53, %34 [0] : vector<1xf32> 
          %55 = llvm.getelementptr %17[%31] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %56 = llvm.load %55 : !llvm.ptr<1> -> f32
          %57 = llvm.insertelement %56, %34[%4 : i32] : vector<1xf32>
          %58 = llvm.shufflevector %57, %34 [0] : vector<1xf32> 
          %59 = llvm.extractelement %29[%3 : i64] : vector<4xf32>
          %60 = llvm.insertelement %59, %34[%4 : i32] : vector<1xf32>
          %61 = llvm.shufflevector %60, %34 [0] : vector<1xf32> 
          %62 = llvm.intr.fmuladd(%61, %36, %58)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
          %63 = llvm.extractelement %29[%2 : i64] : vector<4xf32>
          %64 = llvm.insertelement %63, %34[%4 : i32] : vector<1xf32>
          %65 = llvm.shufflevector %64, %34 [0] : vector<1xf32> 
          %66 = llvm.intr.fmuladd(%65, %42, %62)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
          %67 = llvm.extractelement %29[%1 : i64] : vector<4xf32>
          %68 = llvm.insertelement %67, %34[%4 : i32] : vector<1xf32>
          %69 = llvm.shufflevector %68, %34 [0] : vector<1xf32> 
          %70 = llvm.intr.fmuladd(%69, %48, %66)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
          %71 = llvm.extractelement %29[%0 : i64] : vector<4xf32>
          %72 = llvm.insertelement %71, %34[%4 : i32] : vector<1xf32>
          %73 = llvm.shufflevector %72, %34 [0] : vector<1xf32> 
          %74 = llvm.intr.fmuladd(%73, %54, %70)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
          %75 = llvm.extractelement %74[%3 : i64] : vector<1xf32>
          %76 = llvm.getelementptr %arg2[%31] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          llvm.store %75, %76 : f32, !llvm.ptr<1>
          llvm.return
        }
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %c12 = arith.constant 12 : index
    %c16 = arith.constant 16 : index
    %c128 = arith.constant 128 : index
    %c-1_i64 = arith.constant -1 : i64
    %c0_i64 = arith.constant 0 : i64
    %c-1_i32 = arith.constant -1 : i32
    %c-1 = arith.constant -1 : index
    %c1 = arith.constant 1 : index
    %c2 = arith.constant 2 : index
    %c3 = arith.constant 3 : index
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !hal.fence
    %_params.weight = util.global.load @_params.weight : !hal.buffer
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c16) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status = hal.fence.await until([%_params.weight__timepoint]) timeout_millis(%c-1_i32) : i32
    %0 = util.null : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%c12}
    %status_0 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %1 = arith.select %_device_query_0, %c0, %c-1 : index
    scf.index_switch %1 
    case 0 {
      %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
      hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
        %c0 = (%buffer : !hal.buffer)[%c0, %c16], 
        %c1 = (%_params.weight : !hal.buffer)[%c0, %c128], 
        %c2 = (%transient_buffer : !hal.buffer)[%c0, %c12]
      ])
      %_executable_main_dispatch_0 = util.global.load @_executable_main_dispatch_0 : !hal.executable
      hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_main_dispatch_0 : !hal.executable)[0] workgroups([%c3, %c1, %c1])
      scf.yield
    }
    default {
    }
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_1 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status_2 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence_1) commands([%cmd])
    %status_3 = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status_3, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c12] shape([%c3]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#pipeline_layout = #hal.pipeline.layout<push_constants = 0, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>
#translation = #iree_codegen.translation_info<LLVMGPUMatmulSimt>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private @_device_query_0 : i1
  util.global private @_device_query_0_ok : i1
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    util.global.store %ok, @_device_query_0_ok : i1
    util.global.store %value, @_device_query_0 : i1
    util.initializer.return
  }
  util.global private @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
    util.global.store %descriptor_set_layout, @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    util.initializer.return
  }
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.initializer {
    %_descriptor_set_layout_0 = util.global.load @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    %device = hal.ex.shared_device : !hal.device
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(0) layouts([%_descriptor_set_layout_0]) : !hal.pipeline_layout
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    util.initializer.return
  }
  util.global private @_executable_main_dispatch_0 : !hal.executable
  util.initializer {
    %c0 = arith.constant 0 : index
    %c-1 = arith.constant -1 : index
    %device = hal.ex.shared_device : !hal.device
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %0 = arith.select %_device_query_0, %c0, %c-1 : index
    %1 = scf.index_switch %0 -> !hal.executable 
    case 0 {
      %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
      %exe = hal.executable.create device(%device : !hal.device) target(@main_dispatch_0::@cuda_nvptx_fb) layouts([%_pipeline_layout_0]) : !hal.executable
      scf.yield %exe : !hal.executable
    }
    default {
      %2 = util.null : !hal.executable
      scf.yield %2 : !hal.executable
    }
    util.global.store %1, @_executable_main_dispatch_0 : !hal.executable
    util.initializer.return
  }
  util.global private mutable @_params.weight__timepoint : !hal.fence
  util.global private @_params.weight : !hal.buffer
  util.initializer {
    %c0_i32 = arith.constant 0 : i32
    %c-1_i64 = arith.constant -1 : i64
    %c0 = arith.constant 0 : index
    %c128 = arith.constant 128 : index
    %c0_i64 = arith.constant 0 : i64
    %0 = util.null : !hal.fence
    %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #composite_of_128b
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    %did_import, %mapped = hal.allocator.import<%allocator : !hal.allocator> source(%buffer_cst : !util.buffer)[%c0, %c128] affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : i1, !hal.buffer
    cf.cond_br %did_import, ^bb2(%0, %mapped : !hal.fence, !hal.buffer), ^bb1
  ^bb1:  // pred: ^bb0
    %buffer = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : !hal.buffer{%c128}
    %memory_file = hal.ex.file.from_memory device(%device : !hal.device) affinity(%c-1_i64) access(Read) buffer(%buffer_cst : !util.buffer)[%c0 for %c128] flags(%c0_i32) : !hal.file
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.read<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) source(%memory_file : !hal.file)[%c0_i64] target(%buffer : !hal.buffer)[%c0] length(%c128) flags(0)
    cf.br ^bb2(%fence, %buffer : !hal.fence, !hal.buffer)
  ^bb2(%1: !hal.fence, %2: !hal.buffer):  // 2 preds: ^bb0, ^bb1
    util.global.store %2, @_params.weight : !hal.buffer
    util.global.store %1, @_params.weight__timepoint : !hal.fence
    util.initializer.return
  }
  hal.executable private @main_dispatch_0 {
    hal.executable.variant public @cuda_nvptx_fb target(#executable_target_cuda_nvptx_fb) {
      hal.executable.export public @main_dispatch_0_matmul_1x3x4_f32 ordinal(0) layout(#pipeline_layout) attributes {translation_info = #translation, workgroup_size = [1 : index, 3 : index, 1 : index]} {
      ^bb0(%arg0: !hal.device):
        %c3 = arith.constant 3 : index
        %c1 = arith.constant 1 : index
        hal.return %c3, %c1, %c1 : index, index, index
      }
      builtin.module {
        llvm.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg2: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias}) {
          %0 = llvm.mlir.constant(3 : i64) : i64
          %1 = llvm.mlir.constant(2 : i64) : i64
          %2 = llvm.mlir.constant(1 : i64) : i64
          %3 = llvm.mlir.constant(0 : i64) : i64
          %4 = llvm.mlir.constant(0 : i32) : i32
          %5 = llvm.mlir.constant(63 : index) : i64
          %6 = llvm.mlir.constant(4 : index) : i64
          %7 = llvm.mlir.constant(0 : index) : i64
          %8 = llvm.mlir.constant(1 : index) : i64
          %9 = llvm.mlir.constant(2 : index) : i64
          %10 = llvm.mlir.constant(3 : index) : i64
          %11 = llvm.ptrtoint %arg0 : !llvm.ptr<1> to i64
          %12 = llvm.and %11, %5  : i64
          %13 = llvm.icmp "eq" %12, %7 : i64
          "llvm.intr.assume"(%13) : (i1) -> ()
          %14 = llvm.ptrtoint %arg1 : !llvm.ptr<1> to i64
          %15 = llvm.and %14, %5  : i64
          %16 = llvm.icmp "eq" %15, %7 : i64
          "llvm.intr.assume"(%16) : (i1) -> ()
          %17 = llvm.getelementptr %arg1[16] : (!llvm.ptr<1>) -> !llvm.ptr<1>, f32
          %18 = llvm.ptrtoint %17 : !llvm.ptr<1> to i64
          %19 = llvm.and %18, %5  : i64
          %20 = llvm.icmp "eq" %19, %7 : i64
          "llvm.intr.assume"(%20) : (i1) -> ()
          %21 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
          %22 = llvm.and %21, %5  : i64
          %23 = llvm.icmp "eq" %22, %7 : i64
          "llvm.intr.assume"(%23) : (i1) -> ()
          %24 = nvvm.read.ptx.sreg.ctaid.x : i32
          %25 = llvm.sext %24 : i32 to i64
          %26 = llvm.mul %7, %6  : i64
          %27 = llvm.add %26, %7  : i64
          %28 = llvm.getelementptr %arg0[%27] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %29 = llvm.load %28 {alignment = 4 : i64} : !llvm.ptr<1> -> vector<4xf32>
          %30 = llvm.mul %7, %10  : i64
          %31 = llvm.add %30, %25  : i64
          %32 = llvm.getelementptr %arg1[%31] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %33 = llvm.load %32 : !llvm.ptr<1> -> f32
          %34 = llvm.mlir.undef : vector<1xf32>
          %35 = llvm.insertelement %33, %34[%4 : i32] : vector<1xf32>
          %36 = llvm.shufflevector %35, %34 [0] : vector<1xf32> 
          %37 = llvm.mul %8, %10  : i64
          %38 = llvm.add %37, %25  : i64
          %39 = llvm.getelementptr %arg1[%38] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %40 = llvm.load %39 : !llvm.ptr<1> -> f32
          %41 = llvm.insertelement %40, %34[%4 : i32] : vector<1xf32>
          %42 = llvm.shufflevector %41, %34 [0] : vector<1xf32> 
          %43 = llvm.mul %9, %10  : i64
          %44 = llvm.add %43, %25  : i64
          %45 = llvm.getelementptr %arg1[%44] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %46 = llvm.load %45 : !llvm.ptr<1> -> f32
          %47 = llvm.insertelement %46, %34[%4 : i32] : vector<1xf32>
          %48 = llvm.shufflevector %47, %34 [0] : vector<1xf32> 
          %49 = llvm.mul %10, %10  : i64
          %50 = llvm.add %49, %25  : i64
          %51 = llvm.getelementptr %arg1[%50] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %52 = llvm.load %51 : !llvm.ptr<1> -> f32
          %53 = llvm.insertelement %52, %34[%4 : i32] : vector<1xf32>
          %54 = llvm.shufflevector %53, %34 [0] : vector<1xf32> 
          %55 = llvm.getelementptr %17[%31] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %56 = llvm.load %55 : !llvm.ptr<1> -> f32
          %57 = llvm.insertelement %56, %34[%4 : i32] : vector<1xf32>
          %58 = llvm.shufflevector %57, %34 [0] : vector<1xf32> 
          %59 = llvm.extractelement %29[%3 : i64] : vector<4xf32>
          %60 = llvm.insertelement %59, %34[%4 : i32] : vector<1xf32>
          %61 = llvm.shufflevector %60, %34 [0] : vector<1xf32> 
          %62 = llvm.intr.fmuladd(%61, %36, %58)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
          %63 = llvm.extractelement %29[%2 : i64] : vector<4xf32>
          %64 = llvm.insertelement %63, %34[%4 : i32] : vector<1xf32>
          %65 = llvm.shufflevector %64, %34 [0] : vector<1xf32> 
          %66 = llvm.intr.fmuladd(%65, %42, %62)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
          %67 = llvm.extractelement %29[%1 : i64] : vector<4xf32>
          %68 = llvm.insertelement %67, %34[%4 : i32] : vector<1xf32>
          %69 = llvm.shufflevector %68, %34 [0] : vector<1xf32> 
          %70 = llvm.intr.fmuladd(%69, %48, %66)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
          %71 = llvm.extractelement %29[%0 : i64] : vector<4xf32>
          %72 = llvm.insertelement %71, %34[%4 : i32] : vector<1xf32>
          %73 = llvm.shufflevector %72, %34 [0] : vector<1xf32> 
          %74 = llvm.intr.fmuladd(%73, %54, %70)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
          %75 = llvm.extractelement %74[%3 : i64] : vector<1xf32>
          %76 = llvm.getelementptr %arg2[%31] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          llvm.store %75, %76 : f32, !llvm.ptr<1>
          llvm.return
        }
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %c12 = arith.constant 12 : index
    %c16 = arith.constant 16 : index
    %c128 = arith.constant 128 : index
    %c-1_i64 = arith.constant -1 : i64
    %c0_i64 = arith.constant 0 : i64
    %c-1_i32 = arith.constant -1 : i32
    %c-1 = arith.constant -1 : index
    %c1 = arith.constant 1 : index
    %c2 = arith.constant 2 : index
    %c3 = arith.constant 3 : index
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !hal.fence
    %_params.weight = util.global.load @_params.weight : !hal.buffer
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c16) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status = hal.fence.await until([%_params.weight__timepoint]) timeout_millis(%c-1_i32) : i32
    %0 = util.null : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%c12}
    %status_0 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %1 = arith.select %_device_query_0, %c0, %c-1 : index
    scf.index_switch %1 
    case 0 {
      %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
      hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
        %c0 = (%buffer : !hal.buffer)[%c0, %c16], 
        %c1 = (%_params.weight : !hal.buffer)[%c0, %c128], 
        %c2 = (%transient_buffer : !hal.buffer)[%c0, %c12]
      ])
      %_executable_main_dispatch_0 = util.global.load @_executable_main_dispatch_0 : !hal.executable
      hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_main_dispatch_0 : !hal.executable)[0] workgroups([%c3, %c1, %c1])
      scf.yield
    }
    default {
    }
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_1 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status_2 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence_1) commands([%cmd])
    %status_3 = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status_3, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c12] shape([%c3]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After CSE (cse) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#pipeline_layout = #hal.pipeline.layout<push_constants = 0, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>
#translation = #iree_codegen.translation_info<LLVMGPUMatmulSimt>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private @_device_query_0 : i1
  util.global private @_device_query_0_ok : i1
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    util.global.store %ok, @_device_query_0_ok : i1
    util.global.store %value, @_device_query_0 : i1
    util.initializer.return
  }
  util.global private @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
    util.global.store %descriptor_set_layout, @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    util.initializer.return
  }
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.initializer {
    %_descriptor_set_layout_0 = util.global.load @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    %device = hal.ex.shared_device : !hal.device
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(0) layouts([%_descriptor_set_layout_0]) : !hal.pipeline_layout
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    util.initializer.return
  }
  util.global private @_executable_main_dispatch_0 : !hal.executable
  util.initializer {
    %c0 = arith.constant 0 : index
    %c-1 = arith.constant -1 : index
    %device = hal.ex.shared_device : !hal.device
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %0 = arith.select %_device_query_0, %c0, %c-1 : index
    %1 = scf.index_switch %0 -> !hal.executable 
    case 0 {
      %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
      %exe = hal.executable.create device(%device : !hal.device) target(@main_dispatch_0::@cuda_nvptx_fb) layouts([%_pipeline_layout_0]) : !hal.executable
      scf.yield %exe : !hal.executable
    }
    default {
      %2 = util.null : !hal.executable
      scf.yield %2 : !hal.executable
    }
    util.global.store %1, @_executable_main_dispatch_0 : !hal.executable
    util.initializer.return
  }
  util.global private mutable @_params.weight__timepoint : !hal.fence
  util.global private @_params.weight : !hal.buffer
  util.initializer {
    %c0_i32 = arith.constant 0 : i32
    %c-1_i64 = arith.constant -1 : i64
    %c0 = arith.constant 0 : index
    %c128 = arith.constant 128 : index
    %c0_i64 = arith.constant 0 : i64
    %0 = util.null : !hal.fence
    %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #composite_of_128b
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    %did_import, %mapped = hal.allocator.import<%allocator : !hal.allocator> source(%buffer_cst : !util.buffer)[%c0, %c128] affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : i1, !hal.buffer
    cf.cond_br %did_import, ^bb2(%0, %mapped : !hal.fence, !hal.buffer), ^bb1
  ^bb1:  // pred: ^bb0
    %buffer = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : !hal.buffer{%c128}
    %memory_file = hal.ex.file.from_memory device(%device : !hal.device) affinity(%c-1_i64) access(Read) buffer(%buffer_cst : !util.buffer)[%c0 for %c128] flags(%c0_i32) : !hal.file
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.read<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) source(%memory_file : !hal.file)[%c0_i64] target(%buffer : !hal.buffer)[%c0] length(%c128) flags(0)
    cf.br ^bb2(%fence, %buffer : !hal.fence, !hal.buffer)
  ^bb2(%1: !hal.fence, %2: !hal.buffer):  // 2 preds: ^bb0, ^bb1
    util.global.store %2, @_params.weight : !hal.buffer
    util.global.store %1, @_params.weight__timepoint : !hal.fence
    util.initializer.return
  }
  hal.executable private @main_dispatch_0 {
    hal.executable.variant public @cuda_nvptx_fb target(#executable_target_cuda_nvptx_fb) {
      hal.executable.export public @main_dispatch_0_matmul_1x3x4_f32 ordinal(0) layout(#pipeline_layout) attributes {translation_info = #translation, workgroup_size = [1 : index, 3 : index, 1 : index]} {
      ^bb0(%arg0: !hal.device):
        %c3 = arith.constant 3 : index
        %c1 = arith.constant 1 : index
        hal.return %c3, %c1, %c1 : index, index, index
      }
      builtin.module {
        llvm.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg2: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias}) {
          %0 = llvm.mlir.constant(3 : i64) : i64
          %1 = llvm.mlir.constant(2 : i64) : i64
          %2 = llvm.mlir.constant(1 : i64) : i64
          %3 = llvm.mlir.constant(0 : i64) : i64
          %4 = llvm.mlir.constant(0 : i32) : i32
          %5 = llvm.mlir.constant(63 : index) : i64
          %6 = llvm.mlir.constant(4 : index) : i64
          %7 = llvm.mlir.constant(0 : index) : i64
          %8 = llvm.mlir.constant(1 : index) : i64
          %9 = llvm.mlir.constant(2 : index) : i64
          %10 = llvm.mlir.constant(3 : index) : i64
          %11 = llvm.ptrtoint %arg0 : !llvm.ptr<1> to i64
          %12 = llvm.and %11, %5  : i64
          %13 = llvm.icmp "eq" %12, %7 : i64
          "llvm.intr.assume"(%13) : (i1) -> ()
          %14 = llvm.ptrtoint %arg1 : !llvm.ptr<1> to i64
          %15 = llvm.and %14, %5  : i64
          %16 = llvm.icmp "eq" %15, %7 : i64
          "llvm.intr.assume"(%16) : (i1) -> ()
          %17 = llvm.getelementptr %arg1[16] : (!llvm.ptr<1>) -> !llvm.ptr<1>, f32
          %18 = llvm.ptrtoint %17 : !llvm.ptr<1> to i64
          %19 = llvm.and %18, %5  : i64
          %20 = llvm.icmp "eq" %19, %7 : i64
          "llvm.intr.assume"(%20) : (i1) -> ()
          %21 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
          %22 = llvm.and %21, %5  : i64
          %23 = llvm.icmp "eq" %22, %7 : i64
          "llvm.intr.assume"(%23) : (i1) -> ()
          %24 = nvvm.read.ptx.sreg.ctaid.x : i32
          %25 = llvm.sext %24 : i32 to i64
          %26 = llvm.mul %7, %6  : i64
          %27 = llvm.add %26, %7  : i64
          %28 = llvm.getelementptr %arg0[%27] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %29 = llvm.load %28 {alignment = 4 : i64} : !llvm.ptr<1> -> vector<4xf32>
          %30 = llvm.mul %7, %10  : i64
          %31 = llvm.add %30, %25  : i64
          %32 = llvm.getelementptr %arg1[%31] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %33 = llvm.load %32 : !llvm.ptr<1> -> f32
          %34 = llvm.mlir.undef : vector<1xf32>
          %35 = llvm.insertelement %33, %34[%4 : i32] : vector<1xf32>
          %36 = llvm.shufflevector %35, %34 [0] : vector<1xf32> 
          %37 = llvm.mul %8, %10  : i64
          %38 = llvm.add %37, %25  : i64
          %39 = llvm.getelementptr %arg1[%38] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %40 = llvm.load %39 : !llvm.ptr<1> -> f32
          %41 = llvm.insertelement %40, %34[%4 : i32] : vector<1xf32>
          %42 = llvm.shufflevector %41, %34 [0] : vector<1xf32> 
          %43 = llvm.mul %9, %10  : i64
          %44 = llvm.add %43, %25  : i64
          %45 = llvm.getelementptr %arg1[%44] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %46 = llvm.load %45 : !llvm.ptr<1> -> f32
          %47 = llvm.insertelement %46, %34[%4 : i32] : vector<1xf32>
          %48 = llvm.shufflevector %47, %34 [0] : vector<1xf32> 
          %49 = llvm.mul %10, %10  : i64
          %50 = llvm.add %49, %25  : i64
          %51 = llvm.getelementptr %arg1[%50] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %52 = llvm.load %51 : !llvm.ptr<1> -> f32
          %53 = llvm.insertelement %52, %34[%4 : i32] : vector<1xf32>
          %54 = llvm.shufflevector %53, %34 [0] : vector<1xf32> 
          %55 = llvm.getelementptr %17[%31] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %56 = llvm.load %55 : !llvm.ptr<1> -> f32
          %57 = llvm.insertelement %56, %34[%4 : i32] : vector<1xf32>
          %58 = llvm.shufflevector %57, %34 [0] : vector<1xf32> 
          %59 = llvm.extractelement %29[%3 : i64] : vector<4xf32>
          %60 = llvm.insertelement %59, %34[%4 : i32] : vector<1xf32>
          %61 = llvm.shufflevector %60, %34 [0] : vector<1xf32> 
          %62 = llvm.intr.fmuladd(%61, %36, %58)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
          %63 = llvm.extractelement %29[%2 : i64] : vector<4xf32>
          %64 = llvm.insertelement %63, %34[%4 : i32] : vector<1xf32>
          %65 = llvm.shufflevector %64, %34 [0] : vector<1xf32> 
          %66 = llvm.intr.fmuladd(%65, %42, %62)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
          %67 = llvm.extractelement %29[%1 : i64] : vector<4xf32>
          %68 = llvm.insertelement %67, %34[%4 : i32] : vector<1xf32>
          %69 = llvm.shufflevector %68, %34 [0] : vector<1xf32> 
          %70 = llvm.intr.fmuladd(%69, %48, %66)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
          %71 = llvm.extractelement %29[%0 : i64] : vector<4xf32>
          %72 = llvm.insertelement %71, %34[%4 : i32] : vector<1xf32>
          %73 = llvm.shufflevector %72, %34 [0] : vector<1xf32> 
          %74 = llvm.intr.fmuladd(%73, %54, %70)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
          %75 = llvm.extractelement %74[%3 : i64] : vector<1xf32>
          %76 = llvm.getelementptr %arg2[%31] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          llvm.store %75, %76 : f32, !llvm.ptr<1>
          llvm.return
        }
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %c12 = arith.constant 12 : index
    %c16 = arith.constant 16 : index
    %c128 = arith.constant 128 : index
    %c-1_i64 = arith.constant -1 : i64
    %c0_i64 = arith.constant 0 : i64
    %c-1_i32 = arith.constant -1 : i32
    %c-1 = arith.constant -1 : index
    %c1 = arith.constant 1 : index
    %c2 = arith.constant 2 : index
    %c3 = arith.constant 3 : index
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !hal.fence
    %_params.weight = util.global.load @_params.weight : !hal.buffer
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c16) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status = hal.fence.await until([%_params.weight__timepoint]) timeout_millis(%c-1_i32) : i32
    %0 = util.null : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%c12}
    %status_0 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %1 = arith.select %_device_query_0, %c0, %c-1 : index
    scf.index_switch %1 
    case 0 {
      %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
      hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
        %c0 = (%buffer : !hal.buffer)[%c0, %c16], 
        %c1 = (%_params.weight : !hal.buffer)[%c0, %c128], 
        %c2 = (%transient_buffer : !hal.buffer)[%c0, %c12]
      ])
      %_executable_main_dispatch_0 = util.global.load @_executable_main_dispatch_0 : !hal.executable
      hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_main_dispatch_0 : !hal.executable)[0] workgroups([%c3, %c1, %c1])
      scf.yield
    }
    default {
    }
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_1 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status_2 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence_1) commands([%cmd])
    %status_3 = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status_3, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c12] shape([%c3]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.initializer {
  %device = hal.ex.shared_device : !hal.device
  %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
  util.global.store %descriptor_set_layout, @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  util.initializer.return
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.initializer {
  %device = hal.ex.shared_device : !hal.device
  %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
  util.global.store %value, @_device_query_0 : i1
  util.global.store %ok, @_device_query_0_ok : i1
  util.initializer.return
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.initializer {
  %_descriptor_set_layout_0 = util.global.load @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  %device = hal.ex.shared_device : !hal.device
  %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(0) layouts([%_descriptor_set_layout_0]) : !hal.pipeline_layout
  util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
  util.initializer.return
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.initializer {
  %_device_query_0 = util.global.load @_device_query_0 : i1
  %c0 = arith.constant 0 : index
  %c-1 = arith.constant -1 : index
  %device = hal.ex.shared_device : !hal.device
  %0 = arith.select %_device_query_0, %c0, %c-1 : index
  %1 = scf.index_switch %0 -> !hal.executable 
  case 0 {
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device : !hal.device) target(@main_dispatch_0::@cuda_nvptx_fb) layouts([%_pipeline_layout_0]) : !hal.executable
    scf.yield %exe : !hal.executable
  }
  default {
    %2 = util.null : !hal.executable
    scf.yield %2 : !hal.executable
  }
  util.global.store %1, @_executable_main_dispatch_0 : !hal.executable
  util.initializer.return
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.initializer {
  %c0_i32 = arith.constant 0 : i32
  %c-1_i64 = arith.constant -1 : i64
  %c0 = arith.constant 0 : index
  %c128 = arith.constant 128 : index
  %c0_i64 = arith.constant 0 : i64
  %0 = util.null : !hal.fence
  %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
  %device = hal.ex.shared_device : !hal.device
  %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
  %did_import, %mapped = hal.allocator.import<%allocator : !hal.allocator> source(%buffer_cst : !util.buffer)[%c0, %c128] affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : i1, !hal.buffer
  cf.cond_br %did_import, ^bb2(%0, %mapped : !hal.fence, !hal.buffer), ^bb1
^bb1:  // pred: ^bb0
  %buffer = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : !hal.buffer{%c128}
  %memory_file = hal.ex.file.from_memory device(%device : !hal.device) affinity(%c-1_i64) access(Read) buffer(%buffer_cst : !util.buffer)[%c0 for %c128] flags(%c0_i32) : !hal.file
  %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
  hal.device.queue.read<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) source(%memory_file : !hal.file)[%c0_i64] target(%buffer : !hal.buffer)[%c0] length(%c128) flags(0)
  cf.br ^bb2(%fence, %buffer : !hal.fence, !hal.buffer)
^bb2(%1: !hal.fence, %2: !hal.buffer):  // 2 preds: ^bb0, ^bb1
  util.global.store %2, @_params.weight : !hal.buffer
  util.global.store %1, @_params.weight__timepoint : !hal.fence
  util.initializer.return
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !hal.fence
  %_params.weight = util.global.load @_params.weight : !hal.buffer
  %_device_query_0 = util.global.load @_device_query_0 : i1
  %c0 = arith.constant 0 : index
  %c4 = arith.constant 4 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %c12 = arith.constant 12 : index
  %c16 = arith.constant 16 : index
  %c128 = arith.constant 128 : index
  %c-1_i64 = arith.constant -1 : i64
  %c0_i64 = arith.constant 0 : i64
  %c-1_i32 = arith.constant -1 : i32
  %c-1 = arith.constant -1 : index
  %c1 = arith.constant 1 : index
  %c2 = arith.constant 2 : index
  %c3 = arith.constant 3 : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %device = hal.ex.shared_device : !hal.device
  %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c16) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
  %status = hal.fence.await until([%_params.weight__timepoint]) timeout_millis(%c-1_i32) : i32
  %0 = util.null : !hal.fence
  %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%c12}
  %status_0 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
  %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
  %1 = arith.select %_device_query_0, %c0, %c-1 : index
  scf.index_switch %1 
  case 0 {
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%buffer : !hal.buffer)[%c0, %c16], 
      %c1 = (%_params.weight : !hal.buffer)[%c0, %c128], 
      %c2 = (%transient_buffer : !hal.buffer)[%c0, %c12]
    ])
    %_executable_main_dispatch_0 = util.global.load @_executable_main_dispatch_0 : !hal.executable
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_main_dispatch_0 : !hal.executable)[0] workgroups([%c3, %c1, %c1])
    scf.yield
  }
  default {
  }
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  %fence_1 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
  %status_2 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
  hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence_1) commands([%cmd])
  %status_3 = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
  util.status.check_ok %status_3, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c12] shape([%c3]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
  return %view : !hal.buffer_view
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#pipeline_layout = #hal.pipeline.layout<push_constants = 0, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>
#translation = #iree_codegen.translation_info<LLVMGPUMatmulSimt>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private @_device_query_0 : i1
  util.global private @_device_query_0_ok : i1
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    util.global.store %value, @_device_query_0 : i1
    util.global.store %ok, @_device_query_0_ok : i1
    util.initializer.return
  }
  util.global private @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
    util.global.store %descriptor_set_layout, @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    util.initializer.return
  }
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.initializer {
    %_descriptor_set_layout_0 = util.global.load @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    %device = hal.ex.shared_device : !hal.device
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(0) layouts([%_descriptor_set_layout_0]) : !hal.pipeline_layout
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    util.initializer.return
  }
  util.global private @_executable_main_dispatch_0 : !hal.executable
  util.initializer {
    %c-1 = arith.constant -1 : index
    %c0 = arith.constant 0 : index
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %device = hal.ex.shared_device : !hal.device
    %0 = arith.select %_device_query_0, %c0, %c-1 : index
    %1 = scf.index_switch %0 -> !hal.executable 
    case 0 {
      %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
      %exe = hal.executable.create device(%device : !hal.device) target(@main_dispatch_0::@cuda_nvptx_fb) layouts([%_pipeline_layout_0]) : !hal.executable
      scf.yield %exe : !hal.executable
    }
    default {
      %2 = util.null : !hal.executable
      scf.yield %2 : !hal.executable
    }
    util.global.store %1, @_executable_main_dispatch_0 : !hal.executable
    util.initializer.return
  }
  util.global private mutable @_params.weight__timepoint : !hal.fence
  util.global private @_params.weight : !hal.buffer
  util.initializer {
    %c0_i32 = arith.constant 0 : i32
    %c-1_i64 = arith.constant -1 : i64
    %c0 = arith.constant 0 : index
    %c128 = arith.constant 128 : index
    %c0_i64 = arith.constant 0 : i64
    %0 = util.null : !hal.fence
    %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #composite_of_128b
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    %did_import, %mapped = hal.allocator.import<%allocator : !hal.allocator> source(%buffer_cst : !util.buffer)[%c0, %c128] affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : i1, !hal.buffer
    cf.cond_br %did_import, ^bb2(%0, %mapped : !hal.fence, !hal.buffer), ^bb1
  ^bb1:  // pred: ^bb0
    %buffer = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : !hal.buffer{%c128}
    %memory_file = hal.ex.file.from_memory device(%device : !hal.device) affinity(%c-1_i64) access(Read) buffer(%buffer_cst : !util.buffer)[%c0 for %c128] flags(%c0_i32) : !hal.file
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.read<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) source(%memory_file : !hal.file)[%c0_i64] target(%buffer : !hal.buffer)[%c0] length(%c128) flags(0)
    cf.br ^bb2(%fence, %buffer : !hal.fence, !hal.buffer)
  ^bb2(%1: !hal.fence, %2: !hal.buffer):  // 2 preds: ^bb0, ^bb1
    util.global.store %2, @_params.weight : !hal.buffer
    util.global.store %1, @_params.weight__timepoint : !hal.fence
    util.initializer.return
  }
  hal.executable private @main_dispatch_0 {
    hal.executable.variant public @cuda_nvptx_fb target(#executable_target_cuda_nvptx_fb) {
      hal.executable.export public @main_dispatch_0_matmul_1x3x4_f32 ordinal(0) layout(#pipeline_layout) attributes {translation_info = #translation, workgroup_size = [1 : index, 3 : index, 1 : index]} {
      ^bb0(%arg0: !hal.device):
        %c3 = arith.constant 3 : index
        %c1 = arith.constant 1 : index
        hal.return %c3, %c1, %c1 : index, index, index
      }
      builtin.module {
        llvm.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg2: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias}) {
          %0 = llvm.mlir.constant(3 : i64) : i64
          %1 = llvm.mlir.constant(2 : i64) : i64
          %2 = llvm.mlir.constant(1 : i64) : i64
          %3 = llvm.mlir.constant(0 : i64) : i64
          %4 = llvm.mlir.constant(0 : i32) : i32
          %5 = llvm.mlir.constant(63 : index) : i64
          %6 = llvm.mlir.constant(4 : index) : i64
          %7 = llvm.mlir.constant(0 : index) : i64
          %8 = llvm.mlir.constant(1 : index) : i64
          %9 = llvm.mlir.constant(2 : index) : i64
          %10 = llvm.mlir.constant(3 : index) : i64
          %11 = llvm.ptrtoint %arg0 : !llvm.ptr<1> to i64
          %12 = llvm.and %11, %5  : i64
          %13 = llvm.icmp "eq" %12, %7 : i64
          "llvm.intr.assume"(%13) : (i1) -> ()
          %14 = llvm.ptrtoint %arg1 : !llvm.ptr<1> to i64
          %15 = llvm.and %14, %5  : i64
          %16 = llvm.icmp "eq" %15, %7 : i64
          "llvm.intr.assume"(%16) : (i1) -> ()
          %17 = llvm.getelementptr %arg1[16] : (!llvm.ptr<1>) -> !llvm.ptr<1>, f32
          %18 = llvm.ptrtoint %17 : !llvm.ptr<1> to i64
          %19 = llvm.and %18, %5  : i64
          %20 = llvm.icmp "eq" %19, %7 : i64
          "llvm.intr.assume"(%20) : (i1) -> ()
          %21 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
          %22 = llvm.and %21, %5  : i64
          %23 = llvm.icmp "eq" %22, %7 : i64
          "llvm.intr.assume"(%23) : (i1) -> ()
          %24 = nvvm.read.ptx.sreg.ctaid.x : i32
          %25 = llvm.sext %24 : i32 to i64
          %26 = llvm.mul %7, %6  : i64
          %27 = llvm.add %26, %7  : i64
          %28 = llvm.getelementptr %arg0[%27] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %29 = llvm.load %28 {alignment = 4 : i64} : !llvm.ptr<1> -> vector<4xf32>
          %30 = llvm.mul %7, %10  : i64
          %31 = llvm.add %30, %25  : i64
          %32 = llvm.getelementptr %arg1[%31] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %33 = llvm.load %32 : !llvm.ptr<1> -> f32
          %34 = llvm.mlir.undef : vector<1xf32>
          %35 = llvm.insertelement %33, %34[%4 : i32] : vector<1xf32>
          %36 = llvm.shufflevector %35, %34 [0] : vector<1xf32> 
          %37 = llvm.mul %8, %10  : i64
          %38 = llvm.add %37, %25  : i64
          %39 = llvm.getelementptr %arg1[%38] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %40 = llvm.load %39 : !llvm.ptr<1> -> f32
          %41 = llvm.insertelement %40, %34[%4 : i32] : vector<1xf32>
          %42 = llvm.shufflevector %41, %34 [0] : vector<1xf32> 
          %43 = llvm.mul %9, %10  : i64
          %44 = llvm.add %43, %25  : i64
          %45 = llvm.getelementptr %arg1[%44] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %46 = llvm.load %45 : !llvm.ptr<1> -> f32
          %47 = llvm.insertelement %46, %34[%4 : i32] : vector<1xf32>
          %48 = llvm.shufflevector %47, %34 [0] : vector<1xf32> 
          %49 = llvm.mul %10, %10  : i64
          %50 = llvm.add %49, %25  : i64
          %51 = llvm.getelementptr %arg1[%50] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %52 = llvm.load %51 : !llvm.ptr<1> -> f32
          %53 = llvm.insertelement %52, %34[%4 : i32] : vector<1xf32>
          %54 = llvm.shufflevector %53, %34 [0] : vector<1xf32> 
          %55 = llvm.getelementptr %17[%31] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %56 = llvm.load %55 : !llvm.ptr<1> -> f32
          %57 = llvm.insertelement %56, %34[%4 : i32] : vector<1xf32>
          %58 = llvm.shufflevector %57, %34 [0] : vector<1xf32> 
          %59 = llvm.extractelement %29[%3 : i64] : vector<4xf32>
          %60 = llvm.insertelement %59, %34[%4 : i32] : vector<1xf32>
          %61 = llvm.shufflevector %60, %34 [0] : vector<1xf32> 
          %62 = llvm.intr.fmuladd(%61, %36, %58)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
          %63 = llvm.extractelement %29[%2 : i64] : vector<4xf32>
          %64 = llvm.insertelement %63, %34[%4 : i32] : vector<1xf32>
          %65 = llvm.shufflevector %64, %34 [0] : vector<1xf32> 
          %66 = llvm.intr.fmuladd(%65, %42, %62)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
          %67 = llvm.extractelement %29[%1 : i64] : vector<4xf32>
          %68 = llvm.insertelement %67, %34[%4 : i32] : vector<1xf32>
          %69 = llvm.shufflevector %68, %34 [0] : vector<1xf32> 
          %70 = llvm.intr.fmuladd(%69, %48, %66)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
          %71 = llvm.extractelement %29[%0 : i64] : vector<4xf32>
          %72 = llvm.insertelement %71, %34[%4 : i32] : vector<1xf32>
          %73 = llvm.shufflevector %72, %34 [0] : vector<1xf32> 
          %74 = llvm.intr.fmuladd(%73, %54, %70)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
          %75 = llvm.extractelement %74[%3 : i64] : vector<1xf32>
          %76 = llvm.getelementptr %arg2[%31] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          llvm.store %75, %76 : f32, !llvm.ptr<1>
          llvm.return
        }
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c3 = arith.constant 3 : index
    %c2 = arith.constant 2 : index
    %c1 = arith.constant 1 : index
    %c-1 = arith.constant -1 : index
    %c-1_i32 = arith.constant -1 : i32
    %c0_i64 = arith.constant 0 : i64
    %c-1_i64 = arith.constant -1 : i64
    %c128 = arith.constant 128 : index
    %c16 = arith.constant 16 : index
    %c12 = arith.constant 12 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !hal.fence
    %_params.weight = util.global.load @_params.weight : !hal.buffer
    %_device_query_0 = util.global.load @_device_query_0 : i1
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c16) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status = hal.fence.await until([%_params.weight__timepoint]) timeout_millis(%c-1_i32) : i32
    %0 = util.null : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%c12}
    %status_0 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    %1 = arith.select %_device_query_0, %c0, %c-1 : index
    scf.index_switch %1 
    case 0 {
      %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
      hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
        %c0 = (%buffer : !hal.buffer)[%c0, %c16], 
        %c1 = (%_params.weight : !hal.buffer)[%c0, %c128], 
        %c2 = (%transient_buffer : !hal.buffer)[%c0, %c12]
      ])
      %_executable_main_dispatch_0 = util.global.load @_executable_main_dispatch_0 : !hal.executable
      hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_main_dispatch_0 : !hal.executable)[0] workgroups([%c3, %c1, %c1])
      scf.yield
    }
    default {
    }
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_1 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status_2 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence_1) commands([%cmd])
    %status_3 = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status_3, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c12] shape([%c3]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#pipeline_layout = #hal.pipeline.layout<push_constants = 0, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>
#translation = #iree_codegen.translation_info<LLVMGPUMatmulSimt>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private @_device_query_0 : i1
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    util.global.store %value, @_device_query_0 : i1
    util.initializer.return
  }
  util.global private @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
    util.global.store %descriptor_set_layout, @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    util.initializer.return
  }
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.initializer {
    %_descriptor_set_layout_0 = util.global.load @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    %device = hal.ex.shared_device : !hal.device
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(0) layouts([%_descriptor_set_layout_0]) : !hal.pipeline_layout
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    util.initializer.return
  }
  util.global private @_executable_main_dispatch_0 : !hal.executable
  util.initializer {
    %c-1 = arith.constant -1 : index
    %c0 = arith.constant 0 : index
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %device = hal.ex.shared_device : !hal.device
    %0 = arith.select %_device_query_0, %c0, %c-1 : index
    %1 = scf.index_switch %0 -> !hal.executable 
    case 0 {
      %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
      %exe = hal.executable.create device(%device : !hal.device) target(@main_dispatch_0::@cuda_nvptx_fb) layouts([%_pipeline_layout_0]) : !hal.executable
      scf.yield %exe : !hal.executable
    }
    default {
      %2 = util.null : !hal.executable
      scf.yield %2 : !hal.executable
    }
    util.global.store %1, @_executable_main_dispatch_0 : !hal.executable
    util.initializer.return
  }
  util.global private mutable @_params.weight__timepoint : !hal.fence
  util.global private @_params.weight : !hal.buffer
  util.initializer {
    %c0_i32 = arith.constant 0 : i32
    %c-1_i64 = arith.constant -1 : i64
    %c0 = arith.constant 0 : index
    %c128 = arith.constant 128 : index
    %c0_i64 = arith.constant 0 : i64
    %0 = util.null : !hal.fence
    %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #composite_of_128b
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    %did_import, %mapped = hal.allocator.import<%allocator : !hal.allocator> source(%buffer_cst : !util.buffer)[%c0, %c128] affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : i1, !hal.buffer
    cf.cond_br %did_import, ^bb2(%0, %mapped : !hal.fence, !hal.buffer), ^bb1
  ^bb1:  // pred: ^bb0
    %buffer = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : !hal.buffer{%c128}
    %memory_file = hal.ex.file.from_memory device(%device : !hal.device) affinity(%c-1_i64) access(Read) buffer(%buffer_cst : !util.buffer)[%c0 for %c128] flags(%c0_i32) : !hal.file
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.read<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) source(%memory_file : !hal.file)[%c0_i64] target(%buffer : !hal.buffer)[%c0] length(%c128) flags(0)
    cf.br ^bb2(%fence, %buffer : !hal.fence, !hal.buffer)
  ^bb2(%1: !hal.fence, %2: !hal.buffer):  // 2 preds: ^bb0, ^bb1
    util.global.store %2, @_params.weight : !hal.buffer
    util.global.store %1, @_params.weight__timepoint : !hal.fence
    util.initializer.return
  }
  hal.executable private @main_dispatch_0 {
    hal.executable.variant public @cuda_nvptx_fb target(#executable_target_cuda_nvptx_fb) {
      hal.executable.export public @main_dispatch_0_matmul_1x3x4_f32 ordinal(0) layout(#pipeline_layout) attributes {translation_info = #translation, workgroup_size = [1 : index, 3 : index, 1 : index]} {
      ^bb0(%arg0: !hal.device):
        %c3 = arith.constant 3 : index
        %c1 = arith.constant 1 : index
        hal.return %c3, %c1, %c1 : index, index, index
      }
      builtin.module {
        llvm.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg2: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias}) {
          %0 = llvm.mlir.constant(3 : i64) : i64
          %1 = llvm.mlir.constant(2 : i64) : i64
          %2 = llvm.mlir.constant(1 : i64) : i64
          %3 = llvm.mlir.constant(0 : i64) : i64
          %4 = llvm.mlir.constant(0 : i32) : i32
          %5 = llvm.mlir.constant(63 : index) : i64
          %6 = llvm.mlir.constant(4 : index) : i64
          %7 = llvm.mlir.constant(0 : index) : i64
          %8 = llvm.mlir.constant(1 : index) : i64
          %9 = llvm.mlir.constant(2 : index) : i64
          %10 = llvm.mlir.constant(3 : index) : i64
          %11 = llvm.ptrtoint %arg0 : !llvm.ptr<1> to i64
          %12 = llvm.and %11, %5  : i64
          %13 = llvm.icmp "eq" %12, %7 : i64
          "llvm.intr.assume"(%13) : (i1) -> ()
          %14 = llvm.ptrtoint %arg1 : !llvm.ptr<1> to i64
          %15 = llvm.and %14, %5  : i64
          %16 = llvm.icmp "eq" %15, %7 : i64
          "llvm.intr.assume"(%16) : (i1) -> ()
          %17 = llvm.getelementptr %arg1[16] : (!llvm.ptr<1>) -> !llvm.ptr<1>, f32
          %18 = llvm.ptrtoint %17 : !llvm.ptr<1> to i64
          %19 = llvm.and %18, %5  : i64
          %20 = llvm.icmp "eq" %19, %7 : i64
          "llvm.intr.assume"(%20) : (i1) -> ()
          %21 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
          %22 = llvm.and %21, %5  : i64
          %23 = llvm.icmp "eq" %22, %7 : i64
          "llvm.intr.assume"(%23) : (i1) -> ()
          %24 = nvvm.read.ptx.sreg.ctaid.x : i32
          %25 = llvm.sext %24 : i32 to i64
          %26 = llvm.mul %7, %6  : i64
          %27 = llvm.add %26, %7  : i64
          %28 = llvm.getelementptr %arg0[%27] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %29 = llvm.load %28 {alignment = 4 : i64} : !llvm.ptr<1> -> vector<4xf32>
          %30 = llvm.mul %7, %10  : i64
          %31 = llvm.add %30, %25  : i64
          %32 = llvm.getelementptr %arg1[%31] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %33 = llvm.load %32 : !llvm.ptr<1> -> f32
          %34 = llvm.mlir.undef : vector<1xf32>
          %35 = llvm.insertelement %33, %34[%4 : i32] : vector<1xf32>
          %36 = llvm.shufflevector %35, %34 [0] : vector<1xf32> 
          %37 = llvm.mul %8, %10  : i64
          %38 = llvm.add %37, %25  : i64
          %39 = llvm.getelementptr %arg1[%38] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %40 = llvm.load %39 : !llvm.ptr<1> -> f32
          %41 = llvm.insertelement %40, %34[%4 : i32] : vector<1xf32>
          %42 = llvm.shufflevector %41, %34 [0] : vector<1xf32> 
          %43 = llvm.mul %9, %10  : i64
          %44 = llvm.add %43, %25  : i64
          %45 = llvm.getelementptr %arg1[%44] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %46 = llvm.load %45 : !llvm.ptr<1> -> f32
          %47 = llvm.insertelement %46, %34[%4 : i32] : vector<1xf32>
          %48 = llvm.shufflevector %47, %34 [0] : vector<1xf32> 
          %49 = llvm.mul %10, %10  : i64
          %50 = llvm.add %49, %25  : i64
          %51 = llvm.getelementptr %arg1[%50] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %52 = llvm.load %51 : !llvm.ptr<1> -> f32
          %53 = llvm.insertelement %52, %34[%4 : i32] : vector<1xf32>
          %54 = llvm.shufflevector %53, %34 [0] : vector<1xf32> 
          %55 = llvm.getelementptr %17[%31] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %56 = llvm.load %55 : !llvm.ptr<1> -> f32
          %57 = llvm.insertelement %56, %34[%4 : i32] : vector<1xf32>
          %58 = llvm.shufflevector %57, %34 [0] : vector<1xf32> 
          %59 = llvm.extractelement %29[%3 : i64] : vector<4xf32>
          %60 = llvm.insertelement %59, %34[%4 : i32] : vector<1xf32>
          %61 = llvm.shufflevector %60, %34 [0] : vector<1xf32> 
          %62 = llvm.intr.fmuladd(%61, %36, %58)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
          %63 = llvm.extractelement %29[%2 : i64] : vector<4xf32>
          %64 = llvm.insertelement %63, %34[%4 : i32] : vector<1xf32>
          %65 = llvm.shufflevector %64, %34 [0] : vector<1xf32> 
          %66 = llvm.intr.fmuladd(%65, %42, %62)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
          %67 = llvm.extractelement %29[%1 : i64] : vector<4xf32>
          %68 = llvm.insertelement %67, %34[%4 : i32] : vector<1xf32>
          %69 = llvm.shufflevector %68, %34 [0] : vector<1xf32> 
          %70 = llvm.intr.fmuladd(%69, %48, %66)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
          %71 = llvm.extractelement %29[%0 : i64] : vector<4xf32>
          %72 = llvm.insertelement %71, %34[%4 : i32] : vector<1xf32>
          %73 = llvm.shufflevector %72, %34 [0] : vector<1xf32> 
          %74 = llvm.intr.fmuladd(%73, %54, %70)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
          %75 = llvm.extractelement %74[%3 : i64] : vector<1xf32>
          %76 = llvm.getelementptr %arg2[%31] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          llvm.store %75, %76 : f32, !llvm.ptr<1>
          llvm.return
        }
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c3 = arith.constant 3 : index
    %c2 = arith.constant 2 : index
    %c1 = arith.constant 1 : index
    %c-1 = arith.constant -1 : index
    %c-1_i32 = arith.constant -1 : i32
    %c0_i64 = arith.constant 0 : i64
    %c-1_i64 = arith.constant -1 : i64
    %c128 = arith.constant 128 : index
    %c16 = arith.constant 16 : index
    %c12 = arith.constant 12 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !hal.fence
    %_params.weight = util.global.load @_params.weight : !hal.buffer
    %_device_query_0 = util.global.load @_device_query_0 : i1
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c16) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status = hal.fence.await until([%_params.weight__timepoint]) timeout_millis(%c-1_i32) : i32
    %0 = util.null : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%c12}
    %status_0 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    %1 = arith.select %_device_query_0, %c0, %c-1 : index
    scf.index_switch %1 
    case 0 {
      %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
      hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
        %c0 = (%buffer : !hal.buffer)[%c0, %c16], 
        %c1 = (%_params.weight : !hal.buffer)[%c0, %c128], 
        %c2 = (%transient_buffer : !hal.buffer)[%c0, %c12]
      ])
      %_executable_main_dispatch_0 = util.global.load @_executable_main_dispatch_0 : !hal.executable
      hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_main_dispatch_0 : !hal.executable)[0] workgroups([%c3, %c1, %c1])
      scf.yield
    }
    default {
    }
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_1 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status_2 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence_1) commands([%cmd])
    %status_3 = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status_3, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c12] shape([%c3]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#pipeline_layout = #hal.pipeline.layout<push_constants = 0, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>
#translation = #iree_codegen.translation_info<LLVMGPUMatmulSimt>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private @_device_query_0 : i1
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    util.global.store %value, @_device_query_0 : i1
    util.initializer.return
  }
  util.global private @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
    util.global.store %descriptor_set_layout, @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    util.initializer.return
  }
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.initializer {
    %_descriptor_set_layout_0 = util.global.load @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    %device = hal.ex.shared_device : !hal.device
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(0) layouts([%_descriptor_set_layout_0]) : !hal.pipeline_layout
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    util.initializer.return
  }
  util.global private @_executable_main_dispatch_0 : !hal.executable
  util.initializer {
    %c-1 = arith.constant -1 : index
    %c0 = arith.constant 0 : index
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %device = hal.ex.shared_device : !hal.device
    %0 = arith.select %_device_query_0, %c0, %c-1 : index
    %1 = scf.index_switch %0 -> !hal.executable 
    case 0 {
      %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
      %exe = hal.executable.create device(%device : !hal.device) target(@main_dispatch_0::@cuda_nvptx_fb) layouts([%_pipeline_layout_0]) : !hal.executable
      scf.yield %exe : !hal.executable
    }
    default {
      %2 = util.null : !hal.executable
      scf.yield %2 : !hal.executable
    }
    util.global.store %1, @_executable_main_dispatch_0 : !hal.executable
    util.initializer.return
  }
  util.global private mutable @_params.weight__timepoint : !hal.fence
  util.global private @_params.weight : !hal.buffer
  util.initializer {
    %c0_i32 = arith.constant 0 : i32
    %c-1_i64 = arith.constant -1 : i64
    %c0 = arith.constant 0 : index
    %c128 = arith.constant 128 : index
    %c0_i64 = arith.constant 0 : i64
    %0 = util.null : !hal.fence
    %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #composite_of_128b
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    %did_import, %mapped = hal.allocator.import<%allocator : !hal.allocator> source(%buffer_cst : !util.buffer)[%c0, %c128] affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : i1, !hal.buffer
    cf.cond_br %did_import, ^bb2(%0, %mapped : !hal.fence, !hal.buffer), ^bb1
  ^bb1:  // pred: ^bb0
    %buffer = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : !hal.buffer{%c128}
    %memory_file = hal.ex.file.from_memory device(%device : !hal.device) affinity(%c-1_i64) access(Read) buffer(%buffer_cst : !util.buffer)[%c0 for %c128] flags(%c0_i32) : !hal.file
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.read<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) source(%memory_file : !hal.file)[%c0_i64] target(%buffer : !hal.buffer)[%c0] length(%c128) flags(0)
    cf.br ^bb2(%fence, %buffer : !hal.fence, !hal.buffer)
  ^bb2(%1: !hal.fence, %2: !hal.buffer):  // 2 preds: ^bb0, ^bb1
    util.global.store %2, @_params.weight : !hal.buffer
    util.global.store %1, @_params.weight__timepoint : !hal.fence
    util.initializer.return
  }
  hal.executable private @main_dispatch_0 {
    hal.executable.variant public @cuda_nvptx_fb target(#executable_target_cuda_nvptx_fb) {
      hal.executable.export public @main_dispatch_0_matmul_1x3x4_f32 ordinal(0) layout(#pipeline_layout) attributes {translation_info = #translation, workgroup_size = [1 : index, 3 : index, 1 : index]} {
      ^bb0(%arg0: !hal.device):
        %c3 = arith.constant 3 : index
        %c1 = arith.constant 1 : index
        hal.return %c3, %c1, %c1 : index, index, index
      }
      builtin.module {
        llvm.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg2: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias}) {
          %0 = llvm.mlir.constant(3 : i64) : i64
          %1 = llvm.mlir.constant(2 : i64) : i64
          %2 = llvm.mlir.constant(1 : i64) : i64
          %3 = llvm.mlir.constant(0 : i64) : i64
          %4 = llvm.mlir.constant(0 : i32) : i32
          %5 = llvm.mlir.constant(63 : index) : i64
          %6 = llvm.mlir.constant(4 : index) : i64
          %7 = llvm.mlir.constant(0 : index) : i64
          %8 = llvm.mlir.constant(1 : index) : i64
          %9 = llvm.mlir.constant(2 : index) : i64
          %10 = llvm.mlir.constant(3 : index) : i64
          %11 = llvm.ptrtoint %arg0 : !llvm.ptr<1> to i64
          %12 = llvm.and %11, %5  : i64
          %13 = llvm.icmp "eq" %12, %7 : i64
          "llvm.intr.assume"(%13) : (i1) -> ()
          %14 = llvm.ptrtoint %arg1 : !llvm.ptr<1> to i64
          %15 = llvm.and %14, %5  : i64
          %16 = llvm.icmp "eq" %15, %7 : i64
          "llvm.intr.assume"(%16) : (i1) -> ()
          %17 = llvm.getelementptr %arg1[16] : (!llvm.ptr<1>) -> !llvm.ptr<1>, f32
          %18 = llvm.ptrtoint %17 : !llvm.ptr<1> to i64
          %19 = llvm.and %18, %5  : i64
          %20 = llvm.icmp "eq" %19, %7 : i64
          "llvm.intr.assume"(%20) : (i1) -> ()
          %21 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
          %22 = llvm.and %21, %5  : i64
          %23 = llvm.icmp "eq" %22, %7 : i64
          "llvm.intr.assume"(%23) : (i1) -> ()
          %24 = nvvm.read.ptx.sreg.ctaid.x : i32
          %25 = llvm.sext %24 : i32 to i64
          %26 = llvm.mul %7, %6  : i64
          %27 = llvm.add %26, %7  : i64
          %28 = llvm.getelementptr %arg0[%27] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %29 = llvm.load %28 {alignment = 4 : i64} : !llvm.ptr<1> -> vector<4xf32>
          %30 = llvm.mul %7, %10  : i64
          %31 = llvm.add %30, %25  : i64
          %32 = llvm.getelementptr %arg1[%31] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %33 = llvm.load %32 : !llvm.ptr<1> -> f32
          %34 = llvm.mlir.undef : vector<1xf32>
          %35 = llvm.insertelement %33, %34[%4 : i32] : vector<1xf32>
          %36 = llvm.shufflevector %35, %34 [0] : vector<1xf32> 
          %37 = llvm.mul %8, %10  : i64
          %38 = llvm.add %37, %25  : i64
          %39 = llvm.getelementptr %arg1[%38] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %40 = llvm.load %39 : !llvm.ptr<1> -> f32
          %41 = llvm.insertelement %40, %34[%4 : i32] : vector<1xf32>
          %42 = llvm.shufflevector %41, %34 [0] : vector<1xf32> 
          %43 = llvm.mul %9, %10  : i64
          %44 = llvm.add %43, %25  : i64
          %45 = llvm.getelementptr %arg1[%44] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %46 = llvm.load %45 : !llvm.ptr<1> -> f32
          %47 = llvm.insertelement %46, %34[%4 : i32] : vector<1xf32>
          %48 = llvm.shufflevector %47, %34 [0] : vector<1xf32> 
          %49 = llvm.mul %10, %10  : i64
          %50 = llvm.add %49, %25  : i64
          %51 = llvm.getelementptr %arg1[%50] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %52 = llvm.load %51 : !llvm.ptr<1> -> f32
          %53 = llvm.insertelement %52, %34[%4 : i32] : vector<1xf32>
          %54 = llvm.shufflevector %53, %34 [0] : vector<1xf32> 
          %55 = llvm.getelementptr %17[%31] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %56 = llvm.load %55 : !llvm.ptr<1> -> f32
          %57 = llvm.insertelement %56, %34[%4 : i32] : vector<1xf32>
          %58 = llvm.shufflevector %57, %34 [0] : vector<1xf32> 
          %59 = llvm.extractelement %29[%3 : i64] : vector<4xf32>
          %60 = llvm.insertelement %59, %34[%4 : i32] : vector<1xf32>
          %61 = llvm.shufflevector %60, %34 [0] : vector<1xf32> 
          %62 = llvm.intr.fmuladd(%61, %36, %58)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
          %63 = llvm.extractelement %29[%2 : i64] : vector<4xf32>
          %64 = llvm.insertelement %63, %34[%4 : i32] : vector<1xf32>
          %65 = llvm.shufflevector %64, %34 [0] : vector<1xf32> 
          %66 = llvm.intr.fmuladd(%65, %42, %62)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
          %67 = llvm.extractelement %29[%1 : i64] : vector<4xf32>
          %68 = llvm.insertelement %67, %34[%4 : i32] : vector<1xf32>
          %69 = llvm.shufflevector %68, %34 [0] : vector<1xf32> 
          %70 = llvm.intr.fmuladd(%69, %48, %66)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
          %71 = llvm.extractelement %29[%0 : i64] : vector<4xf32>
          %72 = llvm.insertelement %71, %34[%4 : i32] : vector<1xf32>
          %73 = llvm.shufflevector %72, %34 [0] : vector<1xf32> 
          %74 = llvm.intr.fmuladd(%73, %54, %70)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
          %75 = llvm.extractelement %74[%3 : i64] : vector<1xf32>
          %76 = llvm.getelementptr %arg2[%31] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          llvm.store %75, %76 : f32, !llvm.ptr<1>
          llvm.return
        }
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c3 = arith.constant 3 : index
    %c2 = arith.constant 2 : index
    %c1 = arith.constant 1 : index
    %c-1 = arith.constant -1 : index
    %c-1_i32 = arith.constant -1 : i32
    %c0_i64 = arith.constant 0 : i64
    %c-1_i64 = arith.constant -1 : i64
    %c128 = arith.constant 128 : index
    %c16 = arith.constant 16 : index
    %c12 = arith.constant 12 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !hal.fence
    %_params.weight = util.global.load @_params.weight : !hal.buffer
    %_device_query_0 = util.global.load @_device_query_0 : i1
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c16) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status = hal.fence.await until([%_params.weight__timepoint]) timeout_millis(%c-1_i32) : i32
    %0 = util.null : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%c12}
    %status_0 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    %1 = arith.select %_device_query_0, %c0, %c-1 : index
    scf.index_switch %1 
    case 0 {
      %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
      hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
        %c0 = (%buffer : !hal.buffer)[%c0, %c16], 
        %c1 = (%_params.weight : !hal.buffer)[%c0, %c128], 
        %c2 = (%transient_buffer : !hal.buffer)[%c0, %c12]
      ])
      %_executable_main_dispatch_0 = util.global.load @_executable_main_dispatch_0 : !hal.executable
      hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_main_dispatch_0 : !hal.executable)[0] workgroups([%c3, %c1, %c1])
      scf.yield
    }
    default {
    }
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_1 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status_2 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence_1) commands([%cmd])
    %status_3 = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status_3, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c12] shape([%c3]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::HAL::ElideRedundantCommandsPass (iree-hal-elide-redundant-commands) //----- //
util.initializer {
  %_descriptor_set_layout_0 = util.global.load @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  %device = hal.ex.shared_device : !hal.device
  %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(0) layouts([%_descriptor_set_layout_0]) : !hal.pipeline_layout
  util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
  util.initializer.return
}

// -----// IR Dump After mlir::iree_compiler::IREE::HAL::ElideRedundantCommandsPass (iree-hal-elide-redundant-commands) //----- //
util.initializer {
  %device = hal.ex.shared_device : !hal.device
  %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
  util.global.store %value, @_device_query_0 : i1
  util.initializer.return
}

// -----// IR Dump After mlir::iree_compiler::IREE::HAL::ElideRedundantCommandsPass (iree-hal-elide-redundant-commands) //----- //
util.initializer {
  %device = hal.ex.shared_device : !hal.device
  %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
  util.global.store %descriptor_set_layout, @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  util.initializer.return
}

// -----// IR Dump After mlir::iree_compiler::IREE::HAL::ElideRedundantCommandsPass (iree-hal-elide-redundant-commands) //----- //
util.initializer {
  %c-1 = arith.constant -1 : index
  %c0 = arith.constant 0 : index
  %_device_query_0 = util.global.load @_device_query_0 : i1
  %device = hal.ex.shared_device : !hal.device
  %0 = arith.select %_device_query_0, %c0, %c-1 : index
  %1 = scf.index_switch %0 -> !hal.executable 
  case 0 {
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device : !hal.device) target(@main_dispatch_0::@cuda_nvptx_fb) layouts([%_pipeline_layout_0]) : !hal.executable
    scf.yield %exe : !hal.executable
  }
  default {
    %2 = util.null : !hal.executable
    scf.yield %2 : !hal.executable
  }
  util.global.store %1, @_executable_main_dispatch_0 : !hal.executable
  util.initializer.return
}

// -----// IR Dump After mlir::iree_compiler::IREE::HAL::ElideRedundantCommandsPass (iree-hal-elide-redundant-commands) //----- //
util.initializer {
  %c0_i32 = arith.constant 0 : i32
  %c-1_i64 = arith.constant -1 : i64
  %c0 = arith.constant 0 : index
  %c128 = arith.constant 128 : index
  %c0_i64 = arith.constant 0 : i64
  %0 = util.null : !hal.fence
  %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
  %device = hal.ex.shared_device : !hal.device
  %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
  %did_import, %mapped = hal.allocator.import<%allocator : !hal.allocator> source(%buffer_cst : !util.buffer)[%c0, %c128] affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : i1, !hal.buffer
  cf.cond_br %did_import, ^bb2(%0, %mapped : !hal.fence, !hal.buffer), ^bb1
^bb1:  // pred: ^bb0
  %buffer = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : !hal.buffer{%c128}
  %memory_file = hal.ex.file.from_memory device(%device : !hal.device) affinity(%c-1_i64) access(Read) buffer(%buffer_cst : !util.buffer)[%c0 for %c128] flags(%c0_i32) : !hal.file
  %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
  hal.device.queue.read<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) source(%memory_file : !hal.file)[%c0_i64] target(%buffer : !hal.buffer)[%c0] length(%c128) flags(0)
  cf.br ^bb2(%fence, %buffer : !hal.fence, !hal.buffer)
^bb2(%1: !hal.fence, %2: !hal.buffer):  // 2 preds: ^bb0, ^bb1
  util.global.store %2, @_params.weight : !hal.buffer
  util.global.store %1, @_params.weight__timepoint : !hal.fence
  util.initializer.return
}

// -----// IR Dump After mlir::iree_compiler::IREE::HAL::ElideRedundantCommandsPass (iree-hal-elide-redundant-commands) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c3 = arith.constant 3 : index
  %c2 = arith.constant 2 : index
  %c1 = arith.constant 1 : index
  %c-1 = arith.constant -1 : index
  %c-1_i32 = arith.constant -1 : i32
  %c0_i64 = arith.constant 0 : i64
  %c-1_i64 = arith.constant -1 : i64
  %c128 = arith.constant 128 : index
  %c16 = arith.constant 16 : index
  %c12 = arith.constant 12 : index
  %c553648160_i32 = arith.constant 553648160 : i32
  %c1_i32 = arith.constant 1 : i32
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !hal.fence
  %_params.weight = util.global.load @_params.weight : !hal.buffer
  %_device_query_0 = util.global.load @_device_query_0 : i1
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %device = hal.ex.shared_device : !hal.device
  %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c16) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
  %status = hal.fence.await until([%_params.weight__timepoint]) timeout_millis(%c-1_i32) : i32
  %0 = util.null : !hal.fence
  %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%c12}
  %status_0 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
  %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
  %1 = arith.select %_device_query_0, %c0, %c-1 : index
  scf.index_switch %1 
  case 0 {
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%buffer : !hal.buffer)[%c0, %c16], 
      %c1 = (%_params.weight : !hal.buffer)[%c0, %c128], 
      %c2 = (%transient_buffer : !hal.buffer)[%c0, %c12]
    ])
    %_executable_main_dispatch_0 = util.global.load @_executable_main_dispatch_0 : !hal.executable
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_main_dispatch_0 : !hal.executable)[0] workgroups([%c3, %c1, %c1])
    scf.yield
  }
  default {
  }
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  %fence_1 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
  %status_2 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
  hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence_1) commands([%cmd])
  %status_3 = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
  util.status.check_ok %status_3, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c12] shape([%c3]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
  return %view : !hal.buffer_view
}

// -----// IR Dump After ConvertAffineToStandard (lower-affine) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#pipeline_layout = #hal.pipeline.layout<push_constants = 0, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>
#translation = #iree_codegen.translation_info<LLVMGPUMatmulSimt>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private @_device_query_0 : i1
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    util.global.store %value, @_device_query_0 : i1
    util.initializer.return
  }
  util.global private @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
    util.global.store %descriptor_set_layout, @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    util.initializer.return
  }
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.initializer {
    %_descriptor_set_layout_0 = util.global.load @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    %device = hal.ex.shared_device : !hal.device
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(0) layouts([%_descriptor_set_layout_0]) : !hal.pipeline_layout
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    util.initializer.return
  }
  util.global private @_executable_main_dispatch_0 : !hal.executable
  util.initializer {
    %c-1 = arith.constant -1 : index
    %c0 = arith.constant 0 : index
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %device = hal.ex.shared_device : !hal.device
    %0 = arith.select %_device_query_0, %c0, %c-1 : index
    %1 = scf.index_switch %0 -> !hal.executable 
    case 0 {
      %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
      %exe = hal.executable.create device(%device : !hal.device) target(@main_dispatch_0::@cuda_nvptx_fb) layouts([%_pipeline_layout_0]) : !hal.executable
      scf.yield %exe : !hal.executable
    }
    default {
      %2 = util.null : !hal.executable
      scf.yield %2 : !hal.executable
    }
    util.global.store %1, @_executable_main_dispatch_0 : !hal.executable
    util.initializer.return
  }
  util.global private mutable @_params.weight__timepoint : !hal.fence
  util.global private @_params.weight : !hal.buffer
  util.initializer {
    %c0_i32 = arith.constant 0 : i32
    %c-1_i64 = arith.constant -1 : i64
    %c0 = arith.constant 0 : index
    %c128 = arith.constant 128 : index
    %c0_i64 = arith.constant 0 : i64
    %0 = util.null : !hal.fence
    %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #composite_of_128b
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    %did_import, %mapped = hal.allocator.import<%allocator : !hal.allocator> source(%buffer_cst : !util.buffer)[%c0, %c128] affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : i1, !hal.buffer
    cf.cond_br %did_import, ^bb2(%0, %mapped : !hal.fence, !hal.buffer), ^bb1
  ^bb1:  // pred: ^bb0
    %buffer = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : !hal.buffer{%c128}
    %memory_file = hal.ex.file.from_memory device(%device : !hal.device) affinity(%c-1_i64) access(Read) buffer(%buffer_cst : !util.buffer)[%c0 for %c128] flags(%c0_i32) : !hal.file
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.read<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) source(%memory_file : !hal.file)[%c0_i64] target(%buffer : !hal.buffer)[%c0] length(%c128) flags(0)
    cf.br ^bb2(%fence, %buffer : !hal.fence, !hal.buffer)
  ^bb2(%1: !hal.fence, %2: !hal.buffer):  // 2 preds: ^bb0, ^bb1
    util.global.store %2, @_params.weight : !hal.buffer
    util.global.store %1, @_params.weight__timepoint : !hal.fence
    util.initializer.return
  }
  hal.executable private @main_dispatch_0 {
    hal.executable.variant public @cuda_nvptx_fb target(#executable_target_cuda_nvptx_fb) {
      hal.executable.export public @main_dispatch_0_matmul_1x3x4_f32 ordinal(0) layout(#pipeline_layout) attributes {translation_info = #translation, workgroup_size = [1 : index, 3 : index, 1 : index]} {
      ^bb0(%arg0: !hal.device):
        %c3 = arith.constant 3 : index
        %c1 = arith.constant 1 : index
        hal.return %c3, %c1, %c1 : index, index, index
      }
      builtin.module {
        llvm.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg2: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias}) {
          %0 = llvm.mlir.constant(3 : i64) : i64
          %1 = llvm.mlir.constant(2 : i64) : i64
          %2 = llvm.mlir.constant(1 : i64) : i64
          %3 = llvm.mlir.constant(0 : i64) : i64
          %4 = llvm.mlir.constant(0 : i32) : i32
          %5 = llvm.mlir.constant(63 : index) : i64
          %6 = llvm.mlir.constant(4 : index) : i64
          %7 = llvm.mlir.constant(0 : index) : i64
          %8 = llvm.mlir.constant(1 : index) : i64
          %9 = llvm.mlir.constant(2 : index) : i64
          %10 = llvm.mlir.constant(3 : index) : i64
          %11 = llvm.ptrtoint %arg0 : !llvm.ptr<1> to i64
          %12 = llvm.and %11, %5  : i64
          %13 = llvm.icmp "eq" %12, %7 : i64
          "llvm.intr.assume"(%13) : (i1) -> ()
          %14 = llvm.ptrtoint %arg1 : !llvm.ptr<1> to i64
          %15 = llvm.and %14, %5  : i64
          %16 = llvm.icmp "eq" %15, %7 : i64
          "llvm.intr.assume"(%16) : (i1) -> ()
          %17 = llvm.getelementptr %arg1[16] : (!llvm.ptr<1>) -> !llvm.ptr<1>, f32
          %18 = llvm.ptrtoint %17 : !llvm.ptr<1> to i64
          %19 = llvm.and %18, %5  : i64
          %20 = llvm.icmp "eq" %19, %7 : i64
          "llvm.intr.assume"(%20) : (i1) -> ()
          %21 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
          %22 = llvm.and %21, %5  : i64
          %23 = llvm.icmp "eq" %22, %7 : i64
          "llvm.intr.assume"(%23) : (i1) -> ()
          %24 = nvvm.read.ptx.sreg.ctaid.x : i32
          %25 = llvm.sext %24 : i32 to i64
          %26 = llvm.mul %7, %6  : i64
          %27 = llvm.add %26, %7  : i64
          %28 = llvm.getelementptr %arg0[%27] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %29 = llvm.load %28 {alignment = 4 : i64} : !llvm.ptr<1> -> vector<4xf32>
          %30 = llvm.mul %7, %10  : i64
          %31 = llvm.add %30, %25  : i64
          %32 = llvm.getelementptr %arg1[%31] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %33 = llvm.load %32 : !llvm.ptr<1> -> f32
          %34 = llvm.mlir.undef : vector<1xf32>
          %35 = llvm.insertelement %33, %34[%4 : i32] : vector<1xf32>
          %36 = llvm.shufflevector %35, %34 [0] : vector<1xf32> 
          %37 = llvm.mul %8, %10  : i64
          %38 = llvm.add %37, %25  : i64
          %39 = llvm.getelementptr %arg1[%38] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %40 = llvm.load %39 : !llvm.ptr<1> -> f32
          %41 = llvm.insertelement %40, %34[%4 : i32] : vector<1xf32>
          %42 = llvm.shufflevector %41, %34 [0] : vector<1xf32> 
          %43 = llvm.mul %9, %10  : i64
          %44 = llvm.add %43, %25  : i64
          %45 = llvm.getelementptr %arg1[%44] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %46 = llvm.load %45 : !llvm.ptr<1> -> f32
          %47 = llvm.insertelement %46, %34[%4 : i32] : vector<1xf32>
          %48 = llvm.shufflevector %47, %34 [0] : vector<1xf32> 
          %49 = llvm.mul %10, %10  : i64
          %50 = llvm.add %49, %25  : i64
          %51 = llvm.getelementptr %arg1[%50] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %52 = llvm.load %51 : !llvm.ptr<1> -> f32
          %53 = llvm.insertelement %52, %34[%4 : i32] : vector<1xf32>
          %54 = llvm.shufflevector %53, %34 [0] : vector<1xf32> 
          %55 = llvm.getelementptr %17[%31] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %56 = llvm.load %55 : !llvm.ptr<1> -> f32
          %57 = llvm.insertelement %56, %34[%4 : i32] : vector<1xf32>
          %58 = llvm.shufflevector %57, %34 [0] : vector<1xf32> 
          %59 = llvm.extractelement %29[%3 : i64] : vector<4xf32>
          %60 = llvm.insertelement %59, %34[%4 : i32] : vector<1xf32>
          %61 = llvm.shufflevector %60, %34 [0] : vector<1xf32> 
          %62 = llvm.intr.fmuladd(%61, %36, %58)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
          %63 = llvm.extractelement %29[%2 : i64] : vector<4xf32>
          %64 = llvm.insertelement %63, %34[%4 : i32] : vector<1xf32>
          %65 = llvm.shufflevector %64, %34 [0] : vector<1xf32> 
          %66 = llvm.intr.fmuladd(%65, %42, %62)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
          %67 = llvm.extractelement %29[%1 : i64] : vector<4xf32>
          %68 = llvm.insertelement %67, %34[%4 : i32] : vector<1xf32>
          %69 = llvm.shufflevector %68, %34 [0] : vector<1xf32> 
          %70 = llvm.intr.fmuladd(%69, %48, %66)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
          %71 = llvm.extractelement %29[%0 : i64] : vector<4xf32>
          %72 = llvm.insertelement %71, %34[%4 : i32] : vector<1xf32>
          %73 = llvm.shufflevector %72, %34 [0] : vector<1xf32> 
          %74 = llvm.intr.fmuladd(%73, %54, %70)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
          %75 = llvm.extractelement %74[%3 : i64] : vector<1xf32>
          %76 = llvm.getelementptr %arg2[%31] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          llvm.store %75, %76 : f32, !llvm.ptr<1>
          llvm.return
        }
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c3 = arith.constant 3 : index
    %c2 = arith.constant 2 : index
    %c1 = arith.constant 1 : index
    %c-1 = arith.constant -1 : index
    %c-1_i32 = arith.constant -1 : i32
    %c0_i64 = arith.constant 0 : i64
    %c-1_i64 = arith.constant -1 : i64
    %c128 = arith.constant 128 : index
    %c16 = arith.constant 16 : index
    %c12 = arith.constant 12 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !hal.fence
    %_params.weight = util.global.load @_params.weight : !hal.buffer
    %_device_query_0 = util.global.load @_device_query_0 : i1
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c16) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status = hal.fence.await until([%_params.weight__timepoint]) timeout_millis(%c-1_i32) : i32
    %0 = util.null : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%c12}
    %status_0 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    %1 = arith.select %_device_query_0, %c0, %c-1 : index
    scf.index_switch %1 
    case 0 {
      %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
      hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
        %c0 = (%buffer : !hal.buffer)[%c0, %c16], 
        %c1 = (%_params.weight : !hal.buffer)[%c0, %c128], 
        %c2 = (%transient_buffer : !hal.buffer)[%c0, %c12]
      ])
      %_executable_main_dispatch_0 = util.global.load @_executable_main_dispatch_0 : !hal.executable
      hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_main_dispatch_0 : !hal.executable)[0] workgroups([%c3, %c1, %c1])
      scf.yield
    }
    default {
    }
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_1 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status_2 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence_1) commands([%cmd])
    %status_3 = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status_3, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c12] shape([%c3]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After SCFToControlFlow (convert-scf-to-cf) //----- //
util.initializer {
  %device = hal.ex.shared_device : !hal.device
  %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
  util.global.store %descriptor_set_layout, @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  util.initializer.return
}

// -----// IR Dump After SCFToControlFlow (convert-scf-to-cf) //----- //
util.initializer {
  %device = hal.ex.shared_device : !hal.device
  %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
  util.global.store %value, @_device_query_0 : i1
  util.initializer.return
}

// -----// IR Dump After SCFToControlFlow (convert-scf-to-cf) //----- //
util.initializer {
  %_descriptor_set_layout_0 = util.global.load @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  %device = hal.ex.shared_device : !hal.device
  %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(0) layouts([%_descriptor_set_layout_0]) : !hal.pipeline_layout
  util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
  util.initializer.return
}

// -----// IR Dump After SCFToControlFlow (convert-scf-to-cf) //----- //
util.initializer {
  %c0_i32 = arith.constant 0 : i32
  %c-1_i64 = arith.constant -1 : i64
  %c0 = arith.constant 0 : index
  %c128 = arith.constant 128 : index
  %c0_i64 = arith.constant 0 : i64
  %0 = util.null : !hal.fence
  %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
  %device = hal.ex.shared_device : !hal.device
  %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
  %did_import, %mapped = hal.allocator.import<%allocator : !hal.allocator> source(%buffer_cst : !util.buffer)[%c0, %c128] affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : i1, !hal.buffer
  cf.cond_br %did_import, ^bb2(%0, %mapped : !hal.fence, !hal.buffer), ^bb1
^bb1:  // pred: ^bb0
  %buffer = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : !hal.buffer{%c128}
  %memory_file = hal.ex.file.from_memory device(%device : !hal.device) affinity(%c-1_i64) access(Read) buffer(%buffer_cst : !util.buffer)[%c0 for %c128] flags(%c0_i32) : !hal.file
  %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
  hal.device.queue.read<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) source(%memory_file : !hal.file)[%c0_i64] target(%buffer : !hal.buffer)[%c0] length(%c128) flags(0)
  cf.br ^bb2(%fence, %buffer : !hal.fence, !hal.buffer)
^bb2(%1: !hal.fence, %2: !hal.buffer):  // 2 preds: ^bb0, ^bb1
  util.global.store %2, @_params.weight : !hal.buffer
  util.global.store %1, @_params.weight__timepoint : !hal.fence
  util.initializer.return
}

// -----// IR Dump After SCFToControlFlow (convert-scf-to-cf) //----- //
util.initializer {
  %c-1 = arith.constant -1 : index
  %c0 = arith.constant 0 : index
  %_device_query_0 = util.global.load @_device_query_0 : i1
  %device = hal.ex.shared_device : !hal.device
  %0 = arith.select %_device_query_0, %c0, %c-1 : index
  %1 = arith.index_cast %0 : index to i32
  cf.switch %1 : i32, [
    default: ^bb2,
    0: ^bb1
  ]
^bb1:  // pred: ^bb0
  %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
  %exe = hal.executable.create device(%device : !hal.device) target(@main_dispatch_0::@cuda_nvptx_fb) layouts([%_pipeline_layout_0]) : !hal.executable
  cf.br ^bb3(%exe : !hal.executable)
^bb2:  // pred: ^bb0
  %2 = util.null : !hal.executable
  cf.br ^bb3(%2 : !hal.executable)
^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
  util.global.store %3, @_executable_main_dispatch_0 : !hal.executable
  util.initializer.return
}

// -----// IR Dump After SCFToControlFlow (convert-scf-to-cf) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c3 = arith.constant 3 : index
  %c2 = arith.constant 2 : index
  %c1 = arith.constant 1 : index
  %c-1 = arith.constant -1 : index
  %c-1_i32 = arith.constant -1 : i32
  %c0_i64 = arith.constant 0 : i64
  %c-1_i64 = arith.constant -1 : i64
  %c128 = arith.constant 128 : index
  %c16 = arith.constant 16 : index
  %c12 = arith.constant 12 : index
  %c553648160_i32 = arith.constant 553648160 : i32
  %c1_i32 = arith.constant 1 : i32
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !hal.fence
  %_params.weight = util.global.load @_params.weight : !hal.buffer
  %_device_query_0 = util.global.load @_device_query_0 : i1
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %device = hal.ex.shared_device : !hal.device
  %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c16) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
  %status = hal.fence.await until([%_params.weight__timepoint]) timeout_millis(%c-1_i32) : i32
  %0 = util.null : !hal.fence
  %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%c12}
  %status_0 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
  %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
  %1 = arith.select %_device_query_0, %c0, %c-1 : index
  %2 = arith.index_cast %1 : index to i32
  cf.switch %2 : i32, [
    default: ^bb2,
    0: ^bb1
  ]
^bb1:  // pred: ^bb0
  %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
  hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
    %c0 = (%buffer : !hal.buffer)[%c0, %c16], 
    %c1 = (%_params.weight : !hal.buffer)[%c0, %c128], 
    %c2 = (%transient_buffer : !hal.buffer)[%c0, %c12]
  ])
  %_executable_main_dispatch_0 = util.global.load @_executable_main_dispatch_0 : !hal.executable
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_main_dispatch_0 : !hal.executable)[0] workgroups([%c3, %c1, %c1])
  cf.br ^bb3
^bb2:  // pred: ^bb0
  cf.br ^bb3
^bb3:  // 2 preds: ^bb1, ^bb2
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  %fence_1 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
  %status_2 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
  hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence_1) commands([%cmd])
  %status_3 = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
  util.status.check_ok %status_3, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c12] shape([%c3]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
  return %view : !hal.buffer_view
}

// -----// IR Dump After CombineInitializers (iree-util-combine-initializers) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#pipeline_layout = #hal.pipeline.layout<push_constants = 0, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>
#translation = #iree_codegen.translation_info<LLVMGPUMatmulSimt>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private @_device_query_0 : i1
  util.global private @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.global private @_executable_main_dispatch_0 : !hal.executable
  util.global private mutable @_params.weight__timepoint : !hal.fence
  util.global private @_params.weight : !hal.buffer
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    util.global.store %value, @_device_query_0 : i1
    %device_0 = hal.ex.shared_device : !hal.device
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device_0 : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
    util.global.store %descriptor_set_layout, @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    %_descriptor_set_layout_0 = util.global.load @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    %device_1 = hal.ex.shared_device : !hal.device
    %pipeline_layout = hal.pipeline_layout.create device(%device_1 : !hal.device) push_constants(0) layouts([%_descriptor_set_layout_0]) : !hal.pipeline_layout
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    %c-1 = arith.constant -1 : index
    %c0 = arith.constant 0 : index
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %device_2 = hal.ex.shared_device : !hal.device
    %0 = arith.select %_device_query_0, %c0, %c-1 : index
    %1 = arith.index_cast %0 : index to i32
    cf.switch %1 : i32, [
      default: ^bb2,
      0: ^bb1
    ]
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device_2 : !hal.device) target(@main_dispatch_0::@cuda_nvptx_fb) layouts([%_pipeline_layout_0]) : !hal.executable
    cf.br ^bb3(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %2 = util.null : !hal.executable
    cf.br ^bb3(%2 : !hal.executable)
  ^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %3, @_executable_main_dispatch_0 : !hal.executable
    cf.br ^bb4
  ^bb4:  // pred: ^bb3
    %c0_i32 = arith.constant 0 : i32
    %c-1_i64 = arith.constant -1 : i64
    %c0_3 = arith.constant 0 : index
    %c128 = arith.constant 128 : index
    %c0_i64 = arith.constant 0 : i64
    %4 = util.null : !hal.fence
    %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #composite_of_128b
    %device_4 = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device_4 : !hal.device> : !hal.allocator
    %did_import, %mapped = hal.allocator.import<%allocator : !hal.allocator> source(%buffer_cst : !util.buffer)[%c0_3, %c128] affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : i1, !hal.buffer
    cf.cond_br %did_import, ^bb6(%4, %mapped : !hal.fence, !hal.buffer), ^bb5
  ^bb5:  // pred: ^bb4
    %buffer = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : !hal.buffer{%c128}
    %memory_file = hal.ex.file.from_memory device(%device_4 : !hal.device) affinity(%c-1_i64) access(Read) buffer(%buffer_cst : !util.buffer)[%c0_3 for %c128] flags(%c0_i32) : !hal.file
    %fence = hal.fence.create device(%device_4 : !hal.device) flags("None") : !hal.fence
    hal.device.queue.read<%device_4 : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence) source(%memory_file : !hal.file)[%c0_i64] target(%buffer : !hal.buffer)[%c0_3] length(%c128) flags(0)
    cf.br ^bb6(%fence, %buffer : !hal.fence, !hal.buffer)
  ^bb6(%5: !hal.fence, %6: !hal.buffer):  // 2 preds: ^bb4, ^bb5
    util.global.store %6, @_params.weight : !hal.buffer
    util.global.store %5, @_params.weight__timepoint : !hal.fence
    cf.br ^bb7
  ^bb7:  // pred: ^bb6
    util.initializer.return
  }
  hal.executable private @main_dispatch_0 {
    hal.executable.variant public @cuda_nvptx_fb target(#executable_target_cuda_nvptx_fb) {
      hal.executable.export public @main_dispatch_0_matmul_1x3x4_f32 ordinal(0) layout(#pipeline_layout) attributes {translation_info = #translation, workgroup_size = [1 : index, 3 : index, 1 : index]} {
      ^bb0(%arg0: !hal.device):
        %c3 = arith.constant 3 : index
        %c1 = arith.constant 1 : index
        hal.return %c3, %c1, %c1 : index, index, index
      }
      builtin.module {
        llvm.func @main_dispatch_0_matmul_1x3x4_f32(%arg0: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg1: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias, llvm.readonly}, %arg2: !llvm.ptr<1> {llvm.align = 16 : i32, llvm.noalias}) {
          %0 = llvm.mlir.constant(3 : i64) : i64
          %1 = llvm.mlir.constant(2 : i64) : i64
          %2 = llvm.mlir.constant(1 : i64) : i64
          %3 = llvm.mlir.constant(0 : i64) : i64
          %4 = llvm.mlir.constant(0 : i32) : i32
          %5 = llvm.mlir.constant(63 : index) : i64
          %6 = llvm.mlir.constant(4 : index) : i64
          %7 = llvm.mlir.constant(0 : index) : i64
          %8 = llvm.mlir.constant(1 : index) : i64
          %9 = llvm.mlir.constant(2 : index) : i64
          %10 = llvm.mlir.constant(3 : index) : i64
          %11 = llvm.ptrtoint %arg0 : !llvm.ptr<1> to i64
          %12 = llvm.and %11, %5  : i64
          %13 = llvm.icmp "eq" %12, %7 : i64
          "llvm.intr.assume"(%13) : (i1) -> ()
          %14 = llvm.ptrtoint %arg1 : !llvm.ptr<1> to i64
          %15 = llvm.and %14, %5  : i64
          %16 = llvm.icmp "eq" %15, %7 : i64
          "llvm.intr.assume"(%16) : (i1) -> ()
          %17 = llvm.getelementptr %arg1[16] : (!llvm.ptr<1>) -> !llvm.ptr<1>, f32
          %18 = llvm.ptrtoint %17 : !llvm.ptr<1> to i64
          %19 = llvm.and %18, %5  : i64
          %20 = llvm.icmp "eq" %19, %7 : i64
          "llvm.intr.assume"(%20) : (i1) -> ()
          %21 = llvm.ptrtoint %arg2 : !llvm.ptr<1> to i64
          %22 = llvm.and %21, %5  : i64
          %23 = llvm.icmp "eq" %22, %7 : i64
          "llvm.intr.assume"(%23) : (i1) -> ()
          %24 = nvvm.read.ptx.sreg.ctaid.x : i32
          %25 = llvm.sext %24 : i32 to i64
          %26 = llvm.mul %7, %6  : i64
          %27 = llvm.add %26, %7  : i64
          %28 = llvm.getelementptr %arg0[%27] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %29 = llvm.load %28 {alignment = 4 : i64} : !llvm.ptr<1> -> vector<4xf32>
          %30 = llvm.mul %7, %10  : i64
          %31 = llvm.add %30, %25  : i64
          %32 = llvm.getelementptr %arg1[%31] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %33 = llvm.load %32 : !llvm.ptr<1> -> f32
          %34 = llvm.mlir.undef : vector<1xf32>
          %35 = llvm.insertelement %33, %34[%4 : i32] : vector<1xf32>
          %36 = llvm.shufflevector %35, %34 [0] : vector<1xf32> 
          %37 = llvm.mul %8, %10  : i64
          %38 = llvm.add %37, %25  : i64
          %39 = llvm.getelementptr %arg1[%38] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %40 = llvm.load %39 : !llvm.ptr<1> -> f32
          %41 = llvm.insertelement %40, %34[%4 : i32] : vector<1xf32>
          %42 = llvm.shufflevector %41, %34 [0] : vector<1xf32> 
          %43 = llvm.mul %9, %10  : i64
          %44 = llvm.add %43, %25  : i64
          %45 = llvm.getelementptr %arg1[%44] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %46 = llvm.load %45 : !llvm.ptr<1> -> f32
          %47 = llvm.insertelement %46, %34[%4 : i32] : vector<1xf32>
          %48 = llvm.shufflevector %47, %34 [0] : vector<1xf32> 
          %49 = llvm.mul %10, %10  : i64
          %50 = llvm.add %49, %25  : i64
          %51 = llvm.getelementptr %arg1[%50] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %52 = llvm.load %51 : !llvm.ptr<1> -> f32
          %53 = llvm.insertelement %52, %34[%4 : i32] : vector<1xf32>
          %54 = llvm.shufflevector %53, %34 [0] : vector<1xf32> 
          %55 = llvm.getelementptr %17[%31] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          %56 = llvm.load %55 : !llvm.ptr<1> -> f32
          %57 = llvm.insertelement %56, %34[%4 : i32] : vector<1xf32>
          %58 = llvm.shufflevector %57, %34 [0] : vector<1xf32> 
          %59 = llvm.extractelement %29[%3 : i64] : vector<4xf32>
          %60 = llvm.insertelement %59, %34[%4 : i32] : vector<1xf32>
          %61 = llvm.shufflevector %60, %34 [0] : vector<1xf32> 
          %62 = llvm.intr.fmuladd(%61, %36, %58)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
          %63 = llvm.extractelement %29[%2 : i64] : vector<4xf32>
          %64 = llvm.insertelement %63, %34[%4 : i32] : vector<1xf32>
          %65 = llvm.shufflevector %64, %34 [0] : vector<1xf32> 
          %66 = llvm.intr.fmuladd(%65, %42, %62)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
          %67 = llvm.extractelement %29[%1 : i64] : vector<4xf32>
          %68 = llvm.insertelement %67, %34[%4 : i32] : vector<1xf32>
          %69 = llvm.shufflevector %68, %34 [0] : vector<1xf32> 
          %70 = llvm.intr.fmuladd(%69, %48, %66)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
          %71 = llvm.extractelement %29[%0 : i64] : vector<4xf32>
          %72 = llvm.insertelement %71, %34[%4 : i32] : vector<1xf32>
          %73 = llvm.shufflevector %72, %34 [0] : vector<1xf32> 
          %74 = llvm.intr.fmuladd(%73, %54, %70)  : (vector<1xf32>, vector<1xf32>, vector<1xf32>) -> vector<1xf32>
          %75 = llvm.extractelement %74[%3 : i64] : vector<1xf32>
          %76 = llvm.getelementptr %arg2[%31] : (!llvm.ptr<1>, i64) -> !llvm.ptr<1>, f32
          llvm.store %75, %76 : f32, !llvm.ptr<1>
          llvm.return
        }
      }
    }
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c3 = arith.constant 3 : index
    %c2 = arith.constant 2 : index
    %c1 = arith.constant 1 : index
    %c-1 = arith.constant -1 : index
    %c-1_i32 = arith.constant -1 : i32
    %c0_i64 = arith.constant 0 : i64
    %c-1_i64 = arith.constant -1 : i64
    %c128 = arith.constant 128 : index
    %c16 = arith.constant 16 : index
    %c12 = arith.constant 12 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !hal.fence
    %_params.weight = util.global.load @_params.weight : !hal.buffer
    %_device_query_0 = util.global.load @_device_query_0 : i1
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c16) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status = hal.fence.await until([%_params.weight__timepoint]) timeout_millis(%c-1_i32) : i32
    %0 = util.null : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%c12}
    %status_0 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    %1 = arith.select %_device_query_0, %c0, %c-1 : index
    %2 = arith.index_cast %1 : index to i32
    cf.switch %2 : i32, [
      default: ^bb2,
      0: ^bb1
    ]
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%buffer : !hal.buffer)[%c0, %c16], 
      %c1 = (%_params.weight : !hal.buffer)[%c0, %c128], 
      %c2 = (%transient_buffer : !hal.buffer)[%c0, %c12]
    ])
    %_executable_main_dispatch_0 = util.global.load @_executable_main_dispatch_0 : !hal.executable
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_main_dispatch_0 : !hal.executable)[0] workgroups([%c3, %c1, %c1])
    cf.br ^bb3
  ^bb2:  // pred: ^bb0
    cf.br ^bb3
  ^bb3:  // 2 preds: ^bb1, ^bb2
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_1 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status_2 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence_1) commands([%cmd])
    %status_3 = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status_3, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c12] shape([%c3]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


//
// Generated by LLVM NVPTX Back-End
//

.version 7.5
.target sm_75
.address_size 64

	// .globl	main_dispatch_0_matmul_1x3x4_f32

.visible .entry main_dispatch_0_matmul_1x3x4_f32(
	.param .u64 main_dispatch_0_matmul_1x3x4_f32_param_0,
	.param .u64 main_dispatch_0_matmul_1x3x4_f32_param_1,
	.param .u64 main_dispatch_0_matmul_1x3x4_f32_param_2
)
.maxntid 1, 3, 1
{
	.reg .b32 	%r<2>;
	.reg .f32 	%f<14>;
	.reg .b64 	%rd<7>;

	ld.param.u64 	%rd1, [main_dispatch_0_matmul_1x3x4_f32_param_0];
	ld.param.u64 	%rd2, [main_dispatch_0_matmul_1x3x4_f32_param_1];
	ld.param.u64 	%rd3, [main_dispatch_0_matmul_1x3x4_f32_param_2];
	mov.u32 	%r1, %ctaid.x;
	ld.global.nc.v4.f32 	{%f1, %f2, %f3, %f4}, [%rd1];
	mul.wide.u32 	%rd4, %r1, 4;
	add.s64 	%rd5, %rd2, %rd4;
	ld.global.nc.f32 	%f5, [%rd5];
	ld.global.nc.f32 	%f6, [%rd5+12];
	ld.global.nc.f32 	%f7, [%rd5+24];
	ld.global.nc.f32 	%f8, [%rd5+36];
	ld.global.nc.f32 	%f9, [%rd5+64];
	fma.rn.f32 	%f10, %f1, %f5, %f9;
	fma.rn.f32 	%f11, %f2, %f6, %f10;
	fma.rn.f32 	%f12, %f3, %f7, %f11;
	fma.rn.f32 	%f13, %f4, %f8, %f12;
	add.s64 	%rd6, %rd3, %rd4;
	st.global.f32 	[%rd6], %f13;
	ret;

}
// -----// IR Dump After mlir::iree_compiler::IREE::HAL::SerializeTargetExecutablesPass (iree-hal-serialize-target-executables) //----- //
hal.executable private @main_dispatch_0 {
  hal.executable.binary public @cuda_nvptx_fb attributes {data = dense<"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vector<1302xi8>, format = "cuda-nvptx-fb", mime_type = "application/x-flatbuffers"}
}

// -----// IR Dump After mlir::iree_compiler::IREE::HAL::SerializeExecutablesPass (iree-hal-serialize-executables) //----- //
hal.executable private @main_dispatch_0 {
  hal.executable.binary public @cuda_nvptx_fb attributes {data = dense<"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vector<1302xi8>, format = "cuda-nvptx-fb", mime_type = "application/x-flatbuffers"}
}

// -----// IR Dump After SymbolDCE (symbol-dce) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private @_device_query_0 : i1
  util.global private @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.global private @_executable_main_dispatch_0 : !hal.executable
  util.global private mutable @_params.weight__timepoint : !hal.fence
  util.global private @_params.weight : !hal.buffer
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    util.global.store %value, @_device_query_0 : i1
    %device_0 = hal.ex.shared_device : !hal.device
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device_0 : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
    util.global.store %descriptor_set_layout, @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    %_descriptor_set_layout_0 = util.global.load @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    %device_1 = hal.ex.shared_device : !hal.device
    %pipeline_layout = hal.pipeline_layout.create device(%device_1 : !hal.device) push_constants(0) layouts([%_descriptor_set_layout_0]) : !hal.pipeline_layout
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    %c-1 = arith.constant -1 : index
    %c0 = arith.constant 0 : index
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %device_2 = hal.ex.shared_device : !hal.device
    %0 = arith.select %_device_query_0, %c0, %c-1 : index
    %1 = arith.index_cast %0 : index to i32
    cf.switch %1 : i32, [
      default: ^bb2,
      0: ^bb1
    ]
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device_2 : !hal.device) target(@main_dispatch_0::@cuda_nvptx_fb) layouts([%_pipeline_layout_0]) : !hal.executable
    cf.br ^bb3(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %2 = util.null : !hal.executable
    cf.br ^bb3(%2 : !hal.executable)
  ^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %3, @_executable_main_dispatch_0 : !hal.executable
    cf.br ^bb4
  ^bb4:  // pred: ^bb3
    %c0_i32 = arith.constant 0 : i32
    %c-1_i64 = arith.constant -1 : i64
    %c0_3 = arith.constant 0 : index
    %c128 = arith.constant 128 : index
    %c0_i64 = arith.constant 0 : i64
    %4 = util.null : !hal.fence
    %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #composite_of_128b
    %device_4 = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device_4 : !hal.device> : !hal.allocator
    %did_import, %mapped = hal.allocator.import<%allocator : !hal.allocator> source(%buffer_cst : !util.buffer)[%c0_3, %c128] affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : i1, !hal.buffer
    cf.cond_br %did_import, ^bb6(%4, %mapped : !hal.fence, !hal.buffer), ^bb5
  ^bb5:  // pred: ^bb4
    %buffer = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : !hal.buffer{%c128}
    %memory_file = hal.ex.file.from_memory device(%device_4 : !hal.device) affinity(%c-1_i64) access(Read) buffer(%buffer_cst : !util.buffer)[%c0_3 for %c128] flags(%c0_i32) : !hal.file
    %fence = hal.fence.create device(%device_4 : !hal.device) flags("None") : !hal.fence
    hal.device.queue.read<%device_4 : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence) source(%memory_file : !hal.file)[%c0_i64] target(%buffer : !hal.buffer)[%c0_3] length(%c128) flags(0)
    cf.br ^bb6(%fence, %buffer : !hal.fence, !hal.buffer)
  ^bb6(%5: !hal.fence, %6: !hal.buffer):  // 2 preds: ^bb4, ^bb5
    util.global.store %6, @_params.weight : !hal.buffer
    util.global.store %5, @_params.weight__timepoint : !hal.fence
    cf.br ^bb7
  ^bb7:  // pred: ^bb6
    util.initializer.return
  }
  hal.executable private @main_dispatch_0 {
    hal.executable.binary public @cuda_nvptx_fb attributes {data = dense<"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vector<1302xi8>, format = "cuda-nvptx-fb", mime_type = "application/x-flatbuffers"}
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c3 = arith.constant 3 : index
    %c2 = arith.constant 2 : index
    %c1 = arith.constant 1 : index
    %c-1 = arith.constant -1 : index
    %c-1_i32 = arith.constant -1 : i32
    %c0_i64 = arith.constant 0 : i64
    %c-1_i64 = arith.constant -1 : i64
    %c128 = arith.constant 128 : index
    %c16 = arith.constant 16 : index
    %c12 = arith.constant 12 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !hal.fence
    %_params.weight = util.global.load @_params.weight : !hal.buffer
    %_device_query_0 = util.global.load @_device_query_0 : i1
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c16) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status = hal.fence.await until([%_params.weight__timepoint]) timeout_millis(%c-1_i32) : i32
    %0 = util.null : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%c12}
    %status_0 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    %1 = arith.select %_device_query_0, %c0, %c-1 : index
    %2 = arith.index_cast %1 : index to i32
    cf.switch %2 : i32, [
      default: ^bb2,
      0: ^bb1
    ]
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%buffer : !hal.buffer)[%c0, %c16], 
      %c1 = (%_params.weight : !hal.buffer)[%c0, %c128], 
      %c2 = (%transient_buffer : !hal.buffer)[%c0, %c12]
    ])
    %_executable_main_dispatch_0 = util.global.load @_executable_main_dispatch_0 : !hal.executable
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_main_dispatch_0 : !hal.executable)[0] workgroups([%c3, %c1, %c1])
    cf.br ^bb3
  ^bb2:  // pred: ^bb0
    cf.br ^bb3
  ^bb3:  // 2 preds: ^bb1, ^bb2
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_1 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status_2 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence_1) commands([%cmd])
    %status_3 = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status_3, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c12] shape([%c3]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After CSE (cse) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda], iree.fixedpoint.iteration = 0 : index} {
  util.global private @_device_query_0 : i1
  util.global private @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.global private @_executable_main_dispatch_0 : !hal.executable
  util.global private mutable @_params.weight__timepoint : !hal.fence
  util.global private @_params.weight : !hal.buffer
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    util.global.store %value, @_device_query_0 : i1
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
    util.global.store %descriptor_set_layout, @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    %_descriptor_set_layout_0 = util.global.load @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(0) layouts([%_descriptor_set_layout_0]) : !hal.pipeline_layout
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    %c-1 = arith.constant -1 : index
    %c0 = arith.constant 0 : index
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %0 = arith.select %_device_query_0, %c0, %c-1 : index
    %1 = arith.index_cast %0 : index to i32
    cf.switch %1 : i32, [
      default: ^bb2,
      0: ^bb1
    ]
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device : !hal.device) target(@main_dispatch_0::@cuda_nvptx_fb) layouts([%_pipeline_layout_0]) : !hal.executable
    cf.br ^bb3(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %2 = util.null : !hal.executable
    cf.br ^bb3(%2 : !hal.executable)
  ^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %3, @_executable_main_dispatch_0 : !hal.executable
    cf.br ^bb4
  ^bb4:  // pred: ^bb3
    %c0_i32 = arith.constant 0 : i32
    %c-1_i64 = arith.constant -1 : i64
    %c128 = arith.constant 128 : index
    %c0_i64 = arith.constant 0 : i64
    %4 = util.null : !hal.fence
    %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #composite_of_128b
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    %did_import, %mapped = hal.allocator.import<%allocator : !hal.allocator> source(%buffer_cst : !util.buffer)[%c0, %c128] affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : i1, !hal.buffer
    cf.cond_br %did_import, ^bb6(%4, %mapped : !hal.fence, !hal.buffer), ^bb5
  ^bb5:  // pred: ^bb4
    %buffer = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : !hal.buffer{%c128}
    %memory_file = hal.ex.file.from_memory device(%device : !hal.device) affinity(%c-1_i64) access(Read) buffer(%buffer_cst : !util.buffer)[%c0 for %c128] flags(%c0_i32) : !hal.file
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.read<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence) source(%memory_file : !hal.file)[%c0_i64] target(%buffer : !hal.buffer)[%c0] length(%c128) flags(0)
    cf.br ^bb6(%fence, %buffer : !hal.fence, !hal.buffer)
  ^bb6(%5: !hal.fence, %6: !hal.buffer):  // 2 preds: ^bb4, ^bb5
    util.global.store %6, @_params.weight : !hal.buffer
    util.global.store %5, @_params.weight__timepoint : !hal.fence
    cf.br ^bb7
  ^bb7:  // pred: ^bb6
    util.initializer.return
  }
  hal.executable private @main_dispatch_0 {
    hal.executable.binary public @cuda_nvptx_fb attributes {data = dense<"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vector<1302xi8>, format = "cuda-nvptx-fb", mime_type = "application/x-flatbuffers"}
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c3 = arith.constant 3 : index
    %c2 = arith.constant 2 : index
    %c1 = arith.constant 1 : index
    %c-1 = arith.constant -1 : index
    %c-1_i32 = arith.constant -1 : i32
    %c0_i64 = arith.constant 0 : i64
    %c-1_i64 = arith.constant -1 : i64
    %c128 = arith.constant 128 : index
    %c16 = arith.constant 16 : index
    %c12 = arith.constant 12 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !hal.fence
    %_params.weight = util.global.load @_params.weight : !hal.buffer
    %_device_query_0 = util.global.load @_device_query_0 : i1
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c16) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status = hal.fence.await until([%_params.weight__timepoint]) timeout_millis(%c-1_i32) : i32
    %0 = util.null : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%c12}
    %status_0 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    %1 = arith.select %_device_query_0, %c0, %c-1 : index
    %2 = arith.index_cast %1 : index to i32
    cf.switch %2 : i32, [
      default: ^bb2,
      0: ^bb1
    ]
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%buffer : !hal.buffer)[%c0, %c16], 
      %c1 = (%_params.weight : !hal.buffer)[%c0, %c128], 
      %c2 = (%transient_buffer : !hal.buffer)[%c0, %c12]
    ])
    %_executable_main_dispatch_0 = util.global.load @_executable_main_dispatch_0 : !hal.executable
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_main_dispatch_0 : !hal.executable)[0] workgroups([%c3, %c1, %c1])
    cf.br ^bb3
  ^bb2:  // pred: ^bb0
    cf.br ^bb3
  ^bb3:  // 2 preds: ^bb1, ^bb2
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_1 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status_2 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence_1) commands([%cmd])
    %status_3 = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status_3, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c12] shape([%c3]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda], iree.fixedpoint.iteration = 0 : index} {
  util.global private @_device_query_0 : i1
  util.global private @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.global private @_executable_main_dispatch_0 : !hal.executable
  util.global private mutable @_params.weight__timepoint : !hal.fence
  util.global private @_params.weight : !hal.buffer
  util.initializer {
    %c0_i64 = arith.constant 0 : i64
    %c128 = arith.constant 128 : index
    %c-1_i64 = arith.constant -1 : i64
    %c0_i32 = arith.constant 0 : i32
    %c0 = arith.constant 0 : index
    %c-1 = arith.constant -1 : index
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    util.global.store %value, @_device_query_0 : i1
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
    util.global.store %descriptor_set_layout, @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    %_descriptor_set_layout_0 = util.global.load @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(0) layouts([%_descriptor_set_layout_0]) : !hal.pipeline_layout
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %0 = arith.select %_device_query_0, %c0, %c-1 : index
    %1 = arith.index_cast %0 : index to i32
    cf.switch %1 : i32, [
      default: ^bb2,
      0: ^bb1
    ]
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device : !hal.device) target(@main_dispatch_0::@cuda_nvptx_fb) layouts([%_pipeline_layout_0]) : !hal.executable
    cf.br ^bb3(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %2 = util.null : !hal.executable
    cf.br ^bb3(%2 : !hal.executable)
  ^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %3, @_executable_main_dispatch_0 : !hal.executable
    %4 = util.null : !hal.fence
    %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #composite_of_128b
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    %did_import, %mapped = hal.allocator.import<%allocator : !hal.allocator> source(%buffer_cst : !util.buffer)[%c0, %c128] affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : i1, !hal.buffer
    cf.cond_br %did_import, ^bb5(%4, %mapped : !hal.fence, !hal.buffer), ^bb4
  ^bb4:  // pred: ^bb3
    %buffer = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : !hal.buffer{%c128}
    %memory_file = hal.ex.file.from_memory device(%device : !hal.device) affinity(%c-1_i64) access(Read) buffer(%buffer_cst : !util.buffer)[%c0 for %c128] flags(%c0_i32) : !hal.file
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.read<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence) source(%memory_file : !hal.file)[%c0_i64] target(%buffer : !hal.buffer)[%c0] length(%c128) flags(0)
    cf.br ^bb5(%fence, %buffer : !hal.fence, !hal.buffer)
  ^bb5(%5: !hal.fence, %6: !hal.buffer):  // 2 preds: ^bb3, ^bb4
    util.global.store %6, @_params.weight : !hal.buffer
    util.global.store %5, @_params.weight__timepoint : !hal.fence
    util.initializer.return
  }
  hal.executable private @main_dispatch_0 {
    hal.executable.binary public @cuda_nvptx_fb attributes {data = dense<"0x080000004355444100FBFFFF1C0000005000000044000000580000000400000001000000C00400000100000004000000200000006D61696E5F64697370617463685F305F6D61746D756C5F31783378345F663332000000000100000000000000010000000100000003000000010000006F0400002F2F0A2F2F2047656E657261746564206279204C4C564D204E56505458204261636B2D456E640A2F2F0A0A2E76657273696F6E20372E350A2E74617267657420736D5F37350A2E616464726573735F73697A652036340A0A092F2F202E676C6F626C096D61696E5F64697370617463685F305F6D61746D756C5F31783378345F6633320A0A2E76697369626C65202E656E747279206D61696E5F64697370617463685F305F6D61746D756C5F31783378345F663332280A092E706172616D202E753634206D61696E5F64697370617463685F305F6D61746D756C5F31783378345F6633325F706172616D5F302C0A092E706172616D202E753634206D61696E5F64697370617463685F305F6D61746D756C5F31783378345F6633325F706172616D5F312C0A092E706172616D202E753634206D61696E5F64697370617463685F305F6D61746D756C5F31783378345F6633325F706172616D5F320A290A2E6D61786E74696420312C20332C20310A7B0A092E726567202E623332200925723C323E3B0A092E726567202E663332200925663C31343E3B0A092E726567202E62363420092572643C373E3B0A0A096C642E706172616D2E7536342009257264312C205B6D61696E5F64697370617463685F305F6D61746D756C5F31783378345F6633325F706172616D5F305D3B0A096C642E706172616D2E7536342009257264322C205B6D61696E5F64697370617463685F305F6D61746D756C5F31783378345F6633325F706172616D5F315D3B0A096C642E706172616D2E7536342009257264332C205B6D61696E5F64697370617463685F305F6D61746D756C5F31783378345F6633325F706172616D5F325D3B0A096D6F762E75333220092572312C202563746169642E783B0A096C642E676C6F62616C2E6E632E76342E66333220097B2566312C202566322C202566332C202566347D2C205B257264315D3B0A096D756C2E776964652E7533322009257264342C202572312C20343B0A096164642E7336342009257264352C20257264322C20257264343B0A096C642E676C6F62616C2E6E632E66333220092566352C205B257264355D3B0A096C642E676C6F62616C2E6E632E66333220092566362C205B257264352B31325D3B0A096C642E676C6F62616C2E6E632E66333220092566372C205B257264352B32345D3B0A096C642E676C6F62616C2E6E632E66333220092566382C205B257264352B33365D3B0A096C642E676C6F62616C2E6E632E66333220092566392C205B257264352B36345D3B0A09666D612E726E2E6633322009256631302C202566312C202566352C202566393B0A09666D612E726E2E6633322009256631312C202566322C202566362C20256631303B0A09666D612E726E2E6633322009256631322C202566332C202566372C20256631313B0A09666D612E726E2E6633322009256631332C202566342C202566382C20256631323B0A096164642E7336342009257264362C20257264332C20257264343B0A0973742E676C6F62616C2E66333220095B257264365D2C20256631333B0A097265743B0A0A7D0A00E4FFFFFF08000000040000000A000000696E7075742E6D6C6972000008000C00040008000E001800040008000C0010001400"> : vector<1302xi8>, format = "cuda-nvptx-fb", mime_type = "application/x-flatbuffers"}
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c3 = arith.constant 3 : index
    %c2 = arith.constant 2 : index
    %c1 = arith.constant 1 : index
    %c-1 = arith.constant -1 : index
    %c-1_i32 = arith.constant -1 : i32
    %c0_i64 = arith.constant 0 : i64
    %c-1_i64 = arith.constant -1 : i64
    %c128 = arith.constant 128 : index
    %c16 = arith.constant 16 : index
    %c12 = arith.constant 12 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !hal.fence
    %_params.weight = util.global.load @_params.weight : !hal.buffer
    %_device_query_0 = util.global.load @_device_query_0 : i1
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c16) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status = hal.fence.await until([%_params.weight__timepoint]) timeout_millis(%c-1_i32) : i32
    %0 = util.null : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%c12}
    %status_0 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    %1 = arith.select %_device_query_0, %c0, %c-1 : index
    %2 = arith.index_cast %1 : index to i32
    cf.switch %2 : i32, [
      default: ^bb2,
      0: ^bb1
    ]
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%buffer : !hal.buffer)[%c0, %c16], 
      %c1 = (%_params.weight : !hal.buffer)[%c0, %c128], 
      %c2 = (%transient_buffer : !hal.buffer)[%c0, %c12]
    ])
    %_executable_main_dispatch_0 = util.global.load @_executable_main_dispatch_0 : !hal.executable
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_main_dispatch_0 : !hal.executable)[0] workgroups([%c3, %c1, %c1])
    cf.br ^bb2
  ^bb2:  // 2 preds: ^bb0, ^bb1
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_1 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status_2 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence_1) commands([%cmd])
    %status_3 = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status_3, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c12] shape([%c3]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After CSE (cse) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda], iree.fixedpoint.iteration = 0 : index} {
  util.global private @_device_query_0 : i1
  util.global private @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.global private @_executable_main_dispatch_0 : !hal.executable
  util.global private mutable @_params.weight__timepoint : !hal.fence
  util.global private @_params.weight : !hal.buffer
  util.initializer {
    %c0_i64 = arith.constant 0 : i64
    %c128 = arith.constant 128 : index
    %c-1_i64 = arith.constant -1 : i64
    %c0_i32 = arith.constant 0 : i32
    %c0 = arith.constant 0 : index
    %c-1 = arith.constant -1 : index
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    util.global.store %value, @_device_query_0 : i1
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
    util.global.store %descriptor_set_layout, @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    %_descriptor_set_layout_0 = util.global.load @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(0) layouts([%_descriptor_set_layout_0]) : !hal.pipeline_layout
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %0 = arith.select %_device_query_0, %c0, %c-1 : index
    %1 = arith.index_cast %0 : index to i32
    cf.switch %1 : i32, [
      default: ^bb2,
      0: ^bb1
    ]
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device : !hal.device) target(@main_dispatch_0::@cuda_nvptx_fb) layouts([%_pipeline_layout_0]) : !hal.executable
    cf.br ^bb3(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %2 = util.null : !hal.executable
    cf.br ^bb3(%2 : !hal.executable)
  ^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %3, @_executable_main_dispatch_0 : !hal.executable
    %4 = util.null : !hal.fence
    %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #composite_of_128b
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    %did_import, %mapped = hal.allocator.import<%allocator : !hal.allocator> source(%buffer_cst : !util.buffer)[%c0, %c128] affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : i1, !hal.buffer
    cf.cond_br %did_import, ^bb5(%4, %mapped : !hal.fence, !hal.buffer), ^bb4
  ^bb4:  // pred: ^bb3
    %buffer = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : !hal.buffer{%c128}
    %memory_file = hal.ex.file.from_memory device(%device : !hal.device) affinity(%c-1_i64) access(Read) buffer(%buffer_cst : !util.buffer)[%c0 for %c128] flags(%c0_i32) : !hal.file
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.read<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence) source(%memory_file : !hal.file)[%c0_i64] target(%buffer : !hal.buffer)[%c0] length(%c128) flags(0)
    cf.br ^bb5(%fence, %buffer : !hal.fence, !hal.buffer)
  ^bb5(%5: !hal.fence, %6: !hal.buffer):  // 2 preds: ^bb3, ^bb4
    util.global.store %6, @_params.weight : !hal.buffer
    util.global.store %5, @_params.weight__timepoint : !hal.fence
    util.initializer.return
  }
  hal.executable private @main_dispatch_0 {
    hal.executable.binary public @cuda_nvptx_fb attributes {data = dense<"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vector<1302xi8>, format = "cuda-nvptx-fb", mime_type = "application/x-flatbuffers"}
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c3 = arith.constant 3 : index
    %c2 = arith.constant 2 : index
    %c1 = arith.constant 1 : index
    %c-1 = arith.constant -1 : index
    %c-1_i32 = arith.constant -1 : i32
    %c0_i64 = arith.constant 0 : i64
    %c-1_i64 = arith.constant -1 : i64
    %c128 = arith.constant 128 : index
    %c16 = arith.constant 16 : index
    %c12 = arith.constant 12 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !hal.fence
    %_params.weight = util.global.load @_params.weight : !hal.buffer
    %_device_query_0 = util.global.load @_device_query_0 : i1
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c16) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status = hal.fence.await until([%_params.weight__timepoint]) timeout_millis(%c-1_i32) : i32
    %0 = util.null : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%c12}
    %status_0 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    %1 = arith.select %_device_query_0, %c0, %c-1 : index
    %2 = arith.index_cast %1 : index to i32
    cf.switch %2 : i32, [
      default: ^bb2,
      0: ^bb1
    ]
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%buffer : !hal.buffer)[%c0, %c16], 
      %c1 = (%_params.weight : !hal.buffer)[%c0, %c128], 
      %c2 = (%transient_buffer : !hal.buffer)[%c0, %c12]
    ])
    %_executable_main_dispatch_0 = util.global.load @_executable_main_dispatch_0 : !hal.executable
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_main_dispatch_0 : !hal.executable)[0] workgroups([%c3, %c1, %c1])
    cf.br ^bb2
  ^bb2:  // 2 preds: ^bb0, ^bb1
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_1 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status_2 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence_1) commands([%cmd])
    %status_3 = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status_3, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c12] shape([%c3]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.initializer {
  %c0_i64 = arith.constant 0 : i64
  %c128 = arith.constant 128 : index
  %c-1_i64 = arith.constant -1 : i64
  %c0_i32 = arith.constant 0 : i32
  %c0 = arith.constant 0 : index
  %c-1 = arith.constant -1 : index
  %device = hal.ex.shared_device : !hal.device
  %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
  %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
  %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(0) layouts([%descriptor_set_layout]) : !hal.pipeline_layout
  %0 = arith.select %value, %c0, %c-1 : index
  %1 = arith.index_cast %0 : index to i32
  util.global.store %descriptor_set_layout, @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  util.global.store %value, @_device_query_0 : i1
  util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
  cf.switch %1 : i32, [
    default: ^bb2,
    0: ^bb1
  ]
^bb1:  // pred: ^bb0
  %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
  %exe = hal.executable.create device(%device : !hal.device) target(@main_dispatch_0::@cuda_nvptx_fb) layouts([%_pipeline_layout_0]) : !hal.executable
  cf.br ^bb3(%exe : !hal.executable)
^bb2:  // pred: ^bb0
  %2 = util.null : !hal.executable
  cf.br ^bb3(%2 : !hal.executable)
^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
  %4 = util.null : !hal.fence
  %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
  %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
  %did_import, %mapped = hal.allocator.import<%allocator : !hal.allocator> source(%buffer_cst : !util.buffer)[%c0, %c128] affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : i1, !hal.buffer
  util.global.store %3, @_executable_main_dispatch_0 : !hal.executable
  cf.cond_br %did_import, ^bb5(%4, %mapped : !hal.fence, !hal.buffer), ^bb4
^bb4:  // pred: ^bb3
  %buffer = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : !hal.buffer{%c128}
  %memory_file = hal.ex.file.from_memory device(%device : !hal.device) affinity(%c-1_i64) access(Read) buffer(%buffer_cst : !util.buffer)[%c0 for %c128] flags(%c0_i32) : !hal.file
  %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
  hal.device.queue.read<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence) source(%memory_file : !hal.file)[%c0_i64] target(%buffer : !hal.buffer)[%c0] length(%c128) flags(0)
  cf.br ^bb5(%fence, %buffer : !hal.fence, !hal.buffer)
^bb5(%5: !hal.fence, %6: !hal.buffer):  // 2 preds: ^bb3, ^bb4
  util.global.store %6, @_params.weight : !hal.buffer
  util.global.store %5, @_params.weight__timepoint : !hal.fence
  util.initializer.return
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !hal.fence
  %_params.weight = util.global.load @_params.weight : !hal.buffer
  %_device_query_0 = util.global.load @_device_query_0 : i1
  %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
  %_executable_main_dispatch_0 = util.global.load @_executable_main_dispatch_0 : !hal.executable
  %c3 = arith.constant 3 : index
  %c2 = arith.constant 2 : index
  %c1 = arith.constant 1 : index
  %c-1 = arith.constant -1 : index
  %c-1_i32 = arith.constant -1 : i32
  %c0_i64 = arith.constant 0 : i64
  %c-1_i64 = arith.constant -1 : i64
  %c128 = arith.constant 128 : index
  %c16 = arith.constant 16 : index
  %c12 = arith.constant 12 : index
  %c553648160_i32 = arith.constant 553648160 : i32
  %c1_i32 = arith.constant 1 : i32
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %device = hal.ex.shared_device : !hal.device
  %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c16) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
  %status = hal.fence.await until([%_params.weight__timepoint]) timeout_millis(%c-1_i32) : i32
  %0 = util.null : !hal.fence
  %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%c12}
  %status_0 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
  %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
  %1 = arith.select %_device_query_0, %c0, %c-1 : index
  %2 = arith.index_cast %1 : index to i32
  cf.switch %2 : i32, [
    default: ^bb2,
    0: ^bb1
  ]
^bb1:  // pred: ^bb0
  hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
    %c0 = (%buffer : !hal.buffer)[%c0, %c16], 
    %c1 = (%_params.weight : !hal.buffer)[%c0, %c128], 
    %c2 = (%transient_buffer : !hal.buffer)[%c0, %c12]
  ])
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_main_dispatch_0 : !hal.executable)[0] workgroups([%c3, %c1, %c1])
  cf.br ^bb2
^bb2:  // 2 preds: ^bb0, ^bb1
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  %fence_1 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
  %status_2 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
  hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence_1) commands([%cmd])
  %status_3 = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
  util.status.check_ok %status_3, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c12] shape([%c3]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
  return %view : !hal.buffer_view
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda], iree.fixedpoint.iteration = 0 : index} {
  util.global private @_device_query_0 : i1
  util.global private @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.global private @_executable_main_dispatch_0 : !hal.executable
  util.global private mutable @_params.weight__timepoint : !hal.fence
  util.global private @_params.weight : !hal.buffer
  util.initializer {
    %c0_i64 = arith.constant 0 : i64
    %c128 = arith.constant 128 : index
    %c-1_i64 = arith.constant -1 : i64
    %c0_i32 = arith.constant 0 : i32
    %c0 = arith.constant 0 : index
    %c-1 = arith.constant -1 : index
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(0) layouts([%descriptor_set_layout]) : !hal.pipeline_layout
    %0 = arith.select %value, %c0, %c-1 : index
    %1 = arith.index_cast %0 : index to i32
    util.global.store %descriptor_set_layout, @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    util.global.store %value, @_device_query_0 : i1
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    cf.switch %1 : i32, [
      default: ^bb2,
      0: ^bb1
    ]
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device : !hal.device) target(@main_dispatch_0::@cuda_nvptx_fb) layouts([%_pipeline_layout_0]) : !hal.executable
    cf.br ^bb3(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %2 = util.null : !hal.executable
    cf.br ^bb3(%2 : !hal.executable)
  ^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
    %4 = util.null : !hal.fence
    %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #composite_of_128b
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    %did_import, %mapped = hal.allocator.import<%allocator : !hal.allocator> source(%buffer_cst : !util.buffer)[%c0, %c128] affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : i1, !hal.buffer
    util.global.store %3, @_executable_main_dispatch_0 : !hal.executable
    cf.cond_br %did_import, ^bb5(%4, %mapped : !hal.fence, !hal.buffer), ^bb4
  ^bb4:  // pred: ^bb3
    %buffer = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : !hal.buffer{%c128}
    %memory_file = hal.ex.file.from_memory device(%device : !hal.device) affinity(%c-1_i64) access(Read) buffer(%buffer_cst : !util.buffer)[%c0 for %c128] flags(%c0_i32) : !hal.file
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.read<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence) source(%memory_file : !hal.file)[%c0_i64] target(%buffer : !hal.buffer)[%c0] length(%c128) flags(0)
    cf.br ^bb5(%fence, %buffer : !hal.fence, !hal.buffer)
  ^bb5(%5: !hal.fence, %6: !hal.buffer):  // 2 preds: ^bb3, ^bb4
    util.global.store %6, @_params.weight : !hal.buffer
    util.global.store %5, @_params.weight__timepoint : !hal.fence
    util.initializer.return
  }
  hal.executable private @main_dispatch_0 {
    hal.executable.binary public @cuda_nvptx_fb attributes {data = dense<"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vector<1302xi8>, format = "cuda-nvptx-fb", mime_type = "application/x-flatbuffers"}
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %c12 = arith.constant 12 : index
    %c16 = arith.constant 16 : index
    %c128 = arith.constant 128 : index
    %c-1_i64 = arith.constant -1 : i64
    %c0_i64 = arith.constant 0 : i64
    %c-1_i32 = arith.constant -1 : i32
    %c-1 = arith.constant -1 : index
    %c1 = arith.constant 1 : index
    %c2 = arith.constant 2 : index
    %c3 = arith.constant 3 : index
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !hal.fence
    %_params.weight = util.global.load @_params.weight : !hal.buffer
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %_executable_main_dispatch_0 = util.global.load @_executable_main_dispatch_0 : !hal.executable
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c16) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status = hal.fence.await until([%_params.weight__timepoint]) timeout_millis(%c-1_i32) : i32
    %0 = util.null : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%c12}
    %status_0 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    %1 = arith.select %_device_query_0, %c0, %c-1 : index
    %2 = arith.index_cast %1 : index to i32
    cf.switch %2 : i32, [
      default: ^bb2,
      0: ^bb1
    ]
  ^bb1:  // pred: ^bb0
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%buffer : !hal.buffer)[%c0, %c16], 
      %c1 = (%_params.weight : !hal.buffer)[%c0, %c128], 
      %c2 = (%transient_buffer : !hal.buffer)[%c0, %c12]
    ])
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_main_dispatch_0 : !hal.executable)[0] workgroups([%c3, %c1, %c1])
    cf.br ^bb2
  ^bb2:  // 2 preds: ^bb0, ^bb1
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_1 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status_2 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence_1) commands([%cmd])
    %status_3 = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status_3, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c12] shape([%c3]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda], iree.fixedpoint.iteration = 0 : index} {
  util.global private @_device_query_0 : i1
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.global private @_executable_main_dispatch_0 : !hal.executable
  util.global private mutable @_params.weight__timepoint : !hal.fence
  util.global private @_params.weight : !hal.buffer
  util.initializer {
    %c0_i64 = arith.constant 0 : i64
    %c128 = arith.constant 128 : index
    %c-1_i64 = arith.constant -1 : i64
    %c0_i32 = arith.constant 0 : i32
    %c0 = arith.constant 0 : index
    %c-1 = arith.constant -1 : index
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(0) layouts([%descriptor_set_layout]) : !hal.pipeline_layout
    %0 = arith.select %value, %c0, %c-1 : index
    %1 = arith.index_cast %0 : index to i32
    util.global.store %value, @_device_query_0 : i1
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    cf.switch %1 : i32, [
      default: ^bb2,
      0: ^bb1
    ]
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device : !hal.device) target(@main_dispatch_0::@cuda_nvptx_fb) layouts([%_pipeline_layout_0]) : !hal.executable
    cf.br ^bb3(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %2 = util.null : !hal.executable
    cf.br ^bb3(%2 : !hal.executable)
  ^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
    %4 = util.null : !hal.fence
    %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #composite_of_128b
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    %did_import, %mapped = hal.allocator.import<%allocator : !hal.allocator> source(%buffer_cst : !util.buffer)[%c0, %c128] affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : i1, !hal.buffer
    util.global.store %3, @_executable_main_dispatch_0 : !hal.executable
    cf.cond_br %did_import, ^bb5(%4, %mapped : !hal.fence, !hal.buffer), ^bb4
  ^bb4:  // pred: ^bb3
    %buffer = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : !hal.buffer{%c128}
    %memory_file = hal.ex.file.from_memory device(%device : !hal.device) affinity(%c-1_i64) access(Read) buffer(%buffer_cst : !util.buffer)[%c0 for %c128] flags(%c0_i32) : !hal.file
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.read<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence) source(%memory_file : !hal.file)[%c0_i64] target(%buffer : !hal.buffer)[%c0] length(%c128) flags(0)
    cf.br ^bb5(%fence, %buffer : !hal.fence, !hal.buffer)
  ^bb5(%5: !hal.fence, %6: !hal.buffer):  // 2 preds: ^bb3, ^bb4
    util.global.store %6, @_params.weight : !hal.buffer
    util.global.store %5, @_params.weight__timepoint : !hal.fence
    util.initializer.return
  }
  hal.executable private @main_dispatch_0 {
    hal.executable.binary public @cuda_nvptx_fb attributes {data = dense<"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vector<1302xi8>, format = "cuda-nvptx-fb", mime_type = "application/x-flatbuffers"}
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %c12 = arith.constant 12 : index
    %c16 = arith.constant 16 : index
    %c128 = arith.constant 128 : index
    %c-1_i64 = arith.constant -1 : i64
    %c0_i64 = arith.constant 0 : i64
    %c-1_i32 = arith.constant -1 : i32
    %c-1 = arith.constant -1 : index
    %c1 = arith.constant 1 : index
    %c2 = arith.constant 2 : index
    %c3 = arith.constant 3 : index
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !hal.fence
    %_params.weight = util.global.load @_params.weight : !hal.buffer
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %_executable_main_dispatch_0 = util.global.load @_executable_main_dispatch_0 : !hal.executable
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c16) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status = hal.fence.await until([%_params.weight__timepoint]) timeout_millis(%c-1_i32) : i32
    %0 = util.null : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%c12}
    %status_0 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    %1 = arith.select %_device_query_0, %c0, %c-1 : index
    %2 = arith.index_cast %1 : index to i32
    cf.switch %2 : i32, [
      default: ^bb2,
      0: ^bb1
    ]
  ^bb1:  // pred: ^bb0
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%buffer : !hal.buffer)[%c0, %c16], 
      %c1 = (%_params.weight : !hal.buffer)[%c0, %c128], 
      %c2 = (%transient_buffer : !hal.buffer)[%c0, %c12]
    ])
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_main_dispatch_0 : !hal.executable)[0] workgroups([%c3, %c1, %c1])
    cf.br ^bb2
  ^bb2:  // 2 preds: ^bb0, ^bb1
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_1 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status_2 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence_1) commands([%cmd])
    %status_3 = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status_3, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c12] shape([%c3]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda], iree.fixedpoint.iteration = 0 : index} {
  util.global private @_device_query_0 : i1
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.global private @_executable_main_dispatch_0 : !hal.executable
  util.global private mutable @_params.weight__timepoint : !hal.fence
  util.global private @_params.weight : !hal.buffer
  util.initializer {
    %c0_i64 = arith.constant 0 : i64
    %c128 = arith.constant 128 : index
    %c-1_i64 = arith.constant -1 : i64
    %c0_i32 = arith.constant 0 : i32
    %c0 = arith.constant 0 : index
    %c-1 = arith.constant -1 : index
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(0) layouts([%descriptor_set_layout]) : !hal.pipeline_layout
    %0 = arith.select %value, %c0, %c-1 : index
    %1 = arith.index_cast %0 : index to i32
    util.global.store %value, @_device_query_0 : i1
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    cf.switch %1 : i32, [
      default: ^bb2,
      0: ^bb1
    ]
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device : !hal.device) target(@main_dispatch_0::@cuda_nvptx_fb) layouts([%_pipeline_layout_0]) : !hal.executable
    cf.br ^bb3(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %2 = util.null : !hal.executable
    cf.br ^bb3(%2 : !hal.executable)
  ^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
    %4 = util.null : !hal.fence
    %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #composite_of_128b
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    %did_import, %mapped = hal.allocator.import<%allocator : !hal.allocator> source(%buffer_cst : !util.buffer)[%c0, %c128] affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : i1, !hal.buffer
    util.global.store %3, @_executable_main_dispatch_0 : !hal.executable
    cf.cond_br %did_import, ^bb5(%4, %mapped : !hal.fence, !hal.buffer), ^bb4
  ^bb4:  // pred: ^bb3
    %buffer = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : !hal.buffer{%c128}
    %memory_file = hal.ex.file.from_memory device(%device : !hal.device) affinity(%c-1_i64) access(Read) buffer(%buffer_cst : !util.buffer)[%c0 for %c128] flags(%c0_i32) : !hal.file
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.read<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence) source(%memory_file : !hal.file)[%c0_i64] target(%buffer : !hal.buffer)[%c0] length(%c128) flags(0)
    cf.br ^bb5(%fence, %buffer : !hal.fence, !hal.buffer)
  ^bb5(%5: !hal.fence, %6: !hal.buffer):  // 2 preds: ^bb3, ^bb4
    util.global.store %6, @_params.weight : !hal.buffer
    util.global.store %5, @_params.weight__timepoint : !hal.fence
    util.initializer.return
  }
  hal.executable private @main_dispatch_0 {
    hal.executable.binary public @cuda_nvptx_fb attributes {data = dense<"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vector<1302xi8>, format = "cuda-nvptx-fb", mime_type = "application/x-flatbuffers"}
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %c12 = arith.constant 12 : index
    %c16 = arith.constant 16 : index
    %c128 = arith.constant 128 : index
    %c-1_i64 = arith.constant -1 : i64
    %c0_i64 = arith.constant 0 : i64
    %c-1_i32 = arith.constant -1 : i32
    %c-1 = arith.constant -1 : index
    %c1 = arith.constant 1 : index
    %c2 = arith.constant 2 : index
    %c3 = arith.constant 3 : index
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !hal.fence
    %_params.weight = util.global.load @_params.weight : !hal.buffer
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %_executable_main_dispatch_0 = util.global.load @_executable_main_dispatch_0 : !hal.executable
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c16) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status = hal.fence.await until([%_params.weight__timepoint]) timeout_millis(%c-1_i32) : i32
    %0 = util.null : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%c12}
    %status_0 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    %1 = arith.select %_device_query_0, %c0, %c-1 : index
    %2 = arith.index_cast %1 : index to i32
    cf.switch %2 : i32, [
      default: ^bb2,
      0: ^bb1
    ]
  ^bb1:  // pred: ^bb0
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%buffer : !hal.buffer)[%c0, %c16], 
      %c1 = (%_params.weight : !hal.buffer)[%c0, %c128], 
      %c2 = (%transient_buffer : !hal.buffer)[%c0, %c12]
    ])
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_main_dispatch_0 : !hal.executable)[0] workgroups([%c3, %c1, %c1])
    cf.br ^bb2
  ^bb2:  // 2 preds: ^bb0, ^bb1
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_1 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status_2 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence_1) commands([%cmd])
    %status_3 = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status_3, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c12] shape([%c3]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda], iree.fixedpoint.iteration = 0 : index} {
  util.global private @_device_query_0 : i1
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.global private @_executable_main_dispatch_0 : !hal.executable
  util.global private mutable @_params.weight__timepoint : !hal.fence
  util.global private @_params.weight : !hal.buffer
  util.initializer {
    %c0_i64 = arith.constant 0 : i64
    %c128 = arith.constant 128 : index
    %c-1_i64 = arith.constant -1 : i64
    %c0_i32 = arith.constant 0 : i32
    %c0 = arith.constant 0 : index
    %c-1 = arith.constant -1 : index
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(0) layouts([%descriptor_set_layout]) : !hal.pipeline_layout
    %0 = arith.select %value, %c0, %c-1 : index
    %1 = arith.index_cast %0 : index to i32
    util.global.store %value, @_device_query_0 : i1
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    cf.switch %1 : i32, [
      default: ^bb2,
      0: ^bb1
    ]
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device : !hal.device) target(@main_dispatch_0::@cuda_nvptx_fb) layouts([%_pipeline_layout_0]) : !hal.executable
    cf.br ^bb3(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %2 = util.null : !hal.executable
    cf.br ^bb3(%2 : !hal.executable)
  ^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
    %4 = util.null : !hal.fence
    %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #composite_of_128b
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    %did_import, %mapped = hal.allocator.import<%allocator : !hal.allocator> source(%buffer_cst : !util.buffer)[%c0, %c128] affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : i1, !hal.buffer
    util.global.store %3, @_executable_main_dispatch_0 : !hal.executable
    cf.cond_br %did_import, ^bb5(%4, %mapped : !hal.fence, !hal.buffer), ^bb4
  ^bb4:  // pred: ^bb3
    %buffer = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : !hal.buffer{%c128}
    %memory_file = hal.ex.file.from_memory device(%device : !hal.device) affinity(%c-1_i64) access(Read) buffer(%buffer_cst : !util.buffer)[%c0 for %c128] flags(%c0_i32) : !hal.file
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.read<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence) source(%memory_file : !hal.file)[%c0_i64] target(%buffer : !hal.buffer)[%c0] length(%c128) flags(0)
    cf.br ^bb5(%fence, %buffer : !hal.fence, !hal.buffer)
  ^bb5(%5: !hal.fence, %6: !hal.buffer):  // 2 preds: ^bb3, ^bb4
    util.global.store %6, @_params.weight : !hal.buffer
    util.global.store %5, @_params.weight__timepoint : !hal.fence
    util.initializer.return
  }
  hal.executable private @main_dispatch_0 {
    hal.executable.binary public @cuda_nvptx_fb attributes {data = dense<"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vector<1302xi8>, format = "cuda-nvptx-fb", mime_type = "application/x-flatbuffers"}
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %c12 = arith.constant 12 : index
    %c16 = arith.constant 16 : index
    %c128 = arith.constant 128 : index
    %c-1_i64 = arith.constant -1 : i64
    %c0_i64 = arith.constant 0 : i64
    %c-1_i32 = arith.constant -1 : i32
    %c-1 = arith.constant -1 : index
    %c1 = arith.constant 1 : index
    %c2 = arith.constant 2 : index
    %c3 = arith.constant 3 : index
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !hal.fence
    %_params.weight = util.global.load @_params.weight : !hal.buffer
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %_executable_main_dispatch_0 = util.global.load @_executable_main_dispatch_0 : !hal.executable
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c16) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status = hal.fence.await until([%_params.weight__timepoint]) timeout_millis(%c-1_i32) : i32
    %0 = util.null : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%c12}
    %status_0 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    %1 = arith.select %_device_query_0, %c0, %c-1 : index
    %2 = arith.index_cast %1 : index to i32
    cf.switch %2 : i32, [
      default: ^bb2,
      0: ^bb1
    ]
  ^bb1:  // pred: ^bb0
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%buffer : !hal.buffer)[%c0, %c16], 
      %c1 = (%_params.weight : !hal.buffer)[%c0, %c128], 
      %c2 = (%transient_buffer : !hal.buffer)[%c0, %c12]
    ])
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_main_dispatch_0 : !hal.executable)[0] workgroups([%c3, %c1, %c1])
    cf.br ^bb2
  ^bb2:  // 2 preds: ^bb0, ^bb1
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_1 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status_2 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence_1) commands([%cmd])
    %status_3 = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status_3, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c12] shape([%c3]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After FixedPointIterator (iree-util-fixed-point-iterator) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private @_device_query_0 : i1
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.global private @_executable_main_dispatch_0 : !hal.executable
  util.global private mutable @_params.weight__timepoint : !hal.fence
  util.global private @_params.weight : !hal.buffer
  util.initializer {
    %c0_i64 = arith.constant 0 : i64
    %c128 = arith.constant 128 : index
    %c-1_i64 = arith.constant -1 : i64
    %c0_i32 = arith.constant 0 : i32
    %c0 = arith.constant 0 : index
    %c-1 = arith.constant -1 : index
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(0) layouts([%descriptor_set_layout]) : !hal.pipeline_layout
    %0 = arith.select %value, %c0, %c-1 : index
    %1 = arith.index_cast %0 : index to i32
    util.global.store %value, @_device_query_0 : i1
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    cf.switch %1 : i32, [
      default: ^bb2,
      0: ^bb1
    ]
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device : !hal.device) target(@main_dispatch_0::@cuda_nvptx_fb) layouts([%_pipeline_layout_0]) : !hal.executable
    cf.br ^bb3(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %2 = util.null : !hal.executable
    cf.br ^bb3(%2 : !hal.executable)
  ^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
    %4 = util.null : !hal.fence
    %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #composite_of_128b
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    %did_import, %mapped = hal.allocator.import<%allocator : !hal.allocator> source(%buffer_cst : !util.buffer)[%c0, %c128] affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : i1, !hal.buffer
    util.global.store %3, @_executable_main_dispatch_0 : !hal.executable
    cf.cond_br %did_import, ^bb5(%4, %mapped : !hal.fence, !hal.buffer), ^bb4
  ^bb4:  // pred: ^bb3
    %buffer = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : !hal.buffer{%c128}
    %memory_file = hal.ex.file.from_memory device(%device : !hal.device) affinity(%c-1_i64) access(Read) buffer(%buffer_cst : !util.buffer)[%c0 for %c128] flags(%c0_i32) : !hal.file
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.read<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence) source(%memory_file : !hal.file)[%c0_i64] target(%buffer : !hal.buffer)[%c0] length(%c128) flags(0)
    cf.br ^bb5(%fence, %buffer : !hal.fence, !hal.buffer)
  ^bb5(%5: !hal.fence, %6: !hal.buffer):  // 2 preds: ^bb3, ^bb4
    util.global.store %6, @_params.weight : !hal.buffer
    util.global.store %5, @_params.weight__timepoint : !hal.fence
    util.initializer.return
  }
  hal.executable private @main_dispatch_0 {
    hal.executable.binary public @cuda_nvptx_fb attributes {data = dense<"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vector<1302xi8>, format = "cuda-nvptx-fb", mime_type = "application/x-flatbuffers"}
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %c12 = arith.constant 12 : index
    %c16 = arith.constant 16 : index
    %c128 = arith.constant 128 : index
    %c-1_i64 = arith.constant -1 : i64
    %c0_i64 = arith.constant 0 : i64
    %c-1_i32 = arith.constant -1 : i32
    %c-1 = arith.constant -1 : index
    %c1 = arith.constant 1 : index
    %c2 = arith.constant 2 : index
    %c3 = arith.constant 3 : index
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !hal.fence
    %_params.weight = util.global.load @_params.weight : !hal.buffer
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %_executable_main_dispatch_0 = util.global.load @_executable_main_dispatch_0 : !hal.executable
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c16) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status = hal.fence.await until([%_params.weight__timepoint]) timeout_millis(%c-1_i32) : i32
    %0 = util.null : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%c12}
    %status_0 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    %1 = arith.select %_device_query_0, %c0, %c-1 : index
    %2 = arith.index_cast %1 : index to i32
    cf.switch %2 : i32, [
      default: ^bb2,
      0: ^bb1
    ]
  ^bb1:  // pred: ^bb0
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%buffer : !hal.buffer)[%c0, %c16], 
      %c1 = (%_params.weight : !hal.buffer)[%c0, %c128], 
      %c2 = (%transient_buffer : !hal.buffer)[%c0, %c12]
    ])
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_main_dispatch_0 : !hal.executable)[0] workgroups([%c3, %c1, %c1])
    cf.br ^bb2
  ^bb2:  // 2 preds: ^bb0, ^bb1
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_1 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status_2 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence_1) commands([%cmd])
    %status_3 = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status_3, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c12] shape([%c3]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.initializer {
  %c0_i64 = arith.constant 0 : i64
  %c128 = arith.constant 128 : index
  %c-1_i64 = arith.constant -1 : i64
  %c0_i32 = arith.constant 0 : i32
  %c0 = arith.constant 0 : index
  %c-1 = arith.constant -1 : index
  %device = hal.ex.shared_device : !hal.device
  %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
  %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
  %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(0) layouts([%descriptor_set_layout]) : !hal.pipeline_layout
  %0 = arith.select %value, %c0, %c-1 : index
  %1 = arith.index_cast %0 : index to i32
  util.global.store %value, @_device_query_0 : i1
  util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
  cf.switch %1 : i32, [
    default: ^bb2,
    0: ^bb1
  ]
^bb1:  // pred: ^bb0
  %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
  %exe = hal.executable.create device(%device : !hal.device) target(@main_dispatch_0::@cuda_nvptx_fb) layouts([%_pipeline_layout_0]) : !hal.executable
  cf.br ^bb3(%exe : !hal.executable)
^bb2:  // pred: ^bb0
  %2 = util.null : !hal.executable
  cf.br ^bb3(%2 : !hal.executable)
^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
  %4 = util.null : !hal.fence
  %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
  %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
  %did_import, %mapped = hal.allocator.import<%allocator : !hal.allocator> source(%buffer_cst : !util.buffer)[%c0, %c128] affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : i1, !hal.buffer
  util.global.store %3, @_executable_main_dispatch_0 : !hal.executable
  cf.cond_br %did_import, ^bb5(%4, %mapped : !hal.fence, !hal.buffer), ^bb4
^bb4:  // pred: ^bb3
  %buffer = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : !hal.buffer{%c128}
  %memory_file = hal.ex.file.from_memory device(%device : !hal.device) affinity(%c-1_i64) access(Read) buffer(%buffer_cst : !util.buffer)[%c0 for %c128] flags(%c0_i32) : !hal.file
  %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
  hal.device.queue.read<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence) source(%memory_file : !hal.file)[%c0_i64] target(%buffer : !hal.buffer)[%c0] length(%c128) flags(0)
  cf.br ^bb5(%fence, %buffer : !hal.fence, !hal.buffer)
^bb5(%5: !hal.fence, %6: !hal.buffer):  // 2 preds: ^bb3, ^bb4
  util.global.store %6, @_params.weight : !hal.buffer
  util.global.store %5, @_params.weight__timepoint : !hal.fence
  util.initializer.return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c0 = arith.constant 0 : index
  %c4 = arith.constant 4 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %c12 = arith.constant 12 : index
  %c16 = arith.constant 16 : index
  %c128 = arith.constant 128 : index
  %c-1_i64 = arith.constant -1 : i64
  %c0_i64 = arith.constant 0 : i64
  %c-1_i32 = arith.constant -1 : i32
  %c-1 = arith.constant -1 : index
  %c1 = arith.constant 1 : index
  %c2 = arith.constant 2 : index
  %c3 = arith.constant 3 : index
  %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !hal.fence
  %_params.weight = util.global.load @_params.weight : !hal.buffer
  %_device_query_0 = util.global.load @_device_query_0 : i1
  %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
  %_executable_main_dispatch_0 = util.global.load @_executable_main_dispatch_0 : !hal.executable
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %device = hal.ex.shared_device : !hal.device
  %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c16) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
  %status = hal.fence.await until([%_params.weight__timepoint]) timeout_millis(%c-1_i32) : i32
  %0 = util.null : !hal.fence
  %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%c12}
  %status_0 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
  %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
  %1 = arith.select %_device_query_0, %c0, %c-1 : index
  %2 = arith.index_cast %1 : index to i32
  cf.switch %2 : i32, [
    default: ^bb2,
    0: ^bb1
  ]
^bb1:  // pred: ^bb0
  hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
    %c0 = (%buffer : !hal.buffer)[%c0, %c16], 
    %c1 = (%_params.weight : !hal.buffer)[%c0, %c128], 
    %c2 = (%transient_buffer : !hal.buffer)[%c0, %c12]
  ])
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_main_dispatch_0 : !hal.executable)[0] workgroups([%c3, %c1, %c1])
  cf.br ^bb2
^bb2:  // 2 preds: ^bb0, ^bb1
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  %fence_1 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
  %status_2 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
  hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence_1) commands([%cmd])
  %status_3 = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
  util.status.check_ok %status_3, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c12] shape([%c3]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
  return %view : !hal.buffer_view
}

// -----// IR Dump After Inliner (inline) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private @_device_query_0 : i1
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.global private @_executable_main_dispatch_0 : !hal.executable
  util.global private mutable @_params.weight__timepoint : !hal.fence
  util.global private @_params.weight : !hal.buffer
  util.initializer {
    %c0_i64 = arith.constant 0 : i64
    %c128 = arith.constant 128 : index
    %c-1_i64 = arith.constant -1 : i64
    %c0_i32 = arith.constant 0 : i32
    %c0 = arith.constant 0 : index
    %c-1 = arith.constant -1 : index
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(0) layouts([%descriptor_set_layout]) : !hal.pipeline_layout
    %0 = arith.select %value, %c0, %c-1 : index
    %1 = arith.index_cast %0 : index to i32
    util.global.store %value, @_device_query_0 : i1
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    cf.switch %1 : i32, [
      default: ^bb2,
      0: ^bb1
    ]
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device : !hal.device) target(@main_dispatch_0::@cuda_nvptx_fb) layouts([%_pipeline_layout_0]) : !hal.executable
    cf.br ^bb3(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %2 = util.null : !hal.executable
    cf.br ^bb3(%2 : !hal.executable)
  ^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
    %4 = util.null : !hal.fence
    %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #composite_of_128b
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    %did_import, %mapped = hal.allocator.import<%allocator : !hal.allocator> source(%buffer_cst : !util.buffer)[%c0, %c128] affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : i1, !hal.buffer
    util.global.store %3, @_executable_main_dispatch_0 : !hal.executable
    cf.cond_br %did_import, ^bb5(%4, %mapped : !hal.fence, !hal.buffer), ^bb4
  ^bb4:  // pred: ^bb3
    %buffer = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : !hal.buffer{%c128}
    %memory_file = hal.ex.file.from_memory device(%device : !hal.device) affinity(%c-1_i64) access(Read) buffer(%buffer_cst : !util.buffer)[%c0 for %c128] flags(%c0_i32) : !hal.file
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.read<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence) source(%memory_file : !hal.file)[%c0_i64] target(%buffer : !hal.buffer)[%c0] length(%c128) flags(0)
    cf.br ^bb5(%fence, %buffer : !hal.fence, !hal.buffer)
  ^bb5(%5: !hal.fence, %6: !hal.buffer):  // 2 preds: ^bb3, ^bb4
    util.global.store %6, @_params.weight : !hal.buffer
    util.global.store %5, @_params.weight__timepoint : !hal.fence
    util.initializer.return
  }
  hal.executable private @main_dispatch_0 {
    hal.executable.binary public @cuda_nvptx_fb attributes {data = dense<"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vector<1302xi8>, format = "cuda-nvptx-fb", mime_type = "application/x-flatbuffers"}
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %c12 = arith.constant 12 : index
    %c16 = arith.constant 16 : index
    %c128 = arith.constant 128 : index
    %c-1_i64 = arith.constant -1 : i64
    %c0_i64 = arith.constant 0 : i64
    %c-1_i32 = arith.constant -1 : i32
    %c-1 = arith.constant -1 : index
    %c1 = arith.constant 1 : index
    %c2 = arith.constant 2 : index
    %c3 = arith.constant 3 : index
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !hal.fence
    %_params.weight = util.global.load @_params.weight : !hal.buffer
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %_executable_main_dispatch_0 = util.global.load @_executable_main_dispatch_0 : !hal.executable
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c16) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status = hal.fence.await until([%_params.weight__timepoint]) timeout_millis(%c-1_i32) : i32
    %0 = util.null : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%c12}
    %status_0 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    %1 = arith.select %_device_query_0, %c0, %c-1 : index
    %2 = arith.index_cast %1 : index to i32
    cf.switch %2 : i32, [
      default: ^bb2,
      0: ^bb1
    ]
  ^bb1:  // pred: ^bb0
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%buffer : !hal.buffer)[%c0, %c16], 
      %c1 = (%_params.weight : !hal.buffer)[%c0, %c128], 
      %c2 = (%transient_buffer : !hal.buffer)[%c0, %c12]
    ])
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_main_dispatch_0 : !hal.executable)[0] workgroups([%c3, %c1, %c1])
    cf.br ^bb2
  ^bb2:  // 2 preds: ^bb0, ^bb1
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_1 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status_2 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence_1) commands([%cmd])
    %status_3 = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status_3, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c12] shape([%c3]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After SymbolDCE (symbol-dce) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private @_device_query_0 : i1
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.global private @_executable_main_dispatch_0 : !hal.executable
  util.global private mutable @_params.weight__timepoint : !hal.fence
  util.global private @_params.weight : !hal.buffer
  util.initializer {
    %c0_i64 = arith.constant 0 : i64
    %c128 = arith.constant 128 : index
    %c-1_i64 = arith.constant -1 : i64
    %c0_i32 = arith.constant 0 : i32
    %c0 = arith.constant 0 : index
    %c-1 = arith.constant -1 : index
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(0) layouts([%descriptor_set_layout]) : !hal.pipeline_layout
    %0 = arith.select %value, %c0, %c-1 : index
    %1 = arith.index_cast %0 : index to i32
    util.global.store %value, @_device_query_0 : i1
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    cf.switch %1 : i32, [
      default: ^bb2,
      0: ^bb1
    ]
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device : !hal.device) target(@main_dispatch_0::@cuda_nvptx_fb) layouts([%_pipeline_layout_0]) : !hal.executable
    cf.br ^bb3(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %2 = util.null : !hal.executable
    cf.br ^bb3(%2 : !hal.executable)
  ^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
    %4 = util.null : !hal.fence
    %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #composite_of_128b
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    %did_import, %mapped = hal.allocator.import<%allocator : !hal.allocator> source(%buffer_cst : !util.buffer)[%c0, %c128] affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : i1, !hal.buffer
    util.global.store %3, @_executable_main_dispatch_0 : !hal.executable
    cf.cond_br %did_import, ^bb5(%4, %mapped : !hal.fence, !hal.buffer), ^bb4
  ^bb4:  // pred: ^bb3
    %buffer = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : !hal.buffer{%c128}
    %memory_file = hal.ex.file.from_memory device(%device : !hal.device) affinity(%c-1_i64) access(Read) buffer(%buffer_cst : !util.buffer)[%c0 for %c128] flags(%c0_i32) : !hal.file
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.read<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence) source(%memory_file : !hal.file)[%c0_i64] target(%buffer : !hal.buffer)[%c0] length(%c128) flags(0)
    cf.br ^bb5(%fence, %buffer : !hal.fence, !hal.buffer)
  ^bb5(%5: !hal.fence, %6: !hal.buffer):  // 2 preds: ^bb3, ^bb4
    util.global.store %6, @_params.weight : !hal.buffer
    util.global.store %5, @_params.weight__timepoint : !hal.fence
    util.initializer.return
  }
  hal.executable private @main_dispatch_0 {
    hal.executable.binary public @cuda_nvptx_fb attributes {data = dense<"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vector<1302xi8>, format = "cuda-nvptx-fb", mime_type = "application/x-flatbuffers"}
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %c12 = arith.constant 12 : index
    %c16 = arith.constant 16 : index
    %c128 = arith.constant 128 : index
    %c-1_i64 = arith.constant -1 : i64
    %c0_i64 = arith.constant 0 : i64
    %c-1_i32 = arith.constant -1 : i32
    %c-1 = arith.constant -1 : index
    %c1 = arith.constant 1 : index
    %c2 = arith.constant 2 : index
    %c3 = arith.constant 3 : index
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !hal.fence
    %_params.weight = util.global.load @_params.weight : !hal.buffer
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %_executable_main_dispatch_0 = util.global.load @_executable_main_dispatch_0 : !hal.executable
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c16) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status = hal.fence.await until([%_params.weight__timepoint]) timeout_millis(%c-1_i32) : i32
    %0 = util.null : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%c12}
    %status_0 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    %1 = arith.select %_device_query_0, %c0, %c-1 : index
    %2 = arith.index_cast %1 : index to i32
    cf.switch %2 : i32, [
      default: ^bb2,
      0: ^bb1
    ]
  ^bb1:  // pred: ^bb0
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%buffer : !hal.buffer)[%c0, %c16], 
      %c1 = (%_params.weight : !hal.buffer)[%c0, %c128], 
      %c2 = (%transient_buffer : !hal.buffer)[%c0, %c12]
    ])
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_main_dispatch_0 : !hal.executable)[0] workgroups([%c3, %c1, %c1])
    cf.br ^bb2
  ^bb2:  // 2 preds: ^bb0, ^bb1
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_1 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status_2 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence_1) commands([%cmd])
    %status_3 = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status_3, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c12] shape([%c3]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After SCFForLoopCanonicalization (scf-for-loop-canonicalization) //----- //
util.initializer {
  %c0_i64 = arith.constant 0 : i64
  %c128 = arith.constant 128 : index
  %c-1_i64 = arith.constant -1 : i64
  %c0_i32 = arith.constant 0 : i32
  %c0 = arith.constant 0 : index
  %c-1 = arith.constant -1 : index
  %device = hal.ex.shared_device : !hal.device
  %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
  %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
  %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(0) layouts([%descriptor_set_layout]) : !hal.pipeline_layout
  %0 = arith.select %value, %c0, %c-1 : index
  %1 = arith.index_cast %0 : index to i32
  util.global.store %value, @_device_query_0 : i1
  util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
  cf.switch %1 : i32, [
    default: ^bb2,
    0: ^bb1
  ]
^bb1:  // pred: ^bb0
  %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
  %exe = hal.executable.create device(%device : !hal.device) target(@main_dispatch_0::@cuda_nvptx_fb) layouts([%_pipeline_layout_0]) : !hal.executable
  cf.br ^bb3(%exe : !hal.executable)
^bb2:  // pred: ^bb0
  %2 = util.null : !hal.executable
  cf.br ^bb3(%2 : !hal.executable)
^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
  %4 = util.null : !hal.fence
  %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
  %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
  %did_import, %mapped = hal.allocator.import<%allocator : !hal.allocator> source(%buffer_cst : !util.buffer)[%c0, %c128] affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : i1, !hal.buffer
  util.global.store %3, @_executable_main_dispatch_0 : !hal.executable
  cf.cond_br %did_import, ^bb5(%4, %mapped : !hal.fence, !hal.buffer), ^bb4
^bb4:  // pred: ^bb3
  %buffer = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : !hal.buffer{%c128}
  %memory_file = hal.ex.file.from_memory device(%device : !hal.device) affinity(%c-1_i64) access(Read) buffer(%buffer_cst : !util.buffer)[%c0 for %c128] flags(%c0_i32) : !hal.file
  %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
  hal.device.queue.read<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence) source(%memory_file : !hal.file)[%c0_i64] target(%buffer : !hal.buffer)[%c0] length(%c128) flags(0)
  cf.br ^bb5(%fence, %buffer : !hal.fence, !hal.buffer)
^bb5(%5: !hal.fence, %6: !hal.buffer):  // 2 preds: ^bb3, ^bb4
  util.global.store %6, @_params.weight : !hal.buffer
  util.global.store %5, @_params.weight__timepoint : !hal.fence
  util.initializer.return
}

// -----// IR Dump After SCFForLoopCanonicalization (scf-for-loop-canonicalization) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c0 = arith.constant 0 : index
  %c4 = arith.constant 4 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %c12 = arith.constant 12 : index
  %c16 = arith.constant 16 : index
  %c128 = arith.constant 128 : index
  %c-1_i64 = arith.constant -1 : i64
  %c0_i64 = arith.constant 0 : i64
  %c-1_i32 = arith.constant -1 : i32
  %c-1 = arith.constant -1 : index
  %c1 = arith.constant 1 : index
  %c2 = arith.constant 2 : index
  %c3 = arith.constant 3 : index
  %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !hal.fence
  %_params.weight = util.global.load @_params.weight : !hal.buffer
  %_device_query_0 = util.global.load @_device_query_0 : i1
  %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
  %_executable_main_dispatch_0 = util.global.load @_executable_main_dispatch_0 : !hal.executable
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %device = hal.ex.shared_device : !hal.device
  %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c16) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
  %status = hal.fence.await until([%_params.weight__timepoint]) timeout_millis(%c-1_i32) : i32
  %0 = util.null : !hal.fence
  %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%c12}
  %status_0 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
  %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
  %1 = arith.select %_device_query_0, %c0, %c-1 : index
  %2 = arith.index_cast %1 : index to i32
  cf.switch %2 : i32, [
    default: ^bb2,
    0: ^bb1
  ]
^bb1:  // pred: ^bb0
  hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
    %c0 = (%buffer : !hal.buffer)[%c0, %c16], 
    %c1 = (%_params.weight : !hal.buffer)[%c0, %c128], 
    %c2 = (%transient_buffer : !hal.buffer)[%c0, %c12]
  ])
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_main_dispatch_0 : !hal.executable)[0] workgroups([%c3, %c1, %c1])
  cf.br ^bb2
^bb2:  // 2 preds: ^bb0, ^bb1
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  %fence_1 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
  %status_2 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
  hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence_1) commands([%cmd])
  %status_3 = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
  util.status.check_ok %status_3, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c12] shape([%c3]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
  return %view : !hal.buffer_view
}

// -----// IR Dump After LoopInvariantCodeMotion (loop-invariant-code-motion) //----- //
util.initializer {
  %c0_i64 = arith.constant 0 : i64
  %c128 = arith.constant 128 : index
  %c-1_i64 = arith.constant -1 : i64
  %c0_i32 = arith.constant 0 : i32
  %c0 = arith.constant 0 : index
  %c-1 = arith.constant -1 : index
  %device = hal.ex.shared_device : !hal.device
  %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
  %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
  %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(0) layouts([%descriptor_set_layout]) : !hal.pipeline_layout
  %0 = arith.select %value, %c0, %c-1 : index
  %1 = arith.index_cast %0 : index to i32
  util.global.store %value, @_device_query_0 : i1
  util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
  cf.switch %1 : i32, [
    default: ^bb2,
    0: ^bb1
  ]
^bb1:  // pred: ^bb0
  %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
  %exe = hal.executable.create device(%device : !hal.device) target(@main_dispatch_0::@cuda_nvptx_fb) layouts([%_pipeline_layout_0]) : !hal.executable
  cf.br ^bb3(%exe : !hal.executable)
^bb2:  // pred: ^bb0
  %2 = util.null : !hal.executable
  cf.br ^bb3(%2 : !hal.executable)
^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
  %4 = util.null : !hal.fence
  %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
  %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
  %did_import, %mapped = hal.allocator.import<%allocator : !hal.allocator> source(%buffer_cst : !util.buffer)[%c0, %c128] affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : i1, !hal.buffer
  util.global.store %3, @_executable_main_dispatch_0 : !hal.executable
  cf.cond_br %did_import, ^bb5(%4, %mapped : !hal.fence, !hal.buffer), ^bb4
^bb4:  // pred: ^bb3
  %buffer = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : !hal.buffer{%c128}
  %memory_file = hal.ex.file.from_memory device(%device : !hal.device) affinity(%c-1_i64) access(Read) buffer(%buffer_cst : !util.buffer)[%c0 for %c128] flags(%c0_i32) : !hal.file
  %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
  hal.device.queue.read<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence) source(%memory_file : !hal.file)[%c0_i64] target(%buffer : !hal.buffer)[%c0] length(%c128) flags(0)
  cf.br ^bb5(%fence, %buffer : !hal.fence, !hal.buffer)
^bb5(%5: !hal.fence, %6: !hal.buffer):  // 2 preds: ^bb3, ^bb4
  util.global.store %6, @_params.weight : !hal.buffer
  util.global.store %5, @_params.weight__timepoint : !hal.fence
  util.initializer.return
}

// -----// IR Dump After LoopCoalescing (affine-loop-coalescing) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c0 = arith.constant 0 : index
  %c4 = arith.constant 4 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %c12 = arith.constant 12 : index
  %c16 = arith.constant 16 : index
  %c128 = arith.constant 128 : index
  %c-1_i64 = arith.constant -1 : i64
  %c0_i64 = arith.constant 0 : i64
  %c-1_i32 = arith.constant -1 : i32
  %c-1 = arith.constant -1 : index
  %c1 = arith.constant 1 : index
  %c2 = arith.constant 2 : index
  %c3 = arith.constant 3 : index
  %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !hal.fence
  %_params.weight = util.global.load @_params.weight : !hal.buffer
  %_device_query_0 = util.global.load @_device_query_0 : i1
  %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
  %_executable_main_dispatch_0 = util.global.load @_executable_main_dispatch_0 : !hal.executable
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %device = hal.ex.shared_device : !hal.device
  %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c16) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
  %status = hal.fence.await until([%_params.weight__timepoint]) timeout_millis(%c-1_i32) : i32
  %0 = util.null : !hal.fence
  %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%c12}
  %status_0 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
  %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
  %1 = arith.select %_device_query_0, %c0, %c-1 : index
  %2 = arith.index_cast %1 : index to i32
  cf.switch %2 : i32, [
    default: ^bb2,
    0: ^bb1
  ]
^bb1:  // pred: ^bb0
  hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
    %c0 = (%buffer : !hal.buffer)[%c0, %c16], 
    %c1 = (%_params.weight : !hal.buffer)[%c0, %c128], 
    %c2 = (%transient_buffer : !hal.buffer)[%c0, %c12]
  ])
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_main_dispatch_0 : !hal.executable)[0] workgroups([%c3, %c1, %c1])
  cf.br ^bb2
^bb2:  // 2 preds: ^bb0, ^bb1
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  %fence_1 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
  %status_2 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
  hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence_1) commands([%cmd])
  %status_3 = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
  util.status.check_ok %status_3, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c12] shape([%c3]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
  return %view : !hal.buffer_view
}

// -----// IR Dump After SCFToControlFlow (convert-scf-to-cf) //----- //
util.initializer {
  %c0_i64 = arith.constant 0 : i64
  %c128 = arith.constant 128 : index
  %c-1_i64 = arith.constant -1 : i64
  %c0_i32 = arith.constant 0 : i32
  %c0 = arith.constant 0 : index
  %c-1 = arith.constant -1 : index
  %device = hal.ex.shared_device : !hal.device
  %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
  %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
  %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(0) layouts([%descriptor_set_layout]) : !hal.pipeline_layout
  %0 = arith.select %value, %c0, %c-1 : index
  %1 = arith.index_cast %0 : index to i32
  util.global.store %value, @_device_query_0 : i1
  util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
  cf.switch %1 : i32, [
    default: ^bb2,
    0: ^bb1
  ]
^bb1:  // pred: ^bb0
  %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
  %exe = hal.executable.create device(%device : !hal.device) target(@main_dispatch_0::@cuda_nvptx_fb) layouts([%_pipeline_layout_0]) : !hal.executable
  cf.br ^bb3(%exe : !hal.executable)
^bb2:  // pred: ^bb0
  %2 = util.null : !hal.executable
  cf.br ^bb3(%2 : !hal.executable)
^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
  %4 = util.null : !hal.fence
  %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
  %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
  %did_import, %mapped = hal.allocator.import<%allocator : !hal.allocator> source(%buffer_cst : !util.buffer)[%c0, %c128] affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : i1, !hal.buffer
  util.global.store %3, @_executable_main_dispatch_0 : !hal.executable
  cf.cond_br %did_import, ^bb5(%4, %mapped : !hal.fence, !hal.buffer), ^bb4
^bb4:  // pred: ^bb3
  %buffer = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : !hal.buffer{%c128}
  %memory_file = hal.ex.file.from_memory device(%device : !hal.device) affinity(%c-1_i64) access(Read) buffer(%buffer_cst : !util.buffer)[%c0 for %c128] flags(%c0_i32) : !hal.file
  %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
  hal.device.queue.read<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence) source(%memory_file : !hal.file)[%c0_i64] target(%buffer : !hal.buffer)[%c0] length(%c128) flags(0)
  cf.br ^bb5(%fence, %buffer : !hal.fence, !hal.buffer)
^bb5(%5: !hal.fence, %6: !hal.buffer):  // 2 preds: ^bb3, ^bb4
  util.global.store %6, @_params.weight : !hal.buffer
  util.global.store %5, @_params.weight__timepoint : !hal.fence
  util.initializer.return
}

// -----// IR Dump After LoopInvariantCodeMotion (loop-invariant-code-motion) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c0 = arith.constant 0 : index
  %c4 = arith.constant 4 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %c12 = arith.constant 12 : index
  %c16 = arith.constant 16 : index
  %c128 = arith.constant 128 : index
  %c-1_i64 = arith.constant -1 : i64
  %c0_i64 = arith.constant 0 : i64
  %c-1_i32 = arith.constant -1 : i32
  %c-1 = arith.constant -1 : index
  %c1 = arith.constant 1 : index
  %c2 = arith.constant 2 : index
  %c3 = arith.constant 3 : index
  %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !hal.fence
  %_params.weight = util.global.load @_params.weight : !hal.buffer
  %_device_query_0 = util.global.load @_device_query_0 : i1
  %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
  %_executable_main_dispatch_0 = util.global.load @_executable_main_dispatch_0 : !hal.executable
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %device = hal.ex.shared_device : !hal.device
  %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c16) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
  %status = hal.fence.await until([%_params.weight__timepoint]) timeout_millis(%c-1_i32) : i32
  %0 = util.null : !hal.fence
  %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%c12}
  %status_0 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
  %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
  %1 = arith.select %_device_query_0, %c0, %c-1 : index
  %2 = arith.index_cast %1 : index to i32
  cf.switch %2 : i32, [
    default: ^bb2,
    0: ^bb1
  ]
^bb1:  // pred: ^bb0
  hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
    %c0 = (%buffer : !hal.buffer)[%c0, %c16], 
    %c1 = (%_params.weight : !hal.buffer)[%c0, %c128], 
    %c2 = (%transient_buffer : !hal.buffer)[%c0, %c12]
  ])
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_main_dispatch_0 : !hal.executable)[0] workgroups([%c3, %c1, %c1])
  cf.br ^bb2
^bb2:  // 2 preds: ^bb0, ^bb1
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  %fence_1 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
  %status_2 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
  hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence_1) commands([%cmd])
  %status_3 = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
  util.status.check_ok %status_3, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c12] shape([%c3]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
  return %view : !hal.buffer_view
}

// -----// IR Dump After ConvertAffineToStandard (lower-affine) //----- //
util.initializer {
  %c0_i64 = arith.constant 0 : i64
  %c128 = arith.constant 128 : index
  %c-1_i64 = arith.constant -1 : i64
  %c0_i32 = arith.constant 0 : i32
  %c0 = arith.constant 0 : index
  %c-1 = arith.constant -1 : index
  %device = hal.ex.shared_device : !hal.device
  %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
  %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
  %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(0) layouts([%descriptor_set_layout]) : !hal.pipeline_layout
  %0 = arith.select %value, %c0, %c-1 : index
  %1 = arith.index_cast %0 : index to i32
  util.global.store %value, @_device_query_0 : i1
  util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
  cf.switch %1 : i32, [
    default: ^bb2,
    0: ^bb1
  ]
^bb1:  // pred: ^bb0
  %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
  %exe = hal.executable.create device(%device : !hal.device) target(@main_dispatch_0::@cuda_nvptx_fb) layouts([%_pipeline_layout_0]) : !hal.executable
  cf.br ^bb3(%exe : !hal.executable)
^bb2:  // pred: ^bb0
  %2 = util.null : !hal.executable
  cf.br ^bb3(%2 : !hal.executable)
^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
  %4 = util.null : !hal.fence
  %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
  %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
  %did_import, %mapped = hal.allocator.import<%allocator : !hal.allocator> source(%buffer_cst : !util.buffer)[%c0, %c128] affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : i1, !hal.buffer
  util.global.store %3, @_executable_main_dispatch_0 : !hal.executable
  cf.cond_br %did_import, ^bb5(%4, %mapped : !hal.fence, !hal.buffer), ^bb4
^bb4:  // pred: ^bb3
  %buffer = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : !hal.buffer{%c128}
  %memory_file = hal.ex.file.from_memory device(%device : !hal.device) affinity(%c-1_i64) access(Read) buffer(%buffer_cst : !util.buffer)[%c0 for %c128] flags(%c0_i32) : !hal.file
  %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
  hal.device.queue.read<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence) source(%memory_file : !hal.file)[%c0_i64] target(%buffer : !hal.buffer)[%c0] length(%c128) flags(0)
  cf.br ^bb5(%fence, %buffer : !hal.fence, !hal.buffer)
^bb5(%5: !hal.fence, %6: !hal.buffer):  // 2 preds: ^bb3, ^bb4
  util.global.store %6, @_params.weight : !hal.buffer
  util.global.store %5, @_params.weight__timepoint : !hal.fence
  util.initializer.return
}

// -----// IR Dump After SCFToControlFlow (convert-scf-to-cf) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c0 = arith.constant 0 : index
  %c4 = arith.constant 4 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %c12 = arith.constant 12 : index
  %c16 = arith.constant 16 : index
  %c128 = arith.constant 128 : index
  %c-1_i64 = arith.constant -1 : i64
  %c0_i64 = arith.constant 0 : i64
  %c-1_i32 = arith.constant -1 : i32
  %c-1 = arith.constant -1 : index
  %c1 = arith.constant 1 : index
  %c2 = arith.constant 2 : index
  %c3 = arith.constant 3 : index
  %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !hal.fence
  %_params.weight = util.global.load @_params.weight : !hal.buffer
  %_device_query_0 = util.global.load @_device_query_0 : i1
  %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
  %_executable_main_dispatch_0 = util.global.load @_executable_main_dispatch_0 : !hal.executable
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %device = hal.ex.shared_device : !hal.device
  %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c16) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
  %status = hal.fence.await until([%_params.weight__timepoint]) timeout_millis(%c-1_i32) : i32
  %0 = util.null : !hal.fence
  %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%c12}
  %status_0 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
  %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
  %1 = arith.select %_device_query_0, %c0, %c-1 : index
  %2 = arith.index_cast %1 : index to i32
  cf.switch %2 : i32, [
    default: ^bb2,
    0: ^bb1
  ]
^bb1:  // pred: ^bb0
  hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
    %c0 = (%buffer : !hal.buffer)[%c0, %c16], 
    %c1 = (%_params.weight : !hal.buffer)[%c0, %c128], 
    %c2 = (%transient_buffer : !hal.buffer)[%c0, %c12]
  ])
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_main_dispatch_0 : !hal.executable)[0] workgroups([%c3, %c1, %c1])
  cf.br ^bb2
^bb2:  // 2 preds: ^bb0, ^bb1
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  %fence_1 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
  %status_2 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
  hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence_1) commands([%cmd])
  %status_3 = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
  util.status.check_ok %status_3, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c12] shape([%c3]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
  return %view : !hal.buffer_view
}

// -----// IR Dump After ArithUnsignedWhenEquivalent (arith-unsigned-when-equivalent) //----- //
util.initializer {
  %c0_i64 = arith.constant 0 : i64
  %c128 = arith.constant 128 : index
  %c-1_i64 = arith.constant -1 : i64
  %c0_i32 = arith.constant 0 : i32
  %c0 = arith.constant 0 : index
  %c-1 = arith.constant -1 : index
  %device = hal.ex.shared_device : !hal.device
  %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
  %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
  %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(0) layouts([%descriptor_set_layout]) : !hal.pipeline_layout
  %0 = arith.select %value, %c0, %c-1 : index
  %1 = arith.index_cast %0 : index to i32
  util.global.store %value, @_device_query_0 : i1
  util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
  cf.switch %1 : i32, [
    default: ^bb2,
    0: ^bb1
  ]
^bb1:  // pred: ^bb0
  %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
  %exe = hal.executable.create device(%device : !hal.device) target(@main_dispatch_0::@cuda_nvptx_fb) layouts([%_pipeline_layout_0]) : !hal.executable
  cf.br ^bb3(%exe : !hal.executable)
^bb2:  // pred: ^bb0
  %2 = util.null : !hal.executable
  cf.br ^bb3(%2 : !hal.executable)
^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
  %4 = util.null : !hal.fence
  %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
  %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
  %did_import, %mapped = hal.allocator.import<%allocator : !hal.allocator> source(%buffer_cst : !util.buffer)[%c0, %c128] affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : i1, !hal.buffer
  util.global.store %3, @_executable_main_dispatch_0 : !hal.executable
  cf.cond_br %did_import, ^bb5(%4, %mapped : !hal.fence, !hal.buffer), ^bb4
^bb4:  // pred: ^bb3
  %buffer = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : !hal.buffer{%c128}
  %memory_file = hal.ex.file.from_memory device(%device : !hal.device) affinity(%c-1_i64) access(Read) buffer(%buffer_cst : !util.buffer)[%c0 for %c128] flags(%c0_i32) : !hal.file
  %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
  hal.device.queue.read<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence) source(%memory_file : !hal.file)[%c0_i64] target(%buffer : !hal.buffer)[%c0] length(%c128) flags(0)
  cf.br ^bb5(%fence, %buffer : !hal.fence, !hal.buffer)
^bb5(%5: !hal.fence, %6: !hal.buffer):  // 2 preds: ^bb3, ^bb4
  util.global.store %6, @_params.weight : !hal.buffer
  util.global.store %5, @_params.weight__timepoint : !hal.fence
  util.initializer.return
}

// -----// IR Dump After ConvertAffineToStandard (lower-affine) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c0 = arith.constant 0 : index
  %c4 = arith.constant 4 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %c12 = arith.constant 12 : index
  %c16 = arith.constant 16 : index
  %c128 = arith.constant 128 : index
  %c-1_i64 = arith.constant -1 : i64
  %c0_i64 = arith.constant 0 : i64
  %c-1_i32 = arith.constant -1 : i32
  %c-1 = arith.constant -1 : index
  %c1 = arith.constant 1 : index
  %c2 = arith.constant 2 : index
  %c3 = arith.constant 3 : index
  %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !hal.fence
  %_params.weight = util.global.load @_params.weight : !hal.buffer
  %_device_query_0 = util.global.load @_device_query_0 : i1
  %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
  %_executable_main_dispatch_0 = util.global.load @_executable_main_dispatch_0 : !hal.executable
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %device = hal.ex.shared_device : !hal.device
  %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c16) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
  %status = hal.fence.await until([%_params.weight__timepoint]) timeout_millis(%c-1_i32) : i32
  %0 = util.null : !hal.fence
  %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%c12}
  %status_0 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
  %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
  %1 = arith.select %_device_query_0, %c0, %c-1 : index
  %2 = arith.index_cast %1 : index to i32
  cf.switch %2 : i32, [
    default: ^bb2,
    0: ^bb1
  ]
^bb1:  // pred: ^bb0
  hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
    %c0 = (%buffer : !hal.buffer)[%c0, %c16], 
    %c1 = (%_params.weight : !hal.buffer)[%c0, %c128], 
    %c2 = (%transient_buffer : !hal.buffer)[%c0, %c12]
  ])
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_main_dispatch_0 : !hal.executable)[0] workgroups([%c3, %c1, %c1])
  cf.br ^bb2
^bb2:  // 2 preds: ^bb0, ^bb1
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  %fence_1 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
  %status_2 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
  hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence_1) commands([%cmd])
  %status_3 = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
  util.status.check_ok %status_3, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c12] shape([%c3]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
  return %view : !hal.buffer_view
}

// -----// IR Dump After ArithUnsignedWhenEquivalent (arith-unsigned-when-equivalent) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c0 = arith.constant 0 : index
  %c4 = arith.constant 4 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %c12 = arith.constant 12 : index
  %c16 = arith.constant 16 : index
  %c128 = arith.constant 128 : index
  %c-1_i64 = arith.constant -1 : i64
  %c0_i64 = arith.constant 0 : i64
  %c-1_i32 = arith.constant -1 : i32
  %c-1 = arith.constant -1 : index
  %c1 = arith.constant 1 : index
  %c2 = arith.constant 2 : index
  %c3 = arith.constant 3 : index
  %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !hal.fence
  %_params.weight = util.global.load @_params.weight : !hal.buffer
  %_device_query_0 = util.global.load @_device_query_0 : i1
  %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
  %_executable_main_dispatch_0 = util.global.load @_executable_main_dispatch_0 : !hal.executable
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %device = hal.ex.shared_device : !hal.device
  %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c16) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
  %status = hal.fence.await until([%_params.weight__timepoint]) timeout_millis(%c-1_i32) : i32
  %0 = util.null : !hal.fence
  %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%c12}
  %status_0 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
  %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
  %1 = arith.select %_device_query_0, %c0, %c-1 : index
  %2 = arith.index_cast %1 : index to i32
  cf.switch %2 : i32, [
    default: ^bb2,
    0: ^bb1
  ]
^bb1:  // pred: ^bb0
  hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
    %c0 = (%buffer : !hal.buffer)[%c0, %c16], 
    %c1 = (%_params.weight : !hal.buffer)[%c0, %c128], 
    %c2 = (%transient_buffer : !hal.buffer)[%c0, %c12]
  ])
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_main_dispatch_0 : !hal.executable)[0] workgroups([%c3, %c1, %c1])
  cf.br ^bb2
^bb2:  // 2 preds: ^bb0, ^bb1
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  %fence_1 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
  %status_2 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
  hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence_1) commands([%cmd])
  %status_3 = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
  util.status.check_ok %status_3, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c12] shape([%c3]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
  return %view : !hal.buffer_view
}

// -----// IR Dump After PropagateSubranges (iree-util-propagate-subranges) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private @_device_query_0 : i1
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.global private @_executable_main_dispatch_0 : !hal.executable
  util.global private mutable @_params.weight__timepoint : !hal.fence
  util.global private @_params.weight : !hal.buffer
  util.initializer {
    %c0_i64 = arith.constant 0 : i64
    %c128 = arith.constant 128 : index
    %c-1_i64 = arith.constant -1 : i64
    %c0_i32 = arith.constant 0 : i32
    %c0 = arith.constant 0 : index
    %c-1 = arith.constant -1 : index
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(0) layouts([%descriptor_set_layout]) : !hal.pipeline_layout
    %0 = arith.select %value, %c0, %c-1 : index
    %1 = arith.index_cast %0 : index to i32
    util.global.store %value, @_device_query_0 : i1
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    cf.switch %1 : i32, [
      default: ^bb2,
      0: ^bb1
    ]
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device : !hal.device) target(@main_dispatch_0::@cuda_nvptx_fb) layouts([%_pipeline_layout_0]) : !hal.executable
    cf.br ^bb3(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %2 = util.null : !hal.executable
    cf.br ^bb3(%2 : !hal.executable)
  ^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
    %4 = util.null : !hal.fence
    %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #composite_of_128b
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    %did_import, %mapped = hal.allocator.import<%allocator : !hal.allocator> source(%buffer_cst : !util.buffer)[%c0, %c128] affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : i1, !hal.buffer
    util.global.store %3, @_executable_main_dispatch_0 : !hal.executable
    cf.cond_br %did_import, ^bb5(%4, %mapped : !hal.fence, !hal.buffer), ^bb4
  ^bb4:  // pred: ^bb3
    %buffer = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : !hal.buffer{%c128}
    %memory_file = hal.ex.file.from_memory device(%device : !hal.device) affinity(%c-1_i64) access(Read) buffer(%buffer_cst : !util.buffer)[%c0 for %c128] flags(%c0_i32) : !hal.file
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.read<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence) source(%memory_file : !hal.file)[%c0_i64] target(%buffer : !hal.buffer)[%c0] length(%c128) flags(0)
    cf.br ^bb5(%fence, %buffer : !hal.fence, !hal.buffer)
  ^bb5(%5: !hal.fence, %6: !hal.buffer):  // 2 preds: ^bb3, ^bb4
    util.global.store %6, @_params.weight : !hal.buffer
    util.global.store %5, @_params.weight__timepoint : !hal.fence
    util.initializer.return
  }
  hal.executable private @main_dispatch_0 {
    hal.executable.binary public @cuda_nvptx_fb attributes {data = dense<"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vector<1302xi8>, format = "cuda-nvptx-fb", mime_type = "application/x-flatbuffers"}
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %c12 = arith.constant 12 : index
    %c16 = arith.constant 16 : index
    %c128 = arith.constant 128 : index
    %c-1_i64 = arith.constant -1 : i64
    %c0_i64 = arith.constant 0 : i64
    %c-1_i32 = arith.constant -1 : i32
    %c-1 = arith.constant -1 : index
    %c1 = arith.constant 1 : index
    %c2 = arith.constant 2 : index
    %c3 = arith.constant 3 : index
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !hal.fence
    %_params.weight = util.global.load @_params.weight : !hal.buffer
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %_executable_main_dispatch_0 = util.global.load @_executable_main_dispatch_0 : !hal.executable
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c16) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status = hal.fence.await until([%_params.weight__timepoint]) timeout_millis(%c-1_i32) : i32
    %0 = util.null : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%c12}
    %status_0 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    %1 = arith.select %_device_query_0, %c0, %c-1 : index
    %2 = arith.index_cast %1 : index to i32
    cf.switch %2 : i32, [
      default: ^bb2,
      0: ^bb1
    ]
  ^bb1:  // pred: ^bb0
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%buffer : !hal.buffer)[%c0, %c16], 
      %c1 = (%_params.weight : !hal.buffer)[%c0, %c128], 
      %c2 = (%transient_buffer : !hal.buffer)[%c0, %c12]
    ])
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_main_dispatch_0 : !hal.executable)[0] workgroups([%c3, %c1, %c1])
    cf.br ^bb2
  ^bb2:  // 2 preds: ^bb0, ^bb1
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_1 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status_2 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence_1) commands([%cmd])
    %status_3 = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status_3, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c12] shape([%c3]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private @_device_query_0 : i1
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.global private @_executable_main_dispatch_0 : !hal.executable
  util.global private mutable @_params.weight__timepoint : !hal.fence
  util.global private @_params.weight : !hal.buffer
  util.initializer {
    %c0_i64 = arith.constant 0 : i64
    %c128 = arith.constant 128 : index
    %c-1_i64 = arith.constant -1 : i64
    %c0_i32 = arith.constant 0 : i32
    %c0 = arith.constant 0 : index
    %c-1 = arith.constant -1 : index
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(0) layouts([%descriptor_set_layout]) : !hal.pipeline_layout
    %0 = arith.select %value, %c0, %c-1 : index
    %1 = arith.index_cast %0 : index to i32
    util.global.store %value, @_device_query_0 : i1
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    cf.switch %1 : i32, [
      default: ^bb2,
      0: ^bb1
    ]
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device : !hal.device) target(@main_dispatch_0::@cuda_nvptx_fb) layouts([%_pipeline_layout_0]) : !hal.executable
    cf.br ^bb3(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %2 = util.null : !hal.executable
    cf.br ^bb3(%2 : !hal.executable)
  ^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
    %4 = util.null : !hal.fence
    %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #composite_of_128b
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    %did_import, %mapped = hal.allocator.import<%allocator : !hal.allocator> source(%buffer_cst : !util.buffer)[%c0, %c128] affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : i1, !hal.buffer
    util.global.store %3, @_executable_main_dispatch_0 : !hal.executable
    cf.cond_br %did_import, ^bb5(%4, %mapped : !hal.fence, !hal.buffer), ^bb4
  ^bb4:  // pred: ^bb3
    %buffer = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : !hal.buffer{%c128}
    %memory_file = hal.ex.file.from_memory device(%device : !hal.device) affinity(%c-1_i64) access(Read) buffer(%buffer_cst : !util.buffer)[%c0 for %c128] flags(%c0_i32) : !hal.file
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.read<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence) source(%memory_file : !hal.file)[%c0_i64] target(%buffer : !hal.buffer)[%c0] length(%c128) flags(0)
    cf.br ^bb5(%fence, %buffer : !hal.fence, !hal.buffer)
  ^bb5(%5: !hal.fence, %6: !hal.buffer):  // 2 preds: ^bb3, ^bb4
    util.global.store %6, @_params.weight : !hal.buffer
    util.global.store %5, @_params.weight__timepoint : !hal.fence
    util.initializer.return
  }
  hal.executable private @main_dispatch_0 {
    hal.executable.binary public @cuda_nvptx_fb attributes {data = dense<"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vector<1302xi8>, format = "cuda-nvptx-fb", mime_type = "application/x-flatbuffers"}
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %c12 = arith.constant 12 : index
    %c16 = arith.constant 16 : index
    %c128 = arith.constant 128 : index
    %c-1_i64 = arith.constant -1 : i64
    %c0_i64 = arith.constant 0 : i64
    %c-1_i32 = arith.constant -1 : i32
    %c-1 = arith.constant -1 : index
    %c1 = arith.constant 1 : index
    %c2 = arith.constant 2 : index
    %c3 = arith.constant 3 : index
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !hal.fence
    %_params.weight = util.global.load @_params.weight : !hal.buffer
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %_executable_main_dispatch_0 = util.global.load @_executable_main_dispatch_0 : !hal.executable
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c16) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status = hal.fence.await until([%_params.weight__timepoint]) timeout_millis(%c-1_i32) : i32
    %0 = util.null : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%c12}
    %status_0 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    %1 = arith.select %_device_query_0, %c0, %c-1 : index
    %2 = arith.index_cast %1 : index to i32
    cf.switch %2 : i32, [
      default: ^bb2,
      0: ^bb1
    ]
  ^bb1:  // pred: ^bb0
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%buffer : !hal.buffer)[%c0, %c16], 
      %c1 = (%_params.weight : !hal.buffer)[%c0, %c128], 
      %c2 = (%transient_buffer : !hal.buffer)[%c0, %c12]
    ])
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_main_dispatch_0 : !hal.executable)[0] workgroups([%c3, %c1, %c1])
    cf.br ^bb2
  ^bb2:  // 2 preds: ^bb0, ^bb1
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_1 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status_2 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence_1) commands([%cmd])
    %status_3 = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status_3, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c12] shape([%c3]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After CSE (cse) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private @_device_query_0 : i1
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.global private @_executable_main_dispatch_0 : !hal.executable
  util.global private mutable @_params.weight__timepoint : !hal.fence
  util.global private @_params.weight : !hal.buffer
  util.initializer {
    %c0_i64 = arith.constant 0 : i64
    %c128 = arith.constant 128 : index
    %c-1_i64 = arith.constant -1 : i64
    %c0_i32 = arith.constant 0 : i32
    %c0 = arith.constant 0 : index
    %c-1 = arith.constant -1 : index
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(0) layouts([%descriptor_set_layout]) : !hal.pipeline_layout
    %0 = arith.select %value, %c0, %c-1 : index
    %1 = arith.index_cast %0 : index to i32
    util.global.store %value, @_device_query_0 : i1
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    cf.switch %1 : i32, [
      default: ^bb2,
      0: ^bb1
    ]
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device : !hal.device) target(@main_dispatch_0::@cuda_nvptx_fb) layouts([%_pipeline_layout_0]) : !hal.executable
    cf.br ^bb3(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %2 = util.null : !hal.executable
    cf.br ^bb3(%2 : !hal.executable)
  ^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
    %4 = util.null : !hal.fence
    %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #composite_of_128b
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    %did_import, %mapped = hal.allocator.import<%allocator : !hal.allocator> source(%buffer_cst : !util.buffer)[%c0, %c128] affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : i1, !hal.buffer
    util.global.store %3, @_executable_main_dispatch_0 : !hal.executable
    cf.cond_br %did_import, ^bb5(%4, %mapped : !hal.fence, !hal.buffer), ^bb4
  ^bb4:  // pred: ^bb3
    %buffer = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : !hal.buffer{%c128}
    %memory_file = hal.ex.file.from_memory device(%device : !hal.device) affinity(%c-1_i64) access(Read) buffer(%buffer_cst : !util.buffer)[%c0 for %c128] flags(%c0_i32) : !hal.file
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.read<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence) source(%memory_file : !hal.file)[%c0_i64] target(%buffer : !hal.buffer)[%c0] length(%c128) flags(0)
    cf.br ^bb5(%fence, %buffer : !hal.fence, !hal.buffer)
  ^bb5(%5: !hal.fence, %6: !hal.buffer):  // 2 preds: ^bb3, ^bb4
    util.global.store %6, @_params.weight : !hal.buffer
    util.global.store %5, @_params.weight__timepoint : !hal.fence
    util.initializer.return
  }
  hal.executable private @main_dispatch_0 {
    hal.executable.binary public @cuda_nvptx_fb attributes {data = dense<"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vector<1302xi8>, format = "cuda-nvptx-fb", mime_type = "application/x-flatbuffers"}
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %c12 = arith.constant 12 : index
    %c16 = arith.constant 16 : index
    %c128 = arith.constant 128 : index
    %c-1_i64 = arith.constant -1 : i64
    %c0_i64 = arith.constant 0 : i64
    %c-1_i32 = arith.constant -1 : i32
    %c-1 = arith.constant -1 : index
    %c1 = arith.constant 1 : index
    %c2 = arith.constant 2 : index
    %c3 = arith.constant 3 : index
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !hal.fence
    %_params.weight = util.global.load @_params.weight : !hal.buffer
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %_executable_main_dispatch_0 = util.global.load @_executable_main_dispatch_0 : !hal.executable
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c16) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status = hal.fence.await until([%_params.weight__timepoint]) timeout_millis(%c-1_i32) : i32
    %0 = util.null : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%c12}
    %status_0 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    %1 = arith.select %_device_query_0, %c0, %c-1 : index
    %2 = arith.index_cast %1 : index to i32
    cf.switch %2 : i32, [
      default: ^bb2,
      0: ^bb1
    ]
  ^bb1:  // pred: ^bb0
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%buffer : !hal.buffer)[%c0, %c16], 
      %c1 = (%_params.weight : !hal.buffer)[%c0, %c128], 
      %c2 = (%transient_buffer : !hal.buffer)[%c0, %c12]
    ])
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_main_dispatch_0 : !hal.executable)[0] workgroups([%c3, %c1, %c1])
    cf.br ^bb2
  ^bb2:  // 2 preds: ^bb0, ^bb1
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_1 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status_2 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence_1) commands([%cmd])
    %status_3 = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status_3, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c12] shape([%c3]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.initializer {
  %c0_i64 = arith.constant 0 : i64
  %c128 = arith.constant 128 : index
  %c-1_i64 = arith.constant -1 : i64
  %c0_i32 = arith.constant 0 : i32
  %c0 = arith.constant 0 : index
  %c-1 = arith.constant -1 : index
  %device = hal.ex.shared_device : !hal.device
  %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
  %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
  %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(0) layouts([%descriptor_set_layout]) : !hal.pipeline_layout
  %0 = arith.select %value, %c0, %c-1 : index
  %1 = arith.index_cast %0 : index to i32
  util.global.store %value, @_device_query_0 : i1
  util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
  cf.switch %1 : i32, [
    default: ^bb2,
    0: ^bb1
  ]
^bb1:  // pred: ^bb0
  %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
  %exe = hal.executable.create device(%device : !hal.device) target(@main_dispatch_0::@cuda_nvptx_fb) layouts([%_pipeline_layout_0]) : !hal.executable
  cf.br ^bb3(%exe : !hal.executable)
^bb2:  // pred: ^bb0
  %2 = util.null : !hal.executable
  cf.br ^bb3(%2 : !hal.executable)
^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
  %4 = util.null : !hal.fence
  %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
  %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
  %did_import, %mapped = hal.allocator.import<%allocator : !hal.allocator> source(%buffer_cst : !util.buffer)[%c0, %c128] affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : i1, !hal.buffer
  util.global.store %3, @_executable_main_dispatch_0 : !hal.executable
  cf.cond_br %did_import, ^bb5(%4, %mapped : !hal.fence, !hal.buffer), ^bb4
^bb4:  // pred: ^bb3
  %buffer = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : !hal.buffer{%c128}
  %memory_file = hal.ex.file.from_memory device(%device : !hal.device) affinity(%c-1_i64) access(Read) buffer(%buffer_cst : !util.buffer)[%c0 for %c128] flags(%c0_i32) : !hal.file
  %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
  hal.device.queue.read<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence) source(%memory_file : !hal.file)[%c0_i64] target(%buffer : !hal.buffer)[%c0] length(%c128) flags(0)
  cf.br ^bb5(%fence, %buffer : !hal.fence, !hal.buffer)
^bb5(%5: !hal.fence, %6: !hal.buffer):  // 2 preds: ^bb3, ^bb4
  util.global.store %6, @_params.weight : !hal.buffer
  util.global.store %5, @_params.weight__timepoint : !hal.fence
  util.initializer.return
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !hal.fence
  %_params.weight = util.global.load @_params.weight : !hal.buffer
  %_device_query_0 = util.global.load @_device_query_0 : i1
  %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
  %_executable_main_dispatch_0 = util.global.load @_executable_main_dispatch_0 : !hal.executable
  %c0 = arith.constant 0 : index
  %c4 = arith.constant 4 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %c12 = arith.constant 12 : index
  %c16 = arith.constant 16 : index
  %c128 = arith.constant 128 : index
  %c-1_i64 = arith.constant -1 : i64
  %c0_i64 = arith.constant 0 : i64
  %c-1_i32 = arith.constant -1 : i32
  %c-1 = arith.constant -1 : index
  %c1 = arith.constant 1 : index
  %c2 = arith.constant 2 : index
  %c3 = arith.constant 3 : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %device = hal.ex.shared_device : !hal.device
  %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c16) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
  %status = hal.fence.await until([%_params.weight__timepoint]) timeout_millis(%c-1_i32) : i32
  %0 = util.null : !hal.fence
  %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%c12}
  %status_0 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
  %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
  %1 = arith.select %_device_query_0, %c0, %c-1 : index
  %2 = arith.index_cast %1 : index to i32
  cf.switch %2 : i32, [
    default: ^bb2,
    0: ^bb1
  ]
^bb1:  // pred: ^bb0
  hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
    %c0 = (%buffer : !hal.buffer)[%c0, %c16], 
    %c1 = (%_params.weight : !hal.buffer)[%c0, %c128], 
    %c2 = (%transient_buffer : !hal.buffer)[%c0, %c12]
  ])
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_main_dispatch_0 : !hal.executable)[0] workgroups([%c3, %c1, %c1])
  cf.br ^bb2
^bb2:  // 2 preds: ^bb0, ^bb1
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  %fence_1 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
  %status_2 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
  hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence_1) commands([%cmd])
  %status_3 = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
  util.status.check_ok %status_3, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c12] shape([%c3]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
  return %view : !hal.buffer_view
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private @_device_query_0 : i1
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.global private @_executable_main_dispatch_0 : !hal.executable
  util.global private mutable @_params.weight__timepoint : !hal.fence
  util.global private @_params.weight : !hal.buffer
  util.initializer {
    %c0_i64 = arith.constant 0 : i64
    %c128 = arith.constant 128 : index
    %c-1_i64 = arith.constant -1 : i64
    %c0_i32 = arith.constant 0 : i32
    %c0 = arith.constant 0 : index
    %c-1 = arith.constant -1 : index
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(0) layouts([%descriptor_set_layout]) : !hal.pipeline_layout
    %0 = arith.select %value, %c0, %c-1 : index
    %1 = arith.index_cast %0 : index to i32
    util.global.store %value, @_device_query_0 : i1
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    cf.switch %1 : i32, [
      default: ^bb2,
      0: ^bb1
    ]
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device : !hal.device) target(@main_dispatch_0::@cuda_nvptx_fb) layouts([%_pipeline_layout_0]) : !hal.executable
    cf.br ^bb3(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %2 = util.null : !hal.executable
    cf.br ^bb3(%2 : !hal.executable)
  ^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
    %4 = util.null : !hal.fence
    %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #composite_of_128b
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    %did_import, %mapped = hal.allocator.import<%allocator : !hal.allocator> source(%buffer_cst : !util.buffer)[%c0, %c128] affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : i1, !hal.buffer
    util.global.store %3, @_executable_main_dispatch_0 : !hal.executable
    cf.cond_br %did_import, ^bb5(%4, %mapped : !hal.fence, !hal.buffer), ^bb4
  ^bb4:  // pred: ^bb3
    %buffer = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : !hal.buffer{%c128}
    %memory_file = hal.ex.file.from_memory device(%device : !hal.device) affinity(%c-1_i64) access(Read) buffer(%buffer_cst : !util.buffer)[%c0 for %c128] flags(%c0_i32) : !hal.file
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.read<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence) source(%memory_file : !hal.file)[%c0_i64] target(%buffer : !hal.buffer)[%c0] length(%c128) flags(0)
    cf.br ^bb5(%fence, %buffer : !hal.fence, !hal.buffer)
  ^bb5(%5: !hal.fence, %6: !hal.buffer):  // 2 preds: ^bb3, ^bb4
    util.global.store %6, @_params.weight : !hal.buffer
    util.global.store %5, @_params.weight__timepoint : !hal.fence
    util.initializer.return
  }
  hal.executable private @main_dispatch_0 {
    hal.executable.binary public @cuda_nvptx_fb attributes {data = dense<"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vector<1302xi8>, format = "cuda-nvptx-fb", mime_type = "application/x-flatbuffers"}
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c3 = arith.constant 3 : index
    %c2 = arith.constant 2 : index
    %c1 = arith.constant 1 : index
    %c-1 = arith.constant -1 : index
    %c-1_i32 = arith.constant -1 : i32
    %c0_i64 = arith.constant 0 : i64
    %c-1_i64 = arith.constant -1 : i64
    %c128 = arith.constant 128 : index
    %c16 = arith.constant 16 : index
    %c12 = arith.constant 12 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !hal.fence
    %_params.weight = util.global.load @_params.weight : !hal.buffer
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %_executable_main_dispatch_0 = util.global.load @_executable_main_dispatch_0 : !hal.executable
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c16) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status = hal.fence.await until([%_params.weight__timepoint]) timeout_millis(%c-1_i32) : i32
    %0 = util.null : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%c12}
    %status_0 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    %1 = arith.select %_device_query_0, %c0, %c-1 : index
    %2 = arith.index_cast %1 : index to i32
    cf.switch %2 : i32, [
      default: ^bb2,
      0: ^bb1
    ]
  ^bb1:  // pred: ^bb0
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%buffer : !hal.buffer)[%c0, %c16], 
      %c1 = (%_params.weight : !hal.buffer)[%c0, %c128], 
      %c2 = (%transient_buffer : !hal.buffer)[%c0, %c12]
    ])
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_main_dispatch_0 : !hal.executable)[0] workgroups([%c3, %c1, %c1])
    cf.br ^bb2
  ^bb2:  // 2 preds: ^bb0, ^bb1
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_1 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status_2 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence_1) commands([%cmd])
    %status_3 = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status_3, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c12] shape([%c3]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private @_device_query_0 : i1
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.global private @_executable_main_dispatch_0 : !hal.executable
  util.global private mutable @_params.weight__timepoint : !hal.fence
  util.global private @_params.weight : !hal.buffer
  util.initializer {
    %c0_i64 = arith.constant 0 : i64
    %c128 = arith.constant 128 : index
    %c-1_i64 = arith.constant -1 : i64
    %c0_i32 = arith.constant 0 : i32
    %c0 = arith.constant 0 : index
    %c-1 = arith.constant -1 : index
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(0) layouts([%descriptor_set_layout]) : !hal.pipeline_layout
    %0 = arith.select %value, %c0, %c-1 : index
    %1 = arith.index_cast %0 : index to i32
    util.global.store %value, @_device_query_0 : i1
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    cf.switch %1 : i32, [
      default: ^bb2,
      0: ^bb1
    ]
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device : !hal.device) target(@main_dispatch_0::@cuda_nvptx_fb) layouts([%_pipeline_layout_0]) : !hal.executable
    cf.br ^bb3(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %2 = util.null : !hal.executable
    cf.br ^bb3(%2 : !hal.executable)
  ^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
    %4 = util.null : !hal.fence
    %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #composite_of_128b
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    %did_import, %mapped = hal.allocator.import<%allocator : !hal.allocator> source(%buffer_cst : !util.buffer)[%c0, %c128] affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : i1, !hal.buffer
    util.global.store %3, @_executable_main_dispatch_0 : !hal.executable
    cf.cond_br %did_import, ^bb5(%4, %mapped : !hal.fence, !hal.buffer), ^bb4
  ^bb4:  // pred: ^bb3
    %buffer = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : !hal.buffer{%c128}
    %memory_file = hal.ex.file.from_memory device(%device : !hal.device) affinity(%c-1_i64) access(Read) buffer(%buffer_cst : !util.buffer)[%c0 for %c128] flags(%c0_i32) : !hal.file
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.read<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence) source(%memory_file : !hal.file)[%c0_i64] target(%buffer : !hal.buffer)[%c0] length(%c128) flags(0)
    cf.br ^bb5(%fence, %buffer : !hal.fence, !hal.buffer)
  ^bb5(%5: !hal.fence, %6: !hal.buffer):  // 2 preds: ^bb3, ^bb4
    util.global.store %6, @_params.weight : !hal.buffer
    util.global.store %5, @_params.weight__timepoint : !hal.fence
    util.initializer.return
  }
  hal.executable private @main_dispatch_0 {
    hal.executable.binary public @cuda_nvptx_fb attributes {data = dense<"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vector<1302xi8>, format = "cuda-nvptx-fb", mime_type = "application/x-flatbuffers"}
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c3 = arith.constant 3 : index
    %c2 = arith.constant 2 : index
    %c1 = arith.constant 1 : index
    %c-1 = arith.constant -1 : index
    %c-1_i32 = arith.constant -1 : i32
    %c0_i64 = arith.constant 0 : i64
    %c-1_i64 = arith.constant -1 : i64
    %c128 = arith.constant 128 : index
    %c16 = arith.constant 16 : index
    %c12 = arith.constant 12 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !hal.fence
    %_params.weight = util.global.load @_params.weight : !hal.buffer
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %_executable_main_dispatch_0 = util.global.load @_executable_main_dispatch_0 : !hal.executable
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c16) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status = hal.fence.await until([%_params.weight__timepoint]) timeout_millis(%c-1_i32) : i32
    %0 = util.null : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%c12}
    %status_0 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    %1 = arith.select %_device_query_0, %c0, %c-1 : index
    %2 = arith.index_cast %1 : index to i32
    cf.switch %2 : i32, [
      default: ^bb2,
      0: ^bb1
    ]
  ^bb1:  // pred: ^bb0
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%buffer : !hal.buffer)[%c0, %c16], 
      %c1 = (%_params.weight : !hal.buffer)[%c0, %c128], 
      %c2 = (%transient_buffer : !hal.buffer)[%c0, %c12]
    ])
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_main_dispatch_0 : !hal.executable)[0] workgroups([%c3, %c1, %c1])
    cf.br ^bb2
  ^bb2:  // 2 preds: ^bb0, ^bb1
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_1 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status_2 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence_1) commands([%cmd])
    %status_3 = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status_3, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c12] shape([%c3]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda]} {
  util.global private @_device_query_0 : i1
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.global private @_executable_main_dispatch_0 : !hal.executable
  util.global private mutable @_params.weight__timepoint : !hal.fence
  util.global private @_params.weight : !hal.buffer
  util.initializer {
    %c0_i64 = arith.constant 0 : i64
    %c128 = arith.constant 128 : index
    %c-1_i64 = arith.constant -1 : i64
    %c0_i32 = arith.constant 0 : i32
    %c0 = arith.constant 0 : index
    %c-1 = arith.constant -1 : index
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "cuda-nvptx-fb") : i1, i1 = false
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(0) layouts([%descriptor_set_layout]) : !hal.pipeline_layout
    %0 = arith.select %value, %c0, %c-1 : index
    %1 = arith.index_cast %0 : index to i32
    util.global.store %value, @_device_query_0 : i1
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    cf.switch %1 : i32, [
      default: ^bb2,
      0: ^bb1
    ]
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device : !hal.device) target(@main_dispatch_0::@cuda_nvptx_fb) layouts([%_pipeline_layout_0]) : !hal.executable
    cf.br ^bb3(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %2 = util.null : !hal.executable
    cf.br ^bb3(%2 : !hal.executable)
  ^bb3(%3: !hal.executable):  // 2 preds: ^bb1, ^bb2
    %4 = util.null : !hal.fence
    %buffer_cst = util.buffer.constant {alignment = 64 : index} : !util.buffer = #composite_of_128b
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    %did_import, %mapped = hal.allocator.import<%allocator : !hal.allocator> source(%buffer_cst : !util.buffer)[%c0, %c128] affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : i1, !hal.buffer
    util.global.store %3, @_executable_main_dispatch_0 : !hal.executable
    cf.cond_br %did_import, ^bb5(%4, %mapped : !hal.fence, !hal.buffer), ^bb4
  ^bb4:  // pred: ^bb3
    %buffer = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|SharingImmutable") : !hal.buffer{%c128}
    %memory_file = hal.ex.file.from_memory device(%device : !hal.device) affinity(%c-1_i64) access(Read) buffer(%buffer_cst : !util.buffer)[%c0 for %c128] flags(%c0_i32) : !hal.file
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.read<%device : !hal.device> affinity(%c-1_i64) wait(%4) signal(%fence) source(%memory_file : !hal.file)[%c0_i64] target(%buffer : !hal.buffer)[%c0] length(%c128) flags(0)
    cf.br ^bb5(%fence, %buffer : !hal.fence, !hal.buffer)
  ^bb5(%5: !hal.fence, %6: !hal.buffer):  // 2 preds: ^bb3, ^bb4
    util.global.store %6, @_params.weight : !hal.buffer
    util.global.store %5, @_params.weight__timepoint : !hal.fence
    util.initializer.return
  }
  hal.executable private @main_dispatch_0 {
    hal.executable.binary public @cuda_nvptx_fb attributes {data = dense<"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vector<1302xi8>, format = "cuda-nvptx-fb", mime_type = "application/x-flatbuffers"}
  }
  func.func @main(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c3 = arith.constant 3 : index
    %c2 = arith.constant 2 : index
    %c1 = arith.constant 1 : index
    %c-1 = arith.constant -1 : index
    %c-1_i32 = arith.constant -1 : i32
    %c0_i64 = arith.constant 0 : i64
    %c-1_i64 = arith.constant -1 : i64
    %c128 = arith.constant 128 : index
    %c16 = arith.constant 16 : index
    %c12 = arith.constant 12 : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %_params.weight__timepoint = util.global.load @_params.weight__timepoint : !hal.fence
    %_params.weight = util.global.load @_params.weight : !hal.buffer
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %_executable_main_dispatch_0 = util.global.load @_executable_main_dispatch_0 : !hal.executable
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%c4]) type(%c553648160_i32) encoding(%c1_i32)
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%c16) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status = hal.fence.await until([%_params.weight__timepoint]) timeout_millis(%c-1_i32) : i32
    %0 = util.null : !hal.fence
    %transient_buffer = hal.device.queue.alloca<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence) pool(%c0_i64) type("DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage") : !hal.buffer{%c12}
    %status_0 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    %1 = arith.select %_device_query_0, %c0, %c-1 : index
    %2 = arith.index_cast %1 : index to i32
    cf.switch %2 : i32, [
      default: ^bb2,
      0: ^bb1
    ]
  ^bb1:  // pred: ^bb0
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%buffer : !hal.buffer)[%c0, %c16], 
      %c1 = (%_params.weight : !hal.buffer)[%c0, %c128], 
      %c2 = (%transient_buffer : !hal.buffer)[%c0, %c12]
    ])
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable_main_dispatch_0 : !hal.executable)[0] workgroups([%c3, %c1, %c1])
    cf.br ^bb2
  ^bb2:  // 2 preds: ^bb0, ^bb1
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %fence_1 = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    %status_2 = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%0) signal(%fence_1) commands([%cmd])
    %status_3 = hal.fence.await until([%fence_1]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status_3, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%transient_buffer : !hal.buffer)[%c0, %c12] shape([%c3]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::VM::ConversionPass (iree-vm-conversion) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda], vm.toplevel} {
  vm.module public @LinearModule {
    vm.global.i32 private @_device_query_0 : i32
    vm.global.ref private @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.global.ref private @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
    vm.global.ref private mutable @_params.weight__timepoint : !vm.ref<!hal.fence>
    vm.global.ref private @_params.weight : !vm.ref<!hal.buffer>
    vm.rodata private @main_dispatch_0_cuda_nvptx_fb {alignment = 16 : i64, mime_type = "application/x-flatbuffers"} dense<"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vector<1302xi8>
    vm.initializer {
      %zero = vm.const.i64.zero
      %c128 = vm.const.i64 128
      %c-1 = vm.const.i64 -1
      %zero_0 = vm.const.i32.zero
      %zero_1 = vm.const.i64.zero
      %c-1_2 = vm.const.i64 -1
      %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %buffer = vm.rodata.inline "_utf8_hal_executable_format_EAB228F999C2D3A1" {alignment = 1 : i64} : !vm.buffer = "hal.executable.format"
      %buffer_3 = vm.rodata.inline "_utf8_cuda_nvptx_fb_B15B42B96FDBACC" {alignment = 1 : i64} : !vm.buffer = "cuda-nvptx-fb"
      %0:2 = vm.call @hal.device.query.i64(%ref, %buffer, %buffer_3) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
      %c1 = vm.const.i32 1
      %2 = vm.and.i32 %1, %c1 : i32
      %zero_4 = vm.const.i32.zero
      %3 = vm.select.i32 %0#0, %2, %zero_4 : i32
      %c1_5 = vm.const.i32 1
      %zero_6 = vm.const.i32.zero
      %zero_7 = vm.const.i32.zero
      %c7 = vm.const.i32 7
      %c1_8 = vm.const.i32 1
      %c1_9 = vm.const.i32 1
      %c7_10 = vm.const.i32 7
      %c1_11 = vm.const.i32 1
      %c2 = vm.const.i32 2
      %c7_12 = vm.const.i32 7
      %zero_13 = vm.const.i32.zero
      %ref_14 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero_6, [(%zero_7, %c7, %c1_8), (%c1_9, %c7_10, %c1_11), (%c2, %c7_12, %zero_13)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
      %zero_15 = vm.const.i32.zero
      %ref_16 = vm.call.variadic @hal.pipeline_layout.create(%ref, %zero_15, [%ref_14]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
      %4 = vm.select.i64 %3, %zero_1, %c-1_2 : i64
      %5 = vm.trunc.i64.i32 %4 : i64 -> i32
      vm.global.store.i32 %3, @_device_query_0 : i32
      vm.global.store.ref %ref_16, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      vm.br_table %5 {
        default: ^bb2,
        0: ^bb1
      }
    ^bb1:  // pred: ^bb0
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %main_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @main_dispatch_0_cuda_nvptx_fb : !vm.buffer
      %buffer_17 = vm.rodata.inline "_utf8_cuda_nvptx_fb_B15B42B96FDBACC" {alignment = 1 : i64} : !vm.buffer = "cuda-nvptx-fb"
      %null = vm.const.ref.zero : !vm.buffer
      %ref_18 = vm.call.variadic @hal.executable.create(%ref, %buffer_17, %main_dispatch_0_cuda_nvptx_fb, %null, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
      vm.br ^bb3(%ref_18 : !vm.ref<!hal.executable>)
    ^bb2:  // pred: ^bb0
      %null_19 = vm.const.ref.zero : !vm.ref<!hal.executable>
      vm.br ^bb3(%null_19 : !vm.ref<!hal.executable>)
    ^bb3(%6: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
      %null_20 = vm.const.ref.zero : !vm.ref<!hal.fence>
      %buffer_21 = vm.rodata.inline {alignment = 64 : i64} : !vm.buffer = #composite_of_128b
      %ref_22 = vm.call @hal.device.allocator(%ref) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %c1_23 = vm.const.i32 1
      %c48 = vm.const.i32 48
      %c527363 = vm.const.i32 527363
      %ref_24 = vm.call @hal.allocator.import(%ref_22, %c1_23, %c-1, %c48, %c527363, %buffer_21, %zero_1, %c128) : (!vm.ref<!hal.allocator>, i32, i64, i32, i32, !vm.buffer, i64, i64) -> !vm.ref<!hal.buffer>
      %rnz = vm.cmp.nz.ref %ref_24 : !vm.ref<!hal.buffer>
      vm.global.store.ref %6, @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
      vm.cond_br %rnz, ^bb5(%null_20, %ref_24 : !vm.ref<!hal.fence>, !vm.ref<!hal.buffer>), ^bb4
    ^bb4:  // pred: ^bb3
      %c48_25 = vm.const.i32 48
      %c527363_26 = vm.const.i32 527363
      %ref_27 = vm.call @hal.allocator.allocate(%ref_22, %c-1, %c48_25, %c527363_26, %c128) : (!vm.ref<!hal.allocator>, i64, i32, i32, i64) -> !vm.ref<!hal.buffer>
      %c1_28 = vm.const.i32 1
      %ref_29 = vm.call @hal.ex.file.from_memory(%ref, %c-1, %c1_28, %buffer_21, %zero_1, %c128, %zero_0) : (!vm.ref<!hal.device>, i64, i32, !vm.buffer, i64, i64, i32) -> !vm.ref<!hal.file>
      %zero_30 = vm.const.i32.zero
      %ref_31 = vm.call @hal.fence.create(%ref, %zero_30) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      %zero_32 = vm.const.i32.zero
      vm.call @hal.device.queue.read(%ref, %c-1, %null_20, %ref_31, %ref_29, %zero, %ref_27, %zero_1, %c128, %zero_32) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.file>, i64, !vm.ref<!hal.buffer>, i64, i64, i32) -> ()
      vm.br ^bb5(%ref_31, %ref_27 : !vm.ref<!hal.fence>, !vm.ref<!hal.buffer>)
    ^bb5(%7: !vm.ref<!hal.fence>, %8: !vm.ref<!hal.buffer>):  // 2 preds: ^bb3, ^bb4
      vm.global.store.ref %8, @_params.weight : !vm.ref<!hal.buffer>
      vm.global.store.ref %7, @_params.weight__timepoint : !vm.ref<!hal.fence>
      vm.return
    }
    vm.import private @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects}
    vm.import private @hal.ex.file.from_memory(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %access : i32, %buffer : !vm.buffer, %offset : i64, %length : i64, %flags : i32) -> !vm.ref<!hal.file>
    vm.import private @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
    vm.import private @hal.allocator.import(%allocator : !vm.ref<!hal.allocator>, %try : i32, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %source : !vm.buffer, %offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
    vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
    vm.import private @hal.buffer.subspan(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.buffer.length(%buffer : !vm.ref<!hal.buffer>) -> i64 attributes {nosideeffects}
    vm.import private @hal.buffer.load(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i32) -> i32
    vm.import private @hal.buffer.store(%value : i32, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i32)
    vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
    vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
    vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.buffer_view.element_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
    vm.import private @hal.buffer_view.encoding_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
    vm.import private @hal.buffer_view.rank(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
    vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
    vm.import private @hal.buffer_view.trace(%key : !vm.buffer, %operands : !vm.ref<!hal.buffer_view> ...)
    vm.import private @hal.channel.create(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %flags : i32, %id : !vm.buffer, %group : !vm.buffer, %rank : i32, %count : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects}
    vm.import private @hal.channel.split(%channel : !vm.ref<!hal.channel>, %color : i32, %key : i32, %flags : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects}
    vm.import private @hal.channel.rank_and_count(%channel : !vm.ref<!hal.channel>) -> (i32, i32) attributes {nosideeffects}
    vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer>
    vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.begin_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>, %label : !vm.buffer)
    vm.import private @hal.command_buffer.end_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
    vm.import private @hal.command_buffer.fill_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %pattern : i32, %pattern_length : i32)
    vm.import private @hal.command_buffer.copy_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64)
    vm.import private @hal.command_buffer.collective(%command_buffer : !vm.ref<!hal.command_buffer>, %channel : !vm.ref<!hal.channel>, %op : i32, %param : i32, %send_buffer : !vm.ref<!hal.buffer>, %send_offset : i64, %send_length : i64, %recv_buffer : !vm.ref<!hal.buffer>, %recv_offset : i64, %recv_length : i64, %element_count : i64)
    vm.import private @hal.command_buffer.push_constants(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %offset : i32, %values : i32 ...)
    vm.import private @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32)
    vm.import private @hal.command_buffer.dispatch.indirect(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroups_buffer : !vm.ref<!hal.buffer>, %workgroups_offset : i64)
    vm.import private @hal.command_buffer.execute.commands(%command_buffer : !vm.ref<!hal.command_buffer>, %commands : !vm.ref<!hal.command_buffer>, %bindings : tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects}
    vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
    vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
    vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
    vm.import private @hal.device.queue.dealloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %buffer : !vm.ref<!hal.buffer>)
    vm.import private @hal.device.queue.read(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_file : !vm.ref<!hal.file>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i32)
    vm.import private @hal.device.queue.write(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_file : !vm.ref<!hal.file>, %target_offset : i64, %length : i64, %flags : i32)
    vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
    vm.import private @hal.device.queue.flush(%device : !vm.ref<!hal.device>, %queue_affinity : i64)
    vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects}
    vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
    vm.import private @hal.fence.join(%fences : !vm.ref<!hal.fence> ...) -> !vm.ref<!hal.fence> attributes {nosideeffects}
    vm.import private @hal.fence.query(%fence : !vm.ref<!hal.fence>) -> i32
    vm.import private @hal.fence.signal(%fence : !vm.ref<!hal.fence>)
    vm.import private @hal.fence.fail(%fence : !vm.ref<!hal.fence>, %status : i32)
    vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
    vm.import private @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects}
    vm.func private @main(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
      %c3 = vm.const.i64 3
      %c2 = vm.const.i64 2
      %c1 = vm.const.i64 1
      %c-1 = vm.const.i64 -1
      %c-1_0 = vm.const.i32 -1
      %zero = vm.const.i64.zero
      %c-1_1 = vm.const.i64 -1
      %c128 = vm.const.i64 128
      %c16 = vm.const.i64 16
      %c12 = vm.const.i64 12
      %c553648160 = vm.const.i32 553648160
      %c1_2 = vm.const.i32 1
      %c4 = vm.const.i64 4
      %zero_3 = vm.const.i64.zero
      %_params.weight__timepoint = vm.global.load.ref @_params.weight__timepoint : !vm.ref<!hal.fence>
      %_params.weight = vm.global.load.ref @_params.weight : !vm.ref<!hal.buffer>
      %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %_executable_main_dispatch_0 = vm.global.load.ref @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
      %buffer = vm.rodata.inline "_utf8_input_0_5FD512E67BEFDEEC" {alignment = 1 : i64} : !vm.buffer = "input 0"
      vm.call.variadic @hal.buffer_view.assert(%arg0, %buffer, %c553648160, %c1_2, [%c4]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %buffer_6 = vm.rodata.inline "_utf8_tensor_3C6209B4FD120BDC" {alignment = 1 : i64} : !vm.buffer = "tensor"
      %c16_7 = vm.const.i32 16
      %c3075 = vm.const.i32 3075
      vm.call @hal.buffer.assert(%ref, %buffer_6, %ref_5, %c16, %c16_7, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %zero_8 = vm.const.i32.zero
      %ref_9 = vm.call @hal.fence.create(%ref_4, %zero_8) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      %0 = vm.call.variadic @hal.fence.await(%c-1_0, [%_params.weight__timepoint]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %zero_10 = vm.const.i32.zero
      %c48 = vm.const.i32 48
      %c3075_11 = vm.const.i32 3075
      %ref_12 = vm.call @hal.device.queue.alloca(%ref_4, %c-1_1, %null, %ref_9, %zero_10, %c48, %c3075_11, %c12) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
      %1 = vm.call.variadic @hal.fence.await(%c-1_0, [%ref_9]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      %c17 = vm.const.i32 17
      %c3_13 = vm.const.i32 3
      %zero_14 = vm.const.i32.zero
      %ref_15 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3_13, %zero_14) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
      %2 = vm.select.i64 %_device_query_0, %zero_3, %c-1 : i64
      %3 = vm.trunc.i64.i32 %2 : i64 -> i32
      vm.br_table %3 {
        default: ^bb2,
        0: ^bb1
      }
    ^bb1:  // pred: ^bb0
      %zero_16 = vm.const.i32.zero
      %zero_17 = vm.const.i32.zero
      %zero_18 = vm.const.i32.zero
      %c1_19 = vm.const.i32 1
      %c2_20 = vm.const.i32 2
      vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_15, %_pipeline_layout_0, %zero_16, [(%zero_17, %zero_18, %ref, %zero_3, %c16), (%c1_19, %zero_18, %_params.weight, %zero_3, %c128), (%c2_20, %zero_18, %ref_12, %zero_3, %c12)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      %zero_21 = vm.const.i32.zero
      %c3_22 = vm.const.i32 3
      %c1_23 = vm.const.i32 1
      %c1_24 = vm.const.i32 1
      vm.call @hal.command_buffer.dispatch(%ref_15, %_executable_main_dispatch_0, %zero_21, %c3_22, %c1_23, %c1_24) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
      vm.br ^bb2
    ^bb2:  // 2 preds: ^bb0, ^bb1
      %c28 = vm.const.i32 28
      %c13 = vm.const.i32 13
      %zero_25 = vm.const.i32.zero
      vm.call @hal.command_buffer.execution_barrier(%ref_15, %c28, %c13, %zero_25) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.finalize(%ref_15) : (!vm.ref<!hal.command_buffer>) -> ()
      %zero_26 = vm.const.i32.zero
      %ref_27 = vm.call @hal.fence.create(%ref_4, %zero_26) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      %4 = vm.call.variadic @hal.fence.await(%c-1_0, [%ref_9]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1_1, %null, %ref_27, [%ref_15]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
      %5 = vm.call.variadic @hal.fence.await(%c-1_0, [%ref_27]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_fail %5, "failed to wait on timepoint"
      %ref_28 = vm.call.variadic @hal.buffer_view.create(%ref_12, %zero_3, %c12, %c553648160, %c1_2, [%c3]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_28 : !vm.ref<!hal.buffer_view>
    }
    vm.export @main attributes {iree.abi.stub}
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::VM::HoistInlinedRodataPass (iree-vm-hoist-inlined-rodata) //----- //
vm.module public @LinearModule {
  vm.global.i32 private @_device_query_0 : i32
  vm.global.ref private @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
  vm.global.ref private @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
  vm.global.ref private mutable @_params.weight__timepoint : !vm.ref<!hal.fence>
  vm.global.ref private @_params.weight : !vm.ref<!hal.buffer>
  vm.rodata private @main_dispatch_0_cuda_nvptx_fb {alignment = 16 : i64, mime_type = "application/x-flatbuffers"} dense<"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vector<1302xi8>
  vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
  vm.rodata private @_utf8_cuda_nvptx_fb_B15B42B96FDBACC {alignment = 1 : i64} "cuda-nvptx-fb"
  vm.rodata private @_utf8_cuda_nvptx_fb_B15B42B96FDBACC_0 {alignment = 1 : i64} "cuda-nvptx-fb"
  vm.rodata private @_const {alignment = 64 : i64} #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
  vm.initializer {
    %zero = vm.const.i64.zero
    %c128 = vm.const.i64 128
    %c-1 = vm.const.i64 -1
    %zero_0 = vm.const.i32.zero
    %zero_1 = vm.const.i64.zero
    %c-1_2 = vm.const.i64 -1
    %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
    %_utf8_cuda_nvptx_fb_B15B42B96FDBACC = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
    %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
    %c1 = vm.const.i32 1
    %2 = vm.and.i32 %1, %c1 : i32
    %zero_3 = vm.const.i32.zero
    %3 = vm.select.i32 %0#0, %2, %zero_3 : i32
    %c1_4 = vm.const.i32 1
    %zero_5 = vm.const.i32.zero
    %zero_6 = vm.const.i32.zero
    %c7 = vm.const.i32 7
    %c1_7 = vm.const.i32 1
    %c1_8 = vm.const.i32 1
    %c7_9 = vm.const.i32 7
    %c1_10 = vm.const.i32 1
    %c2 = vm.const.i32 2
    %c7_11 = vm.const.i32 7
    %zero_12 = vm.const.i32.zero
    %ref_13 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero_5, [(%zero_6, %c7, %c1_7), (%c1_8, %c7_9, %c1_10), (%c2, %c7_11, %zero_12)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
    %zero_14 = vm.const.i32.zero
    %ref_15 = vm.call.variadic @hal.pipeline_layout.create(%ref, %zero_14, [%ref_13]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
    %4 = vm.select.i64 %3, %zero_1, %c-1_2 : i64
    %5 = vm.trunc.i64.i32 %4 : i64 -> i32
    vm.global.store.i32 %3, @_device_query_0 : i32
    vm.global.store.ref %ref_15, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.br_table %5 {
      default: ^bb2,
      0: ^bb1
    }
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %main_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @main_dispatch_0_cuda_nvptx_fb : !vm.buffer
    %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_0 = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC_0 : !vm.buffer
    %null = vm.const.ref.zero : !vm.buffer
    %ref_16 = vm.call.variadic @hal.executable.create(%ref, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_0, %main_dispatch_0_cuda_nvptx_fb, %null, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
    vm.br ^bb3(%ref_16 : !vm.ref<!hal.executable>)
  ^bb2:  // pred: ^bb0
    %null_17 = vm.const.ref.zero : !vm.ref<!hal.executable>
    vm.br ^bb3(%null_17 : !vm.ref<!hal.executable>)
  ^bb3(%6: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
    %null_18 = vm.const.ref.zero : !vm.ref<!hal.fence>
    %_const = vm.const.ref.rodata @_const : !vm.buffer
    %ref_19 = vm.call @hal.device.allocator(%ref) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    %c1_20 = vm.const.i32 1
    %c48 = vm.const.i32 48
    %c527363 = vm.const.i32 527363
    %ref_21 = vm.call @hal.allocator.import(%ref_19, %c1_20, %c-1, %c48, %c527363, %_const, %zero_1, %c128) : (!vm.ref<!hal.allocator>, i32, i64, i32, i32, !vm.buffer, i64, i64) -> !vm.ref<!hal.buffer>
    %rnz = vm.cmp.nz.ref %ref_21 : !vm.ref<!hal.buffer>
    vm.global.store.ref %6, @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
    vm.cond_br %rnz, ^bb5(%null_18, %ref_21 : !vm.ref<!hal.fence>, !vm.ref<!hal.buffer>), ^bb4
  ^bb4:  // pred: ^bb3
    %c48_22 = vm.const.i32 48
    %c527363_23 = vm.const.i32 527363
    %ref_24 = vm.call @hal.allocator.allocate(%ref_19, %c-1, %c48_22, %c527363_23, %c128) : (!vm.ref<!hal.allocator>, i64, i32, i32, i64) -> !vm.ref<!hal.buffer>
    %c1_25 = vm.const.i32 1
    %ref_26 = vm.call @hal.ex.file.from_memory(%ref, %c-1, %c1_25, %_const, %zero_1, %c128, %zero_0) : (!vm.ref<!hal.device>, i64, i32, !vm.buffer, i64, i64, i32) -> !vm.ref<!hal.file>
    %zero_27 = vm.const.i32.zero
    %ref_28 = vm.call @hal.fence.create(%ref, %zero_27) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    %zero_29 = vm.const.i32.zero
    vm.call @hal.device.queue.read(%ref, %c-1, %null_18, %ref_28, %ref_26, %zero, %ref_24, %zero_1, %c128, %zero_29) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.file>, i64, !vm.ref<!hal.buffer>, i64, i64, i32) -> ()
    vm.br ^bb5(%ref_28, %ref_24 : !vm.ref<!hal.fence>, !vm.ref<!hal.buffer>)
  ^bb5(%7: !vm.ref<!hal.fence>, %8: !vm.ref<!hal.buffer>):  // 2 preds: ^bb3, ^bb4
    vm.global.store.ref %8, @_params.weight : !vm.ref<!hal.buffer>
    vm.global.store.ref %7, @_params.weight__timepoint : !vm.ref<!hal.fence>
    vm.return
  }
  vm.import private @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects}
  vm.import private @hal.ex.file.from_memory(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %access : i32, %buffer : !vm.buffer, %offset : i64, %length : i64, %flags : i32) -> !vm.ref<!hal.file>
  vm.import private @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
  vm.import private @hal.allocator.import(%allocator : !vm.ref<!hal.allocator>, %try : i32, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %source : !vm.buffer, %offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
  vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
  vm.import private @hal.buffer.subspan(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
  vm.import private @hal.buffer.length(%buffer : !vm.ref<!hal.buffer>) -> i64 attributes {nosideeffects}
  vm.import private @hal.buffer.load(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i32) -> i32
  vm.import private @hal.buffer.store(%value : i32, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i32)
  vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
  vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
  vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
  vm.import private @hal.buffer_view.element_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
  vm.import private @hal.buffer_view.encoding_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
  vm.import private @hal.buffer_view.rank(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
  vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
  vm.import private @hal.buffer_view.trace(%key : !vm.buffer, %operands : !vm.ref<!hal.buffer_view> ...)
  vm.import private @hal.channel.create(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %flags : i32, %id : !vm.buffer, %group : !vm.buffer, %rank : i32, %count : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects}
  vm.import private @hal.channel.split(%channel : !vm.ref<!hal.channel>, %color : i32, %key : i32, %flags : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects}
  vm.import private @hal.channel.rank_and_count(%channel : !vm.ref<!hal.channel>) -> (i32, i32) attributes {nosideeffects}
  vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer>
  vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
  vm.import private @hal.command_buffer.begin_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>, %label : !vm.buffer)
  vm.import private @hal.command_buffer.end_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>)
  vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
  vm.import private @hal.command_buffer.fill_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %pattern : i32, %pattern_length : i32)
  vm.import private @hal.command_buffer.copy_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64)
  vm.import private @hal.command_buffer.collective(%command_buffer : !vm.ref<!hal.command_buffer>, %channel : !vm.ref<!hal.channel>, %op : i32, %param : i32, %send_buffer : !vm.ref<!hal.buffer>, %send_offset : i64, %send_length : i64, %recv_buffer : !vm.ref<!hal.buffer>, %recv_offset : i64, %recv_length : i64, %element_count : i64)
  vm.import private @hal.command_buffer.push_constants(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %offset : i32, %values : i32 ...)
  vm.import private @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32)
  vm.import private @hal.command_buffer.dispatch.indirect(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroups_buffer : !vm.ref<!hal.buffer>, %workgroups_offset : i64)
  vm.import private @hal.command_buffer.execute.commands(%command_buffer : !vm.ref<!hal.command_buffer>, %commands : !vm.ref<!hal.command_buffer>, %bindings : tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects}
  vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
  vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
  vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
  vm.import private @hal.device.queue.dealloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %buffer : !vm.ref<!hal.buffer>)
  vm.import private @hal.device.queue.read(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_file : !vm.ref<!hal.file>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i32)
  vm.import private @hal.device.queue.write(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_file : !vm.ref<!hal.file>, %target_offset : i64, %length : i64, %flags : i32)
  vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
  vm.import private @hal.device.queue.flush(%device : !vm.ref<!hal.device>, %queue_affinity : i64)
  vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects}
  vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
  vm.import private @hal.fence.join(%fences : !vm.ref<!hal.fence> ...) -> !vm.ref<!hal.fence> attributes {nosideeffects}
  vm.import private @hal.fence.query(%fence : !vm.ref<!hal.fence>) -> i32
  vm.import private @hal.fence.signal(%fence : !vm.ref<!hal.fence>)
  vm.import private @hal.fence.fail(%fence : !vm.ref<!hal.fence>, %status : i32)
  vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
  vm.import private @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects}
  vm.rodata private @_utf8_input_0_5FD512E67BEFDEEC {alignment = 1 : i64} "input 0"
  vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
  vm.func private @main(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
    %c3 = vm.const.i64 3
    %c2 = vm.const.i64 2
    %c1 = vm.const.i64 1
    %c-1 = vm.const.i64 -1
    %c-1_0 = vm.const.i32 -1
    %zero = vm.const.i64.zero
    %c-1_1 = vm.const.i64 -1
    %c128 = vm.const.i64 128
    %c16 = vm.const.i64 16
    %c12 = vm.const.i64 12
    %c553648160 = vm.const.i32 553648160
    %c1_2 = vm.const.i32 1
    %c4 = vm.const.i64 4
    %zero_3 = vm.const.i64.zero
    %_params.weight__timepoint = vm.global.load.ref @_params.weight__timepoint : !vm.ref<!hal.fence>
    %_params.weight = vm.global.load.ref @_params.weight : !vm.ref<!hal.buffer>
    %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %_executable_main_dispatch_0 = vm.global.load.ref @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
    %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1_2, [%c4]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
    %c16_6 = vm.const.i32 16
    %c3075 = vm.const.i32 3075
    vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c16, %c16_6, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %zero_7 = vm.const.i32.zero
    %ref_8 = vm.call @hal.fence.create(%ref_4, %zero_7) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    %0 = vm.call.variadic @hal.fence.await(%c-1_0, [%_params.weight__timepoint]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    %null = vm.const.ref.zero : !vm.ref<!hal.fence>
    %zero_9 = vm.const.i32.zero
    %c48 = vm.const.i32 48
    %c3075_10 = vm.const.i32 3075
    %ref_11 = vm.call @hal.device.queue.alloca(%ref_4, %c-1_1, %null, %ref_8, %zero_9, %c48, %c3075_10, %c12) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
    %1 = vm.call.variadic @hal.fence.await(%c-1_0, [%ref_8]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    %c17 = vm.const.i32 17
    %c3_12 = vm.const.i32 3
    %zero_13 = vm.const.i32.zero
    %ref_14 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3_12, %zero_13) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
    %2 = vm.select.i64 %_device_query_0, %zero_3, %c-1 : i64
    %3 = vm.trunc.i64.i32 %2 : i64 -> i32
    vm.br_table %3 {
      default: ^bb2,
      0: ^bb1
    }
  ^bb1:  // pred: ^bb0
    %zero_15 = vm.const.i32.zero
    %zero_16 = vm.const.i32.zero
    %zero_17 = vm.const.i32.zero
    %c1_18 = vm.const.i32 1
    %c2_19 = vm.const.i32 2
    vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_14, %_pipeline_layout_0, %zero_15, [(%zero_16, %zero_17, %ref, %zero_3, %c16), (%c1_18, %zero_17, %_params.weight, %zero_3, %c128), (%c2_19, %zero_17, %ref_11, %zero_3, %c12)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    %zero_20 = vm.const.i32.zero
    %c3_21 = vm.const.i32 3
    %c1_22 = vm.const.i32 1
    %c1_23 = vm.const.i32 1
    vm.call @hal.command_buffer.dispatch(%ref_14, %_executable_main_dispatch_0, %zero_20, %c3_21, %c1_22, %c1_23) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
    vm.br ^bb2
  ^bb2:  // 2 preds: ^bb0, ^bb1
    %c28 = vm.const.i32 28
    %c13 = vm.const.i32 13
    %zero_24 = vm.const.i32.zero
    vm.call @hal.command_buffer.execution_barrier(%ref_14, %c28, %c13, %zero_24) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
    vm.call @hal.command_buffer.finalize(%ref_14) : (!vm.ref<!hal.command_buffer>) -> ()
    %zero_25 = vm.const.i32.zero
    %ref_26 = vm.call @hal.fence.create(%ref_4, %zero_25) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    %4 = vm.call.variadic @hal.fence.await(%c-1_0, [%ref_8]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1_1, %null, %ref_26, [%ref_14]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
    %5 = vm.call.variadic @hal.fence.await(%c-1_0, [%ref_26]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    vm.cond_fail %5, "failed to wait on timepoint"
    %ref_27 = vm.call.variadic @hal.buffer_view.create(%ref_11, %zero_3, %c12, %c553648160, %c1_2, [%c3]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
    vm.return %ref_27 : !vm.ref<!hal.buffer_view>
  }
  vm.export @main attributes {iree.abi.stub}
}

// -----// IR Dump After mlir::iree_compiler::IREE::VM::DeduplicateRodataPass (iree-vm-deduplicate-rodata) //----- //
vm.module public @LinearModule {
  vm.global.i32 private @_device_query_0 : i32
  vm.global.ref private @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
  vm.global.ref private @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
  vm.global.ref private mutable @_params.weight__timepoint : !vm.ref<!hal.fence>
  vm.global.ref private @_params.weight : !vm.ref<!hal.buffer>
  vm.rodata private @main_dispatch_0_cuda_nvptx_fb {alignment = 16 : i64, mime_type = "application/x-flatbuffers"} dense<"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vector<1302xi8>
  vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
  vm.rodata private @_utf8_cuda_nvptx_fb_B15B42B96FDBACC {alignment = 1 : i64} "cuda-nvptx-fb"
  vm.rodata private @_const {alignment = 64 : i64} #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
  vm.initializer {
    %zero = vm.const.i64.zero
    %c128 = vm.const.i64 128
    %c-1 = vm.const.i64 -1
    %zero_0 = vm.const.i32.zero
    %zero_1 = vm.const.i64.zero
    %c-1_2 = vm.const.i64 -1
    %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
    %_utf8_cuda_nvptx_fb_B15B42B96FDBACC = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
    %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
    %c1 = vm.const.i32 1
    %2 = vm.and.i32 %1, %c1 : i32
    %zero_3 = vm.const.i32.zero
    %3 = vm.select.i32 %0#0, %2, %zero_3 : i32
    %c1_4 = vm.const.i32 1
    %zero_5 = vm.const.i32.zero
    %zero_6 = vm.const.i32.zero
    %c7 = vm.const.i32 7
    %c1_7 = vm.const.i32 1
    %c1_8 = vm.const.i32 1
    %c7_9 = vm.const.i32 7
    %c1_10 = vm.const.i32 1
    %c2 = vm.const.i32 2
    %c7_11 = vm.const.i32 7
    %zero_12 = vm.const.i32.zero
    %ref_13 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero_5, [(%zero_6, %c7, %c1_7), (%c1_8, %c7_9, %c1_10), (%c2, %c7_11, %zero_12)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
    %zero_14 = vm.const.i32.zero
    %ref_15 = vm.call.variadic @hal.pipeline_layout.create(%ref, %zero_14, [%ref_13]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
    %4 = vm.select.i64 %3, %zero_1, %c-1_2 : i64
    %5 = vm.trunc.i64.i32 %4 : i64 -> i32
    vm.global.store.i32 %3, @_device_query_0 : i32
    vm.global.store.ref %ref_15, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.br_table %5 {
      default: ^bb2,
      0: ^bb1
    }
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %main_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @main_dispatch_0_cuda_nvptx_fb : !vm.buffer
    %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_16 = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
    %null = vm.const.ref.zero : !vm.buffer
    %ref_17 = vm.call.variadic @hal.executable.create(%ref, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_16, %main_dispatch_0_cuda_nvptx_fb, %null, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
    vm.br ^bb3(%ref_17 : !vm.ref<!hal.executable>)
  ^bb2:  // pred: ^bb0
    %null_18 = vm.const.ref.zero : !vm.ref<!hal.executable>
    vm.br ^bb3(%null_18 : !vm.ref<!hal.executable>)
  ^bb3(%6: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
    %null_19 = vm.const.ref.zero : !vm.ref<!hal.fence>
    %_const = vm.const.ref.rodata @_const : !vm.buffer
    %ref_20 = vm.call @hal.device.allocator(%ref) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    %c1_21 = vm.const.i32 1
    %c48 = vm.const.i32 48
    %c527363 = vm.const.i32 527363
    %ref_22 = vm.call @hal.allocator.import(%ref_20, %c1_21, %c-1, %c48, %c527363, %_const, %zero_1, %c128) : (!vm.ref<!hal.allocator>, i32, i64, i32, i32, !vm.buffer, i64, i64) -> !vm.ref<!hal.buffer>
    %rnz = vm.cmp.nz.ref %ref_22 : !vm.ref<!hal.buffer>
    vm.global.store.ref %6, @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
    vm.cond_br %rnz, ^bb5(%null_19, %ref_22 : !vm.ref<!hal.fence>, !vm.ref<!hal.buffer>), ^bb4
  ^bb4:  // pred: ^bb3
    %c48_23 = vm.const.i32 48
    %c527363_24 = vm.const.i32 527363
    %ref_25 = vm.call @hal.allocator.allocate(%ref_20, %c-1, %c48_23, %c527363_24, %c128) : (!vm.ref<!hal.allocator>, i64, i32, i32, i64) -> !vm.ref<!hal.buffer>
    %c1_26 = vm.const.i32 1
    %ref_27 = vm.call @hal.ex.file.from_memory(%ref, %c-1, %c1_26, %_const, %zero_1, %c128, %zero_0) : (!vm.ref<!hal.device>, i64, i32, !vm.buffer, i64, i64, i32) -> !vm.ref<!hal.file>
    %zero_28 = vm.const.i32.zero
    %ref_29 = vm.call @hal.fence.create(%ref, %zero_28) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    %zero_30 = vm.const.i32.zero
    vm.call @hal.device.queue.read(%ref, %c-1, %null_19, %ref_29, %ref_27, %zero, %ref_25, %zero_1, %c128, %zero_30) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.file>, i64, !vm.ref<!hal.buffer>, i64, i64, i32) -> ()
    vm.br ^bb5(%ref_29, %ref_25 : !vm.ref<!hal.fence>, !vm.ref<!hal.buffer>)
  ^bb5(%7: !vm.ref<!hal.fence>, %8: !vm.ref<!hal.buffer>):  // 2 preds: ^bb3, ^bb4
    vm.global.store.ref %8, @_params.weight : !vm.ref<!hal.buffer>
    vm.global.store.ref %7, @_params.weight__timepoint : !vm.ref<!hal.fence>
    vm.return
  }
  vm.import private @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects}
  vm.import private @hal.ex.file.from_memory(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %access : i32, %buffer : !vm.buffer, %offset : i64, %length : i64, %flags : i32) -> !vm.ref<!hal.file>
  vm.import private @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
  vm.import private @hal.allocator.import(%allocator : !vm.ref<!hal.allocator>, %try : i32, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %source : !vm.buffer, %offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
  vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
  vm.import private @hal.buffer.subspan(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
  vm.import private @hal.buffer.length(%buffer : !vm.ref<!hal.buffer>) -> i64 attributes {nosideeffects}
  vm.import private @hal.buffer.load(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i32) -> i32
  vm.import private @hal.buffer.store(%value : i32, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i32)
  vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
  vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
  vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
  vm.import private @hal.buffer_view.element_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
  vm.import private @hal.buffer_view.encoding_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
  vm.import private @hal.buffer_view.rank(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
  vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
  vm.import private @hal.buffer_view.trace(%key : !vm.buffer, %operands : !vm.ref<!hal.buffer_view> ...)
  vm.import private @hal.channel.create(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %flags : i32, %id : !vm.buffer, %group : !vm.buffer, %rank : i32, %count : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects}
  vm.import private @hal.channel.split(%channel : !vm.ref<!hal.channel>, %color : i32, %key : i32, %flags : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects}
  vm.import private @hal.channel.rank_and_count(%channel : !vm.ref<!hal.channel>) -> (i32, i32) attributes {nosideeffects}
  vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer>
  vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
  vm.import private @hal.command_buffer.begin_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>, %label : !vm.buffer)
  vm.import private @hal.command_buffer.end_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>)
  vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
  vm.import private @hal.command_buffer.fill_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %pattern : i32, %pattern_length : i32)
  vm.import private @hal.command_buffer.copy_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64)
  vm.import private @hal.command_buffer.collective(%command_buffer : !vm.ref<!hal.command_buffer>, %channel : !vm.ref<!hal.channel>, %op : i32, %param : i32, %send_buffer : !vm.ref<!hal.buffer>, %send_offset : i64, %send_length : i64, %recv_buffer : !vm.ref<!hal.buffer>, %recv_offset : i64, %recv_length : i64, %element_count : i64)
  vm.import private @hal.command_buffer.push_constants(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %offset : i32, %values : i32 ...)
  vm.import private @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32)
  vm.import private @hal.command_buffer.dispatch.indirect(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroups_buffer : !vm.ref<!hal.buffer>, %workgroups_offset : i64)
  vm.import private @hal.command_buffer.execute.commands(%command_buffer : !vm.ref<!hal.command_buffer>, %commands : !vm.ref<!hal.command_buffer>, %bindings : tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects}
  vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
  vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
  vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
  vm.import private @hal.device.queue.dealloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %buffer : !vm.ref<!hal.buffer>)
  vm.import private @hal.device.queue.read(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_file : !vm.ref<!hal.file>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i32)
  vm.import private @hal.device.queue.write(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_file : !vm.ref<!hal.file>, %target_offset : i64, %length : i64, %flags : i32)
  vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
  vm.import private @hal.device.queue.flush(%device : !vm.ref<!hal.device>, %queue_affinity : i64)
  vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects}
  vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
  vm.import private @hal.fence.join(%fences : !vm.ref<!hal.fence> ...) -> !vm.ref<!hal.fence> attributes {nosideeffects}
  vm.import private @hal.fence.query(%fence : !vm.ref<!hal.fence>) -> i32
  vm.import private @hal.fence.signal(%fence : !vm.ref<!hal.fence>)
  vm.import private @hal.fence.fail(%fence : !vm.ref<!hal.fence>, %status : i32)
  vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
  vm.import private @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects}
  vm.rodata private @_utf8_input_0_5FD512E67BEFDEEC {alignment = 1 : i64} "input 0"
  vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
  vm.func private @main(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
    %c3 = vm.const.i64 3
    %c2 = vm.const.i64 2
    %c1 = vm.const.i64 1
    %c-1 = vm.const.i64 -1
    %c-1_0 = vm.const.i32 -1
    %zero = vm.const.i64.zero
    %c-1_1 = vm.const.i64 -1
    %c128 = vm.const.i64 128
    %c16 = vm.const.i64 16
    %c12 = vm.const.i64 12
    %c553648160 = vm.const.i32 553648160
    %c1_2 = vm.const.i32 1
    %c4 = vm.const.i64 4
    %zero_3 = vm.const.i64.zero
    %_params.weight__timepoint = vm.global.load.ref @_params.weight__timepoint : !vm.ref<!hal.fence>
    %_params.weight = vm.global.load.ref @_params.weight : !vm.ref<!hal.buffer>
    %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %_executable_main_dispatch_0 = vm.global.load.ref @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
    %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1_2, [%c4]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
    %c16_6 = vm.const.i32 16
    %c3075 = vm.const.i32 3075
    vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c16, %c16_6, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %zero_7 = vm.const.i32.zero
    %ref_8 = vm.call @hal.fence.create(%ref_4, %zero_7) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    %0 = vm.call.variadic @hal.fence.await(%c-1_0, [%_params.weight__timepoint]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    %null = vm.const.ref.zero : !vm.ref<!hal.fence>
    %zero_9 = vm.const.i32.zero
    %c48 = vm.const.i32 48
    %c3075_10 = vm.const.i32 3075
    %ref_11 = vm.call @hal.device.queue.alloca(%ref_4, %c-1_1, %null, %ref_8, %zero_9, %c48, %c3075_10, %c12) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
    %1 = vm.call.variadic @hal.fence.await(%c-1_0, [%ref_8]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    %c17 = vm.const.i32 17
    %c3_12 = vm.const.i32 3
    %zero_13 = vm.const.i32.zero
    %ref_14 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3_12, %zero_13) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
    %2 = vm.select.i64 %_device_query_0, %zero_3, %c-1 : i64
    %3 = vm.trunc.i64.i32 %2 : i64 -> i32
    vm.br_table %3 {
      default: ^bb2,
      0: ^bb1
    }
  ^bb1:  // pred: ^bb0
    %zero_15 = vm.const.i32.zero
    %zero_16 = vm.const.i32.zero
    %zero_17 = vm.const.i32.zero
    %c1_18 = vm.const.i32 1
    %c2_19 = vm.const.i32 2
    vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_14, %_pipeline_layout_0, %zero_15, [(%zero_16, %zero_17, %ref, %zero_3, %c16), (%c1_18, %zero_17, %_params.weight, %zero_3, %c128), (%c2_19, %zero_17, %ref_11, %zero_3, %c12)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    %zero_20 = vm.const.i32.zero
    %c3_21 = vm.const.i32 3
    %c1_22 = vm.const.i32 1
    %c1_23 = vm.const.i32 1
    vm.call @hal.command_buffer.dispatch(%ref_14, %_executable_main_dispatch_0, %zero_20, %c3_21, %c1_22, %c1_23) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
    vm.br ^bb2
  ^bb2:  // 2 preds: ^bb0, ^bb1
    %c28 = vm.const.i32 28
    %c13 = vm.const.i32 13
    %zero_24 = vm.const.i32.zero
    vm.call @hal.command_buffer.execution_barrier(%ref_14, %c28, %c13, %zero_24) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
    vm.call @hal.command_buffer.finalize(%ref_14) : (!vm.ref<!hal.command_buffer>) -> ()
    %zero_25 = vm.const.i32.zero
    %ref_26 = vm.call @hal.fence.create(%ref_4, %zero_25) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    %4 = vm.call.variadic @hal.fence.await(%c-1_0, [%ref_8]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1_1, %null, %ref_26, [%ref_14]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
    %5 = vm.call.variadic @hal.fence.await(%c-1_0, [%ref_26]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    vm.cond_fail %5, "failed to wait on timepoint"
    %ref_27 = vm.call.variadic @hal.buffer_view.create(%ref_11, %zero_3, %c12, %c553648160, %c1_2, [%c3]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
    vm.return %ref_27 : !vm.ref<!hal.buffer_view>
  }
  vm.export @main attributes {iree.abi.stub}
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda], vm.toplevel} {
  vm.module public @LinearModule {
    vm.global.i32 private @_device_query_0 : i32
    vm.global.ref private @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.global.ref private @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
    vm.global.ref private mutable @_params.weight__timepoint : !vm.ref<!hal.fence>
    vm.global.ref private @_params.weight : !vm.ref<!hal.buffer>
    vm.rodata private @main_dispatch_0_cuda_nvptx_fb {alignment = 16 : i64, mime_type = "application/x-flatbuffers"} dense<"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vector<1302xi8>
    vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
    vm.rodata private @_utf8_cuda_nvptx_fb_B15B42B96FDBACC {alignment = 1 : i64} "cuda-nvptx-fb"
    vm.rodata private @_const {alignment = 64 : i64} #composite_of_128b
    vm.initializer {
      %c527363 = vm.const.i32 527363
      %c48 = vm.const.i32 48
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %null_0 = vm.const.ref.zero : !vm.ref<!hal.executable>
      %null_1 = vm.const.ref.zero : !vm.buffer
      %c2 = vm.const.i32 2
      %c7 = vm.const.i32 7
      %c1 = vm.const.i32 1
      %zero = vm.const.i64.zero
      %c128 = vm.const.i64 128
      %c-1 = vm.const.i64 -1
      %zero_2 = vm.const.i32.zero
      %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
      %_utf8_cuda_nvptx_fb_B15B42B96FDBACC = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
      %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
      %2 = vm.and.i32 %1, %c1 : i32
      %3 = vm.select.i32 %0#0, %2, %zero_2 : i32
      %ref_3 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero_2, [(%zero_2, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %zero_2)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
      %ref_4 = vm.call.variadic @hal.pipeline_layout.create(%ref, %zero_2, [%ref_3]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
      %4 = vm.select.i64 %3, %zero, %c-1 : i64
      %5 = vm.trunc.i64.i32 %4 : i64 -> i32
      vm.global.store.i32 %3, @_device_query_0 : i32
      vm.global.store.ref %ref_4, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      vm.br_table %5 {
        default: ^bb2,
        0: ^bb1
      }
    ^bb1:  // pred: ^bb0
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %main_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @main_dispatch_0_cuda_nvptx_fb : !vm.buffer
      %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_5 = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
      %ref_6 = vm.call.variadic @hal.executable.create(%ref, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC_5, %main_dispatch_0_cuda_nvptx_fb, %null_1, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
      vm.br ^bb3(%ref_6 : !vm.ref<!hal.executable>)
    ^bb2:  // pred: ^bb0
      vm.br ^bb3(%null_0 : !vm.ref<!hal.executable>)
    ^bb3(%6: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
      %_const = vm.const.ref.rodata @_const : !vm.buffer
      %ref_7 = vm.call @hal.device.allocator(%ref) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %ref_8 = vm.call @hal.allocator.import(%ref_7, %c1, %c-1, %c48, %c527363, %_const, %zero, %c128) : (!vm.ref<!hal.allocator>, i32, i64, i32, i32, !vm.buffer, i64, i64) -> !vm.ref<!hal.buffer>
      %rnz = vm.cmp.nz.ref %ref_8 : !vm.ref<!hal.buffer>
      vm.global.store.ref %6, @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
      vm.cond_br %rnz, ^bb5(%null, %ref_8 : !vm.ref<!hal.fence>, !vm.ref<!hal.buffer>), ^bb4
    ^bb4:  // pred: ^bb3
      %ref_9 = vm.call @hal.allocator.allocate(%ref_7, %c-1, %c48, %c527363, %c128) : (!vm.ref<!hal.allocator>, i64, i32, i32, i64) -> !vm.ref<!hal.buffer>
      %ref_10 = vm.call @hal.ex.file.from_memory(%ref, %c-1, %c1, %_const, %zero, %c128, %zero_2) : (!vm.ref<!hal.device>, i64, i32, !vm.buffer, i64, i64, i32) -> !vm.ref<!hal.file>
      %ref_11 = vm.call @hal.fence.create(%ref, %zero_2) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      vm.call @hal.device.queue.read(%ref, %c-1, %null, %ref_11, %ref_10, %zero, %ref_9, %zero, %c128, %zero_2) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.file>, i64, !vm.ref<!hal.buffer>, i64, i64, i32) -> ()
      vm.br ^bb5(%ref_11, %ref_9 : !vm.ref<!hal.fence>, !vm.ref<!hal.buffer>)
    ^bb5(%7: !vm.ref<!hal.fence>, %8: !vm.ref<!hal.buffer>):  // 2 preds: ^bb3, ^bb4
      vm.global.store.ref %8, @_params.weight : !vm.ref<!hal.buffer>
      vm.global.store.ref %7, @_params.weight__timepoint : !vm.ref<!hal.fence>
      vm.return
    }
    vm.import private @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects}
    vm.import private @hal.ex.file.from_memory(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %access : i32, %buffer : !vm.buffer, %offset : i64, %length : i64, %flags : i32) -> !vm.ref<!hal.file>
    vm.import private @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
    vm.import private @hal.allocator.import(%allocator : !vm.ref<!hal.allocator>, %try : i32, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %source : !vm.buffer, %offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
    vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
    vm.import private @hal.buffer.subspan(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.buffer.length(%buffer : !vm.ref<!hal.buffer>) -> i64 attributes {nosideeffects}
    vm.import private @hal.buffer.load(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i32) -> i32
    vm.import private @hal.buffer.store(%value : i32, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i32)
    vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
    vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
    vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.buffer_view.element_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
    vm.import private @hal.buffer_view.encoding_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
    vm.import private @hal.buffer_view.rank(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
    vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
    vm.import private @hal.buffer_view.trace(%key : !vm.buffer, %operands : !vm.ref<!hal.buffer_view> ...)
    vm.import private @hal.channel.create(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %flags : i32, %id : !vm.buffer, %group : !vm.buffer, %rank : i32, %count : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects}
    vm.import private @hal.channel.split(%channel : !vm.ref<!hal.channel>, %color : i32, %key : i32, %flags : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects}
    vm.import private @hal.channel.rank_and_count(%channel : !vm.ref<!hal.channel>) -> (i32, i32) attributes {nosideeffects}
    vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer>
    vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.begin_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>, %label : !vm.buffer)
    vm.import private @hal.command_buffer.end_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
    vm.import private @hal.command_buffer.fill_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %pattern : i32, %pattern_length : i32)
    vm.import private @hal.command_buffer.copy_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64)
    vm.import private @hal.command_buffer.collective(%command_buffer : !vm.ref<!hal.command_buffer>, %channel : !vm.ref<!hal.channel>, %op : i32, %param : i32, %send_buffer : !vm.ref<!hal.buffer>, %send_offset : i64, %send_length : i64, %recv_buffer : !vm.ref<!hal.buffer>, %recv_offset : i64, %recv_length : i64, %element_count : i64)
    vm.import private @hal.command_buffer.push_constants(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %offset : i32, %values : i32 ...)
    vm.import private @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32)
    vm.import private @hal.command_buffer.dispatch.indirect(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroups_buffer : !vm.ref<!hal.buffer>, %workgroups_offset : i64)
    vm.import private @hal.command_buffer.execute.commands(%command_buffer : !vm.ref<!hal.command_buffer>, %commands : !vm.ref<!hal.command_buffer>, %bindings : tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects}
    vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
    vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
    vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
    vm.import private @hal.device.queue.dealloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %buffer : !vm.ref<!hal.buffer>)
    vm.import private @hal.device.queue.read(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_file : !vm.ref<!hal.file>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i32)
    vm.import private @hal.device.queue.write(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_file : !vm.ref<!hal.file>, %target_offset : i64, %length : i64, %flags : i32)
    vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
    vm.import private @hal.device.queue.flush(%device : !vm.ref<!hal.device>, %queue_affinity : i64)
    vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects}
    vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
    vm.import private @hal.fence.join(%fences : !vm.ref<!hal.fence> ...) -> !vm.ref<!hal.fence> attributes {nosideeffects}
    vm.import private @hal.fence.query(%fence : !vm.ref<!hal.fence>) -> i32
    vm.import private @hal.fence.signal(%fence : !vm.ref<!hal.fence>)
    vm.import private @hal.fence.fail(%fence : !vm.ref<!hal.fence>, %status : i32)
    vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
    vm.import private @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects}
    vm.rodata private @_utf8_input_0_5FD512E67BEFDEEC {alignment = 1 : i64} "input 0"
    vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
    vm.func private @main(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
      %c13 = vm.const.i32 13
      %c28 = vm.const.i32 28
      %c2 = vm.const.i32 2
      %c3 = vm.const.i32 3
      %c17 = vm.const.i32 17
      %c48 = vm.const.i32 48
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %zero = vm.const.i32.zero
      %c3075 = vm.const.i32 3075
      %c16 = vm.const.i32 16
      %c3_0 = vm.const.i64 3
      %c-1 = vm.const.i64 -1
      %c-1_1 = vm.const.i32 -1
      %zero_2 = vm.const.i64.zero
      %c128 = vm.const.i64 128
      %c16_3 = vm.const.i64 16
      %c12 = vm.const.i64 12
      %c553648160 = vm.const.i32 553648160
      %c1 = vm.const.i32 1
      %c4 = vm.const.i64 4
      %_params.weight__timepoint = vm.global.load.ref @_params.weight__timepoint : !vm.ref<!hal.fence>
      %_params.weight = vm.global.load.ref @_params.weight : !vm.ref<!hal.buffer>
      %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %_executable_main_dispatch_0 = vm.global.load.ref @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
      %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1, [%c4]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c16_3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %ref_6 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      %0 = vm.call.variadic @hal.fence.await(%c-1_1, [%_params.weight__timepoint]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      %ref_7 = vm.call @hal.device.queue.alloca(%ref_4, %c-1, %null, %ref_6, %zero, %c48, %c3075, %c12) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
      %1 = vm.call.variadic @hal.fence.await(%c-1_1, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      %ref_8 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
      %2 = vm.select.i64 %_device_query_0, %zero_2, %c-1 : i64
      %3 = vm.trunc.i64.i32 %2 : i64 -> i32
      vm.br_table %3 {
        default: ^bb2,
        0: ^bb1
      }
    ^bb1:  // pred: ^bb0
      vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_8, %_pipeline_layout_0, %zero, [(%zero, %zero, %ref, %zero_2, %c16_3), (%c1, %zero, %_params.weight, %zero_2, %c128), (%c2, %zero, %ref_7, %zero_2, %c12)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      vm.call @hal.command_buffer.dispatch(%ref_8, %_executable_main_dispatch_0, %zero, %c3, %c1, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
      vm.br ^bb2
    ^bb2:  // 2 preds: ^bb0, ^bb1
      vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
      %ref_9 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      %4 = vm.call.variadic @hal.fence.await(%c-1_1, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1, %null, %ref_9, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
      %5 = vm.call.variadic @hal.fence.await(%c-1_1, [%ref_9]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_br %5, ^bb4(%5 : i32), ^bb3
    ^bb3:  // pred: ^bb2
      %ref_10 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_2, %c12, %c553648160, %c1, [%c3_0]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_10 : !vm.ref<!hal.buffer_view>
    ^bb4(%6: i32):  // pred: ^bb2
      vm.fail %6, "failed to wait on timepoint"
    }
    vm.export @main attributes {iree.abi.stub}
  }
}


// -----// IR Dump After CSE (cse) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda], vm.toplevel} {
  vm.module public @LinearModule {
    vm.global.i32 private @_device_query_0 : i32
    vm.global.ref private @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.global.ref private @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
    vm.global.ref private mutable @_params.weight__timepoint : !vm.ref<!hal.fence>
    vm.global.ref private @_params.weight : !vm.ref<!hal.buffer>
    vm.rodata private @main_dispatch_0_cuda_nvptx_fb {alignment = 16 : i64, mime_type = "application/x-flatbuffers"} dense<"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vector<1302xi8>
    vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
    vm.rodata private @_utf8_cuda_nvptx_fb_B15B42B96FDBACC {alignment = 1 : i64} "cuda-nvptx-fb"
    vm.rodata private @_const {alignment = 64 : i64} #composite_of_128b
    vm.initializer {
      %c527363 = vm.const.i32 527363
      %c48 = vm.const.i32 48
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %null_0 = vm.const.ref.zero : !vm.ref<!hal.executable>
      %null_1 = vm.const.ref.zero : !vm.buffer
      %c2 = vm.const.i32 2
      %c7 = vm.const.i32 7
      %c1 = vm.const.i32 1
      %zero = vm.const.i64.zero
      %c128 = vm.const.i64 128
      %c-1 = vm.const.i64 -1
      %zero_2 = vm.const.i32.zero
      %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
      %_utf8_cuda_nvptx_fb_B15B42B96FDBACC = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
      %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
      %2 = vm.and.i32 %1, %c1 : i32
      %3 = vm.select.i32 %0#0, %2, %zero_2 : i32
      %ref_3 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero_2, [(%zero_2, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %zero_2)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
      %ref_4 = vm.call.variadic @hal.pipeline_layout.create(%ref, %zero_2, [%ref_3]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
      %4 = vm.select.i64 %3, %zero, %c-1 : i64
      %5 = vm.trunc.i64.i32 %4 : i64 -> i32
      vm.global.store.i32 %3, @_device_query_0 : i32
      vm.global.store.ref %ref_4, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      vm.br_table %5 {
        default: ^bb2,
        0: ^bb1
      }
    ^bb1:  // pred: ^bb0
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %main_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @main_dispatch_0_cuda_nvptx_fb : !vm.buffer
      %ref_5 = vm.call.variadic @hal.executable.create(%ref, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC, %main_dispatch_0_cuda_nvptx_fb, %null_1, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
      vm.br ^bb3(%ref_5 : !vm.ref<!hal.executable>)
    ^bb2:  // pred: ^bb0
      vm.br ^bb3(%null_0 : !vm.ref<!hal.executable>)
    ^bb3(%6: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
      %_const = vm.const.ref.rodata @_const : !vm.buffer
      %ref_6 = vm.call @hal.device.allocator(%ref) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %ref_7 = vm.call @hal.allocator.import(%ref_6, %c1, %c-1, %c48, %c527363, %_const, %zero, %c128) : (!vm.ref<!hal.allocator>, i32, i64, i32, i32, !vm.buffer, i64, i64) -> !vm.ref<!hal.buffer>
      %rnz = vm.cmp.nz.ref %ref_7 : !vm.ref<!hal.buffer>
      vm.global.store.ref %6, @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
      vm.cond_br %rnz, ^bb5(%null, %ref_7 : !vm.ref<!hal.fence>, !vm.ref<!hal.buffer>), ^bb4
    ^bb4:  // pred: ^bb3
      %ref_8 = vm.call @hal.allocator.allocate(%ref_6, %c-1, %c48, %c527363, %c128) : (!vm.ref<!hal.allocator>, i64, i32, i32, i64) -> !vm.ref<!hal.buffer>
      %ref_9 = vm.call @hal.ex.file.from_memory(%ref, %c-1, %c1, %_const, %zero, %c128, %zero_2) : (!vm.ref<!hal.device>, i64, i32, !vm.buffer, i64, i64, i32) -> !vm.ref<!hal.file>
      %ref_10 = vm.call @hal.fence.create(%ref, %zero_2) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      vm.call @hal.device.queue.read(%ref, %c-1, %null, %ref_10, %ref_9, %zero, %ref_8, %zero, %c128, %zero_2) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.file>, i64, !vm.ref<!hal.buffer>, i64, i64, i32) -> ()
      vm.br ^bb5(%ref_10, %ref_8 : !vm.ref<!hal.fence>, !vm.ref<!hal.buffer>)
    ^bb5(%7: !vm.ref<!hal.fence>, %8: !vm.ref<!hal.buffer>):  // 2 preds: ^bb3, ^bb4
      vm.global.store.ref %8, @_params.weight : !vm.ref<!hal.buffer>
      vm.global.store.ref %7, @_params.weight__timepoint : !vm.ref<!hal.fence>
      vm.return
    }
    vm.import private @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects}
    vm.import private @hal.ex.file.from_memory(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %access : i32, %buffer : !vm.buffer, %offset : i64, %length : i64, %flags : i32) -> !vm.ref<!hal.file>
    vm.import private @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
    vm.import private @hal.allocator.import(%allocator : !vm.ref<!hal.allocator>, %try : i32, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %source : !vm.buffer, %offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
    vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
    vm.import private @hal.buffer.subspan(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.buffer.length(%buffer : !vm.ref<!hal.buffer>) -> i64 attributes {nosideeffects}
    vm.import private @hal.buffer.load(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i32) -> i32
    vm.import private @hal.buffer.store(%value : i32, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i32)
    vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
    vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
    vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.buffer_view.element_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
    vm.import private @hal.buffer_view.encoding_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
    vm.import private @hal.buffer_view.rank(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
    vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
    vm.import private @hal.buffer_view.trace(%key : !vm.buffer, %operands : !vm.ref<!hal.buffer_view> ...)
    vm.import private @hal.channel.create(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %flags : i32, %id : !vm.buffer, %group : !vm.buffer, %rank : i32, %count : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects}
    vm.import private @hal.channel.split(%channel : !vm.ref<!hal.channel>, %color : i32, %key : i32, %flags : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects}
    vm.import private @hal.channel.rank_and_count(%channel : !vm.ref<!hal.channel>) -> (i32, i32) attributes {nosideeffects}
    vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer>
    vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.begin_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>, %label : !vm.buffer)
    vm.import private @hal.command_buffer.end_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
    vm.import private @hal.command_buffer.fill_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %pattern : i32, %pattern_length : i32)
    vm.import private @hal.command_buffer.copy_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64)
    vm.import private @hal.command_buffer.collective(%command_buffer : !vm.ref<!hal.command_buffer>, %channel : !vm.ref<!hal.channel>, %op : i32, %param : i32, %send_buffer : !vm.ref<!hal.buffer>, %send_offset : i64, %send_length : i64, %recv_buffer : !vm.ref<!hal.buffer>, %recv_offset : i64, %recv_length : i64, %element_count : i64)
    vm.import private @hal.command_buffer.push_constants(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %offset : i32, %values : i32 ...)
    vm.import private @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32)
    vm.import private @hal.command_buffer.dispatch.indirect(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroups_buffer : !vm.ref<!hal.buffer>, %workgroups_offset : i64)
    vm.import private @hal.command_buffer.execute.commands(%command_buffer : !vm.ref<!hal.command_buffer>, %commands : !vm.ref<!hal.command_buffer>, %bindings : tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects}
    vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
    vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
    vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
    vm.import private @hal.device.queue.dealloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %buffer : !vm.ref<!hal.buffer>)
    vm.import private @hal.device.queue.read(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_file : !vm.ref<!hal.file>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i32)
    vm.import private @hal.device.queue.write(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_file : !vm.ref<!hal.file>, %target_offset : i64, %length : i64, %flags : i32)
    vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
    vm.import private @hal.device.queue.flush(%device : !vm.ref<!hal.device>, %queue_affinity : i64)
    vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects}
    vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
    vm.import private @hal.fence.join(%fences : !vm.ref<!hal.fence> ...) -> !vm.ref<!hal.fence> attributes {nosideeffects}
    vm.import private @hal.fence.query(%fence : !vm.ref<!hal.fence>) -> i32
    vm.import private @hal.fence.signal(%fence : !vm.ref<!hal.fence>)
    vm.import private @hal.fence.fail(%fence : !vm.ref<!hal.fence>, %status : i32)
    vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
    vm.import private @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects}
    vm.rodata private @_utf8_input_0_5FD512E67BEFDEEC {alignment = 1 : i64} "input 0"
    vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
    vm.func private @main(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
      %c13 = vm.const.i32 13
      %c28 = vm.const.i32 28
      %c2 = vm.const.i32 2
      %c3 = vm.const.i32 3
      %c17 = vm.const.i32 17
      %c48 = vm.const.i32 48
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %zero = vm.const.i32.zero
      %c3075 = vm.const.i32 3075
      %c16 = vm.const.i32 16
      %c3_0 = vm.const.i64 3
      %c-1 = vm.const.i64 -1
      %c-1_1 = vm.const.i32 -1
      %zero_2 = vm.const.i64.zero
      %c128 = vm.const.i64 128
      %c16_3 = vm.const.i64 16
      %c12 = vm.const.i64 12
      %c553648160 = vm.const.i32 553648160
      %c1 = vm.const.i32 1
      %c4 = vm.const.i64 4
      %_params.weight__timepoint = vm.global.load.ref @_params.weight__timepoint : !vm.ref<!hal.fence>
      %_params.weight = vm.global.load.ref @_params.weight : !vm.ref<!hal.buffer>
      %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %_executable_main_dispatch_0 = vm.global.load.ref @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
      %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1, [%c4]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c16_3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %ref_6 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      %0 = vm.call.variadic @hal.fence.await(%c-1_1, [%_params.weight__timepoint]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      %ref_7 = vm.call @hal.device.queue.alloca(%ref_4, %c-1, %null, %ref_6, %zero, %c48, %c3075, %c12) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
      %1 = vm.call.variadic @hal.fence.await(%c-1_1, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      %ref_8 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
      %2 = vm.select.i64 %_device_query_0, %zero_2, %c-1 : i64
      %3 = vm.trunc.i64.i32 %2 : i64 -> i32
      vm.br_table %3 {
        default: ^bb2,
        0: ^bb1
      }
    ^bb1:  // pred: ^bb0
      vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_8, %_pipeline_layout_0, %zero, [(%zero, %zero, %ref, %zero_2, %c16_3), (%c1, %zero, %_params.weight, %zero_2, %c128), (%c2, %zero, %ref_7, %zero_2, %c12)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      vm.call @hal.command_buffer.dispatch(%ref_8, %_executable_main_dispatch_0, %zero, %c3, %c1, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
      vm.br ^bb2
    ^bb2:  // 2 preds: ^bb0, ^bb1
      vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
      %ref_9 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      %4 = vm.call.variadic @hal.fence.await(%c-1_1, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1, %null, %ref_9, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
      %5 = vm.call.variadic @hal.fence.await(%c-1_1, [%ref_9]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_br %5, ^bb4(%5 : i32), ^bb3
    ^bb3:  // pred: ^bb2
      %ref_10 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_2, %c12, %c553648160, %c1, [%c3_0]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_10 : !vm.ref<!hal.buffer_view>
    ^bb4(%6: i32):  // pred: ^bb2
      vm.fail %6, "failed to wait on timepoint"
    }
    vm.export @main attributes {iree.abi.stub}
  }
}


// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda], vm.toplevel} {
  vm.module public @LinearModule {
    vm.global.i32 private @_device_query_0 : i32
    vm.global.ref private @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.global.ref private @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
    vm.global.ref private mutable @_params.weight__timepoint : !vm.ref<!hal.fence>
    vm.global.ref private @_params.weight : !vm.ref<!hal.buffer>
    vm.rodata private @main_dispatch_0_cuda_nvptx_fb {alignment = 16 : i64, mime_type = "application/x-flatbuffers"} dense<"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vector<1302xi8>
    vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
    vm.rodata private @_utf8_cuda_nvptx_fb_B15B42B96FDBACC {alignment = 1 : i64} "cuda-nvptx-fb"
    vm.rodata private @_const {alignment = 64 : i64} #composite_of_128b
    vm.initializer {
      %c527363 = vm.const.i32 527363
      %c48 = vm.const.i32 48
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %null_0 = vm.const.ref.zero : !vm.ref<!hal.executable>
      %null_1 = vm.const.ref.zero : !vm.buffer
      %c2 = vm.const.i32 2
      %c7 = vm.const.i32 7
      %c1 = vm.const.i32 1
      %zero = vm.const.i64.zero
      %c128 = vm.const.i64 128
      %c-1 = vm.const.i64 -1
      %zero_2 = vm.const.i32.zero
      %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
      %_utf8_cuda_nvptx_fb_B15B42B96FDBACC = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
      %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
      %2 = vm.and.i32 %1, %c1 : i32
      %3 = vm.select.i32 %0#0, %2, %zero_2 : i32
      %ref_3 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero_2, [(%zero_2, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %zero_2)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
      %ref_4 = vm.call.variadic @hal.pipeline_layout.create(%ref, %zero_2, [%ref_3]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
      %4 = vm.select.i64 %3, %zero, %c-1 : i64
      %5 = vm.trunc.i64.i32 %4 : i64 -> i32
      vm.global.store.i32 %3, @_device_query_0 : i32
      vm.global.store.ref %ref_4, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      vm.br_table %5 {
        default: ^bb2,
        0: ^bb1
      }
    ^bb1:  // pred: ^bb0
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %main_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @main_dispatch_0_cuda_nvptx_fb : !vm.buffer
      %ref_5 = vm.call.variadic @hal.executable.create(%ref, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC, %main_dispatch_0_cuda_nvptx_fb, %null_1, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
      vm.br ^bb3(%ref_5 : !vm.ref<!hal.executable>)
    ^bb2:  // pred: ^bb0
      vm.br ^bb3(%null_0 : !vm.ref<!hal.executable>)
    ^bb3(%6: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
      %_const = vm.const.ref.rodata @_const : !vm.buffer
      %ref_6 = vm.call @hal.device.allocator(%ref) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %ref_7 = vm.call @hal.allocator.import(%ref_6, %c1, %c-1, %c48, %c527363, %_const, %zero, %c128) : (!vm.ref<!hal.allocator>, i32, i64, i32, i32, !vm.buffer, i64, i64) -> !vm.ref<!hal.buffer>
      %rnz = vm.cmp.nz.ref %ref_7 : !vm.ref<!hal.buffer>
      vm.global.store.ref %6, @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
      vm.cond_br %rnz, ^bb5(%null, %ref_7 : !vm.ref<!hal.fence>, !vm.ref<!hal.buffer>), ^bb4
    ^bb4:  // pred: ^bb3
      %ref_8 = vm.call @hal.allocator.allocate(%ref_6, %c-1, %c48, %c527363, %c128) : (!vm.ref<!hal.allocator>, i64, i32, i32, i64) -> !vm.ref<!hal.buffer>
      %ref_9 = vm.call @hal.ex.file.from_memory(%ref, %c-1, %c1, %_const, %zero, %c128, %zero_2) : (!vm.ref<!hal.device>, i64, i32, !vm.buffer, i64, i64, i32) -> !vm.ref<!hal.file>
      %ref_10 = vm.call @hal.fence.create(%ref, %zero_2) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      vm.call @hal.device.queue.read(%ref, %c-1, %null, %ref_10, %ref_9, %zero, %ref_8, %zero, %c128, %zero_2) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.file>, i64, !vm.ref<!hal.buffer>, i64, i64, i32) -> ()
      vm.br ^bb5(%ref_10, %ref_8 : !vm.ref<!hal.fence>, !vm.ref<!hal.buffer>)
    ^bb5(%7: !vm.ref<!hal.fence>, %8: !vm.ref<!hal.buffer>):  // 2 preds: ^bb3, ^bb4
      vm.global.store.ref %8, @_params.weight : !vm.ref<!hal.buffer>
      vm.global.store.ref %7, @_params.weight__timepoint : !vm.ref<!hal.fence>
      vm.return
    }
    vm.import private @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects}
    vm.import private @hal.ex.file.from_memory(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %access : i32, %buffer : !vm.buffer, %offset : i64, %length : i64, %flags : i32) -> !vm.ref<!hal.file>
    vm.import private @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
    vm.import private @hal.allocator.import(%allocator : !vm.ref<!hal.allocator>, %try : i32, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %source : !vm.buffer, %offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
    vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
    vm.import private @hal.buffer.subspan(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.buffer.length(%buffer : !vm.ref<!hal.buffer>) -> i64 attributes {nosideeffects}
    vm.import private @hal.buffer.load(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i32) -> i32
    vm.import private @hal.buffer.store(%value : i32, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i32)
    vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
    vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
    vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.buffer_view.element_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
    vm.import private @hal.buffer_view.encoding_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
    vm.import private @hal.buffer_view.rank(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
    vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
    vm.import private @hal.buffer_view.trace(%key : !vm.buffer, %operands : !vm.ref<!hal.buffer_view> ...)
    vm.import private @hal.channel.create(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %flags : i32, %id : !vm.buffer, %group : !vm.buffer, %rank : i32, %count : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects}
    vm.import private @hal.channel.split(%channel : !vm.ref<!hal.channel>, %color : i32, %key : i32, %flags : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects}
    vm.import private @hal.channel.rank_and_count(%channel : !vm.ref<!hal.channel>) -> (i32, i32) attributes {nosideeffects}
    vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer>
    vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.begin_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>, %label : !vm.buffer)
    vm.import private @hal.command_buffer.end_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
    vm.import private @hal.command_buffer.fill_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %pattern : i32, %pattern_length : i32)
    vm.import private @hal.command_buffer.copy_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64)
    vm.import private @hal.command_buffer.collective(%command_buffer : !vm.ref<!hal.command_buffer>, %channel : !vm.ref<!hal.channel>, %op : i32, %param : i32, %send_buffer : !vm.ref<!hal.buffer>, %send_offset : i64, %send_length : i64, %recv_buffer : !vm.ref<!hal.buffer>, %recv_offset : i64, %recv_length : i64, %element_count : i64)
    vm.import private @hal.command_buffer.push_constants(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %offset : i32, %values : i32 ...)
    vm.import private @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32)
    vm.import private @hal.command_buffer.dispatch.indirect(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroups_buffer : !vm.ref<!hal.buffer>, %workgroups_offset : i64)
    vm.import private @hal.command_buffer.execute.commands(%command_buffer : !vm.ref<!hal.command_buffer>, %commands : !vm.ref<!hal.command_buffer>, %bindings : tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects}
    vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
    vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
    vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
    vm.import private @hal.device.queue.dealloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %buffer : !vm.ref<!hal.buffer>)
    vm.import private @hal.device.queue.read(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_file : !vm.ref<!hal.file>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i32)
    vm.import private @hal.device.queue.write(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_file : !vm.ref<!hal.file>, %target_offset : i64, %length : i64, %flags : i32)
    vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
    vm.import private @hal.device.queue.flush(%device : !vm.ref<!hal.device>, %queue_affinity : i64)
    vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects}
    vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
    vm.import private @hal.fence.join(%fences : !vm.ref<!hal.fence> ...) -> !vm.ref<!hal.fence> attributes {nosideeffects}
    vm.import private @hal.fence.query(%fence : !vm.ref<!hal.fence>) -> i32
    vm.import private @hal.fence.signal(%fence : !vm.ref<!hal.fence>)
    vm.import private @hal.fence.fail(%fence : !vm.ref<!hal.fence>, %status : i32)
    vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
    vm.import private @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects}
    vm.rodata private @_utf8_input_0_5FD512E67BEFDEEC {alignment = 1 : i64} "input 0"
    vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
    vm.func private @main(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
      %c13 = vm.const.i32 13
      %c28 = vm.const.i32 28
      %c2 = vm.const.i32 2
      %c3 = vm.const.i32 3
      %c17 = vm.const.i32 17
      %c48 = vm.const.i32 48
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %zero = vm.const.i32.zero
      %c3075 = vm.const.i32 3075
      %c16 = vm.const.i32 16
      %c3_0 = vm.const.i64 3
      %c-1 = vm.const.i64 -1
      %c-1_1 = vm.const.i32 -1
      %zero_2 = vm.const.i64.zero
      %c128 = vm.const.i64 128
      %c16_3 = vm.const.i64 16
      %c12 = vm.const.i64 12
      %c553648160 = vm.const.i32 553648160
      %c1 = vm.const.i32 1
      %c4 = vm.const.i64 4
      %_params.weight__timepoint = vm.global.load.ref @_params.weight__timepoint : !vm.ref<!hal.fence>
      %_params.weight = vm.global.load.ref @_params.weight : !vm.ref<!hal.buffer>
      %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %_executable_main_dispatch_0 = vm.global.load.ref @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
      %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1, [%c4]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c16_3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %ref_6 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      %0 = vm.call.variadic @hal.fence.await(%c-1_1, [%_params.weight__timepoint]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      %ref_7 = vm.call @hal.device.queue.alloca(%ref_4, %c-1, %null, %ref_6, %zero, %c48, %c3075, %c12) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
      %1 = vm.call.variadic @hal.fence.await(%c-1_1, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      %ref_8 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
      %2 = vm.select.i64 %_device_query_0, %zero_2, %c-1 : i64
      %3 = vm.trunc.i64.i32 %2 : i64 -> i32
      vm.br_table %3 {
        default: ^bb2,
        0: ^bb1
      }
    ^bb1:  // pred: ^bb0
      vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_8, %_pipeline_layout_0, %zero, [(%zero, %zero, %ref, %zero_2, %c16_3), (%c1, %zero, %_params.weight, %zero_2, %c128), (%c2, %zero, %ref_7, %zero_2, %c12)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      vm.call @hal.command_buffer.dispatch(%ref_8, %_executable_main_dispatch_0, %zero, %c3, %c1, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
      vm.br ^bb2
    ^bb2:  // 2 preds: ^bb0, ^bb1
      vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
      %ref_9 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      %4 = vm.call.variadic @hal.fence.await(%c-1_1, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1, %null, %ref_9, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
      %5 = vm.call.variadic @hal.fence.await(%c-1_1, [%ref_9]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_br %5, ^bb4, ^bb3
    ^bb3:  // pred: ^bb2
      %ref_10 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_2, %c12, %c553648160, %c1, [%c3_0]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_10 : !vm.ref<!hal.buffer_view>
    ^bb4:  // pred: ^bb2
      vm.fail %5, "failed to wait on timepoint"
    }
    vm.export @main attributes {iree.abi.stub}
  }
}


// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda], vm.toplevel} {
  vm.module public @LinearModule {
    vm.global.i32 private @_device_query_0 : i32
    vm.global.ref private @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.global.ref private @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
    vm.global.ref private mutable @_params.weight__timepoint : !vm.ref<!hal.fence>
    vm.global.ref private @_params.weight : !vm.ref<!hal.buffer>
    vm.rodata private @main_dispatch_0_cuda_nvptx_fb {alignment = 16 : i64, mime_type = "application/x-flatbuffers"} dense<"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vector<1302xi8>
    vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
    vm.rodata private @_utf8_cuda_nvptx_fb_B15B42B96FDBACC {alignment = 1 : i64} "cuda-nvptx-fb"
    vm.rodata private @_const {alignment = 64 : i64} #composite_of_128b
    vm.initializer {
      %c527363 = vm.const.i32 527363
      %c48 = vm.const.i32 48
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %null_0 = vm.const.ref.zero : !vm.ref<!hal.executable>
      %null_1 = vm.const.ref.zero : !vm.buffer
      %c2 = vm.const.i32 2
      %c7 = vm.const.i32 7
      %c1 = vm.const.i32 1
      %zero = vm.const.i64.zero
      %c128 = vm.const.i64 128
      %c-1 = vm.const.i64 -1
      %zero_2 = vm.const.i32.zero
      %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
      %_utf8_cuda_nvptx_fb_B15B42B96FDBACC = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
      %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
      %2 = vm.and.i32 %1, %c1 : i32
      %3 = vm.select.i32 %0#0, %2, %zero_2 : i32
      %ref_3 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero_2, [(%zero_2, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %zero_2)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
      %ref_4 = vm.call.variadic @hal.pipeline_layout.create(%ref, %zero_2, [%ref_3]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
      %4 = vm.select.i64 %3, %zero, %c-1 : i64
      %5 = vm.trunc.i64.i32 %4 : i64 -> i32
      vm.global.store.i32 %3, @_device_query_0 : i32
      vm.global.store.ref %ref_4, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      vm.br_table %5 {
        default: ^bb2,
        0: ^bb1
      }
    ^bb1:  // pred: ^bb0
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %main_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @main_dispatch_0_cuda_nvptx_fb : !vm.buffer
      %ref_5 = vm.call.variadic @hal.executable.create(%ref, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC, %main_dispatch_0_cuda_nvptx_fb, %null_1, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
      vm.br ^bb3(%ref_5 : !vm.ref<!hal.executable>)
    ^bb2:  // pred: ^bb0
      vm.br ^bb3(%null_0 : !vm.ref<!hal.executable>)
    ^bb3(%6: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
      %_const = vm.const.ref.rodata @_const : !vm.buffer
      %ref_6 = vm.call @hal.device.allocator(%ref) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %ref_7 = vm.call @hal.allocator.import(%ref_6, %c1, %c-1, %c48, %c527363, %_const, %zero, %c128) : (!vm.ref<!hal.allocator>, i32, i64, i32, i32, !vm.buffer, i64, i64) -> !vm.ref<!hal.buffer>
      %rnz = vm.cmp.nz.ref %ref_7 : !vm.ref<!hal.buffer>
      vm.global.store.ref %6, @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
      vm.cond_br %rnz, ^bb5(%null, %ref_7 : !vm.ref<!hal.fence>, !vm.ref<!hal.buffer>), ^bb4
    ^bb4:  // pred: ^bb3
      %ref_8 = vm.call @hal.allocator.allocate(%ref_6, %c-1, %c48, %c527363, %c128) : (!vm.ref<!hal.allocator>, i64, i32, i32, i64) -> !vm.ref<!hal.buffer>
      %ref_9 = vm.call @hal.ex.file.from_memory(%ref, %c-1, %c1, %_const, %zero, %c128, %zero_2) : (!vm.ref<!hal.device>, i64, i32, !vm.buffer, i64, i64, i32) -> !vm.ref<!hal.file>
      %ref_10 = vm.call @hal.fence.create(%ref, %zero_2) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      vm.call @hal.device.queue.read(%ref, %c-1, %null, %ref_10, %ref_9, %zero, %ref_8, %zero, %c128, %zero_2) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.file>, i64, !vm.ref<!hal.buffer>, i64, i64, i32) -> ()
      vm.br ^bb5(%ref_10, %ref_8 : !vm.ref<!hal.fence>, !vm.ref<!hal.buffer>)
    ^bb5(%7: !vm.ref<!hal.fence>, %8: !vm.ref<!hal.buffer>):  // 2 preds: ^bb3, ^bb4
      vm.global.store.ref %8, @_params.weight : !vm.ref<!hal.buffer>
      vm.global.store.ref %7, @_params.weight__timepoint : !vm.ref<!hal.fence>
      vm.return
    }
    vm.import private @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects}
    vm.import private @hal.ex.file.from_memory(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %access : i32, %buffer : !vm.buffer, %offset : i64, %length : i64, %flags : i32) -> !vm.ref<!hal.file>
    vm.import private @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
    vm.import private @hal.allocator.import(%allocator : !vm.ref<!hal.allocator>, %try : i32, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %source : !vm.buffer, %offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
    vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
    vm.import private @hal.buffer.subspan(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.buffer.length(%buffer : !vm.ref<!hal.buffer>) -> i64 attributes {nosideeffects}
    vm.import private @hal.buffer.load(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i32) -> i32
    vm.import private @hal.buffer.store(%value : i32, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i32)
    vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
    vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
    vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.buffer_view.element_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
    vm.import private @hal.buffer_view.encoding_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
    vm.import private @hal.buffer_view.rank(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
    vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
    vm.import private @hal.buffer_view.trace(%key : !vm.buffer, %operands : !vm.ref<!hal.buffer_view> ...)
    vm.import private @hal.channel.create(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %flags : i32, %id : !vm.buffer, %group : !vm.buffer, %rank : i32, %count : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects}
    vm.import private @hal.channel.split(%channel : !vm.ref<!hal.channel>, %color : i32, %key : i32, %flags : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects}
    vm.import private @hal.channel.rank_and_count(%channel : !vm.ref<!hal.channel>) -> (i32, i32) attributes {nosideeffects}
    vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer>
    vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.begin_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>, %label : !vm.buffer)
    vm.import private @hal.command_buffer.end_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
    vm.import private @hal.command_buffer.fill_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %pattern : i32, %pattern_length : i32)
    vm.import private @hal.command_buffer.copy_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64)
    vm.import private @hal.command_buffer.collective(%command_buffer : !vm.ref<!hal.command_buffer>, %channel : !vm.ref<!hal.channel>, %op : i32, %param : i32, %send_buffer : !vm.ref<!hal.buffer>, %send_offset : i64, %send_length : i64, %recv_buffer : !vm.ref<!hal.buffer>, %recv_offset : i64, %recv_length : i64, %element_count : i64)
    vm.import private @hal.command_buffer.push_constants(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %offset : i32, %values : i32 ...)
    vm.import private @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32)
    vm.import private @hal.command_buffer.dispatch.indirect(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroups_buffer : !vm.ref<!hal.buffer>, %workgroups_offset : i64)
    vm.import private @hal.command_buffer.execute.commands(%command_buffer : !vm.ref<!hal.command_buffer>, %commands : !vm.ref<!hal.command_buffer>, %bindings : tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects}
    vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
    vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
    vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
    vm.import private @hal.device.queue.dealloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %buffer : !vm.ref<!hal.buffer>)
    vm.import private @hal.device.queue.read(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_file : !vm.ref<!hal.file>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i32)
    vm.import private @hal.device.queue.write(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_file : !vm.ref<!hal.file>, %target_offset : i64, %length : i64, %flags : i32)
    vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
    vm.import private @hal.device.queue.flush(%device : !vm.ref<!hal.device>, %queue_affinity : i64)
    vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects}
    vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
    vm.import private @hal.fence.join(%fences : !vm.ref<!hal.fence> ...) -> !vm.ref<!hal.fence> attributes {nosideeffects}
    vm.import private @hal.fence.query(%fence : !vm.ref<!hal.fence>) -> i32
    vm.import private @hal.fence.signal(%fence : !vm.ref<!hal.fence>)
    vm.import private @hal.fence.fail(%fence : !vm.ref<!hal.fence>, %status : i32)
    vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
    vm.import private @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects}
    vm.rodata private @_utf8_input_0_5FD512E67BEFDEEC {alignment = 1 : i64} "input 0"
    vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
    vm.func private @main(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
      %c13 = vm.const.i32 13
      %c28 = vm.const.i32 28
      %c2 = vm.const.i32 2
      %c3 = vm.const.i32 3
      %c17 = vm.const.i32 17
      %c48 = vm.const.i32 48
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %zero = vm.const.i32.zero
      %c3075 = vm.const.i32 3075
      %c16 = vm.const.i32 16
      %c3_0 = vm.const.i64 3
      %c-1 = vm.const.i64 -1
      %c-1_1 = vm.const.i32 -1
      %zero_2 = vm.const.i64.zero
      %c128 = vm.const.i64 128
      %c16_3 = vm.const.i64 16
      %c12 = vm.const.i64 12
      %c553648160 = vm.const.i32 553648160
      %c1 = vm.const.i32 1
      %c4 = vm.const.i64 4
      %_params.weight__timepoint = vm.global.load.ref @_params.weight__timepoint : !vm.ref<!hal.fence>
      %_params.weight = vm.global.load.ref @_params.weight : !vm.ref<!hal.buffer>
      %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %_executable_main_dispatch_0 = vm.global.load.ref @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
      %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1, [%c4]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c16_3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %ref_6 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      %0 = vm.call.variadic @hal.fence.await(%c-1_1, [%_params.weight__timepoint]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      %ref_7 = vm.call @hal.device.queue.alloca(%ref_4, %c-1, %null, %ref_6, %zero, %c48, %c3075, %c12) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
      %1 = vm.call.variadic @hal.fence.await(%c-1_1, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      %ref_8 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
      %2 = vm.select.i64 %_device_query_0, %zero_2, %c-1 : i64
      %3 = vm.trunc.i64.i32 %2 : i64 -> i32
      vm.br_table %3 {
        default: ^bb2,
        0: ^bb1
      }
    ^bb1:  // pred: ^bb0
      vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_8, %_pipeline_layout_0, %zero, [(%zero, %zero, %ref, %zero_2, %c16_3), (%c1, %zero, %_params.weight, %zero_2, %c128), (%c2, %zero, %ref_7, %zero_2, %c12)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      vm.call @hal.command_buffer.dispatch(%ref_8, %_executable_main_dispatch_0, %zero, %c3, %c1, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
      vm.br ^bb2
    ^bb2:  // 2 preds: ^bb0, ^bb1
      vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
      %ref_9 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      %4 = vm.call.variadic @hal.fence.await(%c-1_1, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1, %null, %ref_9, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
      %5 = vm.call.variadic @hal.fence.await(%c-1_1, [%ref_9]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_br %5, ^bb4, ^bb3
    ^bb3:  // pred: ^bb2
      %ref_10 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_2, %c12, %c553648160, %c1, [%c3_0]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_10 : !vm.ref<!hal.buffer_view>
    ^bb4:  // pred: ^bb2
      vm.fail %5, "failed to wait on timepoint"
    }
    vm.export @main attributes {iree.abi.stub}
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda], vm.toplevel} {
  vm.module public @LinearModule {
    vm.global.i32 private @_device_query_0 : i32
    vm.global.ref private @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.global.ref private @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
    vm.global.ref private mutable @_params.weight__timepoint : !vm.ref<!hal.fence>
    vm.global.ref private @_params.weight : !vm.ref<!hal.buffer>
    vm.rodata private @main_dispatch_0_cuda_nvptx_fb {alignment = 16 : i64, mime_type = "application/x-flatbuffers"} dense<"0x080000004355444100FBFFFF1C0000005000000044000000580000000400000001000000C00400000100000004000000200000006D61696E5F64697370617463685F305F6D61746D756C5F31783378345F663332000000000100000000000000010000000100000003000000010000006F0400002F2F0A2F2F2047656E657261746564206279204C4C564D204E56505458204261636B2D456E640A2F2F0A0A2E76657273696F6E20372E350A2E74617267657420736D5F37350A2E616464726573735F73697A652036340A0A092F2F202E676C6F626C096D61696E5F64697370617463685F305F6D61746D756C5F31783378345F6633320A0A2E76697369626C65202E656E747279206D61696E5F64697370617463685F305F6D61746D756C5F31783378345F663332280A092E706172616D202E753634206D61696E5F64697370617463685F305F6D61746D756C5F31783378345F6633325F706172616D5F302C0A092E706172616D202E753634206D61696E5F64697370617463685F305F6D61746D756C5F31783378345F6633325F706172616D5F312C0A092E706172616D202E753634206D61696E5F64697370617463685F305F6D61746D756C5F31783378345F6633325F706172616D5F320A290A2E6D61786E74696420312C20332C20310A7B0A092E726567202E623332200925723C323E3B0A092E726567202E663332200925663C31343E3B0A092E726567202E62363420092572643C373E3B0A0A096C642E706172616D2E7536342009257264312C205B6D61696E5F64697370617463685F305F6D61746D756C5F31783378345F6633325F706172616D5F305D3B0A096C642E706172616D2E7536342009257264322C205B6D61696E5F64697370617463685F305F6D61746D756C5F31783378345F6633325F706172616D5F315D3B0A096C642E706172616D2E7536342009257264332C205B6D61696E5F64697370617463685F305F6D61746D756C5F31783378345F6633325F706172616D5F325D3B0A096D6F762E75333220092572312C202563746169642E783B0A096C642E676C6F62616C2E6E632E76342E66333220097B2566312C202566322C202566332C202566347D2C205B257264315D3B0A096D756C2E776964652E7533322009257264342C202572312C20343B0A096164642E7336342009257264352C20257264322C20257264343B0A096C642E676C6F62616C2E6E632E66333220092566352C205B257264355D3B0A096C642E676C6F62616C2E6E632E66333220092566362C205B257264352B31325D3B0A096C642E676C6F62616C2E6E632E66333220092566372C205B257264352B32345D3B0A096C642E676C6F62616C2E6E632E66333220092566382C205B257264352B33365D3B0A096C642E676C6F62616C2E6E632E66333220092566392C205B257264352B36345D3B0A09666D612E726E2E6633322009256631302C202566312C202566352C202566393B0A09666D612E726E2E6633322009256631312C202566322C202566362C20256631303B0A09666D612E726E2E6633322009256631322C202566332C202566372C20256631313B0A09666D612E726E2E6633322009256631332C202566342C202566382C20256631323B0A096164642E7336342009257264362C20257264332C20257264343B0A0973742E676C6F62616C2E66333220095B257264365D2C20256631333B0A097265743B0A0A7D0A00E4FFFFFF08000000040000000A000000696E7075742E6D6C6972000008000C00040008000E001800040008000C0010001400"> : vector<1302xi8>
    vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
    vm.rodata private @_utf8_cuda_nvptx_fb_B15B42B96FDBACC {alignment = 1 : i64} "cuda-nvptx-fb"
    vm.rodata private @_const {alignment = 64 : i64} #composite_of_128b
    vm.initializer {
      %c527363 = vm.const.i32 527363
      %c48 = vm.const.i32 48
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %null_0 = vm.const.ref.zero : !vm.ref<!hal.executable>
      %null_1 = vm.const.ref.zero : !vm.buffer
      %c2 = vm.const.i32 2
      %c7 = vm.const.i32 7
      %c1 = vm.const.i32 1
      %zero = vm.const.i64.zero
      %c128 = vm.const.i64 128
      %c-1 = vm.const.i64 -1
      %zero_2 = vm.const.i32.zero
      %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
      %_utf8_cuda_nvptx_fb_B15B42B96FDBACC = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
      %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
      %2 = vm.and.i32 %1, %c1 : i32
      %3 = vm.select.i32 %0#0, %2, %zero_2 : i32
      %ref_3 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero_2, [(%zero_2, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %zero_2)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
      %ref_4 = vm.call.variadic @hal.pipeline_layout.create(%ref, %zero_2, [%ref_3]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
      %4 = vm.select.i64 %3, %zero, %c-1 : i64
      %5 = vm.trunc.i64.i32 %4 : i64 -> i32
      vm.global.store.i32 %3, @_device_query_0 : i32
      vm.global.store.ref %ref_4, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      vm.br_table %5 {
        default: ^bb2,
        0: ^bb1
      }
    ^bb1:  // pred: ^bb0
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %main_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @main_dispatch_0_cuda_nvptx_fb : !vm.buffer
      %ref_5 = vm.call.variadic @hal.executable.create(%ref, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC, %main_dispatch_0_cuda_nvptx_fb, %null_1, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
      vm.br ^bb3(%ref_5 : !vm.ref<!hal.executable>)
    ^bb2:  // pred: ^bb0
      vm.br ^bb3(%null_0 : !vm.ref<!hal.executable>)
    ^bb3(%6: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
      %_const = vm.const.ref.rodata @_const : !vm.buffer
      %ref_6 = vm.call @hal.device.allocator(%ref) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %ref_7 = vm.call @hal.allocator.import(%ref_6, %c1, %c-1, %c48, %c527363, %_const, %zero, %c128) : (!vm.ref<!hal.allocator>, i32, i64, i32, i32, !vm.buffer, i64, i64) -> !vm.ref<!hal.buffer>
      %rnz = vm.cmp.nz.ref %ref_7 : !vm.ref<!hal.buffer>
      vm.global.store.ref %6, @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
      vm.cond_br %rnz, ^bb5(%null, %ref_7 : !vm.ref<!hal.fence>, !vm.ref<!hal.buffer>), ^bb4
    ^bb4:  // pred: ^bb3
      %ref_8 = vm.call @hal.allocator.allocate(%ref_6, %c-1, %c48, %c527363, %c128) : (!vm.ref<!hal.allocator>, i64, i32, i32, i64) -> !vm.ref<!hal.buffer>
      %ref_9 = vm.call @hal.ex.file.from_memory(%ref, %c-1, %c1, %_const, %zero, %c128, %zero_2) : (!vm.ref<!hal.device>, i64, i32, !vm.buffer, i64, i64, i32) -> !vm.ref<!hal.file>
      %ref_10 = vm.call @hal.fence.create(%ref, %zero_2) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      vm.call @hal.device.queue.read(%ref, %c-1, %null, %ref_10, %ref_9, %zero, %ref_8, %zero, %c128, %zero_2) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.file>, i64, !vm.ref<!hal.buffer>, i64, i64, i32) -> ()
      vm.br ^bb5(%ref_10, %ref_8 : !vm.ref<!hal.fence>, !vm.ref<!hal.buffer>)
    ^bb5(%7: !vm.ref<!hal.fence>, %8: !vm.ref<!hal.buffer>):  // 2 preds: ^bb3, ^bb4
      vm.global.store.ref %8, @_params.weight : !vm.ref<!hal.buffer>
      vm.global.store.ref %7, @_params.weight__timepoint : !vm.ref<!hal.fence>
      vm.return
    }
    vm.import private @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects}
    vm.import private @hal.ex.file.from_memory(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %access : i32, %buffer : !vm.buffer, %offset : i64, %length : i64, %flags : i32) -> !vm.ref<!hal.file>
    vm.import private @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
    vm.import private @hal.allocator.import(%allocator : !vm.ref<!hal.allocator>, %try : i32, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %source : !vm.buffer, %offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
    vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
    vm.import private @hal.buffer.subspan(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.buffer.length(%buffer : !vm.ref<!hal.buffer>) -> i64 attributes {nosideeffects}
    vm.import private @hal.buffer.load(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i32) -> i32
    vm.import private @hal.buffer.store(%value : i32, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i32)
    vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
    vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
    vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.buffer_view.element_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
    vm.import private @hal.buffer_view.encoding_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
    vm.import private @hal.buffer_view.rank(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
    vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
    vm.import private @hal.buffer_view.trace(%key : !vm.buffer, %operands : !vm.ref<!hal.buffer_view> ...)
    vm.import private @hal.channel.create(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %flags : i32, %id : !vm.buffer, %group : !vm.buffer, %rank : i32, %count : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects}
    vm.import private @hal.channel.split(%channel : !vm.ref<!hal.channel>, %color : i32, %key : i32, %flags : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects}
    vm.import private @hal.channel.rank_and_count(%channel : !vm.ref<!hal.channel>) -> (i32, i32) attributes {nosideeffects}
    vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer>
    vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.begin_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>, %label : !vm.buffer)
    vm.import private @hal.command_buffer.end_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
    vm.import private @hal.command_buffer.fill_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %pattern : i32, %pattern_length : i32)
    vm.import private @hal.command_buffer.copy_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64)
    vm.import private @hal.command_buffer.collective(%command_buffer : !vm.ref<!hal.command_buffer>, %channel : !vm.ref<!hal.channel>, %op : i32, %param : i32, %send_buffer : !vm.ref<!hal.buffer>, %send_offset : i64, %send_length : i64, %recv_buffer : !vm.ref<!hal.buffer>, %recv_offset : i64, %recv_length : i64, %element_count : i64)
    vm.import private @hal.command_buffer.push_constants(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %offset : i32, %values : i32 ...)
    vm.import private @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32)
    vm.import private @hal.command_buffer.dispatch.indirect(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroups_buffer : !vm.ref<!hal.buffer>, %workgroups_offset : i64)
    vm.import private @hal.command_buffer.execute.commands(%command_buffer : !vm.ref<!hal.command_buffer>, %commands : !vm.ref<!hal.command_buffer>, %bindings : tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects}
    vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
    vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
    vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
    vm.import private @hal.device.queue.dealloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %buffer : !vm.ref<!hal.buffer>)
    vm.import private @hal.device.queue.read(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_file : !vm.ref<!hal.file>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i32)
    vm.import private @hal.device.queue.write(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_file : !vm.ref<!hal.file>, %target_offset : i64, %length : i64, %flags : i32)
    vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
    vm.import private @hal.device.queue.flush(%device : !vm.ref<!hal.device>, %queue_affinity : i64)
    vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects}
    vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
    vm.import private @hal.fence.join(%fences : !vm.ref<!hal.fence> ...) -> !vm.ref<!hal.fence> attributes {nosideeffects}
    vm.import private @hal.fence.query(%fence : !vm.ref<!hal.fence>) -> i32
    vm.import private @hal.fence.signal(%fence : !vm.ref<!hal.fence>)
    vm.import private @hal.fence.fail(%fence : !vm.ref<!hal.fence>, %status : i32)
    vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
    vm.import private @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects}
    vm.rodata private @_utf8_input_0_5FD512E67BEFDEEC {alignment = 1 : i64} "input 0"
    vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
    vm.func private @main(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
      %c13 = vm.const.i32 13
      %c28 = vm.const.i32 28
      %c2 = vm.const.i32 2
      %c3 = vm.const.i32 3
      %c17 = vm.const.i32 17
      %c48 = vm.const.i32 48
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %zero = vm.const.i32.zero
      %c3075 = vm.const.i32 3075
      %c16 = vm.const.i32 16
      %c3_0 = vm.const.i64 3
      %c-1 = vm.const.i64 -1
      %c-1_1 = vm.const.i32 -1
      %zero_2 = vm.const.i64.zero
      %c128 = vm.const.i64 128
      %c16_3 = vm.const.i64 16
      %c12 = vm.const.i64 12
      %c553648160 = vm.const.i32 553648160
      %c1 = vm.const.i32 1
      %c4 = vm.const.i64 4
      %_params.weight__timepoint = vm.global.load.ref @_params.weight__timepoint : !vm.ref<!hal.fence>
      %_params.weight = vm.global.load.ref @_params.weight : !vm.ref<!hal.buffer>
      %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %_executable_main_dispatch_0 = vm.global.load.ref @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
      %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1, [%c4]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c16_3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %ref_6 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      %0 = vm.call.variadic @hal.fence.await(%c-1_1, [%_params.weight__timepoint]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      %ref_7 = vm.call @hal.device.queue.alloca(%ref_4, %c-1, %null, %ref_6, %zero, %c48, %c3075, %c12) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
      %1 = vm.call.variadic @hal.fence.await(%c-1_1, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      %ref_8 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
      %2 = vm.select.i64 %_device_query_0, %zero_2, %c-1 : i64
      %3 = vm.trunc.i64.i32 %2 : i64 -> i32
      vm.br_table %3 {
        default: ^bb2,
        0: ^bb1
      }
    ^bb1:  // pred: ^bb0
      vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_8, %_pipeline_layout_0, %zero, [(%zero, %zero, %ref, %zero_2, %c16_3), (%c1, %zero, %_params.weight, %zero_2, %c128), (%c2, %zero, %ref_7, %zero_2, %c12)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      vm.call @hal.command_buffer.dispatch(%ref_8, %_executable_main_dispatch_0, %zero, %c3, %c1, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
      vm.br ^bb2
    ^bb2:  // 2 preds: ^bb0, ^bb1
      vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
      %ref_9 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      %4 = vm.call.variadic @hal.fence.await(%c-1_1, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1, %null, %ref_9, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
      %5 = vm.call.variadic @hal.fence.await(%c-1_1, [%ref_9]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_br %5, ^bb4, ^bb3
    ^bb3:  // pred: ^bb2
      %ref_10 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_2, %c12, %c553648160, %c1, [%c3_0]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_10 : !vm.ref<!hal.buffer_view>
    ^bb4:  // pred: ^bb2
      vm.fail %5, "failed to wait on timepoint"
    }
    vm.export @main attributes {iree.abi.stub}
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::VM::ResolveRodataLoadsPass (iree-vm-resolve-rodata-loads) //----- //
vm.module public @LinearModule {
  vm.global.i32 private @_device_query_0 : i32
  vm.global.ref private @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
  vm.global.ref private @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
  vm.global.ref private mutable @_params.weight__timepoint : !vm.ref<!hal.fence>
  vm.global.ref private @_params.weight : !vm.ref<!hal.buffer>
  vm.rodata private @main_dispatch_0_cuda_nvptx_fb {alignment = 16 : i64, mime_type = "application/x-flatbuffers"} dense<"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vector<1302xi8>
  vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
  vm.rodata private @_utf8_cuda_nvptx_fb_B15B42B96FDBACC {alignment = 1 : i64} "cuda-nvptx-fb"
  vm.rodata private @_const {alignment = 64 : i64} #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
  vm.initializer {
    %c527363 = vm.const.i32 527363
    %c48 = vm.const.i32 48
    %null = vm.const.ref.zero : !vm.ref<!hal.fence>
    %null_0 = vm.const.ref.zero : !vm.ref<!hal.executable>
    %null_1 = vm.const.ref.zero : !vm.buffer
    %c2 = vm.const.i32 2
    %c7 = vm.const.i32 7
    %c1 = vm.const.i32 1
    %zero = vm.const.i64.zero
    %c128 = vm.const.i64 128
    %c-1 = vm.const.i64 -1
    %zero_2 = vm.const.i32.zero
    %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
    %_utf8_cuda_nvptx_fb_B15B42B96FDBACC = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
    %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
    %2 = vm.and.i32 %1, %c1 : i32
    %3 = vm.select.i32 %0#0, %2, %zero_2 : i32
    %ref_3 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero_2, [(%zero_2, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %zero_2)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
    %ref_4 = vm.call.variadic @hal.pipeline_layout.create(%ref, %zero_2, [%ref_3]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
    %4 = vm.select.i64 %3, %zero, %c-1 : i64
    %5 = vm.trunc.i64.i32 %4 : i64 -> i32
    vm.global.store.i32 %3, @_device_query_0 : i32
    vm.global.store.ref %ref_4, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.br_table %5 {
      default: ^bb2,
      0: ^bb1
    }
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %main_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @main_dispatch_0_cuda_nvptx_fb : !vm.buffer
    %ref_5 = vm.call.variadic @hal.executable.create(%ref, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC, %main_dispatch_0_cuda_nvptx_fb, %null_1, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
    vm.br ^bb3(%ref_5 : !vm.ref<!hal.executable>)
  ^bb2:  // pred: ^bb0
    vm.br ^bb3(%null_0 : !vm.ref<!hal.executable>)
  ^bb3(%6: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
    %_const = vm.const.ref.rodata @_const : !vm.buffer
    %ref_6 = vm.call @hal.device.allocator(%ref) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    %ref_7 = vm.call @hal.allocator.import(%ref_6, %c1, %c-1, %c48, %c527363, %_const, %zero, %c128) : (!vm.ref<!hal.allocator>, i32, i64, i32, i32, !vm.buffer, i64, i64) -> !vm.ref<!hal.buffer>
    %rnz = vm.cmp.nz.ref %ref_7 : !vm.ref<!hal.buffer>
    vm.global.store.ref %6, @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
    vm.cond_br %rnz, ^bb5(%null, %ref_7 : !vm.ref<!hal.fence>, !vm.ref<!hal.buffer>), ^bb4
  ^bb4:  // pred: ^bb3
    %ref_8 = vm.call @hal.allocator.allocate(%ref_6, %c-1, %c48, %c527363, %c128) : (!vm.ref<!hal.allocator>, i64, i32, i32, i64) -> !vm.ref<!hal.buffer>
    %ref_9 = vm.call @hal.ex.file.from_memory(%ref, %c-1, %c1, %_const, %zero, %c128, %zero_2) : (!vm.ref<!hal.device>, i64, i32, !vm.buffer, i64, i64, i32) -> !vm.ref<!hal.file>
    %ref_10 = vm.call @hal.fence.create(%ref, %zero_2) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    vm.call @hal.device.queue.read(%ref, %c-1, %null, %ref_10, %ref_9, %zero, %ref_8, %zero, %c128, %zero_2) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.file>, i64, !vm.ref<!hal.buffer>, i64, i64, i32) -> ()
    vm.br ^bb5(%ref_10, %ref_8 : !vm.ref<!hal.fence>, !vm.ref<!hal.buffer>)
  ^bb5(%7: !vm.ref<!hal.fence>, %8: !vm.ref<!hal.buffer>):  // 2 preds: ^bb3, ^bb4
    vm.global.store.ref %8, @_params.weight : !vm.ref<!hal.buffer>
    vm.global.store.ref %7, @_params.weight__timepoint : !vm.ref<!hal.fence>
    vm.return
  }
  vm.import private @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects}
  vm.import private @hal.ex.file.from_memory(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %access : i32, %buffer : !vm.buffer, %offset : i64, %length : i64, %flags : i32) -> !vm.ref<!hal.file>
  vm.import private @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
  vm.import private @hal.allocator.import(%allocator : !vm.ref<!hal.allocator>, %try : i32, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %source : !vm.buffer, %offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
  vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
  vm.import private @hal.buffer.subspan(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
  vm.import private @hal.buffer.length(%buffer : !vm.ref<!hal.buffer>) -> i64 attributes {nosideeffects}
  vm.import private @hal.buffer.load(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i32) -> i32
  vm.import private @hal.buffer.store(%value : i32, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i32)
  vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
  vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
  vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
  vm.import private @hal.buffer_view.element_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
  vm.import private @hal.buffer_view.encoding_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
  vm.import private @hal.buffer_view.rank(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
  vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
  vm.import private @hal.buffer_view.trace(%key : !vm.buffer, %operands : !vm.ref<!hal.buffer_view> ...)
  vm.import private @hal.channel.create(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %flags : i32, %id : !vm.buffer, %group : !vm.buffer, %rank : i32, %count : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects}
  vm.import private @hal.channel.split(%channel : !vm.ref<!hal.channel>, %color : i32, %key : i32, %flags : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects}
  vm.import private @hal.channel.rank_and_count(%channel : !vm.ref<!hal.channel>) -> (i32, i32) attributes {nosideeffects}
  vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer>
  vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
  vm.import private @hal.command_buffer.begin_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>, %label : !vm.buffer)
  vm.import private @hal.command_buffer.end_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>)
  vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
  vm.import private @hal.command_buffer.fill_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %pattern : i32, %pattern_length : i32)
  vm.import private @hal.command_buffer.copy_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64)
  vm.import private @hal.command_buffer.collective(%command_buffer : !vm.ref<!hal.command_buffer>, %channel : !vm.ref<!hal.channel>, %op : i32, %param : i32, %send_buffer : !vm.ref<!hal.buffer>, %send_offset : i64, %send_length : i64, %recv_buffer : !vm.ref<!hal.buffer>, %recv_offset : i64, %recv_length : i64, %element_count : i64)
  vm.import private @hal.command_buffer.push_constants(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %offset : i32, %values : i32 ...)
  vm.import private @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32)
  vm.import private @hal.command_buffer.dispatch.indirect(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroups_buffer : !vm.ref<!hal.buffer>, %workgroups_offset : i64)
  vm.import private @hal.command_buffer.execute.commands(%command_buffer : !vm.ref<!hal.command_buffer>, %commands : !vm.ref<!hal.command_buffer>, %bindings : tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects}
  vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
  vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
  vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
  vm.import private @hal.device.queue.dealloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %buffer : !vm.ref<!hal.buffer>)
  vm.import private @hal.device.queue.read(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_file : !vm.ref<!hal.file>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i32)
  vm.import private @hal.device.queue.write(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_file : !vm.ref<!hal.file>, %target_offset : i64, %length : i64, %flags : i32)
  vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
  vm.import private @hal.device.queue.flush(%device : !vm.ref<!hal.device>, %queue_affinity : i64)
  vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects}
  vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
  vm.import private @hal.fence.join(%fences : !vm.ref<!hal.fence> ...) -> !vm.ref<!hal.fence> attributes {nosideeffects}
  vm.import private @hal.fence.query(%fence : !vm.ref<!hal.fence>) -> i32
  vm.import private @hal.fence.signal(%fence : !vm.ref<!hal.fence>)
  vm.import private @hal.fence.fail(%fence : !vm.ref<!hal.fence>, %status : i32)
  vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
  vm.import private @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects}
  vm.rodata private @_utf8_input_0_5FD512E67BEFDEEC {alignment = 1 : i64} "input 0"
  vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
  vm.func private @main(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
    %c13 = vm.const.i32 13
    %c28 = vm.const.i32 28
    %c2 = vm.const.i32 2
    %c3 = vm.const.i32 3
    %c17 = vm.const.i32 17
    %c48 = vm.const.i32 48
    %null = vm.const.ref.zero : !vm.ref<!hal.fence>
    %zero = vm.const.i32.zero
    %c3075 = vm.const.i32 3075
    %c16 = vm.const.i32 16
    %c3_0 = vm.const.i64 3
    %c-1 = vm.const.i64 -1
    %c-1_1 = vm.const.i32 -1
    %zero_2 = vm.const.i64.zero
    %c128 = vm.const.i64 128
    %c16_3 = vm.const.i64 16
    %c12 = vm.const.i64 12
    %c553648160 = vm.const.i32 553648160
    %c1 = vm.const.i32 1
    %c4 = vm.const.i64 4
    %_params.weight__timepoint = vm.global.load.ref @_params.weight__timepoint : !vm.ref<!hal.fence>
    %_params.weight = vm.global.load.ref @_params.weight : !vm.ref<!hal.buffer>
    %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %_executable_main_dispatch_0 = vm.global.load.ref @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
    %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1, [%c4]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
    vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c16_3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %ref_6 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    %0 = vm.call.variadic @hal.fence.await(%c-1_1, [%_params.weight__timepoint]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    %ref_7 = vm.call @hal.device.queue.alloca(%ref_4, %c-1, %null, %ref_6, %zero, %c48, %c3075, %c12) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
    %1 = vm.call.variadic @hal.fence.await(%c-1_1, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    %ref_8 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
    %2 = vm.select.i64 %_device_query_0, %zero_2, %c-1 : i64
    %3 = vm.trunc.i64.i32 %2 : i64 -> i32
    vm.br_table %3 {
      default: ^bb2,
      0: ^bb1
    }
  ^bb1:  // pred: ^bb0
    vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_8, %_pipeline_layout_0, %zero, [(%zero, %zero, %ref, %zero_2, %c16_3), (%c1, %zero, %_params.weight, %zero_2, %c128), (%c2, %zero, %ref_7, %zero_2, %c12)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.call @hal.command_buffer.dispatch(%ref_8, %_executable_main_dispatch_0, %zero, %c3, %c1, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
    vm.br ^bb2
  ^bb2:  // 2 preds: ^bb0, ^bb1
    vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
    vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
    %ref_9 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    %4 = vm.call.variadic @hal.fence.await(%c-1_1, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1, %null, %ref_9, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
    %5 = vm.call.variadic @hal.fence.await(%c-1_1, [%ref_9]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    vm.cond_br %5, ^bb4, ^bb3
  ^bb3:  // pred: ^bb2
    %ref_10 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_2, %c12, %c553648160, %c1, [%c3_0]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
    vm.return %ref_10 : !vm.ref<!hal.buffer_view>
  ^bb4:  // pred: ^bb2
    vm.fail %5, "failed to wait on timepoint"
  }
  vm.export @main attributes {iree.abi.stub}
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
vm.initializer {
  %c527363 = vm.const.i32 527363
  %c48 = vm.const.i32 48
  %null = vm.const.ref.zero : !vm.ref<!hal.fence>
  %null_0 = vm.const.ref.zero : !vm.ref<!hal.executable>
  %null_1 = vm.const.ref.zero : !vm.buffer
  %c2 = vm.const.i32 2
  %c7 = vm.const.i32 7
  %c1 = vm.const.i32 1
  %zero = vm.const.i64.zero
  %c128 = vm.const.i64 128
  %c-1 = vm.const.i64 -1
  %zero_2 = vm.const.i32.zero
  %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
  %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
  %_utf8_cuda_nvptx_fb_B15B42B96FDBACC = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
  %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
  %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
  %2 = vm.and.i32 %1, %c1 : i32
  %3 = vm.select.i32 %0#0, %2, %zero_2 : i32
  %ref_3 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero_2, [(%zero_2, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %zero_2)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
  %ref_4 = vm.call.variadic @hal.pipeline_layout.create(%ref, %zero_2, [%ref_3]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
  %4 = vm.select.i64 %3, %zero, %c-1 : i64
  %5 = vm.trunc.i64.i32 %4 : i64 -> i32
  vm.global.store.i32 %3, @_device_query_0 : i32
  vm.global.store.ref %ref_4, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
  vm.br_table %5 {
    default: ^bb2,
    0: ^bb1
  }
^bb1:  // pred: ^bb0
  %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
  %main_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @main_dispatch_0_cuda_nvptx_fb : !vm.buffer
  %ref_5 = vm.call.variadic @hal.executable.create(%ref, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC, %main_dispatch_0_cuda_nvptx_fb, %null_1, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
  vm.br ^bb3(%ref_5 : !vm.ref<!hal.executable>)
^bb2:  // pred: ^bb0
  vm.br ^bb3(%null_0 : !vm.ref<!hal.executable>)
^bb3(%6: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
  %_const = vm.const.ref.rodata @_const : !vm.buffer
  %ref_6 = vm.call @hal.device.allocator(%ref) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
  %ref_7 = vm.call @hal.allocator.import(%ref_6, %c1, %c-1, %c48, %c527363, %_const, %zero, %c128) : (!vm.ref<!hal.allocator>, i32, i64, i32, i32, !vm.buffer, i64, i64) -> !vm.ref<!hal.buffer>
  %rnz = vm.cmp.nz.ref %ref_7 : !vm.ref<!hal.buffer>
  vm.global.store.ref %6, @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
  vm.cond_br %rnz, ^bb5(%null, %ref_7 : !vm.ref<!hal.fence>, !vm.ref<!hal.buffer>), ^bb4
^bb4:  // pred: ^bb3
  %ref_8 = vm.call @hal.allocator.allocate(%ref_6, %c-1, %c48, %c527363, %c128) : (!vm.ref<!hal.allocator>, i64, i32, i32, i64) -> !vm.ref<!hal.buffer>
  %ref_9 = vm.call @hal.ex.file.from_memory(%ref, %c-1, %c1, %_const, %zero, %c128, %zero_2) : (!vm.ref<!hal.device>, i64, i32, !vm.buffer, i64, i64, i32) -> !vm.ref<!hal.file>
  %ref_10 = vm.call @hal.fence.create(%ref, %zero_2) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
  vm.call @hal.device.queue.read(%ref, %c-1, %null, %ref_10, %ref_9, %zero, %ref_8, %zero, %c128, %zero_2) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.file>, i64, !vm.ref<!hal.buffer>, i64, i64, i32) -> ()
  vm.br ^bb5(%ref_10, %ref_8 : !vm.ref<!hal.fence>, !vm.ref<!hal.buffer>)
^bb5(%7: !vm.ref<!hal.fence>, %8: !vm.ref<!hal.buffer>):  // 2 preds: ^bb3, ^bb4
  vm.global.store.ref %8, @_params.weight : !vm.ref<!hal.buffer>
  vm.global.store.ref %7, @_params.weight__timepoint : !vm.ref<!hal.fence>
  vm.return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
vm.func private @main(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
  %c13 = vm.const.i32 13
  %c28 = vm.const.i32 28
  %c2 = vm.const.i32 2
  %c3 = vm.const.i32 3
  %c17 = vm.const.i32 17
  %c48 = vm.const.i32 48
  %null = vm.const.ref.zero : !vm.ref<!hal.fence>
  %zero = vm.const.i32.zero
  %c3075 = vm.const.i32 3075
  %c16 = vm.const.i32 16
  %c3_0 = vm.const.i64 3
  %c-1 = vm.const.i64 -1
  %c-1_1 = vm.const.i32 -1
  %zero_2 = vm.const.i64.zero
  %c128 = vm.const.i64 128
  %c16_3 = vm.const.i64 16
  %c12 = vm.const.i64 12
  %c553648160 = vm.const.i32 553648160
  %c1 = vm.const.i32 1
  %c4 = vm.const.i64 4
  %_params.weight__timepoint = vm.global.load.ref @_params.weight__timepoint : !vm.ref<!hal.fence>
  %_params.weight = vm.global.load.ref @_params.weight : !vm.ref<!hal.buffer>
  %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
  %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
  %_executable_main_dispatch_0 = vm.global.load.ref @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
  %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
  vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1, [%c4]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
  %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
  %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
  %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
  %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
  vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c16_3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
  %ref_6 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
  %0 = vm.call.variadic @hal.fence.await(%c-1_1, [%_params.weight__timepoint]) : (i32, !vm.ref<!hal.fence> ...) -> i32
  %ref_7 = vm.call @hal.device.queue.alloca(%ref_4, %c-1, %null, %ref_6, %zero, %c48, %c3075, %c12) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
  %1 = vm.call.variadic @hal.fence.await(%c-1_1, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
  %ref_8 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
  %2 = vm.select.i64 %_device_query_0, %zero_2, %c-1 : i64
  %3 = vm.trunc.i64.i32 %2 : i64 -> i32
  vm.br_table %3 {
    default: ^bb2,
    0: ^bb1
  }
^bb1:  // pred: ^bb0
  vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_8, %_pipeline_layout_0, %zero, [(%zero, %zero, %ref, %zero_2, %c16_3), (%c1, %zero, %_params.weight, %zero_2, %c128), (%c2, %zero, %ref_7, %zero_2, %c12)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
  vm.call @hal.command_buffer.dispatch(%ref_8, %_executable_main_dispatch_0, %zero, %c3, %c1, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
  vm.br ^bb2
^bb2:  // 2 preds: ^bb0, ^bb1
  vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
  vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
  %ref_9 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
  %4 = vm.call.variadic @hal.fence.await(%c-1_1, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
  vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1, %null, %ref_9, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
  %5 = vm.call.variadic @hal.fence.await(%c-1_1, [%ref_9]) : (i32, !vm.ref<!hal.fence> ...) -> i32
  vm.cond_br %5, ^bb4, ^bb3
^bb3:  // pred: ^bb2
  %ref_10 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_2, %c12, %c553648160, %c1, [%c3_0]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
  vm.return %ref_10 : !vm.ref<!hal.buffer_view>
^bb4:  // pred: ^bb2
  vm.fail %5, "failed to wait on timepoint"
}

// -----// IR Dump After Inliner (inline) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda], vm.toplevel} {
  vm.module public @LinearModule {
    vm.global.i32 private @_device_query_0 : i32
    vm.global.ref private @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.global.ref private @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
    vm.global.ref private mutable @_params.weight__timepoint : !vm.ref<!hal.fence>
    vm.global.ref private @_params.weight : !vm.ref<!hal.buffer>
    vm.rodata private @main_dispatch_0_cuda_nvptx_fb {alignment = 16 : i64, mime_type = "application/x-flatbuffers"} dense<"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vector<1302xi8>
    vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
    vm.rodata private @_utf8_cuda_nvptx_fb_B15B42B96FDBACC {alignment = 1 : i64} "cuda-nvptx-fb"
    vm.rodata private @_const {alignment = 64 : i64} #composite_of_128b
    vm.initializer {
      %c527363 = vm.const.i32 527363
      %c48 = vm.const.i32 48
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %null_0 = vm.const.ref.zero : !vm.ref<!hal.executable>
      %null_1 = vm.const.ref.zero : !vm.buffer
      %c2 = vm.const.i32 2
      %c7 = vm.const.i32 7
      %c1 = vm.const.i32 1
      %zero = vm.const.i64.zero
      %c128 = vm.const.i64 128
      %c-1 = vm.const.i64 -1
      %zero_2 = vm.const.i32.zero
      %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
      %_utf8_cuda_nvptx_fb_B15B42B96FDBACC = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
      %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
      %2 = vm.and.i32 %1, %c1 : i32
      %3 = vm.select.i32 %0#0, %2, %zero_2 : i32
      %ref_3 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero_2, [(%zero_2, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %zero_2)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
      %ref_4 = vm.call.variadic @hal.pipeline_layout.create(%ref, %zero_2, [%ref_3]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
      %4 = vm.select.i64 %3, %zero, %c-1 : i64
      %5 = vm.trunc.i64.i32 %4 : i64 -> i32
      vm.global.store.i32 %3, @_device_query_0 : i32
      vm.global.store.ref %ref_4, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      vm.br_table %5 {
        default: ^bb2,
        0: ^bb1
      }
    ^bb1:  // pred: ^bb0
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %main_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @main_dispatch_0_cuda_nvptx_fb : !vm.buffer
      %ref_5 = vm.call.variadic @hal.executable.create(%ref, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC, %main_dispatch_0_cuda_nvptx_fb, %null_1, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
      vm.br ^bb3(%ref_5 : !vm.ref<!hal.executable>)
    ^bb2:  // pred: ^bb0
      vm.br ^bb3(%null_0 : !vm.ref<!hal.executable>)
    ^bb3(%6: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
      %_const = vm.const.ref.rodata @_const : !vm.buffer
      %ref_6 = vm.call @hal.device.allocator(%ref) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %ref_7 = vm.call @hal.allocator.import(%ref_6, %c1, %c-1, %c48, %c527363, %_const, %zero, %c128) : (!vm.ref<!hal.allocator>, i32, i64, i32, i32, !vm.buffer, i64, i64) -> !vm.ref<!hal.buffer>
      %rnz = vm.cmp.nz.ref %ref_7 : !vm.ref<!hal.buffer>
      vm.global.store.ref %6, @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
      vm.cond_br %rnz, ^bb5(%null, %ref_7 : !vm.ref<!hal.fence>, !vm.ref<!hal.buffer>), ^bb4
    ^bb4:  // pred: ^bb3
      %ref_8 = vm.call @hal.allocator.allocate(%ref_6, %c-1, %c48, %c527363, %c128) : (!vm.ref<!hal.allocator>, i64, i32, i32, i64) -> !vm.ref<!hal.buffer>
      %ref_9 = vm.call @hal.ex.file.from_memory(%ref, %c-1, %c1, %_const, %zero, %c128, %zero_2) : (!vm.ref<!hal.device>, i64, i32, !vm.buffer, i64, i64, i32) -> !vm.ref<!hal.file>
      %ref_10 = vm.call @hal.fence.create(%ref, %zero_2) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      vm.call @hal.device.queue.read(%ref, %c-1, %null, %ref_10, %ref_9, %zero, %ref_8, %zero, %c128, %zero_2) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.file>, i64, !vm.ref<!hal.buffer>, i64, i64, i32) -> ()
      vm.br ^bb5(%ref_10, %ref_8 : !vm.ref<!hal.fence>, !vm.ref<!hal.buffer>)
    ^bb5(%7: !vm.ref<!hal.fence>, %8: !vm.ref<!hal.buffer>):  // 2 preds: ^bb3, ^bb4
      vm.global.store.ref %8, @_params.weight : !vm.ref<!hal.buffer>
      vm.global.store.ref %7, @_params.weight__timepoint : !vm.ref<!hal.fence>
      vm.return
    }
    vm.import private @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects}
    vm.import private @hal.ex.file.from_memory(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %access : i32, %buffer : !vm.buffer, %offset : i64, %length : i64, %flags : i32) -> !vm.ref<!hal.file>
    vm.import private @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
    vm.import private @hal.allocator.import(%allocator : !vm.ref<!hal.allocator>, %try : i32, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %source : !vm.buffer, %offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
    vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
    vm.import private @hal.buffer.subspan(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.buffer.length(%buffer : !vm.ref<!hal.buffer>) -> i64 attributes {nosideeffects}
    vm.import private @hal.buffer.load(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i32) -> i32
    vm.import private @hal.buffer.store(%value : i32, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i32)
    vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
    vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
    vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.buffer_view.element_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
    vm.import private @hal.buffer_view.encoding_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
    vm.import private @hal.buffer_view.rank(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
    vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
    vm.import private @hal.buffer_view.trace(%key : !vm.buffer, %operands : !vm.ref<!hal.buffer_view> ...)
    vm.import private @hal.channel.create(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %flags : i32, %id : !vm.buffer, %group : !vm.buffer, %rank : i32, %count : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects}
    vm.import private @hal.channel.split(%channel : !vm.ref<!hal.channel>, %color : i32, %key : i32, %flags : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects}
    vm.import private @hal.channel.rank_and_count(%channel : !vm.ref<!hal.channel>) -> (i32, i32) attributes {nosideeffects}
    vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer>
    vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.begin_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>, %label : !vm.buffer)
    vm.import private @hal.command_buffer.end_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
    vm.import private @hal.command_buffer.fill_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %pattern : i32, %pattern_length : i32)
    vm.import private @hal.command_buffer.copy_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64)
    vm.import private @hal.command_buffer.collective(%command_buffer : !vm.ref<!hal.command_buffer>, %channel : !vm.ref<!hal.channel>, %op : i32, %param : i32, %send_buffer : !vm.ref<!hal.buffer>, %send_offset : i64, %send_length : i64, %recv_buffer : !vm.ref<!hal.buffer>, %recv_offset : i64, %recv_length : i64, %element_count : i64)
    vm.import private @hal.command_buffer.push_constants(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %offset : i32, %values : i32 ...)
    vm.import private @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32)
    vm.import private @hal.command_buffer.dispatch.indirect(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroups_buffer : !vm.ref<!hal.buffer>, %workgroups_offset : i64)
    vm.import private @hal.command_buffer.execute.commands(%command_buffer : !vm.ref<!hal.command_buffer>, %commands : !vm.ref<!hal.command_buffer>, %bindings : tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects}
    vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
    vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
    vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
    vm.import private @hal.device.queue.dealloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %buffer : !vm.ref<!hal.buffer>)
    vm.import private @hal.device.queue.read(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_file : !vm.ref<!hal.file>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i32)
    vm.import private @hal.device.queue.write(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_file : !vm.ref<!hal.file>, %target_offset : i64, %length : i64, %flags : i32)
    vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
    vm.import private @hal.device.queue.flush(%device : !vm.ref<!hal.device>, %queue_affinity : i64)
    vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects}
    vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
    vm.import private @hal.fence.join(%fences : !vm.ref<!hal.fence> ...) -> !vm.ref<!hal.fence> attributes {nosideeffects}
    vm.import private @hal.fence.query(%fence : !vm.ref<!hal.fence>) -> i32
    vm.import private @hal.fence.signal(%fence : !vm.ref<!hal.fence>)
    vm.import private @hal.fence.fail(%fence : !vm.ref<!hal.fence>, %status : i32)
    vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
    vm.import private @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects}
    vm.rodata private @_utf8_input_0_5FD512E67BEFDEEC {alignment = 1 : i64} "input 0"
    vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
    vm.func private @main(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
      %c13 = vm.const.i32 13
      %c28 = vm.const.i32 28
      %c2 = vm.const.i32 2
      %c3 = vm.const.i32 3
      %c17 = vm.const.i32 17
      %c48 = vm.const.i32 48
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %zero = vm.const.i32.zero
      %c3075 = vm.const.i32 3075
      %c16 = vm.const.i32 16
      %c3_0 = vm.const.i64 3
      %c-1 = vm.const.i64 -1
      %c-1_1 = vm.const.i32 -1
      %zero_2 = vm.const.i64.zero
      %c128 = vm.const.i64 128
      %c16_3 = vm.const.i64 16
      %c12 = vm.const.i64 12
      %c553648160 = vm.const.i32 553648160
      %c1 = vm.const.i32 1
      %c4 = vm.const.i64 4
      %_params.weight__timepoint = vm.global.load.ref @_params.weight__timepoint : !vm.ref<!hal.fence>
      %_params.weight = vm.global.load.ref @_params.weight : !vm.ref<!hal.buffer>
      %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %_executable_main_dispatch_0 = vm.global.load.ref @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
      %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1, [%c4]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c16_3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %ref_6 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      %0 = vm.call.variadic @hal.fence.await(%c-1_1, [%_params.weight__timepoint]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      %ref_7 = vm.call @hal.device.queue.alloca(%ref_4, %c-1, %null, %ref_6, %zero, %c48, %c3075, %c12) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
      %1 = vm.call.variadic @hal.fence.await(%c-1_1, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      %ref_8 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
      %2 = vm.select.i64 %_device_query_0, %zero_2, %c-1 : i64
      %3 = vm.trunc.i64.i32 %2 : i64 -> i32
      vm.br_table %3 {
        default: ^bb2,
        0: ^bb1
      }
    ^bb1:  // pred: ^bb0
      vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_8, %_pipeline_layout_0, %zero, [(%zero, %zero, %ref, %zero_2, %c16_3), (%c1, %zero, %_params.weight, %zero_2, %c128), (%c2, %zero, %ref_7, %zero_2, %c12)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      vm.call @hal.command_buffer.dispatch(%ref_8, %_executable_main_dispatch_0, %zero, %c3, %c1, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
      vm.br ^bb2
    ^bb2:  // 2 preds: ^bb0, ^bb1
      vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
      %ref_9 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      %4 = vm.call.variadic @hal.fence.await(%c-1_1, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1, %null, %ref_9, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
      %5 = vm.call.variadic @hal.fence.await(%c-1_1, [%ref_9]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_br %5, ^bb4, ^bb3
    ^bb3:  // pred: ^bb2
      %ref_10 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_2, %c12, %c553648160, %c1, [%c3_0]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_10 : !vm.ref<!hal.buffer_view>
    ^bb4:  // pred: ^bb2
      vm.fail %5, "failed to wait on timepoint"
    }
    vm.export @main attributes {iree.abi.stub}
  }
}


// -----// IR Dump After SymbolDCE (symbol-dce) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda], vm.toplevel} {
  vm.module public @LinearModule {
    vm.global.i32 private @_device_query_0 : i32
    vm.global.ref private @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.global.ref private @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
    vm.global.ref private mutable @_params.weight__timepoint : !vm.ref<!hal.fence>
    vm.global.ref private @_params.weight : !vm.ref<!hal.buffer>
    vm.rodata private @main_dispatch_0_cuda_nvptx_fb {alignment = 16 : i64, mime_type = "application/x-flatbuffers"} dense<"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vector<1302xi8>
    vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
    vm.rodata private @_utf8_cuda_nvptx_fb_B15B42B96FDBACC {alignment = 1 : i64} "cuda-nvptx-fb"
    vm.rodata private @_const {alignment = 64 : i64} #composite_of_128b
    vm.initializer {
      %c527363 = vm.const.i32 527363
      %c48 = vm.const.i32 48
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %null_0 = vm.const.ref.zero : !vm.ref<!hal.executable>
      %null_1 = vm.const.ref.zero : !vm.buffer
      %c2 = vm.const.i32 2
      %c7 = vm.const.i32 7
      %c1 = vm.const.i32 1
      %zero = vm.const.i64.zero
      %c128 = vm.const.i64 128
      %c-1 = vm.const.i64 -1
      %zero_2 = vm.const.i32.zero
      %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
      %_utf8_cuda_nvptx_fb_B15B42B96FDBACC = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
      %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
      %2 = vm.and.i32 %1, %c1 : i32
      %3 = vm.select.i32 %0#0, %2, %zero_2 : i32
      %ref_3 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero_2, [(%zero_2, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %zero_2)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
      %ref_4 = vm.call.variadic @hal.pipeline_layout.create(%ref, %zero_2, [%ref_3]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
      %4 = vm.select.i64 %3, %zero, %c-1 : i64
      %5 = vm.trunc.i64.i32 %4 : i64 -> i32
      vm.global.store.i32 %3, @_device_query_0 : i32
      vm.global.store.ref %ref_4, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      vm.br_table %5 {
        default: ^bb2,
        0: ^bb1
      }
    ^bb1:  // pred: ^bb0
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %main_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @main_dispatch_0_cuda_nvptx_fb : !vm.buffer
      %ref_5 = vm.call.variadic @hal.executable.create(%ref, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC, %main_dispatch_0_cuda_nvptx_fb, %null_1, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
      vm.br ^bb3(%ref_5 : !vm.ref<!hal.executable>)
    ^bb2:  // pred: ^bb0
      vm.br ^bb3(%null_0 : !vm.ref<!hal.executable>)
    ^bb3(%6: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
      %_const = vm.const.ref.rodata @_const : !vm.buffer
      %ref_6 = vm.call @hal.device.allocator(%ref) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %ref_7 = vm.call @hal.allocator.import(%ref_6, %c1, %c-1, %c48, %c527363, %_const, %zero, %c128) : (!vm.ref<!hal.allocator>, i32, i64, i32, i32, !vm.buffer, i64, i64) -> !vm.ref<!hal.buffer>
      %rnz = vm.cmp.nz.ref %ref_7 : !vm.ref<!hal.buffer>
      vm.global.store.ref %6, @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
      vm.cond_br %rnz, ^bb5(%null, %ref_7 : !vm.ref<!hal.fence>, !vm.ref<!hal.buffer>), ^bb4
    ^bb4:  // pred: ^bb3
      %ref_8 = vm.call @hal.allocator.allocate(%ref_6, %c-1, %c48, %c527363, %c128) : (!vm.ref<!hal.allocator>, i64, i32, i32, i64) -> !vm.ref<!hal.buffer>
      %ref_9 = vm.call @hal.ex.file.from_memory(%ref, %c-1, %c1, %_const, %zero, %c128, %zero_2) : (!vm.ref<!hal.device>, i64, i32, !vm.buffer, i64, i64, i32) -> !vm.ref<!hal.file>
      %ref_10 = vm.call @hal.fence.create(%ref, %zero_2) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      vm.call @hal.device.queue.read(%ref, %c-1, %null, %ref_10, %ref_9, %zero, %ref_8, %zero, %c128, %zero_2) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.file>, i64, !vm.ref<!hal.buffer>, i64, i64, i32) -> ()
      vm.br ^bb5(%ref_10, %ref_8 : !vm.ref<!hal.fence>, !vm.ref<!hal.buffer>)
    ^bb5(%7: !vm.ref<!hal.fence>, %8: !vm.ref<!hal.buffer>):  // 2 preds: ^bb3, ^bb4
      vm.global.store.ref %8, @_params.weight : !vm.ref<!hal.buffer>
      vm.global.store.ref %7, @_params.weight__timepoint : !vm.ref<!hal.fence>
      vm.return
    }
    vm.import private @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects}
    vm.import private @hal.ex.file.from_memory(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %access : i32, %buffer : !vm.buffer, %offset : i64, %length : i64, %flags : i32) -> !vm.ref<!hal.file>
    vm.import private @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
    vm.import private @hal.allocator.import(%allocator : !vm.ref<!hal.allocator>, %try : i32, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %source : !vm.buffer, %offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
    vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
    vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
    vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
    vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer>
    vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
    vm.import private @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32)
    vm.import private @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects}
    vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
    vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
    vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
    vm.import private @hal.device.queue.read(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_file : !vm.ref<!hal.file>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i32)
    vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
    vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects}
    vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
    vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
    vm.import private @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects}
    vm.rodata private @_utf8_input_0_5FD512E67BEFDEEC {alignment = 1 : i64} "input 0"
    vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
    vm.func private @main(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
      %c13 = vm.const.i32 13
      %c28 = vm.const.i32 28
      %c2 = vm.const.i32 2
      %c3 = vm.const.i32 3
      %c17 = vm.const.i32 17
      %c48 = vm.const.i32 48
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %zero = vm.const.i32.zero
      %c3075 = vm.const.i32 3075
      %c16 = vm.const.i32 16
      %c3_0 = vm.const.i64 3
      %c-1 = vm.const.i64 -1
      %c-1_1 = vm.const.i32 -1
      %zero_2 = vm.const.i64.zero
      %c128 = vm.const.i64 128
      %c16_3 = vm.const.i64 16
      %c12 = vm.const.i64 12
      %c553648160 = vm.const.i32 553648160
      %c1 = vm.const.i32 1
      %c4 = vm.const.i64 4
      %_params.weight__timepoint = vm.global.load.ref @_params.weight__timepoint : !vm.ref<!hal.fence>
      %_params.weight = vm.global.load.ref @_params.weight : !vm.ref<!hal.buffer>
      %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %_executable_main_dispatch_0 = vm.global.load.ref @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
      %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1, [%c4]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c16_3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %ref_6 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      %0 = vm.call.variadic @hal.fence.await(%c-1_1, [%_params.weight__timepoint]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      %ref_7 = vm.call @hal.device.queue.alloca(%ref_4, %c-1, %null, %ref_6, %zero, %c48, %c3075, %c12) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
      %1 = vm.call.variadic @hal.fence.await(%c-1_1, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      %ref_8 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
      %2 = vm.select.i64 %_device_query_0, %zero_2, %c-1 : i64
      %3 = vm.trunc.i64.i32 %2 : i64 -> i32
      vm.br_table %3 {
        default: ^bb2,
        0: ^bb1
      }
    ^bb1:  // pred: ^bb0
      vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_8, %_pipeline_layout_0, %zero, [(%zero, %zero, %ref, %zero_2, %c16_3), (%c1, %zero, %_params.weight, %zero_2, %c128), (%c2, %zero, %ref_7, %zero_2, %c12)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      vm.call @hal.command_buffer.dispatch(%ref_8, %_executable_main_dispatch_0, %zero, %c3, %c1, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
      vm.br ^bb2
    ^bb2:  // 2 preds: ^bb0, ^bb1
      vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
      %ref_9 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      %4 = vm.call.variadic @hal.fence.await(%c-1_1, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1, %null, %ref_9, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
      %5 = vm.call.variadic @hal.fence.await(%c-1_1, [%ref_9]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_br %5, ^bb4, ^bb3
    ^bb3:  // pred: ^bb2
      %ref_10 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_2, %c12, %c553648160, %c1, [%c3_0]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_10 : !vm.ref<!hal.buffer_view>
    ^bb4:  // pred: ^bb2
      vm.fail %5, "failed to wait on timepoint"
    }
    vm.export @main attributes {iree.abi.stub}
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda], vm.toplevel} {
  vm.module public @LinearModule {
    vm.global.i32 private @_device_query_0 : i32
    vm.global.ref private @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.global.ref private @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
    vm.global.ref private mutable @_params.weight__timepoint : !vm.ref<!hal.fence>
    vm.global.ref private @_params.weight : !vm.ref<!hal.buffer>
    vm.rodata private @main_dispatch_0_cuda_nvptx_fb {alignment = 16 : i64, mime_type = "application/x-flatbuffers"} dense<"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vector<1302xi8>
    vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
    vm.rodata private @_utf8_cuda_nvptx_fb_B15B42B96FDBACC {alignment = 1 : i64} "cuda-nvptx-fb"
    vm.rodata private @_const {alignment = 64 : i64} #composite_of_128b
    vm.initializer {
      %c527363 = vm.const.i32 527363
      %c48 = vm.const.i32 48
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %null_0 = vm.const.ref.zero : !vm.ref<!hal.executable>
      %null_1 = vm.const.ref.zero : !vm.buffer
      %c2 = vm.const.i32 2
      %c7 = vm.const.i32 7
      %c1 = vm.const.i32 1
      %zero = vm.const.i64.zero
      %c128 = vm.const.i64 128
      %c-1 = vm.const.i64 -1
      %zero_2 = vm.const.i32.zero
      %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
      %_utf8_cuda_nvptx_fb_B15B42B96FDBACC = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
      %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
      %2 = vm.and.i32 %1, %c1 : i32
      %3 = vm.select.i32 %0#0, %2, %zero_2 : i32
      %ref_3 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero_2, [(%zero_2, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %zero_2)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
      %ref_4 = vm.call.variadic @hal.pipeline_layout.create(%ref, %zero_2, [%ref_3]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
      %4 = vm.select.i64 %3, %zero, %c-1 : i64
      %5 = vm.trunc.i64.i32 %4 : i64 -> i32
      vm.global.store.i32 %3, @_device_query_0 : i32
      vm.global.store.ref %ref_4, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      vm.br_table %5 {
        default: ^bb2,
        0: ^bb1
      }
    ^bb1:  // pred: ^bb0
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %main_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @main_dispatch_0_cuda_nvptx_fb : !vm.buffer
      %ref_5 = vm.call.variadic @hal.executable.create(%ref, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC, %main_dispatch_0_cuda_nvptx_fb, %null_1, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
      vm.br ^bb3(%ref_5 : !vm.ref<!hal.executable>)
    ^bb2:  // pred: ^bb0
      vm.br ^bb3(%null_0 : !vm.ref<!hal.executable>)
    ^bb3(%6: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
      %_const = vm.const.ref.rodata @_const : !vm.buffer
      %ref_6 = vm.call @hal.device.allocator(%ref) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %ref_7 = vm.call @hal.allocator.import(%ref_6, %c1, %c-1, %c48, %c527363, %_const, %zero, %c128) : (!vm.ref<!hal.allocator>, i32, i64, i32, i32, !vm.buffer, i64, i64) -> !vm.ref<!hal.buffer>
      %rnz = vm.cmp.nz.ref %ref_7 : !vm.ref<!hal.buffer>
      vm.global.store.ref %6, @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
      vm.cond_br %rnz, ^bb5(%null, %ref_7 : !vm.ref<!hal.fence>, !vm.ref<!hal.buffer>), ^bb4
    ^bb4:  // pred: ^bb3
      %ref_8 = vm.call @hal.allocator.allocate(%ref_6, %c-1, %c48, %c527363, %c128) : (!vm.ref<!hal.allocator>, i64, i32, i32, i64) -> !vm.ref<!hal.buffer>
      %ref_9 = vm.call @hal.ex.file.from_memory(%ref, %c-1, %c1, %_const, %zero, %c128, %zero_2) : (!vm.ref<!hal.device>, i64, i32, !vm.buffer, i64, i64, i32) -> !vm.ref<!hal.file>
      %ref_10 = vm.call @hal.fence.create(%ref, %zero_2) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      vm.call @hal.device.queue.read(%ref, %c-1, %null, %ref_10, %ref_9, %zero, %ref_8, %zero, %c128, %zero_2) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.file>, i64, !vm.ref<!hal.buffer>, i64, i64, i32) -> ()
      vm.br ^bb5(%ref_10, %ref_8 : !vm.ref<!hal.fence>, !vm.ref<!hal.buffer>)
    ^bb5(%7: !vm.ref<!hal.fence>, %8: !vm.ref<!hal.buffer>):  // 2 preds: ^bb3, ^bb4
      vm.global.store.ref %8, @_params.weight : !vm.ref<!hal.buffer>
      vm.global.store.ref %7, @_params.weight__timepoint : !vm.ref<!hal.fence>
      vm.return
    }
    vm.import private @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects}
    vm.import private @hal.ex.file.from_memory(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %access : i32, %buffer : !vm.buffer, %offset : i64, %length : i64, %flags : i32) -> !vm.ref<!hal.file>
    vm.import private @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
    vm.import private @hal.allocator.import(%allocator : !vm.ref<!hal.allocator>, %try : i32, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %source : !vm.buffer, %offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
    vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
    vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
    vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
    vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer>
    vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
    vm.import private @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32)
    vm.import private @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects}
    vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
    vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
    vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
    vm.import private @hal.device.queue.read(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_file : !vm.ref<!hal.file>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i32)
    vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
    vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects}
    vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
    vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
    vm.import private @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects}
    vm.rodata private @_utf8_input_0_5FD512E67BEFDEEC {alignment = 1 : i64} "input 0"
    vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
    vm.func private @main(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
      %c13 = vm.const.i32 13
      %c28 = vm.const.i32 28
      %c2 = vm.const.i32 2
      %c3 = vm.const.i32 3
      %c17 = vm.const.i32 17
      %c48 = vm.const.i32 48
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %zero = vm.const.i32.zero
      %c3075 = vm.const.i32 3075
      %c16 = vm.const.i32 16
      %c3_0 = vm.const.i64 3
      %c-1 = vm.const.i64 -1
      %c-1_1 = vm.const.i32 -1
      %zero_2 = vm.const.i64.zero
      %c128 = vm.const.i64 128
      %c16_3 = vm.const.i64 16
      %c12 = vm.const.i64 12
      %c553648160 = vm.const.i32 553648160
      %c1 = vm.const.i32 1
      %c4 = vm.const.i64 4
      %_params.weight__timepoint = vm.global.load.ref @_params.weight__timepoint : !vm.ref<!hal.fence>
      %_params.weight = vm.global.load.ref @_params.weight : !vm.ref<!hal.buffer>
      %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %_executable_main_dispatch_0 = vm.global.load.ref @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
      %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1, [%c4]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c16_3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %ref_6 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      %0 = vm.call.variadic @hal.fence.await(%c-1_1, [%_params.weight__timepoint]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      %ref_7 = vm.call @hal.device.queue.alloca(%ref_4, %c-1, %null, %ref_6, %zero, %c48, %c3075, %c12) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
      %1 = vm.call.variadic @hal.fence.await(%c-1_1, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      %ref_8 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
      %2 = vm.select.i64 %_device_query_0, %zero_2, %c-1 : i64
      %3 = vm.trunc.i64.i32 %2 : i64 -> i32
      vm.br_table %3 {
        default: ^bb2,
        0: ^bb1
      }
    ^bb1:  // pred: ^bb0
      vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_8, %_pipeline_layout_0, %zero, [(%zero, %zero, %ref, %zero_2, %c16_3), (%c1, %zero, %_params.weight, %zero_2, %c128), (%c2, %zero, %ref_7, %zero_2, %c12)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      vm.call @hal.command_buffer.dispatch(%ref_8, %_executable_main_dispatch_0, %zero, %c3, %c1, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
      vm.br ^bb2
    ^bb2:  // 2 preds: ^bb0, ^bb1
      vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
      %ref_9 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      %4 = vm.call.variadic @hal.fence.await(%c-1_1, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1, %null, %ref_9, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
      %5 = vm.call.variadic @hal.fence.await(%c-1_1, [%ref_9]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_br %5, ^bb4, ^bb3
    ^bb3:  // pred: ^bb2
      %ref_10 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_2, %c12, %c553648160, %c1, [%c3_0]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_10 : !vm.ref<!hal.buffer_view>
    ^bb4:  // pred: ^bb2
      vm.fail %5, "failed to wait on timepoint"
    }
    vm.export @main attributes {iree.abi.stub}
  }
}


// -----// IR Dump After CSE (cse) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda], vm.toplevel} {
  vm.module public @LinearModule {
    vm.global.i32 private @_device_query_0 : i32
    vm.global.ref private @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.global.ref private @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
    vm.global.ref private mutable @_params.weight__timepoint : !vm.ref<!hal.fence>
    vm.global.ref private @_params.weight : !vm.ref<!hal.buffer>
    vm.rodata private @main_dispatch_0_cuda_nvptx_fb {alignment = 16 : i64, mime_type = "application/x-flatbuffers"} dense<"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vector<1302xi8>
    vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
    vm.rodata private @_utf8_cuda_nvptx_fb_B15B42B96FDBACC {alignment = 1 : i64} "cuda-nvptx-fb"
    vm.rodata private @_const {alignment = 64 : i64} #composite_of_128b
    vm.initializer {
      %c527363 = vm.const.i32 527363
      %c48 = vm.const.i32 48
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %null_0 = vm.const.ref.zero : !vm.ref<!hal.executable>
      %null_1 = vm.const.ref.zero : !vm.buffer
      %c2 = vm.const.i32 2
      %c7 = vm.const.i32 7
      %c1 = vm.const.i32 1
      %zero = vm.const.i64.zero
      %c128 = vm.const.i64 128
      %c-1 = vm.const.i64 -1
      %zero_2 = vm.const.i32.zero
      %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
      %_utf8_cuda_nvptx_fb_B15B42B96FDBACC = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
      %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
      %2 = vm.and.i32 %1, %c1 : i32
      %3 = vm.select.i32 %0#0, %2, %zero_2 : i32
      %ref_3 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero_2, [(%zero_2, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %zero_2)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
      %ref_4 = vm.call.variadic @hal.pipeline_layout.create(%ref, %zero_2, [%ref_3]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
      %4 = vm.select.i64 %3, %zero, %c-1 : i64
      %5 = vm.trunc.i64.i32 %4 : i64 -> i32
      vm.global.store.i32 %3, @_device_query_0 : i32
      vm.global.store.ref %ref_4, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      vm.br_table %5 {
        default: ^bb2,
        0: ^bb1
      }
    ^bb1:  // pred: ^bb0
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %main_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @main_dispatch_0_cuda_nvptx_fb : !vm.buffer
      %ref_5 = vm.call.variadic @hal.executable.create(%ref, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC, %main_dispatch_0_cuda_nvptx_fb, %null_1, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
      vm.br ^bb3(%ref_5 : !vm.ref<!hal.executable>)
    ^bb2:  // pred: ^bb0
      vm.br ^bb3(%null_0 : !vm.ref<!hal.executable>)
    ^bb3(%6: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
      %_const = vm.const.ref.rodata @_const : !vm.buffer
      %ref_6 = vm.call @hal.device.allocator(%ref) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %ref_7 = vm.call @hal.allocator.import(%ref_6, %c1, %c-1, %c48, %c527363, %_const, %zero, %c128) : (!vm.ref<!hal.allocator>, i32, i64, i32, i32, !vm.buffer, i64, i64) -> !vm.ref<!hal.buffer>
      %rnz = vm.cmp.nz.ref %ref_7 : !vm.ref<!hal.buffer>
      vm.global.store.ref %6, @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
      vm.cond_br %rnz, ^bb5(%null, %ref_7 : !vm.ref<!hal.fence>, !vm.ref<!hal.buffer>), ^bb4
    ^bb4:  // pred: ^bb3
      %ref_8 = vm.call @hal.allocator.allocate(%ref_6, %c-1, %c48, %c527363, %c128) : (!vm.ref<!hal.allocator>, i64, i32, i32, i64) -> !vm.ref<!hal.buffer>
      %ref_9 = vm.call @hal.ex.file.from_memory(%ref, %c-1, %c1, %_const, %zero, %c128, %zero_2) : (!vm.ref<!hal.device>, i64, i32, !vm.buffer, i64, i64, i32) -> !vm.ref<!hal.file>
      %ref_10 = vm.call @hal.fence.create(%ref, %zero_2) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      vm.call @hal.device.queue.read(%ref, %c-1, %null, %ref_10, %ref_9, %zero, %ref_8, %zero, %c128, %zero_2) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.file>, i64, !vm.ref<!hal.buffer>, i64, i64, i32) -> ()
      vm.br ^bb5(%ref_10, %ref_8 : !vm.ref<!hal.fence>, !vm.ref<!hal.buffer>)
    ^bb5(%7: !vm.ref<!hal.fence>, %8: !vm.ref<!hal.buffer>):  // 2 preds: ^bb3, ^bb4
      vm.global.store.ref %8, @_params.weight : !vm.ref<!hal.buffer>
      vm.global.store.ref %7, @_params.weight__timepoint : !vm.ref<!hal.fence>
      vm.return
    }
    vm.import private @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects}
    vm.import private @hal.ex.file.from_memory(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %access : i32, %buffer : !vm.buffer, %offset : i64, %length : i64, %flags : i32) -> !vm.ref<!hal.file>
    vm.import private @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
    vm.import private @hal.allocator.import(%allocator : !vm.ref<!hal.allocator>, %try : i32, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %source : !vm.buffer, %offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
    vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
    vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
    vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
    vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer>
    vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
    vm.import private @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32)
    vm.import private @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects}
    vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
    vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
    vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
    vm.import private @hal.device.queue.read(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_file : !vm.ref<!hal.file>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i32)
    vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
    vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects}
    vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
    vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
    vm.import private @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects}
    vm.rodata private @_utf8_input_0_5FD512E67BEFDEEC {alignment = 1 : i64} "input 0"
    vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
    vm.func private @main(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
      %c13 = vm.const.i32 13
      %c28 = vm.const.i32 28
      %c2 = vm.const.i32 2
      %c3 = vm.const.i32 3
      %c17 = vm.const.i32 17
      %c48 = vm.const.i32 48
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %zero = vm.const.i32.zero
      %c3075 = vm.const.i32 3075
      %c16 = vm.const.i32 16
      %c3_0 = vm.const.i64 3
      %c-1 = vm.const.i64 -1
      %c-1_1 = vm.const.i32 -1
      %zero_2 = vm.const.i64.zero
      %c128 = vm.const.i64 128
      %c16_3 = vm.const.i64 16
      %c12 = vm.const.i64 12
      %c553648160 = vm.const.i32 553648160
      %c1 = vm.const.i32 1
      %c4 = vm.const.i64 4
      %_params.weight__timepoint = vm.global.load.ref @_params.weight__timepoint : !vm.ref<!hal.fence>
      %_params.weight = vm.global.load.ref @_params.weight : !vm.ref<!hal.buffer>
      %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %_executable_main_dispatch_0 = vm.global.load.ref @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
      %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1, [%c4]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c16_3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %ref_6 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      %0 = vm.call.variadic @hal.fence.await(%c-1_1, [%_params.weight__timepoint]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      %ref_7 = vm.call @hal.device.queue.alloca(%ref_4, %c-1, %null, %ref_6, %zero, %c48, %c3075, %c12) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
      %1 = vm.call.variadic @hal.fence.await(%c-1_1, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      %ref_8 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
      %2 = vm.select.i64 %_device_query_0, %zero_2, %c-1 : i64
      %3 = vm.trunc.i64.i32 %2 : i64 -> i32
      vm.br_table %3 {
        default: ^bb2,
        0: ^bb1
      }
    ^bb1:  // pred: ^bb0
      vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_8, %_pipeline_layout_0, %zero, [(%zero, %zero, %ref, %zero_2, %c16_3), (%c1, %zero, %_params.weight, %zero_2, %c128), (%c2, %zero, %ref_7, %zero_2, %c12)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      vm.call @hal.command_buffer.dispatch(%ref_8, %_executable_main_dispatch_0, %zero, %c3, %c1, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
      vm.br ^bb2
    ^bb2:  // 2 preds: ^bb0, ^bb1
      vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
      %ref_9 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      %4 = vm.call.variadic @hal.fence.await(%c-1_1, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1, %null, %ref_9, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
      %5 = vm.call.variadic @hal.fence.await(%c-1_1, [%ref_9]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_br %5, ^bb4, ^bb3
    ^bb3:  // pred: ^bb2
      %ref_10 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_2, %c12, %c553648160, %c1, [%c3_0]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_10 : !vm.ref<!hal.buffer_view>
    ^bb4:  // pred: ^bb2
      vm.fail %5, "failed to wait on timepoint"
    }
    vm.export @main attributes {iree.abi.stub}
  }
}


// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda], vm.toplevel} {
  vm.module public @LinearModule {
    vm.global.i32 private @_device_query_0 : i32
    vm.global.ref private @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.global.ref private @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
    vm.global.ref private mutable @_params.weight__timepoint : !vm.ref<!hal.fence>
    vm.global.ref private @_params.weight : !vm.ref<!hal.buffer>
    vm.rodata private @main_dispatch_0_cuda_nvptx_fb {alignment = 16 : i64, mime_type = "application/x-flatbuffers"} dense<"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vector<1302xi8>
    vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
    vm.rodata private @_utf8_cuda_nvptx_fb_B15B42B96FDBACC {alignment = 1 : i64} "cuda-nvptx-fb"
    vm.rodata private @_const {alignment = 64 : i64} #composite_of_128b
    vm.initializer {
      %c527363 = vm.const.i32 527363
      %c48 = vm.const.i32 48
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %null_0 = vm.const.ref.zero : !vm.ref<!hal.executable>
      %null_1 = vm.const.ref.zero : !vm.buffer
      %c2 = vm.const.i32 2
      %c7 = vm.const.i32 7
      %c1 = vm.const.i32 1
      %zero = vm.const.i64.zero
      %c128 = vm.const.i64 128
      %c-1 = vm.const.i64 -1
      %zero_2 = vm.const.i32.zero
      %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
      %_utf8_cuda_nvptx_fb_B15B42B96FDBACC = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
      %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
      %2 = vm.and.i32 %1, %c1 : i32
      %3 = vm.select.i32 %0#0, %2, %zero_2 : i32
      %ref_3 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero_2, [(%zero_2, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %zero_2)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
      %ref_4 = vm.call.variadic @hal.pipeline_layout.create(%ref, %zero_2, [%ref_3]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
      %4 = vm.select.i64 %3, %zero, %c-1 : i64
      %5 = vm.trunc.i64.i32 %4 : i64 -> i32
      vm.global.store.i32 %3, @_device_query_0 : i32
      vm.global.store.ref %ref_4, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      vm.br_table %5 {
        default: ^bb2,
        0: ^bb1
      }
    ^bb1:  // pred: ^bb0
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %main_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @main_dispatch_0_cuda_nvptx_fb : !vm.buffer
      %ref_5 = vm.call.variadic @hal.executable.create(%ref, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC, %main_dispatch_0_cuda_nvptx_fb, %null_1, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
      vm.br ^bb3(%ref_5 : !vm.ref<!hal.executable>)
    ^bb2:  // pred: ^bb0
      vm.br ^bb3(%null_0 : !vm.ref<!hal.executable>)
    ^bb3(%6: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
      %_const = vm.const.ref.rodata @_const : !vm.buffer
      %ref_6 = vm.call @hal.device.allocator(%ref) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %ref_7 = vm.call @hal.allocator.import(%ref_6, %c1, %c-1, %c48, %c527363, %_const, %zero, %c128) : (!vm.ref<!hal.allocator>, i32, i64, i32, i32, !vm.buffer, i64, i64) -> !vm.ref<!hal.buffer>
      %rnz = vm.cmp.nz.ref %ref_7 : !vm.ref<!hal.buffer>
      vm.global.store.ref %6, @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
      vm.cond_br %rnz, ^bb5(%null, %ref_7 : !vm.ref<!hal.fence>, !vm.ref<!hal.buffer>), ^bb4
    ^bb4:  // pred: ^bb3
      %ref_8 = vm.call @hal.allocator.allocate(%ref_6, %c-1, %c48, %c527363, %c128) : (!vm.ref<!hal.allocator>, i64, i32, i32, i64) -> !vm.ref<!hal.buffer>
      %ref_9 = vm.call @hal.ex.file.from_memory(%ref, %c-1, %c1, %_const, %zero, %c128, %zero_2) : (!vm.ref<!hal.device>, i64, i32, !vm.buffer, i64, i64, i32) -> !vm.ref<!hal.file>
      %ref_10 = vm.call @hal.fence.create(%ref, %zero_2) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      vm.call @hal.device.queue.read(%ref, %c-1, %null, %ref_10, %ref_9, %zero, %ref_8, %zero, %c128, %zero_2) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.file>, i64, !vm.ref<!hal.buffer>, i64, i64, i32) -> ()
      vm.br ^bb5(%ref_10, %ref_8 : !vm.ref<!hal.fence>, !vm.ref<!hal.buffer>)
    ^bb5(%7: !vm.ref<!hal.fence>, %8: !vm.ref<!hal.buffer>):  // 2 preds: ^bb3, ^bb4
      vm.global.store.ref %8, @_params.weight : !vm.ref<!hal.buffer>
      vm.global.store.ref %7, @_params.weight__timepoint : !vm.ref<!hal.fence>
      vm.return
    }
    vm.import private @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects}
    vm.import private @hal.ex.file.from_memory(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %access : i32, %buffer : !vm.buffer, %offset : i64, %length : i64, %flags : i32) -> !vm.ref<!hal.file>
    vm.import private @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
    vm.import private @hal.allocator.import(%allocator : !vm.ref<!hal.allocator>, %try : i32, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %source : !vm.buffer, %offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
    vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
    vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
    vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
    vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer>
    vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
    vm.import private @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32)
    vm.import private @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects}
    vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
    vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
    vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
    vm.import private @hal.device.queue.read(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_file : !vm.ref<!hal.file>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i32)
    vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
    vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects}
    vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
    vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
    vm.import private @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects}
    vm.rodata private @_utf8_input_0_5FD512E67BEFDEEC {alignment = 1 : i64} "input 0"
    vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
    vm.func private @main(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
      %c13 = vm.const.i32 13
      %c28 = vm.const.i32 28
      %c2 = vm.const.i32 2
      %c3 = vm.const.i32 3
      %c17 = vm.const.i32 17
      %c48 = vm.const.i32 48
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %zero = vm.const.i32.zero
      %c3075 = vm.const.i32 3075
      %c16 = vm.const.i32 16
      %c3_0 = vm.const.i64 3
      %c-1 = vm.const.i64 -1
      %c-1_1 = vm.const.i32 -1
      %zero_2 = vm.const.i64.zero
      %c128 = vm.const.i64 128
      %c16_3 = vm.const.i64 16
      %c12 = vm.const.i64 12
      %c553648160 = vm.const.i32 553648160
      %c1 = vm.const.i32 1
      %c4 = vm.const.i64 4
      %_params.weight__timepoint = vm.global.load.ref @_params.weight__timepoint : !vm.ref<!hal.fence>
      %_params.weight = vm.global.load.ref @_params.weight : !vm.ref<!hal.buffer>
      %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %_executable_main_dispatch_0 = vm.global.load.ref @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
      %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1, [%c4]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c16_3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %ref_6 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      %0 = vm.call.variadic @hal.fence.await(%c-1_1, [%_params.weight__timepoint]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      %ref_7 = vm.call @hal.device.queue.alloca(%ref_4, %c-1, %null, %ref_6, %zero, %c48, %c3075, %c12) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
      %1 = vm.call.variadic @hal.fence.await(%c-1_1, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      %ref_8 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
      %2 = vm.select.i64 %_device_query_0, %zero_2, %c-1 : i64
      %3 = vm.trunc.i64.i32 %2 : i64 -> i32
      vm.br_table %3 {
        default: ^bb2,
        0: ^bb1
      }
    ^bb1:  // pred: ^bb0
      vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_8, %_pipeline_layout_0, %zero, [(%zero, %zero, %ref, %zero_2, %c16_3), (%c1, %zero, %_params.weight, %zero_2, %c128), (%c2, %zero, %ref_7, %zero_2, %c12)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      vm.call @hal.command_buffer.dispatch(%ref_8, %_executable_main_dispatch_0, %zero, %c3, %c1, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
      vm.br ^bb2
    ^bb2:  // 2 preds: ^bb0, ^bb1
      vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
      %ref_9 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      %4 = vm.call.variadic @hal.fence.await(%c-1_1, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1, %null, %ref_9, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
      %5 = vm.call.variadic @hal.fence.await(%c-1_1, [%ref_9]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_br %5, ^bb4, ^bb3
    ^bb3:  // pred: ^bb2
      %ref_10 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_2, %c12, %c553648160, %c1, [%c3_0]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_10 : !vm.ref<!hal.buffer_view>
    ^bb4:  // pred: ^bb2
      vm.fail %5, "failed to wait on timepoint"
    }
    vm.export @main attributes {iree.abi.stub}
  }
}


// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda], vm.toplevel} {
  vm.module public @LinearModule {
    vm.global.i32 private @_device_query_0 : i32
    vm.global.ref private @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.global.ref private @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
    vm.global.ref private mutable @_params.weight__timepoint : !vm.ref<!hal.fence>
    vm.global.ref private @_params.weight : !vm.ref<!hal.buffer>
    vm.rodata private @main_dispatch_0_cuda_nvptx_fb {alignment = 16 : i64, mime_type = "application/x-flatbuffers"} dense<"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vector<1302xi8>
    vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
    vm.rodata private @_utf8_cuda_nvptx_fb_B15B42B96FDBACC {alignment = 1 : i64} "cuda-nvptx-fb"
    vm.rodata private @_const {alignment = 64 : i64} #composite_of_128b
    vm.initializer {
      %c527363 = vm.const.i32 527363
      %c48 = vm.const.i32 48
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %null_0 = vm.const.ref.zero : !vm.ref<!hal.executable>
      %null_1 = vm.const.ref.zero : !vm.buffer
      %c2 = vm.const.i32 2
      %c7 = vm.const.i32 7
      %c1 = vm.const.i32 1
      %zero = vm.const.i64.zero
      %c128 = vm.const.i64 128
      %c-1 = vm.const.i64 -1
      %zero_2 = vm.const.i32.zero
      %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
      %_utf8_cuda_nvptx_fb_B15B42B96FDBACC = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
      %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
      %2 = vm.and.i32 %1, %c1 : i32
      %3 = vm.select.i32 %0#0, %2, %zero_2 : i32
      %ref_3 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero_2, [(%zero_2, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %zero_2)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
      %ref_4 = vm.call.variadic @hal.pipeline_layout.create(%ref, %zero_2, [%ref_3]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
      %4 = vm.select.i64 %3, %zero, %c-1 : i64
      %5 = vm.trunc.i64.i32 %4 : i64 -> i32
      vm.global.store.i32 %3, @_device_query_0 : i32
      vm.global.store.ref %ref_4, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      vm.br_table %5 {
        default: ^bb2,
        0: ^bb1
      }
    ^bb1:  // pred: ^bb0
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %main_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @main_dispatch_0_cuda_nvptx_fb : !vm.buffer
      %ref_5 = vm.call.variadic @hal.executable.create(%ref, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC, %main_dispatch_0_cuda_nvptx_fb, %null_1, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
      vm.br ^bb3(%ref_5 : !vm.ref<!hal.executable>)
    ^bb2:  // pred: ^bb0
      vm.br ^bb3(%null_0 : !vm.ref<!hal.executable>)
    ^bb3(%6: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
      %_const = vm.const.ref.rodata @_const : !vm.buffer
      %ref_6 = vm.call @hal.device.allocator(%ref) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %ref_7 = vm.call @hal.allocator.import(%ref_6, %c1, %c-1, %c48, %c527363, %_const, %zero, %c128) : (!vm.ref<!hal.allocator>, i32, i64, i32, i32, !vm.buffer, i64, i64) -> !vm.ref<!hal.buffer>
      %rnz = vm.cmp.nz.ref %ref_7 : !vm.ref<!hal.buffer>
      vm.global.store.ref %6, @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
      vm.cond_br %rnz, ^bb5(%null, %ref_7 : !vm.ref<!hal.fence>, !vm.ref<!hal.buffer>), ^bb4
    ^bb4:  // pred: ^bb3
      %ref_8 = vm.call @hal.allocator.allocate(%ref_6, %c-1, %c48, %c527363, %c128) : (!vm.ref<!hal.allocator>, i64, i32, i32, i64) -> !vm.ref<!hal.buffer>
      %ref_9 = vm.call @hal.ex.file.from_memory(%ref, %c-1, %c1, %_const, %zero, %c128, %zero_2) : (!vm.ref<!hal.device>, i64, i32, !vm.buffer, i64, i64, i32) -> !vm.ref<!hal.file>
      %ref_10 = vm.call @hal.fence.create(%ref, %zero_2) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      vm.call @hal.device.queue.read(%ref, %c-1, %null, %ref_10, %ref_9, %zero, %ref_8, %zero, %c128, %zero_2) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.file>, i64, !vm.ref<!hal.buffer>, i64, i64, i32) -> ()
      vm.br ^bb5(%ref_10, %ref_8 : !vm.ref<!hal.fence>, !vm.ref<!hal.buffer>)
    ^bb5(%7: !vm.ref<!hal.fence>, %8: !vm.ref<!hal.buffer>):  // 2 preds: ^bb3, ^bb4
      vm.global.store.ref %8, @_params.weight : !vm.ref<!hal.buffer>
      vm.global.store.ref %7, @_params.weight__timepoint : !vm.ref<!hal.fence>
      vm.return
    }
    vm.import private @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects}
    vm.import private @hal.ex.file.from_memory(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %access : i32, %buffer : !vm.buffer, %offset : i64, %length : i64, %flags : i32) -> !vm.ref<!hal.file>
    vm.import private @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
    vm.import private @hal.allocator.import(%allocator : !vm.ref<!hal.allocator>, %try : i32, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %source : !vm.buffer, %offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
    vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
    vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
    vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
    vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer>
    vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
    vm.import private @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32)
    vm.import private @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects}
    vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
    vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
    vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
    vm.import private @hal.device.queue.read(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_file : !vm.ref<!hal.file>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i32)
    vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
    vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects}
    vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
    vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
    vm.import private @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects}
    vm.rodata private @_utf8_input_0_5FD512E67BEFDEEC {alignment = 1 : i64} "input 0"
    vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
    vm.func private @main(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
      %c13 = vm.const.i32 13
      %c28 = vm.const.i32 28
      %c2 = vm.const.i32 2
      %c3 = vm.const.i32 3
      %c17 = vm.const.i32 17
      %c48 = vm.const.i32 48
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %zero = vm.const.i32.zero
      %c3075 = vm.const.i32 3075
      %c16 = vm.const.i32 16
      %c3_0 = vm.const.i64 3
      %c-1 = vm.const.i64 -1
      %c-1_1 = vm.const.i32 -1
      %zero_2 = vm.const.i64.zero
      %c128 = vm.const.i64 128
      %c16_3 = vm.const.i64 16
      %c12 = vm.const.i64 12
      %c553648160 = vm.const.i32 553648160
      %c1 = vm.const.i32 1
      %c4 = vm.const.i64 4
      %_params.weight__timepoint = vm.global.load.ref @_params.weight__timepoint : !vm.ref<!hal.fence>
      %_params.weight = vm.global.load.ref @_params.weight : !vm.ref<!hal.buffer>
      %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %_executable_main_dispatch_0 = vm.global.load.ref @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
      %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1, [%c4]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c16_3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %ref_6 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      %0 = vm.call.variadic @hal.fence.await(%c-1_1, [%_params.weight__timepoint]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      %ref_7 = vm.call @hal.device.queue.alloca(%ref_4, %c-1, %null, %ref_6, %zero, %c48, %c3075, %c12) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
      %1 = vm.call.variadic @hal.fence.await(%c-1_1, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      %ref_8 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
      %2 = vm.select.i64 %_device_query_0, %zero_2, %c-1 : i64
      %3 = vm.trunc.i64.i32 %2 : i64 -> i32
      vm.br_table %3 {
        default: ^bb2,
        0: ^bb1
      }
    ^bb1:  // pred: ^bb0
      vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_8, %_pipeline_layout_0, %zero, [(%zero, %zero, %ref, %zero_2, %c16_3), (%c1, %zero, %_params.weight, %zero_2, %c128), (%c2, %zero, %ref_7, %zero_2, %c12)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      vm.call @hal.command_buffer.dispatch(%ref_8, %_executable_main_dispatch_0, %zero, %c3, %c1, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
      vm.br ^bb2
    ^bb2:  // 2 preds: ^bb0, ^bb1
      vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
      %ref_9 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      %4 = vm.call.variadic @hal.fence.await(%c-1_1, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1, %null, %ref_9, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
      %5 = vm.call.variadic @hal.fence.await(%c-1_1, [%ref_9]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_br %5, ^bb4, ^bb3
    ^bb3:  // pred: ^bb2
      %ref_10 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_2, %c12, %c553648160, %c1, [%c3_0]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_10 : !vm.ref<!hal.buffer_view>
    ^bb4:  // pred: ^bb2
      vm.fail %5, "failed to wait on timepoint"
    }
    vm.export @main attributes {iree.abi.stub}
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda], vm.toplevel} {
  vm.module public @LinearModule {
    vm.global.i32 private @_device_query_0 : i32
    vm.global.ref private @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.global.ref private @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
    vm.global.ref private mutable @_params.weight__timepoint : !vm.ref<!hal.fence>
    vm.global.ref private @_params.weight : !vm.ref<!hal.buffer>
    vm.rodata private @main_dispatch_0_cuda_nvptx_fb {alignment = 16 : i64, mime_type = "application/x-flatbuffers"} dense<"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vector<1302xi8>
    vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
    vm.rodata private @_utf8_cuda_nvptx_fb_B15B42B96FDBACC {alignment = 1 : i64} "cuda-nvptx-fb"
    vm.rodata private @_const {alignment = 64 : i64} #composite_of_128b
    vm.initializer {
      %c527363 = vm.const.i32 527363
      %c48 = vm.const.i32 48
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %null_0 = vm.const.ref.zero : !vm.ref<!hal.executable>
      %null_1 = vm.const.ref.zero : !vm.buffer
      %c2 = vm.const.i32 2
      %c7 = vm.const.i32 7
      %c1 = vm.const.i32 1
      %zero = vm.const.i64.zero
      %c128 = vm.const.i64 128
      %c-1 = vm.const.i64 -1
      %zero_2 = vm.const.i32.zero
      %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
      %_utf8_cuda_nvptx_fb_B15B42B96FDBACC = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
      %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
      %2 = vm.and.i32 %1, %c1 : i32
      %3 = vm.select.i32 %0#0, %2, %zero_2 : i32
      %ref_3 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero_2, [(%zero_2, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %zero_2)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
      %ref_4 = vm.call.variadic @hal.pipeline_layout.create(%ref, %zero_2, [%ref_3]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
      %4 = vm.select.i64 %3, %zero, %c-1 : i64
      %5 = vm.trunc.i64.i32 %4 : i64 -> i32
      vm.global.store.i32 %3, @_device_query_0 : i32
      vm.global.store.ref %ref_4, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      vm.br_table %5 {
        default: ^bb2,
        0: ^bb1
      }
    ^bb1:  // pred: ^bb0
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %main_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @main_dispatch_0_cuda_nvptx_fb : !vm.buffer
      %ref_5 = vm.call.variadic @hal.executable.create(%ref, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC, %main_dispatch_0_cuda_nvptx_fb, %null_1, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
      vm.br ^bb3(%ref_5 : !vm.ref<!hal.executable>)
    ^bb2:  // pred: ^bb0
      vm.br ^bb3(%null_0 : !vm.ref<!hal.executable>)
    ^bb3(%6: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
      %_const = vm.const.ref.rodata @_const : !vm.buffer
      %ref_6 = vm.call @hal.device.allocator(%ref) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %ref_7 = vm.call @hal.allocator.import(%ref_6, %c1, %c-1, %c48, %c527363, %_const, %zero, %c128) : (!vm.ref<!hal.allocator>, i32, i64, i32, i32, !vm.buffer, i64, i64) -> !vm.ref<!hal.buffer>
      %rnz = vm.cmp.nz.ref %ref_7 : !vm.ref<!hal.buffer>
      vm.global.store.ref %6, @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
      vm.cond_br %rnz, ^bb5(%null, %ref_7 : !vm.ref<!hal.fence>, !vm.ref<!hal.buffer>), ^bb4
    ^bb4:  // pred: ^bb3
      %ref_8 = vm.call @hal.allocator.allocate(%ref_6, %c-1, %c48, %c527363, %c128) : (!vm.ref<!hal.allocator>, i64, i32, i32, i64) -> !vm.ref<!hal.buffer>
      %ref_9 = vm.call @hal.ex.file.from_memory(%ref, %c-1, %c1, %_const, %zero, %c128, %zero_2) : (!vm.ref<!hal.device>, i64, i32, !vm.buffer, i64, i64, i32) -> !vm.ref<!hal.file>
      %ref_10 = vm.call @hal.fence.create(%ref, %zero_2) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      vm.call @hal.device.queue.read(%ref, %c-1, %null, %ref_10, %ref_9, %zero, %ref_8, %zero, %c128, %zero_2) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.file>, i64, !vm.ref<!hal.buffer>, i64, i64, i32) -> ()
      vm.br ^bb5(%ref_10, %ref_8 : !vm.ref<!hal.fence>, !vm.ref<!hal.buffer>)
    ^bb5(%7: !vm.ref<!hal.fence>, %8: !vm.ref<!hal.buffer>):  // 2 preds: ^bb3, ^bb4
      vm.global.store.ref %8, @_params.weight : !vm.ref<!hal.buffer>
      vm.global.store.ref %7, @_params.weight__timepoint : !vm.ref<!hal.fence>
      vm.return
    }
    vm.import private @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects}
    vm.import private @hal.ex.file.from_memory(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %access : i32, %buffer : !vm.buffer, %offset : i64, %length : i64, %flags : i32) -> !vm.ref<!hal.file>
    vm.import private @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
    vm.import private @hal.allocator.import(%allocator : !vm.ref<!hal.allocator>, %try : i32, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %source : !vm.buffer, %offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
    vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
    vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
    vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
    vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer>
    vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
    vm.import private @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32)
    vm.import private @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects}
    vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
    vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
    vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
    vm.import private @hal.device.queue.read(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_file : !vm.ref<!hal.file>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i32)
    vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
    vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects}
    vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
    vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
    vm.import private @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects}
    vm.rodata private @_utf8_input_0_5FD512E67BEFDEEC {alignment = 1 : i64} "input 0"
    vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
    vm.func private @main(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
      %c13 = vm.const.i32 13
      %c28 = vm.const.i32 28
      %c2 = vm.const.i32 2
      %c3 = vm.const.i32 3
      %c17 = vm.const.i32 17
      %c48 = vm.const.i32 48
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %zero = vm.const.i32.zero
      %c3075 = vm.const.i32 3075
      %c16 = vm.const.i32 16
      %c3_0 = vm.const.i64 3
      %c-1 = vm.const.i64 -1
      %c-1_1 = vm.const.i32 -1
      %zero_2 = vm.const.i64.zero
      %c128 = vm.const.i64 128
      %c16_3 = vm.const.i64 16
      %c12 = vm.const.i64 12
      %c553648160 = vm.const.i32 553648160
      %c1 = vm.const.i32 1
      %c4 = vm.const.i64 4
      %_params.weight__timepoint = vm.global.load.ref @_params.weight__timepoint : !vm.ref<!hal.fence>
      %_params.weight = vm.global.load.ref @_params.weight : !vm.ref<!hal.buffer>
      %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %_executable_main_dispatch_0 = vm.global.load.ref @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
      %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1, [%c4]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c16_3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %ref_6 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      %0 = vm.call.variadic @hal.fence.await(%c-1_1, [%_params.weight__timepoint]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      %ref_7 = vm.call @hal.device.queue.alloca(%ref_4, %c-1, %null, %ref_6, %zero, %c48, %c3075, %c12) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
      %1 = vm.call.variadic @hal.fence.await(%c-1_1, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      %ref_8 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
      %2 = vm.select.i64 %_device_query_0, %zero_2, %c-1 : i64
      %3 = vm.trunc.i64.i32 %2 : i64 -> i32
      vm.br_table %3 {
        default: ^bb2,
        0: ^bb1
      }
    ^bb1:  // pred: ^bb0
      vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_8, %_pipeline_layout_0, %zero, [(%zero, %zero, %ref, %zero_2, %c16_3), (%c1, %zero, %_params.weight, %zero_2, %c128), (%c2, %zero, %ref_7, %zero_2, %c12)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      vm.call @hal.command_buffer.dispatch(%ref_8, %_executable_main_dispatch_0, %zero, %c3, %c1, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
      vm.br ^bb2
    ^bb2:  // 2 preds: ^bb0, ^bb1
      vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
      %ref_9 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      %4 = vm.call.variadic @hal.fence.await(%c-1_1, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1, %null, %ref_9, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
      %5 = vm.call.variadic @hal.fence.await(%c-1_1, [%ref_9]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_br %5, ^bb4, ^bb3
    ^bb3:  // pred: ^bb2
      %ref_10 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_2, %c12, %c553648160, %c1, [%c3_0]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_10 : !vm.ref<!hal.buffer_view>
    ^bb4:  // pred: ^bb2
      vm.fail %5, "failed to wait on timepoint"
    }
    vm.export @main attributes {iree.abi.stub}
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::VM::GlobalInitializationPass (iree-vm-global-initialization) //----- //
vm.module public @LinearModule {
  vm.global.i32 private mutable @_device_query_0 : i32
  vm.global.ref private mutable @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
  vm.global.ref private mutable @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
  vm.global.ref private mutable @_params.weight__timepoint : !vm.ref<!hal.fence>
  vm.global.ref private mutable @_params.weight : !vm.ref<!hal.buffer>
  vm.rodata private @main_dispatch_0_cuda_nvptx_fb {alignment = 16 : i64, mime_type = "application/x-flatbuffers"} dense<"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vector<1302xi8>
  vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
  vm.rodata private @_utf8_cuda_nvptx_fb_B15B42B96FDBACC {alignment = 1 : i64} "cuda-nvptx-fb"
  vm.rodata private @_const {alignment = 64 : i64} #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
  vm.import private @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects}
  vm.import private @hal.ex.file.from_memory(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %access : i32, %buffer : !vm.buffer, %offset : i64, %length : i64, %flags : i32) -> !vm.ref<!hal.file>
  vm.import private @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
  vm.import private @hal.allocator.import(%allocator : !vm.ref<!hal.allocator>, %try : i32, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %source : !vm.buffer, %offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
  vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
  vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
  vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
  vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
  vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer>
  vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
  vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
  vm.import private @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32)
  vm.import private @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects}
  vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
  vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
  vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
  vm.import private @hal.device.queue.read(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_file : !vm.ref<!hal.file>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i32)
  vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
  vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects}
  vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
  vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
  vm.import private @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects}
  vm.rodata private @_utf8_input_0_5FD512E67BEFDEEC {alignment = 1 : i64} "input 0"
  vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
  vm.func private @main(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
    %c13 = vm.const.i32 13
    %c28 = vm.const.i32 28
    %c2 = vm.const.i32 2
    %c3 = vm.const.i32 3
    %c17 = vm.const.i32 17
    %c48 = vm.const.i32 48
    %null = vm.const.ref.zero : !vm.ref<!hal.fence>
    %zero = vm.const.i32.zero
    %c3075 = vm.const.i32 3075
    %c16 = vm.const.i32 16
    %c3_0 = vm.const.i64 3
    %c-1 = vm.const.i64 -1
    %c-1_1 = vm.const.i32 -1
    %zero_2 = vm.const.i64.zero
    %c128 = vm.const.i64 128
    %c16_3 = vm.const.i64 16
    %c12 = vm.const.i64 12
    %c553648160 = vm.const.i32 553648160
    %c1 = vm.const.i32 1
    %c4 = vm.const.i64 4
    %_params.weight__timepoint = vm.global.load.ref @_params.weight__timepoint : !vm.ref<!hal.fence>
    %_params.weight = vm.global.load.ref @_params.weight : !vm.ref<!hal.buffer>
    %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %_executable_main_dispatch_0 = vm.global.load.ref @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
    %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1, [%c4]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
    vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c16_3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %ref_6 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    %0 = vm.call.variadic @hal.fence.await(%c-1_1, [%_params.weight__timepoint]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    %ref_7 = vm.call @hal.device.queue.alloca(%ref_4, %c-1, %null, %ref_6, %zero, %c48, %c3075, %c12) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
    %1 = vm.call.variadic @hal.fence.await(%c-1_1, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    %ref_8 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
    %2 = vm.select.i64 %_device_query_0, %zero_2, %c-1 : i64
    %3 = vm.trunc.i64.i32 %2 : i64 -> i32
    vm.br_table %3 {
      default: ^bb2,
      0: ^bb1
    }
  ^bb1:  // pred: ^bb0
    vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_8, %_pipeline_layout_0, %zero, [(%zero, %zero, %ref, %zero_2, %c16_3), (%c1, %zero, %_params.weight, %zero_2, %c128), (%c2, %zero, %ref_7, %zero_2, %c12)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.call @hal.command_buffer.dispatch(%ref_8, %_executable_main_dispatch_0, %zero, %c3, %c1, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
    vm.br ^bb2
  ^bb2:  // 2 preds: ^bb0, ^bb1
    vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
    vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
    %ref_9 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    %4 = vm.call.variadic @hal.fence.await(%c-1_1, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1, %null, %ref_9, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
    %5 = vm.call.variadic @hal.fence.await(%c-1_1, [%ref_9]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    vm.cond_br %5, ^bb4, ^bb3
  ^bb3:  // pred: ^bb2
    %ref_10 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_2, %c12, %c553648160, %c1, [%c3_0]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
    vm.return %ref_10 : !vm.ref<!hal.buffer_view>
  ^bb4:  // pred: ^bb2
    vm.fail %5, "failed to wait on timepoint"
  }
  vm.export @main attributes {iree.abi.stub}
  vm.export @__init
  vm.func private @__init() {
    %c527363 = vm.const.i32 527363
    %c48 = vm.const.i32 48
    %null = vm.const.ref.zero : !vm.ref<!hal.fence>
    %null_0 = vm.const.ref.zero : !vm.ref<!hal.executable>
    %null_1 = vm.const.ref.zero : !vm.buffer
    %c2 = vm.const.i32 2
    %c7 = vm.const.i32 7
    %c1 = vm.const.i32 1
    %zero = vm.const.i64.zero
    %c128 = vm.const.i64 128
    %c-1 = vm.const.i64 -1
    %zero_2 = vm.const.i32.zero
    %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
    %_utf8_cuda_nvptx_fb_B15B42B96FDBACC = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
    %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
    %2 = vm.and.i32 %1, %c1 : i32
    %3 = vm.select.i32 %0#0, %2, %zero_2 : i32
    %ref_3 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero_2, [(%zero_2, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %zero_2)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
    %ref_4 = vm.call.variadic @hal.pipeline_layout.create(%ref, %zero_2, [%ref_3]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
    %4 = vm.select.i64 %3, %zero, %c-1 : i64
    %5 = vm.trunc.i64.i32 %4 : i64 -> i32
    vm.global.store.i32 %3, @_device_query_0 : i32
    vm.global.store.ref %ref_4, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.br_table %5 {
      default: ^bb2,
      0: ^bb1
    }
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %main_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @main_dispatch_0_cuda_nvptx_fb : !vm.buffer
    %ref_5 = vm.call.variadic @hal.executable.create(%ref, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC, %main_dispatch_0_cuda_nvptx_fb, %null_1, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
    vm.br ^bb3(%ref_5 : !vm.ref<!hal.executable>)
  ^bb2:  // pred: ^bb0
    vm.br ^bb3(%null_0 : !vm.ref<!hal.executable>)
  ^bb3(%6: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
    %_const = vm.const.ref.rodata @_const : !vm.buffer
    %ref_6 = vm.call @hal.device.allocator(%ref) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    %ref_7 = vm.call @hal.allocator.import(%ref_6, %c1, %c-1, %c48, %c527363, %_const, %zero, %c128) : (!vm.ref<!hal.allocator>, i32, i64, i32, i32, !vm.buffer, i64, i64) -> !vm.ref<!hal.buffer>
    %rnz = vm.cmp.nz.ref %ref_7 : !vm.ref<!hal.buffer>
    vm.global.store.ref %6, @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
    vm.cond_br %rnz, ^bb5(%null, %ref_7 : !vm.ref<!hal.fence>, !vm.ref<!hal.buffer>), ^bb4
  ^bb4:  // pred: ^bb3
    %ref_8 = vm.call @hal.allocator.allocate(%ref_6, %c-1, %c48, %c527363, %c128) : (!vm.ref<!hal.allocator>, i64, i32, i32, i64) -> !vm.ref<!hal.buffer>
    %ref_9 = vm.call @hal.ex.file.from_memory(%ref, %c-1, %c1, %_const, %zero, %c128, %zero_2) : (!vm.ref<!hal.device>, i64, i32, !vm.buffer, i64, i64, i32) -> !vm.ref<!hal.file>
    %ref_10 = vm.call @hal.fence.create(%ref, %zero_2) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    vm.call @hal.device.queue.read(%ref, %c-1, %null, %ref_10, %ref_9, %zero, %ref_8, %zero, %c128, %zero_2) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.file>, i64, !vm.ref<!hal.buffer>, i64, i64, i32) -> ()
    vm.br ^bb5(%ref_10, %ref_8 : !vm.ref<!hal.fence>, !vm.ref<!hal.buffer>)
  ^bb5(%7: !vm.ref<!hal.fence>, %8: !vm.ref<!hal.buffer>):  // 2 preds: ^bb3, ^bb4
    vm.global.store.ref %8, @_params.weight : !vm.ref<!hal.buffer>
    vm.global.store.ref %7, @_params.weight__timepoint : !vm.ref<!hal.fence>
    vm.br ^bb6
  ^bb6:  // pred: ^bb5
    vm.return
  }
  vm.export @__deinit
  vm.func private @__deinit() {
    vm.return
  }
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda], vm.toplevel} {
  vm.module public @LinearModule {
    vm.global.i32 private mutable @_device_query_0 : i32
    vm.global.ref private mutable @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.global.ref private mutable @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
    vm.global.ref private mutable @_params.weight__timepoint : !vm.ref<!hal.fence>
    vm.global.ref private mutable @_params.weight : !vm.ref<!hal.buffer>
    vm.rodata private @main_dispatch_0_cuda_nvptx_fb {alignment = 16 : i64, mime_type = "application/x-flatbuffers"} dense<"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vector<1302xi8>
    vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
    vm.rodata private @_utf8_cuda_nvptx_fb_B15B42B96FDBACC {alignment = 1 : i64} "cuda-nvptx-fb"
    vm.rodata private @_const {alignment = 64 : i64} #composite_of_128b
    vm.import private @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects}
    vm.import private @hal.ex.file.from_memory(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %access : i32, %buffer : !vm.buffer, %offset : i64, %length : i64, %flags : i32) -> !vm.ref<!hal.file>
    vm.import private @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
    vm.import private @hal.allocator.import(%allocator : !vm.ref<!hal.allocator>, %try : i32, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %source : !vm.buffer, %offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
    vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
    vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
    vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
    vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer>
    vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
    vm.import private @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32)
    vm.import private @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects}
    vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
    vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
    vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
    vm.import private @hal.device.queue.read(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_file : !vm.ref<!hal.file>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i32)
    vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
    vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects}
    vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
    vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
    vm.import private @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects}
    vm.rodata private @_utf8_input_0_5FD512E67BEFDEEC {alignment = 1 : i64} "input 0"
    vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
    vm.func private @main(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
      %c13 = vm.const.i32 13
      %c28 = vm.const.i32 28
      %c2 = vm.const.i32 2
      %c3 = vm.const.i32 3
      %c17 = vm.const.i32 17
      %c48 = vm.const.i32 48
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %zero = vm.const.i32.zero
      %c3075 = vm.const.i32 3075
      %c16 = vm.const.i32 16
      %c3_0 = vm.const.i64 3
      %c-1 = vm.const.i64 -1
      %c-1_1 = vm.const.i32 -1
      %zero_2 = vm.const.i64.zero
      %c128 = vm.const.i64 128
      %c16_3 = vm.const.i64 16
      %c12 = vm.const.i64 12
      %c553648160 = vm.const.i32 553648160
      %c1 = vm.const.i32 1
      %c4 = vm.const.i64 4
      %_params.weight__timepoint = vm.global.load.ref @_params.weight__timepoint : !vm.ref<!hal.fence>
      %_params.weight = vm.global.load.ref @_params.weight : !vm.ref<!hal.buffer>
      %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %_executable_main_dispatch_0 = vm.global.load.ref @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
      %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1, [%c4]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c16_3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %ref_6 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      %0 = vm.call.variadic @hal.fence.await(%c-1_1, [%_params.weight__timepoint]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      %ref_7 = vm.call @hal.device.queue.alloca(%ref_4, %c-1, %null, %ref_6, %zero, %c48, %c3075, %c12) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
      %1 = vm.call.variadic @hal.fence.await(%c-1_1, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      %ref_8 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
      %2 = vm.select.i64 %_device_query_0, %zero_2, %c-1 : i64
      %3 = vm.trunc.i64.i32 %2 : i64 -> i32
      vm.br_table %3 {
        default: ^bb2,
        0: ^bb1
      }
    ^bb1:  // pred: ^bb0
      vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_8, %_pipeline_layout_0, %zero, [(%zero, %zero, %ref, %zero_2, %c16_3), (%c1, %zero, %_params.weight, %zero_2, %c128), (%c2, %zero, %ref_7, %zero_2, %c12)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      vm.call @hal.command_buffer.dispatch(%ref_8, %_executable_main_dispatch_0, %zero, %c3, %c1, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
      vm.br ^bb2
    ^bb2:  // 2 preds: ^bb0, ^bb1
      vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
      %ref_9 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      %4 = vm.call.variadic @hal.fence.await(%c-1_1, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1, %null, %ref_9, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
      %5 = vm.call.variadic @hal.fence.await(%c-1_1, [%ref_9]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_br %5, ^bb4, ^bb3
    ^bb3:  // pred: ^bb2
      %ref_10 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_2, %c12, %c553648160, %c1, [%c3_0]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_10 : !vm.ref<!hal.buffer_view>
    ^bb4:  // pred: ^bb2
      vm.fail %5, "failed to wait on timepoint"
    }
    vm.export @main attributes {iree.abi.stub}
    vm.export @__init
    vm.func private @__init() {
      %c527363 = vm.const.i32 527363
      %c48 = vm.const.i32 48
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %null_0 = vm.const.ref.zero : !vm.ref<!hal.executable>
      %null_1 = vm.const.ref.zero : !vm.buffer
      %c2 = vm.const.i32 2
      %c7 = vm.const.i32 7
      %c1 = vm.const.i32 1
      %zero = vm.const.i64.zero
      %c128 = vm.const.i64 128
      %c-1 = vm.const.i64 -1
      %zero_2 = vm.const.i32.zero
      %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
      %_utf8_cuda_nvptx_fb_B15B42B96FDBACC = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
      %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
      %2 = vm.and.i32 %1, %c1 : i32
      %3 = vm.select.i32 %0#0, %2, %zero_2 : i32
      %ref_3 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero_2, [(%zero_2, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %zero_2)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
      %ref_4 = vm.call.variadic @hal.pipeline_layout.create(%ref, %zero_2, [%ref_3]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
      %4 = vm.select.i64 %3, %zero, %c-1 : i64
      %5 = vm.trunc.i64.i32 %4 : i64 -> i32
      vm.global.store.i32 %3, @_device_query_0 : i32
      vm.global.store.ref %ref_4, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      vm.br_table %5 {
        default: ^bb2,
        0: ^bb1
      }
    ^bb1:  // pred: ^bb0
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %main_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @main_dispatch_0_cuda_nvptx_fb : !vm.buffer
      %ref_5 = vm.call.variadic @hal.executable.create(%ref, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC, %main_dispatch_0_cuda_nvptx_fb, %null_1, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
      vm.br ^bb3(%ref_5 : !vm.ref<!hal.executable>)
    ^bb2:  // pred: ^bb0
      vm.br ^bb3(%null_0 : !vm.ref<!hal.executable>)
    ^bb3(%6: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
      %_const = vm.const.ref.rodata @_const : !vm.buffer
      %ref_6 = vm.call @hal.device.allocator(%ref) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %ref_7 = vm.call @hal.allocator.import(%ref_6, %c1, %c-1, %c48, %c527363, %_const, %zero, %c128) : (!vm.ref<!hal.allocator>, i32, i64, i32, i32, !vm.buffer, i64, i64) -> !vm.ref<!hal.buffer>
      %rnz = vm.cmp.nz.ref %ref_7 : !vm.ref<!hal.buffer>
      vm.global.store.ref %6, @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
      vm.cond_br %rnz, ^bb5(%null, %ref_7 : !vm.ref<!hal.fence>, !vm.ref<!hal.buffer>), ^bb4
    ^bb4:  // pred: ^bb3
      %ref_8 = vm.call @hal.allocator.allocate(%ref_6, %c-1, %c48, %c527363, %c128) : (!vm.ref<!hal.allocator>, i64, i32, i32, i64) -> !vm.ref<!hal.buffer>
      %ref_9 = vm.call @hal.ex.file.from_memory(%ref, %c-1, %c1, %_const, %zero, %c128, %zero_2) : (!vm.ref<!hal.device>, i64, i32, !vm.buffer, i64, i64, i32) -> !vm.ref<!hal.file>
      %ref_10 = vm.call @hal.fence.create(%ref, %zero_2) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      vm.call @hal.device.queue.read(%ref, %c-1, %null, %ref_10, %ref_9, %zero, %ref_8, %zero, %c128, %zero_2) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.file>, i64, !vm.ref<!hal.buffer>, i64, i64, i32) -> ()
      vm.br ^bb5(%ref_10, %ref_8 : !vm.ref<!hal.fence>, !vm.ref<!hal.buffer>)
    ^bb5(%7: !vm.ref<!hal.fence>, %8: !vm.ref<!hal.buffer>):  // 2 preds: ^bb3, ^bb4
      vm.global.store.ref %8, @_params.weight : !vm.ref<!hal.buffer>
      vm.global.store.ref %7, @_params.weight__timepoint : !vm.ref<!hal.fence>
      vm.return
    }
    vm.export @__deinit
    vm.func private @__deinit() {
      vm.return
    }
  }
}


// -----// IR Dump After CSE (cse) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda], vm.toplevel} {
  vm.module public @LinearModule {
    vm.global.i32 private mutable @_device_query_0 : i32
    vm.global.ref private mutable @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.global.ref private mutable @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
    vm.global.ref private mutable @_params.weight__timepoint : !vm.ref<!hal.fence>
    vm.global.ref private mutable @_params.weight : !vm.ref<!hal.buffer>
    vm.rodata private @main_dispatch_0_cuda_nvptx_fb {alignment = 16 : i64, mime_type = "application/x-flatbuffers"} dense<"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vector<1302xi8>
    vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
    vm.rodata private @_utf8_cuda_nvptx_fb_B15B42B96FDBACC {alignment = 1 : i64} "cuda-nvptx-fb"
    vm.rodata private @_const {alignment = 64 : i64} #composite_of_128b
    vm.import private @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects}
    vm.import private @hal.ex.file.from_memory(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %access : i32, %buffer : !vm.buffer, %offset : i64, %length : i64, %flags : i32) -> !vm.ref<!hal.file>
    vm.import private @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
    vm.import private @hal.allocator.import(%allocator : !vm.ref<!hal.allocator>, %try : i32, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %source : !vm.buffer, %offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
    vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
    vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
    vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
    vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer>
    vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
    vm.import private @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32)
    vm.import private @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects}
    vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
    vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
    vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
    vm.import private @hal.device.queue.read(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_file : !vm.ref<!hal.file>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i32)
    vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
    vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects}
    vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
    vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
    vm.import private @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects}
    vm.rodata private @_utf8_input_0_5FD512E67BEFDEEC {alignment = 1 : i64} "input 0"
    vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
    vm.func private @main(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
      %c13 = vm.const.i32 13
      %c28 = vm.const.i32 28
      %c2 = vm.const.i32 2
      %c3 = vm.const.i32 3
      %c17 = vm.const.i32 17
      %c48 = vm.const.i32 48
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %zero = vm.const.i32.zero
      %c3075 = vm.const.i32 3075
      %c16 = vm.const.i32 16
      %c3_0 = vm.const.i64 3
      %c-1 = vm.const.i64 -1
      %c-1_1 = vm.const.i32 -1
      %zero_2 = vm.const.i64.zero
      %c128 = vm.const.i64 128
      %c16_3 = vm.const.i64 16
      %c12 = vm.const.i64 12
      %c553648160 = vm.const.i32 553648160
      %c1 = vm.const.i32 1
      %c4 = vm.const.i64 4
      %_params.weight__timepoint = vm.global.load.ref @_params.weight__timepoint : !vm.ref<!hal.fence>
      %_params.weight = vm.global.load.ref @_params.weight : !vm.ref<!hal.buffer>
      %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %_executable_main_dispatch_0 = vm.global.load.ref @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
      %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1, [%c4]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c16_3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %ref_6 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      %0 = vm.call.variadic @hal.fence.await(%c-1_1, [%_params.weight__timepoint]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      %ref_7 = vm.call @hal.device.queue.alloca(%ref_4, %c-1, %null, %ref_6, %zero, %c48, %c3075, %c12) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
      %1 = vm.call.variadic @hal.fence.await(%c-1_1, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      %ref_8 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
      %2 = vm.select.i64 %_device_query_0, %zero_2, %c-1 : i64
      %3 = vm.trunc.i64.i32 %2 : i64 -> i32
      vm.br_table %3 {
        default: ^bb2,
        0: ^bb1
      }
    ^bb1:  // pred: ^bb0
      vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_8, %_pipeline_layout_0, %zero, [(%zero, %zero, %ref, %zero_2, %c16_3), (%c1, %zero, %_params.weight, %zero_2, %c128), (%c2, %zero, %ref_7, %zero_2, %c12)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      vm.call @hal.command_buffer.dispatch(%ref_8, %_executable_main_dispatch_0, %zero, %c3, %c1, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
      vm.br ^bb2
    ^bb2:  // 2 preds: ^bb0, ^bb1
      vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
      %ref_9 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      %4 = vm.call.variadic @hal.fence.await(%c-1_1, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1, %null, %ref_9, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
      %5 = vm.call.variadic @hal.fence.await(%c-1_1, [%ref_9]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_br %5, ^bb4, ^bb3
    ^bb3:  // pred: ^bb2
      %ref_10 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_2, %c12, %c553648160, %c1, [%c3_0]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_10 : !vm.ref<!hal.buffer_view>
    ^bb4:  // pred: ^bb2
      vm.fail %5, "failed to wait on timepoint"
    }
    vm.export @main attributes {iree.abi.stub}
    vm.export @__init
    vm.func private @__init() {
      %c527363 = vm.const.i32 527363
      %c48 = vm.const.i32 48
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %null_0 = vm.const.ref.zero : !vm.ref<!hal.executable>
      %null_1 = vm.const.ref.zero : !vm.buffer
      %c2 = vm.const.i32 2
      %c7 = vm.const.i32 7
      %c1 = vm.const.i32 1
      %zero = vm.const.i64.zero
      %c128 = vm.const.i64 128
      %c-1 = vm.const.i64 -1
      %zero_2 = vm.const.i32.zero
      %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
      %_utf8_cuda_nvptx_fb_B15B42B96FDBACC = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
      %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
      %2 = vm.and.i32 %1, %c1 : i32
      %3 = vm.select.i32 %0#0, %2, %zero_2 : i32
      %ref_3 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero_2, [(%zero_2, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %zero_2)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
      %ref_4 = vm.call.variadic @hal.pipeline_layout.create(%ref, %zero_2, [%ref_3]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
      %4 = vm.select.i64 %3, %zero, %c-1 : i64
      %5 = vm.trunc.i64.i32 %4 : i64 -> i32
      vm.global.store.i32 %3, @_device_query_0 : i32
      vm.global.store.ref %ref_4, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      vm.br_table %5 {
        default: ^bb2,
        0: ^bb1
      }
    ^bb1:  // pred: ^bb0
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %main_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @main_dispatch_0_cuda_nvptx_fb : !vm.buffer
      %ref_5 = vm.call.variadic @hal.executable.create(%ref, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC, %main_dispatch_0_cuda_nvptx_fb, %null_1, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
      vm.br ^bb3(%ref_5 : !vm.ref<!hal.executable>)
    ^bb2:  // pred: ^bb0
      vm.br ^bb3(%null_0 : !vm.ref<!hal.executable>)
    ^bb3(%6: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
      %_const = vm.const.ref.rodata @_const : !vm.buffer
      %ref_6 = vm.call @hal.device.allocator(%ref) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %ref_7 = vm.call @hal.allocator.import(%ref_6, %c1, %c-1, %c48, %c527363, %_const, %zero, %c128) : (!vm.ref<!hal.allocator>, i32, i64, i32, i32, !vm.buffer, i64, i64) -> !vm.ref<!hal.buffer>
      %rnz = vm.cmp.nz.ref %ref_7 : !vm.ref<!hal.buffer>
      vm.global.store.ref %6, @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
      vm.cond_br %rnz, ^bb5(%null, %ref_7 : !vm.ref<!hal.fence>, !vm.ref<!hal.buffer>), ^bb4
    ^bb4:  // pred: ^bb3
      %ref_8 = vm.call @hal.allocator.allocate(%ref_6, %c-1, %c48, %c527363, %c128) : (!vm.ref<!hal.allocator>, i64, i32, i32, i64) -> !vm.ref<!hal.buffer>
      %ref_9 = vm.call @hal.ex.file.from_memory(%ref, %c-1, %c1, %_const, %zero, %c128, %zero_2) : (!vm.ref<!hal.device>, i64, i32, !vm.buffer, i64, i64, i32) -> !vm.ref<!hal.file>
      %ref_10 = vm.call @hal.fence.create(%ref, %zero_2) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      vm.call @hal.device.queue.read(%ref, %c-1, %null, %ref_10, %ref_9, %zero, %ref_8, %zero, %c128, %zero_2) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.file>, i64, !vm.ref<!hal.buffer>, i64, i64, i32) -> ()
      vm.br ^bb5(%ref_10, %ref_8 : !vm.ref<!hal.fence>, !vm.ref<!hal.buffer>)
    ^bb5(%7: !vm.ref<!hal.fence>, %8: !vm.ref<!hal.buffer>):  // 2 preds: ^bb3, ^bb4
      vm.global.store.ref %8, @_params.weight : !vm.ref<!hal.buffer>
      vm.global.store.ref %7, @_params.weight__timepoint : !vm.ref<!hal.fence>
      vm.return
    }
    vm.export @__deinit
    vm.func private @__deinit() {
      vm.return
    }
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda], vm.toplevel} {
  vm.module public @LinearModule {
    vm.global.i32 private mutable @_device_query_0 : i32
    vm.global.ref private mutable @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.global.ref private mutable @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
    vm.global.ref private mutable @_params.weight__timepoint : !vm.ref<!hal.fence>
    vm.global.ref private mutable @_params.weight : !vm.ref<!hal.buffer>
    vm.rodata private @main_dispatch_0_cuda_nvptx_fb {alignment = 16 : i64, mime_type = "application/x-flatbuffers"} dense<"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vector<1302xi8>
    vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
    vm.rodata private @_utf8_cuda_nvptx_fb_B15B42B96FDBACC {alignment = 1 : i64} "cuda-nvptx-fb"
    vm.rodata private @_const {alignment = 64 : i64} #composite_of_128b
    vm.import private @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects}
    vm.import private @hal.ex.file.from_memory(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %access : i32, %buffer : !vm.buffer, %offset : i64, %length : i64, %flags : i32) -> !vm.ref<!hal.file>
    vm.import private @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
    vm.import private @hal.allocator.import(%allocator : !vm.ref<!hal.allocator>, %try : i32, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %source : !vm.buffer, %offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
    vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
    vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
    vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
    vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer>
    vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
    vm.import private @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32)
    vm.import private @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects}
    vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
    vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
    vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
    vm.import private @hal.device.queue.read(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_file : !vm.ref<!hal.file>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i32)
    vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
    vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects}
    vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
    vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
    vm.import private @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects}
    vm.rodata private @_utf8_input_0_5FD512E67BEFDEEC {alignment = 1 : i64} "input 0"
    vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
    vm.func private @main(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
      %c13 = vm.const.i32 13
      %c28 = vm.const.i32 28
      %c2 = vm.const.i32 2
      %c3 = vm.const.i32 3
      %c17 = vm.const.i32 17
      %c48 = vm.const.i32 48
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %zero = vm.const.i32.zero
      %c3075 = vm.const.i32 3075
      %c16 = vm.const.i32 16
      %c3_0 = vm.const.i64 3
      %c-1 = vm.const.i64 -1
      %c-1_1 = vm.const.i32 -1
      %zero_2 = vm.const.i64.zero
      %c128 = vm.const.i64 128
      %c16_3 = vm.const.i64 16
      %c12 = vm.const.i64 12
      %c553648160 = vm.const.i32 553648160
      %c1 = vm.const.i32 1
      %c4 = vm.const.i64 4
      %_params.weight__timepoint = vm.global.load.ref @_params.weight__timepoint : !vm.ref<!hal.fence>
      %_params.weight = vm.global.load.ref @_params.weight : !vm.ref<!hal.buffer>
      %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %_executable_main_dispatch_0 = vm.global.load.ref @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
      %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1, [%c4]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c16_3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %ref_6 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      %0 = vm.call.variadic @hal.fence.await(%c-1_1, [%_params.weight__timepoint]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      %ref_7 = vm.call @hal.device.queue.alloca(%ref_4, %c-1, %null, %ref_6, %zero, %c48, %c3075, %c12) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
      %1 = vm.call.variadic @hal.fence.await(%c-1_1, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      %ref_8 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
      %2 = vm.select.i64 %_device_query_0, %zero_2, %c-1 : i64
      %3 = vm.trunc.i64.i32 %2 : i64 -> i32
      vm.br_table %3 {
        default: ^bb2,
        0: ^bb1
      }
    ^bb1:  // pred: ^bb0
      vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_8, %_pipeline_layout_0, %zero, [(%zero, %zero, %ref, %zero_2, %c16_3), (%c1, %zero, %_params.weight, %zero_2, %c128), (%c2, %zero, %ref_7, %zero_2, %c12)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      vm.call @hal.command_buffer.dispatch(%ref_8, %_executable_main_dispatch_0, %zero, %c3, %c1, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
      vm.br ^bb2
    ^bb2:  // 2 preds: ^bb0, ^bb1
      vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
      %ref_9 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      %4 = vm.call.variadic @hal.fence.await(%c-1_1, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1, %null, %ref_9, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
      %5 = vm.call.variadic @hal.fence.await(%c-1_1, [%ref_9]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_br %5, ^bb4, ^bb3
    ^bb3:  // pred: ^bb2
      %ref_10 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_2, %c12, %c553648160, %c1, [%c3_0]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_10 : !vm.ref<!hal.buffer_view>
    ^bb4:  // pred: ^bb2
      vm.fail %5, "failed to wait on timepoint"
    }
    vm.export @main attributes {iree.abi.stub}
    vm.export @__init
    vm.func private @__init() {
      %c527363 = vm.const.i32 527363
      %c48 = vm.const.i32 48
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %null_0 = vm.const.ref.zero : !vm.ref<!hal.executable>
      %null_1 = vm.const.ref.zero : !vm.buffer
      %c2 = vm.const.i32 2
      %c7 = vm.const.i32 7
      %c1 = vm.const.i32 1
      %zero = vm.const.i64.zero
      %c128 = vm.const.i64 128
      %c-1 = vm.const.i64 -1
      %zero_2 = vm.const.i32.zero
      %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
      %_utf8_cuda_nvptx_fb_B15B42B96FDBACC = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
      %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
      %2 = vm.and.i32 %1, %c1 : i32
      %3 = vm.select.i32 %0#0, %2, %zero_2 : i32
      %ref_3 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero_2, [(%zero_2, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %zero_2)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
      %ref_4 = vm.call.variadic @hal.pipeline_layout.create(%ref, %zero_2, [%ref_3]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
      %4 = vm.select.i64 %3, %zero, %c-1 : i64
      %5 = vm.trunc.i64.i32 %4 : i64 -> i32
      vm.global.store.i32 %3, @_device_query_0 : i32
      vm.global.store.ref %ref_4, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      vm.br_table %5 {
        default: ^bb2,
        0: ^bb1
      }
    ^bb1:  // pred: ^bb0
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %main_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @main_dispatch_0_cuda_nvptx_fb : !vm.buffer
      %ref_5 = vm.call.variadic @hal.executable.create(%ref, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC, %main_dispatch_0_cuda_nvptx_fb, %null_1, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
      vm.br ^bb3(%ref_5 : !vm.ref<!hal.executable>)
    ^bb2:  // pred: ^bb0
      vm.br ^bb3(%null_0 : !vm.ref<!hal.executable>)
    ^bb3(%6: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
      %_const = vm.const.ref.rodata @_const : !vm.buffer
      %ref_6 = vm.call @hal.device.allocator(%ref) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %ref_7 = vm.call @hal.allocator.import(%ref_6, %c1, %c-1, %c48, %c527363, %_const, %zero, %c128) : (!vm.ref<!hal.allocator>, i32, i64, i32, i32, !vm.buffer, i64, i64) -> !vm.ref<!hal.buffer>
      %rnz = vm.cmp.nz.ref %ref_7 : !vm.ref<!hal.buffer>
      vm.global.store.ref %6, @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
      vm.cond_br %rnz, ^bb5(%null, %ref_7 : !vm.ref<!hal.fence>, !vm.ref<!hal.buffer>), ^bb4
    ^bb4:  // pred: ^bb3
      %ref_8 = vm.call @hal.allocator.allocate(%ref_6, %c-1, %c48, %c527363, %c128) : (!vm.ref<!hal.allocator>, i64, i32, i32, i64) -> !vm.ref<!hal.buffer>
      %ref_9 = vm.call @hal.ex.file.from_memory(%ref, %c-1, %c1, %_const, %zero, %c128, %zero_2) : (!vm.ref<!hal.device>, i64, i32, !vm.buffer, i64, i64, i32) -> !vm.ref<!hal.file>
      %ref_10 = vm.call @hal.fence.create(%ref, %zero_2) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      vm.call @hal.device.queue.read(%ref, %c-1, %null, %ref_10, %ref_9, %zero, %ref_8, %zero, %c128, %zero_2) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.file>, i64, !vm.ref<!hal.buffer>, i64, i64, i32) -> ()
      vm.br ^bb5(%ref_10, %ref_8 : !vm.ref<!hal.fence>, !vm.ref<!hal.buffer>)
    ^bb5(%7: !vm.ref<!hal.fence>, %8: !vm.ref<!hal.buffer>):  // 2 preds: ^bb3, ^bb4
      vm.global.store.ref %8, @_params.weight : !vm.ref<!hal.buffer>
      vm.global.store.ref %7, @_params.weight__timepoint : !vm.ref<!hal.fence>
      vm.return
    }
    vm.export @__deinit
    vm.func private @__deinit() {
      vm.return
    }
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::VM::DropEmptyModuleInitializersPass (iree-vm-drop-empty-module-initializers) //----- //
vm.module public @LinearModule {
  vm.global.i32 private mutable @_device_query_0 : i32
  vm.global.ref private mutable @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
  vm.global.ref private mutable @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
  vm.global.ref private mutable @_params.weight__timepoint : !vm.ref<!hal.fence>
  vm.global.ref private mutable @_params.weight : !vm.ref<!hal.buffer>
  vm.rodata private @main_dispatch_0_cuda_nvptx_fb {alignment = 16 : i64, mime_type = "application/x-flatbuffers"} dense<"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vector<1302xi8>
  vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
  vm.rodata private @_utf8_cuda_nvptx_fb_B15B42B96FDBACC {alignment = 1 : i64} "cuda-nvptx-fb"
  vm.rodata private @_const {alignment = 64 : i64} #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
  vm.import private @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects}
  vm.import private @hal.ex.file.from_memory(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %access : i32, %buffer : !vm.buffer, %offset : i64, %length : i64, %flags : i32) -> !vm.ref<!hal.file>
  vm.import private @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
  vm.import private @hal.allocator.import(%allocator : !vm.ref<!hal.allocator>, %try : i32, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %source : !vm.buffer, %offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
  vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
  vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
  vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
  vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
  vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer>
  vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
  vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
  vm.import private @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32)
  vm.import private @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects}
  vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
  vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
  vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
  vm.import private @hal.device.queue.read(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_file : !vm.ref<!hal.file>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i32)
  vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
  vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects}
  vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
  vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
  vm.import private @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects}
  vm.rodata private @_utf8_input_0_5FD512E67BEFDEEC {alignment = 1 : i64} "input 0"
  vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
  vm.func private @main(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
    %c13 = vm.const.i32 13
    %c28 = vm.const.i32 28
    %c2 = vm.const.i32 2
    %c3 = vm.const.i32 3
    %c17 = vm.const.i32 17
    %c48 = vm.const.i32 48
    %null = vm.const.ref.zero : !vm.ref<!hal.fence>
    %zero = vm.const.i32.zero
    %c3075 = vm.const.i32 3075
    %c16 = vm.const.i32 16
    %c3_0 = vm.const.i64 3
    %c-1 = vm.const.i64 -1
    %c-1_1 = vm.const.i32 -1
    %zero_2 = vm.const.i64.zero
    %c128 = vm.const.i64 128
    %c16_3 = vm.const.i64 16
    %c12 = vm.const.i64 12
    %c553648160 = vm.const.i32 553648160
    %c1 = vm.const.i32 1
    %c4 = vm.const.i64 4
    %_params.weight__timepoint = vm.global.load.ref @_params.weight__timepoint : !vm.ref<!hal.fence>
    %_params.weight = vm.global.load.ref @_params.weight : !vm.ref<!hal.buffer>
    %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %_executable_main_dispatch_0 = vm.global.load.ref @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
    %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1, [%c4]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
    vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c16_3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %ref_6 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    %0 = vm.call.variadic @hal.fence.await(%c-1_1, [%_params.weight__timepoint]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    %ref_7 = vm.call @hal.device.queue.alloca(%ref_4, %c-1, %null, %ref_6, %zero, %c48, %c3075, %c12) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
    %1 = vm.call.variadic @hal.fence.await(%c-1_1, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    %ref_8 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
    %2 = vm.select.i64 %_device_query_0, %zero_2, %c-1 : i64
    %3 = vm.trunc.i64.i32 %2 : i64 -> i32
    vm.br_table %3 {
      default: ^bb2,
      0: ^bb1
    }
  ^bb1:  // pred: ^bb0
    vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_8, %_pipeline_layout_0, %zero, [(%zero, %zero, %ref, %zero_2, %c16_3), (%c1, %zero, %_params.weight, %zero_2, %c128), (%c2, %zero, %ref_7, %zero_2, %c12)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.call @hal.command_buffer.dispatch(%ref_8, %_executable_main_dispatch_0, %zero, %c3, %c1, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
    vm.br ^bb2
  ^bb2:  // 2 preds: ^bb0, ^bb1
    vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
    vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
    %ref_9 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    %4 = vm.call.variadic @hal.fence.await(%c-1_1, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1, %null, %ref_9, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
    %5 = vm.call.variadic @hal.fence.await(%c-1_1, [%ref_9]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    vm.cond_br %5, ^bb4, ^bb3
  ^bb3:  // pred: ^bb2
    %ref_10 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_2, %c12, %c553648160, %c1, [%c3_0]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
    vm.return %ref_10 : !vm.ref<!hal.buffer_view>
  ^bb4:  // pred: ^bb2
    vm.fail %5, "failed to wait on timepoint"
  }
  vm.export @main attributes {iree.abi.stub}
  vm.export @__init
  vm.func private @__init() {
    %c527363 = vm.const.i32 527363
    %c48 = vm.const.i32 48
    %null = vm.const.ref.zero : !vm.ref<!hal.fence>
    %null_0 = vm.const.ref.zero : !vm.ref<!hal.executable>
    %null_1 = vm.const.ref.zero : !vm.buffer
    %c2 = vm.const.i32 2
    %c7 = vm.const.i32 7
    %c1 = vm.const.i32 1
    %zero = vm.const.i64.zero
    %c128 = vm.const.i64 128
    %c-1 = vm.const.i64 -1
    %zero_2 = vm.const.i32.zero
    %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
    %_utf8_cuda_nvptx_fb_B15B42B96FDBACC = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
    %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
    %2 = vm.and.i32 %1, %c1 : i32
    %3 = vm.select.i32 %0#0, %2, %zero_2 : i32
    %ref_3 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero_2, [(%zero_2, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %zero_2)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
    %ref_4 = vm.call.variadic @hal.pipeline_layout.create(%ref, %zero_2, [%ref_3]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
    %4 = vm.select.i64 %3, %zero, %c-1 : i64
    %5 = vm.trunc.i64.i32 %4 : i64 -> i32
    vm.global.store.i32 %3, @_device_query_0 : i32
    vm.global.store.ref %ref_4, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.br_table %5 {
      default: ^bb2,
      0: ^bb1
    }
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %main_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @main_dispatch_0_cuda_nvptx_fb : !vm.buffer
    %ref_5 = vm.call.variadic @hal.executable.create(%ref, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC, %main_dispatch_0_cuda_nvptx_fb, %null_1, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
    vm.br ^bb3(%ref_5 : !vm.ref<!hal.executable>)
  ^bb2:  // pred: ^bb0
    vm.br ^bb3(%null_0 : !vm.ref<!hal.executable>)
  ^bb3(%6: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
    %_const = vm.const.ref.rodata @_const : !vm.buffer
    %ref_6 = vm.call @hal.device.allocator(%ref) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    %ref_7 = vm.call @hal.allocator.import(%ref_6, %c1, %c-1, %c48, %c527363, %_const, %zero, %c128) : (!vm.ref<!hal.allocator>, i32, i64, i32, i32, !vm.buffer, i64, i64) -> !vm.ref<!hal.buffer>
    %rnz = vm.cmp.nz.ref %ref_7 : !vm.ref<!hal.buffer>
    vm.global.store.ref %6, @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
    vm.cond_br %rnz, ^bb5(%null, %ref_7 : !vm.ref<!hal.fence>, !vm.ref<!hal.buffer>), ^bb4
  ^bb4:  // pred: ^bb3
    %ref_8 = vm.call @hal.allocator.allocate(%ref_6, %c-1, %c48, %c527363, %c128) : (!vm.ref<!hal.allocator>, i64, i32, i32, i64) -> !vm.ref<!hal.buffer>
    %ref_9 = vm.call @hal.ex.file.from_memory(%ref, %c-1, %c1, %_const, %zero, %c128, %zero_2) : (!vm.ref<!hal.device>, i64, i32, !vm.buffer, i64, i64, i32) -> !vm.ref<!hal.file>
    %ref_10 = vm.call @hal.fence.create(%ref, %zero_2) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    vm.call @hal.device.queue.read(%ref, %c-1, %null, %ref_10, %ref_9, %zero, %ref_8, %zero, %c128, %zero_2) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.file>, i64, !vm.ref<!hal.buffer>, i64, i64, i32) -> ()
    vm.br ^bb5(%ref_10, %ref_8 : !vm.ref<!hal.fence>, !vm.ref<!hal.buffer>)
  ^bb5(%7: !vm.ref<!hal.fence>, %8: !vm.ref<!hal.buffer>):  // 2 preds: ^bb3, ^bb4
    vm.global.store.ref %8, @_params.weight : !vm.ref<!hal.buffer>
    vm.global.store.ref %7, @_params.weight__timepoint : !vm.ref<!hal.fence>
    vm.return
  }
}

// -----// IR Dump After DropCompilerHints (iree-util-drop-compiler-hints) //----- //
#composite_of_128b = #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
#executable_target_cuda_nvptx_fb = #hal.executable.target<"cuda", "cuda-nvptx-fb", {target_arch = "sm_75"}>
#device_target_cuda = #hal.device.target<"cuda", {executable_targets = [#executable_target_cuda_nvptx_fb], legacy_sync}>
module @LinearModule attributes {hal.device.targets = [#device_target_cuda], vm.toplevel} {
  vm.module public @LinearModule {
    vm.global.i32 private mutable @_device_query_0 : i32
    vm.global.ref private mutable @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.global.ref private mutable @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
    vm.global.ref private mutable @_params.weight__timepoint : !vm.ref<!hal.fence>
    vm.global.ref private mutable @_params.weight : !vm.ref<!hal.buffer>
    vm.rodata private @main_dispatch_0_cuda_nvptx_fb {alignment = 16 : i64, mime_type = "application/x-flatbuffers"} dense<"0x080000004355444100FBFFFF1C0000005000000044000000580000000400000001000000C00400000100000004000000200000006D61696E5F64697370617463685F305F6D61746D756C5F31783378345F663332000000000100000000000000010000000100000003000000010000006F0400002F2F0A2F2F2047656E657261746564206279204C4C564D204E56505458204261636B2D456E640A2F2F0A0A2E76657273696F6E20372E350A2E74617267657420736D5F37350A2E616464726573735F73697A652036340A0A092F2F202E676C6F626C096D61696E5F64697370617463685F305F6D61746D756C5F31783378345F6633320A0A2E76697369626C65202E656E747279206D61696E5F64697370617463685F305F6D61746D756C5F31783378345F663332280A092E706172616D202E753634206D61696E5F64697370617463685F305F6D61746D756C5F31783378345F6633325F706172616D5F302C0A092E706172616D202E753634206D61696E5F64697370617463685F305F6D61746D756C5F31783378345F6633325F706172616D5F312C0A092E706172616D202E753634206D61696E5F64697370617463685F305F6D61746D756C5F31783378345F6633325F706172616D5F320A290A2E6D61786E74696420312C20332C20310A7B0A092E726567202E623332200925723C323E3B0A092E726567202E663332200925663C31343E3B0A092E726567202E62363420092572643C373E3B0A0A096C642E706172616D2E7536342009257264312C205B6D61696E5F64697370617463685F305F6D61746D756C5F31783378345F6633325F706172616D5F305D3B0A096C642E706172616D2E7536342009257264322C205B6D61696E5F64697370617463685F305F6D61746D756C5F31783378345F6633325F706172616D5F315D3B0A096C642E706172616D2E7536342009257264332C205B6D61696E5F64697370617463685F305F6D61746D756C5F31783378345F6633325F706172616D5F325D3B0A096D6F762E75333220092572312C202563746169642E783B0A096C642E676C6F62616C2E6E632E76342E66333220097B2566312C202566322C202566332C202566347D2C205B257264315D3B0A096D756C2E776964652E7533322009257264342C202572312C20343B0A096164642E7336342009257264352C20257264322C20257264343B0A096C642E676C6F62616C2E6E632E66333220092566352C205B257264355D3B0A096C642E676C6F62616C2E6E632E66333220092566362C205B257264352B31325D3B0A096C642E676C6F62616C2E6E632E66333220092566372C205B257264352B32345D3B0A096C642E676C6F62616C2E6E632E66333220092566382C205B257264352B33365D3B0A096C642E676C6F62616C2E6E632E66333220092566392C205B257264352B36345D3B0A09666D612E726E2E6633322009256631302C202566312C202566352C202566393B0A09666D612E726E2E6633322009256631312C202566322C202566362C20256631303B0A09666D612E726E2E6633322009256631322C202566332C202566372C20256631313B0A09666D612E726E2E6633322009256631332C202566342C202566382C20256631323B0A096164642E7336342009257264362C20257264332C20257264343B0A0973742E676C6F62616C2E66333220095B257264365D2C20256631333B0A097265743B0A0A7D0A00E4FFFFFF08000000040000000A000000696E7075742E6D6C6972000008000C00040008000E001800040008000C0010001400"> : vector<1302xi8>
    vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
    vm.rodata private @_utf8_cuda_nvptx_fb_B15B42B96FDBACC {alignment = 1 : i64} "cuda-nvptx-fb"
    vm.rodata private @_const {alignment = 64 : i64} #composite_of_128b
    vm.import private @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects}
    vm.import private @hal.ex.file.from_memory(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %access : i32, %buffer : !vm.buffer, %offset : i64, %length : i64, %flags : i32) -> !vm.ref<!hal.file>
    vm.import private @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
    vm.import private @hal.allocator.import(%allocator : !vm.ref<!hal.allocator>, %try : i32, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %source : !vm.buffer, %offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
    vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
    vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
    vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
    vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer>
    vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
    vm.import private @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32)
    vm.import private @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects}
    vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
    vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
    vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
    vm.import private @hal.device.queue.read(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_file : !vm.ref<!hal.file>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i32)
    vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
    vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects}
    vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
    vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
    vm.import private @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects}
    vm.rodata private @_utf8_input_0_5FD512E67BEFDEEC {alignment = 1 : i64} "input 0"
    vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
    vm.func private @main(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
      %c13 = vm.const.i32 13
      %c28 = vm.const.i32 28
      %c2 = vm.const.i32 2
      %c3 = vm.const.i32 3
      %c17 = vm.const.i32 17
      %c48 = vm.const.i32 48
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %zero = vm.const.i32.zero
      %c3075 = vm.const.i32 3075
      %c16 = vm.const.i32 16
      %c3_0 = vm.const.i64 3
      %c-1 = vm.const.i64 -1
      %c-1_1 = vm.const.i32 -1
      %zero_2 = vm.const.i64.zero
      %c128 = vm.const.i64 128
      %c16_3 = vm.const.i64 16
      %c12 = vm.const.i64 12
      %c553648160 = vm.const.i32 553648160
      %c1 = vm.const.i32 1
      %c4 = vm.const.i64 4
      %_params.weight__timepoint = vm.global.load.ref @_params.weight__timepoint : !vm.ref<!hal.fence>
      %_params.weight = vm.global.load.ref @_params.weight : !vm.ref<!hal.buffer>
      %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %_executable_main_dispatch_0 = vm.global.load.ref @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
      %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1, [%c4]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c16_3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %ref_6 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      %0 = vm.call.variadic @hal.fence.await(%c-1_1, [%_params.weight__timepoint]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      %ref_7 = vm.call @hal.device.queue.alloca(%ref_4, %c-1, %null, %ref_6, %zero, %c48, %c3075, %c12) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
      %1 = vm.call.variadic @hal.fence.await(%c-1_1, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      %ref_8 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
      %2 = vm.select.i64 %_device_query_0, %zero_2, %c-1 : i64
      %3 = vm.trunc.i64.i32 %2 : i64 -> i32
      vm.br_table %3 {
        default: ^bb2,
        0: ^bb1
      }
    ^bb1:  // pred: ^bb0
      vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_8, %_pipeline_layout_0, %zero, [(%zero, %zero, %ref, %zero_2, %c16_3), (%c1, %zero, %_params.weight, %zero_2, %c128), (%c2, %zero, %ref_7, %zero_2, %c12)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      vm.call @hal.command_buffer.dispatch(%ref_8, %_executable_main_dispatch_0, %zero, %c3, %c1, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
      vm.br ^bb2
    ^bb2:  // 2 preds: ^bb0, ^bb1
      vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
      %ref_9 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      %4 = vm.call.variadic @hal.fence.await(%c-1_1, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1, %null, %ref_9, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
      %5 = vm.call.variadic @hal.fence.await(%c-1_1, [%ref_9]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_br %5, ^bb4, ^bb3
    ^bb3:  // pred: ^bb2
      %ref_10 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_2, %c12, %c553648160, %c1, [%c3_0]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_10 : !vm.ref<!hal.buffer_view>
    ^bb4:  // pred: ^bb2
      vm.fail %5, "failed to wait on timepoint"
    }
    vm.export @main attributes {iree.abi.stub}
    vm.export @__init
    vm.func private @__init() {
      %c527363 = vm.const.i32 527363
      %c48 = vm.const.i32 48
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %null_0 = vm.const.ref.zero : !vm.ref<!hal.executable>
      %null_1 = vm.const.ref.zero : !vm.buffer
      %c2 = vm.const.i32 2
      %c7 = vm.const.i32 7
      %c1 = vm.const.i32 1
      %zero = vm.const.i64.zero
      %c128 = vm.const.i64 128
      %c-1 = vm.const.i64 -1
      %zero_2 = vm.const.i32.zero
      %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
      %_utf8_cuda_nvptx_fb_B15B42B96FDBACC = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
      %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
      %2 = vm.and.i32 %1, %c1 : i32
      %3 = vm.select.i32 %0#0, %2, %zero_2 : i32
      %ref_3 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero_2, [(%zero_2, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %zero_2)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
      %ref_4 = vm.call.variadic @hal.pipeline_layout.create(%ref, %zero_2, [%ref_3]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
      %4 = vm.select.i64 %3, %zero, %c-1 : i64
      %5 = vm.trunc.i64.i32 %4 : i64 -> i32
      vm.global.store.i32 %3, @_device_query_0 : i32
      vm.global.store.ref %ref_4, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      vm.br_table %5 {
        default: ^bb2,
        0: ^bb1
      }
    ^bb1:  // pred: ^bb0
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %main_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @main_dispatch_0_cuda_nvptx_fb : !vm.buffer
      %ref_5 = vm.call.variadic @hal.executable.create(%ref, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC, %main_dispatch_0_cuda_nvptx_fb, %null_1, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
      vm.br ^bb3(%ref_5 : !vm.ref<!hal.executable>)
    ^bb2:  // pred: ^bb0
      vm.br ^bb3(%null_0 : !vm.ref<!hal.executable>)
    ^bb3(%6: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
      %_const = vm.const.ref.rodata @_const : !vm.buffer
      %ref_6 = vm.call @hal.device.allocator(%ref) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %ref_7 = vm.call @hal.allocator.import(%ref_6, %c1, %c-1, %c48, %c527363, %_const, %zero, %c128) : (!vm.ref<!hal.allocator>, i32, i64, i32, i32, !vm.buffer, i64, i64) -> !vm.ref<!hal.buffer>
      %rnz = vm.cmp.nz.ref %ref_7 : !vm.ref<!hal.buffer>
      vm.global.store.ref %6, @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
      vm.cond_br %rnz, ^bb5(%null, %ref_7 : !vm.ref<!hal.fence>, !vm.ref<!hal.buffer>), ^bb4
    ^bb4:  // pred: ^bb3
      %ref_8 = vm.call @hal.allocator.allocate(%ref_6, %c-1, %c48, %c527363, %c128) : (!vm.ref<!hal.allocator>, i64, i32, i32, i64) -> !vm.ref<!hal.buffer>
      %ref_9 = vm.call @hal.ex.file.from_memory(%ref, %c-1, %c1, %_const, %zero, %c128, %zero_2) : (!vm.ref<!hal.device>, i64, i32, !vm.buffer, i64, i64, i32) -> !vm.ref<!hal.file>
      %ref_10 = vm.call @hal.fence.create(%ref, %zero_2) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      vm.call @hal.device.queue.read(%ref, %c-1, %null, %ref_10, %ref_9, %zero, %ref_8, %zero, %c128, %zero_2) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.file>, i64, !vm.ref<!hal.buffer>, i64, i64, i32) -> ()
      vm.br ^bb5(%ref_10, %ref_8 : !vm.ref<!hal.fence>, !vm.ref<!hal.buffer>)
    ^bb5(%7: !vm.ref<!hal.fence>, %8: !vm.ref<!hal.buffer>):  // 2 preds: ^bb3, ^bb4
      vm.global.store.ref %8, @_params.weight : !vm.ref<!hal.buffer>
      vm.global.store.ref %7, @_params.weight__timepoint : !vm.ref<!hal.fence>
      vm.return
    }
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::VM::GlobalInitializationPass (iree-vm-global-initialization) //----- //
vm.module public @LinearModule {
  vm.global.i32 private mutable @_device_query_0 : i32
  vm.global.ref private mutable @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
  vm.global.ref private mutable @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
  vm.global.ref private mutable @_params.weight__timepoint : !vm.ref<!hal.fence>
  vm.global.ref private mutable @_params.weight : !vm.ref<!hal.buffer>
  vm.rodata private @main_dispatch_0_cuda_nvptx_fb {alignment = 16 : i64, mime_type = "application/x-flatbuffers"} dense<"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vector<1302xi8>
  vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
  vm.rodata private @_utf8_cuda_nvptx_fb_B15B42B96FDBACC {alignment = 1 : i64} "cuda-nvptx-fb"
  vm.rodata private @_const {alignment = 64 : i64} #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
  vm.import private @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects}
  vm.import private @hal.ex.file.from_memory(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %access : i32, %buffer : !vm.buffer, %offset : i64, %length : i64, %flags : i32) -> !vm.ref<!hal.file>
  vm.import private @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
  vm.import private @hal.allocator.import(%allocator : !vm.ref<!hal.allocator>, %try : i32, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %source : !vm.buffer, %offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
  vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
  vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
  vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
  vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
  vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer>
  vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
  vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
  vm.import private @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32)
  vm.import private @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects}
  vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
  vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
  vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
  vm.import private @hal.device.queue.read(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_file : !vm.ref<!hal.file>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i32)
  vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
  vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects}
  vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
  vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
  vm.import private @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects}
  vm.rodata private @_utf8_input_0_5FD512E67BEFDEEC {alignment = 1 : i64} "input 0"
  vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
  vm.func private @main(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
    %c13 = vm.const.i32 13
    %c28 = vm.const.i32 28
    %c2 = vm.const.i32 2
    %c3 = vm.const.i32 3
    %c17 = vm.const.i32 17
    %c48 = vm.const.i32 48
    %null = vm.const.ref.zero : !vm.ref<!hal.fence>
    %zero = vm.const.i32.zero
    %c3075 = vm.const.i32 3075
    %c16 = vm.const.i32 16
    %c3_0 = vm.const.i64 3
    %c-1 = vm.const.i64 -1
    %c-1_1 = vm.const.i32 -1
    %zero_2 = vm.const.i64.zero
    %c128 = vm.const.i64 128
    %c16_3 = vm.const.i64 16
    %c12 = vm.const.i64 12
    %c553648160 = vm.const.i32 553648160
    %c1 = vm.const.i32 1
    %c4 = vm.const.i64 4
    %_params.weight__timepoint = vm.global.load.ref @_params.weight__timepoint : !vm.ref<!hal.fence>
    %_params.weight = vm.global.load.ref @_params.weight : !vm.ref<!hal.buffer>
    %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %_executable_main_dispatch_0 = vm.global.load.ref @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
    %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1, [%c4]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
    vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c16_3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %ref_6 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    %0 = vm.call.variadic @hal.fence.await(%c-1_1, [%_params.weight__timepoint]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    %ref_7 = vm.call @hal.device.queue.alloca(%ref_4, %c-1, %null, %ref_6, %zero, %c48, %c3075, %c12) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
    %1 = vm.call.variadic @hal.fence.await(%c-1_1, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    %ref_8 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
    %2 = vm.select.i64 %_device_query_0, %zero_2, %c-1 : i64
    %3 = vm.trunc.i64.i32 %2 : i64 -> i32
    vm.br_table %3 {
      default: ^bb2,
      0: ^bb1
    }
  ^bb1:  // pred: ^bb0
    vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_8, %_pipeline_layout_0, %zero, [(%zero, %zero, %ref, %zero_2, %c16_3), (%c1, %zero, %_params.weight, %zero_2, %c128), (%c2, %zero, %ref_7, %zero_2, %c12)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.call @hal.command_buffer.dispatch(%ref_8, %_executable_main_dispatch_0, %zero, %c3, %c1, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
    vm.br ^bb2
  ^bb2:  // 2 preds: ^bb0, ^bb1
    vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
    vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
    %ref_9 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    %4 = vm.call.variadic @hal.fence.await(%c-1_1, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1, %null, %ref_9, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
    %5 = vm.call.variadic @hal.fence.await(%c-1_1, [%ref_9]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    vm.cond_br %5, ^bb4, ^bb3
  ^bb3:  // pred: ^bb2
    %ref_10 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_2, %c12, %c553648160, %c1, [%c3_0]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
    vm.return %ref_10 : !vm.ref<!hal.buffer_view>
  ^bb4:  // pred: ^bb2
    vm.fail %5, "failed to wait on timepoint"
  }
  vm.export @main attributes {iree.abi.stub}
  vm.export @__init
  vm.func private @__init() {
    %c527363 = vm.const.i32 527363
    %c48 = vm.const.i32 48
    %null = vm.const.ref.zero : !vm.ref<!hal.fence>
    %null_0 = vm.const.ref.zero : !vm.ref<!hal.executable>
    %null_1 = vm.const.ref.zero : !vm.buffer
    %c2 = vm.const.i32 2
    %c7 = vm.const.i32 7
    %c1 = vm.const.i32 1
    %zero = vm.const.i64.zero
    %c128 = vm.const.i64 128
    %c-1 = vm.const.i64 -1
    %zero_2 = vm.const.i32.zero
    %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
    %_utf8_cuda_nvptx_fb_B15B42B96FDBACC = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
    %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
    %2 = vm.and.i32 %1, %c1 : i32
    %3 = vm.select.i32 %0#0, %2, %zero_2 : i32
    %ref_3 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero_2, [(%zero_2, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %zero_2)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
    %ref_4 = vm.call.variadic @hal.pipeline_layout.create(%ref, %zero_2, [%ref_3]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
    %4 = vm.select.i64 %3, %zero, %c-1 : i64
    %5 = vm.trunc.i64.i32 %4 : i64 -> i32
    vm.global.store.i32 %3, @_device_query_0 : i32
    vm.global.store.ref %ref_4, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.br_table %5 {
      default: ^bb2,
      0: ^bb1
    }
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %main_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @main_dispatch_0_cuda_nvptx_fb : !vm.buffer
    %ref_5 = vm.call.variadic @hal.executable.create(%ref, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC, %main_dispatch_0_cuda_nvptx_fb, %null_1, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
    vm.br ^bb3(%ref_5 : !vm.ref<!hal.executable>)
  ^bb2:  // pred: ^bb0
    vm.br ^bb3(%null_0 : !vm.ref<!hal.executable>)
  ^bb3(%6: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
    %_const = vm.const.ref.rodata @_const : !vm.buffer
    %ref_6 = vm.call @hal.device.allocator(%ref) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    %ref_7 = vm.call @hal.allocator.import(%ref_6, %c1, %c-1, %c48, %c527363, %_const, %zero, %c128) : (!vm.ref<!hal.allocator>, i32, i64, i32, i32, !vm.buffer, i64, i64) -> !vm.ref<!hal.buffer>
    %rnz = vm.cmp.nz.ref %ref_7 : !vm.ref<!hal.buffer>
    vm.global.store.ref %6, @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
    vm.cond_br %rnz, ^bb5(%null, %ref_7 : !vm.ref<!hal.fence>, !vm.ref<!hal.buffer>), ^bb4
  ^bb4:  // pred: ^bb3
    %ref_8 = vm.call @hal.allocator.allocate(%ref_6, %c-1, %c48, %c527363, %c128) : (!vm.ref<!hal.allocator>, i64, i32, i32, i64) -> !vm.ref<!hal.buffer>
    %ref_9 = vm.call @hal.ex.file.from_memory(%ref, %c-1, %c1, %_const, %zero, %c128, %zero_2) : (!vm.ref<!hal.device>, i64, i32, !vm.buffer, i64, i64, i32) -> !vm.ref<!hal.file>
    %ref_10 = vm.call @hal.fence.create(%ref, %zero_2) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    vm.call @hal.device.queue.read(%ref, %c-1, %null, %ref_10, %ref_9, %zero, %ref_8, %zero, %c128, %zero_2) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.file>, i64, !vm.ref<!hal.buffer>, i64, i64, i32) -> ()
    vm.br ^bb5(%ref_10, %ref_8 : !vm.ref<!hal.fence>, !vm.ref<!hal.buffer>)
  ^bb5(%7: !vm.ref<!hal.fence>, %8: !vm.ref<!hal.buffer>):  // 2 preds: ^bb3, ^bb4
    vm.global.store.ref %8, @_params.weight : !vm.ref<!hal.buffer>
    vm.global.store.ref %7, @_params.weight__timepoint : !vm.ref<!hal.fence>
    vm.br ^bb6
  ^bb6:  // pred: ^bb5
    vm.return
  }
  vm.export @__deinit
  vm.func private @__deinit() {
    vm.return
  }
}

// -----// IR Dump After mlir::iree_compiler::IREE::VM::DropEmptyModuleInitializersPass (iree-vm-drop-empty-module-initializers) //----- //
vm.module public @LinearModule {
  vm.global.i32 private mutable @_device_query_0 : i32
  vm.global.ref private mutable @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
  vm.global.ref private mutable @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
  vm.global.ref private mutable @_params.weight__timepoint : !vm.ref<!hal.fence>
  vm.global.ref private mutable @_params.weight : !vm.ref<!hal.buffer>
  vm.rodata private @main_dispatch_0_cuda_nvptx_fb {alignment = 16 : i64, mime_type = "application/x-flatbuffers"} dense<"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vector<1302xi8>
  vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
  vm.rodata private @_utf8_cuda_nvptx_fb_B15B42B96FDBACC {alignment = 1 : i64} "cuda-nvptx-fb"
  vm.rodata private @_const {alignment = 64 : i64} #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
  vm.import private @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects}
  vm.import private @hal.ex.file.from_memory(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %access : i32, %buffer : !vm.buffer, %offset : i64, %length : i64, %flags : i32) -> !vm.ref<!hal.file>
  vm.import private @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
  vm.import private @hal.allocator.import(%allocator : !vm.ref<!hal.allocator>, %try : i32, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %source : !vm.buffer, %offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
  vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
  vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
  vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
  vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
  vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer>
  vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
  vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
  vm.import private @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32)
  vm.import private @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects}
  vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
  vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
  vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
  vm.import private @hal.device.queue.read(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_file : !vm.ref<!hal.file>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i32)
  vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
  vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects}
  vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
  vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
  vm.import private @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects}
  vm.rodata private @_utf8_input_0_5FD512E67BEFDEEC {alignment = 1 : i64} "input 0"
  vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
  vm.func private @main(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
    %c13 = vm.const.i32 13
    %c28 = vm.const.i32 28
    %c2 = vm.const.i32 2
    %c3 = vm.const.i32 3
    %c17 = vm.const.i32 17
    %c48 = vm.const.i32 48
    %null = vm.const.ref.zero : !vm.ref<!hal.fence>
    %zero = vm.const.i32.zero
    %c3075 = vm.const.i32 3075
    %c16 = vm.const.i32 16
    %c3_0 = vm.const.i64 3
    %c-1 = vm.const.i64 -1
    %c-1_1 = vm.const.i32 -1
    %zero_2 = vm.const.i64.zero
    %c128 = vm.const.i64 128
    %c16_3 = vm.const.i64 16
    %c12 = vm.const.i64 12
    %c553648160 = vm.const.i32 553648160
    %c1 = vm.const.i32 1
    %c4 = vm.const.i64 4
    %_params.weight__timepoint = vm.global.load.ref @_params.weight__timepoint : !vm.ref<!hal.fence>
    %_params.weight = vm.global.load.ref @_params.weight : !vm.ref<!hal.buffer>
    %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %_executable_main_dispatch_0 = vm.global.load.ref @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
    %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1, [%c4]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
    vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c16_3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %ref_6 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    %0 = vm.call.variadic @hal.fence.await(%c-1_1, [%_params.weight__timepoint]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    %ref_7 = vm.call @hal.device.queue.alloca(%ref_4, %c-1, %null, %ref_6, %zero, %c48, %c3075, %c12) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
    %1 = vm.call.variadic @hal.fence.await(%c-1_1, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    %ref_8 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
    %2 = vm.select.i64 %_device_query_0, %zero_2, %c-1 : i64
    %3 = vm.trunc.i64.i32 %2 : i64 -> i32
    vm.br_table %3 {
      default: ^bb2,
      0: ^bb1
    }
  ^bb1:  // pred: ^bb0
    vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_8, %_pipeline_layout_0, %zero, [(%zero, %zero, %ref, %zero_2, %c16_3), (%c1, %zero, %_params.weight, %zero_2, %c128), (%c2, %zero, %ref_7, %zero_2, %c12)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.call @hal.command_buffer.dispatch(%ref_8, %_executable_main_dispatch_0, %zero, %c3, %c1, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
    vm.br ^bb2
  ^bb2:  // 2 preds: ^bb0, ^bb1
    vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
    vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
    %ref_9 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    %4 = vm.call.variadic @hal.fence.await(%c-1_1, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1, %null, %ref_9, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
    %5 = vm.call.variadic @hal.fence.await(%c-1_1, [%ref_9]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    vm.cond_br %5, ^bb4, ^bb3
  ^bb3:  // pred: ^bb2
    %ref_10 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_2, %c12, %c553648160, %c1, [%c3_0]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
    vm.return %ref_10 : !vm.ref<!hal.buffer_view>
  ^bb4:  // pred: ^bb2
    vm.fail %5, "failed to wait on timepoint"
  }
  vm.export @main attributes {iree.abi.stub}
  vm.export @__init
  vm.func private @__init() {
    %c527363 = vm.const.i32 527363
    %c48 = vm.const.i32 48
    %null = vm.const.ref.zero : !vm.ref<!hal.fence>
    %null_0 = vm.const.ref.zero : !vm.ref<!hal.executable>
    %null_1 = vm.const.ref.zero : !vm.buffer
    %c2 = vm.const.i32 2
    %c7 = vm.const.i32 7
    %c1 = vm.const.i32 1
    %zero = vm.const.i64.zero
    %c128 = vm.const.i64 128
    %c-1 = vm.const.i64 -1
    %zero_2 = vm.const.i32.zero
    %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
    %_utf8_cuda_nvptx_fb_B15B42B96FDBACC = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
    %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
    %2 = vm.and.i32 %1, %c1 : i32
    %3 = vm.select.i32 %0#0, %2, %zero_2 : i32
    %ref_3 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero_2, [(%zero_2, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %zero_2)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
    %ref_4 = vm.call.variadic @hal.pipeline_layout.create(%ref, %zero_2, [%ref_3]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
    %4 = vm.select.i64 %3, %zero, %c-1 : i64
    %5 = vm.trunc.i64.i32 %4 : i64 -> i32
    vm.global.store.i32 %3, @_device_query_0 : i32
    vm.global.store.ref %ref_4, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.br_table %5 {
      default: ^bb2,
      0: ^bb1
    }
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %main_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @main_dispatch_0_cuda_nvptx_fb : !vm.buffer
    %ref_5 = vm.call.variadic @hal.executable.create(%ref, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC, %main_dispatch_0_cuda_nvptx_fb, %null_1, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
    vm.br ^bb3(%ref_5 : !vm.ref<!hal.executable>)
  ^bb2:  // pred: ^bb0
    vm.br ^bb3(%null_0 : !vm.ref<!hal.executable>)
  ^bb3(%6: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
    %_const = vm.const.ref.rodata @_const : !vm.buffer
    %ref_6 = vm.call @hal.device.allocator(%ref) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    %ref_7 = vm.call @hal.allocator.import(%ref_6, %c1, %c-1, %c48, %c527363, %_const, %zero, %c128) : (!vm.ref<!hal.allocator>, i32, i64, i32, i32, !vm.buffer, i64, i64) -> !vm.ref<!hal.buffer>
    %rnz = vm.cmp.nz.ref %ref_7 : !vm.ref<!hal.buffer>
    vm.global.store.ref %6, @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
    vm.cond_br %rnz, ^bb5(%null, %ref_7 : !vm.ref<!hal.fence>, !vm.ref<!hal.buffer>), ^bb4
  ^bb4:  // pred: ^bb3
    %ref_8 = vm.call @hal.allocator.allocate(%ref_6, %c-1, %c48, %c527363, %c128) : (!vm.ref<!hal.allocator>, i64, i32, i32, i64) -> !vm.ref<!hal.buffer>
    %ref_9 = vm.call @hal.ex.file.from_memory(%ref, %c-1, %c1, %_const, %zero, %c128, %zero_2) : (!vm.ref<!hal.device>, i64, i32, !vm.buffer, i64, i64, i32) -> !vm.ref<!hal.file>
    %ref_10 = vm.call @hal.fence.create(%ref, %zero_2) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    vm.call @hal.device.queue.read(%ref, %c-1, %null, %ref_10, %ref_9, %zero, %ref_8, %zero, %c128, %zero_2) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.file>, i64, !vm.ref<!hal.buffer>, i64, i64, i32) -> ()
    vm.br ^bb5(%ref_10, %ref_8 : !vm.ref<!hal.fence>, !vm.ref<!hal.buffer>)
  ^bb5(%7: !vm.ref<!hal.fence>, %8: !vm.ref<!hal.buffer>):  // 2 preds: ^bb3, ^bb4
    vm.global.store.ref %8, @_params.weight : !vm.ref<!hal.buffer>
    vm.global.store.ref %7, @_params.weight__timepoint : !vm.ref<!hal.fence>
    vm.br ^bb6
  ^bb6:  // pred: ^bb5
    vm.return
  }
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
vm.func private @main(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
  %c13 = vm.const.i32 13
  %c28 = vm.const.i32 28
  %c2 = vm.const.i32 2
  %c3 = vm.const.i32 3
  %c17 = vm.const.i32 17
  %c48 = vm.const.i32 48
  %null = vm.const.ref.zero : !vm.ref<!hal.fence>
  %zero = vm.const.i32.zero
  %c3075 = vm.const.i32 3075
  %c16 = vm.const.i32 16
  %c3_0 = vm.const.i64 3
  %c-1 = vm.const.i64 -1
  %c-1_1 = vm.const.i32 -1
  %zero_2 = vm.const.i64.zero
  %c128 = vm.const.i64 128
  %c16_3 = vm.const.i64 16
  %c12 = vm.const.i64 12
  %c553648160 = vm.const.i32 553648160
  %c1 = vm.const.i32 1
  %c4 = vm.const.i64 4
  %_params.weight__timepoint = vm.global.load.ref @_params.weight__timepoint : !vm.ref<!hal.fence>
  %_params.weight = vm.global.load.ref @_params.weight : !vm.ref<!hal.buffer>
  %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
  %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
  %_executable_main_dispatch_0 = vm.global.load.ref @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
  %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
  vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1, [%c4]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
  %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
  %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
  %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
  %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
  vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c16_3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
  %ref_6 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
  %0 = vm.call.variadic @hal.fence.await(%c-1_1, [%_params.weight__timepoint]) : (i32, !vm.ref<!hal.fence> ...) -> i32
  %ref_7 = vm.call @hal.device.queue.alloca(%ref_4, %c-1, %null, %ref_6, %zero, %c48, %c3075, %c12) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
  %1 = vm.call.variadic @hal.fence.await(%c-1_1, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
  %ref_8 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
  %2 = vm.select.i64 %_device_query_0, %zero_2, %c-1 : i64
  %3 = vm.trunc.i64.i32 %2 : i64 -> i32
  vm.br_table %3 {
    default: ^bb2,
    0: ^bb1
  }
^bb1:  // pred: ^bb0
  vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_8, %_pipeline_layout_0, %zero, [(%zero, %zero, %ref, %zero_2, %c16_3), (%c1, %zero, %_params.weight, %zero_2, %c128), (%c2, %zero, %ref_7, %zero_2, %c12)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
  vm.call @hal.command_buffer.dispatch(%ref_8, %_executable_main_dispatch_0, %zero, %c3, %c1, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
  vm.br ^bb2
^bb2:  // 2 preds: ^bb0, ^bb1
  vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
  vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
  %ref_9 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
  %4 = vm.call.variadic @hal.fence.await(%c-1_1, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
  vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1, %null, %ref_9, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
  %5 = vm.call.variadic @hal.fence.await(%c-1_1, [%ref_9]) : (i32, !vm.ref<!hal.fence> ...) -> i32
  vm.cond_br %5, ^bb4, ^bb3
^bb3:  // pred: ^bb2
  %ref_10 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_2, %c12, %c553648160, %c1, [%c3_0]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
  vm.return %ref_10 : !vm.ref<!hal.buffer_view>
^bb4:  // pred: ^bb2
  vm.fail %5, "failed to wait on timepoint"
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
vm.func private @__init() {
  %c527363 = vm.const.i32 527363
  %c48 = vm.const.i32 48
  %null = vm.const.ref.zero : !vm.ref<!hal.fence>
  %null_0 = vm.const.ref.zero : !vm.ref<!hal.executable>
  %null_1 = vm.const.ref.zero : !vm.buffer
  %c2 = vm.const.i32 2
  %c7 = vm.const.i32 7
  %c1 = vm.const.i32 1
  %zero = vm.const.i64.zero
  %c128 = vm.const.i64 128
  %c-1 = vm.const.i64 -1
  %zero_2 = vm.const.i32.zero
  %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
  %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
  %_utf8_cuda_nvptx_fb_B15B42B96FDBACC = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
  %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
  %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
  %2 = vm.and.i32 %1, %c1 : i32
  %3 = vm.select.i32 %0#0, %2, %zero_2 : i32
  %ref_3 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero_2, [(%zero_2, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %zero_2)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
  %ref_4 = vm.call.variadic @hal.pipeline_layout.create(%ref, %zero_2, [%ref_3]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
  %4 = vm.select.i64 %3, %zero, %c-1 : i64
  %5 = vm.trunc.i64.i32 %4 : i64 -> i32
  vm.global.store.i32 %3, @_device_query_0 : i32
  vm.global.store.ref %ref_4, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
  vm.br_table %5 {
    default: ^bb2,
    0: ^bb1
  }
^bb1:  // pred: ^bb0
  %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
  %main_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @main_dispatch_0_cuda_nvptx_fb : !vm.buffer
  %ref_5 = vm.call.variadic @hal.executable.create(%ref, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC, %main_dispatch_0_cuda_nvptx_fb, %null_1, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
  vm.br ^bb3(%ref_5 : !vm.ref<!hal.executable>)
^bb2:  // pred: ^bb0
  vm.br ^bb3(%null_0 : !vm.ref<!hal.executable>)
^bb3(%6: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
  %_const = vm.const.ref.rodata @_const : !vm.buffer
  %ref_6 = vm.call @hal.device.allocator(%ref) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
  %ref_7 = vm.call @hal.allocator.import(%ref_6, %c1, %c-1, %c48, %c527363, %_const, %zero, %c128) : (!vm.ref<!hal.allocator>, i32, i64, i32, i32, !vm.buffer, i64, i64) -> !vm.ref<!hal.buffer>
  %rnz = vm.cmp.nz.ref %ref_7 : !vm.ref<!hal.buffer>
  vm.global.store.ref %6, @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
  vm.cond_br %rnz, ^bb5(%null, %ref_7 : !vm.ref<!hal.fence>, !vm.ref<!hal.buffer>), ^bb4
^bb4:  // pred: ^bb3
  %ref_8 = vm.call @hal.allocator.allocate(%ref_6, %c-1, %c48, %c527363, %c128) : (!vm.ref<!hal.allocator>, i64, i32, i32, i64) -> !vm.ref<!hal.buffer>
  %ref_9 = vm.call @hal.ex.file.from_memory(%ref, %c-1, %c1, %_const, %zero, %c128, %zero_2) : (!vm.ref<!hal.device>, i64, i32, !vm.buffer, i64, i64, i32) -> !vm.ref<!hal.file>
  %ref_10 = vm.call @hal.fence.create(%ref, %zero_2) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
  vm.call @hal.device.queue.read(%ref, %c-1, %null, %ref_10, %ref_9, %zero, %ref_8, %zero, %c128, %zero_2) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.file>, i64, !vm.ref<!hal.buffer>, i64, i64, i32) -> ()
  vm.br ^bb5(%ref_10, %ref_8 : !vm.ref<!hal.fence>, !vm.ref<!hal.buffer>)
^bb5(%7: !vm.ref<!hal.fence>, %8: !vm.ref<!hal.buffer>):  // 2 preds: ^bb3, ^bb4
  vm.global.store.ref %8, @_params.weight : !vm.ref<!hal.buffer>
  vm.global.store.ref %7, @_params.weight__timepoint : !vm.ref<!hal.fence>
  vm.return
}

// -----// IR Dump After Inliner (inline) //----- //
vm.module public @LinearModule {
  vm.global.i32 private mutable @_device_query_0 : i32
  vm.global.ref private mutable @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
  vm.global.ref private mutable @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
  vm.global.ref private mutable @_params.weight__timepoint : !vm.ref<!hal.fence>
  vm.global.ref private mutable @_params.weight : !vm.ref<!hal.buffer>
  vm.rodata private @main_dispatch_0_cuda_nvptx_fb {alignment = 16 : i64, mime_type = "application/x-flatbuffers"} dense<"0x080000004355444100FBFFFF1C0000005000000044000000580000000400000001000000C00400000100000004000000200000006D61696E5F64697370617463685F305F6D61746D756C5F31783378345F663332000000000100000000000000010000000100000003000000010000006F0400002F2F0A2F2F2047656E657261746564206279204C4C564D204E56505458204261636B2D456E640A2F2F0A0A2E76657273696F6E20372E350A2E74617267657420736D5F37350A2E616464726573735F73697A652036340A0A092F2F202E676C6F626C096D61696E5F64697370617463685F305F6D61746D756C5F31783378345F6633320A0A2E76697369626C65202E656E747279206D61696E5F64697370617463685F305F6D61746D756C5F31783378345F663332280A092E706172616D202E753634206D61696E5F64697370617463685F305F6D61746D756C5F31783378345F6633325F706172616D5F302C0A092E706172616D202E753634206D61696E5F64697370617463685F305F6D61746D756C5F31783378345F6633325F706172616D5F312C0A092E706172616D202E753634206D61696E5F64697370617463685F305F6D61746D756C5F31783378345F6633325F706172616D5F320A290A2E6D61786E74696420312C20332C20310A7B0A092E726567202E623332200925723C323E3B0A092E726567202E663332200925663C31343E3B0A092E726567202E62363420092572643C373E3B0A0A096C642E706172616D2E7536342009257264312C205B6D61696E5F64697370617463685F305F6D61746D756C5F31783378345F6633325F706172616D5F305D3B0A096C642E706172616D2E7536342009257264322C205B6D61696E5F64697370617463685F305F6D61746D756C5F31783378345F6633325F706172616D5F315D3B0A096C642E706172616D2E7536342009257264332C205B6D61696E5F64697370617463685F305F6D61746D756C5F31783378345F6633325F706172616D5F325D3B0A096D6F762E75333220092572312C202563746169642E783B0A096C642E676C6F62616C2E6E632E76342E66333220097B2566312C202566322C202566332C202566347D2C205B257264315D3B0A096D756C2E776964652E7533322009257264342C202572312C20343B0A096164642E7336342009257264352C20257264322C20257264343B0A096C642E676C6F62616C2E6E632E66333220092566352C205B257264355D3B0A096C642E676C6F62616C2E6E632E66333220092566362C205B257264352B31325D3B0A096C642E676C6F62616C2E6E632E66333220092566372C205B257264352B32345D3B0A096C642E676C6F62616C2E6E632E66333220092566382C205B257264352B33365D3B0A096C642E676C6F62616C2E6E632E66333220092566392C205B257264352B36345D3B0A09666D612E726E2E6633322009256631302C202566312C202566352C202566393B0A09666D612E726E2E6633322009256631312C202566322C202566362C20256631303B0A09666D612E726E2E6633322009256631322C202566332C202566372C20256631313B0A09666D612E726E2E6633322009256631332C202566342C202566382C20256631323B0A096164642E7336342009257264362C20257264332C20257264343B0A0973742E676C6F62616C2E66333220095B257264365D2C20256631333B0A097265743B0A0A7D0A00E4FFFFFF08000000040000000A000000696E7075742E6D6C6972000008000C00040008000E001800040008000C0010001400"> : vector<1302xi8>
  vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
  vm.rodata private @_utf8_cuda_nvptx_fb_B15B42B96FDBACC {alignment = 1 : i64} "cuda-nvptx-fb"
  vm.rodata private @_const {alignment = 64 : i64} #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
  vm.import private @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects}
  vm.import private @hal.ex.file.from_memory(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %access : i32, %buffer : !vm.buffer, %offset : i64, %length : i64, %flags : i32) -> !vm.ref<!hal.file>
  vm.import private @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
  vm.import private @hal.allocator.import(%allocator : !vm.ref<!hal.allocator>, %try : i32, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %source : !vm.buffer, %offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
  vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
  vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
  vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
  vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
  vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer>
  vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
  vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
  vm.import private @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32)
  vm.import private @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects}
  vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
  vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
  vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
  vm.import private @hal.device.queue.read(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_file : !vm.ref<!hal.file>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i32)
  vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
  vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects}
  vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
  vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
  vm.import private @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects}
  vm.rodata private @_utf8_input_0_5FD512E67BEFDEEC {alignment = 1 : i64} "input 0"
  vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
  vm.func private @main(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
    %c13 = vm.const.i32 13
    %c28 = vm.const.i32 28
    %c2 = vm.const.i32 2
    %c3 = vm.const.i32 3
    %c17 = vm.const.i32 17
    %c48 = vm.const.i32 48
    %null = vm.const.ref.zero : !vm.ref<!hal.fence>
    %zero = vm.const.i32.zero
    %c3075 = vm.const.i32 3075
    %c16 = vm.const.i32 16
    %c3_0 = vm.const.i64 3
    %c-1 = vm.const.i64 -1
    %c-1_1 = vm.const.i32 -1
    %zero_2 = vm.const.i64.zero
    %c128 = vm.const.i64 128
    %c16_3 = vm.const.i64 16
    %c12 = vm.const.i64 12
    %c553648160 = vm.const.i32 553648160
    %c1 = vm.const.i32 1
    %c4 = vm.const.i64 4
    %_params.weight__timepoint = vm.global.load.ref @_params.weight__timepoint : !vm.ref<!hal.fence>
    %_params.weight = vm.global.load.ref @_params.weight : !vm.ref<!hal.buffer>
    %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %_executable_main_dispatch_0 = vm.global.load.ref @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
    %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1, [%c4]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
    vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c16_3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %ref_6 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    %0 = vm.call.variadic @hal.fence.await(%c-1_1, [%_params.weight__timepoint]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    %ref_7 = vm.call @hal.device.queue.alloca(%ref_4, %c-1, %null, %ref_6, %zero, %c48, %c3075, %c12) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
    %1 = vm.call.variadic @hal.fence.await(%c-1_1, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    %ref_8 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
    %2 = vm.select.i64 %_device_query_0, %zero_2, %c-1 : i64
    %3 = vm.trunc.i64.i32 %2 : i64 -> i32
    vm.br_table %3 {
      default: ^bb2,
      0: ^bb1
    }
  ^bb1:  // pred: ^bb0
    vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_8, %_pipeline_layout_0, %zero, [(%zero, %zero, %ref, %zero_2, %c16_3), (%c1, %zero, %_params.weight, %zero_2, %c128), (%c2, %zero, %ref_7, %zero_2, %c12)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.call @hal.command_buffer.dispatch(%ref_8, %_executable_main_dispatch_0, %zero, %c3, %c1, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
    vm.br ^bb2
  ^bb2:  // 2 preds: ^bb0, ^bb1
    vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
    vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
    %ref_9 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    %4 = vm.call.variadic @hal.fence.await(%c-1_1, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1, %null, %ref_9, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
    %5 = vm.call.variadic @hal.fence.await(%c-1_1, [%ref_9]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    vm.cond_br %5, ^bb4, ^bb3
  ^bb3:  // pred: ^bb2
    %ref_10 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_2, %c12, %c553648160, %c1, [%c3_0]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
    vm.return %ref_10 : !vm.ref<!hal.buffer_view>
  ^bb4:  // pred: ^bb2
    vm.fail %5, "failed to wait on timepoint"
  }
  vm.export @main attributes {iree.abi.stub}
  vm.export @__init
  vm.func private @__init() {
    %c527363 = vm.const.i32 527363
    %c48 = vm.const.i32 48
    %null = vm.const.ref.zero : !vm.ref<!hal.fence>
    %null_0 = vm.const.ref.zero : !vm.ref<!hal.executable>
    %null_1 = vm.const.ref.zero : !vm.buffer
    %c2 = vm.const.i32 2
    %c7 = vm.const.i32 7
    %c1 = vm.const.i32 1
    %zero = vm.const.i64.zero
    %c128 = vm.const.i64 128
    %c-1 = vm.const.i64 -1
    %zero_2 = vm.const.i32.zero
    %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
    %_utf8_cuda_nvptx_fb_B15B42B96FDBACC = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
    %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
    %2 = vm.and.i32 %1, %c1 : i32
    %3 = vm.select.i32 %0#0, %2, %zero_2 : i32
    %ref_3 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero_2, [(%zero_2, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %zero_2)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
    %ref_4 = vm.call.variadic @hal.pipeline_layout.create(%ref, %zero_2, [%ref_3]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
    %4 = vm.select.i64 %3, %zero, %c-1 : i64
    %5 = vm.trunc.i64.i32 %4 : i64 -> i32
    vm.global.store.i32 %3, @_device_query_0 : i32
    vm.global.store.ref %ref_4, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.br_table %5 {
      default: ^bb2,
      0: ^bb1
    }
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %main_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @main_dispatch_0_cuda_nvptx_fb : !vm.buffer
    %ref_5 = vm.call.variadic @hal.executable.create(%ref, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC, %main_dispatch_0_cuda_nvptx_fb, %null_1, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
    vm.br ^bb3(%ref_5 : !vm.ref<!hal.executable>)
  ^bb2:  // pred: ^bb0
    vm.br ^bb3(%null_0 : !vm.ref<!hal.executable>)
  ^bb3(%6: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
    %_const = vm.const.ref.rodata @_const : !vm.buffer
    %ref_6 = vm.call @hal.device.allocator(%ref) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    %ref_7 = vm.call @hal.allocator.import(%ref_6, %c1, %c-1, %c48, %c527363, %_const, %zero, %c128) : (!vm.ref<!hal.allocator>, i32, i64, i32, i32, !vm.buffer, i64, i64) -> !vm.ref<!hal.buffer>
    %rnz = vm.cmp.nz.ref %ref_7 : !vm.ref<!hal.buffer>
    vm.global.store.ref %6, @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
    vm.cond_br %rnz, ^bb5(%null, %ref_7 : !vm.ref<!hal.fence>, !vm.ref<!hal.buffer>), ^bb4
  ^bb4:  // pred: ^bb3
    %ref_8 = vm.call @hal.allocator.allocate(%ref_6, %c-1, %c48, %c527363, %c128) : (!vm.ref<!hal.allocator>, i64, i32, i32, i64) -> !vm.ref<!hal.buffer>
    %ref_9 = vm.call @hal.ex.file.from_memory(%ref, %c-1, %c1, %_const, %zero, %c128, %zero_2) : (!vm.ref<!hal.device>, i64, i32, !vm.buffer, i64, i64, i32) -> !vm.ref<!hal.file>
    %ref_10 = vm.call @hal.fence.create(%ref, %zero_2) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    vm.call @hal.device.queue.read(%ref, %c-1, %null, %ref_10, %ref_9, %zero, %ref_8, %zero, %c128, %zero_2) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.file>, i64, !vm.ref<!hal.buffer>, i64, i64, i32) -> ()
    vm.br ^bb5(%ref_10, %ref_8 : !vm.ref<!hal.fence>, !vm.ref<!hal.buffer>)
  ^bb5(%7: !vm.ref<!hal.fence>, %8: !vm.ref<!hal.buffer>):  // 2 preds: ^bb3, ^bb4
    vm.global.store.ref %8, @_params.weight : !vm.ref<!hal.buffer>
    vm.global.store.ref %7, @_params.weight__timepoint : !vm.ref<!hal.fence>
    vm.return
  }
}

// -----// IR Dump After CSE (cse) //----- //
vm.module public @LinearModule {
  vm.global.i32 private mutable @_device_query_0 : i32
  vm.global.ref private mutable @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
  vm.global.ref private mutable @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
  vm.global.ref private mutable @_params.weight__timepoint : !vm.ref<!hal.fence>
  vm.global.ref private mutable @_params.weight : !vm.ref<!hal.buffer>
  vm.rodata private @main_dispatch_0_cuda_nvptx_fb {alignment = 16 : i64, mime_type = "application/x-flatbuffers"} dense<"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vector<1302xi8>
  vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
  vm.rodata private @_utf8_cuda_nvptx_fb_B15B42B96FDBACC {alignment = 1 : i64} "cuda-nvptx-fb"
  vm.rodata private @_const {alignment = 64 : i64} #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
  vm.import private @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects}
  vm.import private @hal.ex.file.from_memory(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %access : i32, %buffer : !vm.buffer, %offset : i64, %length : i64, %flags : i32) -> !vm.ref<!hal.file>
  vm.import private @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
  vm.import private @hal.allocator.import(%allocator : !vm.ref<!hal.allocator>, %try : i32, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %source : !vm.buffer, %offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
  vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
  vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
  vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
  vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
  vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer>
  vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
  vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
  vm.import private @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32)
  vm.import private @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects}
  vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
  vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
  vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
  vm.import private @hal.device.queue.read(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_file : !vm.ref<!hal.file>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i32)
  vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
  vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects}
  vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
  vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
  vm.import private @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects}
  vm.rodata private @_utf8_input_0_5FD512E67BEFDEEC {alignment = 1 : i64} "input 0"
  vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
  vm.func private @main(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
    %c13 = vm.const.i32 13
    %c28 = vm.const.i32 28
    %c2 = vm.const.i32 2
    %c3 = vm.const.i32 3
    %c17 = vm.const.i32 17
    %c48 = vm.const.i32 48
    %null = vm.const.ref.zero : !vm.ref<!hal.fence>
    %zero = vm.const.i32.zero
    %c3075 = vm.const.i32 3075
    %c16 = vm.const.i32 16
    %c3_0 = vm.const.i64 3
    %c-1 = vm.const.i64 -1
    %c-1_1 = vm.const.i32 -1
    %zero_2 = vm.const.i64.zero
    %c128 = vm.const.i64 128
    %c16_3 = vm.const.i64 16
    %c12 = vm.const.i64 12
    %c553648160 = vm.const.i32 553648160
    %c1 = vm.const.i32 1
    %c4 = vm.const.i64 4
    %_params.weight__timepoint = vm.global.load.ref @_params.weight__timepoint : !vm.ref<!hal.fence>
    %_params.weight = vm.global.load.ref @_params.weight : !vm.ref<!hal.buffer>
    %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %_executable_main_dispatch_0 = vm.global.load.ref @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
    %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1, [%c4]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
    vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c16_3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %ref_6 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    %0 = vm.call.variadic @hal.fence.await(%c-1_1, [%_params.weight__timepoint]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    %ref_7 = vm.call @hal.device.queue.alloca(%ref_4, %c-1, %null, %ref_6, %zero, %c48, %c3075, %c12) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
    %1 = vm.call.variadic @hal.fence.await(%c-1_1, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    %ref_8 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
    %2 = vm.select.i64 %_device_query_0, %zero_2, %c-1 : i64
    %3 = vm.trunc.i64.i32 %2 : i64 -> i32
    vm.br_table %3 {
      default: ^bb2,
      0: ^bb1
    }
  ^bb1:  // pred: ^bb0
    vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_8, %_pipeline_layout_0, %zero, [(%zero, %zero, %ref, %zero_2, %c16_3), (%c1, %zero, %_params.weight, %zero_2, %c128), (%c2, %zero, %ref_7, %zero_2, %c12)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.call @hal.command_buffer.dispatch(%ref_8, %_executable_main_dispatch_0, %zero, %c3, %c1, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
    vm.br ^bb2
  ^bb2:  // 2 preds: ^bb0, ^bb1
    vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
    vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
    %ref_9 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    %4 = vm.call.variadic @hal.fence.await(%c-1_1, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1, %null, %ref_9, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
    %5 = vm.call.variadic @hal.fence.await(%c-1_1, [%ref_9]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    vm.cond_br %5, ^bb4, ^bb3
  ^bb3:  // pred: ^bb2
    %ref_10 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_2, %c12, %c553648160, %c1, [%c3_0]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
    vm.return %ref_10 : !vm.ref<!hal.buffer_view>
  ^bb4:  // pred: ^bb2
    vm.fail %5, "failed to wait on timepoint"
  }
  vm.export @main attributes {iree.abi.stub}
  vm.export @__init
  vm.func private @__init() {
    %c527363 = vm.const.i32 527363
    %c48 = vm.const.i32 48
    %null = vm.const.ref.zero : !vm.ref<!hal.fence>
    %null_0 = vm.const.ref.zero : !vm.ref<!hal.executable>
    %null_1 = vm.const.ref.zero : !vm.buffer
    %c2 = vm.const.i32 2
    %c7 = vm.const.i32 7
    %c1 = vm.const.i32 1
    %zero = vm.const.i64.zero
    %c128 = vm.const.i64 128
    %c-1 = vm.const.i64 -1
    %zero_2 = vm.const.i32.zero
    %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
    %_utf8_cuda_nvptx_fb_B15B42B96FDBACC = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
    %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
    %2 = vm.and.i32 %1, %c1 : i32
    %3 = vm.select.i32 %0#0, %2, %zero_2 : i32
    %ref_3 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero_2, [(%zero_2, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %zero_2)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
    %ref_4 = vm.call.variadic @hal.pipeline_layout.create(%ref, %zero_2, [%ref_3]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
    %4 = vm.select.i64 %3, %zero, %c-1 : i64
    %5 = vm.trunc.i64.i32 %4 : i64 -> i32
    vm.global.store.i32 %3, @_device_query_0 : i32
    vm.global.store.ref %ref_4, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.br_table %5 {
      default: ^bb2,
      0: ^bb1
    }
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %main_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @main_dispatch_0_cuda_nvptx_fb : !vm.buffer
    %ref_5 = vm.call.variadic @hal.executable.create(%ref, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC, %main_dispatch_0_cuda_nvptx_fb, %null_1, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
    vm.br ^bb3(%ref_5 : !vm.ref<!hal.executable>)
  ^bb2:  // pred: ^bb0
    vm.br ^bb3(%null_0 : !vm.ref<!hal.executable>)
  ^bb3(%6: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
    %_const = vm.const.ref.rodata @_const : !vm.buffer
    %ref_6 = vm.call @hal.device.allocator(%ref) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    %ref_7 = vm.call @hal.allocator.import(%ref_6, %c1, %c-1, %c48, %c527363, %_const, %zero, %c128) : (!vm.ref<!hal.allocator>, i32, i64, i32, i32, !vm.buffer, i64, i64) -> !vm.ref<!hal.buffer>
    %rnz = vm.cmp.nz.ref %ref_7 : !vm.ref<!hal.buffer>
    vm.global.store.ref %6, @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
    vm.cond_br %rnz, ^bb5(%null, %ref_7 : !vm.ref<!hal.fence>, !vm.ref<!hal.buffer>), ^bb4
  ^bb4:  // pred: ^bb3
    %ref_8 = vm.call @hal.allocator.allocate(%ref_6, %c-1, %c48, %c527363, %c128) : (!vm.ref<!hal.allocator>, i64, i32, i32, i64) -> !vm.ref<!hal.buffer>
    %ref_9 = vm.call @hal.ex.file.from_memory(%ref, %c-1, %c1, %_const, %zero, %c128, %zero_2) : (!vm.ref<!hal.device>, i64, i32, !vm.buffer, i64, i64, i32) -> !vm.ref<!hal.file>
    %ref_10 = vm.call @hal.fence.create(%ref, %zero_2) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    vm.call @hal.device.queue.read(%ref, %c-1, %null, %ref_10, %ref_9, %zero, %ref_8, %zero, %c128, %zero_2) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.file>, i64, !vm.ref<!hal.buffer>, i64, i64, i32) -> ()
    vm.br ^bb5(%ref_10, %ref_8 : !vm.ref<!hal.fence>, !vm.ref<!hal.buffer>)
  ^bb5(%7: !vm.ref<!hal.fence>, %8: !vm.ref<!hal.buffer>):  // 2 preds: ^bb3, ^bb4
    vm.global.store.ref %8, @_params.weight : !vm.ref<!hal.buffer>
    vm.global.store.ref %7, @_params.weight__timepoint : !vm.ref<!hal.fence>
    vm.return
  }
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
vm.module public @LinearModule {
  vm.global.i32 private mutable @_device_query_0 : i32
  vm.global.ref private mutable @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
  vm.global.ref private mutable @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
  vm.global.ref private mutable @_params.weight__timepoint : !vm.ref<!hal.fence>
  vm.global.ref private mutable @_params.weight : !vm.ref<!hal.buffer>
  vm.rodata private @main_dispatch_0_cuda_nvptx_fb {alignment = 16 : i64, mime_type = "application/x-flatbuffers"} dense<"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vector<1302xi8>
  vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
  vm.rodata private @_utf8_cuda_nvptx_fb_B15B42B96FDBACC {alignment = 1 : i64} "cuda-nvptx-fb"
  vm.rodata private @_const {alignment = 64 : i64} #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
  vm.import private @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects}
  vm.import private @hal.ex.file.from_memory(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %access : i32, %buffer : !vm.buffer, %offset : i64, %length : i64, %flags : i32) -> !vm.ref<!hal.file>
  vm.import private @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
  vm.import private @hal.allocator.import(%allocator : !vm.ref<!hal.allocator>, %try : i32, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %source : !vm.buffer, %offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
  vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
  vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
  vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
  vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
  vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer>
  vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
  vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
  vm.import private @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32)
  vm.import private @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects}
  vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
  vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
  vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
  vm.import private @hal.device.queue.read(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_file : !vm.ref<!hal.file>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i32)
  vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
  vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects}
  vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
  vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
  vm.import private @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects}
  vm.rodata private @_utf8_input_0_5FD512E67BEFDEEC {alignment = 1 : i64} "input 0"
  vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
  vm.func private @main(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
    %c13 = vm.const.i32 13
    %c28 = vm.const.i32 28
    %c2 = vm.const.i32 2
    %c3 = vm.const.i32 3
    %c17 = vm.const.i32 17
    %c48 = vm.const.i32 48
    %null = vm.const.ref.zero : !vm.ref<!hal.fence>
    %zero = vm.const.i32.zero
    %c3075 = vm.const.i32 3075
    %c16 = vm.const.i32 16
    %c3_0 = vm.const.i64 3
    %c-1 = vm.const.i64 -1
    %c-1_1 = vm.const.i32 -1
    %zero_2 = vm.const.i64.zero
    %c128 = vm.const.i64 128
    %c16_3 = vm.const.i64 16
    %c12 = vm.const.i64 12
    %c553648160 = vm.const.i32 553648160
    %c1 = vm.const.i32 1
    %c4 = vm.const.i64 4
    %_params.weight__timepoint = vm.global.load.ref @_params.weight__timepoint : !vm.ref<!hal.fence>
    %_params.weight = vm.global.load.ref @_params.weight : !vm.ref<!hal.buffer>
    %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %_executable_main_dispatch_0 = vm.global.load.ref @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
    %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1, [%c4]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
    vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c16_3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %ref_6 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    %0 = vm.call.variadic @hal.fence.await(%c-1_1, [%_params.weight__timepoint]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    %ref_7 = vm.call @hal.device.queue.alloca(%ref_4, %c-1, %null, %ref_6, %zero, %c48, %c3075, %c12) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
    %1 = vm.call.variadic @hal.fence.await(%c-1_1, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    %ref_8 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
    %2 = vm.select.i64 %_device_query_0, %zero_2, %c-1 : i64
    %3 = vm.trunc.i64.i32 %2 : i64 -> i32
    vm.br_table %3 {
      default: ^bb2,
      0: ^bb1
    }
  ^bb1:  // pred: ^bb0
    vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_8, %_pipeline_layout_0, %zero, [(%zero, %zero, %ref, %zero_2, %c16_3), (%c1, %zero, %_params.weight, %zero_2, %c128), (%c2, %zero, %ref_7, %zero_2, %c12)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.call @hal.command_buffer.dispatch(%ref_8, %_executable_main_dispatch_0, %zero, %c3, %c1, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
    vm.br ^bb2
  ^bb2:  // 2 preds: ^bb0, ^bb1
    vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
    vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
    %ref_9 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    %4 = vm.call.variadic @hal.fence.await(%c-1_1, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1, %null, %ref_9, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
    %5 = vm.call.variadic @hal.fence.await(%c-1_1, [%ref_9]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    vm.cond_br %5, ^bb4, ^bb3
  ^bb3:  // pred: ^bb2
    %ref_10 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_2, %c12, %c553648160, %c1, [%c3_0]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
    vm.return %ref_10 : !vm.ref<!hal.buffer_view>
  ^bb4:  // pred: ^bb2
    vm.fail %5, "failed to wait on timepoint"
  }
  vm.export @main attributes {iree.abi.stub}
  vm.export @__init
  vm.func private @__init() {
    %c527363 = vm.const.i32 527363
    %c48 = vm.const.i32 48
    %null = vm.const.ref.zero : !vm.ref<!hal.fence>
    %null_0 = vm.const.ref.zero : !vm.ref<!hal.executable>
    %null_1 = vm.const.ref.zero : !vm.buffer
    %c2 = vm.const.i32 2
    %c7 = vm.const.i32 7
    %c1 = vm.const.i32 1
    %zero = vm.const.i64.zero
    %c128 = vm.const.i64 128
    %c-1 = vm.const.i64 -1
    %zero_2 = vm.const.i32.zero
    %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
    %_utf8_cuda_nvptx_fb_B15B42B96FDBACC = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
    %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
    %2 = vm.and.i32 %1, %c1 : i32
    %3 = vm.select.i32 %0#0, %2, %zero_2 : i32
    %ref_3 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero_2, [(%zero_2, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %zero_2)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
    %ref_4 = vm.call.variadic @hal.pipeline_layout.create(%ref, %zero_2, [%ref_3]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
    %4 = vm.select.i64 %3, %zero, %c-1 : i64
    %5 = vm.trunc.i64.i32 %4 : i64 -> i32
    vm.global.store.i32 %3, @_device_query_0 : i32
    vm.global.store.ref %ref_4, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.br_table %5 {
      default: ^bb2,
      0: ^bb1
    }
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %main_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @main_dispatch_0_cuda_nvptx_fb : !vm.buffer
    %ref_5 = vm.call.variadic @hal.executable.create(%ref, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC, %main_dispatch_0_cuda_nvptx_fb, %null_1, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
    vm.br ^bb3(%ref_5 : !vm.ref<!hal.executable>)
  ^bb2:  // pred: ^bb0
    vm.br ^bb3(%null_0 : !vm.ref<!hal.executable>)
  ^bb3(%6: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
    %_const = vm.const.ref.rodata @_const : !vm.buffer
    %ref_6 = vm.call @hal.device.allocator(%ref) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    %ref_7 = vm.call @hal.allocator.import(%ref_6, %c1, %c-1, %c48, %c527363, %_const, %zero, %c128) : (!vm.ref<!hal.allocator>, i32, i64, i32, i32, !vm.buffer, i64, i64) -> !vm.ref<!hal.buffer>
    %rnz = vm.cmp.nz.ref %ref_7 : !vm.ref<!hal.buffer>
    vm.global.store.ref %6, @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
    vm.cond_br %rnz, ^bb5(%null, %ref_7 : !vm.ref<!hal.fence>, !vm.ref<!hal.buffer>), ^bb4
  ^bb4:  // pred: ^bb3
    %ref_8 = vm.call @hal.allocator.allocate(%ref_6, %c-1, %c48, %c527363, %c128) : (!vm.ref<!hal.allocator>, i64, i32, i32, i64) -> !vm.ref<!hal.buffer>
    %ref_9 = vm.call @hal.ex.file.from_memory(%ref, %c-1, %c1, %_const, %zero, %c128, %zero_2) : (!vm.ref<!hal.device>, i64, i32, !vm.buffer, i64, i64, i32) -> !vm.ref<!hal.file>
    %ref_10 = vm.call @hal.fence.create(%ref, %zero_2) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    vm.call @hal.device.queue.read(%ref, %c-1, %null, %ref_10, %ref_9, %zero, %ref_8, %zero, %c128, %zero_2) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.file>, i64, !vm.ref<!hal.buffer>, i64, i64, i32) -> ()
    vm.br ^bb5(%ref_10, %ref_8 : !vm.ref<!hal.fence>, !vm.ref<!hal.buffer>)
  ^bb5(%7: !vm.ref<!hal.fence>, %8: !vm.ref<!hal.buffer>):  // 2 preds: ^bb3, ^bb4
    vm.global.store.ref %8, @_params.weight : !vm.ref<!hal.buffer>
    vm.global.store.ref %7, @_params.weight__timepoint : !vm.ref<!hal.fence>
    vm.return
  }
}

// -----// IR Dump After DropCompilerHints (iree-util-drop-compiler-hints) //----- //
vm.module public @LinearModule {
  vm.global.i32 private mutable @_device_query_0 : i32
  vm.global.ref private mutable @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
  vm.global.ref private mutable @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
  vm.global.ref private mutable @_params.weight__timepoint : !vm.ref<!hal.fence>
  vm.global.ref private mutable @_params.weight : !vm.ref<!hal.buffer>
  vm.rodata private @main_dispatch_0_cuda_nvptx_fb {alignment = 16 : i64, mime_type = "application/x-flatbuffers"} dense<"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vector<1302xi8>
  vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
  vm.rodata private @_utf8_cuda_nvptx_fb_B15B42B96FDBACC {alignment = 1 : i64} "cuda-nvptx-fb"
  vm.rodata private @_const {alignment = 64 : i64} #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
  vm.import private @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects}
  vm.import private @hal.ex.file.from_memory(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %access : i32, %buffer : !vm.buffer, %offset : i64, %length : i64, %flags : i32) -> !vm.ref<!hal.file>
  vm.import private @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
  vm.import private @hal.allocator.import(%allocator : !vm.ref<!hal.allocator>, %try : i32, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %source : !vm.buffer, %offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
  vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
  vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
  vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
  vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
  vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer>
  vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
  vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
  vm.import private @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32)
  vm.import private @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects}
  vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
  vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
  vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
  vm.import private @hal.device.queue.read(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_file : !vm.ref<!hal.file>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i32)
  vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
  vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects}
  vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
  vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
  vm.import private @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects}
  vm.rodata private @_utf8_input_0_5FD512E67BEFDEEC {alignment = 1 : i64} "input 0"
  vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
  vm.func private @main(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
    %c13 = vm.const.i32 13
    %c28 = vm.const.i32 28
    %c2 = vm.const.i32 2
    %c3 = vm.const.i32 3
    %c17 = vm.const.i32 17
    %c48 = vm.const.i32 48
    %null = vm.const.ref.zero : !vm.ref<!hal.fence>
    %zero = vm.const.i32.zero
    %c3075 = vm.const.i32 3075
    %c16 = vm.const.i32 16
    %c3_0 = vm.const.i64 3
    %c-1 = vm.const.i64 -1
    %c-1_1 = vm.const.i32 -1
    %zero_2 = vm.const.i64.zero
    %c128 = vm.const.i64 128
    %c16_3 = vm.const.i64 16
    %c12 = vm.const.i64 12
    %c553648160 = vm.const.i32 553648160
    %c1 = vm.const.i32 1
    %c4 = vm.const.i64 4
    %_params.weight__timepoint = vm.global.load.ref @_params.weight__timepoint : !vm.ref<!hal.fence>
    %_params.weight = vm.global.load.ref @_params.weight : !vm.ref<!hal.buffer>
    %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %_executable_main_dispatch_0 = vm.global.load.ref @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
    %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1, [%c4]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
    vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c16_3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %ref_6 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    %0 = vm.call.variadic @hal.fence.await(%c-1_1, [%_params.weight__timepoint]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    %ref_7 = vm.call @hal.device.queue.alloca(%ref_4, %c-1, %null, %ref_6, %zero, %c48, %c3075, %c12) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
    %1 = vm.call.variadic @hal.fence.await(%c-1_1, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    %ref_8 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
    %2 = vm.select.i64 %_device_query_0, %zero_2, %c-1 : i64
    %3 = vm.trunc.i64.i32 %2 : i64 -> i32
    vm.br_table %3 {
      default: ^bb2,
      0: ^bb1
    }
  ^bb1:  // pred: ^bb0
    vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_8, %_pipeline_layout_0, %zero, [(%zero, %zero, %ref, %zero_2, %c16_3), (%c1, %zero, %_params.weight, %zero_2, %c128), (%c2, %zero, %ref_7, %zero_2, %c12)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.call @hal.command_buffer.dispatch(%ref_8, %_executable_main_dispatch_0, %zero, %c3, %c1, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
    vm.br ^bb2
  ^bb2:  // 2 preds: ^bb0, ^bb1
    vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
    vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
    %ref_9 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    %4 = vm.call.variadic @hal.fence.await(%c-1_1, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1, %null, %ref_9, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
    %5 = vm.call.variadic @hal.fence.await(%c-1_1, [%ref_9]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    vm.cond_br %5, ^bb4, ^bb3
  ^bb3:  // pred: ^bb2
    %ref_10 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_2, %c12, %c553648160, %c1, [%c3_0]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
    vm.return %ref_10 : !vm.ref<!hal.buffer_view>
  ^bb4:  // pred: ^bb2
    vm.fail %5, "failed to wait on timepoint"
  }
  vm.export @main attributes {iree.abi.stub}
  vm.export @__init
  vm.func private @__init() {
    %c527363 = vm.const.i32 527363
    %c48 = vm.const.i32 48
    %null = vm.const.ref.zero : !vm.ref<!hal.fence>
    %null_0 = vm.const.ref.zero : !vm.ref<!hal.executable>
    %null_1 = vm.const.ref.zero : !vm.buffer
    %c2 = vm.const.i32 2
    %c7 = vm.const.i32 7
    %c1 = vm.const.i32 1
    %zero = vm.const.i64.zero
    %c128 = vm.const.i64 128
    %c-1 = vm.const.i64 -1
    %zero_2 = vm.const.i32.zero
    %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
    %_utf8_cuda_nvptx_fb_B15B42B96FDBACC = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
    %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
    %2 = vm.and.i32 %1, %c1 : i32
    %3 = vm.select.i32 %0#0, %2, %zero_2 : i32
    %ref_3 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero_2, [(%zero_2, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %zero_2)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
    %ref_4 = vm.call.variadic @hal.pipeline_layout.create(%ref, %zero_2, [%ref_3]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
    %4 = vm.select.i64 %3, %zero, %c-1 : i64
    %5 = vm.trunc.i64.i32 %4 : i64 -> i32
    vm.global.store.i32 %3, @_device_query_0 : i32
    vm.global.store.ref %ref_4, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.br_table %5 {
      default: ^bb2,
      0: ^bb1
    }
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %main_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @main_dispatch_0_cuda_nvptx_fb : !vm.buffer
    %ref_5 = vm.call.variadic @hal.executable.create(%ref, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC, %main_dispatch_0_cuda_nvptx_fb, %null_1, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
    vm.br ^bb3(%ref_5 : !vm.ref<!hal.executable>)
  ^bb2:  // pred: ^bb0
    vm.br ^bb3(%null_0 : !vm.ref<!hal.executable>)
  ^bb3(%6: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
    %_const = vm.const.ref.rodata @_const : !vm.buffer
    %ref_6 = vm.call @hal.device.allocator(%ref) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    %ref_7 = vm.call @hal.allocator.import(%ref_6, %c1, %c-1, %c48, %c527363, %_const, %zero, %c128) : (!vm.ref<!hal.allocator>, i32, i64, i32, i32, !vm.buffer, i64, i64) -> !vm.ref<!hal.buffer>
    %rnz = vm.cmp.nz.ref %ref_7 : !vm.ref<!hal.buffer>
    vm.global.store.ref %6, @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
    vm.cond_br %rnz, ^bb5(%null, %ref_7 : !vm.ref<!hal.fence>, !vm.ref<!hal.buffer>), ^bb4
  ^bb4:  // pred: ^bb3
    %ref_8 = vm.call @hal.allocator.allocate(%ref_6, %c-1, %c48, %c527363, %c128) : (!vm.ref<!hal.allocator>, i64, i32, i32, i64) -> !vm.ref<!hal.buffer>
    %ref_9 = vm.call @hal.ex.file.from_memory(%ref, %c-1, %c1, %_const, %zero, %c128, %zero_2) : (!vm.ref<!hal.device>, i64, i32, !vm.buffer, i64, i64, i32) -> !vm.ref<!hal.file>
    %ref_10 = vm.call @hal.fence.create(%ref, %zero_2) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    vm.call @hal.device.queue.read(%ref, %c-1, %null, %ref_10, %ref_9, %zero, %ref_8, %zero, %c128, %zero_2) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.file>, i64, !vm.ref<!hal.buffer>, i64, i64, i32) -> ()
    vm.br ^bb5(%ref_10, %ref_8 : !vm.ref<!hal.fence>, !vm.ref<!hal.buffer>)
  ^bb5(%7: !vm.ref<!hal.fence>, %8: !vm.ref<!hal.buffer>):  // 2 preds: ^bb3, ^bb4
    vm.global.store.ref %8, @_params.weight : !vm.ref<!hal.buffer>
    vm.global.store.ref %7, @_params.weight__timepoint : !vm.ref<!hal.fence>
    vm.return
  }
}

// -----// IR Dump After mlir::iree_compiler::IREE::VM::OrdinalAllocationPass (iree-vm-ordinal-allocation) //----- //
vm.module public @LinearModule attributes {ordinal_counts = #vm.ordinal_counts<import_funcs = 23, export_funcs = 2, internal_funcs = 2, global_bytes = 4, global_refs = 4, rodatas = 6, rwdatas = 0>} {
  vm.global.i32 private mutable @_device_query_0 {ordinal = 0 : i32} : i32
  vm.global.ref private mutable @_pipeline_layout_0 {ordinal = 0 : i32} : !vm.ref<!hal.pipeline_layout>
  vm.global.ref private mutable @_executable_main_dispatch_0 {ordinal = 1 : i32} : !vm.ref<!hal.executable>
  vm.global.ref private mutable @_params.weight__timepoint {ordinal = 2 : i32} : !vm.ref<!hal.fence>
  vm.global.ref private mutable @_params.weight {ordinal = 3 : i32} : !vm.ref<!hal.buffer>
  vm.rodata private @main_dispatch_0_cuda_nvptx_fb {alignment = 16 : i64, mime_type = "application/x-flatbuffers", ordinal = 0 : i32} dense<"0x080000004355444100FBFFFF1C0000005000000044000000580000000400000001000000C00400000100000004000000200000006D61696E5F64697370617463685F305F6D61746D756C5F31783378345F663332000000000100000000000000010000000100000003000000010000006F0400002F2F0A2F2F2047656E657261746564206279204C4C564D204E56505458204261636B2D456E640A2F2F0A0A2E76657273696F6E20372E350A2E74617267657420736D5F37350A2E616464726573735F73697A652036340A0A092F2F202E676C6F626C096D61696E5F64697370617463685F305F6D61746D756C5F31783378345F6633320A0A2E76697369626C65202E656E747279206D61696E5F64697370617463685F305F6D61746D756C5F31783378345F663332280A092E706172616D202E753634206D61696E5F64697370617463685F305F6D61746D756C5F31783378345F6633325F706172616D5F302C0A092E706172616D202E753634206D61696E5F64697370617463685F305F6D61746D756C5F31783378345F6633325F706172616D5F312C0A092E706172616D202E753634206D61696E5F64697370617463685F305F6D61746D756C5F31783378345F6633325F706172616D5F320A290A2E6D61786E74696420312C20332C20310A7B0A092E726567202E623332200925723C323E3B0A092E726567202E663332200925663C31343E3B0A092E726567202E62363420092572643C373E3B0A0A096C642E706172616D2E7536342009257264312C205B6D61696E5F64697370617463685F305F6D61746D756C5F31783378345F6633325F706172616D5F305D3B0A096C642E706172616D2E7536342009257264322C205B6D61696E5F64697370617463685F305F6D61746D756C5F31783378345F6633325F706172616D5F315D3B0A096C642E706172616D2E7536342009257264332C205B6D61696E5F64697370617463685F305F6D61746D756C5F31783378345F6633325F706172616D5F325D3B0A096D6F762E75333220092572312C202563746169642E783B0A096C642E676C6F62616C2E6E632E76342E66333220097B2566312C202566322C202566332C202566347D2C205B257264315D3B0A096D756C2E776964652E7533322009257264342C202572312C20343B0A096164642E7336342009257264352C20257264322C20257264343B0A096C642E676C6F62616C2E6E632E66333220092566352C205B257264355D3B0A096C642E676C6F62616C2E6E632E66333220092566362C205B257264352B31325D3B0A096C642E676C6F62616C2E6E632E66333220092566372C205B257264352B32345D3B0A096C642E676C6F62616C2E6E632E66333220092566382C205B257264352B33365D3B0A096C642E676C6F62616C2E6E632E66333220092566392C205B257264352B36345D3B0A09666D612E726E2E6633322009256631302C202566312C202566352C202566393B0A09666D612E726E2E6633322009256631312C202566322C202566362C20256631303B0A09666D612E726E2E6633322009256631322C202566332C202566372C20256631313B0A09666D612E726E2E6633322009256631332C202566342C202566382C20256631323B0A096164642E7336342009257264362C20257264332C20257264343B0A0973742E676C6F62616C2E66333220095B257264365D2C20256631333B0A097265743B0A0A7D0A00E4FFFFFF08000000040000000A000000696E7075742E6D6C6972000008000C00040008000E001800040008000C0010001400"> : vector<1302xi8>
  vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64, ordinal = 1 : i32} "hal.executable.format"
  vm.rodata private @_utf8_cuda_nvptx_fb_B15B42B96FDBACC {alignment = 1 : i64, ordinal = 2 : i32} "cuda-nvptx-fb"
  vm.rodata private @_const {alignment = 64 : i64, ordinal = 3 : i32} #util.composite<128xi8, [
    dense<[[1.54099607, -0.293428898, -2.17878938], [0.568431258, -1.08452237, -1.39859545], [0.403346837, 0.838026344, -0.719257593], [-0.403343529, -0.596635341, 0.182036489]]> : tensor<4x3xf32>,
    dense<0> : vector<16xi8>,
    dense<[-0.856674611, 1.10060418, -1.07118738]> : tensor<3xf32>,
    dense<0> : vector<52xi8>,
]>
  vm.import private @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects, ordinal = 0 : i32}
  vm.import private @hal.ex.file.from_memory(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %access : i32, %buffer : !vm.buffer, %offset : i64, %length : i64, %flags : i32) -> !vm.ref<!hal.file> attributes {ordinal = 1 : i32}
  vm.import private @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32, ordinal = 2 : i32}
  vm.import private @hal.allocator.import(%allocator : !vm.ref<!hal.allocator>, %try : i32, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %source : !vm.buffer, %offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32, ordinal = 3 : i32}
  vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32) attributes {ordinal = 4 : i32}
  vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects, ordinal = 5 : i32}
  vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...) attributes {ordinal = 6 : i32}
  vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects, ordinal = 7 : i32}
  vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {ordinal = 8 : i32}
  vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>) attributes {ordinal = 9 : i32}
  vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32) attributes {ordinal = 10 : i32}
  vm.import private @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...) attributes {ordinal = 11 : i32}
  vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32) attributes {ordinal = 12 : i32}
  vm.import private @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects, ordinal = 13 : i32}
  vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects, ordinal = 14 : i32}
  vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects, ordinal = 15 : i32}
  vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {ordinal = 16 : i32}
  vm.import private @hal.device.queue.read(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_file : !vm.ref<!hal.file>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i32) attributes {ordinal = 17 : i32}
  vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...) attributes {ordinal = 18 : i32}
  vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects, ordinal = 19 : i32}
  vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence> attributes {ordinal = 20 : i32}
  vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {ordinal = 21 : i32, vm.yield}
  vm.import private @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects, ordinal = 22 : i32}
  vm.rodata private @_utf8_input_0_5FD512E67BEFDEEC {alignment = 1 : i64, ordinal = 4 : i32} "input 0"
  vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64, ordinal = 5 : i32} "tensor"
  vm.func private @main(%arg0: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> attributes {ordinal = 0 : i32} {
    %c13 = vm.const.i32 13
    %c28 = vm.const.i32 28
    %c2 = vm.const.i32 2
    %c3 = vm.const.i32 3
    %c17 = vm.const.i32 17
    %c48 = vm.const.i32 48
    %null = vm.const.ref.zero : !vm.ref<!hal.fence>
    %zero = vm.const.i32.zero
    %c3075 = vm.const.i32 3075
    %c16 = vm.const.i32 16
    %c3_0 = vm.const.i64 3
    %c-1 = vm.const.i64 -1
    %c-1_1 = vm.const.i32 -1
    %zero_2 = vm.const.i64.zero
    %c128 = vm.const.i64 128
    %c16_3 = vm.const.i64 16
    %c12 = vm.const.i64 12
    %c553648160 = vm.const.i32 553648160
    %c1 = vm.const.i32 1
    %c4 = vm.const.i64 4
    %_params.weight__timepoint = vm.global.load.ref @_params.weight__timepoint : !vm.ref<!hal.fence>
    %_params.weight = vm.global.load.ref @_params.weight : !vm.ref<!hal.buffer>
    %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %_executable_main_dispatch_0 = vm.global.load.ref @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
    %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1, [%c4]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
    vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %c16_3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %ref_6 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    %0 = vm.call.variadic @hal.fence.await(%c-1_1, [%_params.weight__timepoint]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    %ref_7 = vm.call @hal.device.queue.alloca(%ref_4, %c-1, %null, %ref_6, %zero, %c48, %c3075, %c12) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, i32, i32, i32, i64) -> !vm.ref<!hal.buffer>
    %1 = vm.call.variadic @hal.fence.await(%c-1_1, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    %ref_8 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
    %2 = vm.select.i64 %_device_query_0, %zero_2, %c-1 : i64
    %3 = vm.trunc.i64.i32 %2 : i64 -> i32
    vm.br_table %3 {
      default: ^bb2,
      0: ^bb1
    }
  ^bb1:  // pred: ^bb0
    vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_8, %_pipeline_layout_0, %zero, [(%zero, %zero, %ref, %zero_2, %c16_3), (%c1, %zero, %_params.weight, %zero_2, %c128), (%c2, %zero, %ref_7, %zero_2, %c12)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.call @hal.command_buffer.dispatch(%ref_8, %_executable_main_dispatch_0, %zero, %c3, %c1, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
    vm.br ^bb2
  ^bb2:  // 2 preds: ^bb0, ^bb1
    vm.call @hal.command_buffer.execution_barrier(%ref_8, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
    vm.call @hal.command_buffer.finalize(%ref_8) : (!vm.ref<!hal.command_buffer>) -> ()
    %ref_9 = vm.call @hal.fence.create(%ref_4, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    %4 = vm.call.variadic @hal.fence.await(%c-1_1, [%ref_6]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1, %null, %ref_9, [%ref_8]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
    %5 = vm.call.variadic @hal.fence.await(%c-1_1, [%ref_9]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    vm.cond_br %5, ^bb4, ^bb3
  ^bb3:  // pred: ^bb2
    %ref_10 = vm.call.variadic @hal.buffer_view.create(%ref_7, %zero_2, %c12, %c553648160, %c1, [%c3_0]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
    vm.return %ref_10 : !vm.ref<!hal.buffer_view>
  ^bb4:  // pred: ^bb2
    vm.fail %5, "failed to wait on timepoint"
  }
  vm.export @main attributes {iree.abi.stub, ordinal = 0 : i32}
  vm.export @__init attributes {ordinal = 1 : i32}
  vm.func private @__init() attributes {ordinal = 1 : i32} {
    %c527363 = vm.const.i32 527363
    %c48 = vm.const.i32 48
    %null = vm.const.ref.zero : !vm.ref<!hal.fence>
    %null_0 = vm.const.ref.zero : !vm.ref<!hal.executable>
    %null_1 = vm.const.ref.zero : !vm.buffer
    %c2 = vm.const.i32 2
    %c7 = vm.const.i32 7
    %c1 = vm.const.i32 1
    %zero = vm.const.i64.zero
    %c128 = vm.const.i64 128
    %c-1 = vm.const.i64 -1
    %zero_2 = vm.const.i32.zero
    %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
    %_utf8_cuda_nvptx_fb_B15B42B96FDBACC = vm.const.ref.rodata @_utf8_cuda_nvptx_fb_B15B42B96FDBACC : !vm.buffer
    %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
    %2 = vm.and.i32 %1, %c1 : i32
    %3 = vm.select.i32 %0#0, %2, %zero_2 : i32
    %ref_3 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero_2, [(%zero_2, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %zero_2)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
    %ref_4 = vm.call.variadic @hal.pipeline_layout.create(%ref, %zero_2, [%ref_3]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
    %4 = vm.select.i64 %3, %zero, %c-1 : i64
    %5 = vm.trunc.i64.i32 %4 : i64 -> i32
    vm.global.store.i32 %3, @_device_query_0 : i32
    vm.global.store.ref %ref_4, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.br_table %5 {
      default: ^bb2,
      0: ^bb1
    }
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %main_dispatch_0_cuda_nvptx_fb = vm.const.ref.rodata @main_dispatch_0_cuda_nvptx_fb : !vm.buffer
    %ref_5 = vm.call.variadic @hal.executable.create(%ref, %_utf8_cuda_nvptx_fb_B15B42B96FDBACC, %main_dispatch_0_cuda_nvptx_fb, %null_1, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
    vm.br ^bb3(%ref_5 : !vm.ref<!hal.executable>)
  ^bb2:  // pred: ^bb0
    vm.br ^bb3(%null_0 : !vm.ref<!hal.executable>)
  ^bb3(%6: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
    %_const = vm.const.ref.rodata @_const : !vm.buffer
    %ref_6 = vm.call @hal.device.allocator(%ref) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    %ref_7 = vm.call @hal.allocator.import(%ref_6, %c1, %c-1, %c48, %c527363, %_const, %zero, %c128) : (!vm.ref<!hal.allocator>, i32, i64, i32, i32, !vm.buffer, i64, i64) -> !vm.ref<!hal.buffer>
    %rnz = vm.cmp.nz.ref %ref_7 : !vm.ref<!hal.buffer>
    vm.global.store.ref %6, @_executable_main_dispatch_0 : !vm.ref<!hal.executable>
    vm.cond_br %rnz, ^bb5(%null, %ref_7 : !vm.ref<!hal.fence>, !vm.ref<!hal.buffer>), ^bb4
  ^bb4:  // pred: ^bb3
    %ref_8 = vm.call @hal.allocator.allocate(%ref_6, %c-1, %c48, %c527363, %c128) : (!vm.ref<!hal.allocator>, i64, i32, i32, i64) -> !vm.ref<!hal.buffer>
    %ref_9 = vm.call @hal.ex.file.from_memory(%ref, %c-1, %c1, %_const, %zero, %c128, %zero_2) : (!vm.ref<!hal.device>, i64, i32, !vm.buffer, i64, i64, i32) -> !vm.ref<!hal.file>
    %ref_10 = vm.call @hal.fence.create(%ref, %zero_2) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    vm.call @hal.device.queue.read(%ref, %c-1, %null, %ref_10, %ref_9, %zero, %ref_8, %zero, %c128, %zero_2) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.file>, i64, !vm.ref<!hal.buffer>, i64, i64, i32) -> ()
    vm.br ^bb5(%ref_10, %ref_8 : !vm.ref<!hal.fence>, !vm.ref<!hal.buffer>)
  ^bb5(%7: !vm.ref<!hal.fence>, %8: !vm.ref<!hal.buffer>):  // 2 preds: ^bb3, ^bb4
    vm.global.store.ref %8, @_params.weight : !vm.ref<!hal.buffer>
    vm.global.store.ref %7, @_params.weight__timepoint : !vm.ref<!hal.fence>
    vm.return
  }
}

