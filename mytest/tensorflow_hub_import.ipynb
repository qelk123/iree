{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FH3IRpYTta2v"
      },
      "source": [
        "##### Copyright 2021 The IREE Authors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "cellView": "form",
        "id": "mWGa71_Ct2ug"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License v2.0 with LLVM Exceptions.\n",
        "# See https://llvm.org/LICENSE.txt for license information.\n",
        "# SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qb3S0mSjpK7J"
      },
      "source": [
        "# IREE TensorFlow Hub Import\n",
        "\n",
        "This notebook demonstrates how to download, import, and compile models from [TensorFlow Hub](https://tfhub.dev/). It covers:\n",
        "\n",
        "* Downloading a model from TensorFlow Hub\n",
        "* Ensuring the model has serving signatures needed for import\n",
        "* Importing and compiling the model with IREE\n",
        "\n",
        "At the end of the notebook, the compilation artifacts are compressed into a .zip file for you to download and use in an application.\n",
        "\n",
        "See also https://iree.dev/guides/ml-frameworks/tensorflow/."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rNAJKNVkKOr"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "RdVc4TbOkHM2"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!python -m pip install iree-compiler iree-runtime iree-tools-tf -f https://iree.dev/pip-release-links.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%capture\n",
        "!python -m pip install tensorflow_hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRwv3qI_l5O_",
        "outputId": "8d3bf1f1-1843-4fe9-80e0-a9fc5b194778"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-11-08 13:59:12.712499: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10631] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-08 13:59:12.712547: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-08 13:59:12.713341: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1533] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-08 13:59:12.718909: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-11-08 13:59:13.379252: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorFlow version:  2.16.0-dev20231103\n",
            "Using artifacts directory '/tmp/iree/colab_artifacts'\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tempfile\n",
        "from IPython.display import clear_output\n",
        "\n",
        "from iree.compiler import tf as tfc\n",
        "\n",
        "# Print version information for future notebook users to reference.\n",
        "print(\"TensorFlow version: \", tf.__version__)\n",
        "\n",
        "ARTIFACTS_DIR = os.path.join(tempfile.gettempdir(), \"iree\", \"colab_artifacts\")\n",
        "os.makedirs(ARTIFACTS_DIR, exist_ok=True)\n",
        "print(f\"Using artifacts directory '{ARTIFACTS_DIR}'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZAobcAhocFE"
      },
      "source": [
        "## Import pretrained [`mobilenet_v2`](https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4) model\n",
        "\n",
        "IREE supports importing TensorFlow 2 models exported in the [SavedModel](https://www.tensorflow.org/guide/saved_model) format. This model we'll be importing is published in that format already, while other models may need to be converted first.\n",
        "\n",
        "MobileNet V2 is a family of neural network architectures for efficient on-device image classification and related tasks. This TensorFlow Hub module contains a trained instance of one particular network architecture packaged to perform image classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fd0vmnloZo9",
        "outputId": "dabea3a2-d312-4729-c947-b24216a6c25b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloaded model from tfhub to path: '/tmp/tfhub_modules/426589ad685896ab7954855255a52db3442cb38d'\n"
          ]
        }
      ],
      "source": [
        "#@title Download the pretrained model\n",
        "\n",
        "# Use the `hub` library to download the pretrained model to the local disk\n",
        "# https://www.tensorflow.org/hub/api_docs/python/hub\n",
        "HUB_PATH = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4\"\n",
        "model_path = hub.resolve(HUB_PATH)\n",
        "print(f\"Downloaded model from tfhub to path: '{model_path}'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CedNRSQTOE7C"
      },
      "source": [
        "### Check for serving signatures and re-export as needed\n",
        "\n",
        "IREE's compiler tools, like TensorFlow's `saved_model_cli` and other tools, require \"serving signatures\" to be defined in SavedModels.\n",
        "\n",
        "More references:\n",
        "\n",
        "* https://www.tensorflow.org/tfx/serving/signature_defs\n",
        "* https://blog.tensorflow.org/2021/03/a-tour-of-savedmodel-signatures.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qiO66oEYQmsd",
        "outputId": "91f724db-01cd-4dd3-c55c-ba4431233cfa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/v-yinuoliu/miniconda3/envs/iree_new/lib/python3.10/site-packages/keras/src/layers/core/dense.py:73: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1.0339  \n",
            "Epoch 2/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 656us/step - loss: 0.3853\n",
            "Epoch 3/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 615us/step - loss: 0.2302\n",
            "Epoch 4/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600us/step - loss: 0.1886\n",
            "Epoch 5/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 612us/step - loss: 0.1683\n",
            "Epoch 6/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 602us/step - loss: 0.1607\n",
            "Epoch 7/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 584us/step - loss: 0.1520\n",
            "Epoch 8/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 636us/step - loss: 0.1424\n",
            "Epoch 9/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601us/step - loss: 0.1337\n",
            "Epoch 10/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587us/step - loss: 0.1312\n",
            "<Sequential name=sequential_5, built=True>\n",
            "INFO:tensorflow:Assets written to: /home/v-yinuoliu/code/iree/mytest/simple_tf_model.h5/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /home/v-yinuoliu/code/iree/mytest/simple_tf_model.h5/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "---\n",
            "\n",
            "Checking for signature_defs using saved_model_cli:\n",
            "\n",
            "2023-11-08 15:27:43.189517: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10631] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-08 15:27:43.189563: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-08 15:27:43.190401: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1533] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-08 15:27:43.195301: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-11-08 15:27:43.854749: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-11-08 15:27:44.342848: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:273] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2023-11-08 15:27:44.342894: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:129] retrieving CUDA diagnostic information for host: GCRAZGDL1703\n",
            "2023-11-08 15:27:44.342904: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:136] hostname: GCRAZGDL1703\n",
            "2023-11-08 15:27:44.342975: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:159] libcuda reported version is: 470.182.3\n",
            "2023-11-08 15:27:44.343003: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:163] kernel reported version is: 470.182.3\n",
            "2023-11-08 15:27:44.343013: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:241] kernel version seems to match DSO: 470.182.3\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/v-yinuoliu/miniconda3/envs/iree_new/bin/saved_model_cli\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/home/v-yinuoliu/miniconda3/envs/iree_new/lib/python3.10/site-packages/tensorflow/python/tools/saved_model_cli.py\", line 1329, in main\n",
            "    app.run(smcli_main)\n",
            "  File \"/home/v-yinuoliu/miniconda3/envs/iree_new/lib/python3.10/site-packages/absl/app.py\", line 308, in run\n",
            "    _run_main(main, args)\n",
            "  File \"/home/v-yinuoliu/miniconda3/envs/iree_new/lib/python3.10/site-packages/absl/app.py\", line 254, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"/home/v-yinuoliu/miniconda3/envs/iree_new/lib/python3.10/site-packages/tensorflow/python/tools/saved_model_cli.py\", line 1327, in smcli_main\n",
            "    args.func()\n",
            "  File \"/home/v-yinuoliu/miniconda3/envs/iree_new/lib/python3.10/site-packages/tensorflow/python/tools/saved_model_cli.py\", line 1002, in show\n",
            "    _show_inputs_outputs(\n",
            "  File \"/home/v-yinuoliu/miniconda3/envs/iree_new/lib/python3.10/site-packages/tensorflow/python/tools/saved_model_cli.py\", line 404, in _show_inputs_outputs\n",
            "    _show_inputs_outputs_mgd(meta_graph_def, signature_def_key, indent)\n",
            "  File \"/home/v-yinuoliu/miniconda3/envs/iree_new/lib/python3.10/site-packages/tensorflow/python/tools/saved_model_cli.py\", line 363, in _show_inputs_outputs_mgd\n",
            "    inputs_tensor_info = _get_inputs_tensor_info_from_meta_graph_def(\n",
            "  File \"/home/v-yinuoliu/miniconda3/envs/iree_new/lib/python3.10/site-packages/tensorflow/python/tools/saved_model_cli.py\", line 328, in _get_inputs_tensor_info_from_meta_graph_def\n",
            "    raise ValueError(\n",
            "ValueError: Could not find signature \"serving_default\". Please choose from: __saved_model_init_op\n"
          ]
        }
      ],
      "source": [
        "#@title Check for serving signatures\n",
        "\n",
        "# Load the SavedModel from the local disk and check if it has serving signatures\n",
        "# https://www.tensorflow.org/guide/saved_model#loading_and_using_a_custom_model\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
        "  \n",
        "# Define your model (as an example, a Sequential model is used)  \n",
        "model = tf.keras.models.Sequential([  \n",
        "    tf.keras.layers.Dense(10, input_shape=(32,)),  \n",
        "    tf.keras.layers.Dense(10)  \n",
        "])  \n",
        "  \n",
        "# Compile your model  \n",
        "model.compile(optimizer='adam', loss='mse')  \n",
        "  \n",
        "# Train your model  \n",
        "# (use some random data for this example)  \n",
        "import numpy as np  \n",
        "x = np.random.random((1000, 32))  \n",
        "y = np.random.random((1000, 10))  \n",
        "model.fit(x, y, epochs=10)  \n",
        "print(model)\n",
        "# Save your model  \n",
        "tf.saved_model.save(model, '/home/v-yinuoliu/code/iree/mytest/simple_tf_model.h5')  \n",
        "  \n",
        "# Load your model  \n",
        "loaded_model = tf.saved_model.load('/home/v-yinuoliu/code/iree/mytest/simple_tf_model.h5')  \n",
        "\n",
        "# loaded_model = tf.saved_model.load(model_path)\n",
        "\n",
        "# Also check with the saved_model_cli:\n",
        "print(\"\\n---\\n\")\n",
        "print(\"Checking for signature_defs using saved_model_cli:\\n\")\n",
        "!saved_model_cli show --dir {model_path} --tag_set serve --signature_def serving_default"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKqqX2LsReNz"
      },
      "source": [
        "Since the model we downloaded did not include any serving signatures, we'll re-export it with serving signatures defined.\n",
        "\n",
        "* https://www.tensorflow.org/guide/saved_model#specifying_signatures_during_export"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OlDG2OuqOBGC",
        "outputId": "c25d0e59-3a42-4f43-804c-c607eb9fc84c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "          inputs: TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='inputs')\n"
          ]
        }
      ],
      "source": [
        "#@title Look up input signatures to use when exporting\n",
        "\n",
        "# To save serving signatures we need to specify a `ConcreteFunction` with a\n",
        "# TensorSpec signature. We can determine what this signature should be by\n",
        "# looking at any documentation for the model or running the saved_model_cli.\n",
        "\n",
        "!saved_model_cli show --dir {model_path} --all \\\n",
        "    2> /dev/null | grep \"inputs: TensorSpec\" | tail -n 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gnb4HhMmkgiT",
        "outputId": "d5ff3d4a-0483-476e-af6e-0b3c827d4938"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'_UserObject' object has no attribute '__call__'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[1;32m/home/v-yinuoliu/code/iree/mytest/tensorflow_hub_import.ipynb 单元格 14\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Btunnel/home/v-yinuoliu/code/iree/mytest/tensorflow_hub_import.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m loaded_model \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39msaved_model\u001b[39m.\u001b[39mload(\u001b[39m'\u001b[39m\u001b[39m/home/v-yinuoliu/code/iree/mytest/simple_tf_model.h5\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Btunnel/home/v-yinuoliu/code/iree/mytest/tensorflow_hub_import.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# loaded_model = tf.saved_model.load(model_path)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Btunnel/home/v-yinuoliu/code/iree/mytest/tensorflow_hub_import.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Btunnel/home/v-yinuoliu/code/iree/mytest/tensorflow_hub_import.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m#@title Re-export the model using the known signature\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Btunnel/home/v-yinuoliu/code/iree/mytest/tensorflow_hub_import.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# inference on a single image at a time, so set it to `1`. The rest of the\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btunnel/home/v-yinuoliu/code/iree/mytest/tensorflow_hub_import.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# shape is the fixed image dimensions [width=224, height=224, channels=3].\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Btunnel/home/v-yinuoliu/code/iree/mytest/tensorflow_hub_import.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m call \u001b[39m=\u001b[39m loaded_model\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m\u001b[39m.\u001b[39mget_concrete_function(tf\u001b[39m.\u001b[39mTensorSpec([\u001b[39m1\u001b[39m, \u001b[39m224\u001b[39m, \u001b[39m224\u001b[39m, \u001b[39m3\u001b[39m], tf\u001b[39m.\u001b[39mfloat32))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btunnel/home/v-yinuoliu/code/iree/mytest/tensorflow_hub_import.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# Save the model, setting the concrete function as a serving signature.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btunnel/home/v-yinuoliu/code/iree/mytest/tensorflow_hub_import.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# https://www.tensorflow.org/guide/saved_model#saving_a_custom_model\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btunnel/home/v-yinuoliu/code/iree/mytest/tensorflow_hub_import.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m resaved_model_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/tmp/resaved_model\u001b[39m\u001b[39m'\u001b[39m\n",
            "\u001b[0;31mAttributeError\u001b[0m: '_UserObject' object has no attribute '__call__'"
          ]
        }
      ],
      "source": [
        "loaded_model = tf.saved_model.load('/home/v-yinuoliu/code/iree/mytest/simple_tf_model.h5/add.pbtxt')\n",
        "# loaded_model = tf.saved_model.load(model_path)\n",
        "\n",
        "#@title Re-export the model using the known signature\n",
        "\n",
        "# Get a concrete function using the signature we found above.\n",
        "# \n",
        "# The first element of the shape is a dynamic batch size. We'll be running\n",
        "# inference on a single image at a time, so set it to `1`. The rest of the\n",
        "# shape is the fixed image dimensions [width=224, height=224, channels=3].\n",
        "call = loaded_model.__call__.get_concrete_function(tf.TensorSpec([1, 224, 224, 3], tf.float32))\n",
        "\n",
        "# Save the model, setting the concrete function as a serving signature.\n",
        "# https://www.tensorflow.org/guide/saved_model#saving_a_custom_model\n",
        "resaved_model_path = '/tmp/resaved_model'\n",
        "tf.saved_model.save(loaded_model, resaved_model_path, signatures=call)\n",
        "clear_output()  # Skip over TensorFlow's output.\n",
        "print(f\"Saved model with serving signatures to '{resaved_model_path}'\")\n",
        "\n",
        "# Load the model back into memory and check that it has serving signatures now\n",
        "reloaded_model = tf.saved_model.load(resaved_model_path)\n",
        "reloaded_serving_signatures = list(reloaded_model.signatures.keys())\n",
        "print(f\"\\nReloaded SavedModel from '{resaved_model_path}'\")\n",
        "print(f\"Serving signatures: {reloaded_serving_signatures}\")\n",
        "\n",
        "# Also check with the saved_model_cli:\n",
        "print(\"\\n---\\n\")\n",
        "print(\"Checking for signature_defs using saved_model_cli:\\n\")\n",
        "!saved_model_cli show --dir {resaved_model_path} --tag_set serve --signature_def serving_default"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdmgASzwanSz"
      },
      "source": [
        "### Import and compile the SavedModel with IREE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLkjlHE5mdmg",
        "outputId": "c67419f8-94de-4335-ddbc-f062b7d2e48a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-11-08 16:16:40.846089: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /home/v-yinuoliu/code/iree/mytest/simple_tf_model.h5\n",
            "2023-11-08 16:16:40.846165: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: fail: NOT_FOUND: Could not find SavedModel .pb or .pbtxt at supplied export directory path: /home/v-yinuoliu/code/iree/mytest/simple_tf_model.h5. Check that the directory exists and that you have the right permissions for accessing it.. Took 87 microseconds.\n"
          ]
        },
        {
          "ename": "NotFoundError",
          "evalue": "Could not find SavedModel .pb or .pbtxt at supplied export directory path: /home/v-yinuoliu/code/iree/mytest/simple_tf_model.h5. Check that the directory exists and that you have the right permissions for accessing it.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[1;32m/home/v-yinuoliu/code/iree/mytest/tensorflow_hub_import.ipynb 单元格 16\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Btunnel/home/v-yinuoliu/code/iree/mytest/tensorflow_hub_import.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m iree_input \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(ARTIFACTS_DIR, \u001b[39m\"\u001b[39m\u001b[39m/home/v-yinuoliu/code/iree/mytest/mobilenet_v2_iree_input.mlir\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Btunnel/home/v-yinuoliu/code/iree/mytest/tensorflow_hub_import.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# Since our SavedModel uses signature defs, we use `saved_model_tags` with\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btunnel/home/v-yinuoliu/code/iree/mytest/tensorflow_hub_import.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# `import_type=\"SIGNATURE_DEF\"`. If the SavedModel used an object graph, we\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btunnel/home/v-yinuoliu/code/iree/mytest/tensorflow_hub_import.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# would use `exported_names` with `import_type=\"OBJECT_GRAPH\"` instead.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btunnel/home/v-yinuoliu/code/iree/mytest/tensorflow_hub_import.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# We could instead use different backends here, or set `import_only=True` then\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btunnel/home/v-yinuoliu/code/iree/mytest/tensorflow_hub_import.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# download the imported .mlir file for compilation using native tools directly.\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Btunnel/home/v-yinuoliu/code/iree/mytest/tensorflow_hub_import.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m tfc\u001b[39m.\u001b[39;49mcompile_saved_model(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btunnel/home/v-yinuoliu/code/iree/mytest/tensorflow_hub_import.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39m'\u001b[39;49m\u001b[39m/home/v-yinuoliu/code/iree/mytest/simple_tf_model.h5\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btunnel/home/v-yinuoliu/code/iree/mytest/tensorflow_hub_import.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m     output_file\u001b[39m=\u001b[39;49moutput_file,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btunnel/home/v-yinuoliu/code/iree/mytest/tensorflow_hub_import.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m     save_temp_iree_input\u001b[39m=\u001b[39;49miree_input,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btunnel/home/v-yinuoliu/code/iree/mytest/tensorflow_hub_import.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m     import_type\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mSIGNATURE_DEF\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btunnel/home/v-yinuoliu/code/iree/mytest/tensorflow_hub_import.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m     saved_model_tags\u001b[39m=\u001b[39;49m\u001b[39mset\u001b[39;49m([\u001b[39m\"\u001b[39;49m\u001b[39mserve\u001b[39;49m\u001b[39m\"\u001b[39;49m]),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btunnel/home/v-yinuoliu/code/iree/mytest/tensorflow_hub_import.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m     target_backends\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mvmvx\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btunnel/home/v-yinuoliu/code/iree/mytest/tensorflow_hub_import.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m clear_output()  \u001b[39m# Skip over TensorFlow's output.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btunnel/home/v-yinuoliu/code/iree/mytest/tensorflow_hub_import.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSaved compiled output to \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00moutput_file\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "File \u001b[0;32m~/code/iree/iree-build/compiler/bindings/python/iree/compiler/tools/tf.py:138\u001b[0m, in \u001b[0;36mcompile_saved_model\u001b[0;34m(saved_model_dir, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    135\u001b[0m     \u001b[39m# Not saving the file, so generate a loose temp file without tfs.\u001b[39;00m\n\u001b[1;32m    136\u001b[0m     tf_iree_input \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(tmpdir, \u001b[39m\"\u001b[39m\u001b[39mtf-iree-input.mlirbc\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 138\u001b[0m __main__\u001b[39m.\u001b[39;49mimport_saved_model(\n\u001b[1;32m    139\u001b[0m     output_path\u001b[39m=\u001b[39;49mtf_iree_input,\n\u001b[1;32m    140\u001b[0m     saved_model_dir\u001b[39m=\u001b[39;49msaved_model_dir,\n\u001b[1;32m    141\u001b[0m     exported_names\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m,\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49mjoin(options\u001b[39m.\u001b[39;49mexported_names),\n\u001b[1;32m    142\u001b[0m     import_type\u001b[39m=\u001b[39;49moptions\u001b[39m.\u001b[39;49mimport_type\u001b[39m.\u001b[39;49mvalue,\n\u001b[1;32m    143\u001b[0m     tags\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m,\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49mjoin(options\u001b[39m.\u001b[39;49msaved_model_tags),\n\u001b[1;32m    144\u001b[0m )\n\u001b[1;32m    146\u001b[0m \u001b[39mif\u001b[39;00m options\u001b[39m.\u001b[39mimport_only:\n\u001b[1;32m    147\u001b[0m     \u001b[39mif\u001b[39;00m options\u001b[39m.\u001b[39moutput_file:\n",
            "File \u001b[0;32m~/miniconda3/envs/iree_new/lib/python3.10/site-packages/iree/tools/tf/scripts/iree_import_tf/__main__.py:102\u001b[0m, in \u001b[0;36mimport_saved_model\u001b[0;34m(output_path, saved_model_dir, exported_names, import_type, tags)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mlift_variables\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m sig\u001b[39m.\u001b[39mparameters:\n\u001b[1;32m    101\u001b[0m         dumb_extra_kwargs[\u001b[39m\"\u001b[39m\u001b[39mlift_variables\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> 102\u001b[0m     result \u001b[39m=\u001b[39m convert_saved_model_v1(\n\u001b[1;32m    103\u001b[0m         saved_model_dir,\n\u001b[1;32m    104\u001b[0m         exported_names\u001b[39m=\u001b[39;49mexported_names,\n\u001b[1;32m    105\u001b[0m         tags\u001b[39m=\u001b[39;49mtags,\n\u001b[1;32m    106\u001b[0m         show_debug_info\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    107\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mdumb_extra_kwargs,\n\u001b[1;32m    108\u001b[0m     )\n\u001b[1;32m    109\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    110\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnsupported import type: \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mimport_type\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "File \u001b[0;32m~/miniconda3/envs/iree_new/lib/python3.10/site-packages/tensorflow/python/compiler/mlir/mlir.py:141\u001b[0m, in \u001b[0;36mconvert_saved_model_v1\u001b[0;34m(saved_model_path, exported_names, tags, lift_variables, include_variables_in_initializers, upgrade_legacy, show_debug_info)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mmlir.experimental.convert_saved_model_v1\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    116\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconvert_saved_model_v1\u001b[39m(\n\u001b[1;32m    117\u001b[0m     saved_model_path,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    123\u001b[0m     show_debug_info\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    124\u001b[0m ):\n\u001b[1;32m    125\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Converts a v1 SavedModel to MLIR module.\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \n\u001b[1;32m    127\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[39m    SavedModule.\u001b[39;00m\n\u001b[1;32m    140\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 141\u001b[0m   \u001b[39mreturn\u001b[39;00m pywrap_mlir\u001b[39m.\u001b[39;49mexperimental_convert_saved_model_v1_to_mlir(\n\u001b[1;32m    142\u001b[0m       saved_model_path,\n\u001b[1;32m    143\u001b[0m       exported_names,\n\u001b[1;32m    144\u001b[0m       tags,\n\u001b[1;32m    145\u001b[0m       lift_variables,\n\u001b[1;32m    146\u001b[0m       include_variables_in_initializers,\n\u001b[1;32m    147\u001b[0m       upgrade_legacy,\n\u001b[1;32m    148\u001b[0m       show_debug_info,\n\u001b[1;32m    149\u001b[0m   )\n",
            "File \u001b[0;32m~/miniconda3/envs/iree_new/lib/python3.10/site-packages/tensorflow/python/pywrap_mlir.py:91\u001b[0m, in \u001b[0;36mexperimental_convert_saved_model_v1_to_mlir\u001b[0;34m(saved_model_path, exported_names, tags, lift_variables, include_variables_in_initializers, upgrade_legacy, show_debug_info)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mexperimental_convert_saved_model_v1_to_mlir\u001b[39m(\n\u001b[1;32m     83\u001b[0m     saved_model_path,\n\u001b[1;32m     84\u001b[0m     exported_names,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     89\u001b[0m     show_debug_info,\n\u001b[1;32m     90\u001b[0m ):\n\u001b[0;32m---> 91\u001b[0m   \u001b[39mreturn\u001b[39;00m ExperimentalConvertSavedModelV1ToMlir(\n\u001b[1;32m     92\u001b[0m       \u001b[39mstr\u001b[39;49m(saved_model_path)\u001b[39m.\u001b[39;49mencode(\u001b[39m'\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m'\u001b[39;49m),\n\u001b[1;32m     93\u001b[0m       \u001b[39mstr\u001b[39;49m(exported_names)\u001b[39m.\u001b[39;49mencode(\u001b[39m'\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m'\u001b[39;49m),\n\u001b[1;32m     94\u001b[0m       \u001b[39mstr\u001b[39;49m(tags)\u001b[39m.\u001b[39;49mencode(\u001b[39m'\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m'\u001b[39;49m),\n\u001b[1;32m     95\u001b[0m       lift_variables,\n\u001b[1;32m     96\u001b[0m       include_variables_in_initializers,\n\u001b[1;32m     97\u001b[0m       upgrade_legacy,\n\u001b[1;32m     98\u001b[0m       show_debug_info,\n\u001b[1;32m     99\u001b[0m   )\n",
            "\u001b[0;31mNotFoundError\u001b[0m: Could not find SavedModel .pb or .pbtxt at supplied export directory path: /home/v-yinuoliu/code/iree/mytest/simple_tf_model.h5. Check that the directory exists and that you have the right permissions for accessing it."
          ]
        }
      ],
      "source": [
        "#@title Import from SavedModel\n",
        "\n",
        "# The main output file from compilation is a .vmfb \"VM FlatBuffer\". This file\n",
        "# can used to run the compiled model with IREE's runtime.\n",
        "output_file = os.path.join(ARTIFACTS_DIR, \"/home/v-yinuoliu/code/iree/mytest/mobilenet_v2.vmfb\")\n",
        "# As compilation runs, dump an intermediate .mlir file for future inspection.\n",
        "iree_input = os.path.join(ARTIFACTS_DIR, \"/home/v-yinuoliu/code/iree/mytest/mobilenet_v2_iree_input.mlir\")\n",
        "\n",
        "# Since our SavedModel uses signature defs, we use `saved_model_tags` with\n",
        "# `import_type=\"SIGNATURE_DEF\"`. If the SavedModel used an object graph, we\n",
        "# would use `exported_names` with `import_type=\"OBJECT_GRAPH\"` instead.\n",
        "\n",
        "# We'll set `target_backends=[\"vmvx\"]` to use IREE's reference CPU backend.\n",
        "# We could instead use different backends here, or set `import_only=True` then\n",
        "# download the imported .mlir file for compilation using native tools directly.\n",
        "\n",
        "tfc.compile_saved_model(\n",
        "    '/home/v-yinuoliu/code/iree/mytest/simple_tf_model.h5',\n",
        "    output_file=output_file,\n",
        "    save_temp_iree_input=iree_input,\n",
        "    import_type=\"SIGNATURE_DEF\",\n",
        "    saved_model_tags=set([\"serve\"]),\n",
        "    target_backends=[\"vmvx\"])\n",
        "clear_output()  # Skip over TensorFlow's output.\n",
        "\n",
        "print(f\"Saved compiled output to '{output_file}'\")\n",
        "print(f\"Saved iree_input to      '{iree_input}'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "IEJAzOb5qASI",
        "outputId": "9a29aa51-b99d-4acd-dae8-0d97cf9786e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Zipping '/tmp/iree/colab_artifacts' to '/tmp/mobilenet_colab_artifacts.zip' for download...\n",
            "  adding: mobilenet_v2.vmfb (deflated 8%)\n",
            "  adding: mobilenet_v2_iree_input.mlir (deflated 46%)\n",
            "Downloading the artifacts zip file...\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_18545900-47df-4250-9a14-8453ca4b6fc2\", \"mobilenet_colab_artifacts.zip\", 41434352)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#@title Download compilation artifacts\n",
        "\n",
        "ARTIFACTS_ZIP = \"/tmp/mobilenet_colab_artifacts.zip\"\n",
        "\n",
        "print(f\"Zipping '{ARTIFACTS_DIR}' to '{ARTIFACTS_ZIP}' for download...\")\n",
        "!cd {ARTIFACTS_DIR} && zip -r {ARTIFACTS_ZIP} .\n",
        "\n",
        "# Note: you can also download files using the file explorer on the left\n",
        "try:\n",
        "    from google.colab import files\n",
        "    print(\"Downloading the artifacts zip file...\")\n",
        "    files.download(ARTIFACTS_ZIP)\n",
        "except ImportError:\n",
        "    print(\"Missing google_colab Python package, can't download files\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "-V0X0E7LkEa4",
        "FH3IRpYTta2v"
      ],
      "name": "tensorflow_hub_import.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
